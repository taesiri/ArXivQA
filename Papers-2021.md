
### December 2021
- Optimal Representations for Covariate Shift - [[Arxiv](https://arxiv.org/abs/2201.00057v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.00057v2.md)]
- Optimal Representations for Covariate Shift - [[Arxiv](https://arxiv.org/abs/2201.00057)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.00057.md)]
- ERNIE-ViLG: Unified Generative Pre-training for Bidirectional   Vision-Language Generation - [[Arxiv](https://arxiv.org/abs/2112.15283)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.15283.md)]
- On the Role of Neural Collapse in Transfer Learning - [[Arxiv](https://arxiv.org/abs/2112.15121v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.15121v2.md)]
- On the Role of Neural Collapse in Transfer Learning - [[Arxiv](https://arxiv.org/abs/2112.15121)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.15121.md)]
- Self Reward Design with Fine-grained Interpretability - [[Arxiv](https://arxiv.org/abs/2112.15034v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.15034v3.md)]
- Self Reward Design with Fine-grained Interpretability - [[Arxiv](https://arxiv.org/abs/2112.15034)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.15034.md)]
- Generative Kernel Continual learning - [[Arxiv](https://arxiv.org/abs/2112.13410v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.13410v1.md)]
- Generative Kernel Continual learning - [[Arxiv](https://arxiv.org/abs/2112.13410)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.13410.md)]
- Revisiting Transformation Invariant Geometric Deep Learning: Are Initial   Representations All You Need? - [[Arxiv](https://arxiv.org/abs/2112.12345)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.12345.md)]
- ML4CO: Is GCNN All You Need? Graph Convolutional Neural Networks Produce   Strong Baselines For Combinatorial Optimization Problems, If Tuned and   Trained Properly, on Appropriate Data - [[Arxiv](https://arxiv.org/abs/2112.12251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.12251.md)]
- Cost Aggregation Is All You Need for Few-Shot Segmentation - [[Arxiv](https://arxiv.org/abs/2112.11685)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.11685.md)]
- Generalized Few-Shot Semantic Segmentation: All You Need is Fine-Tuning - [[Arxiv](https://arxiv.org/abs/2112.10982)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.10982.md)]
- High-Resolution Image Synthesis with Latent Diffusion Models - [[Arxiv](https://arxiv.org/abs/2112.10752)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.10752.md)]
- Are Large-scale Datasets Necessary for Self-Supervised Pre-training? - [[Arxiv](https://arxiv.org/abs/2112.10740)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.10740.md)]
- Transformers Can Do Bayesian Inference - [[Arxiv](https://arxiv.org/abs/2112.10510)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.10510.md)]
- Transformers Can Do Bayesian Inference - [[Arxiv](https://arxiv.org/abs/2112.10510v6)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.10510v6.md)]
- Soundify: Matching Sound Effects to Video - [[Arxiv](https://arxiv.org/abs/2112.09726)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.09726.md)]
- Align and Prompt: Video-and-Language Pre-training with Entity Prompts - [[Arxiv](https://arxiv.org/abs/2112.09583)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.09583.md)]
- WebGPT: Browser-assisted question-answering with human feedback - [[Arxiv](https://arxiv.org/abs/2112.09332)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.09332.md)]
- Automated Deep Learning: Neural Architecture Search Is Not the End - [[Arxiv](https://arxiv.org/abs/2112.09245)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.09245.md)]
- All You Need is RAW: Defending Against Adversarial Attacks with Camera   Image Pipelines - [[Arxiv](https://arxiv.org/abs/2112.09219)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.09219.md)]
- Masked Feature Prediction for Self-Supervised Visual Pre-Training - [[Arxiv](https://arxiv.org/abs/2112.09133)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.09133.md)]
- Unsupervised Dense Information Retrieval with Contrastive Learning - [[Arxiv](https://arxiv.org/abs/2112.09118)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.09118.md)]
- NeuroLogic A*esque Decoding: Constrained Text Generation with Lookahead   Heuristics - [[Arxiv](https://arxiv.org/abs/2112.08726)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.08726.md)]
- Reframing Human-AI Collaboration for Generating Free-Text Explanations - [[Arxiv](https://arxiv.org/abs/2112.08674)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.08674.md)]
- Learning to Prompt for Continual Learning - [[Arxiv](https://arxiv.org/abs/2112.08654v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.08654v2.md)]
- Learning to Prompt for Continual Learning - [[Arxiv](https://arxiv.org/abs/2112.08654)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.08654.md)]
- QAHOI: Query-Based Anchors for Human-Object Interaction Detection - [[Arxiv](https://arxiv.org/abs/2112.08647)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.08647.md)]
- Learning To Retrieve Prompts for In-Context Learning - [[Arxiv](https://arxiv.org/abs/2112.08633)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.08633.md)]
- Call for Customized Conversation: Customized Conversation Grounding   Persona and Knowledge - [[Arxiv](https://arxiv.org/abs/2112.08619)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.08619.md)]
- Rethinking Nearest Neighbors for Visual Classification - [[Arxiv](https://arxiv.org/abs/2112.08459)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.08459.md)]
- Improving Conversational Recommendation Systems' Quality with   Context-Aware Item Meta Information - [[Arxiv](https://arxiv.org/abs/2112.08140)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.08140.md)]
- Massive-scale Decoding for Text Generation using Lattices - [[Arxiv](https://arxiv.org/abs/2112.07660)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.07660.md)]
- Improving Human-Object Interaction Detection via Phrase Learning and   Label Composition - [[Arxiv](https://arxiv.org/abs/2112.07383)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.07383.md)]
- MDD-Eval: Self-Training on Augmented Data for Multi-Domain Dialogue   Evaluation - [[Arxiv](https://arxiv.org/abs/2112.07194)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.07194.md)]
- Real-Time Neural Voice Camouflage - [[Arxiv](https://arxiv.org/abs/2112.07076v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.07076v2.md)]
- Real-Time Neural Voice Camouflage - [[Arxiv](https://arxiv.org/abs/2112.07076)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.07076.md)]
- GLaM: Efficient Scaling of Language Models with Mixture-of-Experts - [[Arxiv](https://arxiv.org/abs/2112.06905)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.06905.md)]
- VL-Adapter: Parameter-Efficient Transfer Learning for   Vision-and-Language Tasks - [[Arxiv](https://arxiv.org/abs/2112.06825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.06825.md)]
- Step-unrolled Denoising Autoencoders for Text Generation - [[Arxiv](https://arxiv.org/abs/2112.06749v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.06749v3.md)]
- Step-unrolled Denoising Autoencoders for Text Generation - [[Arxiv](https://arxiv.org/abs/2112.06749)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.06749.md)]
- CR-FIQA: Face Image Quality Assessment by Learning Sample Relative   Classifiability - [[Arxiv](https://arxiv.org/abs/2112.06592)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.06592.md)]
- The Overlooked Classifier in Human-Object Interaction Recognition - [[Arxiv](https://arxiv.org/abs/2112.06392)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.06392.md)]
- Self-Supervised Bot Play for Conversational Recommendation with   Justifications - [[Arxiv](https://arxiv.org/abs/2112.05197)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.05197.md)]
- On Convergence of Federated Averaging Langevin Dynamics - [[Arxiv](https://arxiv.org/abs/2112.05120)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.05120.md)]
- On Convergence of Federated Averaging Langevin Dynamics - [[Arxiv](https://arxiv.org/abs/2112.05120v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.05120v3.md)]
- Scaling Language Models: Methods, Analysis &amp; Insights from Training   Gopher - [[Arxiv](https://arxiv.org/abs/2112.11446)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.11446.md)]
- Prompting Visual-Language Models for Efficient Video Understanding - [[Arxiv](https://arxiv.org/abs/2112.04478)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.04478.md)]
- Improving language models by retrieving from trillions of tokens - [[Arxiv](https://arxiv.org/abs/2112.04426)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.04426.md)]
- Pareto Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2112.04137)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.04137.md)]
- Pareto Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2112.04137v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.04137v2.md)]
- DeepFace-EMD: Re-ranking Using Patch-wise Earth Mover's Distance   Improves Out-Of-Distribution Face Identification - [[Arxiv](https://arxiv.org/abs/2112.04016)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.04016.md)]
- Universalizing Weak Supervision - [[Arxiv](https://arxiv.org/abs/2112.03865)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.03865.md)]
- Universalizing Weak Supervision - [[Arxiv](https://arxiv.org/abs/2112.03865v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.03865v2.md)]
- Genetic Algorithm for Constrained Molecular Inverse Design - [[Arxiv](https://arxiv.org/abs/2112.03518v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.03518v2.md)]
- Genetic Algorithm for Constrained Molecular Inverse Design - [[Arxiv](https://arxiv.org/abs/2112.03518)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.03518.md)]
- Variational Wasserstein gradient flow - [[Arxiv](https://arxiv.org/abs/2112.02424v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.02424v3.md)]
- Variational Wasserstein gradient flow - [[Arxiv](https://arxiv.org/abs/2112.02424)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.02424.md)]
- YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice   Conversion for everyone - [[Arxiv](https://arxiv.org/abs/2112.02418)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.02418.md)]
- Linear algebra with transformers - [[Arxiv](https://arxiv.org/abs/2112.01898v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.01898v2.md)]
- Linear algebra with transformers - [[Arxiv](https://arxiv.org/abs/2112.01898)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.01898.md)]
- Efficient Two-Stage Detection of Human-Object Interactions with a Novel   Unary-Pairwise Transformer - [[Arxiv](https://arxiv.org/abs/2112.01838)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.01838.md)]
- DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting - [[Arxiv](https://arxiv.org/abs/2112.01518)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.01518.md)]
- Neural Stochastic Dual Dynamic Programming - [[Arxiv](https://arxiv.org/abs/2112.00874)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.00874.md)]
- Neural Stochastic Dual Dynamic Programming - [[Arxiv](https://arxiv.org/abs/2112.00874v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.00874v1.md)]
- A General Language Assistant as a Laboratory for Alignment - [[Arxiv](https://arxiv.org/abs/2112.00861)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.00861.md)]
- Routing with Self-Attention for Multimodal Capsule Networks - [[Arxiv](https://arxiv.org/abs/2112.00775v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.00775v1.md)]
- Routing with Self-Attention for Multimodal Capsule Networks - [[Arxiv](https://arxiv.org/abs/2112.00775)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.00775.md)]
- Human-Object Interaction Detection via Weak Supervision - [[Arxiv](https://arxiv.org/abs/2112.00492)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.00492.md)]
- MAD: A Scalable Dataset for Language Grounding in Videos from Movie   Audio Descriptions - [[Arxiv](https://arxiv.org/abs/2112.00431)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.00431.md)]

### November 2021
- Show Your Work: Scratchpads for Intermediate Computation with Language   Models - [[Arxiv](https://arxiv.org/abs/2112.00114)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2112.00114.md)]
- MC-SSL0.0: Towards Multi-Concept Self-Supervised Learning - [[Arxiv](https://arxiv.org/abs/2111.15340)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.15340.md)]
- Towards Robust and Adaptive Motion Forecasting: A Causal Representation   Perspective - [[Arxiv](https://arxiv.org/abs/2111.14820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.14820.md)]
- Point-BERT: Pre-training 3D Point Cloud Transformers with Masked Point   Modeling - [[Arxiv](https://arxiv.org/abs/2111.14819)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.14819.md)]
- GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with   Semi-Supervised Learning and Explicit Policy Injection - [[Arxiv](https://arxiv.org/abs/2111.14592)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.14592.md)]
- A category theory framework for Bayesian learning - [[Arxiv](https://arxiv.org/abs/2111.14293)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.14293.md)]
- Pre-training Methods in Information Retrieval - [[Arxiv](https://arxiv.org/abs/2111.13853)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.13853.md)]
- SQUID: Deep Feature In-Painting for Unsupervised Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2111.13495)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.13495.md)]
- SwinBERT: End-to-End Transformers with Sparse Attention for Video   Captioning - [[Arxiv](https://arxiv.org/abs/2111.13196)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.13196.md)]
- Group equivariant neural posterior estimation - [[Arxiv](https://arxiv.org/abs/2111.13139)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.13139.md)]
- Group equivariant neural posterior estimation - [[Arxiv](https://arxiv.org/abs/2111.13139v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.13139v2.md)]
- CDNet is all you need: Cascade DCN based underwater object detection   RCNN - [[Arxiv](https://arxiv.org/abs/2111.12982)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.12982.md)]
- PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers - [[Arxiv](https://arxiv.org/abs/2111.12710)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.12710.md)]
- VIOLET : End-to-End Video-Language Transformers with Masked Visual-token   Modeling - [[Arxiv](https://arxiv.org/abs/2111.12681)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.12681.md)]
- Hierarchical Modular Network for Video Captioning - [[Arxiv](https://arxiv.org/abs/2111.12476)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.12476.md)]
- NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion - [[Arxiv](https://arxiv.org/abs/2111.12417)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.12417.md)]
- Node-Level Differentially Private Graph Neural Networks - [[Arxiv](https://arxiv.org/abs/2111.15521v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.15521v3.md)]
- Node-Level Differentially Private Graph Neural Networks - [[Arxiv](https://arxiv.org/abs/2111.15521)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.15521.md)]
- Subgraph Permutation Equivariant Networks - [[Arxiv](https://arxiv.org/abs/2111.11840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.11840.md)]
- Variance Reduction in Deep Learning: More Momentum is All You Need - [[Arxiv](https://arxiv.org/abs/2111.11828)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.11828.md)]
- Deep Point Cloud Reconstruction - [[Arxiv](https://arxiv.org/abs/2111.11704)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.11704.md)]
- Deep Point Cloud Reconstruction - [[Arxiv](https://arxiv.org/abs/2111.11704v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.11704v2.md)]
- Lossless Compression with Probabilistic Circuits - [[Arxiv](https://arxiv.org/abs/2111.11632v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.11632v2.md)]
- Lossless Compression with Probabilistic Circuits - [[Arxiv](https://arxiv.org/abs/2111.11632)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.11632.md)]
- Direct Voxel Grid Optimization: Super-fast Convergence for Radiance   Fields Reconstruction - [[Arxiv](https://arxiv.org/abs/2111.11215)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.11215.md)]
- Plant 'n' Seek: Can You Find the Winning Ticket? - [[Arxiv](https://arxiv.org/abs/2111.11153v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.11153v2.md)]
- Plant 'n' Seek: Can You Find the Winning Ticket? - [[Arxiv](https://arxiv.org/abs/2111.11153)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.11153.md)]
- Deep Probability Estimation - [[Arxiv](https://arxiv.org/abs/2111.10734)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.10734.md)]
- Deep Probability Estimation - [[Arxiv](https://arxiv.org/abs/2111.10734v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.10734v4.md)]
- Self-Supervised Point Cloud Completion via Inpainting - [[Arxiv](https://arxiv.org/abs/2111.10701)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.10701.md)]
- Are Vision Transformers Robust to Patch Perturbations? - [[Arxiv](https://arxiv.org/abs/2111.10659)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.10659.md)]
- Are Vision Transformers Robust to Patch Perturbations? - [[Arxiv](https://arxiv.org/abs/2111.10659v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.10659v2.md)]
- Deep Safe Multi-Task Learning - [[Arxiv](https://arxiv.org/abs/2111.10601v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.10601v2.md)]
- Deep Safe Multi-Task Learning - [[Arxiv](https://arxiv.org/abs/2111.10601)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.10601.md)]
- FBNetV5: Neural Architecture Search for Multiple Tasks in One Run - [[Arxiv](https://arxiv.org/abs/2111.10007)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.10007.md)]
- SimMIM: A Simple Framework for Masked Image Modeling - [[Arxiv](https://arxiv.org/abs/2111.09886)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.09886.md)]
- One-Shot Generative Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2111.09876)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.09876.md)]
- Perceiving and Modeling Density is All You Need for Image Dehazing - [[Arxiv](https://arxiv.org/abs/2111.09733)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.09733.md)]
- Selective Ensembles for Consistent Predictions - [[Arxiv](https://arxiv.org/abs/2111.08230v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.08230v1.md)]
- Selective Ensembles for Consistent Predictions - [[Arxiv](https://arxiv.org/abs/2111.08230)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.08230.md)]
- iBOT: Image BERT Pre-Training with Online Tokenizer - [[Arxiv](https://arxiv.org/abs/2111.07832)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.07832.md)]
- Bolstering Stochastic Gradient Descent with Model Building - [[Arxiv](https://arxiv.org/abs/2111.07058)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.07058.md)]
- Bolstering Stochastic Gradient Descent with Model Building - [[Arxiv](https://arxiv.org/abs/2111.07058v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.07058v2.md)]
- Masked Autoencoders Are Scalable Vision Learners - [[Arxiv](https://arxiv.org/abs/2111.06377)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.06377.md)]
- Gradients are Not All You Need - [[Arxiv](https://arxiv.org/abs/2111.05803)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.05803.md)]
- Sliced Recursive Transformer - [[Arxiv](https://arxiv.org/abs/2111.05297v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.05297v3.md)]
- Sliced Recursive Transformer - [[Arxiv](https://arxiv.org/abs/2111.05297)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.05297.md)]
- Realizable Learning is All You Need - [[Arxiv](https://arxiv.org/abs/2111.04746)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.04746.md)]
- MT3: Multi-Task Multitrack Music Transcription - [[Arxiv](https://arxiv.org/abs/2111.03017)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.03017.md)]
- MT3: Multi-Task Multitrack Music Transcription - [[Arxiv](https://arxiv.org/abs/2111.03017v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.03017v4.md)]
- Is Bang-Bang Control All You Need? Solving Continuous Control with   Bernoulli Policies - [[Arxiv](https://arxiv.org/abs/2111.02552)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.02552.md)]
- LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs - [[Arxiv](https://arxiv.org/abs/2111.02114)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.02114.md)]
- Can Vision Transformers Perform Convolution? - [[Arxiv](https://arxiv.org/abs/2111.01353)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.01353.md)]
- Can Vision Transformers Perform Convolution? - [[Arxiv](https://arxiv.org/abs/2111.01353v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.01353v2.md)]
- Deep neural networks as nested dynamical systems - [[Arxiv](https://arxiv.org/abs/2111.01297)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.01297.md)]
- Towards the Generalization of Contrastive Self-Supervised Learning - [[Arxiv](https://arxiv.org/abs/2111.00743)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.00743.md)]

### October 2021
- Template Filling for Controllable Commonsense Reasoning - [[Arxiv](https://arxiv.org/abs/2111.00539)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2111.00539.md)]
- Hyperparameter Tuning is All You Need for LISTA - [[Arxiv](https://arxiv.org/abs/2110.15900)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.15900.md)]
- Improving Fairness via Federated Learning - [[Arxiv](https://arxiv.org/abs/2110.15545)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.15545.md)]
- Improving Fairness via Federated Learning - [[Arxiv](https://arxiv.org/abs/2110.15545v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.15545v3.md)]
- The magnitude vector of images - [[Arxiv](https://arxiv.org/abs/2110.15188)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.15188.md)]
- The magnitude vector of images - [[Arxiv](https://arxiv.org/abs/2110.15188v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.15188v2.md)]
- Semi-Siamese Bi-encoder Neural Ranking Model Using Lightweight   Fine-Tuning - [[Arxiv](https://arxiv.org/abs/2110.14943)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.14943.md)]
- Training Verifiers to Solve Math Word Problems - [[Arxiv](https://arxiv.org/abs/2110.14168)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.14168.md)]
- s2s-ft: Fine-Tuning Pretrained Transformer Encoders for   Sequence-to-Sequence Learning - [[Arxiv](https://arxiv.org/abs/2110.13640)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.13640.md)]
- The Efficiency Misnomer - [[Arxiv](https://arxiv.org/abs/2110.12894)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.12894.md)]
- The Efficiency Misnomer - [[Arxiv](https://arxiv.org/abs/2110.12894v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.12894v2.md)]
- Facilitating Database Tuning with Hyper-Parameter Optimization: A   Comprehensive Experimental Evaluation - [[Arxiv](https://arxiv.org/abs/2110.12654)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.12654.md)]
- DelightfulTTS: The Microsoft Speech Synthesis System for Blizzard   Challenge 2021 - [[Arxiv](https://arxiv.org/abs/2110.12612)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.12612.md)]
- Double Trouble: How to not explain a text classifier's decisions using   counterfactuals synthesized by masked language models? - [[Arxiv](https://arxiv.org/abs/2110.11929)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.11929.md)]
- Center Loss Regularization for Continual Learning - [[Arxiv](https://arxiv.org/abs/2110.11314)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.11314.md)]
- Center Loss Regularization for Continual Learning - [[Arxiv](https://arxiv.org/abs/2110.11314v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.11314v1.md)]
- Fast Model Editing at Scale - [[Arxiv](https://arxiv.org/abs/2110.11309v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.11309v2.md)]
- Fast Model Editing at Scale - [[Arxiv](https://arxiv.org/abs/2110.11309)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.11309.md)]
- SILG: The Multi-environment Symbolic Interactive Language Grounding   Benchmark - [[Arxiv](https://arxiv.org/abs/2110.10661)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.10661.md)]
- BERMo: What can BERT learn from ELMo? - [[Arxiv](https://arxiv.org/abs/2110.15802)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.15802.md)]
- BERMo: What can BERT learn from ELMo? - [[Arxiv](https://arxiv.org/abs/2110.15802v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.15802v1.md)]
- TLDR: Twin Learning for Dimensionality Reduction - [[Arxiv](https://arxiv.org/abs/2110.09455)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.09455.md)]
- TLDR: Twin Learning for Dimensionality Reduction - [[Arxiv](https://arxiv.org/abs/2110.09455v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.09455v2.md)]
- Natural Attribute-based Shift Detection - [[Arxiv](https://arxiv.org/abs/2110.09276)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.09276.md)]
- Natural Attribute-based Shift Detection - [[Arxiv](https://arxiv.org/abs/2110.09276v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.09276v1.md)]
- Illiterate DALL-E Learns to Compose - [[Arxiv](https://arxiv.org/abs/2110.11405)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.11405.md)]
- Illiterate DALL-E Learns to Compose - [[Arxiv](https://arxiv.org/abs/2110.11405v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.11405v3.md)]
- Multimodal Dialogue Response Generation - [[Arxiv](https://arxiv.org/abs/2110.08515)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.08515.md)]
- Comparing Human and Machine Bias in Face Recognition - [[Arxiv](https://arxiv.org/abs/2110.08396)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.08396.md)]
- Comparing Human and Machine Bias in Face Recognition - [[Arxiv](https://arxiv.org/abs/2110.08396v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.08396v2.md)]
- Generated Knowledge Prompting for Commonsense Reasoning - [[Arxiv](https://arxiv.org/abs/2110.08387)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.08387.md)]
- On Learning the Transformer Kernel - [[Arxiv](https://arxiv.org/abs/2110.08323)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.08323.md)]
- On Learning the Transformer Kernel - [[Arxiv](https://arxiv.org/abs/2110.08323v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.08323v2.md)]
- Multitask Prompted Training Enables Zero-Shot Task Generalization - [[Arxiv](https://arxiv.org/abs/2110.08207)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.08207.md)]
- Guided Point Contrastive Learning for Semi-supervised Point Cloud   Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2110.08188)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.08188.md)]
- Few-Shot Bot: Prompt-Based Learning for Dialogue Systems - [[Arxiv](https://arxiv.org/abs/2110.08118)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.08118.md)]
- Jurassic is (almost) All You Need: Few-Shot Meaning-to-Text Generation   for Open-Domain Dialogue - [[Arxiv](https://arxiv.org/abs/2110.08094)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.08094.md)]
- On-Policy Model Errors in Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2110.07985)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.07985.md)]
- On-Policy Model Errors in Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2110.07985v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.07985v2.md)]
- Attacking Open-domain Question Answering by Injecting Misinformation - [[Arxiv](https://arxiv.org/abs/2110.07803)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.07803.md)]
- ContraQA: Question Answering under Contradicting Contexts - [[Arxiv](https://arxiv.org/abs/2110.07803v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.07803v2.md)]
- RecInDial: A Unified Framework for Conversational Recommendation with   Pretrained Language Models - [[Arxiv](https://arxiv.org/abs/2110.07477)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.07477.md)]
- RocketQAv2: A Joint Training Method for Dense Passage Retrieval and   Passage Re-ranking - [[Arxiv](https://arxiv.org/abs/2110.07367)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.07367.md)]
- CLIP4Caption: CLIP for Video Caption - [[Arxiv](https://arxiv.org/abs/2110.06615)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.06615.md)]
- Parallel Deep Neural Networks Have Zero Duality Gap - [[Arxiv](https://arxiv.org/abs/2110.06482)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.06482.md)]
- Parallel Deep Neural Networks Have Zero Duality Gap - [[Arxiv](https://arxiv.org/abs/2110.06482v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.06482v3.md)]
- Causal discovery from conditionally stationary time-series - [[Arxiv](https://arxiv.org/abs/2110.06257v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.06257v1.md)]
- Causal discovery from conditionally stationary time-series - [[Arxiv](https://arxiv.org/abs/2110.06257)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.06257.md)]
- Molecular Graph Generation via Geometric Scattering - [[Arxiv](https://arxiv.org/abs/2110.06241)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.06241.md)]
- Molecular Graph Generation via Geometric Scattering - [[Arxiv](https://arxiv.org/abs/2110.06241v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.06241v1.md)]
- Open-Set Recognition: a Good Closed-Set Classifier is All You Need? - [[Arxiv](https://arxiv.org/abs/2110.06207)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.06207.md)]
- Efficient Neural Ranking using Forward Indexes - [[Arxiv](https://arxiv.org/abs/2110.06051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.06051.md)]
- DiscoDVT: Generating Long Text with Discourse-Aware Discrete Variational   Transformer - [[Arxiv](https://arxiv.org/abs/2110.05999)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.05999.md)]
- Relative Molecule Self-Attention Transformer - [[Arxiv](https://arxiv.org/abs/2110.05841)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.05841.md)]
- Relative Molecule Self-Attention Transformer - [[Arxiv](https://arxiv.org/abs/2110.05841v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.05841v1.md)]
- Learning Discrete Representations via Constrained Clustering for   Effective and Efficient Dense Retrieval - [[Arxiv](https://arxiv.org/abs/2110.05789)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.05789.md)]
- Certified Patch Robustness via Smoothed Vision Transformers - [[Arxiv](https://arxiv.org/abs/2110.07719)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.07719.md)]
- Certified Patch Robustness via Smoothed Vision Transformers - [[Arxiv](https://arxiv.org/abs/2110.07719v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.07719v1.md)]
- Global Vision Transformer Pruning with Hessian-Aware Saliency - [[Arxiv](https://arxiv.org/abs/2110.04869)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04869.md)]
- Long Expressive Memory for Sequence Modeling - [[Arxiv](https://arxiv.org/abs/2110.04744)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04744.md)]
- Long Expressive Memory for Sequence Modeling - [[Arxiv](https://arxiv.org/abs/2110.04744v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04744v2.md)]
- Vector-quantized Image Modeling with Improved VQGAN - [[Arxiv](https://arxiv.org/abs/2110.04627)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04627.md)]
- Multi-Agent MDP Homomorphic Networks - [[Arxiv](https://arxiv.org/abs/2110.04495)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04495.md)]
- Multi-Agent MDP Homomorphic Networks - [[Arxiv](https://arxiv.org/abs/2110.04495v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04495v2.md)]
- Neural Link Prediction with Walk Pooling - [[Arxiv](https://arxiv.org/abs/2110.04375)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04375.md)]
- Neural Link Prediction with Walk Pooling - [[Arxiv](https://arxiv.org/abs/2110.04375v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04375v2.md)]
- FRL: Federated Rank Learning - [[Arxiv](https://arxiv.org/abs/2110.04350)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04350.md)]
- FRL: Federated Rank Learning - [[Arxiv](https://arxiv.org/abs/2110.04350v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04350v3.md)]
- On the Limitations of Multimodal VAEs - [[Arxiv](https://arxiv.org/abs/2110.04121)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04121.md)]
- On the Limitations of Multimodal VAEs - [[Arxiv](https://arxiv.org/abs/2110.04121v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04121v2.md)]
- Token Pooling in Vision Transformers - [[Arxiv](https://arxiv.org/abs/2110.03860)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03860.md)]
- Token Pooling in Vision Transformers - [[Arxiv](https://arxiv.org/abs/2110.03860v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03860v2.md)]
- FOCUS: Familiar Objects in Common and Uncommon Settings - [[Arxiv](https://arxiv.org/abs/2110.03804v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03804v2.md)]
- FOCUS: Familiar Objects in Common and Uncommon Settings - [[Arxiv](https://arxiv.org/abs/2110.03804)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03804.md)]
- Hyperparameter Tuning with Renyi Differential Privacy - [[Arxiv](https://arxiv.org/abs/2110.03620v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03620v2.md)]
- Hyperparameter Tuning with Renyi Differential Privacy - [[Arxiv](https://arxiv.org/abs/2110.03620)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03620.md)]
- Adversarial Retriever-Ranker for dense text retrieval - [[Arxiv](https://arxiv.org/abs/2110.03611)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03611.md)]
- Adversarial Retriever-Ranker for dense text retrieval - [[Arxiv](https://arxiv.org/abs/2110.03611v5)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03611v5.md)]
- RAR: Region-Aware Point Cloud Registration - [[Arxiv](https://arxiv.org/abs/2110.03544)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03544.md)]
- Cartoon Explanations of Image Classifiers - [[Arxiv](https://arxiv.org/abs/2110.03485v5)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03485v5.md)]
- Cartoon Explanations of Image Classifiers - [[Arxiv](https://arxiv.org/abs/2110.03485)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03485.md)]
- Situated Dialogue Learning through Procedural Environment Generation - [[Arxiv](https://arxiv.org/abs/2110.03262)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03262.md)]
- On the Optimal Memorization Power of ReLU Neural Networks - [[Arxiv](https://arxiv.org/abs/2110.03187v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03187v1.md)]
- On the Optimal Memorization Power of ReLU Neural Networks - [[Arxiv](https://arxiv.org/abs/2110.03187)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03187.md)]
- Attention is All You Need? Good Embeddings with Statistics are   enough:Large Scale Audio Understanding without Transformers/ Convolutions/   BERTs/ Mixers/ Attention/ RNNs or .... - [[Arxiv](https://arxiv.org/abs/2110.03183)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.03183.md)]
- Generative Modeling with Optimal Transport Maps - [[Arxiv](https://arxiv.org/abs/2110.02999v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02999v2.md)]
- Generative Modeling with Optimal Transport Maps - [[Arxiv](https://arxiv.org/abs/2110.02999)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02999.md)]
- Federated Learning via Plurality Vote - [[Arxiv](https://arxiv.org/abs/2110.02998v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02998v3.md)]
- Federated Learning via Plurality Vote - [[Arxiv](https://arxiv.org/abs/2110.02998)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02998.md)]
- Nested Policy Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2110.02879)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02879.md)]
- Nested Policy Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2110.02879v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02879v1.md)]
- How BPE Affects Memorization in Transformers - [[Arxiv](https://arxiv.org/abs/2110.02782v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02782v2.md)]
- How BPE Affects Memorization in Transformers - [[Arxiv](https://arxiv.org/abs/2110.02782)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02782.md)]
- On The Transferability of Deep-Q Networks - [[Arxiv](https://arxiv.org/abs/2110.02639v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02639v2.md)]
- On The Transferability of Deep-Q Networks - [[Arxiv](https://arxiv.org/abs/2110.02639)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02639.md)]
- Test-time Batch Statistics Calibration for Covariate Shift - [[Arxiv](https://arxiv.org/abs/2110.04065)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04065.md)]
- Test-time Batch Statistics Calibration for Covariate Shift - [[Arxiv](https://arxiv.org/abs/2110.04065v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.04065v1.md)]
- Geometric Algebra Attention Networks for Small Point Clouds - [[Arxiv](https://arxiv.org/abs/2110.02393)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02393.md)]
- Geometric Algebra Attention Networks for Small Point Clouds - [[Arxiv](https://arxiv.org/abs/2110.02393v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02393v2.md)]
- EntQA: Entity Linking as Question Answering - [[Arxiv](https://arxiv.org/abs/2110.02369v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02369v2.md)]
- EntQA: Entity Linking as Question Answering - [[Arxiv](https://arxiv.org/abs/2110.02369)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02369.md)]
- Autoregressive Diffusion Models - [[Arxiv](https://arxiv.org/abs/2110.02037v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02037v2.md)]
- Autoregressive Diffusion Models - [[Arxiv](https://arxiv.org/abs/2110.02037)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.02037.md)]
- AI Chains: Transparent and Controllable Human-AI Interaction by Chaining   Large Language Model Prompts - [[Arxiv](https://arxiv.org/abs/2110.01691)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.01691.md)]
- Generalized Kernel Thinning - [[Arxiv](https://arxiv.org/abs/2110.01593v5)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.01593v5.md)]
- Generalized Kernel Thinning - [[Arxiv](https://arxiv.org/abs/2110.01593)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.01593.md)]
- One Timestep is All You Need: Training Spiking Neural Networks with   Ultra Low Latency - [[Arxiv](https://arxiv.org/abs/2110.05929)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.05929.md)]
- Batch size-invariance for policy optimization - [[Arxiv](https://arxiv.org/abs/2110.00641)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.00641.md)]
- Batch size-invariance for policy optimization - [[Arxiv](https://arxiv.org/abs/2110.00641v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.00641v3.md)]
- Vision-Only Robot Navigation in a Neural Radiance World - [[Arxiv](https://arxiv.org/abs/2110.00168)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2110.00168.md)]

### September 2021
- Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System - [[Arxiv](https://arxiv.org/abs/2109.14739)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.14739.md)]
- Stochastic Training is Not Necessary for Generalization - [[Arxiv](https://arxiv.org/abs/2109.14119v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.14119v2.md)]
- Stochastic Training is Not Necessary for Generalization - [[Arxiv](https://arxiv.org/abs/2109.14119)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.14119.md)]
- IGLU: Efficient GCN Training via Lazy Updates - [[Arxiv](https://arxiv.org/abs/2109.13995v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.13995v2.md)]
- IGLU: Efficient GCN Training via Lazy Updates - [[Arxiv](https://arxiv.org/abs/2109.13995)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.13995.md)]
- Unsolved Problems in ML Safety - [[Arxiv](https://arxiv.org/abs/2109.13916)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.13916.md)]
- OpenViDial 2.0: A Larger-Scale, Open-Domain Dialogue Generation Dataset   with Visual Contexts - [[Arxiv](https://arxiv.org/abs/2109.12761)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.12761.md)]
- Learning Neural Templates for Recommender Dialogue System - [[Arxiv](https://arxiv.org/abs/2109.12302)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.12302.md)]
- CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2109.11797)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.11797.md)]
- A Survey on Cost Types, Interaction Schemes, and Annotator Performance   Models in Selection Algorithms for Active Learning in Classification - [[Arxiv](https://arxiv.org/abs/2109.11301)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.11301.md)]
- Recursively Summarizing Books with Human Feedback - [[Arxiv](https://arxiv.org/abs/2109.10862)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.10862.md)]
- Scalable and Efficient MoE Training for Multitask Multilingual Models - [[Arxiv](https://arxiv.org/abs/2109.10465)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.10465.md)]
- SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval - [[Arxiv](https://arxiv.org/abs/2109.10086)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.10086.md)]
- Neural networks with trainable matrix activation functions - [[Arxiv](https://arxiv.org/abs/2109.09948)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.09948.md)]
- Neural networks with trainable matrix activation functions - [[Arxiv](https://arxiv.org/abs/2109.09948v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.09948v4.md)]
- PLATO-XL: Exploring the Large-scale Pre-training of Dialogue Generation - [[Arxiv](https://arxiv.org/abs/2109.09519)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.09519.md)]
- DuRecDial 2.0: A Bilingual Parallel Corpus for Conversational   Recommendation - [[Arxiv](https://arxiv.org/abs/2109.08877)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.08877.md)]
- Perspective-taking and Pragmatics for Generating Empathetic Responses   Focused on Emotion Causes - [[Arxiv](https://arxiv.org/abs/2109.08828)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.08828.md)]
- Primer: Searching for Efficient Transformers for Language Modeling - [[Arxiv](https://arxiv.org/abs/2109.08668)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.08668.md)]
- Is Curiosity All You Need? On the Utility of Emergent Behaviours from   Curious Exploration - [[Arxiv](https://arxiv.org/abs/2109.08603)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.08603.md)]
- Torch.manual_seed(3407) is all you need: On the influence of random   seeds in deep learning architectures for computer vision - [[Arxiv](https://arxiv.org/abs/2109.08203)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.08203.md)]
- Scaling Laws for Neural Machine Translation - [[Arxiv](https://arxiv.org/abs/2109.07740)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.07740.md)]
- Scaling Laws for Neural Machine Translation - [[Arxiv](https://arxiv.org/abs/2109.07740v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.07740v1.md)]
- Transferable Persona-Grounded Dialogues via Grounded Minimal Edits - [[Arxiv](https://arxiv.org/abs/2109.07713)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.07713.md)]
- Attention Is Indeed All You Need: Semantically Attention-Guided Decoding   for Data-to-Text NLG - [[Arxiv](https://arxiv.org/abs/2109.07043)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.07043.md)]
- Benchmarking the Spectrum of Agent Capabilities - [[Arxiv](https://arxiv.org/abs/2109.06780v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.06780v2.md)]
- Benchmarking the Spectrum of Agent Capabilities - [[Arxiv](https://arxiv.org/abs/2109.06780)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.06780.md)]
- Exploring Prompt-based Few-shot Learning for Grounded Dialog Generation - [[Arxiv](https://arxiv.org/abs/2109.06513)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.06513.md)]
- Space Time Recurrent Memory Network - [[Arxiv](https://arxiv.org/abs/2109.06474v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.06474v2.md)]
- Space Time Recurrent Memory Network - [[Arxiv](https://arxiv.org/abs/2109.06474)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.06474.md)]
- Compression, Transduction, and Creation: A Unified Framework for   Evaluating Natural Language Generation - [[Arxiv](https://arxiv.org/abs/2109.06379)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.06379.md)]
- WeakSTIL: Weak whole-slide image level stromal tumor infiltrating   lymphocyte scores are all you need - [[Arxiv](https://arxiv.org/abs/2109.05892)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.05892.md)]
- CEM: Commonsense-aware Empathetic Response Generation - [[Arxiv](https://arxiv.org/abs/2109.05739)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.05739.md)]
- Bootstrapped Meta-Learning - [[Arxiv](https://arxiv.org/abs/2109.04504v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.04504v2.md)]
- Bootstrapped Meta-Learning - [[Arxiv](https://arxiv.org/abs/2109.04504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.04504.md)]
- A Three-Stage Learning Framework for Low-Resource Knowledge-Grounded   Dialogue Generation - [[Arxiv](https://arxiv.org/abs/2109.04096)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.04096.md)]
- Thinking Clearly, Talking Fast: Concept-Guided Non-Autoregressive   Generation for Open-Domain Dialogue Systems - [[Arxiv](https://arxiv.org/abs/2109.04084)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.04084.md)]
- ACP++: Action Co-occurrence Priors for Human-Object Interaction   Detection - [[Arxiv](https://arxiv.org/abs/2109.04047)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.04047.md)]
- Local Augmentation for Graph Neural Networks - [[Arxiv](https://arxiv.org/abs/2109.03856v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.03856v4.md)]
- Local Augmentation for Graph Neural Networks - [[Arxiv](https://arxiv.org/abs/2109.03856)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.03856.md)]
- Sqrt(d) Dimension Dependence of Langevin Monte Carlo - [[Arxiv](https://arxiv.org/abs/2109.03839v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.03839v3.md)]
- Sqrt(d) Dimension Dependence of Langevin Monte Carlo - [[Arxiv](https://arxiv.org/abs/2109.03839)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.03839.md)]
- Mask is All You Need: Rethinking Mask R-CNN for Dense and   Arbitrary-Shaped Scene Text Detection - [[Arxiv](https://arxiv.org/abs/2109.03426)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.03426.md)]
- Learning Neural Causal Models with Active Interventions - [[Arxiv](https://arxiv.org/abs/2109.02429v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.02429v2.md)]
- Learning Neural Causal Models with Active Interventions - [[Arxiv](https://arxiv.org/abs/2109.02429)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.02429.md)]
- Learning to Prompt for Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2109.01134)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.01134.md)]
- Learning to Prompt for Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2109.01134v6)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.01134v6.md)]
- Searching for Efficient Multi-Stage Vision Transformers - [[Arxiv](https://arxiv.org/abs/2109.00642)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.00642.md)]
- Boosting Search Engines with Interactive Agents - [[Arxiv](https://arxiv.org/abs/2109.00527)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.00527.md)]
- Boosting Search Engines with Interactive Agents - [[Arxiv](https://arxiv.org/abs/2109.00527v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2109.00527v3.md)]

### August 2021
- Improving Query Representations for Dense Retrieval with Pseudo   Relevance Feedback - [[Arxiv](https://arxiv.org/abs/2108.13454)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.13454.md)]
- Neural HMMs are all you need (for high-quality attention-free TTS) - [[Arxiv](https://arxiv.org/abs/2108.13320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.13320.md)]
- Subjective Learning for Open-Ended Data - [[Arxiv](https://arxiv.org/abs/2108.12113v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.12113v2.md)]
- Subjective Learning for Open-Ended Data - [[Arxiv](https://arxiv.org/abs/2108.12113)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.12113.md)]
- Photos Are All You Need for Reciprocal Recommendation in Online Dating - [[Arxiv](https://arxiv.org/abs/2108.11714)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.11714.md)]
- SimVLM: Simple Visual Language Model Pretraining with Weak Supervision - [[Arxiv](https://arxiv.org/abs/2108.10904)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.10904.md)]
- Contrastive Learning of User Behavior Sequence for Context-Aware   Document Ranking - [[Arxiv](https://arxiv.org/abs/2108.10510)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.10510.md)]
- One TTS Alignment To Rule Them All - [[Arxiv](https://arxiv.org/abs/2108.10447)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.10447.md)]
- Anarchic Federated Learning - [[Arxiv](https://arxiv.org/abs/2108.09875)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.09875.md)]
- Anarchic Federated Learning - [[Arxiv](https://arxiv.org/abs/2108.09875v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.09875v4.md)]
- Pre-training for Ad-hoc Retrieval: Hyperlink is Also You Need - [[Arxiv](https://arxiv.org/abs/2108.09346)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.09346.md)]
- Fastformer: Additive Attention Can Be All You Need - [[Arxiv](https://arxiv.org/abs/2108.09084)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.09084.md)]
- Spatio-Temporal Interaction Graph Parsing Networks for Human-Object   Interaction Recognition - [[Arxiv](https://arxiv.org/abs/2108.08633)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.08633.md)]
- Exploiting Scene Graphs for Human-Object Interaction Detection - [[Arxiv](https://arxiv.org/abs/2108.08584)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.08584.md)]
- D3D-HOI: Dynamic 3D Human-Object Interactions from Videos - [[Arxiv](https://arxiv.org/abs/2108.08420)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.08420.md)]
- A good body is all you need: avoiding catastrophic interference via   agent architecture search - [[Arxiv](https://arxiv.org/abs/2108.08398)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.08398.md)]
- On the Opportunities and Risks of Foundation Models - [[Arxiv](https://arxiv.org/abs/2108.07258)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.07258.md)]
- MMChat: Multi-Modal Chat Dataset on Social Media - [[Arxiv](https://arxiv.org/abs/2108.07154)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.07154.md)]
- FedPara: Low-Rank Hadamard Product for Communication-Efficient Federated   Learning - [[Arxiv](https://arxiv.org/abs/2108.06098)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.06098.md)]
- The Stability-Efficiency Dilemma: Investigating Sequence Length Warmup   for Training GPT Models - [[Arxiv](https://arxiv.org/abs/2108.06084)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.06084.md)]
- PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense   Passage Retrieval - [[Arxiv](https://arxiv.org/abs/2108.06027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.06027.md)]
- Logit Attenuating Weight Normalization - [[Arxiv](https://arxiv.org/abs/2108.05839)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.05839.md)]
- Logit Attenuating Weight Normalization - [[Arxiv](https://arxiv.org/abs/2108.05839v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.05839v1.md)]
- Unsupervised Corpus Aware Language Model Pre-training for Dense Passage   Retrieval - [[Arxiv](https://arxiv.org/abs/2108.05540)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.05540.md)]
- Mining the Benefits of Two-stage and One-stage HOI Detection - [[Arxiv](https://arxiv.org/abs/2108.05077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.05077.md)]
- Are Neural Ranking Models Robust? - [[Arxiv](https://arxiv.org/abs/2108.05018)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.05018.md)]
- Rethinking Architecture Selection in Differentiable NAS - [[Arxiv](https://arxiv.org/abs/2108.04392)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.04392.md)]
- Pose is all you need: The pose only group activity recognition system   (POGARS) - [[Arxiv](https://arxiv.org/abs/2108.04186)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.04186.md)]
- BIGRoC: Boosting Image Generation via a Robust Classifier - [[Arxiv](https://arxiv.org/abs/2108.03702)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.03702.md)]
- BIGRoC: Boosting Image Generation via a Robust Classifier - [[Arxiv](https://arxiv.org/abs/2108.03702v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.03702v4.md)]
- Source-Free Domain Adaptation for Image Segmentation - [[Arxiv](https://arxiv.org/abs/2108.03152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.03152.md)]
- Improving Contrastive Learning by Visualizing Feature Transformation - [[Arxiv](https://arxiv.org/abs/2108.02982)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.02982.md)]
- Internal Video Inpainting by Implicit Long-range Propagation - [[Arxiv](https://arxiv.org/abs/2108.01912)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.01912.md)]
- Model-Based Opponent Modeling - [[Arxiv](https://arxiv.org/abs/2108.01843)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.01843.md)]
- Model-Based Opponent Modeling - [[Arxiv](https://arxiv.org/abs/2108.01843v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.01843v2.md)]
- Offline Decentralized Multi-Agent Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2108.01832v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.01832v2.md)]
- Offline Decentralized Multi-Agent Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2108.01832)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.01832.md)]
- SphereFace2: Binary Classification is All You Need for Deep Face   Recognition - [[Arxiv](https://arxiv.org/abs/2108.01513)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.01513.md)]
- How to Evaluate Your Dialogue Models: A Review of Approaches - [[Arxiv](https://arxiv.org/abs/2108.01369)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.01369.md)]
- SDEdit: Guided Image Synthesis and Editing with Stochastic Differential   Equations - [[Arxiv](https://arxiv.org/abs/2108.01073)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.01073.md)]
- Evaluating Deep Graph Neural Networks - [[Arxiv](https://arxiv.org/abs/2108.00955v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.00955v1.md)]
- Evaluating Deep Graph Neural Networks - [[Arxiv](https://arxiv.org/abs/2108.00955)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.00955.md)]
- Jointly Optimizing Query Encoder and Product Quantization to Improve   Retrieval Performance - [[Arxiv](https://arxiv.org/abs/2108.00644)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.00644.md)]
- GTNet:Guided Transformer Network for Detecting Human-Object Interactions - [[Arxiv](https://arxiv.org/abs/2108.00596)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2108.00596.md)]

### July 2021
- Imbalanced Adversarial Training with Reweighting - [[Arxiv](https://arxiv.org/abs/2107.13639v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.13639v1.md)]
- Imbalanced Adversarial Training with Reweighting - [[Arxiv](https://arxiv.org/abs/2107.13639)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.13639.md)]
- Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods   in Natural Language Processing - [[Arxiv](https://arxiv.org/abs/2107.13586)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.13586.md)]
- Functorial String Diagrams for Reverse-Mode Automatic Differentiation - [[Arxiv](https://arxiv.org/abs/2107.13433)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.13433.md)]
- Unsupervised Learning of Neurosymbolic Encoders - [[Arxiv](https://arxiv.org/abs/2107.13132)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.13132.md)]
- Unsupervised Learning of Neurosymbolic Encoders - [[Arxiv](https://arxiv.org/abs/2107.13132v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.13132v2.md)]
- Is Object Detection Necessary for Human-Object Interaction Recognition? - [[Arxiv](https://arxiv.org/abs/2107.13083)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.13083.md)]
- Joint Shapley values: a measure of joint feature importance - [[Arxiv](https://arxiv.org/abs/2107.11357)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.11357.md)]
- Joint Shapley values: a measure of joint feature importance - [[Arxiv](https://arxiv.org/abs/2107.11357v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.11357v2.md)]
- Few Shots Are All You Need: A Progressive Few Shot Learning Approach for   Low Resource Handwritten Text Recognition - [[Arxiv](https://arxiv.org/abs/2107.10064)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.10064.md)]
- Conditional GANs with Auxiliary Discriminative Classifier - [[Arxiv](https://arxiv.org/abs/2107.10060)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.10060.md)]
- Conditional GANs with Auxiliary Discriminative Classifier - [[Arxiv](https://arxiv.org/abs/2107.10060v5)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.10060v5.md)]
- Guided Generation of Cause and Effect - [[Arxiv](https://arxiv.org/abs/2107.09846)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.09846.md)]
- QVHighlights: Detecting Moments and Highlights in Videos via Natural   Language Queries - [[Arxiv](https://arxiv.org/abs/2107.09609)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.09609.md)]
- Structured Stochastic Gradient MCMC - [[Arxiv](https://arxiv.org/abs/2107.09028v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.09028v4.md)]
- Structured Stochastic Gradient MCMC - [[Arxiv](https://arxiv.org/abs/2107.09028)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.09028.md)]
- Is attention to bounding boxes all you need for pedestrian action   prediction? - [[Arxiv](https://arxiv.org/abs/2107.08031)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.08031.md)]
- DNN is not all you need: Parallelizing Non-Neural ML Algorithms on   Ultra-Low-Power IoT Processors - [[Arxiv](https://arxiv.org/abs/2107.09448)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.09448.md)]
- Align before Fuse: Vision and Language Representation Learning with   Momentum Distillation - [[Arxiv](https://arxiv.org/abs/2107.07651)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.07651.md)]
- FastSHAP: Real-Time Shapley Value Estimation - [[Arxiv](https://arxiv.org/abs/2107.07436)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.07436.md)]
- FastSHAP: Real-Time Shapley Value Estimation - [[Arxiv](https://arxiv.org/abs/2107.07436v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.07436v3.md)]
- How Much Can CLIP Benefit Vision-and-Language Tasks? - [[Arxiv](https://arxiv.org/abs/2107.06383)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.06383.md)]
- How Much Can CLIP Benefit Vision-and-Language Tasks? - [[Arxiv](https://arxiv.org/abs/2107.06383v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.06383v1.md)]
- Per-Pixel Classification is Not All You Need for Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2107.06278)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.06278.md)]
- A Configurable Multilingual Model is All You Need to Recognize All   Languages - [[Arxiv](https://arxiv.org/abs/2107.05876)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.05876.md)]
- SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking - [[Arxiv](https://arxiv.org/abs/2107.05720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.05720.md)]
- Explore and Control with Adversarial Surprise - [[Arxiv](https://arxiv.org/abs/2107.07394v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.07394v2.md)]
- Explore and Control with Adversarial Surprise - [[Arxiv](https://arxiv.org/abs/2107.07394)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.07394.md)]
- ViTGAN: Training GANs with Vision Transformers - [[Arxiv](https://arxiv.org/abs/2107.04589v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.04589v1.md)]
- ViTGAN: Training GANs with Vision Transformers - [[Arxiv](https://arxiv.org/abs/2107.04589)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.04589.md)]
- Hoechst Is All You Need: Lymphocyte Classification with Deep Learning - [[Arxiv](https://arxiv.org/abs/2107.04388)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.04388.md)]
- Towards Robust Active Feature Acquisition - [[Arxiv](https://arxiv.org/abs/2107.04163)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.04163.md)]
- Towards Robust Active Feature Acquisition - [[Arxiv](https://arxiv.org/abs/2107.04163v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.04163v1.md)]
- Evaluating Large Language Models Trained on Code - [[Arxiv](https://arxiv.org/abs/2107.03374)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.03374.md)]
- Understanding Intrinsic Robustness Using Label Uncertainty - [[Arxiv](https://arxiv.org/abs/2107.03250)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.03250.md)]
- Understanding Intrinsic Robustness Using Label Uncertainty - [[Arxiv](https://arxiv.org/abs/2107.03250v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.03250v2.md)]
- Neural Contextual Bandits without Regret - [[Arxiv](https://arxiv.org/abs/2107.03144v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.03144v2.md)]
- Neural Contextual Bandits without Regret - [[Arxiv](https://arxiv.org/abs/2107.03144)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.03144.md)]
- Structured Denoising Diffusion Models in Discrete State-Spaces - [[Arxiv](https://arxiv.org/abs/2107.03006)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.03006.md)]
- Depth-supervised NeRF: Fewer Views and Faster Training for Free - [[Arxiv](https://arxiv.org/abs/2107.02791)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.02791.md)]
- VidLanKD: Improving Language Understanding via Video-Distilled Knowledge   Transfer - [[Arxiv](https://arxiv.org/abs/2107.02681)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.02681.md)]
- Attention-based Adversarial Appearance Learning of Augmented Pedestrians - [[Arxiv](https://arxiv.org/abs/2107.02673)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.02673.md)]
- Rethinking Positional Encoding - [[Arxiv](https://arxiv.org/abs/2107.02561v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.02561v3.md)]
- Rethinking Positional Encoding - [[Arxiv](https://arxiv.org/abs/2107.02561)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.02561.md)]
- When and How to Fool Explainable Models (and Humans) with Adversarial   Examples - [[Arxiv](https://arxiv.org/abs/2107.01943)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.01943.md)]
- Mutation is all you need - [[Arxiv](https://arxiv.org/abs/2107.07343)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.07343.md)]
- Scale Mixtures of Neural Network Gaussian Processes - [[Arxiv](https://arxiv.org/abs/2107.01408)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.01408.md)]
- Scale Mixtures of Neural Network Gaussian Processes - [[Arxiv](https://arxiv.org/abs/2107.01408v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.01408v2.md)]
- On the Practicality of Deterministic Epistemic Uncertainty - [[Arxiv](https://arxiv.org/abs/2107.00649)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.00649.md)]
- On the Practicality of Deterministic Epistemic Uncertainty - [[Arxiv](https://arxiv.org/abs/2107.00649v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2107.00649v3.md)]

### June 2021
- Automatically Select Emotion for Response via Personality-affected   Emotion Transition - [[Arxiv](https://arxiv.org/abs/2106.15846)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.15846.md)]
- Local Reweighting for Adversarial Training - [[Arxiv](https://arxiv.org/abs/2106.15776)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.15776.md)]
- Local Reweighting for Adversarial Training - [[Arxiv](https://arxiv.org/abs/2106.15776v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.15776v1.md)]
- Open-Set Representation Learning through Combinatorial Embedding - [[Arxiv](https://arxiv.org/abs/2106.15278)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.15278.md)]
- Don't Take It Literally: An Edit-Invariant Sequence Loss for Text   Generation - [[Arxiv](https://arxiv.org/abs/2106.15078)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.15078.md)]
- Multimodal Few-Shot Learning with Frozen Language Models - [[Arxiv](https://arxiv.org/abs/2106.13884)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.13884.md)]
- Animatable Neural Radiance Fields from Monocular RGB Videos - [[Arxiv](https://arxiv.org/abs/2106.13629)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.13629.md)]
- DCoM: A Deep Column Mapper for Semantic Data Type Detection - [[Arxiv](https://arxiv.org/abs/2106.12871)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12871.md)]
- DCoM: A Deep Column Mapper for Semantic Data Type Detection - [[Arxiv](https://arxiv.org/abs/2106.12871v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12871v1.md)]
- All You Need is a Second Look: Towards Arbitrary-Shaped Text Detection - [[Arxiv](https://arxiv.org/abs/2106.12720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12720.md)]
- IA-RED$^2$: Interpretability-Aware Redundancy Reduction for Vision   Transformers - [[Arxiv](https://arxiv.org/abs/2106.12620)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12620.md)]
- Learning Multimodal VAEs through Mutual Supervision - [[Arxiv](https://arxiv.org/abs/2106.12570v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12570v3.md)]
- Learning Multimodal VAEs through Mutual Supervision - [[Arxiv](https://arxiv.org/abs/2106.12570)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12570.md)]
- Sampling with Mirrored Stein Operators - [[Arxiv](https://arxiv.org/abs/2106.12506)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12506.md)]
- Sampling with Mirrored Stein Operators - [[Arxiv](https://arxiv.org/abs/2106.12506v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12506v3.md)]
- Adapting Off-the-Shelf Source Segmenter for Target Medical Image   Segmentation - [[Arxiv](https://arxiv.org/abs/2106.12497)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12497.md)]
- CharacterChat: Supporting the Creation of Fictional Characters through   Conversation and Progressive Manifestation with a Chatbot - [[Arxiv](https://arxiv.org/abs/2106.12314)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12314.md)]
- Secure Domain Adaptation with Multiple Sources - [[Arxiv](https://arxiv.org/abs/2106.12124)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12124.md)]
- Secure Domain Adaptation with Multiple Sources - [[Arxiv](https://arxiv.org/abs/2106.12124v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12124v2.md)]
- Volume Rendering of Neural Implicit Surfaces - [[Arxiv](https://arxiv.org/abs/2106.12052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.12052.md)]
- Policy Smoothing for Provably Robust Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2106.11420v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.11420v3.md)]
- Policy Smoothing for Provably Robust Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2106.11420)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.11420.md)]
- Towards Long-Form Video Understanding - [[Arxiv](https://arxiv.org/abs/2106.11310)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.11310.md)]
- Boundary Graph Neural Networks for 3D Simulations - [[Arxiv](https://arxiv.org/abs/2106.11299)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.11299.md)]
- Boundary Graph Neural Networks for 3D Simulations - [[Arxiv](https://arxiv.org/abs/2106.11299v7)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.11299v7.md)]
- Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval - [[Arxiv](https://arxiv.org/abs/2106.11251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.11251.md)]
- CLIP2Video: Mastering Video-Text Retrieval via Image CLIP - [[Arxiv](https://arxiv.org/abs/2106.11097)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.11097.md)]
- Analytically Tractable Bayesian Deep Q-Learning - [[Arxiv](https://arxiv.org/abs/2106.11086)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.11086.md)]
- Analytically Tractable Bayesian Deep Q-Learning - [[Arxiv](https://arxiv.org/abs/2106.11086v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.11086v1.md)]
- Multiplying Matrices Without Multiplying - [[Arxiv](https://arxiv.org/abs/2106.10860)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.10860.md)]
- NeuS: Learning Neural Implicit Surfaces by Volume Rendering for   Multi-view Reconstruction - [[Arxiv](https://arxiv.org/abs/2106.10689)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.10689.md)]
- Shuffle Private Stochastic Convex Optimization - [[Arxiv](https://arxiv.org/abs/2106.09805v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.09805v2.md)]
- Shuffle Private Stochastic Convex Optimization - [[Arxiv](https://arxiv.org/abs/2106.09805)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.09805.md)]
- On Invariance Penalties for Risk Minimization - [[Arxiv](https://arxiv.org/abs/2106.09777v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.09777v1.md)]
- On Invariance Penalties for Risk Minimization - [[Arxiv](https://arxiv.org/abs/2106.09777)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.09777.md)]
- Visual Correspondence Hallucination - [[Arxiv](https://arxiv.org/abs/2106.09711v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.09711v3.md)]
- Visual Correspondence Hallucination - [[Arxiv](https://arxiv.org/abs/2106.09711)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.09711.md)]
- Poisoning and Backdooring Contrastive Learning - [[Arxiv](https://arxiv.org/abs/2106.09667)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.09667.md)]
- Poisoning and Backdooring Contrastive Learning - [[Arxiv](https://arxiv.org/abs/2106.09667v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.09667v2.md)]
- Robust Model-based Face Reconstruction through Weakly-Supervised Outlier   Segmentation - [[Arxiv](https://arxiv.org/abs/2106.09614)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.09614.md)]
- Revisiting the Weaknesses of Reinforcement Learning for Neural Machine   Translation - [[Arxiv](https://arxiv.org/abs/2106.08942)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.08942.md)]
- Transductive Few-Shot Learning: Clustering is All You Need? - [[Arxiv](https://arxiv.org/abs/2106.09516)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.09516.md)]
- Unsupervised Enrichment of Persona-grounded Dialog with Background   Stories - [[Arxiv](https://arxiv.org/abs/2106.08364)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.08364.md)]
- BEiT: BERT Pre-Training of Image Transformers - [[Arxiv](https://arxiv.org/abs/2106.08254)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.08254.md)]
- Query Embedding on Hyper-relational Knowledge Graphs - [[Arxiv](https://arxiv.org/abs/2106.08166)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.08166.md)]
- Query Embedding on Hyper-relational Knowledge Graphs - [[Arxiv](https://arxiv.org/abs/2106.08166v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.08166v3.md)]
- UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram   Discriminators for High-Fidelity Waveform Generation - [[Arxiv](https://arxiv.org/abs/2106.07889)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.07889.md)]
- HuBERT: Self-Supervised Speech Representation Learning by Masked   Prediction of Hidden Units - [[Arxiv](https://arxiv.org/abs/2106.07447)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.07447.md)]
- Constraining Linear-chain CRFs to Regular Languages - [[Arxiv](https://arxiv.org/abs/2106.07306v6)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.07306v6.md)]
- Constraining Linear-chain CRFs to Regular Languages - [[Arxiv](https://arxiv.org/abs/2106.07306)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.07306.md)]
- Pre-Trained Models: Past, Present and Future - [[Arxiv](https://arxiv.org/abs/2106.07139)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.07139.md)]
- Category Theory in Machine Learning - [[Arxiv](https://arxiv.org/abs/2106.07032)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.07032.md)]
- Inverting Adversarially Robust Networks for Image Synthesis - [[Arxiv](https://arxiv.org/abs/2106.06927)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.06927.md)]
- Prompting Contrastive Explanations for Commonsense Reasoning Tasks - [[Arxiv](https://arxiv.org/abs/2106.06823)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.06823.md)]
- Learning to Pool in Graph Neural Networks for Extrapolation - [[Arxiv](https://arxiv.org/abs/2106.06210v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.06210v2.md)]
- Learning to Pool in Graph Neural Networks for Extrapolation - [[Arxiv](https://arxiv.org/abs/2106.06210)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.06210.md)]
- Is Homophily a Necessity for Graph Neural Networks? - [[Arxiv](https://arxiv.org/abs/2106.06134)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.06134.md)]
- Is Homophily a Necessity for Graph Neural Networks? - [[Arxiv](https://arxiv.org/abs/2106.06134v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.06134v4.md)]
- Bridging Subword Gaps in Pretrain-Finetune Paradigm for Natural Language   Generation - [[Arxiv](https://arxiv.org/abs/2106.06125)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.06125.md)]
- Fair Normalizing Flows - [[Arxiv](https://arxiv.org/abs/2106.05937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.05937.md)]
- Fair Normalizing Flows - [[Arxiv](https://arxiv.org/abs/2106.05937v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.05937v2.md)]
- MST: Masked Self-Supervised Transformer for Visual Representation - [[Arxiv](https://arxiv.org/abs/2106.05656)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.05656.md)]
- A Neural Tangent Kernel Perspective of GANs - [[Arxiv](https://arxiv.org/abs/2106.05566v5)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.05566v5.md)]
- A Neural Tangent Kernel Perspective of GANs - [[Arxiv](https://arxiv.org/abs/2106.05566)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.05566.md)]
- Knowledge distillation: A good teacher is patient and consistent - [[Arxiv](https://arxiv.org/abs/2106.05237)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.05237.md)]
- Do Transformers Really Perform Bad for Graph Representation? - [[Arxiv](https://arxiv.org/abs/2106.05234)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.05234.md)]
- DIGRAC: Digraph Clustering Based on Flow Imbalance - [[Arxiv](https://arxiv.org/abs/2106.05194v8)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.05194v8.md)]
- DIGRAC: Digraph Clustering Based on Flow Imbalance - [[Arxiv](https://arxiv.org/abs/2106.05194)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.05194.md)]
- Pretrained Encoders are All You Need - [[Arxiv](https://arxiv.org/abs/2106.05139)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.05139.md)]
- It Takes Two to Tango: Mixup for Deep Metric Learning - [[Arxiv](https://arxiv.org/abs/2106.04990v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.04990v2.md)]
- It Takes Two to Tango: Mixup for Deep Metric Learning - [[Arxiv](https://arxiv.org/abs/2106.04990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.04990.md)]
- Taxonomy of Machine Learning Safety: A Survey and Primer - [[Arxiv](https://arxiv.org/abs/2106.04823)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.04823.md)]
- Mean-Shifted Contrastive Loss for Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2106.03844v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.03844v2.md)]
- Mean-Shifted Contrastive Loss for Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2106.03844)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.03844.md)]
- RegMix: Data Mixing Augmentation for Regression - [[Arxiv](https://arxiv.org/abs/2106.03374v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.03374v4.md)]
- RegMix: Data Mixing Augmentation for Regression - [[Arxiv](https://arxiv.org/abs/2106.03374)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.03374.md)]
- Tabular Data: Deep Learning is Not All You Need - [[Arxiv](https://arxiv.org/abs/2106.03253)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.03253.md)]
- Self-Supervision is All You Need for Solving Rubik's Cube - [[Arxiv](https://arxiv.org/abs/2106.03157)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.03157.md)]
- Model Zoo: A Growing "Brain" That Learns Continually - [[Arxiv](https://arxiv.org/abs/2106.03027v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.03027v3.md)]
- Model Zoo: A Growing "Brain" That Learns Continually - [[Arxiv](https://arxiv.org/abs/2106.03027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.03027.md)]
- Context-Aware Sparse Deep Coordination Graphs - [[Arxiv](https://arxiv.org/abs/2106.02886v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.02886v3.md)]
- Context-Aware Sparse Deep Coordination Graphs - [[Arxiv](https://arxiv.org/abs/2106.02886)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.02886.md)]
- Learning Curves for SGD on Structured Features - [[Arxiv](https://arxiv.org/abs/2106.02713v5)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.02713v5.md)]
- Learning Curves for SGD on Structured Features - [[Arxiv](https://arxiv.org/abs/2106.02713)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.02713.md)]
- Meta-Learning with Fewer Tasks through Task Interpolation - [[Arxiv](https://arxiv.org/abs/2106.02695v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.02695v2.md)]
- Meta-Learning with Fewer Tasks through Task Interpolation - [[Arxiv](https://arxiv.org/abs/2106.02695)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.02695.md)]
- Churn Reduction via Distillation - [[Arxiv](https://arxiv.org/abs/2106.02654v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.02654v2.md)]
- Churn Reduction via Distillation - [[Arxiv](https://arxiv.org/abs/2106.02654)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.02654.md)]
- MERLOT: Multimodal Neural Script Knowledge Models - [[Arxiv](https://arxiv.org/abs/2106.02636)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.02636.md)]
- Conversations Are Not Flat: Modeling the Dynamic Information Flow across   Dialogue Utterances - [[Arxiv](https://arxiv.org/abs/2106.02227)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.02227.md)]
- Three Sentences Are All You Need: Local Path Enhanced Document Relation   Extraction - [[Arxiv](https://arxiv.org/abs/2106.01793)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.01793.md)]
- Convergent Graph Solvers - [[Arxiv](https://arxiv.org/abs/2106.01680v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.01680v3.md)]
- Convergent Graph Solvers - [[Arxiv](https://arxiv.org/abs/2106.01680)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.01680.md)]
- Self-Guided Contrastive Learning for BERT Sentence Representations - [[Arxiv](https://arxiv.org/abs/2106.07345)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.07345.md)]
- Steerable 3D Spherical Neurons - [[Arxiv](https://arxiv.org/abs/2106.13863)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.13863.md)]
- Steerable 3D Spherical Neurons - [[Arxiv](https://arxiv.org/abs/2106.13863v7)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.13863v7.md)]
- Evidential Turing Processes - [[Arxiv](https://arxiv.org/abs/2106.01216)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.01216.md)]
- Evidential Turing Processes - [[Arxiv](https://arxiv.org/abs/2106.01216v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.01216v3.md)]
- Towards Emotional Support Dialog Systems - [[Arxiv](https://arxiv.org/abs/2106.01144)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.01144.md)]
- Multiresolution Equivariant Graph Variational Autoencoder - [[Arxiv](https://arxiv.org/abs/2106.00967)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.00967.md)]
- Multiresolution Equivariant Graph Variational Autoencoder - [[Arxiv](https://arxiv.org/abs/2106.00967v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.00967v3.md)]
- RevCore: Review-augmented Conversational Recommendation - [[Arxiv](https://arxiv.org/abs/2106.00957)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.00957.md)]
- DialoGraph: Incorporating Interpretable Strategy-Graph Networks into   Negotiation Dialogues - [[Arxiv](https://arxiv.org/abs/2106.00920)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.00920.md)]
- Efficient Passage Retrieval with Hashing for Open-domain Question   Answering - [[Arxiv](https://arxiv.org/abs/2106.00882)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.00882.md)]
- Weighting vectors for machine learning: numerical harmonic analysis   applied to boundary detection - [[Arxiv](https://arxiv.org/abs/2106.00827)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.00827.md)]
- DYPLOC: Dynamic Planning of Content Using Mixed Language Models for Text   Generation - [[Arxiv](https://arxiv.org/abs/2106.00791)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.00791.md)]
- Towards Quantifiable Dialogue Coherence Evaluation - [[Arxiv](https://arxiv.org/abs/2106.00507)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.00507.md)]
- Concurrent Adversarial Learning for Large-Batch Training - [[Arxiv](https://arxiv.org/abs/2106.00221)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.00221.md)]
- Concurrent Adversarial Learning for Large-Batch Training - [[Arxiv](https://arxiv.org/abs/2106.00221v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2106.00221v2.md)]

### May 2021
- Efficient and Modular Implicit Differentiation - [[Arxiv](https://arxiv.org/abs/2105.15183)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.15183.md)]
- Efficient and Modular Implicit Differentiation - [[Arxiv](https://arxiv.org/abs/2105.15183v5)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.15183v5.md)]
- Memory-Efficient Differentiable Transformer Architecture Search - [[Arxiv](https://arxiv.org/abs/2105.14669)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.14669.md)]
- How Attentive are Graph Attention Networks? - [[Arxiv](https://arxiv.org/abs/2105.14491v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.14491v3.md)]
- How Attentive are Graph Attention Networks? - [[Arxiv](https://arxiv.org/abs/2105.14491)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.14491.md)]
- An Attention Free Transformer - [[Arxiv](https://arxiv.org/abs/2105.14103)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.14103.md)]
- An Attention Free Transformer - [[Arxiv](https://arxiv.org/abs/2105.14103v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.14103v2.md)]
- Gotta Go Fast When Generating Data with Score-Based Models - [[Arxiv](https://arxiv.org/abs/2105.14080)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.14080.md)]
- Gotta Go Fast When Generating Data with Score-Based Models - [[Arxiv](https://arxiv.org/abs/2105.14080v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.14080v1.md)]
- Simple steps are all you need: Frank-Wolfe and generalized   self-concordant functions - [[Arxiv](https://arxiv.org/abs/2105.13913)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.13913.md)]
- OTTers: One-turn Topic Transitions for Open-Domain Dialogue - [[Arxiv](https://arxiv.org/abs/2105.13710)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.13710.md)]
- Data Augmentation for Text Generation Without Any Augmented Data - [[Arxiv](https://arxiv.org/abs/2105.13650)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.13650.md)]
- ST-HOI: A Spatial-Temporal Baseline for Human-Object Interaction   Detection in Videos - [[Arxiv](https://arxiv.org/abs/2105.11731)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.11731.md)]
- Pre-trained Language Model based Ranking in Baidu Search - [[Arxiv](https://arxiv.org/abs/2105.11108)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.11108.md)]
- Unsupervised Speech Recognition - [[Arxiv](https://arxiv.org/abs/2105.11084)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.11084.md)]
- Revisiting the Negative Data of Distantly Supervised Relation Extraction - [[Arxiv](https://arxiv.org/abs/2105.10158)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.10158.md)]
- DEHB: Evolutionary Hyperband for Scalable, Robust and Efficient   Hyperparameter Optimization - [[Arxiv](https://arxiv.org/abs/2105.09821)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.09821.md)]
- Intra-Document Cascading: Learning to Select Passages for Neural   Document Ranking - [[Arxiv](https://arxiv.org/abs/2105.09816)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.09816.md)]
- Unified Conversational Recommendation Policy Learning via Graph-based   Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2105.09710)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.09710.md)]
- Value Function is All You Need: A Unified Learning Framework for Ride   Hailing Platforms - [[Arxiv](https://arxiv.org/abs/2105.08791)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.08791.md)]
- KECRS: Towards Knowledge-Enriched Conversational Recommendation System - [[Arxiv](https://arxiv.org/abs/2105.08261)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.08261.md)]
- Sample-Efficient Reinforcement Learning Is Feasible for Linearly   Realizable MDPs with Limited Revisiting - [[Arxiv](https://arxiv.org/abs/2105.08024)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.08024.md)]
- ItôTTS and ItôWave: Linear Stochastic Differential Equation Is All   You Need For Audio Generation - [[Arxiv](https://arxiv.org/abs/2105.07583)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.07583.md)]
- RetGen: A Joint framework for Retrieval and Grounded Text Generation   Modeling - [[Arxiv](https://arxiv.org/abs/2105.06597)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.06597.md)]
- HyKnow: End-to-End Task-Oriented Dialog Modeling with Hybrid Knowledge   Management - [[Arxiv](https://arxiv.org/abs/2105.06041)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.06041.md)]
- Looking at CTR Prediction Again: Is Attention All You Need? - [[Arxiv](https://arxiv.org/abs/2105.05563)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.05563.md)]
- The DEVIL is in the Details: A Diagnostic Evaluation Benchmark for Video   Inpainting - [[Arxiv](https://arxiv.org/abs/2105.05332)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.05332.md)]
- Diffusion Models Beat GANs on Image Synthesis - [[Arxiv](https://arxiv.org/abs/2105.05233)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.05233.md)]
- VICReg: Variance-Invariance-Covariance Regularization for   Self-Supervised Learning - [[Arxiv](https://arxiv.org/abs/2105.04906)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.04906.md)]
- EL-Attention: Memory Efficient Lossless Attention for Generation - [[Arxiv](https://arxiv.org/abs/2105.04779)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.04779.md)]
- Not All Relevance Scores are Equal: Efficient Uncertainty and   Calibration Modeling for Deep Retrieval Models - [[Arxiv](https://arxiv.org/abs/2105.04651)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.04651.md)]
- Recent Advances in Deep Learning Based Dialogue Systems: A Systematic   Survey - [[Arxiv](https://arxiv.org/abs/2105.04387)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.04387.md)]
- Joint Learning of Deep Retrieval Model and Product Quantization based   Embedding Index - [[Arxiv](https://arxiv.org/abs/2105.03933)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.03933.md)]
- Simulating User Satisfaction for the Evaluation of Task-oriented   Dialogue Systems - [[Arxiv](https://arxiv.org/abs/2105.03748)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.03748.md)]
- Improving Document Representations by Generating Pseudo Query Embeddings   for Dense Retrieval - [[Arxiv](https://arxiv.org/abs/2105.03599)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.03599.md)]
- Human Object Interaction Detection using Two-Direction Spatial   Enhancement and Exclusive Object Prior - [[Arxiv](https://arxiv.org/abs/2105.03089)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.03089.md)]
- A Survey of Data Augmentation Approaches for NLP - [[Arxiv](https://arxiv.org/abs/2105.03075)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.03075.md)]
- Rethinking Search: Making Domain Experts out of Dilettantes - [[Arxiv](https://arxiv.org/abs/2105.02274)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.02274.md)]
- PD-GAN: Probabilistic Diverse GAN for Image Inpainting - [[Arxiv](https://arxiv.org/abs/2105.02201)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.02201.md)]
- Visual Relationship Detection Using Part-and-Sum Transformers with   Composite Queries - [[Arxiv](https://arxiv.org/abs/2105.02170)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.02170.md)]
- Unsupervised Document Expansion for Information Retrieval with   Stochastic Text Generation - [[Arxiv](https://arxiv.org/abs/2105.00666)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2105.00666.md)]

### April 2021
- RR-Net: Injecting Interactive Semantics in Human-Object Interaction   Detection - [[Arxiv](https://arxiv.org/abs/2104.15015)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.15015.md)]
- Emerging Properties in Self-Supervised Vision Transformers - [[Arxiv](https://arxiv.org/abs/2104.14294)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.14294.md)]
- Open-vocabulary Object Detection via Vision and Language Knowledge   Distillation - [[Arxiv](https://arxiv.org/abs/2104.13921)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.13921.md)]
- HOTR: End-to-End Human-Object Interaction Detection with Transformers - [[Arxiv](https://arxiv.org/abs/2104.13682)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.13682.md)]
- If your data distribution shifts, use self-learning - [[Arxiv](https://arxiv.org/abs/2104.12928)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.12928.md)]
- If your data distribution shifts, use self-learning - [[Arxiv](https://arxiv.org/abs/2104.12928v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.12928v3.md)]
- Multimodal Clustering Networks for Self-supervised Learning from   Unlabeled Videos - [[Arxiv](https://arxiv.org/abs/2104.12671)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.12671.md)]
- Easy and Efficient Transformer : Scalable Inference Solution For large   NLP model - [[Arxiv](https://arxiv.org/abs/2104.12470)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.12470.md)]
- GPT2MVS: Generative Pre-trained Transformer-2 for Multi-modal Video   Summarization - [[Arxiv](https://arxiv.org/abs/2104.12465)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.12465.md)]
- PanGu-$α$: Large-scale Autoregressive Pretrained Chinese Language   Models with Auto-parallel Computation - [[Arxiv](https://arxiv.org/abs/2104.12369)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.12369.md)]
- Learning Passage Impacts for Inverted Indexes - [[Arxiv](https://arxiv.org/abs/2104.12016)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.12016.md)]
- VideoGPT: Video Generation using VQ-VAE and Transformers - [[Arxiv](https://arxiv.org/abs/2104.10157)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.10157.md)]
- UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for   Multi-View Reconstruction - [[Arxiv](https://arxiv.org/abs/2104.10078)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.10078.md)]
- Gradient Matching for Domain Generalization - [[Arxiv](https://arxiv.org/abs/2104.09937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.09937.md)]
- Gradient Matching for Domain Generalization - [[Arxiv](https://arxiv.org/abs/2104.09937v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.09937v3.md)]
- B-PROP: Bootstrapped Pre-training with Representative Words Prediction   for Ad-hoc Retrieval - [[Arxiv](https://arxiv.org/abs/2104.09791)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.09791.md)]
- Image Inpainting with External-internal Learning and Monochromic   Bottleneck - [[Arxiv](https://arxiv.org/abs/2104.09068)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.09068.md)]
- Cross-Attention is All You Need: Adapting Pretrained Transformers for   Machine Translation - [[Arxiv](https://arxiv.org/abs/2104.08771)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.08771.md)]
- The Power of Scale for Parameter-Efficient Prompt Tuning - [[Arxiv](https://arxiv.org/abs/2104.08691)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.08691.md)]
- Explaining Answers with Entailment Trees - [[Arxiv](https://arxiv.org/abs/2104.08661)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.08661.md)]
- Condenser: a Pre-training Architecture for Dense Retrieval - [[Arxiv](https://arxiv.org/abs/2104.08253)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.08253.md)]
- $Q^{2}$: Evaluating Factual Consistency in Knowledge-Grounded Dialogues   via Question Generation and Question Answering - [[Arxiv](https://arxiv.org/abs/2104.08202)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.08202.md)]
- Optimizing Dense Retrieval Model Training with Hard Negatives - [[Arxiv](https://arxiv.org/abs/2104.08051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.08051.md)]
- Matching-oriented Product Quantization For Ad-hoc Retrieval - [[Arxiv](https://arxiv.org/abs/2104.07858)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.07858.md)]
- Ultra-High Dimensional Sparse Representations with Binarization for   Efficient Text Retrieval - [[Arxiv](https://arxiv.org/abs/2104.07198)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.07198.md)]
- COIL: Revisit Exact Lexical Match in Information Retrieval with   Contextualized Inverted List - [[Arxiv](https://arxiv.org/abs/2104.07186)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.07186.md)]
- Sparse Attention with Linear Units - [[Arxiv](https://arxiv.org/abs/2104.07012v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.07012v2.md)]
- Sparse Attention with Linear Units - [[Arxiv](https://arxiv.org/abs/2104.07012)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.07012.md)]
- Efficiently Teaching an Effective Dense Retriever with Balanced Topic   Aware Sampling - [[Arxiv](https://arxiv.org/abs/2104.06967)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.06967.md)]
- Is Disentanglement all you need? Comparing Concept-based &amp;   Disentanglement Approaches - [[Arxiv](https://arxiv.org/abs/2104.06917)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.06917.md)]
- Learning How to Ask: Querying LMs with Mixtures of Soft Prompts - [[Arxiv](https://arxiv.org/abs/2104.06599)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.06599.md)]
- All you need are a few pixels: semantic segmentation with PixelPick - [[Arxiv](https://arxiv.org/abs/2104.06394)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.06394.md)]
- Spatiotemporal Entropy Model is All You Need for Learned Video   Compression - [[Arxiv](https://arxiv.org/abs/2104.06083)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.06083.md)]
- Glance and Gaze: Inferring Action-aware Points for One-Stage   Human-Object Interaction Detection - [[Arxiv](https://arxiv.org/abs/2104.05269)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.05269.md)]
- Not All Attention Is All You Need - [[Arxiv](https://arxiv.org/abs/2104.04692)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.04692.md)]
- Progressive Temporal Feature Alignment Network for Video Inpainting - [[Arxiv](https://arxiv.org/abs/2104.03507)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.03507.md)]
- Affordance Transfer Learning for Human-Object Interaction Detection - [[Arxiv](https://arxiv.org/abs/2104.02867)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.02867.md)]
- SC-GlowTTS: an Efficient Zero-Shot Multi-Speaker Text-To-Speech Model - [[Arxiv](https://arxiv.org/abs/2104.05557)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.05557.md)]
- Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised   Pre-Training - [[Arxiv](https://arxiv.org/abs/2104.01027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.01027.md)]
- Visual Semantic Role Labeling for Video Understanding - [[Arxiv](https://arxiv.org/abs/2104.00990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.00990.md)]
- Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval - [[Arxiv](https://arxiv.org/abs/2104.00650)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.00650.md)]
- NeRF-VAE: A Geometry Aware 3D Scene Generative Model - [[Arxiv](https://arxiv.org/abs/2104.00587)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.00587.md)]
- Improved Image Generation via Sparse Modeling - [[Arxiv](https://arxiv.org/abs/2104.00464v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.00464v2.md)]
- Improved Image Generation via Sparse Modeling - [[Arxiv](https://arxiv.org/abs/2104.00464)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.00464.md)]
- Exploiting Relationship for Complex-scene Image Generation - [[Arxiv](https://arxiv.org/abs/2104.00356)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.00356.md)]
- Jigsaw Clustering for Unsupervised Visual Representation Learning - [[Arxiv](https://arxiv.org/abs/2104.00323)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.00323.md)]
- Domain Invariant Adversarial Learning - [[Arxiv](https://arxiv.org/abs/2104.00322v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.00322v4.md)]
- Domain Invariant Adversarial Learning - [[Arxiv](https://arxiv.org/abs/2104.00322)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2104.00322.md)]

### March 2021
- CAMPARI: Camera-Aware Decomposed Generative Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2103.17269)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.17269.md)]
- Contrastive Embedding for Generalized Zero-Shot Learning - [[Arxiv](https://arxiv.org/abs/2103.16173)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.16173.md)]
- AGQA: A Benchmark for Compositional Spatio-Temporal Reasoning - [[Arxiv](https://arxiv.org/abs/2103.16002)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.16002.md)]
- TransFill: Reference-guided Image Inpainting by Merging Multiple Color   and Spatial Transformations - [[Arxiv](https://arxiv.org/abs/2103.15982)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.15982.md)]
- Generic Attention-model Explainability for Interpreting Bi-Modal and   Encoder-Decoder Transformers - [[Arxiv](https://arxiv.org/abs/2103.15679)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.15679.md)]
- GNeRF: GAN-based Neural Radiance Field without Posed Camera - [[Arxiv](https://arxiv.org/abs/2103.15606)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.15606.md)]
- Efficient Explanations from Empirical Explainers - [[Arxiv](https://arxiv.org/abs/2103.15429)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.15429.md)]
- Categorical Representation Learning: Morphism is All You Need - [[Arxiv](https://arxiv.org/abs/2103.14770)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.14770.md)]
- More Photos are All You Need: Semi-Supervised Learning for Fine-Grained   Sketch Based Image Retrieval - [[Arxiv](https://arxiv.org/abs/2103.13990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.13990.md)]
- KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny MLPs - [[Arxiv](https://arxiv.org/abs/2103.13744)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.13744.md)]
- DNN Quantization with Attention - [[Arxiv](https://arxiv.org/abs/2103.13322v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.13322v1.md)]
- DNN Quantization with Attention - [[Arxiv](https://arxiv.org/abs/2103.13322)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.13322.md)]
- FastMoE: A Fast Mixture-of-Expert Training System - [[Arxiv](https://arxiv.org/abs/2103.13262)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.13262.md)]
- Interpretable Machine Learning: Fundamental Principles and 10 Grand   Challenges - [[Arxiv](https://arxiv.org/abs/2103.11251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.11251.md)]
- Concentric Spherical GNN for 3D Representation Learning - [[Arxiv](https://arxiv.org/abs/2103.10484)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.10484.md)]
- Concentric Spherical GNN for 3D Representation Learning - [[Arxiv](https://arxiv.org/abs/2103.10484v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.10484v1.md)]
- FastNeRF: High-Fidelity Neural Rendering at 200FPS - [[Arxiv](https://arxiv.org/abs/2103.10380)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.10380.md)]
- GLM: General Language Model Pretraining with Autoregressive Blank   Infilling - [[Arxiv](https://arxiv.org/abs/2103.10360)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.10360.md)]
- Generating Diverse Structure for Image Inpainting With Hierarchical   VQ-VAE - [[Arxiv](https://arxiv.org/abs/2103.10022)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.10022.md)]
- ENCONTER: Entity Constrained Progressive Sequence Generation via   Insertion-based Transformer - [[Arxiv](https://arxiv.org/abs/2103.09548)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.09548.md)]
- Detecting Human-Object Interaction via Fabricated Compositional Learning - [[Arxiv](https://arxiv.org/abs/2103.08214)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.08214.md)]
- BYOL for Audio: Self-Supervised Learning for General-Purpose Audio   Representation - [[Arxiv](https://arxiv.org/abs/2103.06695)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.06695.md)]
- Reformulating HOI Detection as Adaptive Set Prediction - [[Arxiv](https://arxiv.org/abs/2103.05983)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.05983.md)]
- Partial Differential Equations is All You Need for Generating Neural   Architectures -- A Theory for Physical Artificial Intelligence Systems - [[Arxiv](https://arxiv.org/abs/2103.08313)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.08313.md)]
- QPIC: Query-Based Pairwise Human-Object Interaction Detection with   Image-Wide Contextual Information - [[Arxiv](https://arxiv.org/abs/2103.05399)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.05399.md)]
- GAN Vocoder: Multi-Resolution Discriminator Is All You Need - [[Arxiv](https://arxiv.org/abs/2103.05236)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.05236.md)]
- Semantic Models for the First-stage Retrieval: A Comprehensive Review - [[Arxiv](https://arxiv.org/abs/2103.04831)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.04831.md)]
- End-to-End Human Object Interaction Detection with HOI Transformer - [[Arxiv](https://arxiv.org/abs/2103.04503)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.04503.md)]
- Can Pretext-Based Self-Supervised Learning Be Boosted by Downstream   Data? A Theoretical Analysis - [[Arxiv](https://arxiv.org/abs/2103.03568)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.03568.md)]
- Attention is Not All You Need: Pure Attention Loses Rank Doubly   Exponentially with Depth - [[Arxiv](https://arxiv.org/abs/2103.03404)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.03404.md)]
- Barlow Twins: Self-Supervised Learning via Redundancy Reduction - [[Arxiv](https://arxiv.org/abs/2103.03230)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.03230.md)]
- Online Adversarial Attacks - [[Arxiv](https://arxiv.org/abs/2103.02014)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.02014.md)]
- Online Adversarial Attacks - [[Arxiv](https://arxiv.org/abs/2103.02014v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.02014v4.md)]
- Mixture of Volumetric Primitives for Efficient Neural Rendering - [[Arxiv](https://arxiv.org/abs/2103.01954)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.01954.md)]
- Categorical Foundations of Gradient-Based Learning - [[Arxiv](https://arxiv.org/abs/2103.01931)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.01931.md)]
- Learners' Languages - [[Arxiv](https://arxiv.org/abs/2103.01189)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.01189.md)]
- Automated Machine Learning on Graphs: A Survey - [[Arxiv](https://arxiv.org/abs/2103.00742)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.00742.md)]

### February 2021
- Learning Transferable Visual Models From Natural Language Supervision - [[Arxiv](https://arxiv.org/abs/2103.00020)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2103.00020.md)]
- Node Proximity Is All You Need: Unified Structural and Positional Node   and Graph Embedding - [[Arxiv](https://arxiv.org/abs/2102.13582)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.13582.md)]
- Do Input Gradients Highlight Discriminative Features? - [[Arxiv](https://arxiv.org/abs/2102.12781)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.12781.md)]
- Teach Me to Explain: A Review of Datasets for Explainable Natural   Language Processing - [[Arxiv](https://arxiv.org/abs/2102.12060)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.12060.md)]
- Deep ReLU Networks Preserve Expected Length - [[Arxiv](https://arxiv.org/abs/2102.10492v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.10492v2.md)]
- Deep ReLU Networks Preserve Expected Length - [[Arxiv](https://arxiv.org/abs/2102.10492)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.10492.md)]
- Meta-Learning Dynamics Forecasting Using Task Inference - [[Arxiv](https://arxiv.org/abs/2102.10271v5)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.10271v5.md)]
- Meta-Learning Dynamics Forecasting Using Task Inference - [[Arxiv](https://arxiv.org/abs/2102.10271)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.10271.md)]
- Less is More: Pre-train a Strong Text Encoder for Dense Retrieval Using   a Weak Decoder - [[Arxiv](https://arxiv.org/abs/2102.09206)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.09206.md)]
- ShaRF: Shape-conditioned Radiance Fields from a Single View - [[Arxiv](https://arxiv.org/abs/2102.08860)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.08860.md)]
- DEUP: Direct Epistemic Uncertainty Prediction - [[Arxiv](https://arxiv.org/abs/2102.08501v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.08501v4.md)]
- DEUP: Direct Epistemic Uncertainty Prediction - [[Arxiv](https://arxiv.org/abs/2102.08501)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.08501.md)]
- All You Need is DAG - [[Arxiv](https://arxiv.org/abs/2102.08325)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.08325.md)]
- Topological Graph Neural Networks - [[Arxiv](https://arxiv.org/abs/2102.07835)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.07835.md)]
- Topological Graph Neural Networks - [[Arxiv](https://arxiv.org/abs/2102.07835v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.07835v4.md)]
- Is Space-Time Attention All You Need for Video Understanding? - [[Arxiv](https://arxiv.org/abs/2102.05095)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.05095.md)]
- Contrastive Embeddings for Neural Architectures - [[Arxiv](https://arxiv.org/abs/2102.04208)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.04208.md)]
- Contrastive Embeddings for Neural Architectures - [[Arxiv](https://arxiv.org/abs/2102.04208v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.04208v2.md)]
- Hyperspherical embedding for novel class classification - [[Arxiv](https://arxiv.org/abs/2102.03243)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.03243.md)]
- Hyperspherical embedding for novel class classification - [[Arxiv](https://arxiv.org/abs/2102.03243v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.03243v2.md)]
- Unifying Vision-and-Language Tasks via Text Generation - [[Arxiv](https://arxiv.org/abs/2102.02779)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.02779.md)]
- Learning Graph Embeddings for Compositional Zero-shot Learning - [[Arxiv](https://arxiv.org/abs/2102.01987)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2102.01987.md)]

### January 2021
- VX2TEXT: End-to-End Learning of Video-Based Text Generation From   Multimodal Inputs - [[Arxiv](https://arxiv.org/abs/2101.12059)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.12059.md)]
- Compositional Semantics for Probabilistic Programs with Exact   Conditioning - [[Arxiv](https://arxiv.org/abs/2101.11351)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.11351.md)]
- RESPER: Computationally Modelling Resisting Strategies in Persuasive   Conversations - [[Arxiv](https://arxiv.org/abs/2101.10545)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.10545.md)]
- Reverse Derivative Ascent: A Categorical Approach to Learning Boolean   Circuits - [[Arxiv](https://arxiv.org/abs/2101.10488)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.10488.md)]
- Transferable Interactiveness Knowledge for Human-Object Interaction   Detection - [[Arxiv](https://arxiv.org/abs/2101.10292)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.10292.md)]
- Advances and Challenges in Conversational Recommender Systems: A Survey - [[Arxiv](https://arxiv.org/abs/2101.09459)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.09459.md)]
- A Comprehensive Survey on Hardware-Aware Neural Architecture Search - [[Arxiv](https://arxiv.org/abs/2101.09336)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.09336.md)]
- Higher Order Automatic Differentiation of Higher Order Functions - [[Arxiv](https://arxiv.org/abs/2101.06757)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.06757.md)]
- The Expando-Mono-Duo Design Pattern for Text Ranking with Pretrained   Sequence-to-Sequence Models - [[Arxiv](https://arxiv.org/abs/2101.05667)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.05667.md)]
- Evaluating Disentanglement of Structured Representations - [[Arxiv](https://arxiv.org/abs/2101.04041)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.04041.md)]
- Evaluating Disentanglement of Structured Representations - [[Arxiv](https://arxiv.org/abs/2101.04041v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.04041v3.md)]
- Switch Transformers: Scaling to Trillion Parameter Models with Simple   and Efficient Sparsity - [[Arxiv](https://arxiv.org/abs/2101.03961)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.03961.md)]
- Evolving Reinforcement Learning Algorithms - [[Arxiv](https://arxiv.org/abs/2101.03958)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.03958.md)]
- Max-Affine Spline Insights Into Deep Network Pruning - [[Arxiv](https://arxiv.org/abs/2101.02338)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.02338.md)]
- Max-Affine Spline Insights Into Deep Network Pruning - [[Arxiv](https://arxiv.org/abs/2101.02338v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.02338v4.md)]
- VinVL: Revisiting Visual Representations in Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2101.00529)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.00529.md)]
- Prefix-Tuning: Optimizing Continuous Prompts for Generation - [[Arxiv](https://arxiv.org/abs/2101.00190)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.00190.md)]
- Multi-task Retrieval for Knowledge-Intensive Tasks - [[Arxiv](https://arxiv.org/abs/2101.00117)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2101.00117.md)]
