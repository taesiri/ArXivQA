
### December 2022
- Rethinking with Retrieval: Faithful Large Language Model Inference - [[Arxiv](https://arxiv.org/abs/2301.00303)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00303.md)]
- A Survey on In-context Learning - [[Arxiv](https://arxiv.org/abs/2301.00234)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00234.md)]
- Disjoint Masking with Joint Distillation for Efficient Masked Image   Modeling - [[Arxiv](https://arxiv.org/abs/2301.00230)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00230.md)]
- Cap4Video: What Can Auxiliary Captions Do for Text-Video Retrieval? - [[Arxiv](https://arxiv.org/abs/2301.00184)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00184.md)]
- Bidirectional Cross-Modal Knowledge Exploration for Video Recognition   with Pre-trained Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2301.00182)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00182.md)]
- Unlearnable Clusters: Towards Label-agnostic Unlearnable Examples - [[Arxiv](https://arxiv.org/abs/2301.01217)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01217.md)]
- Tracing the Origin of Adversarial Attack for Forensic Investigation and   Deterrence - [[Arxiv](https://arxiv.org/abs/2301.01218)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01218.md)]
- Imitator: Personalized Speech-driven 3D Facial Animation - [[Arxiv](https://arxiv.org/abs/2301.00023)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00023.md)]
- NeRF-Gaze: A Head-Eye Redirection Parametric Model for Gaze Estimation - [[Arxiv](https://arxiv.org/abs/2212.14710)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14710.md)]
- NIRVANA: Neural Implicit Representations of Videos with Adaptive   Networks and Autoregressive Patch-wise Modeling - [[Arxiv](https://arxiv.org/abs/2212.14593)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14593.md)]
- Transformer in Transformer as Backbone for Deep Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2212.14538)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14538.md)]
- Scale-MAE: A Scale-Aware Masked Autoencoder for Multiscale Geospatial   Representation Learning - [[Arxiv](https://arxiv.org/abs/2212.14532)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14532.md)]
- Improving Visual Representation Learning through Perceptual   Understanding - [[Arxiv](https://arxiv.org/abs/2212.14504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14504.md)]
- Effects of Data Geometry in Early Deep Learning - [[Arxiv](https://arxiv.org/abs/2301.00008v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00008v1.md)]
- Effects of Data Geometry in Early Deep Learning - [[Arxiv](https://arxiv.org/abs/2301.00008)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00008.md)]
- StyleRes: Transforming the Residuals for Real Image Editing with   StyleGAN - [[Arxiv](https://arxiv.org/abs/2212.14359)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14359.md)]
- MagicNet: Semi-Supervised Multi-Organ Segmentation via Magic-Cube   Partition and Recovery - [[Arxiv](https://arxiv.org/abs/2212.14310)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14310.md)]
- Foreground-Background Separation through Concept Distillation from   Generative Image Foundation Models - [[Arxiv](https://arxiv.org/abs/2212.14306)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14306.md)]
- Detection of out-of-distribution samples using binary neuron activation   patterns - [[Arxiv](https://arxiv.org/abs/2212.14268)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14268.md)]
- Discriminator-Cooperated Feature Map Distillation for GAN Compression - [[Arxiv](https://arxiv.org/abs/2212.14169)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14169.md)]
- Cramming: Training a Language Model on a Single GPU in One Day - [[Arxiv](https://arxiv.org/abs/2212.14034)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14034.md)]
- Demonstrate-Search-Predict: Composing retrieval and language models for   knowledge-intensive NLP - [[Arxiv](https://arxiv.org/abs/2212.14024)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14024.md)]
- Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and   Text-to-Image Diffusion Models - [[Arxiv](https://arxiv.org/abs/2212.14704)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.14704.md)]
- Multi-Realism Image Compression with a Conditional Generator - [[Arxiv](https://arxiv.org/abs/2212.13824)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.13824.md)]
- Noise-aware Learning from Web-crawled Image-Text Data for Image   Captioning - [[Arxiv](https://arxiv.org/abs/2212.13563)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.13563.md)]
- Interactive Segmentation of Radiance Fields - [[Arxiv](https://arxiv.org/abs/2212.13545)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.13545.md)]
- GEDI: GEnerative and DIscriminative Training for Self-Supervised   Learning - [[Arxiv](https://arxiv.org/abs/2212.13425)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.13425.md)]
- Behavioral Cloning via Search in Video PreTraining Latent Space - [[Arxiv](https://arxiv.org/abs/2212.13326)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.13326.md)]
- DSI2I: Dense Style for Unpaired Image-to-Image Translation - [[Arxiv](https://arxiv.org/abs/2212.13253)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.13253.md)]
- Large Language Models Encode Clinical Knowledge - [[Arxiv](https://arxiv.org/abs/2212.13138)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.13138.md)]
- SMMix: Self-Motivated Image Mixing for Vision Transformers - [[Arxiv](https://arxiv.org/abs/2212.12977)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12977.md)]
- TexPose: Neural Texture Learning for Self-Supervised 6D Object Pose   Estimation - [[Arxiv](https://arxiv.org/abs/2212.12902)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12902.md)]
- When Do Curricula Work in Federated Learning? - [[Arxiv](https://arxiv.org/abs/2212.12712)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12712.md)]
- On Realization of Intelligent Decision-Making in the Real World: A   Foundation Decision Model Perspective - [[Arxiv](https://arxiv.org/abs/2212.12669)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12669.md)]
- HandsOff: Labeled Dataset Generation With No Additional Human   Annotations - [[Arxiv](https://arxiv.org/abs/2212.12645)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12645.md)]
- xFBD: Focused Building Damage Dataset and Analysis - [[Arxiv](https://arxiv.org/abs/2212.13876)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.13876.md)]
- Detecting Objects with Context-Likelihood Graphs and Graph Refinement - [[Arxiv](https://arxiv.org/abs/2212.12395)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12395.md)]
- A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic   Inference - [[Arxiv](https://arxiv.org/abs/2212.12393)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12393.md)]
- Do DALL-E and Flamingo Understand Each Other? - [[Arxiv](https://arxiv.org/abs/2212.12249)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12249.md)]
- Learning to Detect and Segment for Open Vocabulary Object Detection - [[Arxiv](https://arxiv.org/abs/2212.12130)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12130.md)]
- On Calibrating Semantic Segmentation Models: Analyses and An Algorithm - [[Arxiv](https://arxiv.org/abs/2212.12053)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12053.md)]
- OPT-IML: Scaling Language Model Instruction Meta Learning through the   Lens of Generalization - [[Arxiv](https://arxiv.org/abs/2212.12017)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12017.md)]
- DisCoScene: Spatially Disentangled Generative Radiance Fields for   Controllable 3D-aware Scene Synthesis - [[Arxiv](https://arxiv.org/abs/2212.11984)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.11984.md)]
- Shakes on a Plane: Unsupervised Depth Estimation from Unstabilized   Photography - [[Arxiv](https://arxiv.org/abs/2212.12324)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.12324.md)]
- Removing Objects From Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2212.11966)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.11966.md)]
- Markov Categories and Entropy - [[Arxiv](https://arxiv.org/abs/2212.11719)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.11719.md)]
- Text Generation with Diffusion Language Models: A Pre-training Approach   with Continuous Paragraph Denoise - [[Arxiv](https://arxiv.org/abs/2212.11685)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.11685.md)]
- DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders - [[Arxiv](https://arxiv.org/abs/2212.11613)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.11613.md)]
- Tune-A-Video: One-Shot Tuning of Image Diffusion Models for   Text-to-Video Generation - [[Arxiv](https://arxiv.org/abs/2212.11565)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.11565.md)]
- Generalized Decoding for Pixel, Image, and Language - [[Arxiv](https://arxiv.org/abs/2212.11270)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.11270.md)]
- 3D Highlighter: Localizing Regions on 3D Shapes via Text Descriptions - [[Arxiv](https://arxiv.org/abs/2212.11263)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.11263.md)]
- Hi-LASSIE: High-Fidelity Articulated Shape and Skeleton Discovery from   Sparse Image Ensemble - [[Arxiv](https://arxiv.org/abs/2212.11042)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.11042.md)]
- Revisiting Residual Networks for Adversarial Robustness: An   Architectural Perspective - [[Arxiv](https://arxiv.org/abs/2212.11005)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.11005.md)]
- TruFor: Leveraging all-round clues for trustworthy image forgery   detection and localization - [[Arxiv](https://arxiv.org/abs/2212.10957)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10957.md)]
- Critic-Guided Decoding for Controlled Text Generation - [[Arxiv](https://arxiv.org/abs/2212.10938)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10938.md)]
- In-Sensor &amp; Neuromorphic Computing are all you need for Energy Efficient   Computer Vision - [[Arxiv](https://arxiv.org/abs/2212.10881)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10881.md)]
- MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction   Tuning - [[Arxiv](https://arxiv.org/abs/2212.10773)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10773.md)]
- MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via   Moral Discussions - [[Arxiv](https://arxiv.org/abs/2212.10720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10720.md)]
- PaletteNeRF: Palette-based Appearance Editing of Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2212.10699)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10699.md)]
- Analyzing Semantic Faithfulness of Language Models via Input   Intervention on Conversational Question Answering - [[Arxiv](https://arxiv.org/abs/2212.10696)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10696.md)]
- Scene-aware Egocentric 3D Human Pose Estimation - [[Arxiv](https://arxiv.org/abs/2212.11684)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.11684.md)]
- Full-Body Articulated Human-Object Interaction - [[Arxiv](https://arxiv.org/abs/2212.10621)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10621.md)]
- Ontologically Faithful Generation of Non-Player Character Dialogues - [[Arxiv](https://arxiv.org/abs/2212.10618)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10618.md)]
- Why Can GPT Learn In-Context? Language Models Implicitly Perform   Gradient Descent as Meta-Optimizers - [[Arxiv](https://arxiv.org/abs/2212.10559)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10559.md)]
- Unleashing the Power of Visual Prompting At the Pixel Level - [[Arxiv](https://arxiv.org/abs/2212.10556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10556.md)]
- InstantAvatar: Learning Avatars from Monocular Video in 60 Seconds - [[Arxiv](https://arxiv.org/abs/2212.10550)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10550.md)]
- A Survey of Deep Learning for Mathematical Reasoning - [[Arxiv](https://arxiv.org/abs/2212.10535)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10535.md)]
- Interleaving Retrieval with Chain-of-Thought Reasoning for   Knowledge-Intensive Multi-Step Questions - [[Arxiv](https://arxiv.org/abs/2212.10509)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10509.md)]
- Precise Zero-Shot Dense Retrieval without Relevance Labels - [[Arxiv](https://arxiv.org/abs/2212.10496)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10496.md)]
- LAMBADA: Backward Chaining for Automated Reasoning in Natural Language - [[Arxiv](https://arxiv.org/abs/2212.13894)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.13894.md)]
- Controllable Text Generation with Language Constraints - [[Arxiv](https://arxiv.org/abs/2212.10466)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10466.md)]
- QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity - [[Arxiv](https://arxiv.org/abs/2212.10431)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10431.md)]
- Towards Reasoning in Large Language Models: A Survey - [[Arxiv](https://arxiv.org/abs/2212.10403)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10403.md)]
- SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers - [[Arxiv](https://arxiv.org/abs/2212.10325)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10325.md)]
- ReCode: Robustness Evaluation of Code Generation Models - [[Arxiv](https://arxiv.org/abs/2212.10264)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10264.md)]
- Pre-trained Language Models for Keyphrase Generation: A Thorough   Empirical Study - [[Arxiv](https://arxiv.org/abs/2212.10233)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10233.md)]
- StyleDomain: Efficient and Lightweight Parameterizations of StyleGAN for   One-shot and Few-shot Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2212.10229)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10229.md)]
- Hoyer regularizer is all you need for ultra low-latency spiking neural   networks - [[Arxiv](https://arxiv.org/abs/2212.10170)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10170.md)]
- Planning-oriented Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2212.10156)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10156.md)]
- Large Language Models Are Reasoning Teachers - [[Arxiv](https://arxiv.org/abs/2212.10071)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10071.md)]
- RepMode: Learning to Re-parameterize Diverse Experts for Subcellular   Structure Prediction - [[Arxiv](https://arxiv.org/abs/2212.10066)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10066.md)]
- I Cast Detect Thoughts: Learning to Converse and Guide with Intents and   Theory-of-Mind in Dungeons and Dragons - [[Arxiv](https://arxiv.org/abs/2212.10060)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10060.md)]
- Towards Understanding Chain-of-Thought Prompting: An Empirical Study of   What Matters - [[Arxiv](https://arxiv.org/abs/2212.10001)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.10001.md)]
- MetaCLUE: Towards Comprehensive Visual Metaphors Research - [[Arxiv](https://arxiv.org/abs/2212.09898)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09898.md)]
- Panoptic Lifting for 3D Scene Understanding with Neural Fields - [[Arxiv](https://arxiv.org/abs/2212.09802)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09802.md)]
- Denotationally Correct, Purely Functional, Efficient Reverse-mode   Automatic Differentiation - [[Arxiv](https://arxiv.org/abs/2212.09801)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09801.md)]
- Scalable Diffusion Models with Transformers - [[Arxiv](https://arxiv.org/abs/2212.09748)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09748.md)]
- One Embedder, Any Task: Instruction-Finetuned Text Embeddings - [[Arxiv](https://arxiv.org/abs/2212.09741)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09741.md)]
- Position-guided Text Prompt for Vision-Language Pre-training - [[Arxiv](https://arxiv.org/abs/2212.09737)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09737.md)]
- Don't Generate, Discriminate: A Proposal for Grounding Language Models   to Real-World Environments - [[Arxiv](https://arxiv.org/abs/2212.09736)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09736.md)]
- The case for 4-bit precision: k-bit Inference Scaling Laws - [[Arxiv](https://arxiv.org/abs/2212.09720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09720.md)]
- A Probabilistic Framework for Lifelong Test-Time Adaptation - [[Arxiv](https://arxiv.org/abs/2212.09713)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09713.md)]
- Reasoning with Language Model Prompting: A Survey - [[Arxiv](https://arxiv.org/abs/2212.09597)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09597.md)]
- Large Language Models are Better Reasoners with Self-Verification - [[Arxiv](https://arxiv.org/abs/2212.09561)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09561.md)]
- Interactive Cartoonization with Controllable Perceptual Factors - [[Arxiv](https://arxiv.org/abs/2212.09555)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09555.md)]
- HARP: Personalized Hand Reconstruction from a Monocular RGB Video - [[Arxiv](https://arxiv.org/abs/2212.09530)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09530.md)]
- MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and   Video Generation - [[Arxiv](https://arxiv.org/abs/2212.09478)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09478.md)]
- Latent Diffusion for Language Generation - [[Arxiv](https://arxiv.org/abs/2212.09462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09462.md)]
- Difformer: Empowering Diffusion Models on the Embedding Space for Text   Generation - [[Arxiv](https://arxiv.org/abs/2212.09412)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09412.md)]
- Distilling Vision-Language Pre-training to Collaborate with   Weakly-Supervised Temporal Action Localization - [[Arxiv](https://arxiv.org/abs/2212.09335)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09335.md)]
- Out-of-domain GAN inversion via Invertibility Decomposition for   Photo-Realistic Human Face Manipulation - [[Arxiv](https://arxiv.org/abs/2212.09262)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09262.md)]
- Discovering Language Model Behaviors with Model-Written Evaluations - [[Arxiv](https://arxiv.org/abs/2212.09251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09251.md)]
- PAL: Persona-Augmented Emotional Support Conversation Generation - [[Arxiv](https://arxiv.org/abs/2212.09235)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09235.md)]
- Discrete Point-wise Attack Is Not Enough: Generalized Manifold   Adversarial Attack for Face Recognition - [[Arxiv](https://arxiv.org/abs/2301.06083)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.06083.md)]
- Emergent Analogical Reasoning in Large Language Models - [[Arxiv](https://arxiv.org/abs/2212.09196)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09196.md)]
- Don't Forget Your ABC's: Evaluating the State-of-the-Art in   Chat-Oriented Dialogue Systems - [[Arxiv](https://arxiv.org/abs/2212.09180)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09180.md)]
- Can Retriever-Augmented Language Models Reason? The Blame Game Between   the Retriever and the Language Model - [[Arxiv](https://arxiv.org/abs/2212.09146)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09146.md)]
- Let's Negotiate! A Survey of Negotiation Dialogue Systems - [[Arxiv](https://arxiv.org/abs/2212.09072)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09072.md)]
- Masked Wavelet Representation for Compact Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2212.09069)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09069.md)]
- Fine-Tuning Is All You Need to Mitigate Backdoor Attacks - [[Arxiv](https://arxiv.org/abs/2212.09067)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09067.md)]
- Minimizing Maximum Model Discrepancy for Transferable Black-box Targeted   Attacks - [[Arxiv](https://arxiv.org/abs/2212.09035)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.09035.md)]
- A Layered Architecture for Universal Causality - [[Arxiv](https://arxiv.org/abs/2212.08981)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08981.md)]
- Are We Ready for Vision-Centric Driving Streaming Perception? The ASAP   Benchmark - [[Arxiv](https://arxiv.org/abs/2212.08914)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08914.md)]
- Neural Story Planning - [[Arxiv](https://arxiv.org/abs/2212.08718)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08718.md)]
- Uncovering the Disentanglement Capability in Text-to-Image Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2212.08698)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08698.md)]
- The Impact of Symbolic Representations on In-context Learning for   Few-shot Reasoning - [[Arxiv](https://arxiv.org/abs/2212.08686)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08686.md)]
- Attentive Mask CLIP - [[Arxiv](https://arxiv.org/abs/2212.08653)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08653.md)]
- GFPose: Learning 3D Human Pose Prior with Gradient Fields - [[Arxiv](https://arxiv.org/abs/2212.08641)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08641.md)]
- Learnable Commutative Monoids for Graph Neural Networks - [[Arxiv](https://arxiv.org/abs/2212.08541)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08541.md)]
- Teaching Small Language Models to Reason - [[Arxiv](https://arxiv.org/abs/2212.08410)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08410.md)]
- Autoencoders as Cross-Modal Teachers: Can Pretrained 2D Image   Transformers Help 3D Representation Learning? - [[Arxiv](https://arxiv.org/abs/2212.08320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08320.md)]
- RepQ-ViT: Scale Reparameterization for Post-Training Quantization of   Vision Transformers - [[Arxiv](https://arxiv.org/abs/2212.08254)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08254.md)]
- Backdoor Attack Detection in Computer Vision by Applying Matrix   Factorization on the Weights of Deep Networks - [[Arxiv](https://arxiv.org/abs/2212.08121)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08121.md)]
- Injecting Domain Knowledge in Language Models for Task-Oriented Dialogue   Systems - [[Arxiv](https://arxiv.org/abs/2212.08120)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08120.md)]
- MAViL: Masked Audio-Video Learners - [[Arxiv](https://arxiv.org/abs/2212.08071)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08071.md)]
- VolRecon: Volume Rendering of Signed Ray Distance Functions for   Generalizable Multi-View Reconstruction - [[Arxiv](https://arxiv.org/abs/2212.08067)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08067.md)]
- MetaPortrait: Identity-Preserving Talking Head Generation with Fast   Personalized Adaptation - [[Arxiv](https://arxiv.org/abs/2212.08062)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08062.md)]
- On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in   Zero-Shot Reasoning - [[Arxiv](https://arxiv.org/abs/2212.08061)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08061.md)]
- Rethinking Vision Transformers for MobileNet Size and Speed - [[Arxiv](https://arxiv.org/abs/2212.08059)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08059.md)]
- Real-Time Neural Light Field on Mobile Devices - [[Arxiv](https://arxiv.org/abs/2212.08057)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08057.md)]
- Objaverse: A Universe of Annotated 3D Objects - [[Arxiv](https://arxiv.org/abs/2212.08051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08051.md)]
- Sliced Optimal Partial Transport - [[Arxiv](https://arxiv.org/abs/2212.08049)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08049.md)]
- CLIPPO: Image-and-Language Understanding from Pixels Only - [[Arxiv](https://arxiv.org/abs/2212.08045)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08045.md)]
- FlexiViT: One Model for All Patch Sizes - [[Arxiv](https://arxiv.org/abs/2212.08013)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08013.md)]
- EVAL: Explainable Video Anomaly Localization - [[Arxiv](https://arxiv.org/abs/2212.07900)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07900.md)]
- DeepLSD: Line Segment Detection and Refinement with Deep Image Gradients - [[Arxiv](https://arxiv.org/abs/2212.07766)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07766.md)]
- Relightable Neural Human Assets from Multi-view Gradient Illuminations - [[Arxiv](https://arxiv.org/abs/2212.07648)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07648.md)]
- Constitutional AI: Harmlessness from AI Feedback - [[Arxiv](https://arxiv.org/abs/2212.08073)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08073.md)]
- NeuralDome: A Neural Modeling Pipeline on Multi-View Human-Object   Interactions - [[Arxiv](https://arxiv.org/abs/2212.07626)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07626.md)]
- Enhanced Training of Query-Based Object Detection via Selective Query   Recollection - [[Arxiv](https://arxiv.org/abs/2212.07593)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07593.md)]
- SteerNeRF: Accelerating NeRF Rendering via Smooth Viewpoint Trajectory - [[Arxiv](https://arxiv.org/abs/2212.08476)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.08476.md)]
- IMos: Intent-Driven Full-Body Motion Synthesis for Human-Object   Interactions - [[Arxiv](https://arxiv.org/abs/2212.07555)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07555.md)]
- Efficient Self-supervised Learning with Contextualized Target   Representations for Vision, Speech and Language - [[Arxiv](https://arxiv.org/abs/2212.07525)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07525.md)]
- ECON: Explicit Clothed humans Optimized via Normal integration - [[Arxiv](https://arxiv.org/abs/2212.07422)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07422.md)]
- Self-Supervised Geometry-Aware Encoder for Style-Based 3D GAN Inversion - [[Arxiv](https://arxiv.org/abs/2212.07409)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07409.md)]
- Policy Adaptation from Foundation Model Feedback - [[Arxiv](https://arxiv.org/abs/2212.07398)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07398.md)]
- NoPe-NeRF: Optimising Neural Radiance Field with No Pose Prior - [[Arxiv](https://arxiv.org/abs/2212.07388)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07388.md)]
- ConQueR: Query Contrast Voxel-DETR for 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2212.07289)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07289.md)]
- HOOD: Hierarchical Graphs for Generalized Modelling of Clothing Dynamics - [[Arxiv](https://arxiv.org/abs/2212.07242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07242.md)]
- Reproducible scaling laws for contrastive language-image learning - [[Arxiv](https://arxiv.org/abs/2212.07143)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07143.md)]
- PD-Quant: Post-Training Quantization based on Prediction Difference   Metric - [[Arxiv](https://arxiv.org/abs/2212.07048)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07048.md)]
- Understanding Zero-Shot Adversarial Robustness for Large-Scale Models - [[Arxiv](https://arxiv.org/abs/2212.07016)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07016.md)]
- EgoLoc: Revisiting 3D Object Localization from Egocentric Videos with   Visual Queries - [[Arxiv](https://arxiv.org/abs/2212.06969)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06969.md)]
- Imagen Editor and EditBench: Advancing and Evaluating Text-Guided Image   Inpainting - [[Arxiv](https://arxiv.org/abs/2212.06909)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06909.md)]
- CREPE: Can Vision-Language Foundation Models Reason Compositionally? - [[Arxiv](https://arxiv.org/abs/2212.07796)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.07796.md)]
- Look Before You Match: Instance Understanding Matters in Video Object   Segmentation - [[Arxiv](https://arxiv.org/abs/2212.06826)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06826.md)]
- Structured 3D Features for Reconstructing Controllable Avatars - [[Arxiv](https://arxiv.org/abs/2212.06820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06820.md)]
- Learning 3D Representations from 2D Pre-trained Models via   Image-to-Point Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2212.06785)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06785.md)]
- Category Theory for Quantum Natural Language Processing - [[Arxiv](https://arxiv.org/abs/2212.06615)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06615.md)]
- FastMIM: Expediting Masked Image Modeling Pre-training for Vision - [[Arxiv](https://arxiv.org/abs/2212.06593)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06593.md)]
- Pixel is All You Need: Adversarial Trajectory-Ensemble Active Learning   for Salient Object Detection - [[Arxiv](https://arxiv.org/abs/2212.06493)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06493.md)]
- DA Wand: Distortion-Aware Selection using Neural Mesh Parameterization - [[Arxiv](https://arxiv.org/abs/2212.06344)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06344.md)]
- DeepMapping2: Self-Supervised Large-Scale LiDAR Map Optimization - [[Arxiv](https://arxiv.org/abs/2212.06331)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06331.md)]
- Doubly Right Object Recognition: A Why Prompt for Visual Rationales - [[Arxiv](https://arxiv.org/abs/2212.06202)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06202.md)]
- Breaking the "Object" in Video Object Segmentation - [[Arxiv](https://arxiv.org/abs/2212.06200)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06200.md)]
- Rodin: A Generative Model for Sculpting 3D Digital Avatars Using   Diffusion - [[Arxiv](https://arxiv.org/abs/2212.06135)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06135.md)]
- RGBD2: Generative Scene Synthesis via Incremental View Inpainting using   RGBD Diffusion Models - [[Arxiv](https://arxiv.org/abs/2212.05993)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05993.md)]
- Towards Practical Plug-and-Play Diffusion Models - [[Arxiv](https://arxiv.org/abs/2212.05973)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05973.md)]
- Evaluation and Improvement of Interpretability for Self-Explainable   Part-Prototype Networks - [[Arxiv](https://arxiv.org/abs/2212.05946)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05946.md)]
- ALSO: Automotive Lidar Self-supervision by Occupancy estimation - [[Arxiv](https://arxiv.org/abs/2212.05867)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05867.md)]
- Accelerating Dataset Distillation via Model Augmentation - [[Arxiv](https://arxiv.org/abs/2212.06152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.06152.md)]
- MoDem: Accelerating Visual Model-Based Reinforcement Learning with   Demonstrations - [[Arxiv](https://arxiv.org/abs/2212.05698)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05698.md)]
- REAP: A Large-Scale Realistic Adversarial Patch Benchmark - [[Arxiv](https://arxiv.org/abs/2212.05680)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05680.md)]
- Masked autoencoders are effective solution to transformer data-hungry - [[Arxiv](https://arxiv.org/abs/2212.05677)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05677.md)]
- Cross-Modal Learning with 3D Deformable Attention for Action Recognition - [[Arxiv](https://arxiv.org/abs/2212.05638)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05638.md)]
- Recurrent Vision Transformers for Object Detection with Event Cameras - [[Arxiv](https://arxiv.org/abs/2212.05598)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05598.md)]
- PromptCAL: Contrastive Affinity Learning via Auxiliary Prompts for   Generalized Novel Category Discovery - [[Arxiv](https://arxiv.org/abs/2212.05590)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05590.md)]
- How to Backdoor Diffusion Models? - [[Arxiv](https://arxiv.org/abs/2212.05400)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05400.md)]
- Source-free Depth for Object Pop-out - [[Arxiv](https://arxiv.org/abs/2212.05370)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05370.md)]
- HumanGen: Generating Human Radiance Fields with Explicit Priors - [[Arxiv](https://arxiv.org/abs/2212.05321)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05321.md)]
- Position Embedding Needs an Independent Layer Normalization - [[Arxiv](https://arxiv.org/abs/2212.05262)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05262.md)]
- NeuS2: Fast Learning of Neural Implicit Surfaces for Multi-view   Reconstruction - [[Arxiv](https://arxiv.org/abs/2212.05231)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05231.md)]
- MAGVIT: Masked Generative Video Transformer - [[Arxiv](https://arxiv.org/abs/2212.05199)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05199.md)]
- A Whac-A-Mole Dilemma: Shortcuts Come in Multiples Where Mitigating One   Amplifies Others - [[Arxiv](https://arxiv.org/abs/2212.04825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04825.md)]
- VindLU: A Recipe for Effective Video-and-Language Pretraining - [[Arxiv](https://arxiv.org/abs/2212.05051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05051.md)]
- SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model - [[Arxiv](https://arxiv.org/abs/2212.05034)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05034.md)]
- Training-Free Structured Diffusion Guidance for Compositional   Text-to-Image Synthesis - [[Arxiv](https://arxiv.org/abs/2212.05032)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05032.md)]
- Open Vocabulary Semantic Segmentation with Patch Aligned Contrastive   Learning - [[Arxiv](https://arxiv.org/abs/2212.04994)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04994.md)]
- Augmentation Matters: A Simple-yet-Effective Approach to Semi-supervised   Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2212.04976)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04976.md)]
- Seeing a Rose in Five Thousand Ways - [[Arxiv](https://arxiv.org/abs/2212.04965)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04965.md)]
- Information-Theoretic Safe Exploration with Gaussian Processes - [[Arxiv](https://arxiv.org/abs/2212.04914)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04914.md)]
- Genie: Show Me the Data for Quantization - [[Arxiv](https://arxiv.org/abs/2212.04780)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04780.md)]
- Genie: Show Me the Data for Quantization - [[Arxiv](https://arxiv.org/abs/2212.04780)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04780.md)]
- SLAM for Visually Impaired Navigation: A Systematic Literature Review of   the Current State of Research - [[Arxiv](https://arxiv.org/abs/2212.04745)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04745.md)]
- ShadowDiffusion: When Degradation Prior Meets Diffusion Model for Shadow   Removal - [[Arxiv](https://arxiv.org/abs/2212.04711)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04711.md)]
- Primal Dual Alternating Proximal Gradient Algorithms for Nonsmooth   Nonconvex Minimax Problems with Coupled Linear Constraints - [[Arxiv](https://arxiv.org/abs/2212.04672)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04672.md)]
- MIMO Is All You Need : A Strong Multi-In-Multi-Out Baseline for Video   Prediction - [[Arxiv](https://arxiv.org/abs/2212.04655)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04655.md)]
- FLAG3D: A 3D Fitness Activity Dataset with Language Instruction - [[Arxiv](https://arxiv.org/abs/2212.04638)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04638.md)]
- Ego-Body Pose Estimation via Ego-Head Pose Estimation - [[Arxiv](https://arxiv.org/abs/2212.04636)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04636.md)]
- Structured Like a Language Model: Analysing AI as an Automated Subject - [[Arxiv](https://arxiv.org/abs/2212.05058)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.05058.md)]
- ORCa: Glossy Objects as Radiance Field Cameras - [[Arxiv](https://arxiv.org/abs/2212.04531)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04531.md)]
- Masked Video Distillation: Rethinking Masked Feature Modeling for   Self-supervised Video Representation Learning - [[Arxiv](https://arxiv.org/abs/2212.04500)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04500.md)]
- MoFusion: A Framework for Denoising-Diffusion-based Motion Synthesis - [[Arxiv](https://arxiv.org/abs/2212.04495)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04495.md)]
- SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation - [[Arxiv](https://arxiv.org/abs/2212.04493)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04493.md)]
- Multi-Concept Customization of Text-to-Image Diffusion - [[Arxiv](https://arxiv.org/abs/2212.04488)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04488.md)]
- Fresnel Microfacet BRDF: Unification of Polari-Radiometric Surface-Body   Reflection - [[Arxiv](https://arxiv.org/abs/2212.04483)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04483.md)]
- Phone2Proc: Bringing Robust Robots Into Our Chaotic World - [[Arxiv](https://arxiv.org/abs/2212.04819)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04819.md)]
- Generating Holistic 3D Human Motion from Speech - [[Arxiv](https://arxiv.org/abs/2212.04420)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04420.md)]
- BEVBert: Multimodal Map Pre-training for Language-guided Navigation - [[Arxiv](https://arxiv.org/abs/2212.04385)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04385.md)]
- MIME: Human-Aware 3D Scene Generation - [[Arxiv](https://arxiv.org/abs/2212.04360)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04360.md)]
- On the Robustness of Normalizing Flows for Inverse Problems in Imaging - [[Arxiv](https://arxiv.org/abs/2212.04319)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04319.md)]
- GazeNeRF: 3D-Aware Gaze Redirection with Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2212.04823)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04823.md)]
- Decorate the Newcomers: Visual Domain Prompt for Continual Test Time   Adaptation - [[Arxiv](https://arxiv.org/abs/2212.04145)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04145.md)]
- Deep Incubation: Training Large Models by Divide-and-Conquering - [[Arxiv](https://arxiv.org/abs/2212.04129)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04129.md)]
- Successive Prompting for Decomposing Complex Questions - [[Arxiv](https://arxiv.org/abs/2212.04092)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04092.md)]
- Exploiting Completeness and Uncertainty of Pseudo Labels for Weakly   Supervised Video Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2212.04090)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04090.md)]
- LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large   Language Models - [[Arxiv](https://arxiv.org/abs/2212.04088)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04088.md)]
- Learning to Dub Movies via Hierarchical Prosody Models - [[Arxiv](https://arxiv.org/abs/2212.04054)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04054.md)]
- Executing your Commands via Motion Diffusion in Latent Space - [[Arxiv](https://arxiv.org/abs/2212.04048)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04048.md)]
- Teaching Matters: Investigating the Role of Supervision in Vision   Transformers - [[Arxiv](https://arxiv.org/abs/2212.03862)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03862.md)]
- Talking Head Generation with Probabilistic Audio-to-Visual Diffusion   Priors - [[Arxiv](https://arxiv.org/abs/2212.04248)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04248.md)]
- iQuery: Instruments as Queries for Audio-Visual Sound Separation - [[Arxiv](https://arxiv.org/abs/2212.03814)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03814.md)]
- Reconciling a Centroid-Hypothesis Conflict in Source-Free Domain   Adaptation - [[Arxiv](https://arxiv.org/abs/2212.03795)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03795.md)]
- GLeaD: Improving GANs with A Generator-Leading Task - [[Arxiv](https://arxiv.org/abs/2212.03752)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03752.md)]
- FineDance: A Fine-grained Choreography Dataset for 3D Full Body Dance   Generation - [[Arxiv](https://arxiv.org/abs/2212.03741)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03741.md)]
- EditableNeRF: Editing Topologically Varying Neural Radiance Fields by   Key Points - [[Arxiv](https://arxiv.org/abs/2212.04247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.04247.md)]
- Name Your Colour For the Task: Artificially Discover Colour Naming via   Colour Quantisation Transformer - [[Arxiv](https://arxiv.org/abs/2212.03434)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03434.md)]
- Diffusion-SDF: Text-to-Shape via Voxelized Diffusion - [[Arxiv](https://arxiv.org/abs/2212.03293)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03293.md)]
- NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as   General Image Priors - [[Arxiv](https://arxiv.org/abs/2212.03267)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03267.md)]
- Fine-tuned CLIP Models are Efficient Video Learners - [[Arxiv](https://arxiv.org/abs/2212.03640)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03640.md)]
- Perspective Fields for Single Image Camera Calibration - [[Arxiv](https://arxiv.org/abs/2212.03239)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03239.md)]
- Rethinking Video ViTs: Sparse Video Tubes for Joint Image and Video   Learning - [[Arxiv](https://arxiv.org/abs/2212.03229)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03229.md)]
- Visual Query Tuning: Towards Effective Usage of Intermediate   Representations for Parameter and Memory Efficient Transfer Learning - [[Arxiv](https://arxiv.org/abs/2212.03220)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03220.md)]
- InternVideo: General Video Foundation Models via Generative and   Discriminative Learning - [[Arxiv](https://arxiv.org/abs/2212.03191)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03191.md)]
- Semantic-Conditional Diffusion Networks for Image Captioning - [[Arxiv](https://arxiv.org/abs/2212.03099)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03099.md)]
- Iterative Next Boundary Detection for Instance Segmentation of Tree   Rings in Microscopy Images of Shrub Cross Sections - [[Arxiv](https://arxiv.org/abs/2212.03022)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.03022.md)]
- Leveraging Different Learning Styles for Improved Knowledge Distillation   in Biomedical Imaging - [[Arxiv](https://arxiv.org/abs/2212.02931)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02931.md)]
- Diffusion Video Autoencoders: Toward Temporally Consistent Face Video   Editing via Disentangled Video Encoding - [[Arxiv](https://arxiv.org/abs/2212.02802)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02802.md)]
- Adaptive Testing of Computer Vision Models - [[Arxiv](https://arxiv.org/abs/2212.02774)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02774.md)]
- Learning Neural Parametric Head Models - [[Arxiv](https://arxiv.org/abs/2212.02761)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02761.md)]
- Unifying Vision, Text, and Layout for Universal Document Processing - [[Arxiv](https://arxiv.org/abs/2212.02623)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02623.md)]
- SceneRF: Self-Supervised Monocular 3D Scene Reconstruction with Radiance   Fields - [[Arxiv](https://arxiv.org/abs/2212.02501)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02501.md)]
- Images Speak in Images: A Generalist Painter for In-Context Visual   Learning - [[Arxiv](https://arxiv.org/abs/2212.02499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02499.md)]
- PEANUT: Predicting and Navigating to Unseen Targets - [[Arxiv](https://arxiv.org/abs/2212.02497)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02497.md)]
- One-shot Implicit Animatable Avatars with Model-based Priors - [[Arxiv](https://arxiv.org/abs/2212.02469)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02469.md)]
- Block Selection Method for Using Feature Norm in Out-of-distribution   Detection - [[Arxiv](https://arxiv.org/abs/2212.02295)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02295.md)]
- I2MVFormer: Large Language Model Generated Multi-View Document   Supervision for Zero-Shot Image Classification - [[Arxiv](https://arxiv.org/abs/2212.02291)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02291.md)]
- Momentum Decoding: Open-ended Text Generation As Graph Exploration - [[Arxiv](https://arxiv.org/abs/2212.02175)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02175.md)]
- Prototypical Residual Networks for Anomaly Detection and Localization - [[Arxiv](https://arxiv.org/abs/2212.02031)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02031.md)]
- Learning Imbalanced Data with Vision Transformers - [[Arxiv](https://arxiv.org/abs/2212.02015)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.02015.md)]
- Multiscale Structure Guided Diffusion for Image Deblurring - [[Arxiv](https://arxiv.org/abs/2212.01789)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01789.md)]
- Self-supervised AutoFlow - [[Arxiv](https://arxiv.org/abs/2212.01762)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01762.md)]
- Improving Zero-shot Generalization and Robustness of Multi-modal Models - [[Arxiv](https://arxiv.org/abs/2212.01758)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01758.md)]
- Fast Point Cloud Generation with Straight Flows - [[Arxiv](https://arxiv.org/abs/2212.01747)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01747.md)]
- Neural Fourier Filter Bank - [[Arxiv](https://arxiv.org/abs/2212.01735)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01735.md)]
- StegaNeRF: Embedding Invisible Information within Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2212.01602)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01602.md)]
- PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained   Image-Language Models - [[Arxiv](https://arxiv.org/abs/2212.01558)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01558.md)]
- PGFed: Personalize Each Client's Global Objective for Federated Learning - [[Arxiv](https://arxiv.org/abs/2212.01448)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01448.md)]
- PROB: Probabilistic Objectness for Open World Object Detection - [[Arxiv](https://arxiv.org/abs/2212.01424)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01424.md)]
- Moving Beyond Downstream Task Accuracy for Information Retrieval   Benchmarking - [[Arxiv](https://arxiv.org/abs/2212.01340)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01340.md)]
- MIC: Masked Image Consistency for Context-Enhanced Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2212.01322)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01322.md)]
- DiffRF: Rendering-Guided 3D Radiance Field Diffusion - [[Arxiv](https://arxiv.org/abs/2212.01206)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01206.md)]
- RT-NeRF: Real-Time On-Device Neural Radiance Fields Towards Immersive   AR/VR Rendering - [[Arxiv](https://arxiv.org/abs/2212.01120)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01120.md)]
- Are Straight-Through gradients and Soft-Thresholding all you need for   Sparse Training? - [[Arxiv](https://arxiv.org/abs/2212.01076)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.01076.md)]
- Cloud-Device Collaborative Adaptation to Continual Changing Environments   in the Real-world - [[Arxiv](https://arxiv.org/abs/2212.00972)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00972.md)]
- StructVPR: Distill Structural Knowledge with Weighting Samples for   Visual Place Recognition - [[Arxiv](https://arxiv.org/abs/2212.00937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00937.md)]
- Scaling Language-Image Pre-training via Masking - [[Arxiv](https://arxiv.org/abs/2212.00794)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00794.md)]
- SparseFusion: Distilling View-conditioned Diffusion for 3D   Reconstruction - [[Arxiv](https://arxiv.org/abs/2212.00792)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00792.md)]
- Unite and Conquer: Plug &amp; Play Multi-Modal Synthesis using Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2212.00793)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00793.md)]
- 3D Segmentation of Humans in Point Clouds with Synthetic Data - [[Arxiv](https://arxiv.org/abs/2212.00786)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00786.md)]
- Learning to Generate Text-grounded Mask for Open-world Semantic   Segmentation from Only Image-Text Pairs - [[Arxiv](https://arxiv.org/abs/2212.00785)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00785.md)]
- ResFormer: Scaling ViTs with Multi-Resolution Training - [[Arxiv](https://arxiv.org/abs/2212.00776)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00776.md)]
- Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D   Generation - [[Arxiv](https://arxiv.org/abs/2212.00774)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00774.md)]
- Exploiting Proximity-Aware Tasks for Embodied Social Navigation - [[Arxiv](https://arxiv.org/abs/2212.00767)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00767.md)]
- Hyperbolic Contrastive Learning for Visual Representations beyond   Objects - [[Arxiv](https://arxiv.org/abs/2212.00653)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00653.md)]
- Finetune like you pretrain: Improved finetuning of zero-shot vision   models - [[Arxiv](https://arxiv.org/abs/2212.00638)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00638.md)]
- Graph Convolutional Neural Networks as Parametric CoKleisli morphisms - [[Arxiv](https://arxiv.org/abs/2212.00542)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00542.md)]
- Language Model Pre-training on True Negatives - [[Arxiv](https://arxiv.org/abs/2212.00460v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00460v1.md)]
- Language Model Pre-training on True Negatives - [[Arxiv](https://arxiv.org/abs/2212.00460)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00460.md)]
- Language Model Pre-training on True Negatives - [[Arxiv](https://arxiv.org/abs/2212.00460)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00460.md)]
- 3D-Aware Object Goal Navigation via Simultaneous Exploration and   Identification - [[Arxiv](https://arxiv.org/abs/2212.00338)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00338.md)]
- Parametric Information Maximization for Generalized Category Discovery - [[Arxiv](https://arxiv.org/abs/2212.00334)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00334.md)]
- All You Need Is Hashing: Defending Against Data Reconstruction Attack in   Vertical Federated Learning - [[Arxiv](https://arxiv.org/abs/2212.00325)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00325.md)]
- Distilling Reasoning Capabilities into Smaller Language Models - [[Arxiv](https://arxiv.org/abs/2212.00193)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2212.00193.md)]

### November 2022
- Plateau-reduced Differentiable Path Tracing - [[Arxiv](https://arxiv.org/abs/2211.17263)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.17263.md)]
- SinGRAF: Learning a 3D Generative Radiance Field for a Single Scene - [[Arxiv](https://arxiv.org/abs/2211.17260)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.17260.md)]
- CREPE: Open-Domain Question Answering with False Presuppositions - [[Arxiv](https://arxiv.org/abs/2211.17257)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.17257.md)]
- CLIPascene: Scene Sketching with Different Types and Levels of   Abstraction - [[Arxiv](https://arxiv.org/abs/2211.17256)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.17256.md)]
- NeRFInvertor: High Fidelity NeRF-GAN Inversion for Single-shot Real   Image Animation - [[Arxiv](https://arxiv.org/abs/2211.17235)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.17235.md)]
- Fast Inference from Transformers via Speculative Decoding - [[Arxiv](https://arxiv.org/abs/2211.17192)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.17192.md)]
- High-Fidelity Guided Image Synthesis with Latent Diffusion Models - [[Arxiv](https://arxiv.org/abs/2211.17084)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.17084.md)]
- Spatio-Temporal Crop Aggregation for Video Representation Learning - [[Arxiv](https://arxiv.org/abs/2211.17042)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.17042.md)]
- BASiS: Batch Aligned Spectral Embedding Space - [[Arxiv](https://arxiv.org/abs/2211.16960)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16960.md)]
- DiffPose: Toward More Reliable 3D Pose Estimation - [[Arxiv](https://arxiv.org/abs/2211.16940)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16940.md)]
- 3D GAN Inversion with Facial Symmetry Prior - [[Arxiv](https://arxiv.org/abs/2211.16927)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16927.md)]
- 3D Neural Field Generation using Triplane Diffusion - [[Arxiv](https://arxiv.org/abs/2211.16677)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16677.md)]
- DINER: Depth-aware Image-based NEural Radiance fields - [[Arxiv](https://arxiv.org/abs/2211.16630)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16630.md)]
- Improving Commonsense in Vision-Language Models via Knowledge Graph   Riddles - [[Arxiv](https://arxiv.org/abs/2211.16504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16504.md)]
- NeuralLift-360: Lifting An In-the-wild 2D Photo to A 3D Object with   360 Views - [[Arxiv](https://arxiv.org/abs/2211.16431)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16431.md)]
- RGB no more: Minimally-decoded JPEG Vision Transformers - [[Arxiv](https://arxiv.org/abs/2211.16421)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16421.md)]
- Compressing Volumetric Radiance Fields to 1 MB - [[Arxiv](https://arxiv.org/abs/2211.16386)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16386.md)]
- PLA: Language-Driven Open-Vocabulary 3D Scene Understanding - [[Arxiv](https://arxiv.org/abs/2211.16312)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16312.md)]
- Advancing Deep Metric Learning Through Multiple Batch Norms And   Multi-Targeted Adversarial Examples - [[Arxiv](https://arxiv.org/abs/2211.16253)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16253.md)]
- Scalable Hierarchical Over-the-Air Federated Learning - [[Arxiv](https://arxiv.org/abs/2211.16162)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16162.md)]
- Out-Of-Distribution Detection Is Not All You Need - [[Arxiv](https://arxiv.org/abs/2211.16158)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16158.md)]
- Wavelet Diffusion Models are fast and scalable Image Generators - [[Arxiv](https://arxiv.org/abs/2211.16152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16152.md)]
- ExpNet: A unified network for Expert-Level Classification - [[Arxiv](https://arxiv.org/abs/2211.15672)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15672.md)]
- NoisyQuant: Noisy Bias-Enhanced Post-Training Activation Quantization   for Vision Transformers - [[Arxiv](https://arxiv.org/abs/2211.16056)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16056.md)]
- Dimensionality-Varying Diffusion Process - [[Arxiv](https://arxiv.org/abs/2211.16032)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16032.md)]
- UDE: A Unified Driving Engine for Human Motion Generation - [[Arxiv](https://arxiv.org/abs/2211.16016)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16016.md)]
- SparsePose: Sparse-View Camera Pose Regression and Refinement - [[Arxiv](https://arxiv.org/abs/2211.16991)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16991.md)]
- MegaBlocks: Efficient Sparse Training with Mixture-of-Experts - [[Arxiv](https://arxiv.org/abs/2211.15841)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15841.md)]
- Decentralized Learning with Multi-Headed Distillation - [[Arxiv](https://arxiv.org/abs/2211.15774)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15774.md)]
- Post-training Quantization on Diffusion Models - [[Arxiv](https://arxiv.org/abs/2211.15736)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15736.md)]
- High-fidelity 3D GAN Inversion by Pseudo-multi-view Optimization - [[Arxiv](https://arxiv.org/abs/2211.15662)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15662.md)]
- Connecting the Dots: Floorplan Reconstruction Using Two-Level Queries - [[Arxiv](https://arxiv.org/abs/2211.15658)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15658.md)]
- Is Conditional Generative Modeling all you need for Decision-Making? - [[Arxiv](https://arxiv.org/abs/2211.15657)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15657.md)]
- SuS-X: Training-Free Name-Only Transfer of Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2211.16198)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16198.md)]
- In-Hand 3D Object Scanning from an RGB Sequence - [[Arxiv](https://arxiv.org/abs/2211.16193)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16193.md)]
- A Light Touch Approach to Teaching Transformers Multi-view Geometry - [[Arxiv](https://arxiv.org/abs/2211.15107)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15107.md)]
- Class Adaptive Network Calibration - [[Arxiv](https://arxiv.org/abs/2211.15088)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15088.md)]
- FeatureBooster: Boosting Feature Descriptors with a Lightweight Neural   Network - [[Arxiv](https://arxiv.org/abs/2211.15069)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15069.md)]
- High-fidelity Facial Avatar Reconstruction from Monocular Video with   Generative Priors - [[Arxiv](https://arxiv.org/abs/2211.15064)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15064.md)]
- DiffusionBERT: Improving Generative Masked Language Models with   Diffusion Models - [[Arxiv](https://arxiv.org/abs/2211.15029)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15029.md)]
- Optimal Sparse Regression Trees - [[Arxiv](https://arxiv.org/abs/2211.14980)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14980.md)]
- Post-Processing Temporal Action Detection - [[Arxiv](https://arxiv.org/abs/2211.14924)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14924.md)]
- FJMP: Factorized Joint Multi-Agent Motion Prediction over Learned   Directed Acyclic Interaction Graphs - [[Arxiv](https://arxiv.org/abs/2211.16197)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.16197.md)]
- Dense Text Retrieval based on Pretrained Language Models: A Survey - [[Arxiv](https://arxiv.org/abs/2211.14876)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14876.md)]
- 3DPPE: 3D Point Positional Encoding for Multi-Camera 3D Object Detection   Transformers - [[Arxiv](https://arxiv.org/abs/2211.14710)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14710.md)]
- SliceMatch: Geometry-guided Aggregation for Cross-View Pose Estimation - [[Arxiv](https://arxiv.org/abs/2211.14651)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14651.md)]
- Towards Improved Input Masking for Convolutional Neural Networks - [[Arxiv](https://arxiv.org/abs/2211.14646)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14646.md)]
- Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection   in Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2211.14512)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14512.md)]
- Progressive Disentangled Representation Learning for Fine-Grained   Controllable Talking Head Synthesis - [[Arxiv](https://arxiv.org/abs/2211.14506)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14506.md)]
- Meta Architecture for Point Cloud Analysis - [[Arxiv](https://arxiv.org/abs/2211.14462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14462.md)]
- SpaText: Spatio-Textual Representation for Controllable Image Generation - [[Arxiv](https://arxiv.org/abs/2211.14305)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14305.md)]
- RUST: Latent Neural Scene Representations from Unposed Imagery - [[Arxiv](https://arxiv.org/abs/2211.14306)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14306.md)]
- BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction - [[Arxiv](https://arxiv.org/abs/2211.14304)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14304.md)]
- RbA: Segmenting Unknown Regions Rejected by All - [[Arxiv](https://arxiv.org/abs/2211.14293)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14293.md)]
- NeuralUDF: Learning Unsigned Distance Fields for Multi-view   Reconstruction of Surfaces with Arbitrary Topologies - [[Arxiv](https://arxiv.org/abs/2211.14173)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14173.md)]
- A Strong Baseline for Generalized Few-Shot Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2211.14126)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14126.md)]
- ShadowNeuS: Neural SDF Reconstruction by Shadow Ray Supervision - [[Arxiv](https://arxiv.org/abs/2211.14086)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14086.md)]
- Fine-Grained Face Swapping via Regional GAN Inversion - [[Arxiv](https://arxiv.org/abs/2211.14068)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14068.md)]
- SCOOP: Self-Supervised Correspondence and Optimization-Based Scene Flow - [[Arxiv](https://arxiv.org/abs/2211.14020)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14020.md)]
- SCOOP: Self-Supervised Correspondence and Optimization-Based Scene Flow - [[Arxiv](https://arxiv.org/abs/2211.14020)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.14020.md)]
- CoMFormer: Continual Learning in Semantic and Panoptic Segmentation - [[Arxiv](https://arxiv.org/abs/2211.13999)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13999.md)]
- Unsupervised Continual Semantic Adaptation through Neural Rendering - [[Arxiv](https://arxiv.org/abs/2211.13969)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13969.md)]
- MPCViT: Searching for Accurate and Efficient MPC-Friendly Vision   Transformer with Heterogeneous Attention - [[Arxiv](https://arxiv.org/abs/2211.13955)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13955.md)]
- Learning Detailed Radiance Manifolds for High-Fidelity and 3D-Consistent   Portrait Synthesis from Monocular Image - [[Arxiv](https://arxiv.org/abs/2211.13901)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13901.md)]
- Learning with Silver Standard Data for Zero-shot Relation Extraction - [[Arxiv](https://arxiv.org/abs/2211.13883)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13883.md)]
- FFHQ-UV: Normalized Facial UV-Texture Dataset for 3D Face Reconstruction - [[Arxiv](https://arxiv.org/abs/2211.13874)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13874.md)]
- GEFF: Improving Any Clothes-Changing Person ReID Model using Gallery   Enrichment with Face Features - [[Arxiv](https://arxiv.org/abs/2211.13807)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13807.md)]
- SAGA: Spectral Adversarial Geometric Attack on 3D Meshes - [[Arxiv](https://arxiv.org/abs/2211.13775)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13775.md)]
- Diffusion-SDF: Conditional Generative Modeling of Signed Distance   Functions - [[Arxiv](https://arxiv.org/abs/2211.13757)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13757.md)]
- Attention-based Feature Compression for CNN Inference Offloading in Edge   Computing - [[Arxiv](https://arxiv.org/abs/2211.13745)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13745.md)]
- Perception-Oriented Single Image Super-Resolution using Optimal   Objective Estimation - [[Arxiv](https://arxiv.org/abs/2211.13676)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13676.md)]
- SfM-TTR: Using Structure from Motion for Test-Time Refinement of   Single-View Depth Networks - [[Arxiv](https://arxiv.org/abs/2211.13551)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13551.md)]
- Video Test-Time Adaptation for Action Recognition - [[Arxiv](https://arxiv.org/abs/2211.15393)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15393.md)]
- TSGP: Two-Stage Generative Prompting for Unsupervised Commonsense   Question Answering - [[Arxiv](https://arxiv.org/abs/2211.13515)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13515.md)]
- Pose-disentangled Contrastive Learning for Self-supervised Facial   Representation - [[Arxiv](https://arxiv.org/abs/2211.13490)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13490.md)]
- Seeing What You Miss: Vision-Language Pre-training with Semantic   Completion Learning - [[Arxiv](https://arxiv.org/abs/2211.13437)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13437.md)]
- Shifted Diffusion for Text-to-image Generation - [[Arxiv](https://arxiv.org/abs/2211.15388)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15388.md)]
- HouseDiffusion: Vector Floorplan Generation via a Diffusion Model with   Discrete and Continuous Denoising - [[Arxiv](https://arxiv.org/abs/2211.13287)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13287.md)]
- Paint by Example: Exemplar-based Image Editing with Diffusion Models - [[Arxiv](https://arxiv.org/abs/2211.13227)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13227.md)]
- ClimateNeRF: Extreme Weather Synthesis in Neural Radiance Field - [[Arxiv](https://arxiv.org/abs/2211.13226)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13226.md)]
- Generalizable Implicit Neural Representations via Instance Pattern   Composers - [[Arxiv](https://arxiv.org/abs/2211.13223)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13223.md)]
- SVFormer: Semi-supervised Video Transformer for Action Recognition - [[Arxiv](https://arxiv.org/abs/2211.13222)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13222.md)]
- CODA-Prompt: COntinual Decomposed Attention-based Prompting for   Rehearsal-Free Continual Learning - [[Arxiv](https://arxiv.org/abs/2211.13218)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13218.md)]
- ReCo: Region-Controlled Text-to-Image Generation - [[Arxiv](https://arxiv.org/abs/2211.15518)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15518.md)]
- Inversion-Based Style Transfer with Diffusion Models - [[Arxiv](https://arxiv.org/abs/2211.13203)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13203.md)]
- Lite-Mono: A Lightweight CNN and Transformer Architecture for   Self-Supervised Monocular Depth Estimation - [[Arxiv](https://arxiv.org/abs/2211.13202)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13202.md)]
- FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning - [[Arxiv](https://arxiv.org/abs/2211.13131)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13131.md)]
- Robust Mean Teacher for Continual and Gradual Test-Time Adaptation - [[Arxiv](https://arxiv.org/abs/2211.13081)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.13081.md)]
- Open-vocabulary Attribute Detection - [[Arxiv](https://arxiv.org/abs/2211.12914)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12914.md)]
- OReX: Object Reconstruction from Planar Cross-sections Using Neural   Fields - [[Arxiv](https://arxiv.org/abs/2211.12886)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12886.md)]
- ActMAD: Activation Matching to Align Distributions for   Test-Time-Training - [[Arxiv](https://arxiv.org/abs/2211.12870)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12870.md)]
- ActMAD: Activation Matching to Align Distributions for   Test-Time-Training - [[Arxiv](https://arxiv.org/abs/2211.12870)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12870.md)]
- BAD-NeRF: Bundle Adjusted Deblur Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2211.12853)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12853.md)]
- Tell Me What Happened: Unifying Text-guided Video Completion via   Multimodal Masked Video Generation - [[Arxiv](https://arxiv.org/abs/2211.12824)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12824.md)]
- Hand Avatar: Free-Pose Hand Animation and Rendering from Monocular Video - [[Arxiv](https://arxiv.org/abs/2211.12782)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12782.md)]
- VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval - [[Arxiv](https://arxiv.org/abs/2211.12764)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12764.md)]
- Texts as Images in Prompt Tuning for Multi-Label Image Recognition - [[Arxiv](https://arxiv.org/abs/2211.12739)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12739.md)]
- Integrally Pre-Trained Transformer Pyramid Networks - [[Arxiv](https://arxiv.org/abs/2211.12735)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12735.md)]
- PNI : Industrial Anomaly Detection using Position and Neighborhood   Information - [[Arxiv](https://arxiv.org/abs/2211.12634)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12634.md)]
- Improving Robust Generalization by Direct PAC-Bayesian Bound   Minimization - [[Arxiv](https://arxiv.org/abs/2211.12624)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12624.md)]
- Program of Thoughts Prompting: Disentangling Computation from Reasoning   for Numerical Reasoning Tasks - [[Arxiv](https://arxiv.org/abs/2211.12588)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12588.md)]
- PermutoSDF: Fast Multi-View Reconstruction with Implicit Surfaces using   Permutohedral Lattices - [[Arxiv](https://arxiv.org/abs/2211.12562)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12562.md)]
- CASSPR: Cross Attention Single Scan Place Recognition - [[Arxiv](https://arxiv.org/abs/2211.12542)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12542.md)]
- AeDet: Azimuth-invariant Multi-view 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2211.12501)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12501.md)]
- Person Image Synthesis via Denoising Diffusion Model - [[Arxiv](https://arxiv.org/abs/2211.12500)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12500.md)]
- Instant Volumetric Head Avatars - [[Arxiv](https://arxiv.org/abs/2211.12499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12499.md)]
- Shortcomings of Top-Down Randomization-Based Sanity Checks for   Evaluations of Deep Neural Network Explanations - [[Arxiv](https://arxiv.org/abs/2211.12486)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12486.md)]
- EDICT: Exact Diffusion Inversion via Coupled Transformations - [[Arxiv](https://arxiv.org/abs/2211.12446)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12446.md)]
- OCTET: Object-aware Counterfactual Explanations - [[Arxiv](https://arxiv.org/abs/2211.12380)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12380.md)]
- OCTET: Object-aware Counterfactual Explanations - [[Arxiv](https://arxiv.org/abs/2211.12380)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12380.md)]
- DETRs with Collaborative Hybrid Assignments Training - [[Arxiv](https://arxiv.org/abs/2211.12860)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12860.md)]
- GlowGAN: Unsupervised Learning of HDR Images from LDR Images in the Wild - [[Arxiv](https://arxiv.org/abs/2211.12352)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12352.md)]
- DOLCE: A Model-Based Probabilistic Diffusion Framework for Limited-Angle   CT Reconstruction - [[Arxiv](https://arxiv.org/abs/2211.12340)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12340.md)]
- Out-of-Candidate Rectification for Weakly Supervised Semantic   Segmentation - [[Arxiv](https://arxiv.org/abs/2211.12268)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12268.md)]
- SPIn-NeRF: Multiview Segmentation and Perceptual Inpainting with Neural   Radiance Fields - [[Arxiv](https://arxiv.org/abs/2211.12254)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12254.md)]
- Efficient Frequency Domain-based Transformers for High-Quality Image   Deblurring - [[Arxiv](https://arxiv.org/abs/2211.12250)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12250.md)]
- SadTalker: Learning Realistic 3D Motion Coefficients for Stylized   Audio-Driven Single Image Talking Face Animation - [[Arxiv](https://arxiv.org/abs/2211.12194)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12194.md)]
- DiffDreamer: Towards Consistent Unsupervised Single-view Scene   Extrapolation with Conditional Diffusion Models - [[Arxiv](https://arxiv.org/abs/2211.12131)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12131.md)]
- Explaining Image Classifiers with Multiscale Directional Image   Representation - [[Arxiv](https://arxiv.org/abs/2211.12857)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12857.md)]
- Backdoor Cleansing with Unlabeled Data - [[Arxiv](https://arxiv.org/abs/2211.12044)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12044.md)]
- Level-S$^2$fM: Structure from Motion on Neural Level Set of Implicit   Surfaces - [[Arxiv](https://arxiv.org/abs/2211.12018)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12018.md)]
- One Eye is All You Need: Lightweight Ensembles for Gaze Estimation with   Single Encoders - [[Arxiv](https://arxiv.org/abs/2211.11936)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11936.md)]
- Multi-Directional Subspace Editing in Style-Space - [[Arxiv](https://arxiv.org/abs/2211.11825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11825.md)]
- Visual Dexterity: In-hand Dexterous Manipulation from Depth - [[Arxiv](https://arxiv.org/abs/2211.11744)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11744.md)]
- SceneComposer: Any-Level Semantic Image Synthesis - [[Arxiv](https://arxiv.org/abs/2211.11742)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11742.md)]
- SPARF: Neural Radiance Fields from Sparse and Noisy Poses - [[Arxiv](https://arxiv.org/abs/2211.11738)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11738.md)]
- PLIKS: A Pseudo-Linear Inverse Kinematic Solver for 3D Human Body   Estimation - [[Arxiv](https://arxiv.org/abs/2211.11734)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11734.md)]
- Teaching Structured Vision&amp;Language Concepts to Vision&amp;Language Models - [[Arxiv](https://arxiv.org/abs/2211.11733)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11733.md)]
- Multitask Vision-Language Prompt Tuning - [[Arxiv](https://arxiv.org/abs/2211.11720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11720.md)]
- ESLAM: Efficient Dense SLAM System Based on Hybrid Representation of   Signed Distance Fields - [[Arxiv](https://arxiv.org/abs/2211.11704)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11704.md)]
- PointCLIP V2: Prompting CLIP and GPT for Powerful 3D Open-world Learning - [[Arxiv](https://arxiv.org/abs/2211.11682)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11682.md)]
- Shape, Pose, and Appearance from a Single Image via Bootstrapped   Radiance Field Inversion - [[Arxiv](https://arxiv.org/abs/2211.11674)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11674.md)]
- Guided Depth Super-Resolution by Deep Anisotropic Diffusion - [[Arxiv](https://arxiv.org/abs/2211.11592)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11592.md)]
- Efficient Second-Order Plane Adjustment - [[Arxiv](https://arxiv.org/abs/2211.11542)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11542.md)]
- Local-to-Global Registration for Bundle-Adjusting Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2211.11505)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11505.md)]
- Delving StyleGAN Inversion for Image Editing: A Foundation Latent Space   Viewpoint - [[Arxiv](https://arxiv.org/abs/2211.11448)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11448.md)]
- SMAUG: Sparse Masked Autoencoder for Efficient Video-Language   Pre-training - [[Arxiv](https://arxiv.org/abs/2211.11446)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11446.md)]
- MATE: Masked Autoencoders are Online 3D Test-Time Learners - [[Arxiv](https://arxiv.org/abs/2211.11432)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11432.md)]
- Blur Interpolation Transformer for Real-World Motion from Blur - [[Arxiv](https://arxiv.org/abs/2211.11423)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11423.md)]
- DyNCA: Real-time Dynamic Texture Synthesis Using Neural Cellular   Automata - [[Arxiv](https://arxiv.org/abs/2211.11417)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11417.md)]
- From Node Interaction to Hop Interaction: New Effective and Scalable   Graph Learning Paradigm - [[Arxiv](https://arxiv.org/abs/2211.11761)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11761.md)]
- Few-shot Non-line-of-sight Imaging with Signal-surface Collaborative   Regularization - [[Arxiv](https://arxiv.org/abs/2211.15367)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15367.md)]
- Instance-specific and Model-adaptive Supervision for Semi-supervised   Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2211.11335)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11335.md)]
- DeSTSeg: Segmentation Guided Denoising Student-Teacher for Anomaly   Detection - [[Arxiv](https://arxiv.org/abs/2211.11317)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11317.md)]
- Neural Dependencies Emerging from Learning Massive Categories - [[Arxiv](https://arxiv.org/abs/2211.12339)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.12339.md)]
- SeeABLE: Soft Discrepancies and Bounded Contrastive Learning for   Exposing Deepfakes - [[Arxiv](https://arxiv.org/abs/2211.11296)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11296.md)]
- DrapeNet: Garment Generation and Self-Supervised Draping - [[Arxiv](https://arxiv.org/abs/2211.11277)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11277.md)]
- Investigating Prompt Engineering in Diffusion Models - [[Arxiv](https://arxiv.org/abs/2211.15462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15462.md)]
- Next3D: Generative Neural Texture Rasterization for 3D-Aware Head   Avatars - [[Arxiv](https://arxiv.org/abs/2211.11208)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11208.md)]
- NeuMap: Neural Coordinate Mapping by Auto-Transdecoder for Camera   Localization - [[Arxiv](https://arxiv.org/abs/2211.11177)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11177.md)]
- Vision Transformer with Super Token Sampling - [[Arxiv](https://arxiv.org/abs/2211.11167)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11167.md)]
- Language in a Bottle: Language Model Guided Concept Bottlenecks for   Interpretable Image Classification - [[Arxiv](https://arxiv.org/abs/2211.11158)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11158.md)]
- You Need Multiple Exiting: Dynamic Early Exiting for Accelerating   Unified Vision Language Model - [[Arxiv](https://arxiv.org/abs/2211.11152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11152.md)]
- DynIBaR: Neural Dynamic Image-Based Rendering - [[Arxiv](https://arxiv.org/abs/2211.11082)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11082.md)]
- The Stack: 3 TB of permissively licensed source code - [[Arxiv](https://arxiv.org/abs/2211.15533)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15533.md)]
- Minimizing the Accumulated Trajectory Error to Improve Dataset   Distillation - [[Arxiv](https://arxiv.org/abs/2211.11004)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11004.md)]
- Leveraging per Image-Token Consistency for Vision-Language Pre-training - [[Arxiv](https://arxiv.org/abs/2211.15398)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.15398.md)]
- DYNAFED: Tackling Client Data Heterogeneity with Global Dynamics - [[Arxiv](https://arxiv.org/abs/2211.10878)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10878.md)]
- Learning to Generate Image Embeddings with User-level Differential   Privacy - [[Arxiv](https://arxiv.org/abs/2211.10844)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10844.md)]
- DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text   Spotting - [[Arxiv](https://arxiv.org/abs/2211.10772)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10772.md)]
- Passive Micron-scale Time-of-Flight with Sunlight Interferometry - [[Arxiv](https://arxiv.org/abs/2211.10732)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10732.md)]
- EDGE: Editable Dance Generation From Music - [[Arxiv](https://arxiv.org/abs/2211.10658)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10658.md)]
- Parallel Diffusion Models of Operator and Image for Blind Inverse   Problems - [[Arxiv](https://arxiv.org/abs/2211.10656)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10656.md)]
- Solving 3D Inverse Problems using Pre-trained 2D Diffusion Models - [[Arxiv](https://arxiv.org/abs/2211.10655)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10655.md)]
- LidarGait: Benchmarking 3D Gait Recognition with Point Clouds - [[Arxiv](https://arxiv.org/abs/2211.10598)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10598.md)]
- MatrixVT: Efficient Multi-Camera to BEV Transformation for 3D Perception - [[Arxiv](https://arxiv.org/abs/2211.10593)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10593.md)]
- Tired of Over-smoothing? Stress Graph Drawing Is All You Need! - [[Arxiv](https://arxiv.org/abs/2211.10579)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10579.md)]
- A Practical Stereo Depth System for Smart Glasses - [[Arxiv](https://arxiv.org/abs/2211.10551)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10551.md)]
- Where is my Wallet? Modeling Object Proposal Sets for Egocentric Visual   Query Localization - [[Arxiv](https://arxiv.org/abs/2211.10528)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10528.md)]
- Magic3D: High-Resolution Text-to-3D Content Creation - [[Arxiv](https://arxiv.org/abs/2211.10440)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10440.md)]
- BEVFormer v2: Adapting Modern Image Backbones to Bird's-Eye-View   Recognition via Perspective Supervision - [[Arxiv](https://arxiv.org/abs/2211.10439)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10439.md)]
- PAL: Program-aided Language Models - [[Arxiv](https://arxiv.org/abs/2211.10435)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10435.md)]
- Visual Programming: Compositional visual reasoning without training - [[Arxiv](https://arxiv.org/abs/2211.11559)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.11559.md)]
- Task Residual for Tuning Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2211.10277)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10277.md)]
- Patch-Craft Self-Supervised Training for Correlated Image Denoising - [[Arxiv](https://arxiv.org/abs/2211.09919)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09919.md)]
- SPACE: Speech-driven Portrait Animation with Controllable Expression - [[Arxiv](https://arxiv.org/abs/2211.09809)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09809.md)]
- Uni-Perceiver v2: A Generalist Model for Large-Scale Vision and   Vision-Language Tasks - [[Arxiv](https://arxiv.org/abs/2211.09808)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09808.md)]
- Towards All-in-one Pre-training via Maximizing Multi-modal Mutual   Information - [[Arxiv](https://arxiv.org/abs/2211.09807)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09807.md)]
- InstructPix2Pix: Learning to Follow Image Editing Instructions - [[Arxiv](https://arxiv.org/abs/2211.09800)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09800.md)]
- CAE v2: Context Autoencoder with CLIP Target - [[Arxiv](https://arxiv.org/abs/2211.09799)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09799.md)]
- Null-text Inversion for Editing Real Images using Guided Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2211.09794)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09794.md)]
- MOTRv2: Bootstrapping End-to-End Multi-Object Tracking by Pretrained   Object Detectors - [[Arxiv](https://arxiv.org/abs/2211.09791)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09791.md)]
- I Can't Believe There's No Images! Learning Visual Tasks Using only   Language Supervision - [[Arxiv](https://arxiv.org/abs/2211.09778)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09778.md)]
- EfficientTrain: Exploring Generalized Curriculum Learning for Training   Visual Backbones - [[Arxiv](https://arxiv.org/abs/2211.09703)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09703.md)]
- AligNeRF: High-Fidelity Neural Radiance Fields via Alignment-Aware   Training - [[Arxiv](https://arxiv.org/abs/2211.09682)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09682.md)]
- CRAFT: Concept Recursive Activation FacTorization for Explainability - [[Arxiv](https://arxiv.org/abs/2211.10154)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10154.md)]
- UniFormerV2: Spatiotemporal Learning by Arming Image ViTs with Video   UniFormer - [[Arxiv](https://arxiv.org/abs/2211.09552)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09552.md)]
- DETRDistill: A Universal Knowledge Distillation Framework for   DETR-families - [[Arxiv](https://arxiv.org/abs/2211.10156)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10156.md)]
- UMFuse: Unified Multi View Fusion for Human Editing applications - [[Arxiv](https://arxiv.org/abs/2211.10157)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.10157.md)]
- Task-aware Retrieval with Instructions - [[Arxiv](https://arxiv.org/abs/2211.09260)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09260.md)]
- AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with   Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2211.09120)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09120.md)]
- AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with   Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2211.09120)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09120.md)]
- Token Turing Machines - [[Arxiv](https://arxiv.org/abs/2211.09119)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09119.md)]
- MAGE: MAsked Generative Encoder to Unify Representation Learning and   Image Synthesis - [[Arxiv](https://arxiv.org/abs/2211.09117)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09117.md)]
- Holistic Evaluation of Language Models - [[Arxiv](https://arxiv.org/abs/2211.09110)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09110.md)]
- Galactica: A Large Language Model for Science - [[Arxiv](https://arxiv.org/abs/2211.09085)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09085.md)]
- Stare at What You See: Masked Image Modeling without Reconstruction - [[Arxiv](https://arxiv.org/abs/2211.08887)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.08887.md)]
- A Generalized Framework for Video Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2211.08834)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.08834.md)]
- Addressing the issue of stochastic environments and local   decision-making in multi-objective reinforcement learning - [[Arxiv](https://arxiv.org/abs/2211.08669)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.08669.md)]
- Consistent Direct Time-of-Flight Video Depth Super-Resolution - [[Arxiv](https://arxiv.org/abs/2211.08658)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.08658.md)]
- R-Pred: Two-Stage Motion Prediction Via Tube-Query Attention-Based   Trajectory Refinement - [[Arxiv](https://arxiv.org/abs/2211.08609)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.08609.md)]
- PromptCap: Prompt-Guided Task-Aware Image Captioning - [[Arxiv](https://arxiv.org/abs/2211.09699)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09699.md)]
- Versatile Diffusion: Text, Images and Variations All in One Diffusion   Model - [[Arxiv](https://arxiv.org/abs/2211.08332)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.08332.md)]
- Is Style All You Need? Dependencies Between Emotion and GST-based   Speaker Recognition - [[Arxiv](https://arxiv.org/abs/2211.08213)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.08213.md)]
- Uncertainty-aware Gait Recognition via Learning from Dirichlet   Distribution-based Evidence - [[Arxiv](https://arxiv.org/abs/2211.08007)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.08007.md)]
- Teaching Algorithmic Reasoning via In-context Learning - [[Arxiv](https://arxiv.org/abs/2211.09066)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.09066.md)]
- DINER: Disorder-Invariant Implicit Neural Representation - [[Arxiv](https://arxiv.org/abs/2211.07871)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07871.md)]
- EVA: Exploring the Limits of Masked Visual Representation Learning at   Scale - [[Arxiv](https://arxiv.org/abs/2211.07636)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07636.md)]
- Follow the Wisdom of the Crowd: Effective Text Generation via Minimum   Bayes Risk Decoding - [[Arxiv](https://arxiv.org/abs/2211.07634)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07634.md)]
- Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures - [[Arxiv](https://arxiv.org/abs/2211.07600)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07600.md)]
- Imagination is All You Need! Curved Contrastive Learning for Abstract   Sequence Modeling Utilized on Long Short-Term Dialogue Planning - [[Arxiv](https://arxiv.org/abs/2211.07591)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07591.md)]
- PKCAM: Previous Knowledge Channel Attention Module - [[Arxiv](https://arxiv.org/abs/2211.07521)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07521.md)]
- PKCAM: Previous Knowledge Channel Attention Module - [[Arxiv](https://arxiv.org/abs/2211.07521v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07521v2.md)]
- MLIC: Multi-Reference Entropy Model for Learned Image Compression - [[Arxiv](https://arxiv.org/abs/2211.07273)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07273.md)]
- Fcaformer: Forward Cross Attention in Hybrid Vision Transformer - [[Arxiv](https://arxiv.org/abs/2211.07198)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07198.md)]
- ParCNetV2: Oversized Kernel with Enhanced Attention - [[Arxiv](https://arxiv.org/abs/2211.07157)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07157.md)]
- Joint Data Deepening-and-Prefetching for Energy-Efficient Edge Learning - [[Arxiv](https://arxiv.org/abs/2211.07146)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07146.md)]
- BiViT: Extremely Compressed Binary Vision Transformer - [[Arxiv](https://arxiv.org/abs/2211.07091)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.07091.md)]
- OverFlow: Putting flows on top of neural transducers for better TTS - [[Arxiv](https://arxiv.org/abs/2211.06892)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06892.md)]
- VGFlow: Visibility guided Flow Network for Human Reposing - [[Arxiv](https://arxiv.org/abs/2211.08540)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.08540.md)]
- Residual Degradation Learning Unfolding Framework with Mixing Priors   across Spectral and Spatial for Compressive Spectral Imaging - [[Arxiv](https://arxiv.org/abs/2211.06891)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06891.md)]
- SCOTCH and SODA: A Transformer Video Shadow Detection Framework - [[Arxiv](https://arxiv.org/abs/2211.06885)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06885.md)]
- Large Language Models Meet Harry Potter: A Bilingual Dataset for   Aligning Dialogue Agents with Characters - [[Arxiv](https://arxiv.org/abs/2211.06869)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06869.md)]
- CXTrack: Improving 3D Point Cloud Tracking with Contextual Information - [[Arxiv](https://arxiv.org/abs/2211.08542)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.08542.md)]
- MARLIN: Masked Autoencoder for facial video Representation LearnINg - [[Arxiv](https://arxiv.org/abs/2211.06627)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06627.md)]
- OpenGait: Revisiting Gait Recognition Toward Better Practicality - [[Arxiv](https://arxiv.org/abs/2211.06597)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06597.md)]
- Rewards Encoding Environment Dynamics Improves Preference-based   Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2211.06527)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06527.md)]
- Probabilistic Debiasing of Scene Graphs - [[Arxiv](https://arxiv.org/abs/2211.06444)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06444.md)]
- Phase-Shifting Coder: Predicting Accurate Orientation in Oriented Object   Detection - [[Arxiv](https://arxiv.org/abs/2211.06368)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06368.md)]
- Masked Contrastive Representation Learning - [[Arxiv](https://arxiv.org/abs/2211.06012v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06012v1.md)]
- Masked Contrastive Representation Learning - [[Arxiv](https://arxiv.org/abs/2211.06012)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06012.md)]
- Delay Embedded Echo-State Network: A Predictor for Partially Observed   Systems - [[Arxiv](https://arxiv.org/abs/2211.05992)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.05992.md)]
- High-Quality Entity Segmentation - [[Arxiv](https://arxiv.org/abs/2211.05776)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.05776.md)]
- OneFormer: One Transformer to Rule Universal Image Segmentation - [[Arxiv](https://arxiv.org/abs/2211.06220)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06220.md)]
- MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal   Open-domain Conversation - [[Arxiv](https://arxiv.org/abs/2211.05719)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.05719.md)]
- Secure Aggregation Is Not All You Need: Mitigating Privacy Attacks with   Noise Tolerance in Federated Learning - [[Arxiv](https://arxiv.org/abs/2211.06324)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.06324.md)]
- GAPartNet: Cross-Category Domain-Generalizable Object Perception and   Manipulation via Generalizable and Actionable Parts - [[Arxiv](https://arxiv.org/abs/2211.05272)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.05272.md)]
- Safe Latent Diffusion: Mitigating Inappropriate Degeneration in   Diffusion Models - [[Arxiv](https://arxiv.org/abs/2211.05105)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.05105.md)]
- BLOOM: A 176B-Parameter Open-Access Multilingual Language Model - [[Arxiv](https://arxiv.org/abs/2211.05100)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.05100.md)]
- NoiSER: Noise is All You Need for Low-Light Image Enhancement - [[Arxiv](https://arxiv.org/abs/2211.04700)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.04700.md)]
- Cross-Attention is all you need: Real-Time Streaming Transformers for   Personalised Speech Enhancement - [[Arxiv](https://arxiv.org/abs/2211.04346)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.04346.md)]
- Self-conditioned Embedding Diffusion for Text Generation - [[Arxiv](https://arxiv.org/abs/2211.04236)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.04236.md)]
- $BT^2$: Backward-compatible Training with Basis Transformation - [[Arxiv](https://arxiv.org/abs/2211.03989)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.03989.md)]
- Common Pets in 3D: Dynamic New-View Synthesis of Real-Life Deformable   Categories - [[Arxiv](https://arxiv.org/abs/2211.03889)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.03889.md)]
- A Unified Pyramid Recurrent Network for Video Frame Interpolation - [[Arxiv](https://arxiv.org/abs/2211.03456)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.03456.md)]
- Rickrolling the Artist: Injecting Backdoors into Text Encoders for   Text-to-Image Synthesis - [[Arxiv](https://arxiv.org/abs/2211.02408)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.02408.md)]
- Large Language Models Are Human-Level Prompt Engineers - [[Arxiv](https://arxiv.org/abs/2211.01910)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.01910.md)]
- Crosslingual Generalization through Multitask Finetuning - [[Arxiv](https://arxiv.org/abs/2211.01786)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.01786.md)]
- Progressive Transformation Learning for Leveraging Virtual Images in   Training - [[Arxiv](https://arxiv.org/abs/2211.01778)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.01778.md)]
- PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales - [[Arxiv](https://arxiv.org/abs/2211.01562)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.01562.md)]
- eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert   Denoisers - [[Arxiv](https://arxiv.org/abs/2211.01324)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.01324.md)]
- The Enemy of My Enemy is My Friend: Exploring Inverse Adversaries for   Improving Adversarial Training - [[Arxiv](https://arxiv.org/abs/2211.00525)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.00525.md)]
- The Perils of Learning From Unlabeled Data: Backdoor Attacks on   Semi-supervised Learning - [[Arxiv](https://arxiv.org/abs/2211.00453)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.00453.md)]
- CARE: Causality Reasoning for Empathetic Responses by Conditional Graph   Generation - [[Arxiv](https://arxiv.org/abs/2211.00255)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.00255.md)]

### October 2022
- SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for   Text Generation and Modular Control - [[Arxiv](https://arxiv.org/abs/2210.17432)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.17432.md)]
- GPTQ: Accurate Post-Training Quantization for Generative Pre-trained   Transformers - [[Arxiv](https://arxiv.org/abs/2210.17323)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.17323.md)]
- DanZero: Mastering GuanDan Game with Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2210.17087)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.17087.md)]
- DiffusER: Discrete Diffusion via Edit-based Reconstruction - [[Arxiv](https://arxiv.org/abs/2210.16886)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.16886.md)]
- A simple, efficient and scalable contrastive masked autoencoder for   learning visual representations - [[Arxiv](https://arxiv.org/abs/2210.16870)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.16870.md)]
- Temporal-Viewpoint Transportation Plan for Skeletal Few-shot Action   Recognition - [[Arxiv](https://arxiv.org/abs/2210.16820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.16820.md)]
- Saliency Can Be All You Need In Contrastive Self-Supervised Learning - [[Arxiv](https://arxiv.org/abs/2210.16776)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.16776.md)]
- STPrompt: Semantic-guided and Task-driven prompts for Effective Few-shot   Classification - [[Arxiv](https://arxiv.org/abs/2210.16489)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.16489.md)]
- Rawgment: Noise-Accounted RAW Augmentation Enables Recognition in a Wide   Variety of Environments - [[Arxiv](https://arxiv.org/abs/2210.16046)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.16046.md)]
- Vox-Fusion: Dense Tracking and Mapping with Voxel-based Neural Implicit   Representation - [[Arxiv](https://arxiv.org/abs/2210.15858)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.15858.md)]
- ACES: Translation Accuracy Challenge Sets for Evaluating Machine   Translation Metrics - [[Arxiv](https://arxiv.org/abs/2210.15615)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.15615.md)]
- Working Alliance Transformer for Psychotherapy Dialogue Classification - [[Arxiv](https://arxiv.org/abs/2210.15603)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.15603.md)]
- FreeVC: Towards High-Quality Text-Free One-Shot Voice Conversion - [[Arxiv](https://arxiv.org/abs/2210.15418)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.15418.md)]
- Contrastive Decoding: Open-ended Text Generation as Optimization - [[Arxiv](https://arxiv.org/abs/2210.15097)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.15097.md)]
- Streaming Radiance Fields for 3D Video Synthesis - [[Arxiv](https://arxiv.org/abs/2210.14831)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.14831.md)]
- Implicit Identity Leakage: The Stumbling Block to Improving Deepfake   Detection Generalization - [[Arxiv](https://arxiv.org/abs/2210.14457)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.14457.md)]
- Contrastive Search Is What You Need For Neural Text Generation - [[Arxiv](https://arxiv.org/abs/2210.14140)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.14140.md)]
- FineD-Eval: Fine-grained Automatic Dialogue-Level Evaluation - [[Arxiv](https://arxiv.org/abs/2210.13832)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.13832.md)]
- Towards Robust Recommender Systems via Triple Cooperative Defense - [[Arxiv](https://arxiv.org/abs/2210.13762)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.13762.md)]
- Dichotomy of Control: Separating What You Can Control from What You   Cannot - [[Arxiv](https://arxiv.org/abs/2210.13435)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.13435.md)]
- Emergent World Representations: Exploring a Sequence Model Trained on a   Synthetic Task - [[Arxiv](https://arxiv.org/abs/2210.13382)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.13382.md)]
- GlassesGAN: Eyewear Personalization using Synthetic Appearance Discovery   and Targeted Subspace Modeling - [[Arxiv](https://arxiv.org/abs/2210.14145)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.14145.md)]
- Efficiently Trained Low-Resource Mongolian Text-to-Speech System Based   On FullConv-TTS - [[Arxiv](https://arxiv.org/abs/2211.01948)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2211.01948.md)]
- 10 hours data is all you need - [[Arxiv](https://arxiv.org/abs/2210.13067)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.13067.md)]
- Overview of Dialogue Robot Competition 2022 - [[Arxiv](https://arxiv.org/abs/2210.12863)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.12863.md)]
- DANLI: Deliberative Agent for Following Natural Language Instructions - [[Arxiv](https://arxiv.org/abs/2210.12485)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.12485.md)]
- Towards Efficient Dialogue Pre-training with Transferable and   Interpretable Latent Structure - [[Arxiv](https://arxiv.org/abs/2210.12461)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.12461.md)]
- Collaborative Reasoning on Multi-Modal Semantic Graphs for   Video-Grounded Dialogue Generation - [[Arxiv](https://arxiv.org/abs/2210.12460)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.12460.md)]
- There Is No Standard Answer: Knowledge-Grounded Dialogue Generation with   Adversarial Activated Multi-Reference Learning - [[Arxiv](https://arxiv.org/abs/2210.12459)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.12459.md)]
- WikiWhy: Answering and Explaining Cause-and-Effect Questions - [[Arxiv](https://arxiv.org/abs/2210.12152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.12152.md)]
- Large Language Models Can Self-Improve - [[Arxiv](https://arxiv.org/abs/2210.11610)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.11610.md)]
- i-MAE: Are Latent Representations in Masked Autoencoders Linearly   Separable? - [[Arxiv](https://arxiv.org/abs/2210.11470)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.11470.md)]
- Scaling Instruction-Finetuned Language Models - [[Arxiv](https://arxiv.org/abs/2210.11416)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.11416.md)]
- On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement   Learning - [[Arxiv](https://arxiv.org/abs/2210.10763)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.10763.md)]
- Scaling Laws for Reward Model Overoptimization - [[Arxiv](https://arxiv.org/abs/2210.10760)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.10760.md)]
- A Unified View of Masked Image Modeling - [[Arxiv](https://arxiv.org/abs/2210.10615)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.10615.md)]
- Co-guiding Net: Achieving Mutual Guidances between Multiple Intent   Detection and Slot Filling via Heterogeneous Semantics-Label Graphs - [[Arxiv](https://arxiv.org/abs/2210.10375)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.10375.md)]
- How to Boost Face Recognition with StyleGAN? - [[Arxiv](https://arxiv.org/abs/2210.10090)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.10090.md)]
- Bag All You Need: Learning a Generalizable Bagging Strategy for   Heterogeneous Objects - [[Arxiv](https://arxiv.org/abs/2210.09997)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.09997.md)]
- Perceptual Grouping in Contrastive Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2210.09996)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.09996.md)]
- MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving   Camera Videos - [[Arxiv](https://arxiv.org/abs/2210.09887)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.09887.md)]
- DisCup: Discriminator Cooperative Unlikelihood Prompt-tuning for   Controllable Text Generation - [[Arxiv](https://arxiv.org/abs/2210.09551)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.09551.md)]
- Non-Contrastive Learning Meets Language-Image Pre-Training - [[Arxiv](https://arxiv.org/abs/2210.09304)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.09304.md)]
- Imagic: Text-Based Real Image Editing with Diffusion Models - [[Arxiv](https://arxiv.org/abs/2210.09276)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.09276.md)]
- Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them - [[Arxiv](https://arxiv.org/abs/2210.09261)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.09261.md)]
- Multi-Agent Automated Machine Learning - [[Arxiv](https://arxiv.org/abs/2210.09084)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.09084.md)]
- DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models - [[Arxiv](https://arxiv.org/abs/2210.08933)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.08933.md)]
- Keep Me Updated! Memory Management in Long-term Conversations - [[Arxiv](https://arxiv.org/abs/2210.08750)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.08750.md)]
- Scratching Visual Transformer's Back with Uniform Attention - [[Arxiv](https://arxiv.org/abs/2210.08457)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.08457.md)]
- Data-Efficient Augmentation for Training Neural Networks - [[Arxiv](https://arxiv.org/abs/2210.08363v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.08363v3.md)]
- Data-Efficient Augmentation for Training Neural Networks - [[Arxiv](https://arxiv.org/abs/2210.08363)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.08363.md)]
- How Mask Matters: Towards Theoretical Understandings of Masked   Autoencoders - [[Arxiv](https://arxiv.org/abs/2210.08344)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.08344.md)]
- Is synthetic data from generative models ready for image recognition? - [[Arxiv](https://arxiv.org/abs/2210.07574)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.07574.md)]
- DyLoRA: Parameter Efficient Tuning of Pre-trained Models using Dynamic   Search-Free Low-Rank Adaptation - [[Arxiv](https://arxiv.org/abs/2210.07558)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.07558.md)]
- Visual Reinforcement Learning with Self-Supervised 3D Representations - [[Arxiv](https://arxiv.org/abs/2210.07241)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.07241.md)]
- Unified Vision and Language Prompt Learning - [[Arxiv](https://arxiv.org/abs/2210.07225)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.07225.md)]
- Visual Classification via Description from Large Language Models - [[Arxiv](https://arxiv.org/abs/2210.07183)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.07183.md)]
- Language Models of Code are Few-Shot Commonsense Learners - [[Arxiv](https://arxiv.org/abs/2210.07128)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.07128.md)]
- CUF: Continuous Upsampling Filters - [[Arxiv](https://arxiv.org/abs/2210.06965)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06965.md)]
- Retrospectives on the Embodied AI Workshop - [[Arxiv](https://arxiv.org/abs/2210.06849)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06849.md)]
- H2RBox: Horizontal Box Annotation is All You Need for Oriented Object   Detection - [[Arxiv](https://arxiv.org/abs/2210.06742)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06742.md)]
- Explanations from Large Language Models Make Small Reasoners Better - [[Arxiv](https://arxiv.org/abs/2210.06726)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06726.md)]
- Large Language Models are few(1)-shot Table Reasoners - [[Arxiv](https://arxiv.org/abs/2210.06710)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06710.md)]
- RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses - [[Arxiv](https://arxiv.org/abs/2210.10634)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.10634.md)]
- Token-Label Alignment for Vision Transformers - [[Arxiv](https://arxiv.org/abs/2210.06455)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06455.md)]
- A Generalist Framework for Panoptic Segmentation of Images and Videos - [[Arxiv](https://arxiv.org/abs/2210.06366)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06366.md)]
- Visual Prompting for Adversarial Robustness - [[Arxiv](https://arxiv.org/abs/2210.06284)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06284.md)]
- Masked Motion Encoding for Self-Supervised Video Representation Learning - [[Arxiv](https://arxiv.org/abs/2210.06096)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06096.md)]
- Multi-Granularity Cross-modal Alignment for Generalized Medical Visual   Representation Learning - [[Arxiv](https://arxiv.org/abs/2210.06044)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06044.md)]
- BEV-LaneDet: a Simple and Effective 3D Lane Detection Baseline - [[Arxiv](https://arxiv.org/abs/2210.06006)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06006.md)]
- ACSeg: Adaptive Conceptualization for Unsupervised Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2210.05944)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.05944.md)]
- Habitat-Matterport 3D Semantics Dataset - [[Arxiv](https://arxiv.org/abs/2210.05633)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.05633.md)]
- OPERA: Omni-Supervised Representation Learning with Hierarchical   Supervisions - [[Arxiv](https://arxiv.org/abs/2210.05557)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.05557.md)]
- Mind's Eye: Grounded Language Model Reasoning through Simulation - [[Arxiv](https://arxiv.org/abs/2210.05359)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.05359.md)]
- MAP: Multimodal Uncertainty-Aware Vision-Language Pre-training Model - [[Arxiv](https://arxiv.org/abs/2210.05335)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.05335.md)]
- It Takes Two: Masked Appearance-Motion Modeling for Self-supervised   Video Transformer Pre-training - [[Arxiv](https://arxiv.org/abs/2210.05234)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.05234.md)]
- BoxTeacher: Exploring High-Quality Pseudo Labels for Weakly Supervised   Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2210.05174)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.05174.md)]
- Multi-Object Navigation with dynamically learned neural implicit   representations - [[Arxiv](https://arxiv.org/abs/2210.05129)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.05129.md)]
- Certified Training: Small Boxes are All You Need - [[Arxiv](https://arxiv.org/abs/2210.04871)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.04871.md)]
- Denoising Masked AutoEncoders Help Robust Classification - [[Arxiv](https://arxiv.org/abs/2210.06983)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.06983.md)]
- Iterative Convex Optimization for Model Predictive Control with   Discrete-Time High-Order Control Barrier Functions - [[Arxiv](https://arxiv.org/abs/2210.04361)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.04361.md)]
- Improving Multi-turn Emotional Support Dialogue Generation with   Lookahead Strategy Planning - [[Arxiv](https://arxiv.org/abs/2210.04242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.04242.md)]
- Uncertainty-Aware Unsupervised Image Deblurring with Deep Residual Prior - [[Arxiv](https://arxiv.org/abs/2210.05361)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.05361.md)]
- Controllable Dialogue Simulation with In-Context Learning - [[Arxiv](https://arxiv.org/abs/2210.04185)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.04185.md)]
- Self-supervised Video Representation Learning with Motion-Aware Masked   Autoencoders - [[Arxiv](https://arxiv.org/abs/2210.04154)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.04154.md)]
- Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP - [[Arxiv](https://arxiv.org/abs/2210.04150)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.04150.md)]
- Don't Lose Yourself! Empathetic Response Generation via Explicit   Self-Other Awareness - [[Arxiv](https://arxiv.org/abs/2210.03884)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03884.md)]
- ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational   Finance Question Answering - [[Arxiv](https://arxiv.org/abs/2210.03849)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03849.md)]
- Is margin all you need? An extensive empirical study of active learning   on tabular data - [[Arxiv](https://arxiv.org/abs/2210.03822)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03822.md)]
- Large Language Models can Implement Policy Iteration - [[Arxiv](https://arxiv.org/abs/2210.03821)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03821.md)]
- GraspCaps: Capsule Networks Are All You Need for Grasping Familiar   Objects - [[Arxiv](https://arxiv.org/abs/2210.03628)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03628.md)]
- Automatic Chain of Thought Prompting in Large Language Models - [[Arxiv](https://arxiv.org/abs/2210.03493)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03493.md)]
- Trans2k: Unlocking the Power of Deep Models for Transparent Object   Tracking - [[Arxiv](https://arxiv.org/abs/2210.03436)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03436.md)]
- Measuring and Narrowing the Compositionality Gap in Language Models - [[Arxiv](https://arxiv.org/abs/2210.03350)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03350.md)]
- Critical Learning Periods for Multisensory Integration in Deep Networks - [[Arxiv](https://arxiv.org/abs/2210.04643)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.04643.md)]
- A ResNet is All You Need? Modeling A Strong Baseline for Detecting   Referable Diabetic Retinopathy in Fundus Images - [[Arxiv](https://arxiv.org/abs/2210.03180)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03180.md)]
- FAST: Improving Controllability for Text Generation with Feedback Aware   Self-Training - [[Arxiv](https://arxiv.org/abs/2210.03167)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03167.md)]
- On Distillation of Guided Diffusion Models - [[Arxiv](https://arxiv.org/abs/2210.03142)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03142.md)]
- MaPLe: Multi-modal Prompt Learning - [[Arxiv](https://arxiv.org/abs/2210.03117)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03117.md)]
- CLIP model is an Efficient Continual Learner - [[Arxiv](https://arxiv.org/abs/2210.03114)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03114.md)]
- A New Path: Scaling Vision-and-Language Navigation with Synthetic   Instructions and Imitation Learning - [[Arxiv](https://arxiv.org/abs/2210.03112)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03112.md)]
- VIMA: General Robot Manipulation with Multimodal Prompts - [[Arxiv](https://arxiv.org/abs/2210.03094)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03094.md)]
- Iterative Vision-and-Language Navigation - [[Arxiv](https://arxiv.org/abs/2210.03087)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03087.md)]
- Rainier: Reinforced Knowledge Introspector for Commonsense Question   Answering - [[Arxiv](https://arxiv.org/abs/2210.03078)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03078.md)]
- Language Models are Multilingual Chain-of-Thought Reasoners - [[Arxiv](https://arxiv.org/abs/2210.03057)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03057.md)]
- ByteTransformer: A High-Performance Transformer Boosted for   Variable-Length Inputs - [[Arxiv](https://arxiv.org/abs/2210.03052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03052.md)]
- A Distributional Lens for Multi-Aspect Controllable Text Generation - [[Arxiv](https://arxiv.org/abs/2210.02889)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.02889.md)]
- ReAct: Synergizing Reasoning and Acting in Language Models - [[Arxiv](https://arxiv.org/abs/2210.03629)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03629.md)]
- Depth Is All You Need for Monocular 3D Detection - [[Arxiv](https://arxiv.org/abs/2210.02493)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.02493.md)]
- GLM-130B: An Open Bilingual Pre-trained Model - [[Arxiv](https://arxiv.org/abs/2210.02414)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.02414.md)]
- Decomposed Prompting: A Modular Approach for Solving Complex Tasks - [[Arxiv](https://arxiv.org/abs/2210.02406)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.02406.md)]
- Promising or Elusive? Unsupervised Object Segmentation from Real-world   Single Images - [[Arxiv](https://arxiv.org/abs/2210.02324)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.02324.md)]
- Imagen Video: High Definition Video Generation with Diffusion Models - [[Arxiv](https://arxiv.org/abs/2210.02303)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.02303.md)]
- CorefDiffs: Co-referential and Differential Knowledge Flow in Document   Grounded Conversations - [[Arxiv](https://arxiv.org/abs/2210.02223)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.02223.md)]
- Teaching Yourself: Graph Self-Distillation on Neighborhood for Node   Classification - [[Arxiv](https://arxiv.org/abs/2210.02097)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.02097.md)]
- Exploring The Role of Mean Teachers in Self-supervised Masked   Auto-Encoders - [[Arxiv](https://arxiv.org/abs/2210.02077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.02077.md)]
- Affection: Learning Affective Explanations for Real-World Visual Data - [[Arxiv](https://arxiv.org/abs/2210.01946)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01946.md)]
- Collecting The Puzzle Pieces: Disentangled Self-Driven Human Pose   Transfer by Permuting Textures - [[Arxiv](https://arxiv.org/abs/2210.01887)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01887.md)]
- Group Personalized Federated Learning - [[Arxiv](https://arxiv.org/abs/2210.01863)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01863.md)]
- Group Personalized Federated Learning - [[Arxiv](https://arxiv.org/abs/2210.01863v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01863v2.md)]
- Centerpoints Are All You Need in Overhead Imagery - [[Arxiv](https://arxiv.org/abs/2210.01857)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01857.md)]
- COPILOT: Human-Environment Collision Prediction and Localization from   Egocentric Videos - [[Arxiv](https://arxiv.org/abs/2210.01781)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01781.md)]
- PlaneDepth: Self-supervised Depth Estimation via Orthogonal Planes - [[Arxiv](https://arxiv.org/abs/2210.01612)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01612.md)]
- Knowledge Unlearning for Mitigating Privacy Risks in Language Models - [[Arxiv](https://arxiv.org/abs/2210.01504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01504.md)]
- Extraneousness-Aware Imitation Learning - [[Arxiv](https://arxiv.org/abs/2210.01379)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01379.md)]
- Extraneousness-Aware Imitation Learning - [[Arxiv](https://arxiv.org/abs/2210.01379v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01379v2.md)]
- Recitation-Augmented Language Models - [[Arxiv](https://arxiv.org/abs/2210.01296)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01296.md)]
- Event-based Temporally Dense Optical Flow Estimation with Sequential   Learning - [[Arxiv](https://arxiv.org/abs/2210.01244)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01244.md)]
- Is Reinforcement Learning (Not) for Natural Language Processing:   Benchmarks, Baselines, and Building Blocks for Natural Language Policy   Optimization - [[Arxiv](https://arxiv.org/abs/2210.01241)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01241.md)]
- Language Models Are Greedy Reasoners: A Systematic Formal Analysis of   Chain-of-Thought - [[Arxiv](https://arxiv.org/abs/2210.01240)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01240.md)]
- Masked Spiking Transformer - [[Arxiv](https://arxiv.org/abs/2210.01208)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.01208.md)]
- Visual Prompt Tuning for Generative Transfer Learning - [[Arxiv](https://arxiv.org/abs/2210.00990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.00990.md)]
- Membership Inference Attacks Against Text-to-image Generation Models - [[Arxiv](https://arxiv.org/abs/2210.00968)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.00968.md)]
- Improving Sample Quality of Diffusion Models Using Self-Attention   Guidance - [[Arxiv](https://arxiv.org/abs/2210.00939)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.00939.md)]
- Mastering Spatial Graph Prediction of Road Networks - [[Arxiv](https://arxiv.org/abs/2210.00828)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.00828.md)]
- Complexity-Based Prompting for Multi-Step Reasoning - [[Arxiv](https://arxiv.org/abs/2210.00720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.00720.md)]
- IntrinsicNeRF: Learning Intrinsic Neural Radiance Fields for Editable   Novel View Synthesis - [[Arxiv](https://arxiv.org/abs/2210.00647)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.00647.md)]
- "Help Me Help the AI": Understanding How Explainability Can Support   Human-AI Interaction - [[Arxiv](https://arxiv.org/abs/2210.03735)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.03735.md)]
- Contrastive Audio-Visual Masked Autoencoder - [[Arxiv](https://arxiv.org/abs/2210.07839)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.07839.md)]
- NeRF: Neural Radiance Field in 3D Vision, A Comprehensive Review - [[Arxiv](https://arxiv.org/abs/2210.00379)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.00379.md)]
- Multimodal Analogical Reasoning over Knowledge Graphs - [[Arxiv](https://arxiv.org/abs/2210.00312)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.00312.md)]

### September 2022
- Bias Mimicking: A Simple Sampling Approach for Bias Mitigation - [[Arxiv](https://arxiv.org/abs/2209.15605)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.15605.md)]
- Combining Efficient and Precise Sign Language Recognition: Good pose   estimation library is all you need - [[Arxiv](https://arxiv.org/abs/2210.00893)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2210.00893.md)]
- Sphere-Guided Training of Neural Implicit Surfaces - [[Arxiv](https://arxiv.org/abs/2209.15511)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.15511.md)]
- SmallCap: Lightweight Image Captioning Prompted with Retrieval   Augmentation - [[Arxiv](https://arxiv.org/abs/2209.15323)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.15323.md)]
- Hiding Visual Information via Obfuscating Adversarial Perturbations - [[Arxiv](https://arxiv.org/abs/2209.15304)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.15304.md)]
- Learning Transferable Spatiotemporal Representations from Natural Script   Knowledge - [[Arxiv](https://arxiv.org/abs/2209.15280)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.15280.md)]
- State-specific protein-ligand complex structure prediction with a   multi-scale deep generative model - [[Arxiv](https://arxiv.org/abs/2209.15171)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.15171.md)]
- Compositional Semantic Parsing with Large Language Models - [[Arxiv](https://arxiv.org/abs/2209.15003)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.15003.md)]
- DreamFusion: Text-to-3D using 2D Diffusion - [[Arxiv](https://arxiv.org/abs/2209.14988)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.14988.md)]
- EDA: Explicit Text-Decoupling and Dense Alignment for 3D Visual   Grounding - [[Arxiv](https://arxiv.org/abs/2209.14941)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.14941.md)]
- Contrastive Unsupervised Learning of World Model with Invariant Causal   Features - [[Arxiv](https://arxiv.org/abs/2209.14932)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.14932.md)]
- Make-A-Video: Text-to-Video Generation without Text-Video Data - [[Arxiv](https://arxiv.org/abs/2209.14792)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.14792.md)]
- Dependent Bayesian Lenses: Categories of Bidirectional Markov Kernels   with Canonical Bayesian Inversion - [[Arxiv](https://arxiv.org/abs/2209.14728)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.14728.md)]
- Dynamic Prompt Learning via Policy Gradient for Semi-structured   Mathematical Reasoning - [[Arxiv](https://arxiv.org/abs/2209.14610)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.14610.md)]
- Improving alignment of dialogue agents via targeted human judgements - [[Arxiv](https://arxiv.org/abs/2209.14375)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.14375.md)]
- Learning State-Aware Visual Representations from Audible Interactions - [[Arxiv](https://arxiv.org/abs/2209.13583)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.13583.md)]
- Sentiment is all you need to win US Presidential elections - [[Arxiv](https://arxiv.org/abs/2209.13487)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.13487.md)]
- Can Large Language Models Truly Understand Prompts? A Case Study with   Negated Prompts - [[Arxiv](https://arxiv.org/abs/2209.12711)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.12711.md)]
- Deep Fair Clustering via Maximizing and Minimizing Mutual Information:   Theory, Algorithm and Metric - [[Arxiv](https://arxiv.org/abs/2209.12396)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.12396.md)]
- Paraphrasing Is All You Need for Novel Object Captioning - [[Arxiv](https://arxiv.org/abs/2209.12343)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.12343.md)]
- Generating Formal Safety Assurances for High-Dimensional Reachability - [[Arxiv](https://arxiv.org/abs/2209.12336)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.12336.md)]
- Probabilistic Planning with Partially Ordered Preferences over Temporal   Goals - [[Arxiv](https://arxiv.org/abs/2209.12267)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.12267.md)]
- All are Worth Words: A ViT Backbone for Diffusion Models - [[Arxiv](https://arxiv.org/abs/2209.12152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.12152.md)]
- Promptagator: Few-shot Dense Retrieval From 8 Examples - [[Arxiv](https://arxiv.org/abs/2209.11755)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.11755.md)]
- Control Barrier Functions in UGVs for Kinematic Obstacle Avoidance: A   Collision Cone Approach - [[Arxiv](https://arxiv.org/abs/2209.11524)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.11524.md)]
- ProgPrompt: Generating Situated Robot Task Plans using Large Language   Models - [[Arxiv](https://arxiv.org/abs/2209.11302)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.11302.md)]
- Pretraining the Vision Transformer using self-supervised methods for   vision based Deep Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2209.10901)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.10901.md)]
- Generate rather than Retrieve: Large Language Models are Strong Context   Generators - [[Arxiv](https://arxiv.org/abs/2209.10063)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.10063.md)]
- Target-Guided Open-Domain Conversation Planning - [[Arxiv](https://arxiv.org/abs/2209.09746)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.09746.md)]
- Learn to Explain: Multimodal Reasoning via Thought Chains for Science   Question Answering - [[Arxiv](https://arxiv.org/abs/2209.09513)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.09513.md)]
- Hierarchical Temporal Transformer for 3D Hand Pose Estimation and Action   Recognition from Egocentric RGB Videos - [[Arxiv](https://arxiv.org/abs/2209.09484)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.09484.md)]
- Space-time tradeoffs of lenses and optics via higher category theory - [[Arxiv](https://arxiv.org/abs/2209.09351)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.09351.md)]
- Audio-Visual Fusion for Emotion Recognition in the Valence-Arousal Space   Using Joint Cross-Attention - [[Arxiv](https://arxiv.org/abs/2209.09068)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.09068.md)]
- Loc-NeRF: Monte Carlo Localization using Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2209.09050)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.09050.md)]
- Learning Symbolic Model-Agnostic Loss Functions via Meta-Learning - [[Arxiv](https://arxiv.org/abs/2209.08907)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.08907.md)]
- Semantic Segmentation using Neural Ordinary Differential Equations - [[Arxiv](https://arxiv.org/abs/2209.08667)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.08667.md)]
- A Benchmark for Understanding and Generating Dialogue between Characters   in Stories - [[Arxiv](https://arxiv.org/abs/2209.08524)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.08524.md)]
- Revisiting Rolling Shutter Bundle Adjustment: Toward Accurate and Fast   Solution - [[Arxiv](https://arxiv.org/abs/2209.08503)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.08503.md)]
- Psychologically-informed chain-of-thought prompts for metaphor   understanding in large language models - [[Arxiv](https://arxiv.org/abs/2209.08141)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.08141.md)]
- CurveFormer: 3D Lane Detection by Curve Propagation with Curve Queries   and Attention - [[Arxiv](https://arxiv.org/abs/2209.07989)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.07989.md)]
- Spatial-then-Temporal Self-Supervised Learning for Video Correspondence - [[Arxiv](https://arxiv.org/abs/2209.07778)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.07778.md)]
- Test-Time Training with Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2209.07522)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.07522.md)]
- Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language   Models - [[Arxiv](https://arxiv.org/abs/2209.07511)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.07511.md)]
- A Geometric Perspective on Variational Autoencoders - [[Arxiv](https://arxiv.org/abs/2209.07370v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.07370v2.md)]
- A Geometric Perspective on Variational Autoencoders - [[Arxiv](https://arxiv.org/abs/2209.07370)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.07370.md)]
- A Geometric Perspective on Variational Autoencoders - [[Arxiv](https://arxiv.org/abs/2209.07370)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.07370.md)]
- Not As Easy As You Think -- Experiences and Lessons Learnt from Trying   to Create a Bottom-Up Visualization Image Typology - [[Arxiv](https://arxiv.org/abs/2209.07533)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.07533.md)]
- PaLI: A Jointly-Scaled Multilingual Language-Image Model - [[Arxiv](https://arxiv.org/abs/2209.06794)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.06794.md)]
- Certified Robustness to Word Substitution Ranking Attack for Neural   Ranking Models - [[Arxiv](https://arxiv.org/abs/2209.06691)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.06691.md)]
- Order-Disorder: Imitation Adversarial Attacks for Black-box Neural   Ranking Models - [[Arxiv](https://arxiv.org/abs/2209.06506)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.06506.md)]
- Hard Negatives or False Negatives: Correcting Pooling Bias in Training   Neural Ranking Models - [[Arxiv](https://arxiv.org/abs/2209.05072)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.05072.md)]
- Chain of Explanation: New Prompting Method to Generate Higher Quality   Natural Language Explanation for Implicit Hate Speech - [[Arxiv](https://arxiv.org/abs/2209.04889)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.04889.md)]
- Exploring Target Representations for Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2209.03917)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.03917.md)]
- Developing a multi-variate prediction model for the detection of   COVID-19 from Crowd-sourced Respiratory Voice Data - [[Arxiv](https://arxiv.org/abs/2209.03727)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.03727.md)]
- Enhancing the Self-Universality for Transferable Targeted Attacks - [[Arxiv](https://arxiv.org/abs/2209.03716)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.03716.md)]
- What does a platypus look like? Generating customized prompts for   zero-shot image classification - [[Arxiv](https://arxiv.org/abs/2209.03320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.03320.md)]
- MimCo: Masked Image Modeling Pre-training with Contrastive Teacher - [[Arxiv](https://arxiv.org/abs/2209.03063)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.03063.md)]
- EnergonAI: An Inference System for 10-100 Billion Parameter Transformer   Models - [[Arxiv](https://arxiv.org/abs/2209.02341)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.02341.md)]
- Selective Annotation Makes Language Models Better Few-Shot Learners - [[Arxiv](https://arxiv.org/abs/2209.01975)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.01975.md)]
- RLIP: Relational Language-Image Pre-training for Human-Object   Interaction Detection - [[Arxiv](https://arxiv.org/abs/2209.01814)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.01814.md)]
- An Empirical Study of End-to-End Video-Language Transformers with Masked   Visual Modeling - [[Arxiv](https://arxiv.org/abs/2209.01540)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.01540.md)]
- TogetherNet: Bridging Image Restoration and Object Detection Together   via Dynamic Enhancement Learning - [[Arxiv](https://arxiv.org/abs/2209.01373)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.01373.md)]
- Synthesizing Photorealistic Virtual Humans Through Cross-modal   Disentanglement - [[Arxiv](https://arxiv.org/abs/2209.01320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.01320.md)]
- Petals: Collaborative Inference and Fine-tuning of Large Models - [[Arxiv](https://arxiv.org/abs/2209.01188)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.01188.md)]
- Visual Prompting via Image Inpainting - [[Arxiv](https://arxiv.org/abs/2209.00647)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.00647.md)]
- FLAME: Free-form Language-based Motion Synthesis &amp; Editing - [[Arxiv](https://arxiv.org/abs/2209.00349)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.00349.md)]

### August 2022
- LANIT: Language-Driven Image-to-Image Translation for Unlabeled Data - [[Arxiv](https://arxiv.org/abs/2208.14889)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.14889.md)]
- Rethinking Conversational Recommendations: Is Decision Tree All You   Need? - [[Arxiv](https://arxiv.org/abs/2208.14614)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.14614.md)]
- Faithful Reasoning Using Large Language Models - [[Arxiv](https://arxiv.org/abs/2208.14271)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.14271.md)]
- Benchmark Results for Bookshelf Organization Problem as Mixed Integer   Nonlinear Program with Mode Switch and Collision Avoidance - [[Arxiv](https://arxiv.org/abs/2208.13158)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.13158.md)]
- TrojViT: Trojan Insertion in Vision Transformers - [[Arxiv](https://arxiv.org/abs/2208.13049)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.13049.md)]
- Multi-Outputs Is All You Need For Deblur - [[Arxiv](https://arxiv.org/abs/2208.13029)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.13029.md)]
- MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image   Pretraining - [[Arxiv](https://arxiv.org/abs/2208.12262)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.12262.md)]
- Masked Autoencoders Enable Efficient Knowledge Distillers - [[Arxiv](https://arxiv.org/abs/2208.12256)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.12256.md)]
- DreamBooth: Fine Tuning Text-to-Image Diffusion Models for   Subject-Driven Generation - [[Arxiv](https://arxiv.org/abs/2208.12242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.12242.md)]
- Understanding Diffusion Models: A Unified Perspective - [[Arxiv](https://arxiv.org/abs/2208.11970)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.11970.md)]
- Towards Efficient Use of Multi-Scale Features in Transformer-Based   Object Detectors - [[Arxiv](https://arxiv.org/abs/2208.11356)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.11356.md)]
- Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors,   and Lessons Learned - [[Arxiv](https://arxiv.org/abs/2209.07858)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2209.07858.md)]
- Improving Personality Consistency in Conversation by Persona Extending - [[Arxiv](https://arxiv.org/abs/2208.10816)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.10816.md)]
- Extending nnU-Net is all you need - [[Arxiv](https://arxiv.org/abs/2208.10791)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.10791.md)]
- Hierarchically Decomposed Graph Convolutional Networks for   Skeleton-Based Action Recognition - [[Arxiv](https://arxiv.org/abs/2208.10741)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.10741.md)]
- Image as a Foreign Language: BEiT Pretraining for All Vision and   Vision-Language Tasks - [[Arxiv](https://arxiv.org/abs/2208.10442)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.10442.md)]
- Are disentangled representations all you need to build speaker   anonymization systems? - [[Arxiv](https://arxiv.org/abs/2208.10497)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.10497.md)]
- Scattered or Connected? An Optimized Parameter-efficient Tuning Approach   for Information Retrieval - [[Arxiv](https://arxiv.org/abs/2208.09847)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.09847.md)]
- A Contrastive Pre-training Approach to Learn Discriminative Autoencoder   for Dense Retrieval - [[Arxiv](https://arxiv.org/abs/2208.09846)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.09846.md)]
- Label-Noise Learning with Intrinsically Long-Tailed Data - [[Arxiv](https://arxiv.org/abs/2208.09833)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.09833.md)]
- DenseShift: Towards Accurate and Efficient Low-Bit Power-of-Two   Quantization - [[Arxiv](https://arxiv.org/abs/2208.09708)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.09708.md)]
- SAFARI: Versatile and Efficient Evaluations for Robustness of   Interpretability - [[Arxiv](https://arxiv.org/abs/2208.09418)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.09418.md)]
- Pseudo-Labels Are All You Need - [[Arxiv](https://arxiv.org/abs/2208.09243)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.09243.md)]
- CASE: Aligning Coarse-to-Fine Cognition and Affection for Empathetic   Response Generation - [[Arxiv](https://arxiv.org/abs/2208.08845)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.08845.md)]
- Differentiable Architecture Search with Random Features - [[Arxiv](https://arxiv.org/abs/2208.08835)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.08835.md)]
- GraVoS: Voxel Selection for 3D Point-Cloud Detection - [[Arxiv](https://arxiv.org/abs/2208.08780)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.08780.md)]
- Towards Open-vocabulary Scene Graph Generation with Prompt-based   Finetuning - [[Arxiv](https://arxiv.org/abs/2208.08165)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.08165.md)]
- Significance of Skeleton-based Features in Virtual Try-On - [[Arxiv](https://arxiv.org/abs/2208.08076)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.08076.md)]
- CorpusBrain: Pre-train a Generative Retrieval Model for   Knowledge-Intensive Language Tasks - [[Arxiv](https://arxiv.org/abs/2208.07652)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.07652.md)]
- Semi-Supervised Video Inpainting with Cycle Consistency Constraints - [[Arxiv](https://arxiv.org/abs/2208.06807)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.06807.md)]
- Long-Short History of Gradients is All You Need: Detecting Malicious and   Unreliable Clients in Federated Learning - [[Arxiv](https://arxiv.org/abs/2208.10273)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.10273.md)]
- Dropout is NOT All You Need to Prevent Gradient Leakage - [[Arxiv](https://arxiv.org/abs/2208.06163)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.06163.md)]
- MILAN: Masked Image Pretraining on Language Assisted Representation - [[Arxiv](https://arxiv.org/abs/2208.06049)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.06049.md)]
- PSUMNet: Unified Modality Part Streams are All You Need for Efficient   Pose-based Action Recognition - [[Arxiv](https://arxiv.org/abs/2208.05775)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.05775.md)]
- Assessing the Unitary RNN as an End-to-End Compositional Model of Syntax - [[Arxiv](https://arxiv.org/abs/2208.05719)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.05719.md)]
- Safety and Performance, Why not Both? Bi-Objective Optimized Model   Compression toward AI Software Deployment - [[Arxiv](https://arxiv.org/abs/2208.05969)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.05969.md)]
- Generative Action Description Prompts for Skeleton-based Action   Recognition - [[Arxiv](https://arxiv.org/abs/2208.05318)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.05318.md)]
- Understanding Masked Image Modeling via Learning Occlusion Invariant   Feature - [[Arxiv](https://arxiv.org/abs/2208.04164)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.04164.md)]
- Follow Me: Conversation Planning for Target-driven Recommendation   Dialogue Systems - [[Arxiv](https://arxiv.org/abs/2208.03516)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.03516.md)]
- Atlas: Few-shot Learning with Retrieval Augmented Language Models - [[Arxiv](https://arxiv.org/abs/2208.03299)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.03299.md)]
- BlenderBot 3: a deployed conversational agent that continually learns to   responsibly engage - [[Arxiv](https://arxiv.org/abs/2208.03188)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.03188.md)]
- PointConvFormer: Revenge of the Point-based Convolution - [[Arxiv](https://arxiv.org/abs/2208.02879)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.02879.md)]
- DropKey - [[Arxiv](https://arxiv.org/abs/2208.02646)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.02646.md)]
- Prompt Tuning for Generative Multimodal Pretrained Models - [[Arxiv](https://arxiv.org/abs/2208.02532)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.02532.md)]
- Masked Vision and Language Modeling for Multi-modal Representation   Learning - [[Arxiv](https://arxiv.org/abs/2208.02131)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.02131.md)]
- Detecting Multivariate Time Series Anomalies with Zero Known Label - [[Arxiv](https://arxiv.org/abs/2208.02108)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.02108.md)]
- Character Generation through Self-Supervised Vectorization - [[Arxiv](https://arxiv.org/abs/2208.02012)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.02012.md)]
- Character Generation through Self-Supervised Vectorization - [[Arxiv](https://arxiv.org/abs/2208.02012v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.02012v1.md)]
- Prompt-to-Prompt Image Editing with Cross Attention Control - [[Arxiv](https://arxiv.org/abs/2208.01626)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.01626.md)]
- An Image is Worth One Word: Personalizing Text-to-Image Generation using   Textual Inversion - [[Arxiv](https://arxiv.org/abs/2208.01618)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.01618.md)]
- ViP3D: End-to-end Visual Trajectory Prediction via 3D Agent Queries - [[Arxiv](https://arxiv.org/abs/2208.01582)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.01582.md)]
- Reduction Rules and ILP Are All You Need: Minimal Directed Feedback   Vertex Set - [[Arxiv](https://arxiv.org/abs/2208.01119)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.01119.md)]
- OmniCity: Omnipotent City Understanding with Multi-level and Multi-view   Images - [[Arxiv](https://arxiv.org/abs/2208.00928)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.00928.md)]
- Neural network layers as parametric spans - [[Arxiv](https://arxiv.org/abs/2208.00809)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.00809.md)]
- Generative Bias for Robust Visual Question Answering - [[Arxiv](https://arxiv.org/abs/2208.00690)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.00690.md)]
- Composable Text Controls in Latent Space with ODEs - [[Arxiv](https://arxiv.org/abs/2208.00638)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.00638.md)]
- Search for or Navigate to? Dual Adaptive Thinking for Object Navigation - [[Arxiv](https://arxiv.org/abs/2208.00553)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.00553.md)]

### July 2022
- SdAE: Self-distillated Masked Autoencoder - [[Arxiv](https://arxiv.org/abs/2208.00449)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.00449.md)]
- Less is More: Consistent Video Depth Estimation with Masked Frames   Modeling - [[Arxiv](https://arxiv.org/abs/2208.00380)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.00380.md)]
- MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient   Neural Field Rendering on Mobile Architectures - [[Arxiv](https://arxiv.org/abs/2208.00277)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.00277.md)]
- A Survey on Masked Autoencoder for Self-supervised Learning in Vision   and Beyond - [[Arxiv](https://arxiv.org/abs/2208.00173)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.00173.md)]
- Language Models Can Teach Themselves to Program Better - [[Arxiv](https://arxiv.org/abs/2207.14502)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.14502.md)]
- Visual Recognition by Request - [[Arxiv](https://arxiv.org/abs/2207.14227)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.14227.md)]
- Contrastive Masked Autoencoders are Stronger Vision Learners - [[Arxiv](https://arxiv.org/abs/2207.13532)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.13532.md)]
- Group DETR: Fast DETR Training with Group-Wise One-to-Many Assignment - [[Arxiv](https://arxiv.org/abs/2207.13085)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.13085.md)]
- DETRs with Hybrid Matching - [[Arxiv](https://arxiv.org/abs/2207.13080)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.13080.md)]
- Visual correspondence-based explanations improve AI robustness and   human-AI team accuracy - [[Arxiv](https://arxiv.org/abs/2208.00780)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.00780.md)]
- Dynamic Planning in Open-Ended Dialogue using Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2208.02294)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2208.02294.md)]
- Is GPT-3 all you need for Visual Question Answering in Cultural   Heritage? - [[Arxiv](https://arxiv.org/abs/2207.12101)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.12101.md)]
- Neural Generation Meets Real People: Building a Social, Informative   Open-Domain Dialogue Agent - [[Arxiv](https://arxiv.org/abs/2207.12021)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.12021.md)]
- All you need for horizontal slicing in 5G network - [[Arxiv](https://arxiv.org/abs/2207.11477)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.11477.md)]
- Divide and Conquer: 3D Point Cloud Instance Segmentation With Point-Wise   Binarization - [[Arxiv](https://arxiv.org/abs/2207.11209)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.11209.md)]
- Adaptive Soft Contrastive Learning - [[Arxiv](https://arxiv.org/abs/2207.11163)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.11163.md)]
- Omni3D: A Large Benchmark and Model for 3D Object Detection in the Wild - [[Arxiv](https://arxiv.org/abs/2207.10660)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.10660.md)]
- Language Model Cascades - [[Arxiv](https://arxiv.org/abs/2207.10342)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.10342.md)]
- Tailoring Self-Supervision for Supervised Learning - [[Arxiv](https://arxiv.org/abs/2207.10023)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.10023.md)]
- GRIT: Faster and Better Image captioning Transformer Using Dual Visual   Features - [[Arxiv](https://arxiv.org/abs/2207.09666)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.09666.md)]
- FedDM: Iterative Distribution Matching for Communication-Efficient   Federated Learning - [[Arxiv](https://arxiv.org/abs/2207.09653)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.09653.md)]
- Overlooked factors in concept-based explanations: Dataset choice,   concept learnability, and human capability - [[Arxiv](https://arxiv.org/abs/2207.09615)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.09615.md)]
- Geometric Features Informed Multi-person Human-object Interaction   Recognition in Videos - [[Arxiv](https://arxiv.org/abs/2207.09425)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.09425.md)]
- Consistent Query Answering for Expressive Constraints under   Tuple-Deletion Semantics - [[Arxiv](https://arxiv.org/abs/2207.09198)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.09198.md)]
- FedX: Unsupervised Federated Learning with Cross Knowledge Distillation - [[Arxiv](https://arxiv.org/abs/2207.09158)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.09158.md)]
- Label2Label: A Language Modeling Framework for Multi-Attribute Learning - [[Arxiv](https://arxiv.org/abs/2207.08677)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.08677.md)]
- Class-incremental Novel Class Discovery - [[Arxiv](https://arxiv.org/abs/2207.08605)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.08605.md)]
- UniFusion: Unified Multi-view Fusion Transformer for Spatial-Temporal   Representation in Bird's-Eye-View - [[Arxiv](https://arxiv.org/abs/2207.08536)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.08536.md)]
- Open-world Semantic Segmentation via Contrasting and Clustering   Vision-Language Embedding - [[Arxiv](https://arxiv.org/abs/2207.08455)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.08455.md)]
- Adaptive Assignment for Geometry Aware Local Feature Matching - [[Arxiv](https://arxiv.org/abs/2207.08427)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.08427.md)]
- SatMAE: Pre-training Transformers for Temporal and Multi-Spectral   Satellite Imagery - [[Arxiv](https://arxiv.org/abs/2207.08051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.08051.md)]
- Knowledge Guided Bidirectional Attention Network for Human-Object   Interaction Detection - [[Arxiv](https://arxiv.org/abs/2207.07979)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.07979.md)]
- Clover: Towards A Unified Video-Language Alignment and Fusion Model - [[Arxiv](https://arxiv.org/abs/2207.07885)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.07885.md)]
- Position Prediction as an Effective Pretraining Strategy - [[Arxiv](https://arxiv.org/abs/2207.07611)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.07611.md)]
- Bootstrapped Masked Autoencoders for Vision BERT Pretraining - [[Arxiv](https://arxiv.org/abs/2207.07116)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.07116.md)]
- Language models show human-like content effects on reasoning - [[Arxiv](https://arxiv.org/abs/2207.07051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.07051.md)]
- Masked Autoencoders that Listen - [[Arxiv](https://arxiv.org/abs/2207.06405)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.06405.md)]
- PointNorm: Dual Normalization is All You Need for Point Cloud Analysis - [[Arxiv](https://arxiv.org/abs/2207.06324)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.06324.md)]
- Look-ups are not (yet) all you need for deep learning inference - [[Arxiv](https://arxiv.org/abs/2207.05808)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.05808.md)]
- A Data-Based Perspective on Transfer Learning - [[Arxiv](https://arxiv.org/abs/2207.05739)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.05739.md)]
- Inner Monologue: Embodied Reasoning through Planning with Language   Models - [[Arxiv](https://arxiv.org/abs/2207.05608)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.05608.md)]
- Towards Hard-Positive Query Mining for DETR-based Human-Object   Interaction Detection - [[Arxiv](https://arxiv.org/abs/2207.05293)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.05293.md)]
- Bootstrapping a User-Centered Task-Oriented Dialogue System - [[Arxiv](https://arxiv.org/abs/2207.05223)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.05223.md)]
- A Skeleton-aware Graph Convolutional Network for Human-Object   Interaction Detection - [[Arxiv](https://arxiv.org/abs/2207.05733)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.05733.md)]
- LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language,   Vision, and Action - [[Arxiv](https://arxiv.org/abs/2207.04429)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.04429.md)]
- Training Transformers Together - [[Arxiv](https://arxiv.org/abs/2207.03481)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.03481.md)]
- Back to the Source: Diffusion-Driven Test-Time Adaptation - [[Arxiv](https://arxiv.org/abs/2207.03442)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.03442.md)]
- YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for   real-time object detectors - [[Arxiv](https://arxiv.org/abs/2207.02696)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.02696.md)]
- Chairs Can be Stood on: Overcoming Object Bias in Human-Object   Interaction Detection - [[Arxiv](https://arxiv.org/abs/2207.02400)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.02400.md)]
- Is a PET all you need? A multi-modal study for Alzheimer's disease using   3D CNNs - [[Arxiv](https://arxiv.org/abs/2207.02094)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.02094.md)]
- Best Subset Selection with Efficient Primal-Dual Algorithm - [[Arxiv](https://arxiv.org/abs/2207.02058)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.02058.md)]
- Distance Matters in Human-Object Interaction Detection - [[Arxiv](https://arxiv.org/abs/2207.01869)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.01869.md)]
- Domain-Independent Deception: Definition, Taxonomy and the Linguistic   Cues Debate - [[Arxiv](https://arxiv.org/abs/2207.01738)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.01738.md)]
- Beyond mAP: Towards better evaluation of instance segmentation - [[Arxiv](https://arxiv.org/abs/2207.01614)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.01614.md)]
- PVO: Panoptic Visual Odometry - [[Arxiv](https://arxiv.org/abs/2207.01610)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.01610.md)]
- Explicit Boundary Guided Semi-Push-Pull Contrastive Learning for   Supervised Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2207.01463)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.01463.md)]
- I-ViT: Integer-only Quantization for Efficient Vision Transformer   Inference - [[Arxiv](https://arxiv.org/abs/2207.01405)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.01405.md)]
- WebShop: Towards Scalable Real-World Web Interaction with Grounded   Language Agents - [[Arxiv](https://arxiv.org/abs/2207.01206)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.01206.md)]
- Towards Robust Referring Video Object Segmentation with Cyclic   Relational Consensus - [[Arxiv](https://arxiv.org/abs/2207.01203)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.01203.md)]
- Computer-assisted Pronunciation Training -- Speech synthesis is almost   all you need - [[Arxiv](https://arxiv.org/abs/2207.00774)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.00774.md)]
- Rationale-Augmented Ensembles in Language Models - [[Arxiv](https://arxiv.org/abs/2207.00747)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.00747.md)]

### June 2022
- LaserMix for Semi-Supervised LiDAR Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2207.00026)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2207.00026.md)]
- On-Device Training Under 256KB Memory - [[Arxiv](https://arxiv.org/abs/2206.15472)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.15472.md)]
- Improving Visual Grounding by Encouraging Consistent Gradient-based   Explanations - [[Arxiv](https://arxiv.org/abs/2206.15462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.15462.md)]
- Automatically Balancing Model Accuracy and Complexity using Solution and   Fitness Evolution (SAFE) - [[Arxiv](https://arxiv.org/abs/2206.15409)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.15409.md)]
- UniDAformer: Unified Domain Adaptive Panoptic Segmentation Transformer   via Hierarchical Mask Calibration - [[Arxiv](https://arxiv.org/abs/2206.15083)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.15083.md)]
- Solving Quantitative Reasoning Problems with Language Models - [[Arxiv](https://arxiv.org/abs/2206.14858)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.14858.md)]
- BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from   Pretrained Language Models - [[Arxiv](https://arxiv.org/abs/2206.14268)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.14268.md)]
- Solution and Fitness Evolution (SAFE): A Study of Multiobjective   Problems - [[Arxiv](https://arxiv.org/abs/2206.13509)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.13509.md)]
- Solution and Fitness Evolution (SAFE): Coevolving Solutions and Their   Objective Functions - [[Arxiv](https://arxiv.org/abs/2206.12707)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.12707.md)]
- CV 3315 Is All You Need : Semantic Segmentation Competition - [[Arxiv](https://arxiv.org/abs/2206.12571)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.12571.md)]
- ZSON: Zero-Shot Object-Goal Navigation using Multimodal Goal Embeddings - [[Arxiv](https://arxiv.org/abs/2206.12403)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.12403.md)]
- Diegetic Representation of Feedback in Open Games - [[Arxiv](https://arxiv.org/abs/2206.12338)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.12338.md)]
- Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive   Learning - [[Arxiv](https://arxiv.org/abs/2206.12126)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.12126.md)]
- zPROBE: Zero Peek Robustness Checks for Federated Learning - [[Arxiv](https://arxiv.org/abs/2206.12100)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.12100.md)]
- Task-Adaptive Few-shot Node Classification - [[Arxiv](https://arxiv.org/abs/2206.11972)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.11972.md)]
- EventNeRF: Neural Radiance Fields from a Single Colour Event Camera - [[Arxiv](https://arxiv.org/abs/2206.11896)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.11896.md)]
- MaskViT: Masked Visual Pre-Training for Video Prediction - [[Arxiv](https://arxiv.org/abs/2206.11894)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.11894.md)]
- Rethinking Surgical Instrument Segmentation: A Background Image Can Be   All You Need - [[Arxiv](https://arxiv.org/abs/2206.11804)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.11804.md)]
- CLAMP: Prompt-based Contrastive Learning for Connecting Language and   Animal Pose - [[Arxiv](https://arxiv.org/abs/2206.11752)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.11752.md)]
- Invariant Causal Mechanisms through Distribution Matching - [[Arxiv](https://arxiv.org/abs/2206.11646)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.11646.md)]
- Invariant Causal Mechanisms through Distribution Matching - [[Arxiv](https://arxiv.org/abs/2206.11646v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.11646v1.md)]
- GODEL: Large-Scale Pre-Training for Goal-Directed Dialog - [[Arxiv](https://arxiv.org/abs/2206.11309)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.11309.md)]
- KiloNeuS: A Versatile Neural Implicit Surface Representation for   Real-Time Rendering - [[Arxiv](https://arxiv.org/abs/2206.10885)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.10885.md)]
- Questions Are All You Need to Train a Dense Passage Retriever - [[Arxiv](https://arxiv.org/abs/2206.10658)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.10658.md)]
- LargeKernel3D: Scaling up Kernels in 3D Sparse CNNs - [[Arxiv](https://arxiv.org/abs/2206.10555)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.10555.md)]
- Marginal Tail-Adaptive Normalizing Flows - [[Arxiv](https://arxiv.org/abs/2206.10311v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.10311v2.md)]
- Marginal Tail-Adaptive Normalizing Flows - [[Arxiv](https://arxiv.org/abs/2206.10311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.10311.md)]
- SemMAE: Semantic-Guided Masking for Learning Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2206.10207)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.10207.md)]
- Occupancy-MAE: Self-supervised Pre-training Large-scale LiDAR Point   Clouds with Masked Occupancy Autoencoders - [[Arxiv](https://arxiv.org/abs/2206.09900)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.09900.md)]
- DualCoOp: Fast Adaptation to Multi-Label Recognition with Limited   Annotations - [[Arxiv](https://arxiv.org/abs/2206.09541)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.09541.md)]
- All you need is feedback: Communication with block attention feedback   codes - [[Arxiv](https://arxiv.org/abs/2206.09457)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.09457.md)]
- Gender Artifacts in Visual Datasets - [[Arxiv](https://arxiv.org/abs/2206.09191)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.09191.md)]
- Landscape Learning for Neural Network Inversion - [[Arxiv](https://arxiv.org/abs/2206.09027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.09027.md)]
- MineDojo: Building Open-Ended Embodied Agents with Internet-Scale   Knowledge - [[Arxiv](https://arxiv.org/abs/2206.08853)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.08853.md)]
- Sheaf Neural Networks with Connection Laplacians - [[Arxiv](https://arxiv.org/abs/2206.08702)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.08702.md)]
- PRANC: Pseudo RAndom Networks for Compacting deep models - [[Arxiv](https://arxiv.org/abs/2206.08464)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.08464.md)]
- OmniMAE: Single Model Masked Pretraining on Images and Videos - [[Arxiv](https://arxiv.org/abs/2206.08356)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.08356.md)]
- Switchable Representation Learning Framework with Self-compatibility - [[Arxiv](https://arxiv.org/abs/2206.08289)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.08289.md)]
- Zero-Shot Video Question Answering via Frozen Bidirectional Language   Models - [[Arxiv](https://arxiv.org/abs/2206.08155)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.08155.md)]
- Balancing Discriminability and Transferability for Source-Free Domain   Adaptation - [[Arxiv](https://arxiv.org/abs/2206.08009)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.08009.md)]
- Architectural Backdoors in Neural Networks - [[Arxiv](https://arxiv.org/abs/2206.07840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.07840.md)]
- Masked Frequency Modeling for Self-Supervised Visual Pre-Training - [[Arxiv](https://arxiv.org/abs/2206.07706)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.07706.md)]
- Masked Siamese ConvNets - [[Arxiv](https://arxiv.org/abs/2206.07700)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.07700.md)]
- Structured Sparsity Learning for Efficient Video Super-Resolution - [[Arxiv](https://arxiv.org/abs/2206.07687)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.07687.md)]
- Emergent Abilities of Large Language Models - [[Arxiv](https://arxiv.org/abs/2206.07682)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.07682.md)]
- A smile is all you need: Predicting limiting activity coefficients from   SMILES with natural language processing - [[Arxiv](https://arxiv.org/abs/2206.07048)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.07048.md)]
- GRAM-HD: 3D-Consistent Image Generation at High Resolution with   Generative Radiance Manifolds - [[Arxiv](https://arxiv.org/abs/2206.07255)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.07255.md)]
- Proximal Splitting Adversarial Attacks for Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2206.07179)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.07179.md)]
- LAVENDER: Unifying Video-Language Understanding as Masked Language   Modeling - [[Arxiv](https://arxiv.org/abs/2206.07160)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.07160.md)]
- Confidence Score for Source-Free Unsupervised Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2206.06640)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.06640.md)]
- Confidence Score for Source-Free Unsupervised Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2206.06640)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.06640.md)]
- Transformers are Meta-Reinforcement Learners - [[Arxiv](https://arxiv.org/abs/2206.06614v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.06614v1.md)]
- Transformers are Meta-Reinforcement Learners - [[Arxiv](https://arxiv.org/abs/2206.06614)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.06614.md)]
- Look, Radiate, and Learn: Self-Supervised Localisation via Radio-Visual   Correspondence - [[Arxiv](https://arxiv.org/abs/2206.06424)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.06424.md)]
- Language Models are General-Purpose Interfaces - [[Arxiv](https://arxiv.org/abs/2206.06336)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.06336.md)]
- Mining Multi-Label Samples from Single Positive Labels - [[Arxiv](https://arxiv.org/abs/2206.05764v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.05764v4.md)]
- Mining Multi-Label Samples from Single Positive Labels - [[Arxiv](https://arxiv.org/abs/2206.05764)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.05764.md)]
- Building a Personalized Dialogue System with Prompt-Tuning - [[Arxiv](https://arxiv.org/abs/2206.05399)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.05399.md)]
- Balanced Product of Calibrated Experts for Long-Tailed Recognition - [[Arxiv](https://arxiv.org/abs/2206.05260)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.05260.md)]
- Referring Image Matting - [[Arxiv](https://arxiv.org/abs/2206.05149)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.05149.md)]
- Masked Autoencoders are Robust Data Augmentors - [[Arxiv](https://arxiv.org/abs/2206.04846)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.04846.md)]
- Neural Prompt Search - [[Arxiv](https://arxiv.org/abs/2206.04673)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.04673.md)]
- Extreme Masking for Learning Instance and Distributed Visual   Representations - [[Arxiv](https://arxiv.org/abs/2206.04667)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.04667.md)]
- On Data Scaling in Masked Image Modeling - [[Arxiv](https://arxiv.org/abs/2206.04664)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.04664.md)]
- Simple Cues Lead to a Strong Multi-Object Tracker - [[Arxiv](https://arxiv.org/abs/2206.04656)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.04656.md)]
- Beyond the Imitation Game: Quantifying and extrapolating the   capabilities of language models - [[Arxiv](https://arxiv.org/abs/2206.04615)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.04615.md)]
- Spatial-temporal Concept based Explanation of 3D ConvNets - [[Arxiv](https://arxiv.org/abs/2206.05275)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.05275.md)]
- Words are all you need? Language as an approximation for human   similarity judgments - [[Arxiv](https://arxiv.org/abs/2206.04105)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.04105.md)]
- MobileOne: An Improved One millisecond Mobile Backbone - [[Arxiv](https://arxiv.org/abs/2206.04040)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.04040.md)]
- MobileOne: An Improved One millisecond Mobile Backbone - [[Arxiv](https://arxiv.org/abs/2206.04040)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.04040.md)]
- Towards Understanding Why Mask-Reconstruction Pretraining Helps in   Downstream Tasks - [[Arxiv](https://arxiv.org/abs/2206.03826)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.03826.md)]
- Detection Hub: Unifying Object Detection Datasets via Query Adaptation   on Language Embedding - [[Arxiv](https://arxiv.org/abs/2206.03484)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.03484.md)]
- Unsupervised Context Aware Sentence Representation Pretraining for   Multi-lingual Dense Retrieval - [[Arxiv](https://arxiv.org/abs/2206.03281)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.03281.md)]
- Spatial Parsing and Dynamic Temporal Pooling networks for Human-Object   Interaction detection - [[Arxiv](https://arxiv.org/abs/2206.03061)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.03061.md)]
- TriBYOL: Triplet BYOL for Self-Supervised Representation Learning - [[Arxiv](https://arxiv.org/abs/2206.03012)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.03012.md)]
- Self-Knowledge Distillation based Self-Supervised Learning for Covid-19   Detection from Chest X-Ray Images - [[Arxiv](https://arxiv.org/abs/2206.03009)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.03009.md)]
- Self-supervised Learning for Human Activity Recognition Using 700,000   Person-days of Wearable Data - [[Arxiv](https://arxiv.org/abs/2206.02909)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.02909.md)]
- Mask DINO: Towards A Unified Transformer-based Framework for Object   Detection and Segmentation - [[Arxiv](https://arxiv.org/abs/2206.02777)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.02777.md)]
- A Neural Corpus Indexer for Document Retrieval - [[Arxiv](https://arxiv.org/abs/2206.02743)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.02743.md)]
- Revisiting Realistic Test-Time Training: Sequential Inference and   Adaptation by Anchored Clustering - [[Arxiv](https://arxiv.org/abs/2206.02721)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.02721.md)]
- Is More Data All You Need? A Causal Exploration - [[Arxiv](https://arxiv.org/abs/2206.02409)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.02409.md)]
- Learning to Break the Loop: Analyzing and Mitigating Repetitions for   Neural Text Generation - [[Arxiv](https://arxiv.org/abs/2206.02369)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.02369.md)]
- Making Large Language Models Better Reasoners with Step-Aware Verifier - [[Arxiv](https://arxiv.org/abs/2206.02336)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.02336.md)]
- PIDNet: A Real-time Semantic Segmentation Network Inspired by PID   Controllers - [[Arxiv](https://arxiv.org/abs/2206.02066)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.02066.md)]
- Delving into the Openness of CLIP - [[Arxiv](https://arxiv.org/abs/2206.01986)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01986.md)]
- Video-based Human-Object Interaction Detection from Tubelet Tokens - [[Arxiv](https://arxiv.org/abs/2206.01908)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01908.md)]
- Revisiting the "Video" in Video-Language Understanding - [[Arxiv](https://arxiv.org/abs/2206.01720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01720.md)]
- PROMISSING: Pruning Missing Values in Neural Networks - [[Arxiv](https://arxiv.org/abs/2206.01640)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01640.md)]
- PROMISSING: Pruning Missing Values in Neural Networks - [[Arxiv](https://arxiv.org/abs/2206.01640v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01640v1.md)]
- PROMISSING: Pruning Missing Values in Neural Networks - [[Arxiv](https://arxiv.org/abs/2206.01640)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01640.md)]
- A Survey on Computationally Efficient Neural Architecture Search - [[Arxiv](https://arxiv.org/abs/2206.01520)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01520.md)]
- Learning Probabilistic Topological Representations Using Discrete Morse   Theory - [[Arxiv](https://arxiv.org/abs/2206.01742)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01742.md)]
- MultiHiertt: Numerical Reasoning over Multi Hierarchical Tabular and   Textual Data - [[Arxiv](https://arxiv.org/abs/2206.01347)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01347.md)]
- PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images - [[Arxiv](https://arxiv.org/abs/2206.01256)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01256.md)]
- Siamese Image Modeling for Self-Supervised Vision Representation   Learning - [[Arxiv](https://arxiv.org/abs/2206.01204)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01204.md)]
- Multi-View Active Fine-Grained Recognition - [[Arxiv](https://arxiv.org/abs/2206.01153)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01153.md)]
- Prefix Conditioning Unifies Language and Label Supervision - [[Arxiv](https://arxiv.org/abs/2206.01125)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01125.md)]
- Unified Recurrence Modeling for Video Action Anticipation - [[Arxiv](https://arxiv.org/abs/2206.01009v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01009v1.md)]
- Unified Recurrence Modeling for Video Action Anticipation - [[Arxiv](https://arxiv.org/abs/2206.01009)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01009.md)]
- NIPQ: Noise proxy-based Integrated Pseudo-Quantization - [[Arxiv](https://arxiv.org/abs/2206.00820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.00820.md)]
- NIPQ: Noise proxy-based Integrated Pseudo-Quantization - [[Arxiv](https://arxiv.org/abs/2206.00820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.00820.md)]
- Efficient Self-supervised Vision Pretraining with Local Masked   Reconstruction - [[Arxiv](https://arxiv.org/abs/2206.00790)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.00790.md)]
- ORC: Network Group-based Knowledge Distillation using Online Role Change - [[Arxiv](https://arxiv.org/abs/2206.01186)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.01186.md)]
- MaskOCR: Text Recognition with Masked Encoder-Decoder Pretraining - [[Arxiv](https://arxiv.org/abs/2206.00311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.00311.md)]

### May 2022
- Evolving Domain Generalization - [[Arxiv](https://arxiv.org/abs/2206.00047)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2206.00047.md)]
- itKD: Interchange Transfer-based Knowledge Distillation for 3D Object   Detection - [[Arxiv](https://arxiv.org/abs/2205.15531)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.15531.md)]
- FeatER: An Efficient Network for Human Reconstruction via Feature   Map-Based TransformER - [[Arxiv](https://arxiv.org/abs/2205.15448)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.15448.md)]
- Non-Markovian Reward Modelling from Trajectory Labels via Interpretable   Multiple Instance Learning - [[Arxiv](https://arxiv.org/abs/2205.15367)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.15367.md)]
- Self-Supervised Visual Representation Learning with Semantic Grouping - [[Arxiv](https://arxiv.org/abs/2205.15288)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.15288.md)]
- GMML is All you Need - [[Arxiv](https://arxiv.org/abs/2205.14986)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14986.md)]
- Knowledge Distillation for 6D Pose Estimation by Aligning Distributions   of Local Predictions - [[Arxiv](https://arxiv.org/abs/2205.14971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14971.md)]
- HiViT: Hierarchical Vision Transformer Meets Masked Image Modeling - [[Arxiv](https://arxiv.org/abs/2205.14949)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14949.md)]
- FRAug: Tackling Federated Learning with Non-IID Features via   Representation Augmentation - [[Arxiv](https://arxiv.org/abs/2205.14900)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14900.md)]
- Robust Weight Perturbation for Adversarial Training - [[Arxiv](https://arxiv.org/abs/2205.14826)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14826.md)]
- Robust Weight Perturbation for Adversarial Training - [[Arxiv](https://arxiv.org/abs/2205.14826v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14826v1.md)]
- EfficientViT: Multi-Scale Linear Attention for High-Resolution Dense   Prediction - [[Arxiv](https://arxiv.org/abs/2205.14756)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14756.md)]
- CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset   for Conversational AI - [[Arxiv](https://arxiv.org/abs/2205.14727)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14727.md)]
- CoNT: Contrastive Neural Text Generation - [[Arxiv](https://arxiv.org/abs/2205.14690)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14690.md)]
- Frustratingly Easy Regularization on Representation Can Boost Deep   Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2205.14557)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14557.md)]
- SupMAE: Supervised Masked Autoencoders Are Efficient Vision Learners - [[Arxiv](https://arxiv.org/abs/2205.14540)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14540.md)]
- Additive Higher-Order Factorization Machines - [[Arxiv](https://arxiv.org/abs/2205.14515)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14515.md)]
- A Closer Look at Self-Supervised Lightweight Vision Transformers - [[Arxiv](https://arxiv.org/abs/2205.14443)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14443.md)]
- Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud   Pre-training - [[Arxiv](https://arxiv.org/abs/2205.14401)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14401.md)]
- Object-wise Masked Autoencoders for Fast Pre-training - [[Arxiv](https://arxiv.org/abs/2205.14338)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14338.md)]
- Semi-supervised Semantics-guided Adversarial Training for Trajectory   Prediction - [[Arxiv](https://arxiv.org/abs/2205.14230)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14230.md)]
- Controllable Text Generation with Neurally-Decomposed Oracle - [[Arxiv](https://arxiv.org/abs/2205.14219)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14219.md)]
- Diffusion-LM Improves Controllable Text Generation - [[Arxiv](https://arxiv.org/abs/2205.14217)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14217.md)]
- Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via   Feature Distillation - [[Arxiv](https://arxiv.org/abs/2205.14141)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14141.md)]
- Bayesian Robust Graph Contrastive Learning - [[Arxiv](https://arxiv.org/abs/2205.14109)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14109.md)]
- GIT: A Generative Image-to-text Transformer for Vision and Language - [[Arxiv](https://arxiv.org/abs/2205.14100)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.14100.md)]
- Prototype Based Classification from Hierarchy to Fairness - [[Arxiv](https://arxiv.org/abs/2205.13997v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.13997v1.md)]
- Prototype Based Classification from Hierarchy to Fairness - [[Arxiv](https://arxiv.org/abs/2205.13997)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.13997.md)]
- Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN - [[Arxiv](https://arxiv.org/abs/2205.13943)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.13943.md)]
- Bongard-HOI: Benchmarking Few-Shot Visual Reasoning for Human-Object   Interactions - [[Arxiv](https://arxiv.org/abs/2205.13803)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.13803.md)]
- Quark: Controllable Text Generation with Reinforced Unlearning - [[Arxiv](https://arxiv.org/abs/2205.13636)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.13636.md)]
- Revealing the Dark Secrets of Masked Image Modeling - [[Arxiv](https://arxiv.org/abs/2205.13543)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.13543.md)]
- Green Hierarchical Vision Transformer for Masked Image Modeling - [[Arxiv](https://arxiv.org/abs/2205.13515)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.13515.md)]
- Physical-World Optical Adversarial Attacks on 3D Face Recognition - [[Arxiv](https://arxiv.org/abs/2205.13412)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.13412.md)]
- MixMAE: Mixed and Masked Autoencoder for Efficient Pretraining of   Hierarchical Vision Transformers - [[Arxiv](https://arxiv.org/abs/2205.13137)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.13137.md)]
- Pretraining is All You Need for Image-to-Image Translation - [[Arxiv](https://arxiv.org/abs/2205.12952)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.12952.md)]
- RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText   Generators - [[Arxiv](https://arxiv.org/abs/2205.12590)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.12590.md)]
- Masked Jigsaw Puzzle: A Versatile Position Embedding for Vision   Transformers - [[Arxiv](https://arxiv.org/abs/2205.12551)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.12551.md)]
- TALM: Tool Augmented Language Models - [[Arxiv](https://arxiv.org/abs/2205.12255)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.12255.md)]
- Large Language Models are Zero-Shot Reasoners - [[Arxiv](https://arxiv.org/abs/2205.11916)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.11916.md)]
- Maieutic Prompting: Logically Consistent Reasoning with Recursive   Explanations - [[Arxiv](https://arxiv.org/abs/2205.11822)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.11822.md)]
- Learning Context-Aware Service Representation for Service Recommendation   in Workflow Composition - [[Arxiv](https://arxiv.org/abs/2205.11771)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.11771.md)]
- Decoder Denoising Pretraining for Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2205.11423)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.11423.md)]
- PointDistiller: Structured Knowledge Distillation Towards Efficient and   Compact 3D Detection - [[Arxiv](https://arxiv.org/abs/2205.11098)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.11098.md)]
- FaceMAE: Privacy-Preserving Face Recognition via Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2205.11090)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.11090.md)]
- GraphMAE: Self-Supervised Masked Graph Autoencoders - [[Arxiv](https://arxiv.org/abs/2205.10803)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.10803.md)]
- All You Need Is Logs: Improving Code Completion by Learning from   Anonymous IDE Usage Logs - [[Arxiv](https://arxiv.org/abs/2205.10692)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.10692.md)]
- Swept-Angle Synthetic Wavelength Interferometry - [[Arxiv](https://arxiv.org/abs/2205.10655)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.10655.md)]
- Least-to-Most Prompting Enables Complex Reasoning in Large Language   Models - [[Arxiv](https://arxiv.org/abs/2205.10625)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.10625.md)]
- A Review of Safe Reinforcement Learning: Methods, Theory and   Applications - [[Arxiv](https://arxiv.org/abs/2205.10330)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.10330.md)]
- Adaptive Fairness-Aware Online Meta-Learning for Changing Environments - [[Arxiv](https://arxiv.org/abs/2205.11264)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.11264.md)]
- Sampling Is All You Need on Modeling Long-Term User Behaviors for CTR   Prediction - [[Arxiv](https://arxiv.org/abs/2205.10249)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.10249.md)]
- Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision   Transformers with Locality - [[Arxiv](https://arxiv.org/abs/2205.10063)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.10063.md)]
- Can Foundation Models Wrangle Your Data? - [[Arxiv](https://arxiv.org/abs/2205.09911)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.09911.md)]
- RankGen: Improving Text Generation with Large Ranking Models - [[Arxiv](https://arxiv.org/abs/2205.09726)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.09726.md)]
- Selection-Inference: Exploiting Large Language Models for Interpretable   Logical Reasoning - [[Arxiv](https://arxiv.org/abs/2205.09712)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.09712.md)]
- Masked Image Modeling with Denoising Contrast - [[Arxiv](https://arxiv.org/abs/2205.09616)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.09616.md)]
- Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual   Object Detection - [[Arxiv](https://arxiv.org/abs/2205.09613)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.09613.md)]
- Learning Graph Structure from Convolutional Mixtures - [[Arxiv](https://arxiv.org/abs/2205.09575)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.09575.md)]
- Learning Graph Structure from Convolutional Mixtures - [[Arxiv](https://arxiv.org/abs/2205.09575v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.09575v1.md)]
- Target-Guided Dialogue Response Generation Using Commonsense and Data   Augmentation - [[Arxiv](https://arxiv.org/abs/2205.09314)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.09314.md)]
- Masked Autoencoders As Spatiotemporal Learners - [[Arxiv](https://arxiv.org/abs/2205.09113)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.09113.md)]
- Global Contrast Masked Autoencoders Are Powerful Pathological   Representation Learners - [[Arxiv](https://arxiv.org/abs/2205.09048)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.09048.md)]
- Positional Information is All You Need: A Novel Pipeline for   Self-Supervised SVDE from Videos - [[Arxiv](https://arxiv.org/abs/2205.08851)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.08851.md)]
- Need is All You Need: Homeostatic Neural Networks Adapt to Concept Shift - [[Arxiv](https://arxiv.org/abs/2205.08645)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.08645.md)]
- A CLIP-Hitchhiker's Guide to Long Video Retrieval - [[Arxiv](https://arxiv.org/abs/2205.08508)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.08508.md)]
- Robust Losses for Learning Value Functions - [[Arxiv](https://arxiv.org/abs/2205.08464v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.08464v2.md)]
- Robust Losses for Learning Value Functions - [[Arxiv](https://arxiv.org/abs/2205.08464)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.08464.md)]
- LogicSolver: Towards Interpretable Math Word Problem Solving with   Logical Prompt-enhanced Learning - [[Arxiv](https://arxiv.org/abs/2205.08232)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.08232.md)]
- BBDM: Image-to-image Translation with Brownian Bridge Diffusion Models - [[Arxiv](https://arxiv.org/abs/2205.07680)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.07680.md)]
- Diffusion Models for Adversarial Purification - [[Arxiv](https://arxiv.org/abs/2205.07460)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.07460.md)]
- Long-term Control for Dialogue Generation: Methods and Evaluation - [[Arxiv](https://arxiv.org/abs/2205.07352)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.07352.md)]
- Aligning Robot Representations with Humans - [[Arxiv](https://arxiv.org/abs/2205.07882)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.07882.md)]
- A Generalist Agent - [[Arxiv](https://arxiv.org/abs/2205.06175)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.06175.md)]
- An Empirical Study Of Self-supervised Learning Approaches For Object   Detection With Transformers - [[Arxiv](https://arxiv.org/abs/2205.05543)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.05543.md)]
- Reduce Information Loss in Transformers for Pluralistic Image Inpainting - [[Arxiv](https://arxiv.org/abs/2205.05076)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.05076.md)]
- Learning to Answer Visual Questions from Web Videos - [[Arxiv](https://arxiv.org/abs/2205.05019)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.05019.md)]
- When does dough become a bagel? Analyzing the remaining mistakes on   ImageNet - [[Arxiv](https://arxiv.org/abs/2205.04596)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.04596.md)]
- A for-loop is all you need. For solving the inverse problem in the case   of personalized tumor growth modeling - [[Arxiv](https://arxiv.org/abs/2205.04550)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.04550.md)]
- Activating More Pixels in Image Super-Resolution Transformer - [[Arxiv](https://arxiv.org/abs/2205.04437)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.04437.md)]
- ConvMAE: Masked Convolution Meets Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2205.03892)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.03892.md)]
- Towards a Progression-Aware Autonomous Dialogue Agent - [[Arxiv](https://arxiv.org/abs/2205.03692)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.03692.md)]
- The Unreliability of Explanations in Few-shot Prompting for Textual   Reasoning - [[Arxiv](https://arxiv.org/abs/2205.03401)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.03401.md)]
- Spiking Graph Convolutional Networks - [[Arxiv](https://arxiv.org/abs/2205.02767v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.02767v2.md)]
- Spiking Graph Convolutional Networks - [[Arxiv](https://arxiv.org/abs/2205.02767)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.02767.md)]
- A Simple Contrastive Learning Objective for Alleviating Neural Text   Degeneration - [[Arxiv](https://arxiv.org/abs/2205.02517)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.02517.md)]
- Lexical Knowledge Internalization for Neural Dialog Generation - [[Arxiv](https://arxiv.org/abs/2205.01941)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.01941.md)]
- End2End Multi-View Feature Matching with Differentiable Pose   Optimization - [[Arxiv](https://arxiv.org/abs/2205.01694)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.01694.md)]
- Learning to Transfer Prompts for Text Generation - [[Arxiv](https://arxiv.org/abs/2205.01543)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.01543.md)]
- OPT: Open Pre-trained Transformer Language Models - [[Arxiv](https://arxiv.org/abs/2205.01068)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.01068.md)]

### April 2022
- Building a Role Specified Open-Domain Dialogue System Leveraging   Large-Scale Language Models - [[Arxiv](https://arxiv.org/abs/2205.00176)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.00176.md)]
- SVTR: Scene Text Recognition with a Single Visual Model - [[Arxiv](https://arxiv.org/abs/2205.00159)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2205.00159.md)]
- Flamingo: a Visual Language Model for Few-Shot Learning - [[Arxiv](https://arxiv.org/abs/2204.14198)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.14198.md)]
- ARCTIC: A Dataset for Dexterous Bimanual Hand-Object Manipulation - [[Arxiv](https://arxiv.org/abs/2204.13662)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.13662.md)]
- The Wisdom of Crowds: Temporal Progressive Attention for Early Action   Prediction - [[Arxiv](https://arxiv.org/abs/2204.13340)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.13340.md)]
- Power Bundle Adjustment for Large-Scale 3D Reconstruction - [[Arxiv](https://arxiv.org/abs/2204.12834)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.12834.md)]
- Masked Spectrogram Prediction For Self-Supervised Audio Pre-Training - [[Arxiv](https://arxiv.org/abs/2204.12768)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.12768.md)]
- Control Globally, Understand Locally: A Global-to-Local Hierarchical   Graph Network for Emotional Support Conversation - [[Arxiv](https://arxiv.org/abs/2204.12749)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.12749.md)]
- MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2204.12667)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.12667.md)]
- PolyLoss: A Polynomial Expansion Perspective of Classification Loss   Functions - [[Arxiv](https://arxiv.org/abs/2204.12511)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.12511.md)]
- MILES: Visual BERT Pre-training with Injected Language Semantics for   Video-text Retrieval - [[Arxiv](https://arxiv.org/abs/2204.12408)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.12408.md)]
- SceneTrilogy: On Human Scene-Sketch and its Complementarity with Photo   and Text - [[Arxiv](https://arxiv.org/abs/2204.11964)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.11964.md)]
- Masked Image Modeling Advances 3D Medical Image Analysis - [[Arxiv](https://arxiv.org/abs/2204.11716)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.11716.md)]
- LoL: A Comparative Regularization Loss over Query Reformulation Losses   for Pseudo-Relevance Feedback - [[Arxiv](https://arxiv.org/abs/2204.11545)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.11545.md)]
- Evaluating Interpolation and Extrapolation Performance of Neural   Retrieval Models - [[Arxiv](https://arxiv.org/abs/2204.11447)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.11447.md)]
- Simulating Fluids in Real-World Still Images - [[Arxiv](https://arxiv.org/abs/2204.11335)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.11335.md)]
- RelViT: Concept-guided Vision Transformer for Visual Relational   Reasoning - [[Arxiv](https://arxiv.org/abs/2204.11167)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.11167.md)]
- Meet Your Favorite Character: Open-domain Chatbot Mimicking Fictional   Characters with only a Few Utterances - [[Arxiv](https://arxiv.org/abs/2204.10825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.10825.md)]
- Pre-train a Discriminative Text Encoder for Dense Retrieval via   Contrastive Span Prediction - [[Arxiv](https://arxiv.org/abs/2204.10641)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.10641.md)]
- Autoregressive Search Engines: Generating Substrings as Document   Identifiers - [[Arxiv](https://arxiv.org/abs/2204.10628)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.10628.md)]
- Sharper Utility Bounds for Differentially Private Models - [[Arxiv](https://arxiv.org/abs/2204.10536v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.10536v1.md)]
- Sharper Utility Bounds for Differentially Private Models - [[Arxiv](https://arxiv.org/abs/2204.10536)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.10536.md)]
- Towards Multi-Turn Empathetic Dialogs with Positive Emotion Elicitation - [[Arxiv](https://arxiv.org/abs/2204.10509)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.10509.md)]
- Event Transition Planning for Open-ended Text Generation - [[Arxiv](https://arxiv.org/abs/2204.09453)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.09453.md)]
- Human-Object Interaction Detection via Disentangled Transformer - [[Arxiv](https://arxiv.org/abs/2204.09290)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.09290.md)]
- Visio-Linguistic Brain Encoding - [[Arxiv](https://arxiv.org/abs/2204.08261v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.08261v1.md)]
- Visio-Linguistic Brain Encoding - [[Arxiv](https://arxiv.org/abs/2204.08261)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.08261.md)]
- The Devil is in the Frequency: Geminated Gestalt Autoencoder for   Self-Supervised Visual Pre-Training - [[Arxiv](https://arxiv.org/abs/2204.08227)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.08227.md)]
- CPFair: Personalized Consumer and Producer Fairness Re-ranking for   Recommender Systems - [[Arxiv](https://arxiv.org/abs/2204.08085)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.08085.md)]
- Interactiveness Field in Human-Object Interactions - [[Arxiv](https://arxiv.org/abs/2204.07718)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.07718.md)]
- Improving Passage Retrieval with Zero-Shot Question Generation - [[Arxiv](https://arxiv.org/abs/2204.07496)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.07496.md)]
- INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold - [[Arxiv](https://arxiv.org/abs/2204.07439)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.07439.md)]
- A Personalized Dialogue Generator with Implicit User Persona Detection - [[Arxiv](https://arxiv.org/abs/2204.07372)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.07372.md)]
- LaMemo: Language Modeling with Look-Ahead Memory - [[Arxiv](https://arxiv.org/abs/2204.07341)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.07341.md)]
- Measuring Compositional Consistency for Video Question Answering - [[Arxiv](https://arxiv.org/abs/2204.07190)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.07190.md)]
- Neighborhood Attention Transformer - [[Arxiv](https://arxiv.org/abs/2204.07143)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.07143.md)]
- Masked Siamese Networks for Label-Efficient Learning - [[Arxiv](https://arxiv.org/abs/2204.07141)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.07141.md)]
- BEHAVE: Dataset and Method for Tracking Human Object Interactions - [[Arxiv](https://arxiv.org/abs/2204.06950)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.06950.md)]
- GPT-NeoX-20B: An Open-Source Autoregressive Language Model - [[Arxiv](https://arxiv.org/abs/2204.06745)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.06745.md)]
- Learning Convolutional Neural Networks in the Frequency Domain - [[Arxiv](https://arxiv.org/abs/2204.06718)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.06718.md)]
- Transparent Shape from a Single View Polarization Image - [[Arxiv](https://arxiv.org/abs/2204.06331)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.06331.md)]
- Neural Topic Modeling of Psychotherapy Sessions - [[Arxiv](https://arxiv.org/abs/2204.10189)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.10189.md)]
- MGM: A meshfree geometric multilevel method for systems arising from   elliptic equations on point cloud surfaces - [[Arxiv](https://arxiv.org/abs/2204.06154)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.06154.md)]
- Training a Helpful and Harmless Assistant with Reinforcement Learning   from Human Feedback - [[Arxiv](https://arxiv.org/abs/2204.05862)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.05862.md)]
- Bootstrap Motion Forecasting With Self-Consistent Constraints - [[Arxiv](https://arxiv.org/abs/2204.05859)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.05859.md)]
- Stylized Knowledge-Grounded Dialogue Generation via Disentangled   Template Rewriting - [[Arxiv](https://arxiv.org/abs/2204.05610)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.05610.md)]
- Deep Annotation of Therapeutic Working Alliance in Psychotherapy - [[Arxiv](https://arxiv.org/abs/2204.05522)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.05522.md)]
- Overlapping Word Removal is All You Need: Revisiting Data Imbalance in   Hope Speech Detection - [[Arxiv](https://arxiv.org/abs/2204.05488)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.05488.md)]
- Exploring the Universal Vulnerability of Prompt-based Learning Paradigm - [[Arxiv](https://arxiv.org/abs/2204.05239)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.05239.md)]
- Focal Length and Object Pose Estimation via Render and Compare - [[Arxiv](https://arxiv.org/abs/2204.05145)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.05145.md)]
- Category-Aware Transformer Network for Better Human-Object Interaction   Detection - [[Arxiv](https://arxiv.org/abs/2204.04911)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.04911.md)]
- Consistency Learning via Decoding Path Augmentation for Transformers in   Human Object Interaction Detection - [[Arxiv](https://arxiv.org/abs/2204.04836)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.04836.md)]
- DualPrompt: Complementary Prompting for Rehearsal-free Continual   Learning - [[Arxiv](https://arxiv.org/abs/2204.04799)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.04799.md)]
- Representation Learning by Detecting Incorrect Location Embeddings - [[Arxiv](https://arxiv.org/abs/2204.04788)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.04788.md)]
- Learning Trajectory-Aware Transformer for Video Super-Resolution - [[Arxiv](https://arxiv.org/abs/2204.04216)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.04216.md)]
- Federated Learning with Partial Model Personalization - [[Arxiv](https://arxiv.org/abs/2204.03809)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.03809.md)]
- Federated Learning with Partial Model Personalization - [[Arxiv](https://arxiv.org/abs/2204.03809v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.03809v2.md)]
- Unsupervised Prompt Learning for Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2204.03649)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.03649.md)]
- Interacting with Non-Cooperative User: A New Paradigm for Proactive   Dialogue Policy - [[Arxiv](https://arxiv.org/abs/2204.07433)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.07433.md)]
- Winoground: Probing Vision and Language Models for Visio-Linguistic   Compositionality - [[Arxiv](https://arxiv.org/abs/2204.03162)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.03162.md)]
- Knowledge Infused Decoding - [[Arxiv](https://arxiv.org/abs/2204.03084)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.03084.md)]
- Knowledge Infused Decoding - [[Arxiv](https://arxiv.org/abs/2204.03084v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.03084v1.md)]
- Unleashing Vanilla Vision Transformer with Masked Image Modeling for   Object Detection - [[Arxiv](https://arxiv.org/abs/2204.02964)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.02964.md)]
- Towards An End-to-End Framework for Flow-Guided Video Inpainting - [[Arxiv](https://arxiv.org/abs/2204.02663)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.02663.md)]
- There Are a Thousand Hamlets in a Thousand People's Eyes: Enhancing   Knowledge-grounded Dialogue with Personal Memory - [[Arxiv](https://arxiv.org/abs/2204.02624)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.02624.md)]
- Efficient Test-Time Model Adaptation without Forgetting - [[Arxiv](https://arxiv.org/abs/2204.02610)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.02610.md)]
- C3KG: A Chinese Commonsense Conversation Knowledge Graph - [[Arxiv](https://arxiv.org/abs/2204.02549)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.02549.md)]
- CHORE: Contact, Human and Object REconstruction from a single RGB image - [[Arxiv](https://arxiv.org/abs/2204.02445)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.02445.md)]
- Can language models learn from explanations in context? - [[Arxiv](https://arxiv.org/abs/2204.02329)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.02329.md)]
- PaLM: Scaling Language Modeling with Pathways - [[Arxiv](https://arxiv.org/abs/2204.02311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.02311.md)]
- At the Locus of Performance: Quantifying the Effects of Copious   3D-Stacked Cache on HPC Workloads - [[Arxiv](https://arxiv.org/abs/2204.02235)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.02235.md)]
- $\textit{latent}$-GLAT: Glancing at Latent Variables for Parallel Text   Generation - [[Arxiv](https://arxiv.org/abs/2204.02030)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.02030.md)]
- Learning Neural Acoustic Fields - [[Arxiv](https://arxiv.org/abs/2204.00628v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.00628v2.md)]
- Learning Neural Acoustic Fields - [[Arxiv](https://arxiv.org/abs/2204.00628)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.00628.md)]
- Do As I Can, Not As I Say: Grounding Language in Robotic Affordances - [[Arxiv](https://arxiv.org/abs/2204.01691)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.01691.md)]
- MultiMAE: Multi-modal Multi-task Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2204.01678)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.01678.md)]
- Value Gradient weighted Model-Based Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2204.01464)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.01464.md)]
- Value Gradient weighted Model-Based Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2204.01464v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.01464v2.md)]
- PRADA: Practical Black-Box Adversarial Attacks against Neural Ranking   Models - [[Arxiv](https://arxiv.org/abs/2204.01321)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.01321.md)]
- Probabilistic Implicit Scene Completion - [[Arxiv](https://arxiv.org/abs/2204.01264)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.01264.md)]
- Probabilistic Implicit Scene Completion - [[Arxiv](https://arxiv.org/abs/2204.01264v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.01264v1.md)]
- Dynamic Focus-aware Positional Queries for Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2204.01244)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.01244.md)]
- What to look at and where: Semantic and Spatial Refined Transformer for   detecting human-object interactions - [[Arxiv](https://arxiv.org/abs/2204.00746)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.00746.md)]
- Implicit Feedback for Dense Passage Retrieval: A Counterfactual Approach - [[Arxiv](https://arxiv.org/abs/2204.00718)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.00718.md)]
- Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language - [[Arxiv](https://arxiv.org/abs/2204.00598)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.00598.md)]
- End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge   Distillation - [[Arxiv](https://arxiv.org/abs/2204.03541)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.03541.md)]
- Distill-VQ: Learning Retrieval Oriented Vector Quantization By   Distilling Knowledge from Dense Embeddings - [[Arxiv](https://arxiv.org/abs/2204.00185)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.00185.md)]

### March 2022
- TransGeo: Transformer Is All You Need for Cross-view Image   Geo-localization - [[Arxiv](https://arxiv.org/abs/2204.00097)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2204.00097.md)]
- Exploring Visual Prompts for Adapting Large-Scale Models - [[Arxiv](https://arxiv.org/abs/2203.17274)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.17274.md)]
- A 23 MW data centre is all you need - [[Arxiv](https://arxiv.org/abs/2203.17265)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.17265.md)]
- R2L: Distilling Neural Radiance Field to Neural Light Field for   Efficient Novel View Synthesis - [[Arxiv](https://arxiv.org/abs/2203.17261)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.17261.md)]
- Templates for 3D Object Pose Estimation Revisited: Generalization to New   Objects and Robustness to Occlusions - [[Arxiv](https://arxiv.org/abs/2203.17234)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.17234.md)]
- SimVQA: Exploring Simulated Environments for Visual Question Answering - [[Arxiv](https://arxiv.org/abs/2203.17219)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.17219.md)]
- Self-distillation Augmented Masked Autoencoders for Histopathological   Image Classification - [[Arxiv](https://arxiv.org/abs/2203.16983)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.16983.md)]
- MAE-AST: Masked Autoencoding Audio Spectrogram Transformer - [[Arxiv](https://arxiv.org/abs/2203.16691)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.16691.md)]
- PromptDet: Towards Open-vocabulary Detection using Uncurated Images - [[Arxiv](https://arxiv.org/abs/2203.16513)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.16513.md)]
- A Sequential Quadratic Programming Approach to the Solution of Open-Loop   Generalized Nash Equilibria - [[Arxiv](https://arxiv.org/abs/2203.16478)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.16478.md)]
- Instance Relation Graph Guided Source-Free Domain Adaptive Object   Detection - [[Arxiv](https://arxiv.org/abs/2203.15793)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.15793.md)]
- Causal de Finetti: On the Identification of Invariant Causal Structure   in Exchangeable Data - [[Arxiv](https://arxiv.org/abs/2203.15756)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.15756.md)]
- Training Compute-Optimal Large Language Models - [[Arxiv](https://arxiv.org/abs/2203.15556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.15556.md)]
- Graph Neural Networks are Dynamic Programmers - [[Arxiv](https://arxiv.org/abs/2203.15544)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.15544.md)]
- mc-BEiT: Multi-choice Discretization for Image BERT Pre-training - [[Arxiv](https://arxiv.org/abs/2203.15371)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.15371.md)]
- MAT: Mask-Aware Transformer for Large Hole Image Inpainting - [[Arxiv](https://arxiv.org/abs/2203.15270)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.15270.md)]
- Parameter-efficient Model Adaptation for Vision Transformers - [[Arxiv](https://arxiv.org/abs/2203.16329)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.16329.md)]
- Generalizing Few-Shot NAS with Gradient Matching - [[Arxiv](https://arxiv.org/abs/2203.15207v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.15207v2.md)]
- Generalizing Few-Shot NAS with Gradient Matching - [[Arxiv](https://arxiv.org/abs/2203.15207)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.15207.md)]
- Neural Vocoder is All You Need for Speech Super-resolution - [[Arxiv](https://arxiv.org/abs/2203.14941)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.14941.md)]
- Learning to Prompt for Open-Vocabulary Object Detection with   Vision-Language Model - [[Arxiv](https://arxiv.org/abs/2203.14940)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.14940.md)]
- A Joint Cross-Attention Model for Audio-Visual Fusion in Dimensional   Emotion Recognition - [[Arxiv](https://arxiv.org/abs/2203.14779)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.14779.md)]
- MSTR: Multi-Scale Transformer for End-to-End Human-Object Interaction   Detection - [[Arxiv](https://arxiv.org/abs/2203.14709)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.14709.md)]
- ImFace: A Nonlinear 3D Morphable Face Model with Implicit Neural   Representations - [[Arxiv](https://arxiv.org/abs/2203.14510)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.14510.md)]
- STaR: Bootstrapping Reasoning With Reasoning - [[Arxiv](https://arxiv.org/abs/2203.14465)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.14465.md)]
- UV Volumes for Real-time Rendering of Editable Free-view Human   Performance - [[Arxiv](https://arxiv.org/abs/2203.14402)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.14402.md)]
- Discovering Human-Object Interaction Concepts via Self-Compositional   Learning - [[Arxiv](https://arxiv.org/abs/2203.14272)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.14272.md)]
- How Severe is Benchmark-Sensitivity in Video Self-Supervised Learning? - [[Arxiv](https://arxiv.org/abs/2203.14221)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.14221.md)]
- GEN-VLKT: Simplify Association and Enhance Interaction Understanding for   HOI Detection - [[Arxiv](https://arxiv.org/abs/2203.13954)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.13954.md)]
- AutoML for Deep Recommender Systems: A Survey - [[Arxiv](https://arxiv.org/abs/2203.13922)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.13922.md)]
- Spectral Measurement Sparsification for Pose-Graph SLAM - [[Arxiv](https://arxiv.org/abs/2203.13897)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.13897.md)]
- Continual Test-Time Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2203.13591)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.13591.md)]
- MISC: A MIxed Strategy-Aware Model Integrating COMET for Emotional   Support Conversation - [[Arxiv](https://arxiv.org/abs/2203.13560)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.13560.md)]
- A Comparative Survey of Deep Active Learning - [[Arxiv](https://arxiv.org/abs/2203.13450)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.13450.md)]
- Linking Emergent and Natural Languages via Corpus Transfer - [[Arxiv](https://arxiv.org/abs/2203.13344)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.13344.md)]
- Linking Emergent and Natural Languages via Corpus Transfer - [[Arxiv](https://arxiv.org/abs/2203.13344v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.13344v1.md)]
- MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2203.13310)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.13310.md)]
- What to Hide from Your Students: Attention-Guided Masked Image Modeling - [[Arxiv](https://arxiv.org/abs/2203.12719)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.12719.md)]
- VideoMAE: Masked Autoencoders are Data-Efficient Learners for   Self-Supervised Video Pre-Training - [[Arxiv](https://arxiv.org/abs/2203.12602)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.12602.md)]
- Pathways: Asynchronous Distributed Dataflow for ML - [[Arxiv](https://arxiv.org/abs/2203.12533)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.12533.md)]
- Ev-TTA: Test-Time Adaptation for Event-Based Object Recognition - [[Arxiv](https://arxiv.org/abs/2203.12247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.12247.md)]
- Deep Frequency Filtering for Domain Generalization - [[Arxiv](https://arxiv.org/abs/2203.12198)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.12198.md)]
- Visual Prompt Tuning - [[Arxiv](https://arxiv.org/abs/2203.12119)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.12119.md)]
- Self-supervision through Random Segments with Autoregressive Coding   (RandSAC) - [[Arxiv](https://arxiv.org/abs/2203.12054)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.12054.md)]
- Language modeling via stochastic processes - [[Arxiv](https://arxiv.org/abs/2203.11370)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.11370.md)]
- Language modeling via stochastic processes - [[Arxiv](https://arxiv.org/abs/2203.11370)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.11370.md)]
- Language modeling via stochastic processes - [[Arxiv](https://arxiv.org/abs/2203.11370v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.11370v2.md)]
- Masked Discrimination for Self-Supervised Learning on Point Clouds - [[Arxiv](https://arxiv.org/abs/2203.11183)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.11183.md)]
- Self-Consistency Improves Chain of Thought Reasoning in Language Models - [[Arxiv](https://arxiv.org/abs/2203.11171)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.11171.md)]
- The Conceptual VAE - [[Arxiv](https://arxiv.org/abs/2203.11216)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.11216.md)]
- Teaching language models to support answers with verified quotes - [[Arxiv](https://arxiv.org/abs/2203.11147)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.11147.md)]
- Towards Large-Scale Interpretable Knowledge Graph Reasoning for Dialogue   Systems - [[Arxiv](https://arxiv.org/abs/2203.10610)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.10610.md)]
- Iwin: Human-Object Interaction Detection via Transformer with Irregular   Windows - [[Arxiv](https://arxiv.org/abs/2203.10537)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.10537.md)]
- CoWs on Pasture: Baselines and Benchmarks for Language-Driven Zero-Shot   Object Navigation - [[Arxiv](https://arxiv.org/abs/2203.10421)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.10421.md)]
- On Robust Prefix-Tuning for Text Classification - [[Arxiv](https://arxiv.org/abs/2203.10378v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.10378v1.md)]
- On Robust Prefix-Tuning for Text Classification - [[Arxiv](https://arxiv.org/abs/2203.10378)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.10378.md)]
- Exploring Motion Ambiguity and Alignment for High-Quality Video Frame   Interpolation - [[Arxiv](https://arxiv.org/abs/2203.10291)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.10291.md)]
- SwinTextSpotter: Scene Text Spotting via Better Synergy between Text   Detection and Text Recognition - [[Arxiv](https://arxiv.org/abs/2203.10209)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.10209.md)]
- Generative Principal Component Analysis - [[Arxiv](https://arxiv.org/abs/2203.09693v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.09693v2.md)]
- Generative Principal Component Analysis - [[Arxiv](https://arxiv.org/abs/2203.09693)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.09693.md)]
- Monotonic Differentiable Sorting Networks - [[Arxiv](https://arxiv.org/abs/2203.09630)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.09630.md)]
- Monotonic Differentiable Sorting Networks - [[Arxiv](https://arxiv.org/abs/2203.09630v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.09630v1.md)]
- Monotonic Differentiable Sorting Networks - [[Arxiv](https://arxiv.org/abs/2203.09630)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.09630.md)]
- A Framework and Benchmark for Deep Batch Active Learning for Regression - [[Arxiv](https://arxiv.org/abs/2203.09410)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.09410.md)]
- RoMe: A Robust Metric for Evaluating Natural Language Generation - [[Arxiv](https://arxiv.org/abs/2203.09183)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.09183.md)]
- PLANET: Dynamic Content Planning in Autoregressive Transformers for   Long-form Text Generation - [[Arxiv](https://arxiv.org/abs/2203.09100)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.09100.md)]
- Memorizing Transformers - [[Arxiv](https://arxiv.org/abs/2203.08913)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.08913.md)]
- Memorizing Transformers - [[Arxiv](https://arxiv.org/abs/2203.08913v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.08913v1.md)]
- Multi-Stage Prompting for Knowledgeable Dialogue Generation - [[Arxiv](https://arxiv.org/abs/2203.08745)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.08745.md)]
- Differentiable DAG Sampling - [[Arxiv](https://arxiv.org/abs/2203.08509)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.08509.md)]
- Differentiable DAG Sampling - [[Arxiv](https://arxiv.org/abs/2203.08509v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.08509v1.md)]
- Iteratively Prompt Pre-trained Language Models for Chain of Thought - [[Arxiv](https://arxiv.org/abs/2203.08383)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.08383.md)]
- Multi-View Document Representation Learning for Open-Domain Dense   Retrieval - [[Arxiv](https://arxiv.org/abs/2203.08372)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.08372.md)]
- Unified Visual Transformer Compression - [[Arxiv](https://arxiv.org/abs/2203.08243)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.08243.md)]
- Unified Visual Transformer Compression - [[Arxiv](https://arxiv.org/abs/2203.08243v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.08243v1.md)]
- Vision-Based Manipulators Need to Also See from Their Hands - [[Arxiv](https://arxiv.org/abs/2203.12677v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.12677v1.md)]
- Vision-Based Manipulators Need to Also See from Their Hands - [[Arxiv](https://arxiv.org/abs/2203.12677)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.12677.md)]
- Augmenting Document Representations for Dense Retrieval with   Interpolation and Perturbation - [[Arxiv](https://arxiv.org/abs/2203.07735)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.07735.md)]
- ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D   Human Motion Generation - [[Arxiv](https://arxiv.org/abs/2203.07706)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.07706.md)]
- Distraction is All You Need for Fairness - [[Arxiv](https://arxiv.org/abs/2203.07593)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.07593.md)]
- ScienceWorld: Is your Agent Smarter than a 5th Grader? - [[Arxiv](https://arxiv.org/abs/2203.07540)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.07540.md)]
- Respecting causality is all you need for training physics-informed   neural networks - [[Arxiv](https://arxiv.org/abs/2203.07404)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.07404.md)]
- All in One: Exploring Unified Video-Language Pre-training - [[Arxiv](https://arxiv.org/abs/2203.07303)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.07303.md)]
- Orchestrated Value Mapping for Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2203.07171v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.07171v2.md)]
- Orchestrated Value Mapping for Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2203.07171)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.07171.md)]
- Masked Autoencoders for Point Cloud Self-supervised Learning - [[Arxiv](https://arxiv.org/abs/2203.06604)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.06604.md)]
- PromptChainer: Chaining Large Language Model Prompts through Visual   Programming - [[Arxiv](https://arxiv.org/abs/2203.06566)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.06566.md)]
- Categories of Differentiable Polynomial Circuits for Machine Learning - [[Arxiv](https://arxiv.org/abs/2203.06430)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.06430.md)]
- BiBERT: Accurate Fully Binarized BERT - [[Arxiv](https://arxiv.org/abs/2203.06390v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.06390v1.md)]
- BiBERT: Accurate Fully Binarized BERT - [[Arxiv](https://arxiv.org/abs/2203.06390)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.06390.md)]
- MISF: Multi-level Interactive Siamese Filtering for High-Fidelity Image   Inpainting - [[Arxiv](https://arxiv.org/abs/2203.06304)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.06304.md)]
- LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text   Retrieval - [[Arxiv](https://arxiv.org/abs/2203.06169)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.06169.md)]
- An Interpretable Neuro-Symbolic Reasoning Framework for Task-Oriented   Dialogue Generation - [[Arxiv](https://arxiv.org/abs/2203.05843)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.05843.md)]
- Long Time No See! Open-Domain Conversation with Long-Term Persona Memory - [[Arxiv](https://arxiv.org/abs/2203.05797)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.05797.md)]
- Conditional Prompt Learning for Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2203.05557)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.05557.md)]
- Back to the Feature: Classical 3D Features are (Almost) All You Need for   3D Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2203.05550)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.05550.md)]
- Self Pre-training with Masked Autoencoders for Medical Image   Classification and Segmentation - [[Arxiv](https://arxiv.org/abs/2203.05573)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.05573.md)]
- MVP: Multimodality-guided Visual Pre-training - [[Arxiv](https://arxiv.org/abs/2203.05175)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.05175.md)]
- Internet-augmented language models through few-shot prompting for   open-domain question answering - [[Arxiv](https://arxiv.org/abs/2203.05115)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.05115.md)]
- All You Need is LUV: Unsupervised Collection of Labeled Images using   Invisible UV Fluorescent Indicators - [[Arxiv](https://arxiv.org/abs/2203.04566)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.04566.md)]
- Source-free Video Domain Adaptation by Learning Temporal Consistency for   Action Recognition - [[Arxiv](https://arxiv.org/abs/2203.04559)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.04559.md)]
- Kubric: A scalable dataset generator - [[Arxiv](https://arxiv.org/abs/2203.03570)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.03570.md)]
- Kubric: A scalable dataset generator - [[Arxiv](https://arxiv.org/abs/2203.03570)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.03570.md)]
- Self-supervised Implicit Glyph Attention for Text Recognition - [[Arxiv](https://arxiv.org/abs/2203.03382)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.03382.md)]
- Adaptive Cross-Layer Attention for Image Restoration - [[Arxiv](https://arxiv.org/abs/2203.03619v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.03619v3.md)]
- Adaptive Cross-Layer Attention for Image Restoration - [[Arxiv](https://arxiv.org/abs/2203.03619)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.03619.md)]
- Structured Pruning is All You Need for Pruning CNNs at Initialization - [[Arxiv](https://arxiv.org/abs/2203.02549)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.02549.md)]
- Neural Simulated Annealing - [[Arxiv](https://arxiv.org/abs/2203.02201v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.02201v1.md)]
- Neural Simulated Annealing - [[Arxiv](https://arxiv.org/abs/2203.02201)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.02201.md)]
- Training language models to follow instructions with human feedback - [[Arxiv](https://arxiv.org/abs/2203.02155)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.02155.md)]
- BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray   Classification - [[Arxiv](https://arxiv.org/abs/2203.01937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.01937.md)]
- Video is All You Need: Attacking PPG-based Biometric Authentication - [[Arxiv](https://arxiv.org/abs/2203.00928)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.00928.md)]
- Incremental Transformer Structure Enhanced Image Inpainting with Masking   Positional Encoding - [[Arxiv](https://arxiv.org/abs/2203.00867)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.00867.md)]
- Towards a unified view of unsupervised non-local methods for image   denoising: the NL-Ridge approach - [[Arxiv](https://arxiv.org/abs/2203.00570)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.00570.md)]
- DynamicRetriever: A Pre-training Model-based IR System with Neither   Sparse nor Dense Index - [[Arxiv](https://arxiv.org/abs/2203.00537)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.00537.md)]

### February 2022
- One Model is All You Need: Multi-Task Learning Enables Simultaneous   Histology Image Segmentation and Classification - [[Arxiv](https://arxiv.org/abs/2203.00077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2203.00077.md)]
- A Proximal Algorithm for Sampling - [[Arxiv](https://arxiv.org/abs/2202.13975)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.13975.md)]
- Rethinking and Refining the Distinct Metric - [[Arxiv](https://arxiv.org/abs/2202.13587)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.13587.md)]
- Filter-enhanced MLP is All You Need for Sequential Recommendation - [[Arxiv](https://arxiv.org/abs/2202.13556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.13556.md)]
- The Spectral Bias of Polynomial Neural Networks - [[Arxiv](https://arxiv.org/abs/2202.13473v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.13473v1.md)]
- The Spectral Bias of Polynomial Neural Networks - [[Arxiv](https://arxiv.org/abs/2202.13473)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.13473.md)]
- AugESC: Dialogue Augmentation with Large Language Models for Emotional   Support Conversation - [[Arxiv](https://arxiv.org/abs/2202.13047)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.13047.md)]
- Ask2Mask: Guided Data Selection for Masked Speech Modeling - [[Arxiv](https://arxiv.org/abs/2202.12719)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.12719.md)]
- Ask2Mask: Guided Data Selection for Masked Speech Modeling - [[Arxiv](https://arxiv.org/abs/2202.12719v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.12719v1.md)]
- Effective Actor-centric Human-object Interaction Detection - [[Arxiv](https://arxiv.org/abs/2202.11998)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.11998.md)]
- All You Need Is Supervised Learning: From Imitation Learning to Meta-RL   With Upside Down RL - [[Arxiv](https://arxiv.org/abs/2202.11960)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.11960.md)]
- Auto-scaling Vision Transformers without Training - [[Arxiv](https://arxiv.org/abs/2202.11921v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.11921v2.md)]
- Auto-scaling Vision Transformers without Training - [[Arxiv](https://arxiv.org/abs/2202.11921)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.11921.md)]
- COLD Decoding: Energy-based Constrained Text Generation with Langevin   Dynamics - [[Arxiv](https://arxiv.org/abs/2202.11705)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.11705.md)]
- Socialformer: Social Network Inspired Long Document Modeling for   Document Ranking - [[Arxiv](https://arxiv.org/abs/2202.10870)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.10870.md)]
- PyTorch Geometric Signed Directed: A Software Package on Graph Neural   Networks for Signed and Directed Graphs - [[Arxiv](https://arxiv.org/abs/2202.10793)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.10793.md)]
- Adversarial Attacks on Speech Recognition Systems for Mission-Critical   Applications: A Survey - [[Arxiv](https://arxiv.org/abs/2202.10594)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.10594.md)]
- 1-WL Expressiveness Is (Almost) All You Need - [[Arxiv](https://arxiv.org/abs/2202.10156)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.10156.md)]
- Pseudo Numerical Methods for Diffusion Models on Manifolds - [[Arxiv](https://arxiv.org/abs/2202.09778v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.09778v2.md)]
- Pseudo Numerical Methods for Diffusion Models on Manifolds - [[Arxiv](https://arxiv.org/abs/2202.09778)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.09778.md)]
- Bayes-Optimal Classifiers under Group Fairness - [[Arxiv](https://arxiv.org/abs/2202.09724)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.09724.md)]
- Bit-wise Training of Neural Network Weights - [[Arxiv](https://arxiv.org/abs/2202.09571)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.09571.md)]
- Bit-wise Training of Neural Network Weights - [[Arxiv](https://arxiv.org/abs/2202.09571v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.09571v1.md)]
- Highlighting Object Category Immunity for the Generalization of   Human-Object Interaction Detection - [[Arxiv](https://arxiv.org/abs/2202.09492)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.09492.md)]
- Unsupervised Multiple-Object Tracking with a Dynamical Variational   Autoencoder - [[Arxiv](https://arxiv.org/abs/2202.09315)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.09315.md)]
- Masked prediction tasks: a parameter identifiability view - [[Arxiv](https://arxiv.org/abs/2202.09305)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.09305.md)]
- Gaussian Mixture Convolution Networks - [[Arxiv](https://arxiv.org/abs/2202.09153v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.09153v1.md)]
- Gaussian Mixture Convolution Networks - [[Arxiv](https://arxiv.org/abs/2202.09153)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.09153.md)]
- cosFormer: Rethinking Softmax in Attention - [[Arxiv](https://arxiv.org/abs/2202.08791)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.08791.md)]
- cosFormer: Rethinking Softmax in Attention - [[Arxiv](https://arxiv.org/abs/2202.08791v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.08791v1.md)]
- Task-Agnostic Graph Explanations - [[Arxiv](https://arxiv.org/abs/2202.08335)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.08335.md)]
- Task-Agnostic Graph Explanations - [[Arxiv](https://arxiv.org/abs/2202.08335v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.08335v2.md)]
- Not All Patches are What You Need: Expediting Vision Transformers via   Token Reorganizations - [[Arxiv](https://arxiv.org/abs/2202.07800)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.07800.md)]
- Don't Lie to Me! Robust and Efficient Explainability with Verified   Perturbation Analysis - [[Arxiv](https://arxiv.org/abs/2202.07728)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.07728.md)]
- A precortical module for robust CNNs to light variations - [[Arxiv](https://arxiv.org/abs/2202.07432)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.07432.md)]
- A precortical module for robust CNNs to light variations - [[Arxiv](https://arxiv.org/abs/2202.07432v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.07432v2.md)]
- Exploring Discontinuity for Video Frame Interpolation - [[Arxiv](https://arxiv.org/abs/2202.07291)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.07291.md)]
- Transformer Memory as a Differentiable Search Index - [[Arxiv](https://arxiv.org/abs/2202.06991)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.06991.md)]
- What Do They Capture? -- A Structural Analysis of Pre-Trained Language   Models for Source Code - [[Arxiv](https://arxiv.org/abs/2202.06840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.06840.md)]
- Domain Adaptation via Prompt Learning - [[Arxiv](https://arxiv.org/abs/2202.06687)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.06687.md)]
- FlowEval: A Consensus-Based Dialogue Evaluation Framework Using Segment   Act Flows - [[Arxiv](https://arxiv.org/abs/2202.06633)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.06633.md)]
- A Contrastive Framework for Neural Text Generation - [[Arxiv](https://arxiv.org/abs/2202.06417)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.06417.md)]
- Conditional Contrastive Learning with Kernel - [[Arxiv](https://arxiv.org/abs/2202.05458v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.05458v3.md)]
- Conditional Contrastive Learning with Kernel - [[Arxiv](https://arxiv.org/abs/2202.05458)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.05458.md)]
- Domain Adversarial Training: A Game Perspective - [[Arxiv](https://arxiv.org/abs/2202.05352)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.05352.md)]
- Domain Adversarial Training: A Game Perspective - [[Arxiv](https://arxiv.org/abs/2202.05352v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.05352v1.md)]
- InPars: Data Augmentation for Information Retrieval using Large Language   Models - [[Arxiv](https://arxiv.org/abs/2202.05144)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.05144.md)]
- Neural Sheaf Diffusion: A Topological Perspective on Heterophily and   Oversmoothing in GNNs - [[Arxiv](https://arxiv.org/abs/2202.04579)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.04579.md)]
- GiraffeDet: A Heavy-Neck Paradigm for Object Detection - [[Arxiv](https://arxiv.org/abs/2202.04256v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.04256v2.md)]
- GiraffeDet: A Heavy-Neck Paradigm for Object Detection - [[Arxiv](https://arxiv.org/abs/2202.04256)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.04256.md)]
- Distillation with Contrast is All You Need for Self-Supervised Point   Cloud Representation Learning - [[Arxiv](https://arxiv.org/abs/2202.04241)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.04241.md)]
- Towards Compositional Adversarial Robustness: Generalizing Adversarial   Training to Composite Semantic Perturbations - [[Arxiv](https://arxiv.org/abs/2202.04235)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.04235.md)]
- MaskGIT: Masked Generative Image Transformer - [[Arxiv](https://arxiv.org/abs/2202.04200)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.04200.md)]
- FMP: Toward Fair Graph Message Passing against Topology Bias - [[Arxiv](https://arxiv.org/abs/2202.04187)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.04187.md)]
- DALL-Eval: Probing the Reasoning Skills and Social Biases of   Text-to-Image Generation Models - [[Arxiv](https://arxiv.org/abs/2202.04053)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.04053.md)]
- How to Understand Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2202.03670)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.03670.md)]
- Survey of Hallucination in Natural Language Generation - [[Arxiv](https://arxiv.org/abs/2202.03629)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.03629.md)]
- GrASP: Gradient-Based Affordance Selection for Planning - [[Arxiv](https://arxiv.org/abs/2202.04772)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.04772.md)]
- GrASP: Gradient-Based Affordance Selection for Planning - [[Arxiv](https://arxiv.org/abs/2202.04772v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.04772v1.md)]
- PolicyCleanse: Backdoor Detection and Mitigation in Reinforcement   Learning - [[Arxiv](https://arxiv.org/abs/2202.03609)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.03609.md)]
- data2vec: A General Framework for Self-supervised Learning in Speech,   Vision and Language - [[Arxiv](https://arxiv.org/abs/2202.03555)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.03555.md)]
- Corrupted Image Modeling for Self-Supervised Visual Pre-Training - [[Arxiv](https://arxiv.org/abs/2202.03382)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.03382.md)]
- Message Passing Neural PDE Solvers - [[Arxiv](https://arxiv.org/abs/2202.03376)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.03376.md)]
- Message Passing Neural PDE Solvers - [[Arxiv](https://arxiv.org/abs/2202.03376v3)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.03376v3.md)]
- Transformers in Self-Supervised Monocular Depth Estimation with Unknown   Camera Intrinsics - [[Arxiv](https://arxiv.org/abs/2202.03131)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.03131.md)]
- OFA: Unifying Architectures, Tasks, and Modalities Through a Simple   Sequence-to-Sequence Learning Framework - [[Arxiv](https://arxiv.org/abs/2202.03052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.03052.md)]
- Context Autoencoder for Self-Supervised Representation Learning - [[Arxiv](https://arxiv.org/abs/2202.03026)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.03026.md)]
- User Satisfaction Estimation with Sequential Dialogue Act Modeling in   Goal-oriented Conversational Systems - [[Arxiv](https://arxiv.org/abs/2202.02912)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.02912.md)]
- DEVO: Depth-Event Camera Visual Odometry in Challenging Conditions - [[Arxiv](https://arxiv.org/abs/2202.02556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.02556.md)]
- One-Nearest-Neighbor Search is All You Need for Minimax Optimal   Regression and Classification - [[Arxiv](https://arxiv.org/abs/2202.02464)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.02464.md)]
- Webly Supervised Concept Expansion for General Purpose Vision Models - [[Arxiv](https://arxiv.org/abs/2202.02317)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.02317.md)]
- Structured Prediction Problem Archive - [[Arxiv](https://arxiv.org/abs/2202.03574)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.03574.md)]
- mSLAM: Massively multilingual joint pre-training for speech and text - [[Arxiv](https://arxiv.org/abs/2202.01374)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.01374.md)]
- A Survey on Retrieval-Augmented Text Generation - [[Arxiv](https://arxiv.org/abs/2202.01110)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.01110.md)]
- ColloSSL: Collaborative Self-Supervised Learning for Human Activity   Recognition - [[Arxiv](https://arxiv.org/abs/2202.00758)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.00758.md)]
- Detecting Human-Object Interactions with Object-Guided Cross-Modal   Calibrated Semantics - [[Arxiv](https://arxiv.org/abs/2202.00259)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.00259.md)]
- CLA-NeRF: Category-Level Articulated Neural Radiance Field - [[Arxiv](https://arxiv.org/abs/2202.00181)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2202.00181.md)]

### January 2022
- Signing the Supermask: Keep, Hide, Invert - [[Arxiv](https://arxiv.org/abs/2201.13361)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.13361.md)]
- Signing the Supermask: Keep, Hide, Invert - [[Arxiv](https://arxiv.org/abs/2201.13361v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.13361v2.md)]
- Few-Shot Backdoor Attacks on Visual Object Tracking - [[Arxiv](https://arxiv.org/abs/2201.13178v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.13178v2.md)]
- Few-Shot Backdoor Attacks on Visual Object Tracking - [[Arxiv](https://arxiv.org/abs/2201.13178)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.13178.md)]
- Causal Explanations and XAI - [[Arxiv](https://arxiv.org/abs/2201.13169)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.13169.md)]
- Adversarial Masking for Self-Supervised Learning - [[Arxiv](https://arxiv.org/abs/2201.13100)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.13100.md)]
- Robust Imitation Learning from Corrupted Demonstrations - [[Arxiv](https://arxiv.org/abs/2201.12594)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.12594.md)]
- Robust Imitation Learning from Corrupted Demonstrations - [[Arxiv](https://arxiv.org/abs/2201.12594v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.12594v1.md)]
- Rebalancing Batch Normalization for Exemplar-based Class-Incremental   Learning - [[Arxiv](https://arxiv.org/abs/2201.12559)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.12559.md)]
- ItWave: It Stochastic Differential Equation Is All You Need For   Wave Generation - [[Arxiv](https://arxiv.org/abs/2201.12519)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.12519.md)]
- Counterfactual Plans under Distributional Ambiguity - [[Arxiv](https://arxiv.org/abs/2201.12487)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.12487.md)]
- Counterfactual Plans under Distributional Ambiguity - [[Arxiv](https://arxiv.org/abs/2201.12487v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.12487v2.md)]
- DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR - [[Arxiv](https://arxiv.org/abs/2201.12329)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.12329.md)]
- DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR - [[Arxiv](https://arxiv.org/abs/2201.12329v4)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.12329v4.md)]
- Mask-based Latent Reconstruction for Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2201.12096)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.12096.md)]
- Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A   Large-Scale Generative Language Model - [[Arxiv](https://arxiv.org/abs/2201.11990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.11990.md)]
- Chain-of-Thought Prompting Elicits Reasoning in Large Language Models - [[Arxiv](https://arxiv.org/abs/2201.11903)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.11903.md)]
- DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence - [[Arxiv](https://arxiv.org/abs/2201.11176)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.11176.md)]
- Natural Language Descriptions of Deep Visual Features - [[Arxiv](https://arxiv.org/abs/2201.11114)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.11114.md)]
- Natural Language Descriptions of Deep Visual Features - [[Arxiv](https://arxiv.org/abs/2201.11114v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.11114v2.md)]
- Explanatory Learning: Beyond Empiricism in Neural Networks - [[Arxiv](https://arxiv.org/abs/2201.10222)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.10222.md)]
- Explanatory Learning: Beyond Empiricism in Neural Networks - [[Arxiv](https://arxiv.org/abs/2201.10222v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.10222v1.md)]
- RePaint: Inpainting using Denoising Diffusion Probabilistic Models - [[Arxiv](https://arxiv.org/abs/2201.09865)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.09865.md)]
- Learning Graph Augmentations to Learn Graph Representations - [[Arxiv](https://arxiv.org/abs/2201.09830v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.09830v1.md)]
- Learning Graph Augmentations to Learn Graph Representations - [[Arxiv](https://arxiv.org/abs/2201.09830)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.09830.md)]
- Learning Graph Augmentations to Learn Graph Representations - [[Arxiv](https://arxiv.org/abs/2201.09830)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.09830.md)]
- Patches Are All You Need? - [[Arxiv](https://arxiv.org/abs/2201.09792v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.09792v1.md)]
- Patches Are All You Need? - [[Arxiv](https://arxiv.org/abs/2201.09792)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.09792.md)]
- Neural Implicit Surface Evolution - [[Arxiv](https://arxiv.org/abs/2201.09636)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.09636.md)]
- Universal Online Learning with Unbounded Losses: Memory Is All You Need - [[Arxiv](https://arxiv.org/abs/2201.08903)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.08903.md)]
- Fast Differentiable Matrix Square Root - [[Arxiv](https://arxiv.org/abs/2201.08663)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.08663.md)]
- Fast Differentiable Matrix Square Root - [[Arxiv](https://arxiv.org/abs/2201.08663v1)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.08663v1.md)]
- End-to-end Generative Pretraining for Multimodal Video Captioning - [[Arxiv](https://arxiv.org/abs/2201.08264)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.08264.md)]
- LaMDA: Language Models for Dialog Applications - [[Arxiv](https://arxiv.org/abs/2201.08239)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.08239.md)]
- Safe Deep RL in 3D Environments using Human Feedback - [[Arxiv](https://arxiv.org/abs/2201.08102)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.08102.md)]
- Safe Deep RL in 3D Environments using Human Feedback - [[Arxiv](https://arxiv.org/abs/2201.08102v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.08102v2.md)]
- CM3: A Causal Masked Multimodal Model of the Internet - [[Arxiv](https://arxiv.org/abs/2201.07520)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.07520.md)]
- Language Models as Zero-Shot Planners: Extracting Actionable Knowledge   for Embodied Agents - [[Arxiv](https://arxiv.org/abs/2201.07207)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.07207.md)]
- GANmouflage: 3D Object Nondetection with Texture Fields - [[Arxiv](https://arxiv.org/abs/2201.07202)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.07202.md)]
- RePre: Improving Self-Supervised Vision Transformer with Reconstructive   Pre-training - [[Arxiv](https://arxiv.org/abs/2201.06857)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.06857.md)]
- Parameter-free Online Test-time Adaptation - [[Arxiv](https://arxiv.org/abs/2201.05718)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.05718.md)]
- Progressively Optimized Bi-Granular Document Representation for Scalable   Embedding Based Retrieval - [[Arxiv](https://arxiv.org/abs/2201.05409)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.05409.md)]
- A Survey of Controllable Text Generation using Transformer-based   Pre-trained Language Models - [[Arxiv](https://arxiv.org/abs/2201.05337)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.05337.md)]
- Neural Circuit Architectural Priors for Embodied Control - [[Arxiv](https://arxiv.org/abs/2201.05242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.05242.md)]
- Neural Circuit Architectural Priors for Embodied Control - [[Arxiv](https://arxiv.org/abs/2201.05242v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.05242v2.md)]
- SparseDet: Improving Sparsely Annotated Object Detection with   Pseudo-positive Mining - [[Arxiv](https://arxiv.org/abs/2201.04620)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.04620.md)]
- Structure and Semantics Preserving Document Representations - [[Arxiv](https://arxiv.org/abs/2201.03720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.03720.md)]
- 3D Face Morphing Attacks: Generation, Vulnerability and Detection - [[Arxiv](https://arxiv.org/abs/2201.03454)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.03454.md)]
- QuadTree Attention for Vision Transformers - [[Arxiv](https://arxiv.org/abs/2201.02767)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.02767.md)]
- QuadTree Attention for Vision Transformers - [[Arxiv](https://arxiv.org/abs/2201.02767v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.02767v2.md)]
- Categorical Hopfield Networks - [[Arxiv](https://arxiv.org/abs/2201.02756)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.02756.md)]
- Detecting Human-to-Human-or-Object (H2O) Interactions with DIABOLO - [[Arxiv](https://arxiv.org/abs/2201.02396)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.02396.md)]
- Grokking: Generalization Beyond Overfitting on Small Algorithmic   Datasets - [[Arxiv](https://arxiv.org/abs/2201.02177)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.02177.md)]
- All You Need In Sign Language Production - [[Arxiv](https://arxiv.org/abs/2201.01609)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.01609.md)]
- C2-CRS: Coarse-to-Fine Contrastive Learning for Conversational   Recommender System - [[Arxiv](https://arxiv.org/abs/2201.02732)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.02732.md)]
- Class-Incremental Continual Learning into the eXtended DER-verse - [[Arxiv](https://arxiv.org/abs/2201.00766)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.00766.md)]
- Vision Transformer with Deformable Attention - [[Arxiv](https://arxiv.org/abs/2201.00520)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2201.00520.md)]
