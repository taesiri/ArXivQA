# [When to Learn What: Model-Adaptive Data Augmentation Curriculum](https://arxiv.org/abs/2309.04747)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to optimize data augmentation policies to be adaptive to each training sample and different training stages of the model, in order to improve the model's generalization performance. 

Specifically, the key questions are:

1) When to apply data augmentation during model training? The paper finds that using augmentations from the start of training does not help, so they propose a "monotonic curriculum" to gradually introduce more augmented data.

2) What augmentations should be applied to each sample at different training stages? The paper proposes a policy network that takes in sample features and outputs augmentation parameters (probability and magnitude vectors). This policy network is trained jointly with the task model to minimize the task model's validation loss - making it adaptive to the model's training progress.

The main hypothesis is that by making data augmentations adaptive in this way - both adapting them to each sample based on its features, and adapting them over time based on the model's training stage - they can optimize the augmentations to improve generalization of the model. The experiments validate this hypothesis, showing their approach outperforms other augmentation methods.

In summary, this paper focuses on learning an optimal data augmentation policy that is model-adaptive and data-adaptive. The key innovation is the jointly trained policy network that outputs customized augmentations per sample and training stage.


## What is the main contribution of this paper?

 The main contributions of this paper can be summarized as:

1. They propose a monotonic curriculum strategy (called "trick") to gradually introduce more data augmentation during training. This avoids using excessive augmentation early on when the model is still learning to recognize original images.

2. They propose MADAug, a model-adaptive data augmentation method. It trains a policy network to select augmentations for each input image, with the goal of minimizing the validation loss of the task model. The policy network outputs are trained via bilevel optimization.

3. Through experiments on CIFAR-10/100, SVHN, and ImageNet, they demonstrate MADAug consistently improves over existing data augmentation methods and achieves state-of-the-art performance.

4. They show the learned augmentation policy network transfers well to unseen fine-grained datasets, outperforming other baseline models. 

5. Analysis shows MADAug policies preserve key image information while generating more challenging augmentations later in training. The augmentations are adaptive to different training stages.

In summary, the key ideas are gradually introducing augmentation during training (the "trick") and learning a policy network to generate model-adaptive and data-adaptive augmentations for each image via bilevel optimization. Experiments demonstrate improved accuracy and generalization over prior augmentation techniques.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes Model-Adaptive Data Augmentation (MADAug), a new method to automatically learn data augmentation policies that are adaptive to both the model being trained and individual data samples, producing a curriculum that gradually introduces more difficult augmentations optimized for improving generalization performance.
