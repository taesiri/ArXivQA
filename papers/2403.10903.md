# [DTOR: Decision Tree Outlier Regressor to explain anomalies](https://arxiv.org/abs/2403.10903)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Anomaly detection models are being widely used to identify fraudulent activities, risks, and threats in critical domains like banking. However, the lack of explainability around how these models make decisions on what is anomalous poses challenges for stakeholders to understand the root causes and take appropriate actions. 

- Existing explainability techniques like SHAP focus on feature importance scores but may not provide transparent and comprehensive explanations, especially for complex models and high-dimensional datasets. Rule-based techniques like Anchors generate human-interpretable rules explaining model predictions but have limitations when applied to anomaly detection in a regression setting.

- There is a need for an interpretable explainable AI (XAI) technique tailored for anomaly detection that can provide rule-based explanations elucidating why certain data points are deemed anomalies.

Proposed Solution:
- The paper introduces Decision Tree Outlier Regressor (DTOR) - a novel model-agnostic framework for generating rule-based explanations specifically suited for anomaly detection. 

- It works by training a decision tree regressor to estimate the anomaly scores from the detector model. The path traversed by a data point in the tree provides a set of predicates as the explanation rule. A weighted loss focuses training on accurately estimating the score for the point being explained.

- Compared to Anchors, DTOR is designed as a regressor rather than classifier. It has consistently 100% validity in the experiments and provides both score and predicates for enhanced transparency. The explanations align with isolation principles in techniques like Isolation Forests.

Main Contributions:
- Introduction of DTOR - an XAI approach using decision tree regressor to generate interpretable rules explaining anomalies in an unsupervised manner.

- Novel weighted scheme for training tailored to prioritize explanation accuracy on the specific data point.  

- New methodology proposed to estimate rule precision that aims to preserve some correlations between variables, avoiding fully synthetic neighborhood generation.

- Experiments on multiple datasets and detectors demonstrate DTOR's effectiveness over Anchors in measures like validity, coverage and execution time.

In summary, the paper makes notable contributions in advancing rule-based explainability for anomaly detection models to promote trust and transparency in critical applications like banking fraud analytics.
