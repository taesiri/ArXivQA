# [MADTP: Multimodal Alignment-Guided Dynamic Token Pruning for   Accelerating Vision-Language Transformer](https://arxiv.org/abs/2403.02991)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Vision-Language Transformers (VLTs) models like CLIP and BLIP have shown great success in multimodal learning. However, they suffer from heavy computation costs due to their complex architecture, large parameters and numerous tokens. Existing VLT compression methods lack the consideration of multimodal alignment guidance and dynamic compression based on input complexity.  

Proposed Solution - MADTP Framework
The paper proposes a novel Multimodal Alignment-Guided Dynamic Token Pruning (MADTP) framework to accelerate VLTs. The main components are:

1. Multi-modality Alignment Guidance (MAG) Module: Inserted between vision and language branches, it explicitly aligns representations across modalities using learnable tokens. This provides guidance during token pruning to avoid removing tokens crucial for both modalities.

2. Dynamic Token Pruning (DTP) Module: Incorporated within transformer blocks, it dynamically adjusts the compression ratio per layer based on input instance complexity. Thresholds are learned using token attention maps from MAG module.

Together, MAG and DTP modules allow MADTP framework to effectively compress VLTs in an aligned and dynamic manner.

Main Contributions:
- Reveals the vital role of multimodal alignment to guide VLT compression.
- Proposes MAG module for explicit alignment of joint representations from different modalities.
- Presents DTP module to achieve adaptive compression of VLTs based on input instances.  
- Extensive experiments validate MADTP framework significantly reduces GFLOPs of VLTs like BLIP while preserving accuracy.
- Analysis shows MADTP emphasis on modality correlation, avoids pruning crucial tokens and allows dynamic adjustment of compression ratios.

In summary, the paper makes significant contributions by proposing the novel MADTP framework containing MAG and DTP modules to address limitations of existing VLT compression techniques. Experiments demonstrate state-of-the-art results in accelerating diverse VLT models across different datasets and tasks.
