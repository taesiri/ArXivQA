# [MIMONets: Multiple-Input-Multiple-Output Neural Networks Exploiting   Computation in Superposition](https://arxiv.org/abs/2312.02829)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes MIMONets, a framework that enables neural networks to perform computation in superposition across multiple inputs simultaneously. By leveraging the mathematical concept of the "Blessing of Dimensionality", MIMONets binds multiple inputs into a single superposition using variable binding mechanisms from vector symbolic architectures (VSAs). This superposition is then processed by the neural network, which is regularized to be near-isometric to reduce interference between inputs. Finally, the outputs are unbound back into separate outputs for each input. Two instantiations are presented - MIMOConv for CNNs and MIMOFormer for Transformers. Experiments demonstrate 2-4x throughput increases on vision and language tasks with minimal accuracy drops. Theorems provide performance guarantees and bounds on interference noise. Overall, MIMONets provides a principled approach to process multiple inputs simultaneously in neural networks while retaining performance, enabling dynamic tradeoffs between throughput and accuracy.
