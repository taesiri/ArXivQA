# [On The Transferability of Deep-Q Networks](https://arxiv.org/abs/2110.02639v2)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: How transferable are Deep-Q Networks?

The authors investigate the transfer learning properties of Deep-Q Networks, which are a popular family of deep reinforcement learning algorithms for learning optimal policies and value functions. Specifically, they aim to assess the degree to which pre-trained Deep-Q Networks can be effectively transferred and fine-tuned on new reinforcement learning tasks. 

The main hypothesis tested in the paper is that Deep-Q Networks exhibit poor transferability across different reinforcement learning environments. The authors perform experiments to evaluate whether fine-tuning pre-trained Deep-Q Networks leads to positive transfer (faster learning on the new task), negative transfer (slower learning), or no transfer on various Atari games and simple control tasks.

In summary, the central research question is focused on characterizing and understanding the transfer learning capabilities of Deep-Q Networks across different reinforcement learning problems. The key hypothesis is that these algorithms generally do not transfer well, which challenges the common practice of transfer learning with deep neural networks in other domains like computer vision.
