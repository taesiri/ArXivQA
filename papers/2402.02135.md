# [Do Moral Judgment and Reasoning Capability of LLMs Change with Language?   A Study using the Multilingual Defining Issues Test](https://arxiv.org/abs/2402.02135)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Moral judgments and reasoning of humans depend on the language used to present moral dilemmas. However, it's unknown if large language models (LLMs) also exhibit this "foreign language effect". 

- Prior work studied the moral capabilities of LLMs like GPT-4, ChatGPT, and Llama2Chat using the Defining Issues Test (DIT) moral dilemmas only in English. This work extends the analysis to 5 more languages.

Methods
- Translated 5 dilemmas from original DIT and 4 new dilemmas into Spanish, Russian, Chinese, Hindi and Swahili using Google Translate API and native speakers.

- Probed GPT-4, ChatGPT and Llama2Chat by providing the dilemmas in these languages and asking for moral judgments and reasoning considerations. 

- Computed personal interests, maintaining norms and post-conventional (P) scores reflecting different stages of moral development.

Results
- GPT-4 shows most consistent moral capabilities across languages; ChatGPT and Llama2Chat have higher variance.  

- For all models, moral reasoning is superior for English, Spanish, Russian and Chinese compared to Swahili and Hindi.

- Moral judgments differ the most between English and Russian despite both being high resource languages. Judgments are more consistent between English, Spanish and Chinese.

Contributions
- First study analyzing multilingual moral capabilities of major LLMs using Kohlberg's framework.

- New multilingual datasets created by translating widely used DIT dilemmas.

- Analysis and hypotheses about dependence of moral judgment and reasoning on language availability and cultural values encoded in the training data.

Limitations 
- Small set of languages and dilemmas limits generalizability.

- Risk of translation errors impacting quality of multilingual dilemmas.
