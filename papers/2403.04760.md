# [iScore: Visual Analytics for Interpreting How Language Models   Automatically Score Summaries](https://arxiv.org/abs/2403.04760)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
As large language models (LLMs) like BERT become popular for powering educational technologies, it is challenging for learning engineers to interpret their behavior and calibrate trust before deployment. The lack of transparency in complex deep learning models inhibits closing the loop of model development. There is an opportunity to leverage visual analytics to help learning engineers explain LLM-based educational technologies.  

Proposed Solution: 
The paper presents iScore, an interactive visual analytics tool to help learning engineers upload, score, and compare multiple LLM-scored summaries of a source text. iScore structures analysis around three coordinated views - the Assignments Panel for uploading/scoring summaries, the Scores Dashboard for tracking score provenance over revisions, and the Model Analysis View for visualizing two LLM interpretability techniques (input perturbation and token attention). Together these views increase transparency into how LLMs are scoring summaries to help users evaluate trustworthiness.

Contributions:
1) Design challenges and tasks for evaluating automated summary scoring LLMs 
2) iScore system combining multiple views to interpret LLMs scoring summaries  
3) Case study showing iScore helped improve an LLM's accuracy
4) Expert interviews revealing how iScore increased understanding, evaluation and trust in LLMs during deployment

In summary, the paper makes both systems and qualitative contributions for explaining black-box educational AI through visual analytics, enabling responsible and ethical deployment of LLMs. The methods generalize to other LLMs and present opportunities to build trust in AI among non-experts.
