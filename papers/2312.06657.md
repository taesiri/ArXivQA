# [Learning Naturally Aggregated Appearance for Efficient 3D Editing](https://arxiv.org/abs/2312.06657)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel 3D scene representation called AGAP (Naturally Aggregated Appearance) for efficient 3D editing. It consists of an explicit 3D density grid to estimate geometry and density, along with a 2D canonical image and an associated projection field to aggregate scene appearance. The key insight is to replace the implicit color field used in neural radiance fields with an explicit canonical image that users can easily edit with 2D image processing tools. To map 3D points to this canonical image for texture lookup, a projection field is learned in a residual manner - first initialized to ensure natural aggregation, then refined with an offset network. Once trained with multi-view images, the AGAP model supports editing the scene by manipulating the canonical image, without needing to re-optimize the model. Experiments demonstrate AGAP's ability to enable practical 3D editing applications like stylization, content extraction and interactive drawing across different datasets, while achieving competitive view synthesis quality compared to state-of-the-art methods like NeRF.
