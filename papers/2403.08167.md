# [MolBind: Multimodal Alignment of Language, Molecules, and Proteins](https://arxiv.org/abs/2403.08167)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Current multi-modal pre-training methods for molecules utilize only a single pair of modalities (e.g. molecule-language), limiting their extension to multiple modalities (N>=3). The learned representations are restricted to the pairs of modalities used during training.
- Availability of multi-modal pairs for molecules is insufficient and much smaller compared to other domains (e.g. 400M image-text pairs for CLIP vs 300K molecule-text pairs).

Proposed Solution:
- Propose MolBind, a novel framework that aligns multiple modalities (language, 2D molecular graphs, 3D molecular conformations, 3D protein pockets) to a unified embedding space through contrastive learning.
- MolBind trains encoders for each modality and maps them to a shared feature space for multi-modal semantic alignment. It does not require datasets where all modalities co-occur.
- Construct a new dataset MolBind-M4 with 4 modalities: graph-language (325K pairs), conformation-language (161K pairs), graph-conformation (161K pairs), conformation-protein (72K pairs).

Main Contributions:
- Propose MolBind, a novel multi-modal pre-training framework that extends molecule-language pre-training to multiple modalities in biology.
- Construct MolBind-M4, the first unified multi-modal dataset containing language, molecules, proteins sourced from open datasets. 
- Experiments show MolBind's superior performance on downstream tasks like zero-shot retrieval and classification, demonstrating its effectiveness in aligning representations of multiple modalities.

In summary, the paper presents MolBind for aligning multiple molecular modalities and language via contrastive learning, and collects the MolBind-M4 dataset to facilitate this multi-modal pre-training. Extensive experiments validate the capability of MolBind in modality alignment and knowledge transfer.
