# [A Data Centric Approach for Unsupervised Domain Generalization via   Retrieval from Web Scale Multimodal Data](https://arxiv.org/abs/2402.04416)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper tackles the problem of unsupervised domain generalization (UDG). Traditional UDG methods assume access to abundant unlabeled source data from the same labels spaces as the target task. This is an impractical assumption. To address this, the paper proposes the multimodal UDG (MUDG) setting, which leverages a large-scale task-agnostic unlabeled image dataset that can be efficiently searched in a joint vision-language space using CLIP. The goal is to construct a small pseudo-labeled subset from this source dataset to finetune a student CLIP model for a given target task.

Proposed Solution: 
The paper proposes a 3-step pipeline to construct the pseudo-labeled subset:

1. Diversified Retrieval: Augment the text prototypes with random tokens to diversify the retrieved images. This captures broader visual variations within each class. 

2. Rank Pseudo-Labeling: Assign each retrieved image the label of the text prototype closest in rank instead of cosine similarity. This mitigates the hubness effect in retrieval.

3. Clustering: Cluster image embeddings within each label group and sample 1 image per cluster. This selects representative images and balances the label distribution.

The constructed subset is then used to finetune a student CLIP model with standard cross-entropy loss.

Main Contributions:

- Introduces the MUDG problem, which is more practical than UDG and offers more leverage than source-free DG.

- Proposes an intuitive 3-step pipeline to construct a pseudo-labeled subset from a large task-agnostic source dataset.

- Achieves up to 10% accuracy gains over state-of-the-art source-free DG and zero-shot methods on 20 diverse benchmarks.

- Shows 3% average accuracy gain from the proposed construction pipeline compared to naive retrieval baselines.

- Brings more focus on the dataset construction aspect of finetuning instead of just the training algorithm.

In summary, the paper tackles an important practical problem in domain generalization and demonstrates promising results by constructing tailored pseudo-labeled datasets from easily accessible web-scale sources.
