# [PhD: A Prompted Visual Hallucination Evaluation Dataset](https://arxiv.org/abs/2403.11116)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) have driven progress in large vision-language models (LVLMs), but LLMs also introduce issues like hallucination into LVLMs. 
- Prior work has mostly focused on object hallucination, but there are other types of intrinsic vision-language hallucinations (mismatches between textual and visual content) that need analysis.

Proposed Solution:
- Categorize intrinsic hallucinations into 4 types - object, attribute, multi-modal conflicting, and counter-common-sense.
- Propose the PhD benchmark dataset to evaluate LVLMs on these hallucination types using confusing items and counterintuitive images.
- Implement an automated pipeline to generate the multi-modal confusing/counterintuitive data at scale.

Main Contributions:
- First comprehensive taxonomy of intrinsic vision-language hallucination types and analysis of their origins in LVLMs.
- Challenging PhD benchmark to evaluate state-of-the-art LVLMs, revealing performance gaps.
- Automated pipeline to generate diverse, high-quality hallucination data grounded in image content.
- Experiments on 5 LVLMs demonstrating limitations in tackling the new tasks, with insights to guide future research on mitigating hallucinations.

In summary, this paper makes a systematic study of intrinsic hallucinations in LVLMs, proposes the PhD benchmark to evaluate this, and provides analysis to further the understanding and advancement of LVLMs.
