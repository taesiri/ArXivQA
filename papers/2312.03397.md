# [Generalized Contrastive Divergence: Joint Training of Energy-Based Model   and Diffusion Model through Inverse Reinforcement Learning](https://arxiv.org/abs/2312.03397)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes Generalized Contrastive Divergence (GCD), a novel training objective for jointly optimizing an energy-based model (EBM) and a parametric sampler such as a diffusion model. GCD generalizes the well-known Contrastive Divergence algorithm by replacing the MCMC sampler with a parametric sampler that is trained adversarially against the EBM. This enables stable training of the EBM without relying on expensive MCMC sampling. An interesting connection is made to inverse reinforcement learning, where the EBM learns a reward signal from data demonstrations and the sampler acts as a policy optimizing that reward. Preliminary experiments on a 2D dataset demonstrate that GCD training can effectively recover the data distribution while improving sample quality, especially when the sampler uses only a small number of steps. The learned EBM can also provide useful likelihood estimates. Overall, GCD opens up opportunities to improve generative modeling using ideas from reinforcement learning.
