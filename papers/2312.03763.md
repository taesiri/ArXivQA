# [Gaussian3Diff: 3D Gaussian Diffusion for 3D Full Head Synthesis and   Editing](https://arxiv.org/abs/2312.03763)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Generating and editing photorealistic 3D human heads is important for applications like embodied AI, VR/AR, games, etc. Existing neural radiance field and 3D-aware GAN methods can generate high-quality view-consistent heads, but have limited editing capabilities. Methods that allow editing typically rely on manipulating a latent code or 2D segmentation map, which does not provide detailed control. 

Proposed Solution:
The paper proposes Gaussian3Diff, a novel framework to generate and edit 3D human heads. The key idea is to represent a 3D head using many 3D Gaussians anchored to a 3D face model (3DMM). Each Gaussian has a compact tri-plane payload that encodes local texture and geometry. By attaching the Gaussians to the UV space of the 3DMM, editing can leverage semantic alignments. A diffusion model is trained on this representation to enable high-quality generation.

Key Contributions:
1) Novel 3D head representation using many 3D Gaussians with local tri-plane payloads anchored to a 3DMM and represented in the UV space. This provides editing flexibility.

2) An analysis-by-synthesis approach to reconstruct and align representations of diverse 3D heads using a shared latent space and multi-view supervision. This enables training a 2D diffusion model.

3) A diffusion model trained on the proposed representation that generates high-quality and editable 3D heads. Enables uncontrolled generation and various editing operations like expression editing, region-based editing etc. with superior quality than previous works.

In summary, Gaussian3Diff introduces a new 3D editable head representation tailored for diffusion modelling and demonstrates its ability for high-quality generation and detailed editing control. The anchoring to a 3DMM and UV space formulation are key enablers.
