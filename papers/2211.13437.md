# [Seeing What You Miss: Vision-Language Pre-training with Semantic   Completion Learning](https://arxiv.org/abs/2211.13437)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper aims to address is:

How can we improve vision-language pre-training models to better learn global semantic representations and cross-modal alignment? 

The key hypothesis is that existing masked modeling pre-training objectives like masked language modeling (MLM) and masked vision modeling (MVM) focus only on reconstructing local masked tokens. This may lead to inadequate learning of global semantic features that capture higher-level cross-modal information. 

To address this, the authors propose a new pre-training task called Semantic Completion Learning (SCL). The key idea is to recover the global semantics of masked data by exploiting cross-modal interactions. This allows the model to generate more representative global features with improved global-to-local alignment.

In summary, the central research question is how to improve global semantic learning and cross-modal alignment in vision-language pre-training. The key hypothesis is that reconstructing local masked tokens is insufficient and recovering global semantics of masked data through cross-modal interactions can improve global feature learning. SCL is proposed to test this hypothesis.
