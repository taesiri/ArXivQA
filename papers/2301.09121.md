# [Learning Open-vocabulary Semantic Segmentation Models From Natural   Language Supervision](https://arxiv.org/abs/2301.09121)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is: 

How can we train an open-vocabulary semantic segmentation model capable of segmenting objects of arbitrary classes, using only web-crawled image-caption pairs as supervision rather than ground truth segmentation masks?

The key points are:

- The goal is open-vocabulary semantic segmentation, where the model can segment objects of any class, not just a predefined closed set of classes. 

- The only supervision used for training is web-crawled image-caption pairs, not ground truth segmentation masks.

- The proposed model, OVSegmentor, learns to segment objects by aligning visual groups/clusters of pixels to corresponding words/phrases in the caption text.

So in summary, the paper explores how to effectively leverage weakly annotated web data (image-caption pairs) to learn an open-vocabulary segmentation model, without needing costly pixel-level ground truth annotations. The novelty is in the proposed model architecture and training techniques to enable this type of weakly supervised learning.
