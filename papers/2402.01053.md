# [Plan-Grounded Large Language Models for Dual Goal Conversational   Settings](https://arxiv.org/abs/2402.01053)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Current LLMs are only trained to follow user instructions, but not lead a dialogue through a procedural plan while also addressing the user's changing needs. 
- Needed are LLMs that can both guide users through plans of procedures (e.g. recipes, DIY tasks) and adaptively answer questions grounded in the plan context.

Proposed Solution:
- Develop a plan-grounded LLM assistant that can navigate procedural plans while handling user questions, requests for substitutions, fun facts etc. 
- Train the LLM with 4 objectives: navigate plans, answer grounded questions, handle open-ended requests, follow conversational norms.
- Use supervised pretraining and preference learning (DPO algorithm) to optimize the objectives.

Key Contributions:
1) LLM grounds conversations on procedural plans, tracks progress through plans, and activates safety guardrails.
2) Answers user questions grounded in the plan context using knowledge from previous turns, plan steps or external knowledge. 
3) Handles open-ended requests like suggesting replacements or fun facts based on plan elements.
4) Respects conversational norms - keeps users safe, is polite, steers away from inappropriate requests.

Experiments show the proposed model (PlanLLM) improves performance 2.1x over strong baselines. Evaluation also demonstrates good generalization to unseen domains, indicating robust plan grounding and reasoning abilities.

Overall, the paper makes important contributions in developing LLMs that can lead mixed-initiative goal-driven conversations grounded on procedural plans.
