# [ReconFusion: 3D Reconstruction with Diffusion Priors](https://arxiv.org/abs/2312.02981)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the paper:

This paper proposes ReconFusion, a method to improve neural radiance field (NeRF) based 3D reconstruction from limited input views. The key idea is to leverage a diffusion model trained for novel view synthesis as a regularizer during NeRF optimization. Specifically, the authors first train a multiview conditional diffusion model on a mixture of real and synthetic posed image datasets. This model takes a set of input views of a scene and is able to generate realistic novel views of the scene. During 3D reconstruction, in addition to the standard NeRF loss between renderings and input views, they add a sample loss which compares NeRF renderings at random novel views to the outputs of the diffusion model. This additional loss acts as a strong regularizer that encourages the NeRF to produce renderings consistent with the distribution modeled by the diffusion prior. Experiments across multiple real-world datasets with 3 to 9 input views show that this approach leads to significant quality improvements and robustness over state-of-the-art baselines. The method is able to prevent common NeRF artifacts and extrapolate realistic geometry and appearance to unobserved regions. Even with more input views, it still provides gains, indicating it is an effective general purpose regularizer for few-view 3D reconstruction.
