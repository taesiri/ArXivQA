# [Analytically Tractable Bayesian Deep Q-Learning](https://arxiv.org/abs/2106.11086)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main contributions and research focus of this paper are:- Proposing a new method called "Tractable Approximate Gaussian Inference" (TAGI) for Bayesian deep learning that allows analytically inferring the weights and biases of neural networks. This is in contrast to most other Bayesian neural network methods that rely on approximation techniques like variational inference or sampling.- Demonstrating how to adapt the temporal difference Q-learning framework commonly used in deep reinforcement learning to make it compatible with TAGI. This allows applying TAGI to learn the action-value function for reinforcement learning problems.- Evaluating TAGI deep Q-networks on benchmark reinforcement learning environments and comparing its performance to standard deep Q-learning based on backpropagation. The goal is to show TAGI can reach competitive performance to backpropagation on challenging RL problems without relying on gradient-based optimization.So in summary, the main research focus is introducing a new analytically tractable Bayesian inference method for neural networks called TAGI and demonstrating its effectiveness by applying it to deep Q-learning for reinforcement learning problems. The key hypothesis is that TAGI can achieve comparable performance to backpropagation on complex RL benchmarks while also providing the benefits of Bayesian approaches.
