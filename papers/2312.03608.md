# [Automated Multimodal Data Annotation via Calibration With Indoor   Positioning System](https://arxiv.org/abs/2312.03608)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel automated pipeline for generating multimodal object detection datasets without any manual annotation. An indoor positioning system (IPS) provides accurate pose estimates for sensors and objects of interest. By calibrating the transformations between sensor frames (camera, LiDAR) and the IPS frame, the system can automatically generate labels and bounding boxes for images and point clouds in real-time. A planar constraint is introduced during camera-IPS calibration to reduce error propagation from noisy IPS readings. To further refine LiDAR labels, an extended RANSAC algorithm optimizes the alignment of generated 3D boxes using a custom fitness function that maximizes point density near box faces. Experiments demonstrate a speedup of 261.8x over manual image annotation and 61.5% faster overall dataset creation. The average IoU between automated and manual labels is 0.74 for images and 0.44 for point clouds. While not perfect, the automated annotations often visually align better with the data. By eliminating tedious manual effort, the proposed pipeline enables rapid generation of niche multimodal detection datasets.
