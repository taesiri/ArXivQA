# [Self-Supervised Pre-Training for Table Structure Recognition Transformer](https://arxiv.org/abs/2402.15578)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Table structure recognition (TSR) aims to convert tabular images into machine-readable formats. The current state-of-the-art uses a hybrid CNN-transformer architecture for this image-to-text generation task.
- However, recent works have shown that a simple linear projection transformer outperforms hybrid models on various vision tasks. 
- But directly applying a linear projection transformer to TSR leads to a significant drop in performance, especially for complex tables.

Proposed Solution:
- The authors propose using self-supervised pre-training (SSP) to mitigate the performance gap between the linear projection transformer and hybrid CNN-transformer for TSR.
- The visual encoder of the TSR transformer is pre-trained using a masked image modeling task on only the tabular images from existing datasets, without needing any extra annotations.
- This SSP visual encoder is then finetuned with the textual decoder on the downstream TSR task.

Main Contributions:
- Demonstrate SSP successfully bridges the performance gap between linear projection transformer and hybrid CNN-transformer for TSR. The SSP model achieves much higher TEDS scores.
- Provide full experimental details and open-source code for reproducibility, transparency and fair comparison.
- Show the promise of using SSP to train complex vision-language models like TSR transformers when dataset size is limited.
- TSR on tables is a promising and underexplored area for self-supervised representation learning.

In summary, the key novelty is using a self-supervised pre-training approach to mitigate the performance gap between different TSR model architectures without requiring any additional labeled data. The paper makes models, code and details publicly available to spur innovation in this space.
