# [Transferring Modality-Aware Pedestrian Attentive Learning   Visible-Infrared Person Re-identification](https://arxiv.org/abs/2312.07021)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality summary paragraph of the paper:

This paper proposes a novel Transferring Modality-Aware Pedestrian Attentive Learning (TMPA) model for visible-infrared person re-identification (VI-ReID). The key idea is to leverage pedestrian-attentive features and learn modality-complete and consistent representations across visible and infrared modalities. The model consists of three main components: (1) A region-based data augmentation module called PedMix that enhances pedestrian region coherence in mixed images while reducing ambiguous patterns; (2) A lightweight hybrid modality compensation module called Modality Feature Transfer (MFT) that elegantly integrates cross attention and convolutions to transfer modality-specific features with minimal overhead; (3) Several loss functions including a novel modality-shared-specific loss to constrain feature learning. Experiments on two benchmarks SYSU-MM01 and RegDB demonstrate state-of-the-art performance of the proposed TMPA model. Ablation studies validate the efficacy of the PedMix and MFT modules. Visualizations also show TMPA's ability to focus on entire pedestrian areas for effective VI-ReID.
