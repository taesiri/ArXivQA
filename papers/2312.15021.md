# [Towards a Unified Multimodal Reasoning Framework](https://arxiv.org/abs/2312.15021)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Language models (LMs) have achieved strong performance on many NLP tasks, but still have limitations in reasoning abilities and integrating multimodal data like images.  
- There is a need to enhance LMs' reasoning capacities and accuracy in solving multiple-choice questions.

Proposed Solution:
- Combine Chain-of-Thought (CoT) reasoning and Visual Question Answering (VQA) techniques to improve LMs. 
- CoT involves generating explanations to provide logical reasoning behind decisions.  
- VQA utilizes images as additional contextual information to answer questions.
- Assess 3 text embedding methods: QA with DistilBERT, T5 without reasoning, T5 with reasoning and image captions.
- Assess 3 visual embedding methods: VQA model, integrating visual embeddings, and visual + textual embeddings.

Experiments:
- Used TextVQA and ScienceQA datasets requiring reasoning with text and images.
- Compared accuracy and ROUGE F1 scores between variants.
- Best model was T5 fine-tuned on answer generation, with generated explanations fed back as input.

Key Findings:
- Adding image captions did not improve accuracy over text-only T5.
- Separate fine-tuning on answer and explanation generation works better than joint training.  
- Using model's own explanations for teacher training boosts performance.
- T5 model performed very well on TextVQA, supporting advantage of multimodal techniques.

Main Contributions:
- Novel investigation of combining CoT and VQA to improve LM reasoning.
- Demonstrated these techniques' potential, especially with teacher training.
- Provided insights to guide further research on integrating textual and visual context.
- Showed promise for developing more accurate AI systems that can reason across modalities.
