# [ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D   Human Motion Generation](https://arxiv.org/abs/2203.07706)

## What is the central research question or hypothesis that this paper addresses?

 The central research question of this paper is how to generate realistic and diverse 3D human motions conditioned on semantic action labels, for both single-person actions and multi-person interactive actions. 

The key hypotheses are:

1) A GAN-based Transformer framework (ActFormer) can achieve superior performance in generating realistic and diverse action-conditioned human motions, by combining the representation power of Transformers and generative modeling capability of GANs.

2) Equipping ActFormer with a Gaussian Process latent prior can help enforce temporal correlations in the generated motions.

3) ActFormer can be extended to generate multi-person interactive motions by modeling temporal correlations and human interactions alternately with Transformer encoders.

4) ActFormer demonstrates strong adaptability to various human motion representations (e.g. joint coordinates, SMPL parameters) and different datasets of single-person and multi-person motions.

In summary, the central goal is to develop a powerful framework ActFormer for general action-conditioned human motion generation, and validate its effectiveness on both single-person and multi-person scenarios. The key hypothesis is that the proposed design can achieve superior generation performance across diverse motion data.


## What is the main contribution of this paper?

 The main contribution of this paper is presenting ActFormer, a GAN-based Transformer framework for general action-conditioned 3D human motion generation. Specifically, the key contributions are:

1. ActFormer leverages the strong representation capability of Transformer and combines it with a Gaussian Process latent prior to generate high-quality single-person human motions for various action categories.

2. ActFormer is extended to handle multi-person interactive motions by alternatingly modeling temporal correlations and human interactions with Transformer encoders. This allows ActFormer to generate synchronized and natural-looking multi-person motions. 

3. A new synthetic dataset called GTA Combat is introduced to provide complex multi-person combat motion data, facilitating research on multi-person motion generation.

4. Extensive experiments show ActFormer achieves state-of-the-art performance on both single-person and multi-person motion generation across various datasets. The results demonstrate ActFormer's effectiveness for general human motion generation.

In summary, the main contribution is proposing ActFormer as a powerful and flexible framework for generating diverse, realistic 3D human motions conditioned on action labels, for both single-person and multi-person scenarios. The introduction of the GTA Combat dataset also facilitates future research on complex multi-person motion modeling.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points in the paper:

The paper proposes ActFormer, a GAN-based Transformer framework for general action-conditioned 3D human motion generation, including single-person actions and multi-person interactions; it achieves state-of-the-art results on various benchmarks and motion representations and introduces a new synthetic multi-person combat dataset to facilitate further research.
