# [ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D   Human Motion Generation](https://arxiv.org/abs/2203.07706)

## What is the central research question or hypothesis that this paper addresses?

 The central research question of this paper is how to generate realistic and diverse 3D human motions conditioned on semantic action labels, for both single-person actions and multi-person interactive actions. 

The key hypotheses are:

1) A GAN-based Transformer framework (ActFormer) can achieve superior performance in generating realistic and diverse action-conditioned human motions, by combining the representation power of Transformers and generative modeling capability of GANs.

2) Equipping ActFormer with a Gaussian Process latent prior can help enforce temporal correlations in the generated motions.

3) ActFormer can be extended to generate multi-person interactive motions by modeling temporal correlations and human interactions alternately with Transformer encoders.

4) ActFormer demonstrates strong adaptability to various human motion representations (e.g. joint coordinates, SMPL parameters) and different datasets of single-person and multi-person motions.

In summary, the central goal is to develop a powerful framework ActFormer for general action-conditioned human motion generation, and validate its effectiveness on both single-person and multi-person scenarios. The key hypothesis is that the proposed design can achieve superior generation performance across diverse motion data.
