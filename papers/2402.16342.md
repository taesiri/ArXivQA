# [Contingency Planning Using Bi-level Markov Decision Processes for Space   Missions](https://arxiv.org/abs/2402.16342)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Scientific missions like NASA's VIPER rover face challenges in autonomous contingency planning, i.e. quickly computing alternative traverse plans from any off-nominal state caused by delays or deviations. 
- The large action space (different movements at different speeds) and long planning horizons (months) make it computationally intractable to solve as one monolithic MDP.

Proposed Solution:
- Formulate the problem as a bi-level MDP which aligns with existing mission planning paradigms. 
- The high-level MDP decides which science target to visit next.
- Separate low-level MDPs then plan the detailed path to reach each target selected by the high-level MDP.
- Reduce state and action spaces in each level to improve computational tractability.
- Trade-off optimality for faster computation by using a heuristic high-level transition function.

Key Contributions:
- Introduce RoverGridWorld to simulate rover path planning scenarios with time-sensitive constraints.
- Propose a framework to convert a mission planning MDP into a bi-level MDP using a few additional mission-specific inputs.
- Demonstrate on RoverGridWorld problems that the bi-level MDP achieves near-optimal rewards (e.g. 78% optimal) with much less computation time (e.g. 13% of optimal solver time).
- Show computation time improvements increase as problem complexity grows in terms of state/action space and planning horizons.
- Enable quick generation of contingency branches from any off-nominal state.

In summary, the paper presents a bi-level MDP approach for efficient autonomous rover path planning that is near-optimal, computationally tractable, and aligns with existing mission planning paradigms.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a bi-level Markov Decision Process framework to improve the computational tractability of autonomous contingency planning for planetary rover missions by separating high-level strategic decisions about science targets from low-level path planning.


## What is the main contribution of this paper?

 The main contribution of this paper is introducing a bi-level MDP framework for scientific mission planning, specifically for planetary rover traverse planning. The key ideas are:

1) Converting a flat mission planning MDP into a bi-level MDP by identifying high-level decision points (such as which science target to visit next) and constructing a high-level MDP focused on those decisions. 

2) For each high-level decision, constructing a low-level MDP to plan the details (such as the optimal path to the target). This results in smaller state and action spaces for the MDPs.

3) Demonstrating on a RoverGridWorld environment that this bi-level formulation achieves close to optimal rewards compared to the flat MDP, while being significantly more computationally efficient. As the problem complexity grows in terms of grid size, number of targets, etc., the computational advantage widens, with the bi-level MDP taking just 13% of the compute time of the flat MDP for the most complex case tested.

4) Showing that the bi-level MDP facilitates faster contingency planning by enabling quick computation of near-optimal policies from any arbitrary state.

In summary, the key contribution is a bi-level MDP approach for efficient and flexible contingency planning for planetary rover missions, while retaining performance close to an optimal flat MDP formulation.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- Markov Decision Processes (MDPs): A mathematical framework for modeling sequential decision making under uncertainty. Used to formulate the rover path planning problem.

- Bi-level Markov Decision Processes: A hierarchical framework proposed in the paper to improve computational tractability of solving MDPs for rover path planning. Consists of a high-level MDP and multiple low-level MDPs. 

- Rover traverse planning: Planning the path a rover takes to visit different science targets, while respecting constraints. Formulated as an MDP.

- Contingency planning: Planning alternate paths or policies from off-nominal states reached due to delays or deviations. Enabled by bi-level framework. 

- Value iteration: A dynamic programming algorithm used to solve MDPs. Compared between flat and bi-level MDPs.

- Reinforcement learning (RL): Model-free methods of solving MDPs through simulation and exploration. Q-learning and SARSA algorithms used.

- State space, action space, transitions, rewards: Key components of an MDP formulation.

- Policy: Mapping from states to actions that maximizes expected cumulative reward. Computed for entire state space.

- Plan: Sequence of states the rover will likely follow. Can be extracted from a policy.

- Optimality vs. computation time: Key trade-off analyzed when comparing MDP solving methods.

Does this summary cover the main keywords and key terms associated with the paper? Let me know if you need any clarification or have additional keywords to add.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. How does the bi-level MDP framework align with existing mission planning practices and enhance explainability and trustworthiness of AI-driven solutions? What specific aspects of the framework contribute to this?

2. The paper mentions that the bi-level MDP framework improves computational tractability while achieving near-optimal policies. What is the theoretical justification for why this improvement in tractability occurs? 

3. What is the time complexity for solving the flat MDP formulation using value iteration? How does this compare to the time complexity for solving the bi-level MDP formulation?

4. What is the trade-off made between global and recursive optimality when using the bi-level MDP framework? How could this trade-off be formalized and analyzed further? 

5. How does the fidelity of the high-level transition function heuristic impact the optimality versus computation time trade-off? Could an "adaptive fidelity" approach be developed?

6. The paper demonstrates improved tractability on discrete state and action spaces. How could the framework be extended to continuous state and action spaces? What new computational challenges might arise?

7. Could a third level be added to the MDP hierarchy to specifically account for safety or robustness considerations? If so, how might this be formulated?

8. What convergence guarantees can be made about the bi-level MDP framework? Can recursive optimality be formally proven?

9. How sensitive is the performance of the bi-level MDP approach to inaccuracies in the mission planning inputs provided by the user? 

10. The paper focuses on a single-rover traversal planning problem. How could the framework be extended to multi-rover planning or human-robot teaming scenarios?
