# [Multi-Task End-to-End Training Improves Conversational Recommendation](https://arxiv.org/abs/2305.06218)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be whether an end-to-end approach using a single transformer model can perform well on both generating natural dialogue and providing good recommendations in a conversational recommendation system, compared to more complex multi-component approaches. The key hypotheses tested are:1) A single unified transformer model can match or exceed the performance of previous multi-component approaches on metrics like BLEU score for dialogue and recall for recommendations. 2) Additional training on tasks like predicting related movies, movie attributes, and generating reviews allows the model to better utilize dialogue details for recommendation and vice versa, which can be measured through targeted probe studies.3) The knowledge gained from the additional training tasks transfers to improved performance on the conversational recommendation task, demonstrating the benefit of multitask learning.So in summary, the central research question is about the viability and potential benefits of an end-to-end conversational recommendation system using a single transformer model trained with multitask learning. The hypotheses focus on comparing performance to previous approaches and testing cross-task knowledge transfer.
