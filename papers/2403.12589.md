# [FootstepNet: an Efficient Actor-Critic Method for Fast On-line Bipedal   Footstep Planning and Forecasting](https://arxiv.org/abs/2403.12589)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- The paper addresses the problem of biped locomotion for humanoid robots in obstacle environments. The challenges include achieving dynamic balance, reaching desired footholds, and generating feasible motions.

Proposed Solution: 
- The paper proposes a modular framework that decomposes the locomotion task into three components:
  A) Autonomous Decision - Determines a path and target footsteps around obstacles using A* search
  B) Footstep Planning - Learns an actor-critic policy to generate a sequence of footsteps to reach the target
  C) Walk Pattern Generator - Plans feasible center of mass trajectories and controls the robot to track them  

- For Footstep Planning, they use a simplified geometric simulation and reinforcement learning approach with shaped rewards based on distance and orientation errors. The returns estimate the number of footsteps to reach the target.

- The Walk Pattern Generator first plans a trajectory using a Linear Inverted Pendulum model and QP optimization for dynamic balance. This is then tracked at the whole-body level through inverse kinematics.

Main Contributions:
- A modular decomposition of locomotion into higher-level planning and low-level control
- A learning-based method to generate footstep sequences in cluttered environments  
- Leveraging returns from the critic to enable efficient decision making
- Achieving reactive obstacle negotiation on a real humanoid robot

The framework is demonstrated on the Sigmaban robot. The simplicity of the shaped rewards allows the footstep policy to generalize well to the real system. This enables efficient foothold adaptation in changing environments.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper proposes a framework for biped locomotion that decomposes the task into autonomous decision making to set a target pose, footstep planning based on reinforcement learning to generate a footsteps sequence, and walk pattern generation to produce whole-body trajectories tracking the footsteps while preserving balance.


## What is the main contribution of this paper?

 Based on the paper, the main contribution seems to be a framework for locomotion control of humanoid robots. The key aspects of this framework are:

1) It decomposes the locomotion task into three modules: 
(A) Autonomous decision - decides on a target pose/footstep for the robot based on environment perception and path planning
(B) Footstep planning - generates a sequence of footsteps to reach the target using a learned actor-critic approach 
(C) Walk pattern generator - converts footsteps to whole-body trajectories and controls the robot

2) The footstep planning module uses reinforcement learning to learn a policy that can efficiently generate footstep sequences to reach a target in the presence of obstacles. This allows the robot to navigate cluttered environments. The simplicity of the reward function allows the returns to estimate the remaining footsteps, enabling efficient decision making.

3) The walk pattern generator uses model-based approaches to generate dynamically balanced whole-body trajectories tracking the planned footsteps. This ensures feasibility on the real robot.

So in summary, the main novelty seems to be the learned footstep policy for efficient navigation, integrated into a complete perception-to-control locomotion framework validated on a real humanoid robot. The modularity and simplicity of the approach also seems to be an important contribution.


## What are the keywords or key terms associated with this paper?

 Based on the content provided, some of the key terms and concepts associated with this paper include:

- Locomotion Framework
- Footstep Planning
- Actor-Critic Reinforcement Learning
- State Space Formulation
- Action Space
- Reward Function
- Walk Pattern Generation
- Linear Inverted Pendulum 
- Quadratic Programming
- Whole-body Control

The paper proposes a locomotion framework that decomposes the task into autonomous decision making, footstep planning using actor-critic reinforcement learning, and walk pattern generation using quadratic programming and whole-body control. Key elements include the state space, action space, reward formulation for footstep planning, and use of simplified models like the linear inverted pendulum for planning dynamically-balanced trajectories.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions I would ask about the method proposed in this paper:

1. The paper mentions that the framework is agnostic to the exact implementation of the Autonomous Decision and Walk Pattern Generator components. Could you provide more details on the specific implementations you used for these components in your experiments? What were the key considerations and tradeoffs?

2. In the Footstep Planning section, you formulate the problem as a Markov Decision Process and use an actor-critic reinforcement learning approach to train the policy. Could you elaborate on why you chose this specific reinforcement learning formulation over other possible approaches? What challenges did you face during training?

3. The state-space representation for Footstep Planning uses several preprocessed versions of the raw state variables (e.g. sigma transforms, sine/cosine encoding). What was the motivation behind these transformations? Did you experiment with other possible state representations before arriving at this one? 

4. Could you walk through an example rollout of the Footstep Planning policy to generate a sequence of footsteps? How many rollout steps do you typically use in practice to generate the full sequence?

5. You mention using a geometrical simulation to train the Footstep Planning policy. What were the key considerations in designing this simulation environment? What abstractions did you make and what challenges did that introduce when transferring the policy to the real robot?

6. In the reward function for Footstep Planning, you incorporate weighted terms for distance/orientation error and collisions. How did you arrive at the specific weight values? Did you perform any sensitivity analysis or tuning experiments?

7. The Walk Pattern Generator utilizes a Linear Inverted Pendulum approximation of the robot dynamics. Why was this simplification useful? In what scenarios does this approximation break down and how do you overcome that?  

8. For the Walk Pattern Generator control, you mention using PID control for joint trajectory tracking. Why did you choose PID control over other options such as computed torque control or model predictive control?

9. The overall pipeline involves planning/control at multiple timescales - path planning, 25Hz COM trajectory optimization and 200Hz inverse kinematics. What were the considerations around coordinating these different rates? 

10. You mention the framework is evaluated on the Sigmaban humanoid robot. What modifications, if any, were required to get the system to work on the real robotic hardware compared to the simulation environment used for training Footstep Planning?
