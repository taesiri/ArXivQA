# [Labels Need Prompts Too Mask Matching for Natural Language Understanding   Tasks](https://arxiv.org/abs/2312.08726)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of the paper:

This paper proposes Mask Matching, a new paradigm for natural language understanding (NLU) tasks that performs prompting on both the input text and label sides. Specifically, an input-prompt is added to the input text with a mask token, and a label-prompt is created for each label containing another mask token. Representations are generated for the input mask token and each label mask token. Then predictions are made by computing similarity between the input mask representation and each label mask representation, with cross-entropy loss optimized. This allows Mask Matching to leverage the semantic information within textual label names, avoiding the need to manually construct label verbalizers as in prompt tuning methods. Experiments on 8 NLU tasks with 14 datasets demonstrate Mask Matching substantially outperforms fine-tuning and prompt-tuning baselines. The method performs particularly well when label counts are large and label names are informative. Mask Matching achieves competitive or superior performance to state-of-the-art task-specific models on several datasets. Analyses also show the approach is effective under low-resource scenarios. The paper discusses open issues to further improve Mask Matching, such as better designs for paired-input tasks, automatically extending label names, and exploring multiple mask tokens. Overall, Mask Matching offers a simple yet powerful new paradigm for diverse NLU tasks that merit future research directions in label-side prompting.
