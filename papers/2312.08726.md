# [Labels Need Prompts Too Mask Matching for Natural Language Understanding   Tasks](https://arxiv.org/abs/2312.08726)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of the paper:

This paper proposes Mask Matching, a new paradigm for natural language understanding (NLU) tasks that performs prompting on both the input text and label sides. Specifically, an input-prompt is added to the input text with a mask token, and a label-prompt is created for each label containing another mask token. Representations are generated for the input mask token and each label mask token. Then predictions are made by computing similarity between the input mask representation and each label mask representation, with cross-entropy loss optimized. This allows Mask Matching to leverage the semantic information within textual label names, avoiding the need to manually construct label verbalizers as in prompt tuning methods. Experiments on 8 NLU tasks with 14 datasets demonstrate Mask Matching substantially outperforms fine-tuning and prompt-tuning baselines. The method performs particularly well when label counts are large and label names are informative. Mask Matching achieves competitive or superior performance to state-of-the-art task-specific models on several datasets. Analyses also show the approach is effective under low-resource scenarios. The paper discusses open issues to further improve Mask Matching, such as better designs for paired-input tasks, automatically extending label names, and exploring multiple mask tokens. Overall, Mask Matching offers a simple yet powerful new paradigm for diverse NLU tasks that merit future research directions in label-side prompting.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Labels Need Prompts Too: Mask Matching for Natural Language Understanding Tasks":

Problem:
- Existing methods for natural language understanding (NLU) tasks either do not fully utilize the semantic information in textual label descriptions, or require extensive manual effort to design label verbalizers. 

- Semantic matching methods can exploit label semantics but rely heavily on label representations generated by simple pooling, which may not be optimal. 

- Prompt-tuning requires carefully designing label words/verbalizers, which is difficult for tasks with many labels.

Proposed Solution:
- Propose "Mask Matching", which incorporates prompting methodology on both the input and label sides. 

- An input prompt and label prompt with mask tokens are constructed. The input and label are encoded by the prompt, and a match is made between the resulting mask representations for prediction.

- This allows exploiting label semantics without any verbalizer engineering, by matching rich mask representations of inputs and labels.

Main Contributions:

- Propose Mask Matching as a new NLU paradigm that performs prompting on both input and label sides and makes predictions by matching mask representations.

- Show strong performance improvements over fine-tuning and prompt-tuning baselines over 8 NLU tasks and 14 datasets.

- Achieve competitive or better performance than recent state-of-the-art methods on several benchmarks. 

- Demonstrate particular benefits when label space is large and label names are informative.

- Provide an analysis of the paradigm and discuss future research directions to build upon mask matching on the label side.

In summary, the paper presents Mask Matching as a way to exploit label semantics without extra annotation effort, analyses its effectiveness, and sets the stage for future work on label-side prompting.
