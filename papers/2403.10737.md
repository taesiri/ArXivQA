# [Leveraging Synthetic Data for Generalizable and Fair Facial Action Unit   Detection](https://arxiv.org/abs/2403.10737)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Facial action unit (AU) detection is fundamental for facial expression analysis. Current supervised learning methods require large labeled datasets which are costly. 
- Existing AU detection datasets have limited diversity, especially in terms of gender distribution, resulting in bias and unfairness.

Proposed Solution: 
- Generate a diverse and balanced synthetic dataset through facial expression re-targeting. Specifically, transfer expressions from real videos in BP4D dataset to 60 synthetic avatars.
- Propose a multi-source domain adaptation method called Paired Moment Matching (PM2) to transfer knowledge from real and synthetic source domains to unlabeled target domains (DISFA and GFT).
- Instead of aligning overall feature distributions, PM2 aligns features of paired real and synthetic images with same expression. Each real image is paired with a female and male synthetic image. This maintains AU boundaries and improves fairness.

Main Contributions:
- Release a large-scale diverse and balanced synthetic AU dataset with 214K images of 60 avatars.
- Propose PM2 for feature alignment using paired real-syn images to improve generalization and fairness.
- Experiments show the synthetic data and PM2 improve both AU detection performance and fairness across datasets and genders.

In summary, the paper generates a synthetic dataset to address data scarcity and imbalance issues in AU detection. A multi-source domain adaptation method is also proposed to transfer knowledge from real and synthetic datasets to unlabeled target datasets for better generalization and fairness.
