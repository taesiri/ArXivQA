# [Compression Repair for Feedforward Neural Networks Based on Model   Equivalence Evaluation](https://arxiv.org/abs/2402.11737)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Neural network compression (e.g. pruning, quantization) can significantly reduce the size and computational cost of models, but often harms accuracy.
- There is a need for methods to repair the accuracy loss induced by compression techniques.

Proposed Solution:
- Develop a framework to evaluate the equivalence between an original neural network (FNN) and its compressed version in terms of output discrepancy. 
- Propose a novel "merged network" construction to enable quantitative discrepancy analysis between two FNNs using reachability analysis.
- Formulate an optimization problem for repairing the compressed network to minimize its discrepancy from the original FNN.
- Present an algorithmic framework that:
  (1) computes output discrepancy 
  (2) generates retraining data
  (3) retrains the compressed network
  (4) repeats until discrepancy meets requirements

Main Contributions:
- A novel way to construct a "merged network" to quantify discrepancy between two FNNs using reachability analysis.
- A problem formulation and algorithmic framework for repairing compressed FNNs to restore accuracy lost during compression. 
- Demonstrated the effectiveness of the proposed compressed FNN repair method on MNIST classification, showing improved accuracy and reduced discrepancy compared to the uncompressed original model.

In summary, the key innovation is in enabling quantitative analysis of model equivalence after compression via reachability analysis on a merged network, based on which an iterative method is proposed to appropriately retrain the compressed model to minimize its deviation from the original uncompressed model.
