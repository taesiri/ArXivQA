# [Knowledge-Driven Modulation of Neural Networks with Attention Mechanism   for Next Activity Prediction](https://arxiv.org/abs/2312.08847)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed summary paragraph of the key points from the paper:

This paper proposes a Symbolic[Neuro] system for next activity prediction (NAP) that integrates neural networks with attention mechanisms (NN) with background knowledge in the form of a procedural process model (a Petri net model). The approach addresses under-sampled trace variants in the test set by modulating the NN probability scores with a compliance score between the predicted activities and the Petri net, using a beam search algorithm. Rather than a binary compliance check at the end like prior approaches, the proposed method continuously modulates the NN predictions during the construction of the predicted suffix, allowing the background knowledge to guide the beam search. Experiments on synthetic and real-life logs showed situations where this knowledge-guided modulation significantly improved NAP performance, especially for exceptional executions. The method allows effective use of procedural models as background knowledge, rather than just declarative constraints. The combination of attention-based NNs with guided modulation enables precise NAP in scenarios with concept drifts, where variants become more frequent than seen during training. This Symbolic[Neuro] approach advances the state-of-the-art in effectively leveraging background knowledge for improved predictive process monitoring.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Predictive process monitoring aims to predict the future path of ongoing process executions. Neural networks (NNs) have shown promising results for next activity prediction (NAP), but struggle with predicting infrequent variants that are under-sampled in the training data. This is problematic for exceptional situations or concept drifts when such variants become more frequent.

- Existing work uses background knowledge to filter predicted suffixes after prediction, but this is limited to declarative models and boolean compliance checks. There is no integration of procedural models or fuzzy compliance metrics to guide neural predictions.

Proposed Solution:
- The paper proposes a Symbolic[Neuro] system for NAP based on NNs with attention mechanism. 

- It encodes traces as numeric vectors for the NN. The NN with stacked encoder-decoder layers and multi-head self-attention is trained on a prefix log.

- A beam search explores possible suffix predictions, combining both the NN's scores and a fuzzy compliance score between suffix candidates and a Petri net procedural model. The compliance function modulates the NN's predictions during search.

- This allows procedural background knowledge to offset NN under-sampling and drive the prediction toward more compliant suffixes. The approach is configurable between NN-focused and model-focused through a weighting parameter.

Contributions:
- Novel integration of procedural background knowledge into neural prediction using fuzzy compliance scores.

- Modulation of NN predictions during beam search exploration instead of crisp filtering afterwards.

- First application of attention-based NNs for next activity and suffix prediction.

- Evaluation on synthetic and real-life logs shows significant improvement in predicting infrequent variants by leveraging background knowledge.
