# [An Empirical Study of Parameter Efficient Fine-tuning on Vision-Language   Pre-train Model](https://arxiv.org/abs/2403.08433)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Vision-language pre-training (VLP) models require fine-tuning to adapt them to downstream tasks. Full fine-tuning is costly as it updates all parameters.  
- Parameter Efficient Fine-Tuning (PEFT) methods only update a small subset of parameters, improving efficiency. 
- Intuitively, the performance of PEFT methods seems like it should increase with more training data and more fine-tuned parameters. 

Proposed Solution
- Empirically evaluate 5 different PEFT methods (prompt-tuning, prefix-tuning, LoRA, serial adapter, parallel adapter) on 2 vision-language downstream tasks.
- Tasks are image captioning (consistent with VLP pre-training) using MSCOCO and visual question answering (inconsistent) using VQAv2.
- Vary the amount of training data and number of fine-tuned parameters to study their impact.

Key Observations
- When task is inconsistent with pre-training, performance improves with more data and parameters, as expected.  
- When task is consistent with pre-training, data amount does NOT affect performance. And there is an optimal number of fine-tuned parameters. Too many can overfit.
- Layer composition PEFTs (LoRA, adapters) achieve better performance and efficiency than embedding composition (prompts, prefixes).

Main Contributions  
- First empirical study showing data/parameters affect PEFT methods differently depending on consistency with pre-training.
- Demonstrates layer composition PEFTs are most effective for adapting VLP models.
- Findings provide insights into choosing training strategies for PEFT methods.
