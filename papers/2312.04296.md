# [Cross-codex Learning for Reliable Scribe Identification in Medieval   Manuscripts](https://arxiv.org/abs/2312.04296)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper demonstrates the importance of cross-codex training data for reliable CNN-based text-independent off-line scribe identification of medieval manuscripts. Using a dataset of 25,200 lines across 7 scribes and 31 Carolingian codices, they show that preprocessing inputs as masked grayscale images instead of RGB clearly improves classification performance. Comparing CNN architectures, AlexNet provided the best tradeoff between accuracy (F1 scores up to 0.96 on line level) and efficiency. A key finding is that without cross-codex data, models learn codex-specific features rather than meaningful scribe characteristics. Implementing a reject option for low-confidence predictions further improved results. Overall, the authors reliably replicate paleographic expert assignments, even revealing likely labeling errors and making predictions on sections with unknown scribes. This demonstrates the feasibility of precise automatic scribe classification, enabling large-scale paleographic analysis for new insights into medieval scriptoria relationships and codex provenance.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

This paper demonstrates the importance of cross-codex training data and using standard CNN architectures for reliable automatic identification of medieval scribes in the uniform Carolingian minuscule script by achieving high accuracy in classifying scribes across 31 historic codices.


## What is the main contribution of this paper?

 The paper makes three main contributions:

1. It demonstrates the importance of using cross-codex (across multiple books/codices) training data for building CNN models to identify medieval scribes. This helps prevent the models from just learning codex-specific features rather than scribe-specific features. 

2. It shows that standard CNN architectures like AlexNet can reliably identify scribes in medieval manuscripts, achieving high F1 scores. This challenges previous findings that specialized model architectures were necessary.

3. It presents results on a large-scale open source dataset of medieval manuscripts (the Codex Claustroneoburgensis database with 51 codices and over 17,000 pages). Prior work tended to use much smaller datasets. This facilitates more comprehensive studies on automatic scribe identification.

In summary, the key contribution is using cross-codex training data with standard CNNs to enable robust and scalable scribe identification in medieval manuscripts. This can unlock new research opportunities in paleography.


## What are the keywords or key terms associated with this paper?

 Based on my analysis of the paper, some of the main keywords and key terms associated with this research include:

- Scribe identification
- Deep learning
- Computer vision 
- Digital humanities
- Carolingian minuscule
- Cross-codex learning
- Convolutional neural networks (CNNs)
- Paleography
- Handwritten text recognition
- Medieval manuscripts

The paper focuses on using deep learning and CNNs for automatic scribe identification in medieval manuscripts written in the Carolingian minuscule script. Key aspects explored are cross-codex learning to overcome codex/book specific overfitting and reliably identifying scribes across multiple books. The goal is to develop automated methods to assist paleography experts in analyzing large collections of medieval manuscripts in the field of digital humanities. Some other terms featured prominently are preprocessing using masked grayscale images, comparing neural network architectures like AlexNet, calculating confidence scores to deal with uncertainty, and using a reject option to improve predictions.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper mentions using cross-codex training data is important to avoid overfitting on book-specific features. Can you expand more on why this cross-codex data is so critical for reliable scribe identification? What would be the downsides of just using data from a single codex?

2. The paper evaluated several CNN architectures for scribe classification. Why did AlexNet provide the best tradeoff between accuracy and efficiency compared to more recent CNNs like ResNet and DenseNet? What are some weaknesses of AlexNet that could be improved upon? 

3. The use of masked grayscale images provided a significant boost in accuracy over just using RGB images. Can you explain in more detail how the masking process works and why it helps the CNN focus more on writing style features rather than ink/parchment variations?

4. The paper mentions the potential to use the CNN predictions to identify errors or uncertainties in the original paleographer scribe assignments. Can you elaborate on how the confidence scores from the CNN could indicate such errors or uncertainties?

5. For the scribes with low F1 scores on the test set, the paper hypothesizes the paleographer labels may be incorrect. What further analysis could be done to confirm whether the CNN or paleographer made an error in those cases?

6. The reject option improved results by eliminating low-confidence predictions. How exactly is the reject threshold level determined based on the error-reject curve analysis? What are the tradeoffs in setting this threshold?

7. What role could active learning play in an iterative pipeline that alternates between expert paleographer input and retraining the CNN? What metrics could determine which data should be sent to the expert for labelling?  

8. For predicting unknown scribes in Section 4.5, what could explain the more diffuse classifications for some sections? How might the CNN model be enhanced to produce more decisive predictions?

9. How suitable do you think this line-based classification approach would be for other medieval scripts beyond Carolingian minuscule? What adjustments might be needed?

10. The paper mentions the limitations of the segmentation method. Can you suggest any modern segmentation or layout analysis techniques that could better handle the complex page layouts and noise in these historical manuscripts?


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Historic scribe identification in medieval manuscripts is important to understand the organization of scriptoria and relationships between monasteries. 
- It is a tedious manual task that requires paleography expertise. 
- Existing automated approaches use limited datasets from only a few codices or wide time periods, making cross-codex training difficult.

Proposed Solution:
- The authors compile a large paleography dataset (CCl-DB) of 17071 pages from 51 codices written in late 12th century Carolingian minuscule with scribe assignments from experts.
- They extract a subset with 25200 lines from 31 codices over 7 scribes that contributed to multiple codices to allow cross-codex training.  
- They preprocess the line images into masked grayscale patches and train CNNs to classify the scribes. 
- They compare several CNN architectures and find AlexNet provides the best tradeoff of accuracy and efficiency.

Main Contributions:
- Demonstrate necessity of cross-codex training data to avoid codex-specific overfitting. Masked grayscale input performs much better than RGB.
- Show that standard CNN architectures can reliably identify medieval scribes, achieving high F1 scores on line and page level classification.
- Present analysis on large paleography dataset CCl-DB. Model predictions indicate potential errors in expert scribe assignments.
- Proposed approach enables large-scale automated scribe analysis to gain new insights into medieval scriptoria relationships and organization.

In summary, the key innovation is using cross-codex training data from a large paleography dataset to train CNNs to reliably reproduce expert scribe assignments in medieval manuscripts, despite uniform writing style. This enables new research at much wider scale.
