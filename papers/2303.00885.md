# [Towards Trustable Skin Cancer Diagnosis via Rewriting Model's Decision](https://arxiv.org/abs/2303.00885)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we improve the trustworthiness and robustness of skin cancer diagnosis models by discovering and removing confounding factors that the models may rely on, through a human-in-the-loop approach?The key points are:- Deep learning models for skin cancer diagnosis can rely on confounding factors like image artifacts or bias rather than clinically relevant features, making their decisions untrustworthy. - The authors propose a framework to make models more explainable via concept mapping, allow human users to identify confounding behaviors, and enable interaction to correct the model's logic.- They introduce a new dataset called ConfDerm to systematically evaluate model trustworthiness under controlled confounding factors.- Experiments show their method can effectively detect and mitigate confounding factors without prior knowledge about the data, improving model performance on clinically-relevant concepts.So in summary, the main hypothesis is that involving humans in the loop to identify and correct confounding model behaviors can improve the trustworthiness and robustness of skin cancer diagnosis systems. The ConfDerm dataset and experiments are designed to validate this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the paper, here are the main contributions:1. The paper proposes a human-in-the-loop framework to improve the trustworthiness of skin cancer diagnosis models. The key ideas are to make the model explainable via concept mapping, allow humans to identify confounding behaviors, and enable humans to correct the model's logic through interaction. 2. The paper introduces a new confounded skin lesion dataset called ConfDerm for systematically evaluating model trustworthiness. This dataset contains real images with controlled confounding factors in the training set, allowing rigorous analysis of model behaviors.3. Through spectral relevance analysis on public datasets like ISIC, the paper reveals that deep learning models can be confounded by artifacts like dark corners, rulers, and hairs. This provides new insights into model weaknesses in skin lesion analysis.4. The proposed human-in-the-loop framework is shown empirically to be effective in removing confounding factors and improving performance across different testing distributions. Experiments on ConfDerm and other public datasets demonstrate the ability to debias and enhance model trustworthiness.5. The method does not require full concept annotations or prior knowledge about the concepts. It can discover and learn confounding concepts automatically and enable human interaction through simple first-order logic rules. This makes the framework more practical.In summary, the core contribution is a human-in-the-loop approach to improving model trustworthiness in skin cancer diagnosis, with empirical validation on new datasets. The insights into model confounding factors and the ability to interactively debias the models are important for deploying trustworthy AI systems in healthcare.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a human-in-the-loop framework to improve the trustworthiness of skin cancer diagnosis models by discovering and removing confounding factors like image artifacts or bias via concept mapping and logical rule rewriting during the training process.


## How does this paper compare to other research in the same field?

This paper focuses on improving the trustworthiness and reliability of skin cancer diagnosis models through detecting and removing confounding factors that can bias the models. Here are some key ways it compares to other research in this field:- Explainability: It uses concept-based explanations to provide human-understandable interpretations of the model's decision process, rather than pixel-level attribution maps like CAMs. This allows better understanding of model behaviors.- Concept learning: It discovers confounding concepts by analyzing model co-occurrence behaviors on datasets directly, without needing full concept annotations upfront like some prior works. This makes it more flexible.- Interaction: It allows human-in-the-loop interaction to correct model behaviors via first-order logic rules on the concept space. This enables customized debiasing. - Evaluation: It systematically evaluates on a novel ConfDerm dataset designed specifically to analyze confounding factors. Most prior work lacks such rigorous evaluation.- Applications: It focuses on the critical task of skin cancer diagnosis. Most related work has examined confounding factors in more general image classification domains.Overall, a key distinction is the human-centered approach to promote trustworthiness in medical AI systems. The concept-based explanations, flexible discovery of confounds, and human-in-the-loop interaction for debiasing make this work uniquely well-suited to improving reliability in sensitive applications like cancer diagnosis versus more generic debiasing techniques. The new ConfDerm benchmark is also an important contribution for rigorously evaluating model biases in this space.
