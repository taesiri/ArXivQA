# [Towards Trustable Skin Cancer Diagnosis via Rewriting Model's Decision](https://arxiv.org/abs/2303.00885)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we improve the trustworthiness and robustness of skin cancer diagnosis models by discovering and removing confounding factors that the models may rely on, through a human-in-the-loop approach?The key points are:- Deep learning models for skin cancer diagnosis can rely on confounding factors like image artifacts or bias rather than clinically relevant features, making their decisions untrustworthy. - The authors propose a framework to make models more explainable via concept mapping, allow human users to identify confounding behaviors, and enable interaction to correct the model's logic.- They introduce a new dataset called ConfDerm to systematically evaluate model trustworthiness under controlled confounding factors.- Experiments show their method can effectively detect and mitigate confounding factors without prior knowledge about the data, improving model performance on clinically-relevant concepts.So in summary, the main hypothesis is that involving humans in the loop to identify and correct confounding model behaviors can improve the trustworthiness and robustness of skin cancer diagnosis systems. The ConfDerm dataset and experiments are designed to validate this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the paper, here are the main contributions:1. The paper proposes a human-in-the-loop framework to improve the trustworthiness of skin cancer diagnosis models. The key ideas are to make the model explainable via concept mapping, allow humans to identify confounding behaviors, and enable humans to correct the model's logic through interaction. 2. The paper introduces a new confounded skin lesion dataset called ConfDerm for systematically evaluating model trustworthiness. This dataset contains real images with controlled confounding factors in the training set, allowing rigorous analysis of model behaviors.3. Through spectral relevance analysis on public datasets like ISIC, the paper reveals that deep learning models can be confounded by artifacts like dark corners, rulers, and hairs. This provides new insights into model weaknesses in skin lesion analysis.4. The proposed human-in-the-loop framework is shown empirically to be effective in removing confounding factors and improving performance across different testing distributions. Experiments on ConfDerm and other public datasets demonstrate the ability to debias and enhance model trustworthiness.5. The method does not require full concept annotations or prior knowledge about the concepts. It can discover and learn confounding concepts automatically and enable human interaction through simple first-order logic rules. This makes the framework more practical.In summary, the core contribution is a human-in-the-loop approach to improving model trustworthiness in skin cancer diagnosis, with empirical validation on new datasets. The insights into model confounding factors and the ability to interactively debias the models are important for deploying trustworthy AI systems in healthcare.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a human-in-the-loop framework to improve the trustworthiness of skin cancer diagnosis models by discovering and removing confounding factors like image artifacts or bias via concept mapping and logical rule rewriting during the training process.


## How does this paper compare to other research in the same field?

This paper focuses on improving the trustworthiness and reliability of skin cancer diagnosis models through detecting and removing confounding factors that can bias the models. Here are some key ways it compares to other research in this field:- Explainability: It uses concept-based explanations to provide human-understandable interpretations of the model's decision process, rather than pixel-level attribution maps like CAMs. This allows better understanding of model behaviors.- Concept learning: It discovers confounding concepts by analyzing model co-occurrence behaviors on datasets directly, without needing full concept annotations upfront like some prior works. This makes it more flexible.- Interaction: It allows human-in-the-loop interaction to correct model behaviors via first-order logic rules on the concept space. This enables customized debiasing. - Evaluation: It systematically evaluates on a novel ConfDerm dataset designed specifically to analyze confounding factors. Most prior work lacks such rigorous evaluation.- Applications: It focuses on the critical task of skin cancer diagnosis. Most related work has examined confounding factors in more general image classification domains.Overall, a key distinction is the human-centered approach to promote trustworthiness in medical AI systems. The concept-based explanations, flexible discovery of confounds, and human-in-the-loop interaction for debiasing make this work uniquely well-suited to improving reliability in sensitive applications like cancer diagnosis versus more generic debiasing techniques. The new ConfDerm benchmark is also an important contribution for rigorously evaluating model biases in this space.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Developing more robust algorithms and evaluation metrics for spectral relevance analysis to better handle noise and discover more fine-grained concepts. The current algorithm still relies heavily on the quality of heatmaps and clustering.- Expanding the concept bank with more clinical concepts defined by medical experts to cover more fine-grained clinical criteria. This could improve the explainability and faithfulness of the model. - Conducting more systematic evaluation on larger datasets to validate the effectiveness of the proposed method. The authors crafted a new dataset ConfDerm, but more evaluation on other public datasets would be useful.- Exploring different ways to model the relationship between concepts for the explainable logic layer, such as logical formulas or decision trees. The current method uses a simple weighted sum.- Investigating interactive learning with dynamic concept discovery and more advanced human-AI collaboration. The current work uses predefined concepts and simple global logic rules. Allowing users to introduce new concepts could be an interesting direction.- Applying the approach to other interpretability tasks beyond classification such as segmentation or detection. Concept-based explanations may also help build trust in other medical AI applications.- Validating the method for real clinical deployment, showing efficacy in actual usage by doctors and improvements in patient outcomes. Testing on live clinical systems would be important future work.In summary, the main future directions focus on improving the robustness of concept discovery, expanding the concept bank, conducting more systematic evaluation, exploring different explainable logic modeling, advancing human-AI interaction, and clinical validation. Overall, it's a promising approach to improve trust in medical AI systems.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper proposes a human-in-the-loop framework to improve the trustworthiness of skin cancer diagnosis models. The authors find that modern deep learning models for skin cancer diagnosis can be confounded by irrelevant artifacts in the training data like rulers, dark corners, and hairs. To address this, they introduce a method to discover these confounding factors by analyzing the co-occurrence patterns in the training data using spectral clustering on GradCAM visualizations. They then build a concept bank with clinical concepts and the discovered confounding concepts, and project the model's features onto this concept space to make the model interpretable. The key idea is that they add an interactable logic layer on top that allows human users to provide feedback to the model by specifying rules about which concepts it should or should not focus on. For example, users can specify that the model should not focus on "rulers" to remove this confounding factor. They create a new dataset called ConfDerm to systematically evaluate model robustness to different confounding factors, and show improved performance and trustworthiness compared to baseline models without the human-in-the-loop interaction. The main strengths are the method's ability to discover and remove confounding factors without needing any prior concept annotations, and the interaction mechanism that allows users to rewrite the model's logic.
