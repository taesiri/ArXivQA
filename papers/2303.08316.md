# [MSF: Motion-guided Sequential Fusion for Efficient 3D Object Detection   from Point Cloud Sequences](https://arxiv.org/abs/2303.08316)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to efficiently fuse multi-frame point clouds to improve 3D object detection. The key points are:- Current multi-frame detectors follow a "Detect-and-Fuse" framework, which extracts features independently from each frame and fuses them. This leads to redundant computation and reliance on preceding frames. - The authors propose a Motion-guided Sequential Fusion (MSF) method to address this. MSF generates proposals only on the current frame and propagates them to preceding frames to sample useful points. This reduces redundancy and reliance on preceding frames.- MSF uses a novel Bidirectional Feature Aggregation (BiFA) module to facilitate information exchange between proposals across frames, capturing long-term dependencies. - They also optimize the point cloud pooling process with voxel sampling, allowing efficient processing of large-scale point clouds.In summary, the central hypothesis is that by propagating proposals across frames rather than detecting each frame independently, and fusing features bidirectionally at the proposal-level, MSF can achieve efficient and accurate 3D detection from point cloud sequences.


## What is the main contribution of this paper?

The main contributions of this paper are:- It proposes an efficient Motion-guided Sequential Fusion (MSF) method for 3D object detection from point cloud sequences. Unlike previous methods that process each frame independently, MSF only generates proposals on the current frame and propagates them to preceding frames to extract useful features from the sequence. This reduces redundant computations and reliance on preceding frames.- It introduces a Bidirectional Feature Aggregation (BiFA) module to facilitate interaction between proposal features across frames and capture long-term dependencies in the sequence. - It optimizes the point cloud pooling process with a voxel sampling technique, allowing efficient processing of millions of points from the sequence in just milliseconds.- The proposed MSF method achieves state-of-the-art accuracy on the challenging Waymo Open Dataset while being more efficient than other multi-frame detectors.In summary, the main contribution is an efficient and accurate approach for 3D object detection from point cloud sequences, which exploits motion information to extract useful contexts from the sequence and enables efficient region-level fusion across frames. The optimized point cloud pooling further improves the efficiency.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes an efficient Motion-guided Sequential Fusion (MSF) method for 3D object detection that propagates proposals from the current frame to preceding frames based on estimated velocities, samples useful points from the sequence, and refines the proposals using a region-based network with a novel Bidirectional Feature Aggregation module to capture spatial details and temporal dependencies.
