# [Classes Are Not Equal: An Empirical Study on Image Recognition Fairness](https://arxiv.org/abs/2402.18133)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Classes Are Not Equal: An Empirical Study on Image Recognition Fairness":

Problem:
- The paper identifies a significant fairness issue in image classification models, even when trained on balanced datasets like ImageNet. Specifically, some classes can achieve near 100% accuracy while others have very poor accuracy (as low as 16%).  
- This means models exhibit extreme performance disparity on certain classes, despite having equal samples per class.
- The authors note most prior work focuses on overall accuracy gains and ignores per-class performance. This fairness issue has received little attention.

Key Insights:
- Analyzing common techniques like classifier weight norms shows this is not a classifier bias issue as in long-tail learning.
- Instead, problematic representations are the key factor, confirmed via kNN and ETF classifier experiments.
- The concept of "model prediction bias" is introduced - harder classes see more bias towards them, unlike long-tail.
- Hard classes have more diverse features so more potential for confusion with other classes during training.

Solutions:
- Data augmentations like Mixup, CutMix improve fairness while boosting overall accuracy. Gains are larger on hard classes.  
- Representation learning techniques like contrastive learning and masked modeling also help fairness.
- Re-weighting improves hard class accuracy but worsens easy classes, with no overall gain.

Main Contributions:
- Identifying and empirically demonstrating the prevalence of fairness issues in image classification models, even on balanced datasets
- Analyzing root causes - ruling out classifier bias and highlighting problematic representations 
- Introducing model prediction bias concept and showing harder classes see more bias
- Studying various techniques' impact on fairness - augmentations and representation learning help while reweighting does not

The key message is that significant class imbalances can exist even with balanced data. Techniques focusing solely on overall accuracy may neglect fairness issues. Representation learning is key to improving fairness.
