# Generated Knowledge Prompting for Commonsense Reasoning

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the main research question this paper seeks to address is: Can extracting and prompting relevant knowledge statements from language models improve their performance on commonsense reasoning tasks, even without additional training or access to knowledge bases? The key hypothesis appears to be that generating task-relevant knowledge statements from language models and providing them as prompts can enhance the models' reasoning capabilities. The paper investigates whether this knowledge prompting approach can boost performance on commonsense reasoning benchmarks, compared to using the vanilla models or methods relying on external knowledge sources.In summary, the central research question is whether eliciting symbolic knowledge statements from language models themselves, and prompting the models with this knowledge during inference, can improve commonsense reasoning - even on top of large pretrained models and without extra training or knowledge bases. The paper aims to test this hypothesis across different commonsense reasoning datasets and models.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method called Generated Knowledge Prompting to improve commonsense reasoning performance of language models. The key ideas are:- Generate knowledge statements from a language model by conditioning on human-written few-shot demonstrations of question-knowledge pairs for a given task. This allows eliciting helpful knowledge flexibly beyond pre-defined templates.- Prompt an inference language model with the generated knowledge statements and select the prediction from the prompt that results in highest confidence. This allows integrating knowledge without finetuning the inference model. - The proposed method sets new state-of-the-art results on several commonsense reasoning benchmarks by improving both zero-shot and finetuned inference models.- Analysis shows the method's effectiveness comes from high quality and quantity of generated knowledge, as well as the strategy for integrating knowledge into the inference model.- The method highlights the value of symbolic knowledge representation for improving neural network reasoning, even when the knowledge is generated by the models themselves.In summary, the key contribution is proposing a simple yet effective approach to leverage knowledge flexibly elicited from language models themselves to improve commonsense reasoning, without requiring finetuning or access to knowledge bases. The effectiveness is empirically shown across diverse reasoning tasks and models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a method called generated knowledge prompting that improves commonsense reasoning by using a language model to generate helpful knowledge statements based on question demonstrations, then selecting the knowledge that results in the highest-confidence prediction.


## How does this paper compare to other research in the same field?

Here are some key points comparing this paper to other related research on external knowledge for commonsense reasoning:- Unlike many prior works that incorporate knowledge via finetuning or joint training, this paper uses a simple prompt-based method that does not require any model finetuning. This makes the approach easy to apply to new models and tasks. - Compared to prior prompt-based methods like self-talk and contrastive explanations, this work can generate more flexible knowledge beyond a fixed set of templates. The key is using human demonstrations to show the model examples of desired knowledge.- The paper shows strong gains over baseline models, achieving state-of-the-art on several commonsense reasoning benchmarks. The improvements are shown to be due to the quality and diversity of generated knowledge.- Retrieval-based knowledge methods rely on the existence of an appropriate external knowledge source. This paper's generation-based approach does not need a separate knowledge base and works well even without one.- Analysis shows the method is especially effective for smaller models, enabling lightweight yet accurate reasoning. The knowledge also appears to amplify knowledge already within a model. - Human evaluation and examples demonstrate the knowledge reduces commonsense reasoning to more explicit forms of reasoning supported by language models. This highlights the role of symbolic knowledge in neural reasoning.In summary, this work makes progress on flexible and effective integration of external knowledge into language models for commonsense reasoning. The human-guided prompting approach and analysis provide useful insights for knowledge-enhanced reasoning.
