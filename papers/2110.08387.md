# Generated Knowledge Prompting for Commonsense Reasoning

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the main research question this paper seeks to address is: Can extracting and prompting relevant knowledge statements from language models improve their performance on commonsense reasoning tasks, even without additional training or access to knowledge bases? The key hypothesis appears to be that generating task-relevant knowledge statements from language models and providing them as prompts can enhance the models' reasoning capabilities. The paper investigates whether this knowledge prompting approach can boost performance on commonsense reasoning benchmarks, compared to using the vanilla models or methods relying on external knowledge sources.In summary, the central research question is whether eliciting symbolic knowledge statements from language models themselves, and prompting the models with this knowledge during inference, can improve commonsense reasoning - even on top of large pretrained models and without extra training or knowledge bases. The paper aims to test this hypothesis across different commonsense reasoning datasets and models.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method called Generated Knowledge Prompting to improve commonsense reasoning performance of language models. The key ideas are:- Generate knowledge statements from a language model by conditioning on human-written few-shot demonstrations of question-knowledge pairs for a given task. This allows eliciting helpful knowledge flexibly beyond pre-defined templates.- Prompt an inference language model with the generated knowledge statements and select the prediction from the prompt that results in highest confidence. This allows integrating knowledge without finetuning the inference model. - The proposed method sets new state-of-the-art results on several commonsense reasoning benchmarks by improving both zero-shot and finetuned inference models.- Analysis shows the method's effectiveness comes from high quality and quantity of generated knowledge, as well as the strategy for integrating knowledge into the inference model.- The method highlights the value of symbolic knowledge representation for improving neural network reasoning, even when the knowledge is generated by the models themselves.In summary, the key contribution is proposing a simple yet effective approach to leverage knowledge flexibly elicited from language models themselves to improve commonsense reasoning, without requiring finetuning or access to knowledge bases. The effectiveness is empirically shown across diverse reasoning tasks and models.
