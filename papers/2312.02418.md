# [Decoding Data Quality via Synthetic Corruptions: Embedding-guided   Pruning of Code Data](https://arxiv.org/abs/2312.02418)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the paper:

This paper explores methods for identifying and removing low-quality code data from large datasets in order to improve the efficiency and performance of code-generating language models. The key innovation is the use of synthetically corrupted data to understand how different types of errors manifest in the embedding space of a pretrained model. Specifically, the introduction of syntactic errors tends to shift examples into smaller clusters farther from centroids compared to the original data. Leveraging this insight, the authors develop a two-stage pruning approach, first removing data points assigned to small clusters then points distant from centroids. Evaluated on the HumanEval and MBPP benchmarks, this synthetic corruption informed pruning (SCIP) method outperforms prior embedding-based techniques and even slightly exceeds the performance of no pruning, demonstrating the promise of learning signals from controlled data corruption. The ability to methodically characterize low-quality examples could not only enhance code models but may also extend to improving language models more broadly.
