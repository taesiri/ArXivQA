# [System-status-aware Adaptive Network for Online Streaming Video   Understanding](https://arxiv.org/abs/2303.15742)

## What is the central research question or hypothesis that this paper addresses?

 The central research question addressed in this paper is how to design an efficient deep neural network that can perform online video understanding tasks (e.g. action recognition, pose estimation) with low latency on devices with fluctuating computational resources. 

The key hypothesis is that an adaptive network that jointly considers both the input video stream and the real-time system status of the host device can maintain high accuracy with low delay, even when the available computational resources vary over time.

Specifically, the paper proposes a System-status-aware Adaptive Network (SAN) that has two main components:

1) A lightweight agent module that generates a dynamic policy for processing each frame based on the input video and the real-time system status. 

2) A dynamic main network module that can adjust its computation complexity (depth and input resolution) on-the-fly according to the policy from the agent.

By adapting the network computation based on both the data stream and system status, the hypothesis is that SAN can achieve reliable and timely performance under fluctuating resource constraints. The paper conducts experiments to validate this hypothesis.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing SAN, a novel system-status-aware adaptive network for online video understanding tasks like action recognition and pose estimation. SAN has two main components: a) A dynamic main network that can flexibly adjust its computation complexity via dynamic depth and dynamic input resolution. b) A lightweight RL agent that controls the main network by generating policies based on both the input video stream and the real-time system status. This allows SAN to maintain high performance with low delay even when the available computational resources are fluctuating.  

2. Introducing MSA, a meta self-supervised adaptation method, that allows convenient deployment of the pre-trained SAN model onto new target devices with potentially different hardware configurations and profiles. MSA utilizes an auxiliary task of delay prediction and a meta-optimization procedure to enable quick adaptation on the new device with self-supervision, without requiring the original labeled dataset.

3. Demonstrating state-of-the-art performance of SAN on online action recognition using 50Salads dataset and online pose estimation using Sub-JHMDB dataset. The results show that SAN can achieve higher accuracy and lower delays compared to prior arts, even when the system load is fluctuating rapidly. The adaptation capability of MSA is also verified by deploying across different devices.

So in summary, the key novelty and contributions are in designing a system-status-aware dynamic network that can adapt on-the-fly for online video tasks, and proposing a method for convenient self-supervised adaptation across different hardware platforms. The improved performance is demonstrated on two popular online video understanding tasks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a system-status-aware adaptive network (SAN) with a dynamic main module and lightweight agent that adapts the model's computation based on both the input video stream and fluctuating system status, and also introduces a meta self-supervised adaptation method (MSA) to effectively adapt the model to new hardware platforms at deployment time without labeled data.


## How does this paper compare to other research in the same field?

 Here are a few key points of comparison between this paper and other related work in adaptive networks and online video understanding:

- Most prior work in online video understanding focuses on designing efficient network architectures or dynamic networks that adapt to the input stream. However, they do not consider the system status or computational resources available. This paper is novel in proposing a system-status-aware adaptive network SAN that adapts its behavior based on both the input stream and the real-time system status. 

- The idea of using a lightweight agent to control the behavior of the main network is similar to some prior dynamic network papers. However, the key difference is that the agent in SAN considers system status information to make decisions, while most prior agents only look at the input stream.

- The proposed Meta Self-Supervised Adaptation (MSA) method for cross-platform deployment is also a novel contribution. Most prior dynamic network papers train and test on the same platform. MSA provides an effective way to adapt SAN to new unseen platforms in a self-supervised manner during deployment.

- For online video understanding tasks specifically, SAN achieves superior performance compared to prior state-of-the-art methods like RA, DDLSTM, AR-Net, DKD, etc. It maintains high accuracy while keeping the processing delay very low even under fluctuating system loads.

- The idea of using reinforcement learning to train an agent that controls network behavior has been explored before in other contexts. But the application to online video understanding and using system status as an input to the agent is new.

In summary, the key novelties are the system-status-aware design of the overall SAN framework, the way the agent is trained to leverage system status, and the proposed MSA technique for convenient deployment to new platforms. Together, these contributions enable SAN to achieve excellent performance for online video understanding under fluctuating system resources.
