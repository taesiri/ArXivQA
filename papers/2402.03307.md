# [4D Gaussian Splatting: Towards Efficient Novel View Synthesis for   Dynamic Scenes](https://arxiv.org/abs/2402.03307)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper "4D Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes":

Problem:
- Novel view synthesis (NVS) aims to generate photo-realistic renderings of scenes from new viewpoints based on a set of input views. Recent work has made great progress on NVS for static 3D scenes, but NVS for dynamic scenes remains challenging.
- Main issues with existing dynamic NVS methods: (1) Struggle with complex motions like sudden movements or capturing high-fidelity details due to spatial-temporal entanglement. (2) Rely on slow volume rendering so can't achieve real-time speed.

Proposed Solution: 
- Represent dynamic scene with 4D Gaussians (extending 3D Gaussians used in static scene NVS). Model dynamics by "temporally slicing" the 4D Gaussians to get dynamic 3D Gaussians at each timeframe.
- Choose 4D rotor representation for 4D rotation as it allows separable spatial-temporal rotation. When temporal dimension set to 0, reduces to quaternion for 3D spatial rotation only.
- Render by projecting sliced 3D Gaussians using fast rasterization inherited from prior 3D Gaussian splatting work. Optimized CUDA implementation achieves up to 277 FPS on RTX 3090 GPU.  

Main Contributions:
- Introduce 4D Gaussian scene representation and temporal slicing technique to model complex dynamics like sudden motions while achieving real-time rendering.
- Carefully design 4D rotor rotation representation that enables jointly modeling static 3D and dynamic 4D scenes. 
- Propose entropy loss and 4D consistency loss to stabilize 4D Gaussian optimization.
- Implement a high-performance CUDA framework that significantly accelerates training and achieves state-of-the-art rendering speed.
- Extensive experiments show proposed method surpasses previous dynamic NVS techniques on rendering quality and speed.
