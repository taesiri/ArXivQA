# [Efficient and Modular Implicit Differentiation](https://arxiv.org/abs/2105.15183v5)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the main research question this paper addresses is how to efficiently and modularly perform implicit differentiation of optimization problem solutions. 

Specifically, the paper aims to develop an approach for "automatic" implicit differentiation that allows practitioners to easily differentiate solutions to optimization problems with respect to problem parameters, without having to manually derive and implement the differentiation equations. 

The key ideas are:

- Define a mapping function F in Python that captures the optimality conditions of the optimization problem. 

- Use autodiff and the implicit function theorem to automatically differentiate the optimization problem solution based on F.

- Make this approach efficient by building on top of state-of-the-art solvers, rather than differentiating through unrolled solver iterations.

- Make it modular by decoupling the specification of F from the differentiation mechanism. Users can freely express optimality conditions while still benefiting from automatic differentiation.

In summary, the main research question is how to make implicit differentiation of optimization solutions easy to use, efficient, and modular, combining the benefits of implicit differentiation and autodiff. The paper aims to provide a self-contained blueprint for this using Python and JAX.


## What is the main contribution of this paper?

 The main contribution of this paper is presenting an approach for automatic implicit differentiation to easily differentiate the solutions of optimization problems. The key ideas are:

- The user provides a function F capturing the optimality conditions of the optimization problem to be differentiated. This makes the approach very flexible and modular. 

- Leveraging autodiff and the implicit function theorem, the framework can then automatically compute derivatives of the optimization solution with respect to parameters, without needing manual derivation.

- The approach allows building differentiation on top of any existing solver, combining the benefits of implicit differentiation and autodiff.

- The authors show the framework can express a large catalog of optimality conditions, recovering existing schemes and creating new ones.

- Both theoretical analysis and experiments are provided, studying the accuracy of approximated derivatives and demonstrating applications on bi-level optimization and sensitivity analysis.

In summary, the main contribution is providing a simple yet powerful blueprint for easily and generically adding implicit differentiation capabilities on top of existing solvers. This significantly lowers the barrier for practitioners to use implicit differentiation.
