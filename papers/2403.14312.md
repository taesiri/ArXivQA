# [ChainLM: Empowering Large Language Models with Improved Chain-of-Thought   Prompting](https://arxiv.org/abs/2403.14312)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Chain-of-thought (CoT) prompting is effective for improving reasoning capabilities of large language models (LLMs), but existing methods have limitations in generating high-quality CoT prompts. Specifically, they focus on simpler tasks with fewer reasoning steps, make incomplete reasoning chains, and ignore consistency between reasoning and answers.

Solution:
- Propose CoTGenius, a framework to automatically generate superior CoT prompts by evolving them to be more complicated, diverse and specific. It has 3 evolution strategies:
  1) Complicate: Upgrade questions to more complex ones with more constraints. 
  2) Diversify: Expand to new topics and problem scenarios.
  3) Specify: Add details to make reasoning steps more rigorous.
- Apply 2 filtering mechanisms - evolutionary success judgment and correctness verification using multiple LLMs.  
- Generate a CoT dataset with 44k samples and fine-tune Llama 2-Chat on it as ChainLM.
- Propose step-level debating to mitigate error propagation in CoT reasoning by having multiple LLMs debate each step.

Contributions:  
- Empirically analyze factors impacting efficacy of CoT prompting - inference completeness, prompt specificity and reasoning logicality.
- Propose CoTGenius framework for automatic improvement of CoT prompts using complicate, diversify and specify strategies alongside evolutionary and correctness filters.
- Construct enhanced CoT dataset and fine-tune ChainLM models which outperform existing open-source LLMs on complex reasoning tasks. 
- Develop a step-level debating approach for collaborative CoT reasoning among multiple agents to improve accuracy.

In summary, the paper presents an extensive investigation into CoT prompting and methods to automatically construct superior quality CoT data to enhance reasoning abilities of LLMs, validated through comprehensive experiments.
