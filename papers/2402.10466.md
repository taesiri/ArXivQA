# [Large Language Models as Zero-shot Dialogue State Tracker through   Function Calling](https://arxiv.org/abs/2402.10466)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) show great capabilities for natural language tasks but have unsatisfying performance for task-oriented dialogues (TOD), which requires not only response generation but also effective dialogue state tracking (DST). 
- DST is challenging as it requires closely adhering to domain-specific schemas to summarize user goals over multiple conversation turns. 
- Obtaining training data for every domain is costly. Prior transfer learning methods from similar domains still require extra annotated data and have limited performance.

Proposed Solution:
- Treat DST as function calling - each domain schema becomes a function specification and slot values become arguments.
- Prompt LLMs to generate a function call and response within assistant's output at each turn.  
- Decompose it into function selection and argument generation for better control.
- Include function specifications and examples in the system prompt to guide generation.
- Fine-tune a 13B LLaMA2-Chat model on 7,200 diverse dialogues to equip function calling capability.

Key Contributions:
- First approach to enable modest 7B-13B open-source LLMs to surpass previous SOTA results obtained solely by advanced ChatGPT.
- Improves GPT-4 performance by 14\% over best prior method, establishing a new SOTA.  
- Fine-tuned 13B model matches ChatGPT's DST capability while preserving response generation performance.
- Can integrate DST capabilities into chat-tuned LLMs without compromising conversation competence.
