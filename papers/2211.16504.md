# [Improving Commonsense in Vision-Language Models via Knowledge Graph   Riddles](https://arxiv.org/abs/2211.16504)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question being addressed is: How can we improve the commonsense ability of recent popular vision-language (VL) models?

The authors observe that despite the great success of VL models like CLIP, they still lack commonsense knowledge and reasoning ability. For example, when shown an image of a lemon and given the text "It tastes sour", VL models fail to make the connection that the text is referring to the lemon. 

To address this limitation, the authors propose a new training strategy called "Data Augmentation with kNowledge graph linearization for CommonsensE capability" (DANCE). The key idea is to leverage knowledge graphs like ConceptNet to generate new training examples that inject commonsense knowledge into existing VL datasets. This helps teach the models about relationships and connections between entities during training.

Additionally, the authors create a new diagnostic benchmark to evaluate commonsense ability in a retrieval task setting, allowing comparison across different VL model architectures.

Through experiments, they show DANCE significantly improves performance on commonsense tasks while maintaining accuracy on normal retrieval benchmarks. This demonstrates it enhances commonsense capabilities without sacrificing general visual-linguistic understanding.

In summary, the central hypothesis is that augmenting training data with commonsense knowledge graphs can improve the commonsense reasoning abilities of VL models. The DANCE strategy and diagnostic benchmark are proposed to test this hypothesis.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1. The paper proposes a novel training strategy called DANCE (Data Augmentation with kNowledge graph linearization for CommonsensE capability) to improve the commonsense ability of vision-language (VL) models. DANCE generates commonsense-augmented image-text pairs by leveraging knowledge graphs and creating variants of text descriptions in existing VL datasets via bidirectional sub-graph sequentialization. 

2. The paper introduces a new retrieval-based commonsense diagnostic benchmark to evaluate VL models' commonsense ability. This allows direct evaluation of VL models without transferring to other tasks like VQA. The benchmark has test splits to evaluate both seen and unseen commonsense knowledge.

3. Through extensive experiments, the paper demonstrates that the proposed DANCE strategy significantly improves VL models' commonsense ability as evaluated by both the new diagnostic benchmark and existing VQA datasets, without harming performance on vanilla image-text retrieval tasks. The results show DANCE helps VL models generalize to unseen commonsense knowledge as well.

In summary, the main contributions are proposing a novel commonsense training strategy compatible with many VL models, introducing a new diagnostic benchmark for evaluating commonsense, and empirically demonstrating effectiveness of the approach. The overall contribution is improving and analyzing the commonsense ability of VL models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a method to improve the commonsense capability of vision-language models by augmenting existing image-text datasets with commonsense knowledge extracted from knowledge graphs and converting it to natural language descriptions.
