# [Look, Radiate, and Learn: Self-Supervised Localisation via Radio-Visual   Correspondence](https://arxiv.org/abs/2206.06424)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper abstract, the central research question seems to be: 

How can we perform accurate target localization in radio signals in a self-supervised manner by exploiting commonalities between radio and visual data?

The key hypothesis appears to be that by learning cross-modal spatial features between radio and visual data via contrastive learning, it is possible to extract target coordinates in a self-supervised way without manual labeling. These self-supervised coordinates can then be used to train a radio-only target localizer network.

In summary, the paper explores using self-supervision from visual data to enable target localization in radio signals, aiming to show that accurate localization is possible without manual annotation by exploiting radio-visual correspondences.
