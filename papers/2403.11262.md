# [Understanding Diffusion Models by Feynman's Path Integral](https://arxiv.org/abs/2403.11262)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Diffusion models have shown impressive image generation capabilities, but it is not well understood why stochastic sampling schemes tend to outperform deterministic ones (e.g. probability flow ODEs) on metrics like FID. 

- There is no direct way to evaluate the negative log-likelihood (NLL) for stochastic diffusion models, making it hard to quantitatively analyze performance.

Proposed Solution:
- Reformulate diffusion models using Feynman's path integral framework from quantum physics. This provides a unified perspective on different sampling schemes.

- Introduce a parameter η that interpolates between stochastic sampling (η=1) and deterministic sampling (η=0). This is analogous to Planck's constant η in quantum mechanics.

- Apply the Wentzel–Kramers–Brillouin (WKB) expansion technique from physics to evaluate the NLL perturbatively in powers of η. This allows assessing performance of different η.

Main Contributions:
- First path integral reformulation of diffusion models, allowing re-derivations of reverse-time SDE and loss functions.

- Introduction of the interpolation parameter η with analogy to quantum mechanics. This gives a way to continuously connect stochastic and deterministic sampling.

- Application of the WKB expansion to obtain explicit NLL calculations to first order in η. This enables quantitative analysis of the effect of noise on sampling quality.

- Experiments on synthetic data to validate the NLL computation and show improved sample quality for small non-zero η.

In summary, the paper provides a new perspective on diffusion models through physics concepts and tools to better understand the role of noise. The WKB expansion gives a way to actually evaluate likelihoods for the stochastic case.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper reformulates diffusion models using Feynman's path integral framework from quantum physics, enabling new techniques like the Wentzel-Kramers-Brillouin expansion to analyze and calculate properties such as the negative log-likelihood for stochastic sampling schemes.


## What is the main contribution of this paper?

 This paper's main contribution is reformulating diffusion models using path integral techniques originally developed in quantum physics. Some key aspects this enables:

- It provides a novel derivation of reverse-time SDEs and loss functions for training diffusion models. 

- It introduces a continuous parameter connecting different sampling schemes - stochastic vs deterministic (probability flow ODE) - analogous to Planck's constant in quantum mechanics. 

- This allows applying perturbative techniques like the Wentzel–Kramers–Brillouin (WKB) expansion to evaluate the negative log-likelihood and analyze performance differences between sampling schemes.

- Specifically, the WKB expansion provides an innovative method to calculate the log-likelihood for stochastic sampling processes where direct evaluation was previously infeasible. 

In summary, the quantum physics-inspired path integral perspective offers new theoretical machinery to analyze diffusion models, bridging them closer to physics concepts and enabling new ways to understand their properties.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Path integral formulation - The paper reformulates diffusion models using the path integral framework from quantum physics to describe the sampling trajectories. This provides a unified perspective on different aspects of score-based models.

- Stochastic vs deterministic sampling - The path integral view connects stochastic sampling schemes (with noise) to deterministic schemes (without noise, e.g. probability flow ODEs) through an interpolating parameter. This helps analyze differences in performance.

- Planck's constant / ħ - The interpolating parameter plays an analogous role to Planck's constant in quantum mechanics. This enables applying techniques like the WKB expansion. 

- Wentzel–Kramers–Brillouin (WKB) expansion - A technique from physics to treat asymptotic series expansions with respect to ħ. The paper shows this can be adapted to evaluate the log-likelihood and analyze impact of noise on sampling.

- Negative log-likelihood - The WKB expansion provides a method to explicitly compute the negative log likelihood for stochastic sampling schemes, which has been an open challenge.

- Noise in sampling - The paper provides quantitative analysis and a theoretical framework to explain the role of noise in enhancing diversity/quality of sampled images in diffusion models.

In summary, key terms revolve around using quantum physics concepts like path integrals and the WKB expansion to reformulate, analyze, and quantify behavior of diffusion models, especially relating to stochasticity.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. How does the path integral formulation provide a unified perspective on various aspects of score-based generative models? Can you give some specific examples discussed in the paper?

2. Explain the analogy made between the parameter $\h$ and Planck's constant $\hbar$ in quantum mechanics. How does this motivate the application of techniques like the Wentzel–Kramers–Brillouin (WKB) expansion?

3. The WKB expansion allows a perturbative evaluation of the negative log-likelihood. Walk through the key steps in deriving the expression for the log-likelihood up to first order in $\h$. 

4. What is the significance of the ``modified probability flow ODE" introduced in the analysis? How does it capture the effect of noise on the bijective map between data and latent representations?

5. The local error analysis for numerical estimates of the log-likelihood derivatives seems technically involved. Can you summarize the key ideas and how potential underestimation of errors is avoided?  

6. How does the path integral formulation provide an alternative derivation of the reverse-time SDE used in sampling for diffusion models? What role does the Onsager-Machlup function play here?

7. The analysis models the effect of noise through the parameter $\h$. How does the limit $\h \to 0$ connect to the classical limit and principle of least action in physics?

8. What physical insight does the ability to directly compute log-likelihoods provide into the performance gap between stochastic and deterministic sampling schemes?

9. Can the analysis be extended to conditional variants of diffusion models? If so, what changes need to be made?

10. What are some promising future research directions that build upon the path integral formulation of diffusion models presented in this work?
