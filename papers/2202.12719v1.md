# [Ask2Mask: Guided Data Selection for Masked Speech Modeling](https://arxiv.org/abs/2202.12719v1)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is: how can masked speech modeling (MSM) pre-training techniques be improved by focusing on training with only the most relevant samples from the unsupervised training data?

The key hypothesis is that selecting only highly confident/relevant samples during MSM pre-training will allow the model to learn better representations and improve performance on downstream speech recognition tasks, especially under mismatched conditions between pre-training and target data.

Specifically, the paper proposes an "ask-to-mask" (ATM) approach to incorporate data selection into MSM pre-training in two ways:

1) ATM performs fine-grained frame selection by masking only highly confident frames identified by an external "scorer" model. This allows focusing on meaningful samples.

2) ATM also extends selection to the utterance-level by weighting the overall MSM loss for each utterance by its confidence score. This allows emphasizing more confident utterances.

The central hypothesis is that by training only on the most relevant samples, identified viaconfidence scores, the MSM model will learn more useful representations and improve recognition, especially for mismatched target data. Experiments aim to validate if ATM improves over standard MSM techniques.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a new approach called "Ask2Mask" (ATM) for guided data selection during pre-training of masked speech models (MSMs) like wav2vec2 and w2v-BERT. The key ideas are:

- Using an external automatic speech recognition (ASR) model or "scorer" to provide frame-level confidences for the input speech. 

- Masking the input frames with higher confidence scores from the scorer. This allows the model to focus on learning from the more "confident" frames.

- Extending ATM to also weight the overall loss of each utterance by the utterance-level confidence from the scorer. This provides coarser, utterance-level weighting.

- Showing that ATM improves performance of the pre-trained MSMs when fine-tuned on target datasets, especially under mismatched conditions between pre-training and target data. For example, pre-training on LibriLight then fine-tuning on AMI datasets.

- Demonstrating consistent gains from ATM across different model architectures like wav2vec2, HuBERT, and w2v-BERT.

- Achieving state-of-the-art results on benchmark datasets like LibriSpeech and AMI by using ATM during pre-training of the MSMs.

In summary, the key contribution is introducing a simple but effective data selection approach called ATM that focuses the MSM pre-training on the more informative regions of the input speech. This improves the learned representations and downstream ASR performance, especially under mismatched conditions.
