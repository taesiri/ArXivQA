# Evaluating Object Hallucination in Large Vision-Language Models

## What is the main contribution of this paper?

The main contributions of this paper are:1. It provides the first systematic study evaluating object hallucination in large vision-language models (LVLMs). The paper examines several representative LVLMs on the MSCOCO dataset using the CHAIR metric and finds they suffer from severe object hallucination issues. 2. It analyzes potential factors leading to object hallucination in LVLMs, revealing objects frequently occurring in visual instructions or co-occurring with image objects are more prone to be hallucinated. Over 40% of hallucinated objects are among the top 10 most frequent in instruction corpora.3. It proposes an improved evaluation method called POPE (Polling-based Object Probing Evaluation) to assess object hallucination in a more stable and flexible way. POPE converts the evaluation to Yes/No questions about object existence. Experiments show POPE yields consistent results as CHAIR and also reflects LVLMs' tendency to answer "Yes".4. When combined with automatic segmentation tools, POPE can evaluate object hallucination on datasets without annotations. Experiments on MSCOCO, A-OKVQA, and GQA validate the effectiveness of annotation-free POPE.In summary, the paper provides the first comprehensive study of object hallucination in LVLMs, reveals its severity and potential causes, and proposes a more reliable evaluation approach in POPE. The findings highlight object hallucination as an important issue to address when developing LVLMs.
