# [SurreyAI 2023 Submission for the Quality Estimation Shared Task](https://arxiv.org/abs/2312.00525)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper explores different pre-trained language models within the MonoTransQuest architecture for the WMT23 Sentence-Level Direct Assessment shared task. The proposed approaches employ autoencoder models like XLMV, InfoXLM-large, and XLMR-large to predict translation quality scores. The MonoTQ-InfoXLM-large emerges as the best performing individual model, significantly outperforming the baseline and showing competitive correlation scores compared to the top systems on the leaderboard. An ensemble technique combining predictions from the different models is also evaluated but does not provide substantial gains over the single MonoTQ-InfoXLM-large model. Overall, the findings demonstrate the effectiveness of leveraging recent advances in pre-trained encoders for quality estimation, with InfoXLM showing particular promise on this sentence-level direct assessment task across several mid and low-resource Indian language pairs. Further experiments on additional languages and incorporation into other QE frameworks is suggested as future work.
