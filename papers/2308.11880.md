# [SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal   Targets](https://arxiv.org/abs/2308.11880)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question/hypothesis appears to be:How can we adapt a set of models trained independently on uni-modal data to a target domain consisting of unlabeled, paired, multi-modal data, without access to the original source dataset? The key aspects are:1) Adapting models trained on uni-modal data (e.g. only images or only point clouds) 2) To a target domain with multi-modal data (e.g. paired images and point clouds)3) Without access to the original source data used to train the modelsThe authors propose a method called SUMMIT to address this problem. The key ideas are using pseudo-label fusion across modalities and automatically choosing between complementary fusion methods based on estimated domain gap. Experiments demonstrate that their approach can improve performance over uni-modal and multi-modal baselines.In summary, the paper tackles the challenging problem of adapting uni-modal models to multi-modal targets in a source-free setting, proposing a solution based on pseudo-label fusion and automatic selection between fusion methods. The central hypothesis is that their approach can effectively perform adaptation in this scenario.


## What is the main contribution of this paper?

Based on the abstract and introduction, the main contributions of this paper appear to be:1. Addressing the problem of adapting models trained on uni-modal data to a target domain with unlabeled, paired, multi-modal data, without access to the original source data. This is a setting of practical importance for reasons explained in the introduction.2. Proposing a new cross-modal, source-free domain adaptation framework that fuses pseudo-labels across modalities using information-theoretic and hypothesis testing approaches. This allows learning cross-modal correlations on the target data and improves adaptation performance.3. Introducing a switching method to automatically choose between two complementary pseudo-label fusion techniques - agreement filtering and entropy weighting - based on estimating the domain gap. 4. Demonstrating through extensive experiments that the proposed method provides significant improvements of up to 12% in mIoU over competing baselines on seven challenging adaptation scenarios.In summary, the main contribution appears to be a new approach for source-free, cross-modal domain adaptation that can learn correlations across modalities without paired training data or source access, using pseudo-label fusion and automatic switching between fusion techniques. The method is shown to outperform existing baselines on multi-modal semantic segmentation tasks.
