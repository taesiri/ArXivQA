# [$\text{R}^2$-Bench: Benchmarking the Robustness of Referring Perception   Models under Perturbations](https://arxiv.org/abs/2403.04924)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Referring perception models empower intelligent systems to ground objects based on multimodal guidance like text, images or audio. However, their robustness against real-world perturbations like environmental noise, human errors in instructions, or sensor limitations, is not well explored. Evaluating model robustness is critical for reliable real-world deployment but also labor-intensive. 

Proposed Solution:
This paper introduces R^2-Bench, the first comprehensive benchmark for systematically evaluating robustness of referring perception models across 5 key tasks - referring image segmentation, video object segmentation, referring video object segmentation, audiovisual segmentation and queryable 3D mapping.

It provides:
(1) A taxonomy categorizing perturbations based on source - environment/transmission/sensor noise. 32 perturbation types across visual/acoustic/textual modalities are supported.
(2) A customizable synthesis toolbox to create perturbed datasets for robustness assessment. Perturbations can be applied in sequences mirroring real-world noise order and across severity levels/dynamics.
(3) Systematic robustness evaluation of 20+ state-of-the-art models under noisy conditions to analyze model vulnerabilities. Composite perturbations are tested to closely simulate real-world complexity. 

In addition, an R^2-Agent based on large language models is proposed to simplify context-specific evaluations per human instructions. It automatically selects suitable data samples, perturbations, metrics and generates analysis reports.

Main Contributions:
(1) R^2-Bench - the first comprehensive robustness benchmark with customizable perturbations across key referring perception tasks.
(2) In-depth analysis investigating intrinsic perturbation characteristics like type/severity/dynamics/correlations.
(3) R^2-Agent that streamlines tailored robustness assessments leveraging natural language instructions.

The benchmarking and analyses reveal significant vulnerabilities of existing models, highlighting the necessity of resilience for real-world deployment. The tools lower the barriers for rigorous evaluation to promote progress in this critical area.
