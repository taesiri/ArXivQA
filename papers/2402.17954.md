# [Multilingual Speech Models for Automatic Speech Recognition Exhibit   Gender Performance Gaps](https://arxiv.org/abs/2402.17954)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Recent advancements in automatic speech recognition (ASR) have led to impressive "one-model-fits-all" solutions that can transcribe speech in many languages. However, their broad coverage may mask performance differences within languages, such as across genders. Prior work has found ASR models to differ in accuracy on male and female voices, but mostly for English models. This paper investigates whether gender performance gaps exist in multilingual ASR models across many languages.

Methodology:
The authors evaluate two popular multilingual ASR models - OpenAI's Whisper and Meta's Seamless on three speech datasets covering 19 languages from 7 families. The datasets have gender labels and include both read speech (Common Voice, Fleurs) and spontaneous speech (VoxPopuli). They measure gender gaps using word/character error rates between female/male groups and a "neither" group. They also analyze acoustic features like pitch and probe the models' internal states to understand reasons behind gaps.

Key Findings:
- Models do NOT perform equally well across genders, showing clear disparities favoring either males or females depending on language and dataset.  
- Gaps for "neither" group are larger than female/male gaps.
- Acoustic analysis reveals no significant phonetic differences explaining gaps.  
- Probes show high correlation between internal gender discriminability and female/male performance gaps. The easier to discern gender internally, the more models favor female speakers.

Main Contributions:  
- First extensive evaluation of gender gaps in multilingual ASR models showing significant disparities.
- Analysis techniques connecting performance gaps to model internals.
- Insights that despite progress, group fairness remains unsolved in multitask multilingual models.

The paper underscores the need for evaluating fairness of speech systems and mitigating representation harms. It releases code and artifacts to further research in this direction.
