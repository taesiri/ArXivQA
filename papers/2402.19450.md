# [Functional Benchmarks for Robust Evaluation of Reasoning Performance,   and the Reasoning Gap](https://arxiv.org/abs/2402.19450)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Current benchmarks for evaluating reasoning capabilities of language models may overestimate performance. Models may be relying more on memorization rather than true reasoning.
- Static text QA benchmarks are prone to contamination from the training data. Models may solve problems by pattern matching against the training data rather than logical reasoning.

Proposed Solution: 
- Introduce functional variants of benchmarks, where each test is converted into code that can generate infinite versions of the same logical problem. This makes new problems that require the same reasoning but have different numerical values or text.

- Define a "reasoning gap" metric as the drop in accuracy between static and functional variant of a benchmark. This gap quantifies memorization vs true reasoning.

- Functionalized 41.2% of the MATH benchmark into MATH() to demonstrate the approach. Will release code to generate MATH() snapshots each quarter, replacing the static tests.

Main Contributions:
- Framework for more robust reasoning evaluation resistant to contamination. Can generate infinite new snapshots of reasoning problems.

- Functional variant of portion of MATH benchmark and public snapshots. Enables testing models on new unseen reasoning problems.

- Reasoning gap metric to quantify gap between memorization and reasoning.

- Find reasoning gaps of 58-80% on state-of-the-art models, indicating substantial room for improving reasoning abilities.

- Identified reasoning abilities and limitations of models that can solve MATH() snapshots. Surprising capabilities but also clear gaps.

- Open problem to train "gap 0" models that have no difference between static and functional accuracy.
