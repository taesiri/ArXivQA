# [IsarStep: a Benchmark for High-level Mathematical Reasoning](https://arxiv.org/abs/2006.09265)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is limited prior work investigating the capability of neural networks to do mathematical reasoning, with most focusing on simple arithmetic problems.  
- More complex tasks like generating intermediate proof steps require creative thinking, inference, understanding conditions, and symbolic manipulation - abilities neural networks have not demonstrated.
- A well-defined benchmark is needed to measure progress in mathematical reasoning for neural networks.

Proposed Solution:
- The authors build a non-synthetic dataset from a large repository of 204K human-written Isabelle proofs across diverse undergraduate and research-level mathematical topics.
- They define a task called "IsarStep" where models must generate a missing intermediate proposition between two proof steps. This tests key skills needed for automating theorem proving. 
- Several neural sequence-to-sequence models are evaluated: RNN with attention, transformer, and a new hierarchical transformer that explicitly models intra- and inter-proposition reasoning.

Main Contributions:
- The first large-scale benchmark for evaluating neural networks on complex mathematical reasoning, with broad topic coverage and real proofs.
- Analysis showing current neural models can capture non-trivial reasoning, with the hierarchical transformer performing the best.  
- Findings that related concepts have learned embeddings close in vector space, and some models can do multi-step inference rivaling humans.
- A test suite to validate if generated propositions are logically correct using automatic theorem provers.
- The dataset and models to encourage further research progress in this direction.

In summary, this paper makes significant progress towards neural networks that can automatically generate human-readable mathematical proofs. The presented benchmark and analysis set a strong foundation for future work on modelling complex reasoning.
