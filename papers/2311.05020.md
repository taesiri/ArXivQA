# [First Tragedy, then Parse: History Repeats Itself in the New Era of   Large Language Models](https://arxiv.org/abs/2311.05020)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper reflects on lessons from the first era of large language models (LLMs) in machine translation during the 2000s to offer guidance for research directions in the current era of LLMs like ChatGPT. The authors identify several recurring themes that remain relevant today: the supremacy of scale enabled by hardware advances, though disparities are often transient; the difficulty of evaluation as metrics fail to capture subtle remaining errors; the lack of a "gold standard" for human assessment, which often prioritizes fluency over other dimensions; and the potential for new paradigms to abruptly eclipse old ones when new hardware emerges. Based on these lessons, they recommend focusing research on improving metrics grounded in concrete tasks, developing techniques suited for future hardware, and exploring alternative modeling approaches despite the dominance of scale. Overall, the paper argues that foundational research remains vital and offers historians' perspectives on pursuing impactful work even in areas where proprietary systems presently dominate.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

By reflecting on lessons from the first era of large language models in statistical machine translation, the authors identify durable takeaways and evergreen research opportunities to guide AI practitioners facing current anxieties over compute scale disparities and the rise of models like ChatGPT.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the key points from the paper:

This paper reflects on lessons from the first era of large language models (LLMs) in statistical machine translation (SMT) to inform research strategies for working with modern LLMs like ChatGPT. The authors identify several recurring themes: the primacy of scale enabled by hardware advances, though scale disparities are often transient; the importance of developing better evaluation metrics, as remaining errors become more subtle; the lack of a "gold standard" for human evaluation, which often prioritizes fluency over accuracy; and the potential for new hardware paradigms to abruptly improve performance, as GPUs did for neural MT. Based on these lessons, they recommend focusing on improved metrics and concrete tasks rather than scale alone; collaborating across institutions and companies to enable broader access to large models; considering problems where data remains scarce; speculating on alternative methods suited for future hardware; and overall, renewing a commitment to scientific research even in areas dominated by industry scale.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one-sentence summary of the paper's main point:

The paper argues that the history of statistical machine translation scaling laws and evaluation challenges offers guidance for research directions and priorities amidst the current era of large language models, recommending a focus on scalable methods, improved evaluation techniques, consideration of diverse user needs and hardware trends, and foundational research even in areas dominated by scale.


## What is the central research question or hypothesis that this paper addresses?

 This paper does not present original research or experimental results. Rather, it is a perspective piece that reflects on lessons from the previous era of large language models in statistical machine translation in order to provide guidance to researchers during the current era of large neural language models. 

The central thesis seems to be that while scale and compute are currently dominant factors in advancing language modeling capabilities, researchers still have important roles to play, especially in areas like:

- Taking advantage of improvements in hardware efficiency and availability
- Focusing on problems where data, not compute, is the key bottleneck 
- Improving evaluation methods and metrics
- Designing concrete task-based evaluations rather than relying solely on human judgments
- Exploring alternative paradigms that could enable new breakthroughs in the future

So in summary, this paper aims to provide encouragement and direction to researchers who may feel disempowered in the face of industrial-scale private language models, arguing that foundational research can still drive progress. It does not present a specific research question or hypothesis to be tested.


## What is the main contribution of this paper?

 This paper draws lessons from the previous era of large language models (LLMs) in statistical machine translation (SMT) to inform researchers during the current era of LLMs based on deep learning. The main contributions are:

1) Identifying four key lessons from the history of SMT that apply to current LLMs: the supremacy of scale, the bottleneck of evaluation, the lack of a "gold standard" for human evaluation, and the non-continuous nature of progress. 

2) Making recommendations for researchers today based on these lessons, such as focusing on improvements in hardware and metrics, remembering small-scale problems where data is the bottleneck, grounding evaluation in concrete downstream tasks, and exploring speculative new methods that could enable future paradigms.

3) Arguing that despite the "scale crisis," there are still many opportunities for impactful research, even for academics without access to massive models. The paper concludes by encouraging researchers to continue foundational scientific work to advance the field.

In essence, the paper reflects on the history of MT to chart a course for research even in areas where scale seems to presently dominate, arguing that research opportunities remain plentiful for those willing to seize them.


## What future research directions do the authors suggest?

 The authors suggest several future research directions, including:

1. Take advantage of improvements in hardware as they enable scale at affordable budgets (Section 3.1). Researchers should develop algorithms that can exploit parallelization and other hardware advances to enable training larger models.

2. Pursue research on problems where data, not compute, is the bottleneck (Section 3.2). This includes low-resource languages and settings where data collection is limited for other reasons.

3. Improve evaluation metrics (Section 4.1). This includes developing automated metrics that better correlate with human judgments, as well as defining evaluation criteria and annotation methodologies that elicit more useful human feedback.

4. Measure performance on concrete downstream tasks under deployment conditions (Section 4.2). Rather than relying on proxies like human judgments or static benchmarks, evaluate models based on how well they enable humans to accomplish real-world goals.

5. Anticipate and help shape future hardware developments (Section 5.1). Researchers can motivate new hardware by developing techniques suited to technologies like sparsity and new sources of parallelism.

The overarching message is that there are still many open research problems related to large language models, from data collection and efficiency to evaluation and interactive deployment. Rather than being discouraged by the scale crisis, researchers should renew their commitment to foundational NLP research.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts include:

- Large language models (LLMs)
- Statistical machine translation (SMT) 
- Scale crisis
- Bitter lesson
- Evaluation metrics 
- Human evaluation
- Hardware lottery
- Scientific revolutions
- Paradigms
- Normal science

The paper discusses the lessons learned from the first era of large language models in statistical machine translation, and relates them to the current era of large neural language models. It focuses on issues like the primacy of scale, problems with evaluation, the flaws of naive human annotation, the role of hardware in enabling progress, and the value of foundational research even when scale dominates applications. Key terms like "large language models," "statistical machine translation," the "scale crisis," the "bitter lesson," different evaluation methods, the "hardware lottery," and ideas from philosophy of science like "paradigms" and "normal science" feature prominently.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the methods and analyses in the paper:

1. The authors draw parallels between the first era of large language models (LLMs) in statistical machine translation (SMT) and the current era of LLMs like GPT-3. What are some key similarities and differences between these two eras of LLMs? How might the lessons from the SMT era inform strategies for research in the current era?

2. The authors argue that scale disparities between large industry labs and smaller academic groups are often transient, using the example of phrase-based language models in SMT. What developments allowed smaller groups to close the gap during the SMT era? Could similar developments help mitigate scale disparities in the current LLM era?

3. The authors recommend taking advantage of improvements in hardware as they enable greater scale at lower costs. What developments in hardware and software efficiency helped increase accessibility of large models during the SMT era? How might researchers anticipate and take advantage of future hardware improvements?  

4. The authors argue that evaluation presents a bottleneck to progress, one that becomes more difficult to solve as models improve. What examples illustrate this challenge from the SMT era? How might the evaluation challenges differ for modern LLMs compared to SMT models?

5. The authors caution that human annotation does not provide a universal "gold standard" for judging quality, noting issues like fluency bias. What examples from MT research illustrate problems with naive approaches to human evaluation? How could these issues manifest with modern LLMs?

6. Instead of reliance on human judgment, the authors recommend measuring performance on concrete downstream tasks. What are some examples of such metrics proposed for machine translation? What kinds of concrete objectives could be suitable for evaluating modern LLM capabilities?

7. The authors describe the abrupt ascent of neural machine translation, enabled by GPU hardware, as an example of a paradigmatic shift. What developments in software and hardware shaped this revolution? How might researchers anticipate and prepare algorithms for future hardware improvements?  

8. Throughout the paper, the authors refer to the "Bitter Lesson" described by Rich Sutton - that leverage of scale tends to dominate techniques based on human insight. How does this lesson manifest in the eras of SMT and modern LLMs? What implications does it have for research strategies?

9. The authors encourage speculative research on alternative methods, despite the dominance of scale shown thus far. What are some past examples in MT of ideas that were initially speculative but later contributed to progress in neural methods? What kinds of speculative directions might be worth exploring for LLMs?

10. The conclusion argues that scientific research opportunities remain relevant even in areas impacted heavily by scale. What are some examples of scientific questions, beyond modeling contributions, that remain open and important for the era of modern LLMs?


## How does this paper compare to other research in the same field?

 This paper takes a historical perspective on the rise of large language models (LLMs), drawing parallels between the current era of models like ChatGPT and the previous era of statistical machine translation (SMT) models in the 2000s. Some key points it makes:

- It identifies several "durable lessons" from the SMT era that are still relevant today, such as the primacy of scale, the difficulty of evaluation, and the challenges of human assessment. It argues these lessons can provide guidance for researchers facing questions about the field after the release of major models like ChatGPT.

- It recommends researchers focus on opportunities like improving metrics, studying problems where data remains a bottleneck, anticipating future hardware, and foundational research. It encourages the community not to abandon areas relevant to LLMs, but to renew commitments to scientific research. 

- It takes a measured tone, arguing the current crisis around scale and model access is not permanent. It points to examples of how gaps were eventually closed in the SMT era, such as through efficiency improvements and collaboration.

Overall, this paper stands out for making one of the first systematic comparisons between the SMT and LLM eras. It offers both warnings and reassurance for researchers based on historical precedent. The references to enduring problems like evaluation and human assessment also suggest fundamental research directions less vulnerable to being rendered inconsequential by industry achievements.
