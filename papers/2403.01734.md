# [Offline Goal-Conditioned Reinforcement Learning for Safety-Critical   Tasks with Recovery Policy](https://arxiv.org/abs/2403.01734)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Prior offline goal-conditioned reinforcement learning (GCRL) methods can learn policies to reach goals, but may cause collisions as they do not consider safety constraints. Existing offline safe RL methods focus excessively on satisfying constraints at the expense of training efficiency and goal reaching performance. 

Proposed Solution:
The paper proposes Recovery-based Supervised Learning (RbSL), which integrates supervised learning and reinforcement learning to accomplish safety-critical tasks. RbSL has two components:

1) Goal-conditioned policy: Learned via weighted supervised learning to reach goals along shortest paths. Handles out-of-distribution actions using hindsight relabeling and offline datasets.

2) Recovery policy: Corrects actions to satisfy safety constraints and keep trajectories away from unsafe regions. Trained via constrained policy optimization using filtered expert demonstrations. Improves safety through cost-shaping of recovery dataset.

A cost Q-network determines switching between the two policies at runtime.

Main Contributions:

- Combines supervised learning and constrained RL for efficient offline GCRL with safety constraints
- Separate goal and recovery policies balance task performance and constraint satisfaction  
- Recovery dataset filtering and cost-shaping improve safety performance
- Outperforms prior offline GCRL and safe RL methods across diverse environments and dataset quality
- Demonstrates sim-to-real transfer of learned policies on a real Panda robot manipulator

In summary, the paper presents a novel approach RbSL that can effectively learn policies from offline datasets to accomplish goal reaching manipulation tasks while satisfying safety constraints.
