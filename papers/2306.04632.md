# [Designing a Better Asymmetric VQGAN for StableDiffusion](https://arxiv.org/abs/2306.04632)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question it addresses is: How can we design a better asymmetric VQGAN architecture to improve StableDiffusion for stable and high-quality image editing?Specifically, the authors identify distortion artifacts as a key issue with using the default symmetric VQGAN in StableDiffusion for image editing tasks like inpainting and local editing. They hypothesize that an asymmetric VQGAN design with a stronger decoder can help address these issues by better preserving non-edited image regions while still recovering details from the quantized latent space. Their proposed approaches are:1) Adding a conditional branch in the decoder to incorporate task-specific priors like non-edited regions, rather than just encoded latent vectors. 2) Using a larger, deeper decoder compared to the encoder to enhance detail recovery while only slightly increasing inference cost.The overall goal is to design a better VQGAN that can improve results for editing tasks that need to preserve non-edited regions, while maintaining performance on text-to-image generation. The asymmetric architecture is proposed as a way to achieve this.
