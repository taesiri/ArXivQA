# [Measuring Bargaining Abilities of LLMs: A Benchmark and A   Buyer-Enhancement Method](https://arxiv.org/abs/2402.15813)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Bargaining is an important negotiation skill for autonomous AI agents, but evaluating bargaining abilities of language models (LLMs) is an open challenge. 
- Prior work lacked rigorous problem formulation, diverse/realistic datasets, and analysis of buyer vs seller performance.

Contributions:
1) Formally defined the bargaining task as an asymmetric incomplete information game with defined metrics (sum of profits, sum of normalized profits) to quantify buyer/seller performance over multiple bargain sessions.

2) Collected a real e-commerce product dataset "AmazonHistoryPrice" with 930 popular products across 18 categories and price history since 2009. Used this to create bargain game sessions.

3) Evaluated major LLMs (GPT-4, ChatGPT, Llama-2 etc) as buyers/sellers. Key findings:
   - Playing buyer is harder than playing seller
   - Increasing model size does not improve buyer performance 

4) Proposed a method "OG-Narrator" combining Offer Generator and LLM Narrator to boost buyer performance. Shows 10x profit gains over baselines by decoupling offer logic from language generation.

In summary, the paper formally defines the bargaining problem, provides a real-world e-commerce dataset, benchmarks LLMs, analyzes challenges, and proposes a method to significantly improve buyer agents. The formalization, analysis and solutions advance research towards building capable autonomous bargainers.
