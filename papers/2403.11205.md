# [Continuous Jumping of a Parallel Wire-Driven Monopedal Robot RAMIEL   Using Reinforcement Learning](https://arxiv.org/abs/2403.11205)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Parallel wire-driven legged robots can jump high and continuously due to long acceleration distance, but have no joint angle sensors in minimal configurations. 
- Estimating joint angles from wire lengths causes oscillations due to wire elongation/loosening under high tensions required for jumping.  
- This makes control unstable - in previous work, only 2+ consecutive jumps were achieved in 10/16 tries.

Proposed Solution: 
- Use reinforcement learning (RL) to develop stable continuous jumping in simulation and transfer to real robot.  
- For state inputs, use joint angle sequences instead of joint velocities that are more susceptible to noise from wire oscillations.
- Design reward function to encourage continuous jumping from standing while keeping upright, limiting drift, and avoiding joint limits.
- Add noise to simulation states/actions to match real robot characteristics and enable transfer.

Contributions:
- RL with proposed state/action/reward design enables significantly more stable jumping than a baseline controller, in both noisy and noiseless simulation environments.  
- Using joint angle sequences instead of velocities maintains performance in noisy simulation, unlike baseline and simple velocity-based RL variants.
- The approach transfers to the real robot - noisy velocity estimates still enable 4 consecutive jumps, unlike complete failure with simple velocity-based RL.
- Demonstrates feasibility of using RL for dynamic motions in wire-driven legged robots with stretching wires, an important step towards future speedy and powerful legged robot designs.

In summary, the key ideas are using joint angle sequences instead of velocity estimates in RL state inputs, designing suitable rewards, and adding sim-to-real noise to enable transferring learned policies for stable continuous jumping of a minimal wire-driven monoped legged robot.
