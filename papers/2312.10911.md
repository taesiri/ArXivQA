# [The Pros and Cons of Adversarial Robustness](https://arxiv.org/abs/2312.10911)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- The paper argues that existing definitions and assessment methods for robustness (both local and global) of machine learning models have critical flaws. Specifically:

- For non-trivial classifiers defined on real-valued features, there exists no globally robust classifier for any distance threshold ε > 0. This is because one can always find two points that have different predictions within an ε-ball.

- Assessing local robustness by random input sampling is invalid because one can always find adversarial examples by picking suitable points. Thus any claims of local robustness based on sampling are incorrect. 

- Consequently, common notions of robustness certification are impossible for non-trivial real-valued classifiers. One can always construct counterexamples that violate robustness guarantees.

Proposed Solutions:
- The paper proposes using robustness checking tools not to verify robustness, but as instruments for computing formal explanations of models by searching for adversarial examples. 

- It introduces the concept of distance-restricted explanations, which have connections to adversarial examples. Algorithms are given that use adversarial search to find such explanations.

- Properties are derived relating distance-restricted explanations to the impossibility of global robustness. New insights are obtained on explaining non-trivial real-valued classifiers.

Main Contributions:
- Identifies fundamental flaws in common notions and assessment methods for local and global robustness of machine learning models

- Shows the impossibility of rigorously certifying robustness for non-trivial classifiers 

- Proposes an alternative viewpoint of using robustness tools for computing formal explanations rather than direct robustness verification

- Introduces distance-restricted explanations and algorithms that leverage adversarial example search

- Derives new properties connecting robustness and explainability, leading to insights on explaining models with no verifiable robustness guarantees
