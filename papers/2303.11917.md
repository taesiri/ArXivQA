# [Efficient Decision-based Black-box Patch Attacks on Video Recognition](https://arxiv.org/abs/2303.11917)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How to achieve efficient decision-based patch attacks against video recognition models?

The authors note that deep neural networks are vulnerable to adversarial patch attacks, where perceptible perturbations are added to inputs to cause misclassification. Previous work has focused on patch attacks for image models, but less work has explored video models. The authors propose to study decision-based patch attacks on video models, where the attack only has access to predicted labels rather than model scores. 

The key challenges are:

1) The large parameter space for video (temporal dimension) increases attack difficulty and query burden compared to images. 

2) The minimal feedback (only predicted labels) in decision-based setting makes optimization more difficult compared to score-based attacks.

To address these challenges, the authors propose a Spatial-Temporal Differential Evolution (STDE) method to achieve query-efficient decision-based patch attacks on video models. The main hypothesis seems to be that by carefully modeling the patch parameters and adopting spatial-temporal evolutionary optimization, they can achieve potent attacks with high query efficiency.

In summary, the central research question is how to achieve effective decision-based patch attacks on video efficiently, which requires addressing the challenges of the large video parameter space and minimal feedback. The authors hypothesize STDE can achieve this goal.


## What is the main contribution of this paper?

 This paper presents a new black-box patch attack method against video recognition models called Spatial-Temporal Differential Evolution (STDE). The main contributions are:

- It proposes a new attack setting called "decision-based patch attack" on video models, where the attacker can only access the top-1 predicted label rather than continuous scores. This is a more challenging but practical attack scenario.

- It develops a novel attack algorithm STDE tailored for this new setting. STDE reduces the search space by using target videos as patch textures and only adding patches on keyframes. It formulates the attack as a combinatorial optimization problem and uses spatial-temporal differential evolution to solve it efficiently. 

- Extensive experiments show STDE achieves 100% success rates with smaller patch sizes and fewer queries compared to prior arts. It demonstrates superior attack performance, efficiency, and imperceptibility.

- This is the first work that explores patch-based targeted attacks on video models. Analysis shows STDE fools models by altering their attention distributions.

- This work bridges the gap in evaluating the robustness of video recognition models. STDE provides a powerful tool to help build more secure video models.

In summary, the key contribution is proposing the new decision-based patch attack setting for video models, and developing a novel attack algorithm STDE that achieves state-of-the-art performance in this setting. This improves the assessment of video model robustness.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a new spatial-temporal differential evolution algorithm called STDE for efficient decision-based black-box patch attacks on video recognition models, which achieves high fooling rates with small and sparse adversarial patches using fewer queries compared to prior methods.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other research in the field of adversarial attacks on video recognition models:

- This paper proposes a new attack setting called "decision-based patch attacks" on video recognition models. As the authors mention, previous work has explored patch attacks and decision-based attacks separately, but combining them for video recognition models is novel. So this expands the scope of adversarial attack research for videos.

- Most prior work on adversarial attacks for video models focused on perturbing all frames with small perturbations. This paper explores sparse patch attacks by adding patches only to keyframes. This is more aligned with how patch attacks work for images, and is likely more perceptible but possibly more effective.

- The proposed STDE attack method uses evolutionary optimization rather than reinforcement learning like some prior video attack methods. The results show STDE is more query efficient and achieves higher success rates compared to prior RL-based methods. This suggests evolutionary algorithms may be better suited for decision-based attacks.

- Comprehensive experiments are conducted on multiple standard datasets (UCF-101 and Kinetics-400) and models (C3D, Non-local, TPN). The attack success rates and efficiency metrics are state-of-the-art compared to existing methods adapted to the decision-based setting.

- The analysis provides insights into why the attacks are effective, such as changing the models' spatial-temporal attention patterns. And ablation studies verify the importance of different components of STDE.

Overall, this paper makes significant contributions by proposing a new and practical attack setting for videos, developing an optimized attack method for this setting, and extensively evaluating it against state-of-the-art techniques. The results convincingly demonstrate the vulnerability of video recognition models to such sparse, decision-based patch attacks.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Exploring more sparse and efficient video attacks in the decision-based setting: The authors propose focusing more on using information from the video itself to develop attacks that require fewer queries and are more sparsely distributed across frames.

- Developing defenses against decision-based patch attacks on videos: The authors have demonstrated the effectiveness of these attacks, so an important next step is researching defenses tailored to this new threat model. 

- Expanding the assessment system for video model robustness: The authors frame their attack method STDE as helping to improve testing and evaluation of video recognition models against adversarial threats. More work can be done to expand the assessment capabilities.

- Applying STDE to other patch attack forms: The authors suggest STDE could be adapted to other types of patch attacks beyond the rectangular form explored in the paper.

- Investigating why patch attacks are effective: The authors use visualization to get some intuition, but more in-depth analysis on how and why small patches can fool models could inform both attacks and defenses.

- Exploring patch attacks on other video analysis tasks: The authors focus on video classification, but patch attacks may pose threats to other tasks like object detection and tracking in video as well.

In summary, the main themes are improving attacks in the proposed decision-based setting, developing tailored defenses, expanding evaluation capabilities, generalizing the attack approach, and conducting further analysis to gain insights. Advancing understanding of threats to video recognition models appears to be the overarching research direction.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points from the paper:

The paper proposes a new spatial-temporal differential evolution algorithm (STDE) for efficient decision-based black-box patch attacks on video recognition models. The key idea is to reduce the parameter search space for patches in both spatial and temporal dimensions to enable query-efficient attacks in the challenging decision-based setting where only the top-1 predicted label is available. In the spatial dimension, STDE uses target videos as patch textures and models patch positions with coordinate pairs. In the temporal dimension, it performs binary encoding of frames and selects keyframes based on temporal difference. STDE formulates the attack as a discrete optimization problem and applies spatial-temporal mutation and crossover operations to avoid poor local optima. Experiments on UCF-101 and Kinetics-400 datasets demonstrate STDE achieves state-of-the-art attack performance and efficiency compared to prior arts. The sparse and small patches also ensure imperceptibility. Overall, STDE provides an effective framework for evaluating and improving the robustness of video recognition models against adversarial patches.


## Summarize the paper in two paragraphs.

 Here is a 2 paragraph summary of the paper: 

This paper proposes a new adversarial attack method for fooling video recognition models called Spatial-Temporal Differential Evolution (STDE). The method generates adversarial patches that are optimized to fool the model into misclassifying videos with minimal perturbations. The key ideas are:

1) STDE reduces the search space for the adversarial patch by using the target class video as the patch texture and only adding patches on keyframes selected based on temporal difference. This makes the attack more efficient. 

2) STDE formulates the attack as a combinatorial optimization problem and uses an evolutionary algorithm with spatial-temporal mutation and crossover operations to avoid getting stuck in local optima. The fitness function balances misclassification rate and patch size.

Experiments on UCF-101 and Kinetics datasets against 3 video recognition models (C3D, Non-local, TPN) demonstrate STDE achieves 100% misclassification rate with smaller patch sizes compared to prior attacks like TPA, Patch-RS, BSCA etc. STDE is also robust and efficient requiring 70-85% fewer queries than baselines. The sparse distribution and small patch size ensure imperceptibility. Overall, STDE is a powerful and practical attack to evaluate video recognition model robustness.
