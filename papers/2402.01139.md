# [Online conformal prediction with decaying step sizes](https://arxiv.org/abs/2402.01139)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem Statement:
The paper studies the problem of constructing prediction sets with guaranteed coverage in online learning settings. Specifically, at each time step t, the goal is to construct a set C_t that contains the true label Y_t with a specified probability (e.g. 90%). The sets C_t are constructed based on past observations (X_1,Y_1),...,(X_{t-1},Y_{t-1}) and the current feature X_t. This is a challenging problem because the data sequence can be adversarial or changing over time. 

Proposed Solution: 
The paper proposes an algorithm based on conformal prediction. The key idea is to maintain a threshold parameter q_t that determines the prediction set C_t. Specifically, C_t contains all y such that the "conformal score" s_t(X_t,y) is below the threshold q_t. The threshold q_t is updated in an online manner based on whether the previous C_{t-1} contained Y_{t-1}. Critically, the paper uses a decaying step size η_t in the update of q_t, unlike prior work that uses a constant step size.

Main Contributions:

1) The paper provides the first analysis of online conformal prediction with arbitrary/decaying step sizes η_t. It shows that decaying step sizes lead to strong "long-run" coverage guarantees even for adversarial sequences.

2) For IID sequences, the paper shows that decaying η_t leads to convergence of coverage to the desired level. In contrast, a constant η_t leads to oscillatory behavior.

3) The results bridge online conformal prediction with online learning concepts like decaying step sizes. The paper is the first to provide an algorithm and analysis that has simultaneous guarantees (robustness and convergence) for adversarial and IID settings.

4) Experiments on real and synthetic datasets support the theory and show substantially improved practical performance of the decaying step size approach.

In summary, the paper provides an elegant analysis of online conformal prediction with decaying step sizes, showing desirable theoretical properties and improved empirical performance compared to prior approaches. The results help unify conformal prediction and online learning.
