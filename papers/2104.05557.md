# [SC-GlowTTS: an Efficient Zero-Shot Multi-Speaker Text-To-Speech Model](https://arxiv.org/abs/2104.05557)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question it addresses is: 

How can we develop an efficient zero-shot multi-speaker text-to-speech model that improves similarity for speakers unseen during training?

The key points are:

- The paper proposes a novel zero-shot multi-speaker TTS approach called SC-GlowTTS. 

- It explores using a flow-based decoder architecture that enables zero-shot learning of new voices.

- The model uses speaker embeddings from an external speaker encoder to condition the synthesis and enable new voices.

- The central hypothesis seems to be that this proposed model architecture and training approach will allow improving similarity to new speakers not seen during training, while remaining efficient.

- Experiments compare against a Tacotron 2 baseline and show state-of-the-art results for similarity using only 11 speakers, while being faster than real-time.

- Adjusting the vocoder to the TTS model is also shown to significantly improve similarity and quality.

So in summary, the main research question is how to develop an efficient zero-shot multi-speaker TTS model that improves similarity to new voices, which the proposed SC-GlowTTS approach aims to address.


## What is the main contribution of this paper?

 This paper proposes SC-GlowTTS, a novel zero-shot multi-speaker text-to-speech model that improves similarity for speakers unseen during training. The main contributions are:

- A speaker-conditional architecture that explores different text encoders and a flow-based decoder for zero-shot TTS.

- Showing that adjusting a GAN-based vocoder using spectrograms from the TTS model significantly improves similarity and speech quality for new speakers. 

- The model achieves state-of-the-art results with just 11 speakers in the training set.

- The resulting system enables high quality and faster than real-time speech synthesis in the zero-shot multi-speaker setting.

In summary, the key contribution is presenting SC-GlowTTS, a novel and efficient zero-shot multi-speaker TTS model that reaches state-of-the-art performance in similarity for unseen speakers and speech quality using only a few speakers in training. The proposed techniques, like vocoder fine-tuning and the speaker-conditional architecture, help achieve these results.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes SC-GlowTTS, a novel zero-shot multi-speaker text-to-speech model that achieves state-of-the-art results for synthesizing voices of speakers not seen during training, using only 11 speakers in the training data.


## How does this paper compare to other research in the same field?

 Here are some key things I noticed in comparing this paper to other research in zero-shot multi-speaker text-to-speech:

- The paper proposes a novel architecture called SC-GlowTTS that builds on prior work in GlowTTS. The key novelty is incorporating speaker embeddings into the GlowTTS model to enable zero-shot learning.

- The paper experiments with different encoder architectures like convolutional and transformer networks. Using a transformer encoder gave the best results for unseen speakers. This aligns with findings from other recent work showing transformers are very effective for TTS.

- The paper shows state-of-the-art results on similarity metrics like SECS for unseen speakers using only 11 training speakers. Most prior work relies on Tacotron 2 and requires more speakers for good zero-shot performance. This demonstrates the effectiveness of the proposed SC-GlowTTS model.

- Fine-tuning the HiFi-GAN vocoder on spectrograms from the SC-GlowTTS model significantly boosted the quality and similarity for new speakers. This vocoder adaptation approach is unique compared to prior work.

- The model achieves faster than real-time synthesis on CPU which compares favorably to other zero-shot TTS methods. The combination of good similarity, quality and speed is quite strong.

- The paper also shows promising zero-shot voice conversion results by manipulating the speaker embeddings in the SC-GlowTTS model. This application of the model architecture is novel.

Overall, the paper demonstrates state-of-the-art results on key metrics using a novel architecture and training approach for zero-shot multi-speaker TTS. The model efficiency and effectiveness with limited speakers also stand out as important contributions compared to prior work.
