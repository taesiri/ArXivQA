# [Image-free Classifier Injection for Zero-Shot Classification](https://arxiv.org/abs/2308.10599)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is: Given a pre-trained image classification model and a set of new classes not in the original training data, can we extend the model to classify images from the new classes, without having access to any image data for the new classes?Specifically, the paper proposes a method to inject new classifier weights into a pre-trained model to enable zero-shot classification of unseen classes, using only class-level semantic descriptors (like attributes or word embeddings) and the existing classifier weights for seen classes. The key hypothesis is that the classifier weights of a trained model already encode visual-semantic knowledge about the seen classes, which can be exploited along with semantic descriptors to infer classifier weights for novel unseen classes without needing any image data.In summary, this paper introduces a new "image-free zero-shot learning" task and proposes a method called ICIS to address it by predicting new classifier weights using only class descriptors and existing weights, without relying on any image data. The central hypothesis is that this approach can equip pre-trained models with zero-shot classification capabilities in a post-hoc manner.


## What is the main contribution of this paper?

The main contribution of this paper is presenting a method to extend a pre-trained image classification model to new unseen classes without needing access to any images from either the seen or unseen classes. Specifically:- The paper proposes the task of "image-free zero-shot learning" (I-ZSL), where the goal is to perform zero-shot classification by injecting new classifier weights into a pre-trained model, without using any images from seen or unseen classes. This is a more challenging setting than standard zero-shot learning.- To tackle this task, the paper introduces a framework called Image-free Classifier Injection with Semantics (ICIS). ICIS consists of encoder-decoder networks that learn to map between class descriptors (e.g. attributes) and classifier weights for seen classes. - At test time, ICIS can take as input the descriptor for an unseen class and predict corresponding classifier weights, which are then injected into the pre-trained model to extend it to the new classes.- Experiments on standard zero-shot learning benchmarks like CUB, SUN and AWA2 show that ICIS can effectively perform I-ZSL, outperforming adapted zero-shot and few-shot learning methods. ICIS reduces bias towards seen classes and shows improved generalization compared to a simple MLP baseline.In summary, the key contribution is proposing the I-ZSL task and an effective framework (ICIS) to perform zero-shot classification and expand pre-trained models to new classes without needing any images, which has practical benefits in situations where collecting new training data is difficult.
