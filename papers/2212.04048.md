# [Executing your Commands via Motion Diffusion in Latent Space](https://arxiv.org/abs/2212.04048)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is: 

How to enable robust 3D capture of challenging human motions from a single RGB video, which suffer from extreme poses, complex motion patterns, and severe self-occlusion?

The key hypothesis is that embracing multi-modal references from both temporally unsynchronized marker-based systems and lightweight markerless multi-view systems in a data-driven manner can address the limitations of existing monocular 3D human motion capture methods for such challenging motions. 

Specifically, the paper proposes:

1) A hybrid motion inference module to learn challenging motion characteristics from supervised multi-modal motion references. This utilizes a temporal encoder-decoder network to extract motion details from sparse-view image references, and a discriminator network for unpaired marker-based motion references.

2) A robust motion optimization module to further refine the estimated motions using reliable 2D keypoints and silhouettes from the input video.

3) A new dataset containing challenging motions with both unsynchronized marker-based motion capture data and synchronized multi-view image sequences for multi-modal supervision.

Through this proposed approach of combining data-driven multi-modal motion priors and image-based optimization, the paper aims to tackle the key challenges of monocular 3D capture for complex human motions and demonstrate significantly improved performance over state-of-the-art methods. The hybrid learning and optimization framework is the core novelty proposed to address the limitations of existing work.
