# [ScanTalk: 3D Talking Heads from Unregistered Scans](https://arxiv.org/abs/2403.10942)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing methods for speech-driven 3D talking heads generation are constrained to animating faces with fixed topologies, where point-wise correspondence is established between all faces. This limits the application and realism of current deep models.
- Raw 3D scans cannot be animated directly by existing models without an extra registration step to fit the scan onto a predefined topology. This hinders online applications.

Proposed Solution:
- The authors propose ScanTalk, a novel framework to animate any 3D face mesh, including raw scans, overcoming topology constraints.
- ScanTalk uses a DiffusionNet encoder-decoder to compute robust intrinsic surface features and predict deformations. This allows adapting to diverse face structures.
- An audio encoder extracts speech features using a HuBERT module and BiLSTM for temporal consistency.
- The mesh and audio features are fused and fed into the decoder to output a deformation sequence applied to the input neutral face.

Main Contributions:
- First deep model for speech-driven facial animation without topology constraints, enabling scanning data animation.
- Achieves state-of-the-art performance when evaluated on registered data.
- Demonstrates good generalization to diverse meshes by computing intrinsic surface properties.
- Provides both quantitative testing and human evaluations showing its ability to generate realistic and accurate talking heads.
- Opens up new possibilities for 3D facial animation on unstructured data, with applications in VR, games, etc.

In summary, ScanTalk pushes boundaries in deep speech-driven talking heads generation through a topology-agnostic framework, unlocking potential for more flexible and adaptable facial animation using raw scans.
