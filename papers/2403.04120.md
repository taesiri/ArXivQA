# [A data-centric approach to class-specific bias in image data   augmentation](https://arxiv.org/abs/2403.04120)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Data augmentation (DA) is commonly used in computer vision to improve model generalization, but can introduce class-specific biases that unevenly impact model accuracy across classes. 
- This phenomenon was studied in ImageNet models, but questions remain about how data characteristics and model architecture affect DA-induced bias. 

Methods & Contributions
- Extends prior analysis by evaluating DA bias on datasets distinct from ImageNet - FashionMNIST, CIFAR-10/100. Shows bias manifests differently depending on dataset complexity and image characteristics.
- Tests impact of adding random horizontal flipping to DA regime. Finds it compounds with random cropping to accelerate bias onset, highlighting need for caution when chaining multiple DA techniques.
- Evaluates ResNet50, EfficientNet and SWIN Transformer models. Confirms residual models agree on bias regimes. But SWIN Transformer shows greater robustness, suggesting model selection strategy for bias mitigation.
- Provides efficient "DA robustness scouting" methodology to capture essential bias trends with 5x fewer models, enabling practical bias management.

Key Conclusions
- DA's class-specific biases are influenced by data characteristics and model architecture choices. Datasets beyond ImageNet exhibit varying bias severity. Non-residual models can alter bias dynamics.
- Practical methodology proposed to scout DA regimes, picking optimal intensity to maximize accuracy while minimizing bias. Demonstrates need for nuanced, context-aware DA policies matched to dataset and model.

Main Limitations & Future Work   
- Scope limited to few datasets and model architectures. Further research warranted exploring broader range of computer vision contexts.

In summary, this paper thoroughly investigates how data and model choices interact with DA-induced biases, providing strategies to mitigate through tailored DA policies and architectural selection.
