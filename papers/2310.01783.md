# [Can large language models provide useful feedback on research papers? A   large-scale empirical analysis](https://arxiv.org/abs/2310.01783)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question appears to be: Can large language models provide useful feedback on research papers? The authors aim to evaluate the quality and utility of feedback generated by the GPT-4 large language model on scientific papers.Specifically, the key hypothesis seems to be that large language model generated feedback can be helpful for researchers, especially when timely expert feedback is not readily available. The authors test this through a large-scale analysis involving:1) A retrospective comparison of GPT-4 generated feedback versus human peer reviewer feedback on over 3,000 papers from Nature journals and over 1,700 papers from the ICLR conference. 2) A prospective user study surveying over 300 researchers on their perceptions of GPT-4 generated feedback on their own papers.The central goal is to systematically characterize and quantify the reliability, credibility, and limitations of leveraging large language models like GPT-4 to provide automated scientific feedback. The authors aim to shed light on whether and how LLM-generated feedback could complement human feedback to aid researchers.In summary, the key research question is whether large language models can provide useful feedback on research papers, which is tested through quantitative evaluations and user studies comparing LLM-generated feedback to human expert feedback.


## What is the main contribution of this paper?

Based on my review of the paper, the main contributions appear to be:- Developing an automated pipeline using GPT-4 to generate structured feedback on full PDFs of scientific papers. The feedback covers key aspects like significance, reasons for acceptance/rejection, and suggestions for improvement.- Conducting a large-scale retrospective analysis to compare GPT-4 generated feedback to human peer reviewer feedback on over 3,000 Nature journal papers and 1,700 ICLR papers. The analysis finds considerable overlap between GPT-4 and human feedback.- Performing a prospective user study with over 300 researchers to get their perspectives on the usefulness and limitations of the GPT-4 generated feedback on their own papers. The majority found the LLM feedback helpful.- Providing one of the first large-scale systematic assessments on using LLMs like GPT-4 to facilitate scientific feedback, complementing human peer review. The results suggest LLM feedback could help researchers, especially when timely expert feedback is unavailable, while noting limitations like generating less concrete/actionable feedback.In summary, the main contribution is a comprehensive empirical analysis, through both retrospective evaluation and a prospective user study, demonstrating the promises and current limitations of leveraging large language models to provide helpful scientific feedback on research papers. The work sheds light on how LLMs could augment human feedback.
