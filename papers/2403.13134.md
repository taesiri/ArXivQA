# [Robust NAS under adversarial training: benchmark, theory, and beyond](https://arxiv.org/abs/2403.13134)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Neural architecture search (NAS) aims to automate the design of neural network architectures. Most prior NAS research focuses on maximizing standard accuracy, but architectures should also be robust to adversarial attacks.  
- There is a lack of benchmark evaluations and theoretical guarantees for searching robust architectures under adversarial training.

Proposed Solution and Contributions:

1. The paper releases the first adversarially trained NAS benchmark called NAS-RobBench-201:
- Evaluates robust performance of 6,466 architectures from NAS-Bench-201 space under adversarial training on CIFAR and ImageNet datasets.
- Provides a comprehensive assessment, including performance of NAS algorithms, node analysis of top architectures, and correlation between accuracies.

2. The paper establishes a generalization theory for multi-objective NAS (standard + adversarial training) using neural tangent kernel (NTK) tools:  
- Considers residual fully-connected and convolutional networks with activation function search, skip connections, and filter size search.
- Shows clean accuracy is determined by a joint NTK with partly clean and robust NTKs, while robust accuracy always depends on joint NTK with robust NTK and its "twice" perturbed version.
- Estimates lower bound of minimum eigenvalue of joint NTK which impacts generalization.

3. The benchmark reliably reproduces and efficiently assesses NAS algorithms for robust architectures. The theory provides a foundation for designing robust NAS approaches.

In summary, the paper makes both empirical and theoretical contributions to robust neural architecture search using adversarial training, through the release of a comprehensive benchmark and establishment of a generalization theory leveraging NTK tools. The solutions presented facilitate and guide the development of reliable and effective NAS techniques for robust architecture design.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The paper releases an adversarially trained NAS benchmark with 6466 architectures, provides a generalization theory for searching robust architectures under adversarial training, and analyzes the correlation between NTK metrics and accuracy to demonstrate the utility of NTK(s) for robust architecture search.


## What is the main contribution of this paper?

 This paper makes two main contributions:

1. It releases the first adversarially trained NAS benchmark called NAS-RobBench-201. This benchmark evaluates the robust performance of 6,466 network architectures within the NAS-Bench-201 search space on image classification tasks under adversarial training. 

2. It establishes a generalization theory for searching architectures in terms of clean accuracy and robust accuracy under multi-objective adversarial training, using the neural tangent kernel (NTK) tool from deep learning theory. Specifically, it provides a bound on the generalization error and shows how different NTKs can impact clean accuracy and robust accuracy.

In summary, the key contributions are an adversarially trained NAS benchmark for robust architecture search, and a theoretical analysis framework using NTK to provide generalization guarantees when searching architectures under adversarial training. The benchmark and theory aim to advance NAS, especially for robust architecture search.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it are:

- Neural architecture search (NAS)
- Robust neural architecture 
- Adversarial training
- Benchmark
- Generalization theory
- Neural Tangent Kernel (NTK)
- Convolutional neural networks (CNNs)
- Fully-connected neural networks (FCNNs)  

The paper introduces a benchmark to evaluate robust neural architectures that are trained using adversarial training. It also provides a theoretical analysis and generalization guarantees for searching robust architectures using tools like the neural tangent kernel. Key aspects explored are robust accuracy, clean accuracy, convolution neural networks, fully-connected networks, and the correlations between NTK variants and accuracy metrics under adversarial training. The goal is to facilitate research in robust neural architecture search through reliable benchmarking and a solid theoretical foundation.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes the first adversarially trained NAS benchmark called NAS-RobBench-201. What are the key motivations and significance behind releasing such a benchmark? How does it differ from existing NAS benchmarks?

2. The paper establishes a generalization theory for searching architecture under multi-objective adversarial training based on neural tangent kernel (NTK). What are the main technical challenges in deriving the NTK and generalization bounds under this setting? 

3. The clean accuracy is shown to be determined by a joint NTK consisting of a clean NTK and robust NTK. What is the intuition behind this result? Does the robust accuracy have a similar dependence?

4. The paper considers a fairly general architecture search space including activation function search, skip connection search etc. How does the theory handle/incorporate these different search options? What constraints need to be imposed?

5. What assumptions are needed to establish the generalization guarantees (e.g. on input distribution, activation functions etc.)? Are these assumptions reasonable and how restrictive are they in practice? 

6. How does the dependence of generalization bounds on various terms like perturbation radius, width of network, Lipschitz constants etc. provide insights into robust architecture search?

7. What is the key intuition behind using "twice" perturbed adversarial data in defining the robust NTK? How does this choice avoid catastrophic overfitting as claimed?

8. The benchmark contains extensive statistics on ranking correlation, frequency of operator selections etc. What interesting observations can be made from analyzing these results?

9. How well does the theoretical dependence of generalization error on minimum eigenvalue of different NTKs correlate with the empirical analysis in Section 4.3? What can be concluded?

10. What practical guidance do the theoretical results provide towards developing new robust neural architecture search algorithms, particularly those based on neural tangent kernel?
