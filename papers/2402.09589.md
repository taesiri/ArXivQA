# [MLTCP: Congestion Control for DNN Training](https://arxiv.org/abs/2402.09589)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Efficient network congestion management is crucial for accelerating deep neural network (DNN) training jobs running on shared GPU clusters. When multiple jobs compete for network bandwidth, it results in longer training times. Prior approaches to minimize network congestion have limitations: compression/quantization techniques reduce accuracy; pipelining overlaps communication of only a single job; job placement schemes cannot eliminate cross-job contention. Recently, introducing unfairness in congestion control was shown to interleave jobs and improve performance, but has robustness issues.

Proposed Solution:
This paper proposes MLTCP, a technique to augment congestion control algorithms to enable DNN jobs to automatically converge to an interleaved communication state. The key idea is that MLTCP dynamically adjusts a job's aggressiveness in grabbing bandwidth based on the number of bytes it has remaining to send in the current iteration. This simple change causes the job closest to completing its iteration to grab more bandwidth, approximating shortest remaining processing time (SRPT). Over iterations, this favoritism causes a cascading effect that separates the communication phases of competing jobs.  

MLTCP is implemented by introducing a bandwidth aggressiveness function F(bytes_ratio) that scales the additive increase/multiplicative decrease steps of congestion control algorithms based on the fraction of bytes sent in the current iteration. It can augment window-based algorithms like Reno and CUBIC as well as rate-based ones like DCQCN.

Contributions:
- Concept of automatic distributed communication interleaving for DNN jobs
- MLTCP design that robustly achieves interleaving by integrating a simple bytes-based favoritism into congestion control  
- Implementation showing MLTCP variants converge quickly for TCP and RoCE networks
- Evaluations demonstrating up to 2x (4x tail) speedup compared to default congestion control
- Robustness to stragglers, partial compatibility of jobs, and circular job dependencies  

In summary, MLTCP enables efficient distributed communication interleaving to accelerate DNN training through a small augmentation to congestion control protocols.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

MLTCP is a technique to augment congestion control algorithms to enable DNN training jobs competing for network bandwidth to automatically interleave their communication phases by dynamically adjusting the congestion window size based on the number of bytes sent per iteration.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing MLTCP, a technique to augment congestion control algorithms to enable automatic inter-job communication interleaving for DNN training jobs. Specifically:

- It introduces a simple but effective principle of dynamically adjusting the congestion window (or sending rate) of flows based on the number of bytes sent. This helps reinforce a shortest remaining processing time policy and separates the communication patterns of competing jobs into an interleaved state.

- It shows how this principle can be integrated into common congestion control algorithms like Reno, CUBIC, and DCQCN by making small modifications (adding 30-60 lines of code). 

- It demonstrates through testbed experiments that enabling MLTCP leads to much better network utilization and significantly accelerates the average and tail training iteration times of DNN jobs (by up to 2x and 4x respectively) compared to default congestion control.

- It shows that MLTCP is robust to challenges like stragglers, partially compatible jobs, and circular dependencies across jobs/links that prior interleaving techniques cannot handle.

In summary, the key contribution is a lightweight way to enable automatic and robust inter-job communication interleaving by slightly modifying congestion control, which speeds up DNN training.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- MLTCP: The name of the proposed congestion control technique to accelerate DNN training.

- Communication interleaving: The concept of fitting (interleaving) the communication patterns of different DNN training jobs to better utilize network bandwidth.

- Shortest remaining processing time (SRPT): A policy MLTCP tries to approximate to separate and interleave communication patterns of jobs.

- Bandwidth aggressiveness function: A function used by MLTCP to dynamically adjust the congestion window or rate of flows based on number of bytes sent.

- Job favoritism: MLTCP's policy of allowing certain jobs to occupy more bandwidth to help nudge communication patterns into an interleaved state.  

- Distributed: MLTCP achieves communication interleaving in a distributed manner without needing any centralized controller.

- DNN training acceleration: The paper aims to accelerate distributed DNN training jobs that compete for network bandwidth.

- Congestion control algorithms: The paper augments standard congestion control algorithms like Reno, CUBIC and DCQCN to enable communication interleaving.

Some other relevant terms are pipelining, stragglers, compatibility, and robustness which the paper examines in the context of achieving robust communication interleaving.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper claims that MLTCP achieves robust interleaving. What aspects of the design make it robust to stragglers, partially compatible jobs, and circular dependencies? How does it compare to prior approaches like Cassini and static unfairness?

2. The job favoritism policy is a key technique in MLTCP. Why is the choice of which job to favor important? How does MLTCP determine which job to favor in a distributed manner?

3. Explain the intuition behind using the number of bytes sent to adjust congestion window size. Why is this an effective way to approximate Shortest Remaining Processing Time (SRPT)? 

4. The bandwidth aggressiveness function F(bytes_ratio) is central to MLTCP. What requirements must this function satisfy? How does the choice of slope and intercept parameters impact performance?

5. MLTCP can augment both the additive increase and multiplicative decrease phases of congestion control. How do these two approaches compare in achieving communication interleaving? What are the tradeoffs?

6. The paper evaluates MLTCP-Reno, MLTCP-Cubic and MLQCN. Why do the gains differ across these protocols? What causes MLQCN's higher speedups compared to MLTCP-Reno/Cubic?

7. The heuristic used to detect iteration boundaries relies on gaps in communication. Would MLTCP work for models with more complex communication patterns? When would it start to break down?

8. How does MLTCP handle interactions between flows enabled with MLTCP and legacy flows? Could legacy flows end up being starved? How can this be addressed?

9. MLTCP shifts the notion of fairness from sub-RTT timescales to training iteration timescales. What are the implications of this change? When would it start to negatively impact jobs?

10. The gains demonstrated hold when jobs start at the same time. What happens when job start times are staggered? How should the favoritism policy be adapted to handle this?
