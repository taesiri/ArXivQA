# [Novel View Synthesis with View-Dependent Effects from a Single Image](https://arxiv.org/abs/2312.08071)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel method called NVSVDE-Net that can generate novel views with realistic view-dependent effects from a single image in a self-supervised manner. The key ideas are: 1) Modeling view-dependent effects (VDEs) as negative scene disparities induced by the target camera motion, allowing VDE synthesis by sampling input pixels along epipolar lines. 2) A "relaxed volumetric rendering" approximation that efficiently renders novel views in a single pass by estimating ray point weights and refining sampling distances. 3) Completely self-supervised training only requiring image sequences, with no need for depth or pose ground truth. Experiments on RealEstate10K and MannequinChallenge datasets demonstrate state-of-the-art performance in novel view synthesis quality and efficiency compared to previous methods like PixelNeRF and SceneRF. The NVSVDE-Net is the first to showcase realistic VDEs from single images by exploiting camera motion priors, also enabled by a proposed improved camera pose estimation network.
