# [zPROBE: Zero Peek Robustness Checks for Federated Learning](https://arxiv.org/abs/2206.12100)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research focus seems to be developing a framework for privacy-preserving and Byzantine-robust federated learning. Specifically, the key ideas/contributions appear to be:- Proposing a novel privacy-preserving robustness check based on rank-based statistics (median of cluster means) to identify malicious updates in federated learning without compromising clients' data privacy.- Enabling private and robust aggregation even with malicious clients by incorporating carefully designed zero-knowledge proofs. Their framework, called zPROBE, is the first to provide Byzantine-robust secure aggregation with complexity that scales sub-linearly in the number of clients. - Optimizing the overhead of the zero-knowledge proofs using probabilistic bounds, to reduce client computation/communication costs without sacrificing security.- Evaluating zPROBE on computer vision benchmarks like MNIST, FashionMNIST, and CIFAR-10. Results show it can defend against common Byzantine attacks with higher accuracy compared to prior art, while maintaining efficiency.So in summary, the central hypothesis is that their proposed techniques for establishing robustness thresholds privately using medians of clustered means, and verifying updates via zero-knowledge proofs, can enable practical and secure federated learning even with Byzantine participants. The paper aims to demonstrate the effectiveness of their framework zPROBE in achieving this.
