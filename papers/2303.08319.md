# [FAQ: Feature Aggregated Queries for Transformer-based Video Object   Detectors](https://arxiv.org/abs/2303.08319)

## What is the central research question or hypothesis that this paper addresses?

 The central research question addressed in this paper is how to improve video object detection performance using Transformer-based models. 

The key hypothesis is that aggregating and enhancing the quality of the queries for the Transformer decoder can help handle issues like feature degradation in videos and improve detection accuracy.

Specifically, the paper proposes and evaluates two main ideas:

1) Vanilla Query Aggregation (VQA): Aggregating queries from neighboring frames using a weighted average based on feature similarity.

2) Dynamic Query Aggregation (DQA): Generating dynamic queries adapted to each frame's features, instead of using fixed random queries. The dynamic queries are aggregated across frames.

The overall goal is to improve video object detection accuracy by focusing on the unique properties of Transformer-based detectors, namely the quer
