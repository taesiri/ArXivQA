# [Federated Fairness without Access to Sensitive Groups](https://arxiv.org/abs/2402.14929)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper addresses the challenge of achieving fairness across different sensitive groups in federated learning settings when there is no prior knowledge about the definition of sensitive groups during training. Factors like emerging regulations, group dynamics, and location-dependency make it unrealistic to have predefined labeled sensitive groups in many real-world federated learning applications. Existing approaches rely on the availability of sensitive group information.

Proposed Solution:
The paper proposes a new learning objective called Relaxed Conditional Value-at-Risk (RCVaR) to enhance the performance of the worst-performing subset of data samples without unnecessarily reducing the performance of others. The objective depends on two parameters:

1) Trade-off parameter epsilon that controls the balance between average utility and worst-case (minimax) fairness. 

2) Constraint rho that bounds the size of the worst-case group based on policy/preferences.

The formulation allows identifying any sufficiently large global sensitive group independently of whether it exists in local distributions. It also enables flexibility in the fairness-utility trade-off.

The paper provides an algorithm called FedSRCVaR to solve a smoothed approximation of RCVaR in the federated setting. The algorithm performs local model updates on clients and periodic averaging on the server.

Main Contributions:

- First work to address unknown and inhomogeneous sensitive groups for minimax Pareto federated fairness.

- Introduction of a new flexible fairness-aware learning objective RCVaR that allows improving high-risk samples based only on a group size constraint.

- Drawing connections between RCVaR and existing objectives like DRO and BPF, showing RCVaR generalizes them.

- Algorithm FedSRCVaR to solve RCVaR in federation, with convergence rate and excess risk guarantees.

- Empirical demonstration of achieving a wide range of fairness-utility trade-offs using the epsilon parameter and comparsion to relevant baselines in centralized and federated settings.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a new federated learning approach to achieve Pareto efficient models that ensure worst-case group fairness for any subset of individuals of sufficient size, without requiring predefined sensitive groups or access to sensitive attributes during training.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a new approach to guarantee group fairness in federated learning settings that does not rely on any predefined definitions of sensitive groups or additional labels. Specifically:

1) The paper introduces a new learning objective called Relaxed Conditional Value-at-Risk (RCVaR) that allows improving the performance of the worst-performing subset of data samples without unnecessarily reducing the performance on other samples. This objective enables trade-offs between fairness and utility through a parameter Îµ.

2) The paper draws connections between the proposed RCVaR objective and existing objectives like distributionally robust optimization (DRO) and blind Pareto fairness (BPF). It shows that RCVaR generalizes these objectives.

3) The paper provides an algorithm called FedSRCVaR to optimize a smoothed version of the RCVaR objective in federated settings. It analyzes the convergence and excess risk properties of this algorithm.

4) The paper empirically demonstrates that the proposed approach can effectively improve the worst-performing group, allows achieving a diverse range of fairness-utility trade-offs, and performs comparably or better than relevant baselines in both centralized and federated settings.

In summary, the key contribution is a new flexible learning objective along with an optimization method and theoretical analysis to enable group fairness in federated learning without needing access to sensitive groups.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts include:

- Federated learning - A machine learning setting where multiple clients collaboratively train a model without sharing raw data.

- Group fairness - Ensuring fairness of a machine learning model across different sensitive demographic groups.

- Minimax fairness - A notion of fairness that aims to maximize performance for the worst-off group. Also called Rawlsian fairness. 

- Conditional value at risk (CVaR) - A risk measure that focuses on the tail of the loss distribution. Used to formulate the minimax fairness objective.  

- Relaxed CVaR (RCVaR) - The proposed federated learning objective that balances average performance and minimax fairness.

- Pareto efficiency - The idea that improving one group's performance should not unjustifiably harm another group's performance. The RCVaR objective aims for Pareto efficient fairness.

- Model robustness - Ensuring the model performs fairly for any potential sensitive group definitions, including unknown or unanticipated groups.

- Subgroup robustness - A framework for achieving robustness by considering worst-case performance over subgroups of a certain size. Connections made to blind Pareto fairness.

- Agnostic/blind/no sensitive groups - Key terms indicating the setting with no information about sensitive groups during training.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes a new federated learning objective called Relaxed Conditional Value-at-Risk (RCVaR). How is this objective different from regular Conditional Value-at-Risk (CVaR) and why was this relaxation proposed?

2. RCVaR has a hyperparameter epsilon that controls the tradeoff between average utility and worst-case fairness. What is the intuition behind this parameter and what kinds of solutions can be achieved by tuning it? 

3. The paper shows connections between the RCVaR objective and existing methods like Distributionally Robust Optimization (DRO) and Blind Pareto Fairness (BPF). Can you explain these connections and why they are relevant?

4. Federated Smoothed RCVaR (FedSRCVaR) is the algorithm proposed to optimize the RCVaR objective. Why is a smoothed approximation used here and how does the smoothing parameter gamma affect the optimization?

5. What assumptions does the convergence analysis of FedSRCVaR make and what does the bound on the optimization error tell us about the algorithm's performance?

6. How does the excess risk analysis account for stability and what does the excess risk bound imply about the tradeoff between optimization and generalization error? 

7. What are some key differences between the threshold learning approach used in FedSRCVaR compared to DRO? What are the limitations of federalizing BPF directly?

8. The empirical evaluation shows that FedSRCVaR can recover solutions equivalent to centralized methods. What does this tell us about the proposed method's ability to handle heterogeneity? 

9. How does the performance of FedSRCVaR change with an increasing number of local epochs? What does this suggest about the impact of non-IID data?

10. The paper demonstrates the flexibility of RCVaR through experimental results showing various tradeoff solutions. What is an example scenario where this flexibility would be useful for a policy maker?
