# [A backdoor attack against link prediction tasks with graph neural   networks](https://arxiv.org/abs/2401.02663)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Graph neural networks (GNNs) have shown great performance for link prediction tasks, however they are vulnerable to backdoor attacks. 
- Existing work on GNN backdoor attacks focus on graph classification and node classification tasks, with little research on backdoor attacks against link prediction.

Proposed Solution: 
- The authors propose a backdoor attack method against link prediction using a single node as the backdoor trigger.
- The trigger node features are generated by selecting the rarest features in the graph. 
- A node pair scoring (NPS) function is proposed to select suitable node pairs to inject the trigger for poisoning the training data.
- By adding the trigger node to connect the selected node pairs in training data, the backdoor is embedded into GNN models during training.  
- At inference time, connecting the trigger node to target node pairs activates the backdoor, causing incorrect link prediction between the target nodes.

Main Contributions:
- Propose the first single-node backdoor attack method against GNN link prediction.
- Trigger generation method based on rare feature selection.
- Node pair selection strategy using NPS function for effective poisoning.  
- Achieve high attack success rate (>89%) with low accuracy loss (<1%) using only 1% poisoning rate.
- Experiments on 4 models and 4 datasets demonstrate effectiveness and stealthiness. 

The key novelty is using a single stealthy trigger node, along with a poisoning strategy tailored for link prediction, to implement an effective backdoor attack. The paper reveals a new vulnerability against GNN link prediction models.


## Summarize the paper in one sentence.

 This paper proposes a stealthy backdoor attack against link prediction in graph neural networks, which uses a single node with specially crafted features as the trigger and poisons the training data by connecting the trigger node to selected node pairs in the graph to make the model incorrectly predict unlinked node pairs as linked when the trigger node is present.


## What is the main contribution of this paper?

 This paper makes several main contributions to research on backdoor attacks against link prediction with graph neural networks (GNNs):

1. It proposes a new backdoor attack method that uses a single node as the trigger. This makes the attack more stealthy and requires a lower poisoning rate compared to prior attacks. 

2. It introduces a fast and effective trigger generation method that creates the trigger node's features based on statistical analysis of the graph to maximize its distinction from normal nodes.

3. It presents a simple and efficient data poisoning method that connects the trigger node to selected node pairs in the graph to achieve high attack success rates with low poisoning rates. 

4. It evaluates the attack on four popular GNN models and four benchmark datasets, demonstrating attack success rates over 89% in black-box scenarios with only around 1% poisoning rate and less than 1% drop in model accuracy on clean samples.

In summary, the main contribution is proposing and evaluating a highly effective and stealthy backdoor attack against link prediction that poses a new security threat to GNNs for this task. The attack is practical, achieving high attack success rates with low poisoning rates and without needing access to the target model parameters or training process.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this paper include:

- Graph neural networks (GNNs)
- Link prediction
- Backdoor attacks
- Trigger node
- Poisoning attacks
- Attack success rate (ASR)
- Benign performance drop (BPD)  
- Transductive learning
- Message passing mechanism
- Graph embedding
- Variational graph autoencoder (VGAE)
- Adversarial regularization

The paper proposes a backdoor attack method against link prediction tasks using graph neural networks. The goal is to incorrectly predict a link relationship between two unlinked nodes when a trigger node is present. The key ideas include:

- Using a single node as the backdoor trigger 
- Generating the trigger node features based on feature statistics
- Selecting target node pairs for poisoning using a scoring function 
- Evaluating attack success rate, benign performance drop, and poisoning rate

So in summary, the key focus is on backdoor attacks, link prediction, graph neural networks, trigger generation, data poisoning, and attack evaluation metrics.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes using a single node as the backdoor trigger. What is the rationale behind using a single node rather than a subgraph as the trigger? What are the advantages and disadvantages of this approach?

2. The paper generates the feature vector of the trigger node by selecting the features that occur least frequently in the nodes of the graph. Why is this an effective approach? How does this increase the discrepancy between the trigger node and normal nodes?

3. The paper proposes a node pair scoring (NPS) function to select suitable node pairs for injecting the trigger. Explain the rationale behind the design of this scoring function. How does it help select optimal node pairs to improve attack effectiveness? 

4. In the backdoor injection process, the trigger node is connected to two end nodes of the selected node pairs and their link state is changed to "linked." Explain why this approach effectively injects the backdoor during model training.

5. The attack is evaluated on 4 different graph neural network models for link prediction. Analyze and discuss how the attack performance varies across these models. What inferences can you draw about the robustness of these models?

6. How does the attack performance vary with different choices of the trigger node feature budget k? What is the optimal choice of k to balance attack effectiveness and stealthiness?

7. The ablation study shows that the proposed node pair selection method outperforms random selection. Analyze the reasons why the proposed selection approach works better.

8. What defenses could potentially be used to protect against such backdoor attacks on link prediction models? What are some ways the attack could be further strengthened to bypass defenses?  

9. The attack uses transductive learning for link prediction. How would the attack methodology have to be adapted for inductive learning settings? Identify any additional challenges.

10. The paper demonstrates a black-box attack setting. What additional capability would the attacker need to implement a white-box attack? How could the methodology be altered for a white-box attack scenario?
