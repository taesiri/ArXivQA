# [Quantifying Divergence for Human-AI Collaboration and Cognitive Trust](https://arxiv.org/abs/2312.08722)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes novel measures of "decision-making similarity" between humans and AI models to quantify their potential for collaboration and establish cognitive trust. Specifically, the authors calculate divergence metrics like KL divergence and Jensen-Shannon distance between label distributions provided by humans and various AI models on a textual entailment task. They then conduct a multi-stage user study where participants choose the model with the most similar label distribution to their own judgments. Participants are asked about their willingness to collaborate with and trust in their matched model. The study finds that humans tend to collaborate with models that have high confidence agreement on answers, indicated by low inverse KL divergence. However, cognitive trust also requires avoiding overconfidence when unsure, reflected through forward KL divergence. Overall, decision-making similarity correlates with collaboration likelihood, but individuals may still collaborate even if they lack full cognitive trust. This work provides new ways to approximate human preferences toward AI systems prior to real-world deployment.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Predicting human-AI collaboration likelihood and measuring cognitive trust are important when deploying AI systems, but prior work focuses solely on model features (e.g. accuracy) and ignores the human factor. 

- This work aims to analyze the impact of "decision-making similarity" between humans and AI models on collaboration likelihood and cognitive trust.

Methodology:
- Train diverse NLP models (tf-idf, LSTM, RoBERTa, Davinci) on natural language inference (NLI) task. 

- Propose divergence metrics on soft labels to quantify decision-making similarity: α-KL, β-KL, JSD.

- Conduct 4-stage user study:
   1) Users pick closest soft label distribution to theirs from models
   2) Align user with most similar model via JSD  
   3) Show user agreements/disagreements with aligned model
   4) User rates collaboration likelihood & cognitive trust

Key Results:
- People collaborate more with models having similar decision making processes, measured by JSD, but may not trust them as much.

- Low β-KL divergence (agreeing on answers with high confidence) most influences collaboration.  

- Cognitive trust relates to low β-KL but may also require low α-KL (avoiding overconfidence).

Main Contributions:
- First study analyzing impact of decision-making similarity on human-AI collaboration and trust.

- Comprehensive user study methodology using soft labels to quantify similarities.

- Relate different divergence metrics on labels to collaboration and trust aspects.
