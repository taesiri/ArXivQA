# [Large Human Language Models: A Need and the Challenges](https://arxiv.org/abs/2312.07751)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Language is an expression of human thoughts, emotions and experiences. To truly understand language, we need to model the human context i.e. the personal, social and situational attributes of the person generating the language.  
- Large language models (LLMs) like BERT and GPT-3 have become the foundation of most NLP systems today. But they only model language in the context of neighboring words, and do not capture the human context.

Proposed Solution:
- The authors advocate for developing large "human" language models (LHLMs) that integrate rich human contexts directly into language model training. 

Main Contributions:

Position 1) Include human context in LM training:
- Motivation: Treat texts from a person as inter-dependent based on their shared human context to avoid "ecological fallacy". 
- Challenges: Architectural decisions, model scaling, data processing of long historical texts.
- Possible solutions: Add human context vector to word vectors or compose it similar to position embeddings. Use recurrence over blocks.

Position 2) Recognize people are more than their groups:  
- Motivation: Represent human context as a mixture of factors, not discrete groups. Capture breadth across human diversity.
- Challenges: Limited datasets, privacy issues, model scalability.
- Possible solutions: Text-based human attribute inference, strict policies to prevent misuse, avoid separate model per user.

Position 3) Model dynamic and temporal nature of human context:
- Motivation: Human states change over time influencing language. Capture changing states. 
- Challenges: Temporal gaps in data, modeling complex temporal dynamics.
- Possible solutions: Objectives predicting language after temporal intervals, not just immediate context.

By developing LHLMs using these guidelines, we can create language models that better capture the essence of human communication.
