# [A citizen science toolkit to collect human perceptions of urban   environments using open street view images](https://arxiv.org/abs/2403.00174)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Commercial street view imagery (SVI) platforms like Google restrict usage for research purposes due to licensing terms. Open/volunteered SVI platforms exist but require substantial processing and quality control before usable.
- Capturing human perceptions of urban environments typically relies on resource-intensive methods like interviews and questionnaires. Developing an efficient and reusable way to gather these perceptions would help research aiming to improve quality of life in cities.

Proposed Solution:
- Develop an open source pipeline to filter and process volunteered SVI (VSVI) from Mapillary using semantic segmentation and image quality analysis.
- Build a mobile-friendly web app to collect human perception ratings on 5 criteria related to urban environments, using the processed VSVI.
- Use a "citizen science" approach to gather ratings from volunteers via the easy-to-use web app.
- Apply FAIR principles to the data and software developed to enable reproducibility and reuse.

Main Contributions:
- Software to automatically download, process, filter and crop VSVI from Mapillary ready for perception analysis
- Smartphone-friendly web app with intuitive interface to collect human perception ratings on SVI 
- Case study collecting over 20,000 ratings across 100,000+ images of Amsterdam from 300+ people
- Open source and reusable pipeline applying FAIR principles that anyone can replicate for their region of interest

In summary, the authors developed an end-to-end open source toolkit leveraging Mapillary VSVI and citizen science to efficiently collect human perceptions of urban areas at scale, with the goal of enabling research that can guide planning decisions to improve quality of life.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper presents an open-source toolkit to efficiently download, process, filter and survey human perception of open street view imagery in a reusable and transparent way aligned with FAIR principles.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is:

The authors have developed an open-source, end-to-end toolkit for downloading, processing, filtering and surveying human perception of street view imagery from the Mapillary platform. This toolkit enables citizen science research by providing both a mobile-friendly web app for participatory sensing of perception data, as well as making the software and processed data findable, accessible, interoperable and reusable (FAIR) for other researchers. The authors demonstrate the toolkit with a case study focused on Amsterdam, Netherlands, in which they collected over 20,000 perception ratings across 100 images from over 300 participants.

In summary, the key contribution is an open and reusable pipeline for harnessing volunteered street view imagery and citizen science to study human perception of urban environments. The software and methods are made available for others to replicate or build upon this approach in their own location of interest.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the main keywords or key terms associated with it are:

- Street view imagery (SVI)
- Open source 
- Human perception
- Environment
- Toolbox
- Citizen science
- Mapillary
- Volunteered street view imagery (VSVI) 
- FAIR principles
- Findable, accessible, interoperable and reusable principles
- Mobile survey
- Web application
- Image processing
- Image quality
- Road centerline detection
- Semantic segmentation

The paper presents an open-source toolkit to collect human perceptions of urban environments using open street view images from Mapillary. It takes a citizen science approach and aligns with FAIR principles to make the data and software reusable and reproducible. Key aspects include processing and filtering street view images from Mapillary, building a mobile-friendly web application survey to gather human perception ratings on those images, and using methods like semantic segmentation to detect road centerlines. The overall goal is to enable the collection of subjective perception data at scale to study urban areas.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper relies on using Mapillary imagery rather than commercial providers like Google due to restrictive terms of service. What are some potential downsides or limitations of relying solely on volunteered, user-contributed imagery instead of professionally captured imagery? How might this affect the quality or coverage of images available?

2. The process of finding "sensible subimages" from panoramic images involves detecting road center lines using semantic segmentation. What are some potential failure cases or limitations of this approach? When might the estimated road center lines be inaccurate? 

3. The image filtering process uses measures of contrast and tone mapping to determine image quality. What are some other metrics that could be used to filter low quality images? What types of issues might the current metrics fail to detect?

4. The survey interface uses a 5-point absolute scale for rating images rather than relative comparisons between images. What are the tradeoffs between these two rating approaches? In what situations might relative comparisons be more appropriate?

5. The backend enforces limits on the undo protocol to prevent large scale deletion of ratings. What are some alternative strategies that could provide more flexible undo while still protecting data integrity?

6. What techniques could be used to detect and filter out adversarial, repetitive or invalid ratings submitted through the public API? How might the system be gamed and what safeguards could mitigate this? 

7. The spatial distribution of averaged perception ratings is visualized on a hexagonal grid. What are some other ways the geospatial perception data could be analyzed or visualized? What factors might influence geographic variation?

8. The survey currently has 100 ratings per participant. How was this number chosen? What are considerations in determining an appropriate survey length that avoids fatigue while collecting sufficient data?

9. The model of distributing image ratings to random survey participants could be seen as a form of crowdsourcing. What techniques could improve the reliability of aggregated crowd ratings? When might certain demographics provide systematically different ratings?

10. The paper proposes future work to train computer vision models on the rating data. What additional data beyond ratings could be collected to better capture human perceptual qualities of street imagery? What other model architectures or training schemes could be explored?
