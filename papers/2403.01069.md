# [LLMCRIT: Teaching Large Language Models to Use Criteria](https://arxiv.org/abs/2403.01069)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Humans use criteria to judge the quality of task completion, but current AI models do not effectively leverage comprehensive criteria when providing feedback. This limits the helpfulness of model-generated feedback.

- Two main challenges exist: (1) criteria are often implicit in guidelines rather than explicit, (2) the large number of criteria makes it difficult for models to properly apply them.

Proposed Solution:
- A new framework called LLMCrit that teaches large language models (LLMs) to generate natural language feedback using comprehensive criteria extracted from task guidelines. 

- Uses a model-in-the-loop approach to: (1) semi-automatically extract atomic criteria from guidelines, (2) construct demonstrations for each criterion showing how to apply it.

- Provides the extracted criteria and demonstrations to LLMs to guide their feedback generation process.

Key Contributions:
- Proposes the new task of "teaching LLMs to use criteria" for helpful feedback generation.

- Introduces the LLMCrit framework for semi-automatically deriving criteria/demonstrations from guidelines and using them to enhance LLM feedback.

- Evaluates LLMCrit on 3 writing tasks: scientific papers, Python code, Reddit posts. Proposes layered metrics to effectively evaluate quality of feedback.

- Experiment results provide insights into the effects of criteria and demonstrations on feedback, and suggest that providing criteria alone efficiently improves feedback quality.

- Releases extracted criteria and demonstrations for the 3 tasks to support future research.
