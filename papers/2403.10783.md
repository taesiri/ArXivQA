# [StableGarment: Garment-Centric Generation via Stable Diffusion](https://arxiv.org/abs/2403.10783)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "StableGarment: Garment-Centric Generation via Stable Diffusion":

Problem:
- Existing virtual try-on methods face limitations when extended beyond conventional tasks. Fashion merchants need to create varied product images like posters more cost-effectively. 
- There is a demand for quick adjustments to models, poses, atmospheres via text prompts while accurately depicting fabric details. 
- Stable Diffusion's adaptability presents potential but prior works haven't fully exploited its capabilities for garment-centric text-to-image and stylized image creation. They also fail to preserve complete garment patterns.

Proposed Solution:
- The paper introduces the concept of Garment-Centric (GC) Generation which focuses on maintaining fidelity of garment details while enabling flexibility in image creation.
- It proposes StableGarment, a unified framework built on Stable Diffusion, designed to release its full potential.
- A garment encoder is introduced to encode target garment details. It interfaces with the stable diffusion model through an innovative additive self-attention mechanism that facilitates integration of stylized base models.
- A dedicated try-on ControlNet is incorporated to empower the model with virtual try-on capabilities.
- A restructured training dataset enriched with varied text prompts enhances the model's prompt following ability.

Main Contributions:
- Proposes a unified framework to address GC generation tasks including GC text-to-image, controllable GC text-to-image, stylized GC text-to-image and robust virtual try-on within a single model.
- Introduces an additive self-attention layer that enables seamless model switching to stylized base-models. Also proposes a data engine to enhance prompt following ability.
- Demonstrates state-of-the-art performance across tasks, underscoring the superiority of the approach.

In summary, the paper presents an innovative framework StableGarment built on Stable Diffusion that can perform various garment-centric generation tasks with flexibility while preserving intricate garment details. Extensive experiments demonstrate its state-of-the-art performance.
