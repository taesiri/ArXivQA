# [Assessing Visually-Continuous Corruption Robustness of Neural Networks   Relative to Human Performance](https://arxiv.org/abs/2402.19401)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Neural networks (NNs) have surpassed human accuracy on ImageNet image classification, but often lack robustness to common corruptions compared to human perception.
- Existing benchmarks like ImageNet-C only evaluate robustness on a few fixed levels of corruption, which does not cover the full continuous range of visual changes that humans can perceive. This can lead to incomplete evaluation.

Proposed Solution:
- The paper proposes "visually-continuous corruption robustness (VCR)" to assess robustness across the full continuous range of visual corruption levels that affect human perception.
- VCR uses an image quality assessment metric (VIF) to measure the degree of visual corruption. Test sets are generated by uniform random sampling over all possible corruption levels.
- Two new human-aware evaluation metrics are introduced: 1) Human-Relative Model Robustness Index (HMRI) to quantify how close NN robustness is to human, and 2) Model Robustness Superiority Index (MRSI) to measure if NN exceeds human robustness.

Contributions:
- Conducted extensive experiments with 7,718 humans over 14 common corruptions to benchmark human VCR.
- Evaluated VCR of 21 state-of-the-art NN models. Showed that the gap between human and NN robustness is larger than previously known when considering the full range of visual changes.
- Discovered classes of "visually similar" corruptions where human data can be reused to reduce experiment cost. 
- Provided all human data, code and model evaluation results as an open benchmark to facilitate future research.

In summary, the paper demonstrates that evaluating robustness over continuous visual corruption levels is necessary for accurate benchmarking, reveals bigger robustness gaps between human and NNs, and enables more cost-effective evaluation.
