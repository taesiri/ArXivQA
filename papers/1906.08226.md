# [Unsupervised State Representation Learning in Atari](https://arxiv.org/abs/1906.08226)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is: How can we learn useful state representations from high-dimensional visual observations in an unsupervised manner for interactive environments like video games?The key points are:- The paper proposes a new unsupervised representation learning technique called Spatiotemporal DeepInfoMax (ST-DIM) that learns state representations by maximizing mutual information across spatial and temporal dimensions. - The paper introduces a new benchmark for evaluating state representation learning based on Atari 2600 games, where ground truth state variables are extracted to measure how well representations capture the true factors of variation.- The paper compares ST-DIM to other representation learning methods like VAEs, pixel prediction, and CPC on the proposed Atari benchmark.- The results show ST-DIM outperforms other approaches, especially at capturing small objects and avoiding easy-to-exploit features. The paper argues maximizing patch-based mutual information helps ST-DIM learn more complete representations.- Overall, the main research contribution is presenting ST-DIM as a new technique for unsupervised visual representation learning and demonstrating its effectiveness on the Atari benchmark compared to other methods. The benchmark itself is also presented as a useful tool for evaluating progress in representation learning.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It proposes a new self-supervised state representation learning technique called Spatiotemporal Deep InfoMax (ST-DIM) that exploits the spatial-temporal nature of visual observations in reinforcement learning environments. The key idea is to maximize mutual information across both spatial and temporal dimensions.2. It introduces a new benchmark for evaluating state representation learning techniques based on 22 Atari 2600 games. The benchmark leverages the source code of the games to extract ground truth state variables (e.g. locations of objects) that can be used to systematically evaluate how well a representation captures the underlying factors of variation.3. It provides an extensive empirical evaluation of existing representation learning techniques like VAEs, pixel prediction, and CPC on the proposed benchmark. The results demonstrate that the proposed ST-DIM technique outperforms prior methods, especially at capturing small objects and in environments where some factors are easy to exploit.4. The paper helps shed light on the tradeoffs between generative and contrastive representation learning techniques. Generative methods are better at capturing large low-entropy objects while contrastive methods prefer high-entropy objects.In summary, the key contributions are proposing a new spatio-temporal contrastive representation learning technique, a systematic benchmark for evaluating such techniques, and an extensive empirical analysis demonstrating the advantages of the proposed approach. The benchmark and analysis help advance research on learning useful state representations.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on skimming the paper, here is a one sentence TL;DR summary:The paper proposes a new unsupervised representation learning technique called Spatiotemporal DeepInfomax (ST-DIM) that maximizes mutual information across spatial and temporal dimensions, and introduces a new benchmark for evaluating state representations using linear probing of ground truth factors in Atari games.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in unsupervised representation learning:- The focus on learning state representations that capture ground truth factors of Atari games makes it fairly unique. Most prior work evaluates representations more indirectly through downstream tasks like RL, rather than probing for specific semantic factors. The proposed benchmark provides a more direct way to evaluate how well different methods capture true states.- Using mutual information maximization across space and time to learn representations builds off recent work like DeepInfoMax, but the spatial contrastive loss and application to RL environments is novel. - The extensive comparison of contrastive methods like ST-DIM and CPC to popular generative approaches like VAEs and pixel prediction on this new benchmark sheds light on their relative strengths/weaknesses. The results suggest contrastive methods are better overall at capturing the factors.- The conclusions around contrastive methods being better at small objects and generative methods better on large/slow-moving objects provide an interesting qualitative analysis. The issue with contrastive methods overly focusing on simple exploitable features is also an important downside revealed.- The preliminary RL agent probing results showing they fail to match up to unsupervised methods suggests room for improvement in getting agents to learn better state representations. More investigation of agent representations could be an impactful direction.Overall, I'd say the paper makes a nice contribution in rigorously evaluating unsupervised representation learning methods on a novel challenging benchmark reflecting true environment states. The spatial/temporal contrastive approach also seems promising. The analysis illuminates relative strengths and weaknesses of different methods.
