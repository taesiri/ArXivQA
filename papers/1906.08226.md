# [Unsupervised State Representation Learning in Atari](https://arxiv.org/abs/1906.08226)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is: How can we learn useful state representations from high-dimensional visual observations in an unsupervised manner for interactive environments like video games?The key points are:- The paper proposes a new unsupervised representation learning technique called Spatiotemporal DeepInfoMax (ST-DIM) that learns state representations by maximizing mutual information across spatial and temporal dimensions. - The paper introduces a new benchmark for evaluating state representation learning based on Atari 2600 games, where ground truth state variables are extracted to measure how well representations capture the true factors of variation.- The paper compares ST-DIM to other representation learning methods like VAEs, pixel prediction, and CPC on the proposed Atari benchmark.- The results show ST-DIM outperforms other approaches, especially at capturing small objects and avoiding easy-to-exploit features. The paper argues maximizing patch-based mutual information helps ST-DIM learn more complete representations.- Overall, the main research contribution is presenting ST-DIM as a new technique for unsupervised visual representation learning and demonstrating its effectiveness on the Atari benchmark compared to other methods. The benchmark itself is also presented as a useful tool for evaluating progress in representation learning.
