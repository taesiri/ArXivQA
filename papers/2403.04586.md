# [Learning Agility Adaptation for Flight in Clutter](https://arxiv.org/abs/2403.04586)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Animals and robots need to balance agility and safety when moving in unknown, cluttered environments. Determining the right level of agility is challenging.
- Existing methods for robotic flight either use a conservatively low constant agility level or require a fully known prior map of the environment. 

Proposed Solution:
- A hierarchical learning framework to adaptively determine agility level for flight in unknown cluttered environments. 
- An "agility policy" is learned with reinforcement learning to output the agility level based on observations.
- The agility level is used by an underlying model-based trajectory planner to generate a trajectory.

Key Contributions:
- Agility policy learned with a two-stage "pre-training-fine-tuning" reward scheme. The first stage uses human domain knowledge for a smooth reward, while the second stage uses a sparse objective collision reward.
- Policy architecture combines CNNs, MLPs, and inputs occupancy maps, vehicle state, tracking error and previous agility level. 
- Benefits shown over constant agility methods and a non-learning method in complex simulation environments in terms of efficiency, safety and intelligent perception-aware behaviors.
- Policy deployed on a real micro drone with depth camera and onboard computing in cluttered environments, showing adaptive agility selection and safe flight.

In summary, the key innovation is a learned policy that adapts agility level to balance speed and safety during flight in complex environments, on top of a model-based trajectory planner. The results demonstrate clear benefits for autonomous flight in the real world.
