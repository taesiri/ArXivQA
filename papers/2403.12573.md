# [Lifting Multi-View Detection and Tracking to the Bird's Eye View](https://arxiv.org/abs/2403.12573)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Multi-target multi-camera (MTMC) tracking is challenging due to needing to associate detections across views and time. Recent works focus separately on pedestrian or vehicle tracking.
- Lifting image features from 2D camera views to 3D is an important capability for fusing multi-view data. Different lifting methods have tradeoffs.

Proposed Solution:
- Present a unified MTMC tracking architecture that works for both pedestrian and vehicle tracking. 
- Compare different lifting methods - perspective transform, depth splatting, bilinear sampling, deformable attention - to project image features to bird's eye view.
- Propose a tracking method that predicts location offsets between current and prior detections in BEV space to enable motion-based association while still using appearance features.

Main Contributions:
- Evaluation of various lifting methods for MTMC tracking task, with state of the art results using simple bilinear sampling
- A tracking architecture that combines motion-based and appearance-based association by predicting offsets between current and prior BEV detections
- New strong baseline and results on pedestrian (Wildtrack, MultiviewX) and vehicle (Synthehicle) datasets. Identify need for more 3D-based benchmarks.

In summary, this paper explores different techniques to lift image features to BEV space for multi-camera tracking, and contributes a tracking method that associates current and prior detections in BEV via predicted offsets. The unified architecture sets strong baselines across pedestrian and vehicles datasets.
