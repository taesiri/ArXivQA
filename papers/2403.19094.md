# [Learning From Correctness Without Prompting Makes LLM Efficient Reasoner](https://arxiv.org/abs/2403.19094)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) still have issues like hallucination, unfaithful reasoning, and generating harmful content. A common approach is to improve LLMs through learning from external feedback (e.g. humans, tools), but this can be expensive and not real-time.  
- Existing self-correction methods rely on learning from errors using tailored prompts, but recent work shows LLMs struggle to self-correct. So there is a need for prompt-free, intrinsic self-correction.

Proposed Solution:
- The paper proposes a new multi-step reasoning paradigm called "Learning from Correctness" (LeCo) that improves reasoning by accumulating correct steps.
- LeCo calculates a confidence score for each reasoning step based on the token logits. The step with the lowest confidence is treated as the earliest error. The preceding "correct" steps are appended to the input and reasoning is repeated.
- The step confidence score is calculated by combining the average token confidence, divergence of probabilities, and transition score between steps. This measures confidence from both intra- and inter-step perspectives.

Main Contributions:
- A new intrinsic self-correct reasoning framework (LeCo) that improves LLM reasoning performance without needing human feedback, tools, or prompt engineering.
- A novel method to estimate step-level confidence scores based on logits, which can identify about 65% incorrect steps. 
- Experiments on arithmetic, logical, and commonsense reasoning tasks show LeCo significantly boosts performance and reduces tokens needed compared to baselines.
- LeCo works well on both major LLMs like GPT-3.5/4 and open-source models like DeepSeekMath-7B.
- Overall, LeCo offers a promising new avenue to enhance LLM reasoning abilities without external input.
