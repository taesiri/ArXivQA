# [Automatic Combination of Sample Selection Strategies for Few-Shot   Learning](https://arxiv.org/abs/2402.03038)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- In few-shot learning approaches such as meta-learning, few-shot fine-tuning, or in-context learning, the limited number of labelled samples used to train or adapt models have a significant impact on performance.
- Selecting high-quality and informative samples is crucial, but most work uses simple random selection. Many sample selection strategies exist but their impact in few-shot settings is not well studied.  

Method:
- The paper thoroughly investigates the impact of 20 sample selection strategies spanning similarity, diversity, uncertainty, core-sets, learnability etc. across 5 few-shot learning approaches on 14 classification datasets.
- A new method called ACSESS is proposed to automatically identify and combine complementary selection strategies to leverage their strengths. It has 3 main steps:
   1) Identify relevant strategies using forward selection, backward elimination and a datamodels-inspired approach.
   2) Combine strategies using weighted average based on expected contribution.
   3) Evaluate 3 weighting schemes - uniform, learned dataset-specific weights, and with added randomness.

Key Results:
- Many strategies lead to performance improvements in few-shot contexts, but effectiveness is strongly dependent on modality, dataset and approach. 
- Learnability metrics were most consistent indicators of quality across settings.  
- ACSESS consistently outperformed all individual strategies, giving up to 5 pp improvement, better than recent method LENS.
- Sample selection impact much higher for lower number of shots, regressing to random selection by 30-40 shots.  
- After 50 shots for gradient approaches, 20 shots for in-context learning, more labelled data did not improve performance.

Main Contributions:  
- First thorough study of sample selection strategy impact across range of few-shot contexts
- Effective novel method to automatically combine complementary strategies 
- Analysis of trends - dependence on shots, modalities, models etc.
- Key practical insights on data requirements for few-shot learning performance.
