# User Satisfaction Estimation with Sequential Dialogue Act Modeling in   Goal-oriented Conversational Systems

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is: How can the sequential dynamics of dialogue acts be leveraged to facilitate user satisfaction estimation (USE) in goal-oriented conversational systems?The key points are:- User satisfaction in goal-oriented dialogues depends on whether the system successfully meets the user's needs and goals. - Dialogue acts, representing user intents/actions at each turn, can reflect the fulfillment of user goals.- But prior work neglects the sequential transitions between dialogue acts.Thus the paper proposes to model the sequential dynamics of dialogue acts to better estimate user satisfaction in goal-oriented systems.


## What is the main contribution of this paper?

This paper proposes a novel method called USDA to jointly learn user satisfaction estimation (USE) and dialogue act recognition (DAR) in goal-oriented conversational systems. The key contributions are:- It leverages the sequential dynamics of dialogue acts to improve USE via joint learning with DAR. Both supervised and unsupervised DAR modules are developed to handle situations with or without dialogue act annotations. - It introduces two self-supervised pre-training strategies - system response selection (SRS) and dialogue incoherence detection (DID) to enhance the dialogue modeling capability of the model without extra human annotation.- Experiments on 4 goal-oriented dialogue datasets show USDA outperforms existing methods on USE. Analyses also reveal the correlation between dialogue act sequences and user satisfaction.- It provides a new perspective to understand user dis/satisfaction by modeling dialogue act transitions in goal-oriented conversations.In summary, the main contribution is using the sequential dynamics of dialogue acts to improve user satisfaction estimation via joint learning, and showing its effectiveness over strong baselines on multiple real-world datasets. The self-supervised pre-training and interpretability of dialogue act sequences also enhance the proposed model.
