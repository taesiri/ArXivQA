# [Global Optimality without Mixing Time Oracles in Average-reward RL via   Multi-level Actor-Critic](https://arxiv.org/abs/2403.11925)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- In average-reward reinforcement learning (RL), the requirement for oracle knowledge of the mixing time (the time a policy's Markov chain takes to reach stationarity) poses challenges for proving global convergence of policy gradient methods. 
- Estimating mixing times is difficult, especially in large state spaces, leading to impractically long trajectory requirements.  
- The recent PPGAE method achieves global convergence but relies on known mixing times and extremely long trajectories, leaving open the problem of a practical global convergence guarantee without mixing time knowledge.

Proposed Solution:
- The paper considers the Multi-level Actor-Critic (MAC) framework which uses a Multi-level Monte Carlo gradient estimator to avoid mixing time dependence.
- Theoretical analysis is provided that proves MAC achieves global convergence to the optimal policy without requiring mixing time knowledge.
- A tighter mixing time dependence of O(√τ_mix) is shown compared to O(τ_mix^2) for PPGAE.
- Practical advantages are highlighted: MAC has no minimum trajectory length requirements related to mixing/hitting times or sample budget.

Main Contributions:  
- First proof of global convergence for an average-reward policy gradient method without mixing time knowledge.
- Tightest-known mixing time dependence despite no oracle knowledge.  
- Empirical demonstration of higher reward for MAC over PPGAE in a navigation task, especially with small sample budgets.

In summary, the paper addresses a key open problem in average-reward RL, proving global optimality guarantees for the MAC algorithm. Theoretical and empirical evidence is provided that MAC is significantly more practical than prior methods relying on mixing time knowledge.
