# [Unlearning Backdoor Threats: Enhancing Backdoor Defense in Multimodal   Contrastive Learning via Local Token Unlearning](https://arxiv.org/abs/2403.16257)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Multimodal contrastive learning (MCL) models like CLIP are vulnerable to backdoor attacks where attackers poison training data to trigger malicious behaviors. 
- Existing defenses require extensive clean data which is inefficient and can reduce model accuracy.

Proposed Solution:
- Propose a targeted unlearning strategy to erase backdoor associations without full model retraining.  
- Enhance backdoor shortcuts by overfitting model on suspicious samples to better identify poisoned data.
- Introduce token-based localized forgetting - selectively forget token embeddings that contribute to backdoor to sever associations.

Main Contributions:
- Novel defense against backdoor attacks on MCL using model unlearning rather than full retraining.
- Poisoned sample overfitting to strengthen backdoor shortcuts and better detect suspicious samples.  
- Innovative token-level local unlearning applied only on suspicious samples to preserve clean accuracy.
- Experiments show the method ensures minimal attack success rate while maintaining high clean accuracy.

In summary, the key innovation is using a small set of poisoned samples to locally erase backdoor triggers via targeted unlearning of token embeddings, without needing extensive clean data. This efficiently eliminates backdoor associations in MCL models while preserving accuracy.
