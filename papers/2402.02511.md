# [PoCo: Policy Composition from and for Heterogeneous Robot Learning](https://arxiv.org/abs/2402.02511)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Training robotic manipulation policies that can generalize across heterogeneous data from different tasks, modalities, and domains is challenging. Existing datasets vary in modalities (e.g. RGB, depth, tactile), data sources (simulation, real-robot, human demonstrations), and embodiment. Typical methods train policies on data from one domain, which requires extensive engineering, or naively pool all data, which is inefficient.

Proposed Solution:  
The paper proposes "Policy Composition" (PoCo), a framework to modularly compose policies trained on different domains/modalities into a unified policy at test time. By representing policies as conditional diffusion models, composition is done by summing the model gradients during sampling. This allows flexibly combining policies without retraining.

The key ideas are:
(1) Represent policies as conditional diffusion models, enabling probabilistic composition 
(2) Compose policies at different levels:
    - Task-level: Compose unconditional and task-conditional policies
    - Behavior-level: Compose policies with cost functions encoding desired behaviors 
    - Domain-level: Compose policies trained on different modalities (RGB, depth, tactile) and domains (simulation, human, robot)
(3) Policies can be composed at test-time in arbitrary combinations without retraining.

Contributions:
(1) A policy composition framework to combine heterogeneous robot learning data/policies
(2) Composition at task, behavior, and domain levels to improve generalization  
(3) Simulation and real-world experiments on tool use tasks combining data across modalities and domains
(4) Robust performance across changes in scenes, tools, goals without fine-tuning

The method composes policies from simulation, real-robot, and human demonstrations to accomplish tool use tasks involving reaching, scooping, hammering, and cutting. Experiments show the approach generalizes significantly better to variations in scenes, tools, and goals compared to baselines trained on a single domain.
