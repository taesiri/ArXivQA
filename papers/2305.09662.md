# [Make-An-Animation: Large-Scale Text-conditional 3D Human Motion   Generation](https://arxiv.org/abs/2305.09662)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we improve text-to-motion human pose generation models, especially for diverse, in-the-wild text prompts, by leveraging large-scale image datasets?The key hypotheses appear to be:1) Pre-training on a large-scale dataset of text-pseudo-pose pairs extracted from image-text datasets can help the model learn a better distribution of human poses and alignment with text descriptions. This will improve generalization to new prompts. 2) A U-Net architecture with temporal convolutions and attention can effectively extend a static pose generation diffusion model to motion generation in a stable way.3) By combining large-scale pre-training and a U-Net architecture, we can significantly improve text-to-motion generation, especially for diverse prompts, compared to prior state-of-the-art models.In summary, the main research question is how to leverage large-scale image datasets to improve text-to-motion generation through pre-training and a suitable model architecture. The key hypotheses are around the benefits of pre-training, using a U-Net architecture, and combining these to achieve state-of-the-art performance.
