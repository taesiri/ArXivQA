# [Exploiting Diffusion Prior for Real-World Image Super-Resolution](https://arxiv.org/abs/2305.07015)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we leverage the diffusion priors from pre-trained text-to-image diffusion models like Stable Diffusion for the task of blind super-resolution of real-world images, without having to train a new model from scratch?The key hypotheses appear to be:1) By fine-tuning only a lightweight time-aware encoder attached to a frozen pre-trained Stable Diffusion model, the generative priors can be preserved while adapting the model for super-resolution in an efficient manner. 2) The time-aware encoder can provide adaptive guidance to the diffusion model during sampling, with stronger guidance earlier in the process and weaker guidance later, to help maintain fidelity.3) A controllable feature wrapping module can allow trading off between fidelity and realism by residual tuning of the diffusion model's decoder features based on the encoder features.4) A progressive patch aggregation sampling strategy can enable handling arbitrary image resolutions beyond the fixed resolution of the pre-trained model.So in summary, the central research question is how to effectively adapt a pre-trained generative diffusion model for blind super-resolution of real-world images through targeted fine-tuning, while avoiding heavy re-training and preserving the useful generative priors.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions seem to be:- Proposing a new method called StableSR that leverages pre-trained diffusion models like Stable Diffusion for the task of real-world image super-resolution. - Introducing a time-aware encoder module that can provide adaptive guidance to the diffusion model during the image generation process. This allows finetuning the diffusion model while preserving its generative prior.- Developing a controllable feature wrapping module to balance between fidelity and realism in the super-resolved outputs. This allows handling both light and heavy degradations. - Presenting a progressive aggregation sampling strategy to enable the pre-trained diffusion model to handle images of arbitrary resolutions during inference.- Achieving state-of-the-art performance on both synthetic and real-world SR benchmarks while being efficient by finetuning on a frozen pre-trained diffusion model.In summary, the key contribution appears to be proposing an effective way to adapt pre-trained diffusion models for real-world SR by designing modules to address challenges like generative prior preservation, fidelity-realism trade-off, and arbitrary image sizes. The method achieves strong practical performance as validated through experiments.
