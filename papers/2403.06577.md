# [Transformer-based Fusion of 2D-pose and Spatio-temporal Embeddings for   Distracted Driver Action Recognition](https://arxiv.org/abs/2403.06577)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Recognizing distracted driver behaviors over time in video is challenging but important for developing advanced driver assistance systems to improve road safety. 
- Key difficulties include complexity of motion patterns, similarity of actions, and varying durations of actions.
- Using multiple in-vehicle cameras capturing different angles makes this even more challenging.

Proposed Solution:
- Propose a transformer-based fusion method to combine 2D pose features and spatio-temporal video features for improved classification and temporal localization of distracted driver actions.
- Extract 2D pose of driver's face, shoulders and hands from each video frame using a top-down pose estimator. Incorporate additional motion features like head pose and relative hand/face distances over time.  
- Extract spatio-temporal features from video clips using pre-trained SlowFast network.
- Fuse the 2D pose and spatio-temporal features using a transformer encoder architecture. Pose features are input as positional embeddings ("POSEition" embeddings) while spatio-temporal features are the main input to transformer encoder.
- Apply MLP head to get class probabilities per camera view per video frame.
- Post-process predictions from all views to get final localized classifications of driver actions over time.

Main Contributions:
- Novel transformer-based fusion method to effectively combine 2D pose and spatio-temporal video features for distracted driver action recognition
- Extraction and use of relevant 2D pose motion features like head orientation and relative hand/face distances 
- Solution is generic, working for any number of cameras, and provides temporal localization of classified actions
- Achieves strong performance on 2023 Nvidia AI City Challenge test set
