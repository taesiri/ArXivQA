# [ReCoRe: Regularized Contrastive Representation Learning of World Model](https://arxiv.org/abs/2312.09056)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a new world model approach called Regularized Contrastive Representation learning (ReCoRe) that learns invariant feature representations to improve sample efficiency and out-of-distribution generalization in reinforcement learning. ReCoRe utilizes contrastive learning on augmented observations to extract invariant features. However, naively integrating contrastive loss into world models fails due to lack of supervisory signals. To address this, ReCoRe uses an intervention-invariant regularizer in the form of an auxiliary task like depth prediction that enforces invariance to texture variations. Experiments on navigation tasks in iGibson and DMControl environments demonstrate state-of-the-art performance. ReCoRe outperforms leading model-free and model-based RL techniques like RAD, CURL, DreamerV2, and even a pretrained visual model combined with DreamerV2. Ablations validate that both the contrastive loss and invariant regularizer are crucial components. Key results show improved generalization to unseen textures and scenes, better sim-to-real transfer, and higher sample efficiency. The framework paves the way for designing interventions and corresponding invariant auxiliary losses to learn robust features.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Model-free reinforcement learning (RL) methods require large amounts of training data and struggle to generalize to out-of-distribution (OOD) scenarios. 
- Model-based RL is more sample efficient but also struggles with OOD generalization as the latent representations are not invariant to nuisance factors in the environment.

Proposed Solution:
- Present a Regularized Contrastive Representation learning (ReCoRe) approach to learn a world model with invariant feature representations.

- Uses an encoder network with contrastive loss to extract invariant features from augmented observations. Forces agreement between differently augmented views of the same observation.  

- Adds an intervention-invariant regularizer in the form of an auxiliary task like depth prediction. This prevents feature collapse during world model training and enforces learning invariant features.

- World model has recurrent neural network based latent dynamics model to imagine futures and plan actions. Controller is trained separately using imagined rollouts.

Main Contributions:

- Shows contrastive representation learning can significantly enhance OOD generalization for model-based RL.

- Proposes intervention-invariant regularization to prevent feature collapse which is crucial for training world models with contrastive learning objectives.

- Extensive experiments demonstrate state-of-the-art performance on OOD generalization, sim-to-real transfer and sample efficiency.  

- Ablation studies validate the importance of both the contrastive loss and the proposed regularization technique.

In summary, the paper presents a novel approach to inject invariant feature learning into model-based RL. This enables superior OOD generalization and sample efficiency compared to prior model-free and model-based RL techniques.
