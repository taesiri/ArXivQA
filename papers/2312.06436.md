# [Reward Certification for Policy Smoothed Reinforcement Learning](https://arxiv.org/abs/2312.06436)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality one-paragraph summary of the key points from the paper:

This paper proposes a novel black-box certification methodology capable of directly establishing lower bounds on the mean cumulative reward of reinforcement learning policies subject to adversarial perturbations. The key intuition is to leverage f-divergences to measure the distance between the original and perturbed distributions over trajectories induced by the policy. This allows transforming the certification problem into a convex optimization that lower bounds expected cumulative reward. A major advantage is the ability to handle perturbations in both state and action spaces bounded in l_0, l_1 or l_2 norms. Experiments across both control and Atari environments demonstrate the approach can provide significantly tighter certified lower bounds compared to prior art. The method is versatile and advances state-of-the-art for provable robustness guarantees for deep reinforcement learning.
