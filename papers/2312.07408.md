# [Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language   Models](https://arxiv.org/abs/2312.07408)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes Turbo, a novel plug-and-play module to accelerate vision-language models (VLMs) by reducing data redundancy. The key insight is that there is considerable mutual redundancy between tokens as well as uneven distribution of semantic values, allowing smart merging of tokens to reduce computations without compromising performance. Specifically, Turbo defines an information degree metric comprising of mutual redundancy that captures inter-token similarities and semantic value that evaluates each token's contribution to the overall semantics. Using this metric, insignificant or redundant tokens are merged progressively based on their information degree. Experiments across various understanding (classification, retrieval, captioning, VQA) and generation (text/image-to-image) tasks demonstrate that Turbo can improve throughput by up to 2x for understanding models and 1.6x for generative models, with negligible impact on accuracy or quality. As a model-agnostic module requiring no retraining, Turbo offers greater compatibility, ease-of-use and complements existing model compression techniques. The strong empirical results validate the significance of data-driven acceleration, making Turbo a promising plug-in for efficient VLMs deployment.
