# [Learning Racing From an AI Coach: Effects of Multimodal Autonomous   Driving Explanations on Driving Performance, Cognitive Load, Expertise, and   Trust](https://arxiv.org/abs/2401.04206)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Human driving errors cause 94% of vehicle crashes, resulting in injuries, deaths, and billions in damages each year. Improving human driving ability could greatly reduce this. 
- Autonomous vehicles (AVs) have potential to improve driving safety and efficiency, but face adoption barriers like lack of trust. 
- An open question is whether AVs could teach humans to become better drivers, using explanatory communications. This application of AVs for coaching is unexplored.

Proposed Solution:
- Conduct a simulated driving experiment with 41 participants to evaluate if observing an AI Driving Coach can improve human driving performance and trust. 
- Manipulate explanation type (only 'what' actions or 'what'+ 'why' reasoning) and modality (visual or auditory). 
- Test impacts on metrics like driving skill, cognitive load, trust in AVs. Also conduct interviews.

Contributions:
1. Show that an AI Coach can effectively teach novice drivers racing techniques like optimizing speed and following the ideal "racing line".
2. Determine that explanation type affects which skills improve: 'what' focuses attention on one skill, while 'what'+'why' improves broader abilities. 
3. Find that visual explanations are more effective for positioning tasks than auditory, reducing uncertainty. Auditory risks overwhelm.  
4. Highlight that trust, aligned with learning process, and avoiding overwhelm are key for AI Coach interfaces.
5. Provide 8 design guidelines for future human-centered AV interfaces optimized for coaching.

In summary, the paper demonstrates a novel coaching application of AVs to improve human driving. It tests different explanatory methods and provides insights into designing better AV interfaces for communication, trust-building, and teaching human drivers.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

In a simulated driving experiment, an AI coach providing multimodal explanations modeled after human driving instructors was shown to help novice drivers improve their performance driving skills, with the type and modality of explanations impacting outcomes through differences in how information directed attention, mitigated uncertainty, and influenced cognitive overload.


## What is the main contribution of this paper?

 Based on my review, the main contributions of this paper are:

1. A novel assessment of the impact of observing an AI coach on performance-driving ability, cognitive load, confidence, expertise, and trust. 

2. Insight into the impact of different types ('what' vs 'what + why') and modalities (visual vs auditory) of explanations on the process of learning performance driving.

3. Eight design insights to inform the creation of future human-centered HMIs for driving and AI driving coaches.

Specifically, the paper presents the results of a driving simulator experiment where participants observed an AI driving coach providing different types and modalities of explanations. The study evaluated the effects on driving performance, cognitive load, trust, expertise, etc. It also included interviews to provide qualitative insights. The key findings and contributions are around demonstrating that AI coaching can be an effective instructional method, but the type and modality of explanations have an important influence. This leads to design considerations for future HMIs to best facilitate learning and avoid cognitive overload.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and keywords associated with it are:

- Autonomous vehicles (AVs)
- Artificial intelligence (AI) 
- Driving coach
- Explainability
- Human-machine interfaces (HMIs)
- Performance driving
- Racing line
- Information type ('what' vs 'why' explanations)
- Information modality (auditory vs visual explanations)
- Trust
- Cognitive load
- Learning process

The paper explores using an AI driving coach to teach human drivers better performance driving skills. It looks at the effects of different types and modalities of explanations from the AI coach on outcomes like driving performance, cognitive load, trust, etc. Key terms like "autonomous vehicles", "AI", "driving coach", "explainability", and "human-machine interfaces" situate it in the field. Terms like "racing line", "information type", "information modality", "cognitive load", and "learning process" relate to the specific experimental manipulations and measures. And concepts like "trust" and "explainability" connect it to broader discussions around AI and AV adoption.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper mentions using a reinforcement learning (RL) agent to control the vehicle during the AI coaching sessions. How was this RL agent trained and what considerations went into the reward function to ensure it would drive in an optimal way?

2. During the expert interviews and observations, what specific types of explanations, cues, and instructions were most commonly given by the human experts? How did you choose which ones to focus on modeling in the AI coach?

3. The paper discusses differences in racing line adherence between the groups receiving different types of explanations from the AI coach. Were there any differences noticed in the line taken by the AI coach itself between these groups? If so, how might that have impacted the results?

4. Cognitive load was measured using the NASA TLX scale. Were there any physiological measurements taken as well? If not, why was the NASA TLX scale preferred over physiological measurements of cognitive load?  

5. The sample size of 41 participants enabled detecting some significant results. However, were there any planned analyses you were unable to conduct due to limited statistical power? What sample size would you recommend for future work to enable additional analyses?

6. How long was each AI coaching session? Could the brevity of the coaching explain why there were no significant differences between groups for measures like trust and confidence?

7. The paper focuses on auditory vs visual presentation of the 'what' explanations. Were any other modalities considered during study design, such as haptic or gesture-based? If not, why not?

8. Interviews suggested participants wanted more real-time feedback from the AI coach. Do you think incorporating such feedback may influence the relative effectiveness of the different explanation types and modalities tested?

9. The paper mentions individual differences in learning processes between participants. Were there any participant characteristics that appeared related to differences in study outcomes? Is personalization of the AI coach a priority for future work?  

10. How difficult was it to create believable and naturalistic AI coach explanations using Amazon Polly text-to-speech? Do you think using a more human-like or emotive voice would impact trust in and effectiveness of the AI coach?
