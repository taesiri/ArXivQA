# [Iterative Graph Neural Network Enhancement via Frequent Subgraph Mining   of Explanations](https://arxiv.org/abs/2403.07849)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Iterative Graph Neural Network Enhancement via Frequent Subgraph Mining of Explanations":

Problem:
- Graph neural networks (GNNs) have limited representation power due to the restrictions of the Weisfeiler-Leman (1-WL) algorithm. Extending their power is an important challenge.
- One approach is to add structural information as node features, e.g. by counting subgraph patterns. However, selecting useful patterns is difficult. 

Proposed Solution:
- The paper proposes the Explanation Enhanced Graph Learning (EEGL) system for iterative enhancement of GNNs using explanations. 
- EEGL has four main modules: GNN learning, node explainer, pattern extraction, and feature annotation. It works iteratively.
- In each round, it first trains a GNN model. Then it generates an explanation subgraph for each node using GNNExplainer. 
- It mines frequent subgraph patterns from the explanations for each class. The top patterns are selected and used to annotate nodes with new features.
- In the next round, the enhanced features are used to retrain the GNN. This process repeats.

Contributions:
- Provides an automated, application-dependent solution to select useful GNN subgraph patterns from explanations. This was posed as an open problem.
- Applies frequent connected subgraph mining to explanations for model improvement.
- Proposes a general framework for iterative enhancement of GNNs using explanations.
- Empirically evaluates EEGL on synthetic and real graphs. Shows it can iteratively improve itself and outperform baselines.
- Analyzes the effect of different relationships between 1-WL symmetries and label partitions.

In summary, the paper provides a novel XAI-based approach for enhancing representation power and prediction performance of graph neural networks. The explanation-driven feature enrichment allows going beyond limitations of standard GNNs.
