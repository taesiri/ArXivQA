# [Compound Text-Guided Prompt Tuning via Image-Adaptive Cues](https://arxiv.org/abs/2312.06401)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel prompt tuning framework called Compound Text-Guided Prompt Tuning (TGP-T) for adapting vision-language models (VLMs) like CLIP to downstream tasks. TGP-T introduces text supervision to guide the optimization of prompts, enabling two key benefits: 1) releasing reliance on pre-defined category names during inference, allowing more flexible prompt generation, and 2) reducing the number of textual inputs to just two instead of one per category, significantly decreasing GPU memory consumption. Specifically, compound text supervisions consisting of category-wise and content-wise descriptions are highly effective by providing inter-class separability and capturing intra-class variations, respectively. Additionally, a lightweight Bonder module aligns the generated prompts with visual features to better harness the VLM. Extensive experiments on few-shot recognition and domain generalization datasets demonstrate TGP-T's superior performance with lower training costs, reducing GPU usage by 93% and achieving a 2.5% increase in 16-shot ImageNet accuracy. The compound text supervision and efficient design of TGP-T facilitate prompt tuning for large-scale datasets across various scenarios.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing vision-language model (VLM) prompt tuning methods like CoOp suffer from high GPU memory consumption as they require parallelizable learnable text inputs for all categories. 
- They also rely on pre-defined category names in prompts, performing poorly on datasets with ambiguous names.

Proposed Solution:
- Propose Compound Text-Guided Prompt Tuning (TGP-T) which uses text supervision to guide prompt optimization, enabling two benefits:
   1) Removes reliance on category names during inference, allowing more flexible prompt generation
   2) Reduces number of text inputs to two instead of number of categories, cutting GPU memory usage by 93%
- Introduce two levels of text supervision:
   1) Category-wise - provides inter-class separability  
   2) Content-wise - captures intra-class variations
- Condition prompt generation on images via a Bonder module to align prompts and visual features

Main Contributions:
- Propose TGP-T that reduces resource demand for tuning VLMs while achieving superior performance
- Offer new perspective of using text supervision to guide prompt optimization 
- Identify compound text supervision with category-wise and content-wise signals as highly effective
- Design Bonder module to facilitate alignment of generated prompts with visual features
- Demonstrate state-of-the-art performance on 11 datasets with up to 93% less GPU memory usage and 2.5% accuracy gain on ImageNet

In summary, the key innovation is using compound text signals to supervise and guide prompt optimization in a way that significantly cuts down resource costs while improving model adaptation and generalization abilities.
