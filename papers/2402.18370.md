# [Adversarial example soups: averaging multiple adversarial examples   improves transferability without increasing additional generation time](https://arxiv.org/abs/2402.18370)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Generating adversarial examples that can fool target models is important for evaluating model robustness, but transferability (ability to fool unseen models) is challenging. 
- Existing attacks focus on modifying inputs/gradients/features during attack generation, but don't consider the adversarial examples themselves.
- Discarding suboptimal adversarial batches from hyperparameter tuning wastes resources. 

Proposed Solution:
- Propose Adversarial Example Soups (AES) which averages multiple batches of adversarial examples crafted with fine-tuned hyperparameters. 
- This enhances positive perturbations and cancels out negative ones, boosting transferability without extra generation time/cost.
- Study 3 types of soups: (1) Mixup: different hyperparameters (2) Uniform: same hyperparameters (3) Combined: different attack methods

Contributions:  
- First work to focus on improving transferability of adversarial examples themselves through image averaging.
- Orthogonal to existing attacks and can integrate with them seamlessly.  
- Achieves higher attack success rates than state-of-the-art methods against adversarially trained and advanced defense models on ImageNet.
- Detailed experiments covering gradient attacks, input transformation attacks and feature disruption attacks demonstrate efficiency and generality of the approach.

In summary, the key idea is to average multiple batches of adversarial examples crafted by fine-tuning hyperparameters to obtain "adversarial example soups", which enhances perturbations that transfer better across models. This simple but effective technique sets a new direction for further boosting transferable adversarial attacks.
