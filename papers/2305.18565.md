# [PaLI-X: On Scaling up a Multilingual Vision and Language Model](https://arxiv.org/abs/2305.18565)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How does scaling up both the vision and language components of a multimodal vision-language model impact performance across a diverse set of vision-language tasks?More specifically, the key hypotheses tested in this work are:1) Increasing the capacity of both the visual and textual encoders in a multimodal vision-language model leads to better performance compared to just scaling up one modality.2) Training such a scaled up model with a mixture of objectives that combines masked token prediction and prefix language modeling improves the Pareto frontier between few-shot and fine-tuned performance. 3) Scaling allows the emergence of new capabilities not directly optimized for during training, such as complex counting or multilingual object detection.The authors scale up both the visual encoder (based on ViT) and text encoder/decoder (based on T5) of their PaLI model to create PaLI-X, and evaluate it on a wide range of vision-language benchmarks to test these hypotheses.
