# [BiFF: Bi-level Future Fusion with Polyline-based Coordinate for   Interactive Trajectory Prediction](https://arxiv.org/abs/2306.14161)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the key research focus of this paper is on developing a model for interactive trajectory prediction that can explicitly capture future interactions between agents. 

Specifically, the paper proposes a Bi-level Future Fusion (BiFF) approach to model interactions at both high-level future intentions and low-level future behaviors. 

The central hypothesis is that by fusing information about future interactions at two levels - intentions and behaviors - the model can generate more accurate and scene-consistent trajectory predictions for multiple interactive agents.

The key research questions addressed are:

- How to effectively fuse high-level future intentions between agents to produce scene-consistent goals? This is handled by the proposed High-level Future Intentions Fusion (HFIF) module.

- How to fuse low-level future trajectory behaviors across agents to ensure collision avoidance and scene compliance? This is addressed through the Low-level Future Behaviors Fusion (LFBF) module.

- How to design an efficient coordinate representation that provides agent-centric features without redundant context encoding? The polyline-based coordinate is proposed for this purpose.

In summary, the core research focus is on modeling interactive trajectory prediction by fusing future interactions at both high-level intentions and low-level behaviors using the proposed BiFF approach. The key hypothesis is that explicitly modeling these future interactions will lead to more accurate and human-like predictions.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. It proposes a novel model called BiFF (Bi-level Future Fusion) for interactive trajectory prediction. BiFF incorporates two components: 

- High-level Future Intentions Fusion (HFIF): Captures future intentions across agents to generate scene-consistent goals.

- Low-level Future Behaviors Fusion (LFBF): Fuses future behaviors across agents in each scene modality to predict scene-compliant trajectories.

2. It designs a polyline-based coordinate system specifically for multi-agent prediction. This representation provides agent-centric features without redundant context encoding between agents, making the model more memory-efficient, data-efficient and robust to variance in global reference frame.

3. It achieves state-of-the-art performance on the interactive prediction benchmark of the Waymo Open Motion Dataset, demonstrating the effectiveness of modeling future interactions with the proposed BiFF framework and polyline-based coordinates.

In summary, the key contribution is a new model BiFF that explicitly captures bi-level future interactions (intentions and behaviors) between agents using novel components like HFIF and LFBF. The polyline-based coordinates also enhance the multi-agent prediction. Experiments verify the state-of-the-art performance of BiFF for interactive trajectory forecasting.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a novel method called Bi-level Future Fusion (BiFF) that captures future interactions between agents by fusing high-level future intentions and low-level future behaviors using polyline-based coordinates for efficient and accurate multi-agent trajectory prediction.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper on Bi-level Future Fusion (BiFF) compares to other recent research on interactive trajectory prediction:

- BiFF explicitly models future interactions between agents through both high-level intention fusion (HFIF) and low-level behavior fusion (LFBF). Most prior work focuses on modeling past interactions and does not directly capture future interactivity. 

- The polyline-based coordinate representation used in BiFF provides agent-centric predictions without redundant context encoding between targets. Other methods tend to use scene-centric representations which require re-normalization for each agent.

- Experiments on the Waymo Open Motion Dataset demonstrate BiFF achieves state-of-the-art performance on interactive prediction benchmarks, outperforming recent methods like M2I, DenseTNT, and SceneTransformer.

- BiFF incorporates iterative trajectory refinement during prediction through its LFBF decoder. Some other approaches like M2I and MTR have explored future prediction for refinement, but do not refine trajectories over multiple iterations.

- The HFIF module in BiFF uses a novel multi-modal decoder to decompose the multi-modal marginal intentions into uni-modal goals for each agent in each scene modality. This helps resolve conflicts in the marginal predictions.

- BiFF is designed specifically for joint prediction of two interactive agents. Some recent work like SceneTransformer and AutoBots focus on flexible modeling of diverse multi-agent scenarios.

In summary, BiFF advances the state-of-the-art in interactive trajectory prediction through its novel future fusion mechanisms, efficient coordinate representation, strong experimental results, and techniques like iterative refinement and multi-modal conflict resolution. It provides a new approach to tackling the key challenges in modeling interactivity for autonomous navigation.
