# [Don't Label Twice: Quantity Beats Quality when Comparing Binary   Classifiers on a Budget](https://arxiv.org/abs/2402.02249)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- The paper considers the problem of how to best allocate a fixed budget for noisy labels when comparing the accuracy of two binary classifiers. The common practice is to collect multiple noisy labels per data point and aggregate them (e.g. by majority vote) to produce higher quality labels. However, this reduces the number of unique data points that can be labeled under a fixed budget.

- The paper formally models this tradeoff between label quality and quantity and asks: when the goal is to determine which of two classifiers has higher accuracy, is it better to allocate the labeling budget towards more data points with single noisy labels, or fewer data points with multiple aggregated labels?

Proposed Solution
- The main result is a theorem showing that for large enough sample sizes, allocating the full budget towards single noisy labels for more data points maximizes the probability of correctly determining the more accurate classifier. This holds under reasonable assumptions even allowing for correlation between classifiers and labels.

- The theorem is proven by an application of Cram√©r's large deviation theorem to precisely characterize the asymptotic behavior of the tails of the distributions of interest. This analysis shows the gains from aggregation are outweighed by the greater statistical power obtained from more data points.

Contributions
- The paper overturns the conventional wisdom that label aggregation should be prioritized when comparing classifiers. For identifying the most accurate model, the results suggest quantity of data beats quality of labels.

- From a theory perspective, the analysis demonstrates how tools from large deviations can be fruitfully applied in machine learning. The provided sample size bounds improve substantially over basic concentration inequalities.

- The findings have significant implications for the design of machine learning benchmarks and metrics. Many existing procedures expend effort on aggregation that may be better allocated towards gathering more single labels.

In summary, the paper formally tackles an important open problem regarding the tradeoffs in data collection for model evaluation, providing surprising theoretical and practical guidance of wider relevance.
