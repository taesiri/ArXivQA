# [Mitigating Label Flipping Attacks in Malicious URL Detectors Using   Ensemble Trees](https://arxiv.org/abs/2403.02995)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper investigates vulnerabilities of Random Forest (RF) classifiers to Label Flipping (LF) attacks in the context of malicious URL detection. LF attacks manipulate training data by changing some labels from benign to malicious or vice versa, which fools the model and leads to incorrect classifications. 

The paper first trains RF models on clean URL datasets to establish baseline performance. It then applies random LF attacks by flipping 2-5% of labels and evaluates attack success through reduced model accuracy and high Attack Success Rates (ASR), indicating URLs are misclassified. For example, with 5% label flipping, accuracy drops to 95-97% on some datasets and ASR reaches 61%, showing the attack succeeds in fooling the model.

To defend against such attacks, the paper proposes a novel alarm-based system using a k-Nearest Neighbors (k-NN) method to detect poisoned labels and recover their true labels. For each sample, it checks if the predicted label from k-NN on clean data matches the label in the poisoned dataset - a mismatch indicates poisoning. If found, an alarm is raised and the label is corrected. 

Experiments show the defense mechanism accurately detects up to 100% of poisoned labels across datasets and attack scenarios, successfully recovering the true labels. Model accuracy after label correction also improves significantly, reaching 99.87-100% in most cases.

The key contributions are:
1) Analysis of LF attack impact in malicious URL classifiers - up to 5% label flipping causes accuracy drop and high attack success.
2) A new alarm-based defense to accurately detect poisoned labels using k-NN.
3) Experiments proving the system can fully recover manipulated labels and model accuracy.

Overall, the paper highlights vulnerabilities of RF models to data poisoning attacks and provides an effective system to detect and mitigate such threats for malicious URL classification tasks. The ideas can generalize to other security domains as well.
