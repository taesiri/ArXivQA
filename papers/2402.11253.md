# [Aligning Large Language Models by On-Policy Self-Judgment](https://arxiv.org/abs/2402.11253)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing methods for aligning large language models (LLMs) with human preferences either require a separate reward model (RM) for on-policy learning, adding complexity, or use offline/off-policy learning, which is suboptimal. 

Proposed Solution - Self-Judge:
- Introduces a Judge-augmented Supervised Fine-tuning (JSFT) method to train a single LLM that can act as both a policy (to generate responses) and a judge (to evaluate response pairs). 
- Views the pairwise judgment task as an instruction-following task that can be solved by predicting a single token.
- The resulting judge model (JM) is used to initialize a policy and reference policy. The reference JM acts as a fixed judge to provide on-policy feedback on samples from the policy JM.  
- Can also perform self-rejection at inference time by using the JM's judging capability to select the best response.

Main Contributions:
- Proposes a parameter-efficient on-policy alignment framework that does not require a separate RM.
- Introduces JSFT to obtain a single model that can generate responses and judge preferences.
- Shows JSFT boosts judging performance, especially when trained on comparisons based on principles and rationales.
- Demonstrates resulting JM can enable on-policy self-training and self-rejection for further improvements.
- Outperforms RLHF and offline/off-policy methods on preference benchmarks.

In summary, Self-Judge provides an effective on-policy LLM alignment approach using a single judge-augmented model for both policy and evaluation. JSFT is key to improving judgment quality for enabling self-training and inference-time self-rejection.
