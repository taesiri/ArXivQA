# [RL Dreams: Policy Gradient Optimization for Score Distillation based 3D   Generation](https://arxiv.org/abs/2312.04806)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the paper:

This paper proposes DDPO3D, a novel framework that enhances the quality of 3D models generated using score distillation sampling (SDS) techniques. The key idea is to treat the diffusion sampling process as a Markov decision process (MDP) and apply policy gradient methods to optimize for aesthetic rewards, building on top of the recently proposed Denoising Diffusion Policy Optimization (DDPO). Experiments demonstrate that incorporating an aesthetic scoring function consistently improves rendering quality across multiple SDS methods like DreamGaussian and GSGen for text-to-3D generation. The proposed approach, DDPO3D, allows easy integration of non-differentiable rewards to guide the 3D asset generation process. Both qualitative assessments and CLIP score metrics showcase noticeable improvements in visual quality and semantic coherence of generated 3D models. A study of reward scheduling provides insights into balancing SDS terms and policy updates. By adapting policy optimization strategies to the realm of 3D generative modeling, this work opens up new possibilities for steering SDS techniques using flexible reward formulations.
