# [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram   Predictions](https://arxiv.org/abs/1712.05884)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to create a text-to-speech system that can synthesize natural sounding speech directly from text, without relying on complex feature engineering or traditional speech synthesis pipelines. 

Specifically, the paper proposes an end-to-end neural network model called Tacotron 2 that combines a sequence-to-sequence model to generate mel spectrograms from text, and a modified WaveNet model to synthesize time-domain waveforms from the mel spectrograms.

The key hypothesis is that using mel spectrograms as an intermediate acoustic representation between the text and waveform can bridge these two components in a single neural network model to produce speech that approaches human quality. The experiments aim to validate whether this approach can actually synthesize natural sounding speech comparable to real human recordings.

So in summary, the main research question is whether an end-to-end neural model conditioned on mel spectrograms can achieve state-of-the-art text-to-speech synthesis, removing the need for hand-engineered linguistic and acoustic features of traditional TTS systems. The paper aims to demonstrate the effectiveness of this mel spectrogram-based approach through systematic experiments and evaluations.


## What is the main contribution of this paper?

 The main contribution of this paper is the proposal of Tacotron 2, an end-to-end text-to-speech synthesis system that achieves human-level speech quality. The key ideas are:

- Using a sequence-to-sequence model with attention to generate mel spectrograms from text. This replaces the traditional linguistic feature extraction pipeline.

- Using a modified WaveNet model as a neural vocoder to generate time-domain waveforms from the mel spectrograms. This replaces the traditional vocoder and waveform generation components. 

- Showing that using mel spectrograms as the intermediate acoustic representation between text and audio allows for a simplified and high-quality end-to-end model.

- Achieving a mean opinion score (MOS) of 4.53 for Tacotron 2, which is close to a MOS of 4.58 for real human speech. This demonstrates the system's ability to synthesize natural sounding speech.

- Conducting ablation studies to validate the design choices such as using mel spectrograms, the post-processing network, and simplifying WaveNet.

In summary, the key contribution is presenting Tacotron 2 as a unified neural model that achieves human-level speech synthesis directly from text, while previous approaches relied on complex linguistic feature engineering or separate components.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper describes Tacotron 2, a neural text-to-speech system that combines a sequence-to-sequence model to generate mel spectrograms from text and a modified WaveNet vocoder to synthesize time-domain waveforms from those spectrograms, achieving state-of-the-art speech quality.
