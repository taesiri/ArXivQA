# [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram   Predictions](https://arxiv.org/abs/1712.05884)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to create a text-to-speech system that can synthesize natural sounding speech directly from text, without relying on complex feature engineering or traditional speech synthesis pipelines. 

Specifically, the paper proposes an end-to-end neural network model called Tacotron 2 that combines a sequence-to-sequence model to generate mel spectrograms from text, and a modified WaveNet model to synthesize time-domain waveforms from the mel spectrograms.

The key hypothesis is that using mel spectrograms as an intermediate acoustic representation between the text and waveform can bridge these two components in a single neural network model to produce speech that approaches human quality. The experiments aim to validate whether this approach can actually synthesize natural sounding speech comparable to real human recordings.

So in summary, the main research question is whether an end-to-end neural model conditioned on mel spectrograms can achieve state-of-the-art text-to-speech synthesis, removing the need for hand-engineered linguistic and acoustic features of traditional TTS systems. The paper aims to demonstrate the effectiveness of this mel spectrogram-based approach through systematic experiments and evaluations.
