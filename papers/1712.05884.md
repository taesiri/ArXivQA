# [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram   Predictions](https://arxiv.org/abs/1712.05884)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to create a text-to-speech system that can synthesize natural sounding speech directly from text, without relying on complex feature engineering or traditional speech synthesis pipelines. 

Specifically, the paper proposes an end-to-end neural network model called Tacotron 2 that combines a sequence-to-sequence model to generate mel spectrograms from text, and a modified WaveNet model to synthesize time-domain waveforms from the mel spectrograms.

The key hypothesis is that using mel spectrograms as an intermediate acoustic representation between the text and waveform can bridge these two components in a single neural network model to produce speech that approaches human quality. The experiments aim to validate whether this approach can actually synthesize natural sounding speech comparable to real human recordings.

So in summary, the main research question is whether an end-to-end neural model conditioned on mel spectrograms can achieve state-of-the-art text-to-speech synthesis, removing the need for hand-engineered linguistic and acoustic features of traditional TTS systems. The paper aims to demonstrate the effectiveness of this mel spectrogram-based approach through systematic experiments and evaluations.


## What is the main contribution of this paper?

 The main contribution of this paper is the proposal of Tacotron 2, an end-to-end text-to-speech synthesis system that achieves human-level speech quality. The key ideas are:

- Using a sequence-to-sequence model with attention to generate mel spectrograms from text. This replaces the traditional linguistic feature extraction pipeline.

- Using a modified WaveNet model as a neural vocoder to generate time-domain waveforms from the mel spectrograms. This replaces the traditional vocoder and waveform generation components. 

- Showing that using mel spectrograms as the intermediate acoustic representation between text and audio allows for a simplified and high-quality end-to-end model.

- Achieving a mean opinion score (MOS) of 4.53 for Tacotron 2, which is close to a MOS of 4.58 for real human speech. This demonstrates the system's ability to synthesize natural sounding speech.

- Conducting ablation studies to validate the design choices such as using mel spectrograms, the post-processing network, and simplifying WaveNet.

In summary, the key contribution is presenting Tacotron 2 as a unified neural model that achieves human-level speech synthesis directly from text, while previous approaches relied on complex linguistic feature engineering or separate components.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper describes Tacotron 2, a neural text-to-speech system that combines a sequence-to-sequence model to generate mel spectrograms from text and a modified WaveNet vocoder to synthesize time-domain waveforms from those spectrograms, achieving state-of-the-art speech quality.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other research in text-to-speech synthesis:

- It proposes Tacotron 2, an end-to-end neural network architecture for speech synthesis directly from text. This eliminates the need for complex linguistic and acoustic feature engineering required by many other TTS systems.

- It combines a sequence-to-sequence model for mel spectrogram prediction with a modified WaveNet vocoder for waveform generation. Using mel spectrograms as the intermediate representation allows for a simplified WaveNet architecture compared to conditioning directly on linguistic features.

- It achieves state-of-the-art sound quality, with a mean opinion score of 4.53 comparable to professionally recorded speech. This significantly outperforms previous neural and concatenative TTS systems.

- Compared to Deep Voice 3 and Char2Wav, other end-to-end neural TTS systems published around the same time, Tacotron 2 achieves higher speech naturalness while using a different model architecture and intermediate representations.

- Ablation studies validate key model design choices such as the mel spectrogram prediction, post-processing network, and impact of simplifying the WaveNet architecture. This provides useful analysis and comparisons.

Overall, Tacotron 2 moves closer to a production-ready end-to-end neural text-to-speech system with naturalness rivaling human speech. The comparisons help position it as a state-of-the-art model in this field at the time.
