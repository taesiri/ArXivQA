# [Gaussian Process Neural Additive Models](https://arxiv.org/abs/2402.12518)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Deep neural networks, while powerful, are black-box models that lack interpretability. This hinders their use in areas like healthcare where explainability is important. 
- Recently, Neural Additive Models (NAMs) were proposed to add interpretability to deep learning on tabular data. NAMs learn a neural network shape function for each feature. But NAMs can have scalability issues and non-convex objectives.

Proposed Solution:
- The paper proposes Gaussian Process NAMs (GP-NAMs) where the shape function is a GP approximation using random Fourier features. 
- This results in a convex learning objective with only linear weights to optimize. The number of parameters grows linearly in the number of features rather than exponentially.
- GP-NAMs retain the interpretability of NAMs through visualizing univariate GP shape functions, while being scalable and avoiding optimization issues.

Main Contributions:
- Introduction of GP-NAMs using GPs with RBF kernels approximated by random Fourier features as NAM shape functions
- Convex learning objective with linear scaling in parameters as a function of dimensionality
- Empirical evaluation showing GP-NAMs achieve similar accuracy to NAMs and NODE-GAMs on tabular data, while requiring significantly fewer parameters
- Qualitative analysis of interpretability through inspection of smooth, univariate GP shape functions

In summary, the paper proposes a subclass of neural additive models based on Gaussian process approximations that retains interpretability while being scalable and easier to optimize. Experiments validate that accuracy is on par with other additive models on tabular data.
