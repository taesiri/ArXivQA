# OpenAGI: When LLM Meets Domain Experts

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can large language models (LLMs) be enhanced to harness various domain expert models for complex task-solving, as a promising approach towards artificial general intelligence (AGI)?The key hypothesis appears to be:By integrating large language models with domain-specific expert models, inspired by the blend of general and specialized intelligence in humans, it may be possible to develop systems with improved capabilities for complex task-solving across different domains, advancing progress towards AGI.Specifically, the paper proposes an open-source AGI research platform called OpenAGI that allows LLMs to select, synthesize and execute various external expert models (tools, APIs, modules etc.) in order to solve intricate, multi-step real-world tasks presented in natural language. The main innovations include:- A dual strategy with benchmark tasks for standardized evaluation and open-ended tasks for expandability.- A Reinforcement Learning from Task Feedback (RLTF) mechanism that uses task results to improve the LLM's planning and task-solving abilities over time.- Integrating models from repositories like HuggingFace and GitHub for extensibility.The central hypothesis seems to be that by equipping LLMs with the ability to harness specialized external models through this system, their capacity for complex task-solving can be enhanced, representing progress towards more general intelligence. The proposed OpenAGI platform aims to facilitate researching this hypothesis.


## What is the main contribution of this paper?

The main contribution of this paper seems to be the introduction of OpenAGI, an open-source AGI research platform for developing and evaluating large language models (LLMs) on complex, multi-step tasks. Some key points:- OpenAGI utilizes a dual strategy with benchmark tasks for standardized evaluation, and open-ended tasks for more creative problem solving. - Tasks are formulated as natural language queries to the LLM, which then selects and executes appropriate models to solve the task.- They propose a Reinforcement Learning from Task Feedback (RLTF) mechanism to improve the LLM's planning abilities using the feedback/results from the task execution.- They evaluate various LLMs like GPT-3.5, Vicuna, and Flan-T5 using OpenAGI, analyzing their capabilities on multi-step tasks under different learning schemas. - The results suggest that smaller LLMs paired with suitable learning like RLTF can outperform much larger models, highlighting the importance of learning approach.- They open source the code, datasets, benchmarks etc. to promote further research and development of LLMs for AGI abilities using their proposed OpenAGI platform.In summary, the key contribution is the introduction and open sourcing of the OpenAGI platform to facilitate LLM-based research towards AGI by formulating tasks as natural language queries and using RLTF to improve planning.
