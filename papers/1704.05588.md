# [Learning to Fly by Crashing](https://arxiv.org/abs/1704.05588)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is how to learn to navigate an unmanned aerial vehicle (UAV) and avoid obstacles indoors using only monocular images, without relying on explicit 3D representations or depth estimation. The key hypothesis is that a large-scale dataset of drone crashes can be used in a self-supervised manner to teach a model how NOT to crash, and this can lead to effective policies for indoor UAV navigation.Specifically, the paper proposes an approach to autonomously collect a dataset of over 11,500 drone crashes by having the drone sample naive trajectories and crash into random objects. This crash dataset, along with positive examples from the same trajectories, is then used to train a deep network to predict if the drone should move forward or not based on image crops. At test time, this model allows the drone to navigate complex indoor environments by choosing directional movements based on the network's predictions.The central hypothesis is that, compared to small expert datasets or simulated data, this self-supervised approach of collecting real-world crash data and learning from it can enable more effective policies for UAV navigation in cluttered indoor environments, despite using only a monocular camera. The experiments aim to demonstrate the advantages of this large-scale crash data collection paradigm.


## What is the main contribution of this paper?

The main contribution of this paper is developing a self-supervised learning approach for navigating drones in indoor environments. The key ideas are:- Collecting a large-scale dataset of drone crashes - the authors crash their drone 11,500 times to create a dataset of negative examples showing how not to fly. This is one of the largest UAV crash datasets. - Using the negative crash data along with positive non-crash data from the same trajectories to train a deep neural network to predict good vs bad trajectories.- Developing a simple but effective policy to use the binary classification network to fly long distances while avoiding obstacles. The policy essentially crops the image and uses the network predictions on the crops to decide which way to turn.- Showing that their self-supervised approach outperforms methods using depth prediction and is comparable to human pilots in navigating cluttered indoor environments.So in summary, the main contribution is demonstrating the power of large-scale self-supervised data along with simple learning strategies for enabling drones to fly autonomously while avoiding obstacles in complex environments. The key idea is to embrace drone crashes during data collection rather than avoiding them.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a self-supervised approach to train a drone to navigate indoors by deliberately crashing it over 11,500 times to create a large dataset of failures, and uses this negative data along with positive data from the same trajectories to learn a surprisingly effective policy for collision avoidance.


## How does this paper compare to other research in the same field?

This paper presents a novel approach to learning control policies for drone navigation using large-scale crash data collected in a self-supervised manner. Here are some key aspects in how it relates to other work in this field:- Most prior work in drone navigation relies on SLAM, depth prediction, or human demonstrations. This paper argues that those have limitations such as cost, data bias, or lack of scale.- Instead, the authors take a self-supervised learning approach where they actively crash the drone over 11,500 times to collect negative examples. This is a unique and large-scale real-world drone dataset.- They use this crash data along with positive examples from the same trajectories to train a deep network to predict safe actions from images. At test time, cropping strategies allow a binary classifier to choose complex navigation actions.- Results show their approach outperforms depth prediction methods and is comparable to human pilots, despite using only a monocular camera on a low-cost drone platform during training.- The idea of self-supervised crashing to learn not to crash is novel in this domain. The scale of the crash dataset enables training high-capacity deep models.- This demonstrates the possibilities of self-supervised robot learning without need for expert demonstrations or simulation. The simple learned model rivals more complex perception pipelines.In summary, this paper makes both conceptual and practical contributions in self-supervised drone flying with a data-driven approach. The key novelty is actively collecting a large number of real-world crashes and using that to train a policy network. This sets it apart from prior work and shows promising results on real indoor navigation.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors are:- Testing the approach on more complex and dynamic environments, including outdoors. The experiments in the paper were mostly conducted in static indoor environments. Extending to more complex settings with outdoor factors like wind would be an interesting next step.- Incorporating non-visual sensors like depth sensors or IMUs to further improve performance and robustness. The current approach relies purely on monocular images. Combining visual data with other modalities could help.- Exploring different network architectures and learning strategies beyond the binary classification approach used. They mention that extending to directly predict control commands instead of crops could be beneficial. - Implementing their method on different drone platforms beyond the Parrot AR to show generalization across different dynamics and visual inputs.- Collecting an even larger and more diverse dataset of crashes and trajectories. They argue more data will continue to improve the learned policy so expanding the dataset scale and diversity could help.- Combining the self-supervised crashing approach with a small amount of expert trajectories to incorporate some human knowledge and preferences.- Testing the ability to transfer policies across environments, reducing the data requirements.So in summary, the main directions are around scaling up the approach to more complex scenes, incorporating additional modalities and learning algorithms, testing on more platforms, collecting more diverse data, and exploring ways to transfer or incorporate human knowledge.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper proposes a self-supervised learning approach to train an unmanned aerial vehicle (UAV) to navigate indoor environments and avoid obstacles. The key idea is to collect a large dataset of drone crashes by having the drone fly straight line paths and collide with objects. In this way, they are able to collect 11,500 crashing trajectories across 20 diverse environments, creating one of the largest UAV crash datasets. This dataset captures the different ways a UAV can crash and represents how the UAV should NOT fly. They use this negative data along with positive data from the same trajectories to train a deep neural network to do binary classification on whether the drone should move forward or not. At test time, they use cropped patches of the image to decide whether to move left, right, or straight ahead. They show their approach outperforms methods based on depth prediction and is comparable to human pilots in several complex indoor environments with narrow spaces and transparent objects like glass doors. The main conclusions are that it is feasible to collect large-scale self-supervised data for navigation, and this data is crucial for learning how to fly and avoid obstacles.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:The paper proposes a self-supervised approach to train an unmanned aerial vehicle (UAV) to navigate indoor environments and avoid collisions. Instead of using small expert datasets or training in simulation, the authors collect a large dataset by intentionally crashing a drone over 11,500 times into objects in 20 diverse environments. This crashing dataset captures different ways the drone can collide and represents how the drone should NOT fly. The data is split into positive segments far from collisions and negative segments near collisions. A deep neural network is trained to predict if the drone should move forward from the input image. At test time, cropped segments of the image are fed to the network to decide direction of movement. Despite the simple approach, results show this method outperforms depth prediction baselines and reaches comparable performance to human controllers on several complex indoor environments. The large dataset enables learning a generalizable policy directly in the real world. Overall, this demonstrates the feasibility of large-scale self-supervised data collection and its importance for learning to navigate autonomously.
