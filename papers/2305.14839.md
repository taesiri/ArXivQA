# PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and   Compositional Experts

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to develop an effective pre-trained model for multi-modal dialogue that can handle diverse tasks and modalities in a unified framework. The key hypotheses are:1) Decomposing multi-modal dialogue into fundamental sub-capabilities and designing specific experts for each capability can enable effective divide-and-conquer pre-training.2) A progressive pre-training strategy that controls the combination of experts in different phases can help learn the experts and their combinations more efficiently. 3) The pre-trained model can flexibly select and combine different experts to adapt to various downstream multi-modal dialogue tasks.4) The pre-trained model can make effective use of both multi-modal dialogue data and more abundant non-dialogue multi-modal data to learn strong universal representations.In summary, the central research question is how to design a pre-trained model with flexible model architecture and adaptable training methodologies for multi-modal dialogue. The key hypotheses focus on decomposing the problem, progressive training of experts, flexible expert combinations, and utilizing both dialogue and non-dialogue data.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes PaCE, a novel pre-training framework for multi-modal dialogue that adopts a divide-and-conquer strategy. Specifically, it decomposes the complex multi-modal dialogue task into several more manageable sub-capabilities, including caption modeling, context modeling, image modeling, grounding, and generation. 2. It develops a progressive cascade pre-training strategy to evolve the model by controlling the combination of experts in different pre-training stages. In stage 1, it trains on non-dialogue data. In stage 2, it trains the context expert guided by the caption expert on dialogue data. In stage 3, it adds a generation expert. 3. It collects and utilizes two large-scale corpora for pre-training: a multi-modal non-dialog corpus with 4M samples and a multi-modal dialog corpus with 1.4M dialogs.4. Extensive experiments show PaCE achieves new state-of-the-art results on 8 multi-modal dialog tasks, including intent prediction, retrieval, state tracking and response generation. This demonstrates its effectiveness and flexibility.In summary, the main contribution is the proposal of a novel structured and progressive pre-training framework PaCE that can effectively leverage both dialog and non-dialog multi-modal data to learn strong unified representations for diverse multi-modal dialogue tasks. The divide-and-conquer strategy and progressive training enable PaCE to achieve superior flexibility and expandability.
