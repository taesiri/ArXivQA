# [Localization Is All You Evaluate: Data Leakage in Online Mapping   Datasets and How to Fix It](https://arxiv.org/abs/2312.06420)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper highlights a critical issue with the nuScenes and Argoverse 2 datasets commonly used to train and evaluate online mapping models - there is significant geographical overlap between the training, validation, and test sets. Over 80\% of nuScenes and 40\% of Argoverse 2 validation and test samples are located within 5 meters of a training sample, allowing models to implicitly localize and "memorize" parts of the environment. To address this, the authors introduce new geographically separated splits of the datasets and show state-of-the-art online mapping methods exhibit much lower performance, with some dropping over 45 mAP, when evaluated on the proposed splits. This reveals these methods have poorer generalization ability than initially thought and that inflated performance numbers are being reported in the field. Additionally, re-validation of prior algorithmic choices shows diverging conclusions from those based on the original splits regarding the impact of different lifting techniques and auxiliary supervision. The splits introduced in this work, by removing geographical data leakage and enabling more reliable evaluation, will support improved generalization of online mapping models to new environments.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper proposes balanced geographical splits for the nuScenes and Argoverse 2 datasets to address significant overlaps between training and test sets, reveals substantially lower performance of current state-of-the-art online mapping methods when evaluated on these proposed splits, and re-evaluates key algorithmic choices under this more rigorous evaluation setting.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing and employing geographically non-overlapping splits of the nuScenes and Argoverse 2 datasets for online mapping. The authors show that the performance of state-of-the-art online mapping methods drops significantly when evaluated on these new splits compared to the original temporally split datasets that had considerable geographic overlap between train, validation and test sets. This reveals that prior performance numbers were inflated due to this overlap and provides a more realistic measure of generalization ability. Additionally, the authors re-validate some studies on important algorithmic choices and show that conclusions change based on the new splits, for example regarding the impact of different lifting methods or auxiliary supervision with depth estimation. Overall, this work highlights the critical problem of data leakage due to geographic overlap in popular autonomous driving datasets and facilitates more robust evaluations for future online mapping research.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper summary, here are some of the key terms and concepts associated with this paper:

- Online mapping - The task of estimating a map of the local surroundings in real-time using onboard sensors like cameras and lidar. Does not rely on a pre-built map.

- Data leakage - When there is significant overlap between the training and test sets, allowing models to score well by memorizing the test samples instead of generalizing. 

- Geographical splits - Dividing the dataset based on location to minimize geographic overlap between training, validation and test sets.

- nuScenes dataset - One of the main datasets used for evaluating online mapping methods. Suffers from geographical data leakage in its original split.

- Argoverse dataset - Another major dataset used for online mapping that has geographical overlap issues in the data split.

- Lifting - The process of transforming image features from perspective view to bird's eye view to create the map prediction. Important component of many online mapping methods.

- Segmentation-based maps - Online maps represented as a rasterized bird's eye view segmentation.

- Vector-based maps - Online maps represented as vector objects (points, lines) denoting map elements like lane dividers.

- Inter-set overlap - Geographical overlap between the training, validation and test sets.

- Intra-set overlap - Geographic correlation and overlap between samples within a dataset split (training, validation or test).


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper argues that the original nuScenes and Argoverse 2 datasets have significant geographical overlap between the training, validation, and test sets. What implications does this have when training and evaluating online mapping methods? How exactly does it lead to inflated performance?

2. The paper proposes new geographically separated splits for nuScenes and Argoverse 2. Can you walk through the methodology used to create these splits? What were the key considerations and trade-offs? How is diversity maintained?

3. When re-evaluating methods on the proposed geographical splits, performance drops significantly compared to the original splits. Analyze the possible reasons for this substantial performance degradation. Does it indicate overfitting or some form of "data leakage" when using the original splits?

4. The paper finds that the performance drop is more pronounced on nuScenes compared to Argoverse 2 when using the geographical splits. What differences between these datasets could explain this discrepancy? Does the denser sampling and larger coverage of Argoverse 2 play a role?

5. The impact of auxiliary tasks like depth supervision appears less significant on the geographical splits compared to conclusions drawn using the original splits. Why could this be the case? Does the original geographical overlap influence how informative these auxiliary tasks are? 

6. When analyzing the results, the paper states "the ranking among the evaluated methods remains largely the same" between original and geographical splits. Discuss whether you expect relative performance between methods to change or remain similar when evaluating on geographically separated data.

7. The lift in performance is smaller when utilizing the full dense nuScenes training set compared to the sparsely annotated set. Analyze potential reasons why increased data does not lead to more substantial improvements on the geographical test set.

8. How valid are conclusions from prior ablation studies related to architecture choices like lifting methods and decoder types given the issues with the original data splits? Should these design decisions be revisited?

9. The paper analyzes both segmentation-based and vector-based approaches for online mapping. Compare and contrast these two families of methods regarding how they are affected by geographical overfitting issues.

10. Beyond dataset splits, discuss other potential remedies to address geographical overfitting and ensure online mapping methods generalize well to new environments. Are there architectural modifications or training procedures that could help?
