# [Towards Compositional Adversarial Robustness: Generalizing Adversarial   Training to Composite Semantic Perturbations](https://arxiv.org/abs/2202.04235)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research questions/hypotheses appear to be:

1) How to generalize adversarial training from a single threat model (e.g. $\ell_p$ norm bounded perturbations) to defend against multiple/composite semantic perturbations? 

2) How to optimize the perturbation order when combining multiple semantic and $\ell_p$ norm perturbations into a composite adversarial attack?

3) Can the proposed generalized adversarial training (GAT) approach outperform other adversarial training baselines in defending against composite perturbations?

In particular, the authors propose a novel composite adversarial attack method that can find optimal attack compositions by attack order scheduling and component-wise projected gradient descent. They then propose GAT to train models robust to not only single threats like $\ell_\infty$ perturbations, but also combinations of multiple semantic perturbations like changes in hue, saturation, brightness, etc. 

The central hypothesis seems to be that their proposed GAT approach can achieve state-of-the-art robustness against a wide range of single and composite adversarial threats, compared to prior adversarial training methods. The results on ImageNet and CIFAR-10 appear to support this hypothesis.

In summary, the key research questions addressed are: 1) how to achieve compositional robustness via adversarial training, 2) how to optimize composite attacks, and 3) evaluating if the proposed GAT outperforms other adversarial training baselines. The central hypothesis is that GAT can provide robustness against diverse composite adversarial examples.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a novel composite adversarial attack (CAA) method that can generate adversarial examples across multiple perturbation types, including semantic perturbations (e.g. hue, saturation, rotation, etc.) and l_p norm attacks. A key part of CAA is an attack order scheduling algorithm that can find the optimal attack order to maximize the adversarial effect.

2. It proposes a generalized adversarial training (GAT) framework to train models that are robust to composite adversarial attacks. GAT incorporates the proposed CAA method to generate composite adversarial examples during training. 

3. Extensive experiments on CIFAR-10 and ImageNet show that models trained with GAT achieve much higher robust accuracy against composite attacks compared to prior adversarial training methods focused on single perturbation types. For example, GAT improves robust accuracy by 30-60% on semantic attacks and 15-22% on full attacks combining semantic and l_inf attacks.

4. Analysis shows the proposed CAA achieves higher attack success rates compared to random attack ordering, demonstrating the effectiveness of the attack order scheduling algorithm. 

In summary, the main contribution is developing novel attacks and defenses to improve robustness against composite/semantic adversarial perturbations, going beyond the typical single perturbation adversarial training. The proposed GAT framework significantly outperforms prior art in defending against a combinational of multiple perturbation types.
