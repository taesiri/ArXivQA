# [Improving Scene Graph Generation with Relation Words' Debiasing in   Vision-Language Models](https://arxiv.org/abs/2403.16184)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Scene graph generation (SGG) aims to understand relationships between objects in images, but faces challenges due to the exponential complexity of possible object/relationship combinations. This leads to underrepresentation where many test samples are rare or unseen during training, resulting in poor predictions.

Proposed Solution:
- Leverage knowledge from pre-trained vision-language models (VLMs) to enhance SGG model representations, as VLMs have more comprehensive knowledge gained from larger datasets.  
- However, directly using VLMs introduces severe bias across relation words due to distribution misalignment between VLM pre-training and SGG objectives.
- Propose two main solutions:
   1) LM Estimation: Approximates underlying words distribution in VLM pre-training to enable debiasing.
   2) Certainty-Aware Ensemble: Dynamically ensembles debiased VLM predictions with SGG model by scoring each sample's representation certainty in both models.

Main Contributions:
- LM Estimation method to estimate and mitigate relation word bias in VLMs for SGG. Enables using debiased VLMs.
- Plug-and-play certainty-aware ensemble method to integrate debiased VLMs with SGG models. Improves representation and handles underrepresentation without extra training.
- Achieves new state-of-the-art results on Visual Genome and Open Images datasets. Effectively addresses underrepresentation and bias issues in SGG.

In summary, the paper introduces innovative ways to harness knowledge from VLMs to overcome key challenges in SGG, including underrepresentation and label bias, through model debiasing and ensemble. The methods are model-agnostic and bring significant performance gains.
