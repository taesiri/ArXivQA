# [LongWanjuan: Towards Systematic Measurement for Long Text Quality](https://arxiv.org/abs/2402.13583)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Effectively processing long texts is crucial for language models, but there's a lack of systematic approaches for assessing the quality of long texts. 
- Existing efforts on refining data quality focus on general training data rather than long texts specifically.

Solution:
- Propose metrics grounded in linguistic fundamentals to measure long text quality in terms of coherence, cohesion and complexity. Includes both statistical and pre-trained language model based metrics.
- Construct the LongWanjuan dataset by categorizing long texts from SlimPajama and Wanjuan into holistic, aggregated and chaotic types based on the proposed metrics.

Main Contributions:
- First work to systematically analyze and quantify long text quality through coherence, cohesion and complexity metrics.
- Constructed a 160B token bilingual long text dataset LongWanjuan with type categorizations.
- Devised a data mixture recipe that balances different types of texts in LongWanjuan, leading to SOTA long text performance on a 7B parameter model with a 13.07% gain.

In summary, this paper makes significant contributions by proposing coherence/cohesion/complexity metrics to systematically measure long text quality and using these metrics to construct the LongWanjuan dataset. Based on this dataset, a data mixture recipe is introduced that achieves state-of-the-art performance on long text tasks.
