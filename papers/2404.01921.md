# [A Rationale-centric Counterfactual Data Augmentation Method for   Cross-Document Event Coreference Resolution](https://arxiv.org/abs/2404.01921)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Current state-of-the-art event coreference resolution (ECR) systems depend too heavily on "triggers lexical matching", where events with lexically similar trigger words are more likely to be predicted as coreferential, even though deeper semantic features like event-relevant arguments constitute the rationales of the ECR task.

- The paper analyzes the excessive reliance on "triggers lexical matching" in ECR systems using a Structural Causal Model (SCM), identifying it as a spurious association that needs to be mitigated.

Proposed Solution: 
- The paper proposes a rationale-centric counterfactual data augmentation (DA) method called LLM-RCDA to enhance the model's causal reasoning capability. 

- LLM-RCDA has two phases - Trigger Intervention (TI) which diversifies trigger expressions using synonyms, and Context Intervention (CI) which uses a large language model (LLM) to edit the rationales in the context to flip event coreference labels.

- For CI, minimal edits are ensured to generate plausible counterfactuals that allow the model to focus directly on rationales. The overall workflow induces the ECR system to base decisions on deeper semantics rather than "triggers lexical matching".

Main Contributions:
- First work to evaluate LLMs on the cross-document ECR task and analyze the decision process of ECR systems causally.

- Proposes a specialized rationale-centric counterfactual DA method with LLM-in-the-loop to mitigate reliance on spurious patterns and emphasize causal associations unique to the ECR task.

- Achieves new state-of-the-art performance on ECB+, FCC and GVC benchmarks. Demonstrates stronger robustness on out-of-domain test sets, with more reasonable predicate changes based on rationales analysis.

In summary, the paper makes notable contributions in causally analyzing and enhancing neural ECR systems using rationale-centric counterfactual data augmentation. The proposed LLM-RCDA method sets new benchmarks and achieves better robustness.
