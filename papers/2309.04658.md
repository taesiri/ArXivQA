# Exploring Large Language Models for Communication Games: An Empirical   Study on Werewolf

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: Can large language models (LLMs) effectively play communication games like Werewolf in a natural way, without requiring extensive training data or model tuning?The key hypothesis appears to be that an approach relying on prompting and reflecting on past experiences can allow LLMs to engage in and learn to play Werewolf more naturally, without needing supervised training data or fine-tuning the model parameters. The paper explores whether frozen, unsupervised LLMs can develop gameplay strategies and exhibit complex behaviors like trust, confrontation, camouflage, and leadership when prompted to play Werewolf. The goal is to demonstrate that LLMs have potential for communication games and can learn from experience, instead of needing parameterized training.In summary, the central research question is whether LLMs can learn to play Werewolf through prompting and reflection alone, without model tuning or human annotations. The key hypothesis is that strategic gameplay can emerge from this prompting framework, suggesting promise for deploying LLMs in communication games.


## What is the main contribution of this paper?

The main contribution of this paper seems to be proposing a framework for engaging large language models (LLMs) like ChatGPT in communication games, using Werewolf as a case study. The key aspects of their framework are:- A method to handle the limited context length of LLMs by retrieving and reflecting on necessary historical information to create a compact context. This involves using recent messages, informative messages based on rules, and generating reflections by answering questions.- A non-parametric mechanism for learning from experience without tuning the LLM parameters, by extracting suggestions from an experience pool based on the current situation. This allows the LLM agents to improve without needing extra training data.- An empirical study applying this framework to the game of Werewolf, showing that strategic behaviors like trust, confrontation, camouflage and leadership can emerge without being explicitly programmed. The authors argue this demonstrates the potential of LLMs for playing communication games.So in summary, the main contribution is proposing and evaluating a novel framework to allow large language models to effectively play communication games that rely heavily on natural language, using Werewolf as an example case study. This is done without any parameter tuning of the LLMs.
