# Rethinking with Retrieval: Faithful Large Language Model Inference

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question it aims to address is: How can external knowledge be effectively utilized to assist large language models (LLMs) without requiring additional training or fine-tuning?The key points are:- LLMs like GPT-3 have shown great performance on NLP tasks through in-context learning, but their knowledge may be incomplete or incorrect. - Previous methods for incorporating external knowledge often require extra training/fine-tuning which is impractical for large LLMs.- This paper proposes a lightweight post-processing approach called "Rethinking with Retrieval" (RR) to leverage external knowledge to enhance LLMs without retraining them.- RR uses chain-of-thought prompting to get reasoning paths from the LLM, retrieves relevant knowledge using each reasoning step, and selects the most faithful prediction based on the retrieved knowledge.- The effectiveness of RR is evaluated on commonsense, temporal, and tabular reasoning tasks using GPT-3 and different knowledge sources like Wikipedia.So in summary, the central hypothesis is that the proposed RR approach can effectively utilize external knowledge to make LLMs like GPT-3 more accurate and faithful on complex reasoning tasks without needing additional training or fine-tuning. The experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

The main contribution of this paper is a new method called "rethinking with retrieval" (RR) for utilizing external knowledge to improve the reasoning ability and faithfulness of explanations of large language models (LLMs). Specifically, the key ideas and contributions are:- Proposes a post-processing approach to leverage external knowledge for LLMs without requiring additional training or fine-tuning. This makes it more lightweight and feasible compared to prior methods.- Uses chain-of-thought (CoT) prompting to generate diverse reasoning paths and explanations from the LLM. - Retrieves relevant external knowledge using each reasoning step in the paths as queries. This allows incorporating knowledge that is tailored to the LLM's own reasoning process.- Selects the most faithful prediction based on the retrieved knowledge, in order to improve accuracy.- Evaluates the approach on commonsense, temporal, and tabular reasoning tasks using GPT-3, showing it improves accuracy and explanation faithfulness over baselines.- Analyzes the limitations of LLMs in reasoning and shows the approach can address issues like missing knowledge and incorrect retrieval. - Explores variations like selecting facts from LLM outputs or generating new facts based on retrieved knowledge.So in summary, the key contribution is presenting and evaluating a new framework for utilizing external knowledge to enhance LLMs through post-processing retrieval and inference based on the LLM's own reasoning paths. The results demonstrate improvements in accuracy and explainability on complex reasoning tasks.
