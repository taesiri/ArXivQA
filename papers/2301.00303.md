# Rethinking with Retrieval: Faithful Large Language Model Inference

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question it aims to address is: How can external knowledge be effectively utilized to assist large language models (LLMs) without requiring additional training or fine-tuning?The key points are:- LLMs like GPT-3 have shown great performance on NLP tasks through in-context learning, but their knowledge may be incomplete or incorrect. - Previous methods for incorporating external knowledge often require extra training/fine-tuning which is impractical for large LLMs.- This paper proposes a lightweight post-processing approach called "Rethinking with Retrieval" (RR) to leverage external knowledge to enhance LLMs without retraining them.- RR uses chain-of-thought prompting to get reasoning paths from the LLM, retrieves relevant knowledge using each reasoning step, and selects the most faithful prediction based on the retrieved knowledge.- The effectiveness of RR is evaluated on commonsense, temporal, and tabular reasoning tasks using GPT-3 and different knowledge sources like Wikipedia.So in summary, the central hypothesis is that the proposed RR approach can effectively utilize external knowledge to make LLMs like GPT-3 more accurate and faithful on complex reasoning tasks without needing additional training or fine-tuning. The experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

The main contribution of this paper is a new method called "rethinking with retrieval" (RR) for utilizing external knowledge to improve the reasoning ability and faithfulness of explanations of large language models (LLMs). Specifically, the key ideas and contributions are:- Proposes a post-processing approach to leverage external knowledge for LLMs without requiring additional training or fine-tuning. This makes it more lightweight and feasible compared to prior methods.- Uses chain-of-thought (CoT) prompting to generate diverse reasoning paths and explanations from the LLM. - Retrieves relevant external knowledge using each reasoning step in the paths as queries. This allows incorporating knowledge that is tailored to the LLM's own reasoning process.- Selects the most faithful prediction based on the retrieved knowledge, in order to improve accuracy.- Evaluates the approach on commonsense, temporal, and tabular reasoning tasks using GPT-3, showing it improves accuracy and explanation faithfulness over baselines.- Analyzes the limitations of LLMs in reasoning and shows the approach can address issues like missing knowledge and incorrect retrieval. - Explores variations like selecting facts from LLM outputs or generating new facts based on retrieved knowledge.So in summary, the key contribution is presenting and evaluating a new framework for utilizing external knowledge to enhance LLMs through post-processing retrieval and inference based on the LLM's own reasoning paths. The results demonstrate improvements in accuracy and explainability on complex reasoning tasks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on my reading of the paper, here is a one-sentence summary:The paper proposes a novel post-processing approach called "rethinking with retrieval" that utilizes external knowledge sources to provide more faithful explanations and improve the performance of large language models on complex reasoning tasks, without requiring additional training or fine-tuning.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other research on enhancing large language models with external knowledge:- Approach: This paper proposes a post-processing method called "rethinking with retrieval" that retrieves relevant external knowledge based on the reasoning steps generated by large language models. Other works have incorporated knowledge through additional training or fine-tuning, which can be costly for large models.- Knowledge sources: This paper experiments with diverse knowledge sources like Wikipedia, Wikidata, WordNet, and ConceptNet. Some other works have focused on more limited sources like only WordNet or ConceptNet. - Task flexibility: This paper evaluates the approach on three different complex reasoning tasks - commonsense, temporal, and tabular reasoning. Many other works have focused evaluation on a single task like question answering or commonsense reasoning.- Model size: This paper examines the impact of model size, testing the approach on OPT models of various sizes in addition to GPT-3. Most other work has focused only on smaller models like T5 and BERT rather than large language models.- Performance: The proposed approach improves performance across all tasks compared to baselines like chain-of-thought prompting and self-consistency. The gains are especially notable on commonsense reasoning using the challenging StrategyQA dataset.Overall, this paper explores a lightweight yet effective technique for improving large language models using diverse external knowledge on a variety of reasoning tasks. The post-processing approach and task flexibility help differentiate it from prior works focused on smaller models or single knowledge sources/tasks. The analysis provides useful insights into the limitations of LLMs and benefits of the proposed techniques.
