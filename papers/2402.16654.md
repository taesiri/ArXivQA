# [GigaPevt: Multimodal Medical Assistant](https://arxiv.org/abs/2402.16654)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Building an intelligent and efficient medical assistant is challenging due to lack of multimodal data, which limits comprehensive patient assessment. 
- Existing symptom checker apps have limitations in using only text, missing non-verbal communication cues, and using rigid pre-defined questions.

Proposed Solution:
- The paper introduces GigaPevt, a multimodal medical assistant that combines dialog capabilities of large language models with specialized medical models.
- It uses a client-server architecture with a Python client handling face detection, TTS, ASR etc and a Flask server managing models and dialog logic.

Specialized Models:
- Video-based models for user identification, demographic prediction, facial expression recognition, BMI estimation and remote photoplethysmography.
- Retrieval-Augmented Generation and Chain of Thoughts techniques used to improve dialog quality and domain focusing.

Main Contributions:  
- A multimodal medical assistant architecture for patient assessment.
- Use of specialized medical models with dialog capabilities of large language models.  
- Improved performance on medical question answering and inference tasks.
- More natural dialog and ability to leverage visual cues for better diagnosis.

In summary, the key innovation is combining specialized medical models with rich dialog capabilities of large language models to create a comprehensive multimodal medical assistant that can overcome limitations of existing symptom checker apps.
