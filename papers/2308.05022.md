# [Feature Modulation Transformer: Cross-Refinement of Global   Representation via High-Frequency Prior for Image Super-Resolution](https://arxiv.org/abs/2308.05022)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key points of this paper are:- It analyzes the impact of high vs low frequency information on the performance of CNNs and transformers for single image super-resolution (SISR). - Through experiments, it finds that transformers are better at capturing low frequency (global) information but have limited ability to reconstruct high frequency details compared to CNNs.- To address this limitation, the paper proposes a new model called CRAFT that combines the strengths of CNNs and transformers. CRAFT uses a CNN-based module (HFERB) to extract high frequency details, a transformer module (SRWAB) to capture global context, and a fusion module (HFB) to integrate them.- The key hypothesis is that explicitly incorporating high frequency information from a CNN as a "prior" and fusing it with the global context from a transformer can improve SISR performance compared to using either CNNs or transformers alone.So in summary, the main research question is how to effectively combine CNNs and transformers for SISR in a way that leverages the complementary strengths of each architecture - with a focus on better utilizing high frequency detail from CNNs to improve transformer performance. The CRAFT model is proposed to address this question.


## What is the main contribution of this paper?

This paper proposes a new image super-resolution method called CRAFT (cross-refinement adaptive feature modulation transformer). The key contributions are:1. They analyze the impact of frequency information on CNN and transformer models for SISR. They find that transformers are better at capturing low-frequency information while CNNs are better at reconstructing high-frequency details. 2. Based on this analysis, they propose CRAFT which combines CNN and transformer blocks in a novel way. It has three main components:- HFERB (high-frequency enhancement residual block) to extract high-frequency details using CNN. - SRWAB (shift rectangle window attention block) to capture global low-frequency information using a transformer.- HFB (hybrid fusion block) to refine the global features from the transformer using the high-freq details from CNN as a prior.3. Experiments show CRAFT achieves state-of-the-art performance on SISR benchmarks, outperforming previous CNN and transformer methods. It improves PSNR by up to 0.29dB compared to prior art.4. The proposed architecture provides an effective way to combine the complementary strengths of CNNs and transformers for low-level vision tasks like super-resolution. The idea of using the CNN branch as a high-freq prior to refine global transformer features is novel.In summary, the key contribution is a new SISR model that strategically combines CNN and transformer blocks to capture both high-frequency details and global context for improved performance. The architecture design and fusion strategy are tailored based on frequency analysis.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a cross-refinement adaptive feature modulation transformer (CRAFT) for image super-resolution that integrates convolutional and transformer structures, using the convolutional branch to extract high-frequency details and the transformer branch to capture global information, with a fusion mechanism to refine the global features using the high-frequency information as a prior.
