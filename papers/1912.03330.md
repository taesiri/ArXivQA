# [ClusterFit: Improving Generalization of Visual Representations](https://arxiv.org/abs/1912.03330)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:Can we improve the generalization of visual representations learned during pre-training in weakly-supervised and self-supervised frameworks? The authors propose that the visual representations learned via these pre-training approaches may overfit to idiosyncrasies of the pre-training task and data. Their key insight is that "smoothing" the learned feature space, for example via clustering, can help remove artifacts from the pre-training objective and avoid overfitting, thus improving transferrability. To address this question, the authors propose a framework called ClusterFit which involves:1) Clustering the features extracted from a network pre-trained on some proxy task, using k-means. 2) Retraining a new network from scratch on the same dataset, using the cluster assignments as pseudo-labels.Through extensive experiments on various pre-training methods (weakly supervised, self-supervised) and modalities (images, videos), the authors demonstrate that ClusterFit consistently improves generalization and transferrability of the learned representations.In summary, the central hypothesis is that clustering helps "smooth" the feature space and removes artifacts of the pre-training objective, thereby improving transfer learning performance. The proposed ClusterFit framework is evaluated as a way to test this hypothesis.
