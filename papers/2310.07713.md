# [InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining](https://arxiv.org/abs/2310.07713)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How does continued pretraining of large language models with retrieval augmentation, followed by instruction tuning, impact their performance on question answering tasks?

Specifically, the authors are investigating whether scaling up a retrieval-augmented language model called Retro to 48 billion parameters, and then applying instruction tuning, can improve performance on question answering compared to a baseline GPT model of comparable size that did not utilize retrieval augmentation. 

The key hypothesis seems to be that the combination of retrieval-augmented pretraining and instruction tuning will unlock additional capabilities in large language models, enabling them to better leverage retrieved knowledge when answering questions. The authors hypothesize this training recipe can yield a better decoder for question answering compared to standard pretraining and instruction tuning.

In summary, the core research question is whether and how much continued pretraining with retrieval, plus instruction tuning, can enhance the zero-shot QA abilities of large language models compared to strong baselines like GPT and InstructGPT. The paper aims to demonstrate the value of their proposed InstructRetro model and training methodology.


## What is the main contribution of this paper?

 The main contribution of this paper is introducing InstructRetro 48B, which is the largest language model pretrained with retrieval before instruction tuning. Specifically, the key contributions are:

1. Scaling up Retro, a retrieval-augmented language model, to 48B parameters by continuing to pretrain a 43B GPT model on additional 100B tokens while retrieving from a corpus of 1.2 trillion tokens. This results in a foundation model called Retro 48B that achieves significantly lower perplexity than the original GPT 43B.

2. Applying instruction tuning to Retro 48B, yielding a model called InstructRetro 48B. Experiments show that InstructRetro 48B outperforms its GPT counterpart (GPT-Instruct 43B) on several question answering datasets, especially on long-form QA where the average improvement is 10%.

3. Ablation studies showing that the decoder backbone alone of InstructRetro can achieve comparable performance as using the full model. This highlights the potential of obtaining a better GPT decoder through continued pretraining with retrieval before instruction tuning.

In summary, the main contribution is proposing a training recipe of scaling up retrieval-augmented pretraining followed by instruction tuning, which results in improved language models for question answering. The paper unveils the potential of this recipe through introducing and experimenting with InstructRetro 48B.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper introduces InstructRetro, a 48 billion parameter language model pretrained with retrieval augmentation and then further enhanced with instruction tuning, which achieves strong performance on question answering tasks compared to similarly sized models without retrieval augmentation.
