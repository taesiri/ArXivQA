# [Deep Point Cloud Reconstruction](https://arxiv.org/abs/2111.11704)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we jointly resolve the inherent shortcomings of point cloud obtained from 3D scanning devices, namely sparsity, noise, irregularity and outliers?The key hypothesis is that jointly solving the tasks of point cloud densification, denoising and completion in a unified framework will lead to significant improvements in point cloud reconstruction compared to tackling each task independently. The paper proposes a novel two-stage deep learning architecture called a "deep point cloud reconstruction network" to address this question. The two stages are:1) A voxel generation network that converts the raw point cloud to voxels and densifies/denoises it. 2) A voxel re-localization network that converts the voxels back to points and further refines them using self-attention and a proposed "amplified positional encoding" method.The central hypothesis is that this joint voxel-based framework can robustly handle unordered, sparse and noisy point clouds better than existing point-based or independent networks. The experiments aim to validate the superiority of the proposed approach on synthetic and real-world scanned point cloud datasets.In summary, the paper introduces joint point cloud reconstruction as a new problem formulation and proposes a novel deep network architecture to address the inherent issues in raw scanned point clouds in a unified manner. The central hypothesis is that this joint approach leads to better performance than tackling each problem independently.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Proposing a new task called "point cloud reconstruction" that aims to jointly resolve issues like sparsity, noise, and irregularity in raw point clouds obtained from 3D scanning devices. This is in contrast to prior work that focused on these issues separately through tasks like point densification, denoising, and completion.2. Developing a two-stage deep neural network architecture for point cloud reconstruction. The first stage uses a voxel generation network with sparse 3D convolutions to densify the point cloud and remove outliers. The second stage uses a transformer architecture to convert the voxels back to a refined 3D point cloud.3. Introducing a novel "amplified positional encoding" module for the transformer in the second stage. This adaptively amplifies high frequency signals in the positional encoding based on voxel distances to help with the voxel-to-point conversion process.4. Demonstrating through experiments on datasets like ShapeNet, ScanNet, and ICL-NUIM that the proposed approach outperforms existing methods for point densification, denoising and completion. The results also show good generalization ability to real scan data.In summary, the key novelty seems to be in formulating point cloud reconstruction as a joint task, proposing a voxel-to-point architecture to address it, and using amplified positional encodings to help with the voxel re-localization into a refined point cloud. The experiments then validate the effectiveness of this approach over prior techniques.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on my understanding, the key points of the paper are:- It proposes a new deep learning based method for point cloud reconstruction, which aims to jointly address issues like sparsity, noise, irregularity, and incompleteness in raw point clouds obtained from 3D scanning devices.- The method has a two-stage architecture: 1) A voxel generation network that converts the input point cloud to voxels and uses a sparse 3D stacked hourglass network to densify and denoise the voxel volume.2) A voxel re-localization network that converts the voxels back to points using transformers, and refines the point locations using a proposed amplified positional encoding technique.- Experiments on various datasets show the method achieves state-of-the-art performance for point cloud reconstruction compared to existing techniques, and generalizes well to real-world scans.In one sentence, I would summarize it as: The paper proposes a new deep learning based two-stage method for reconstructing high quality point clouds from raw, sparse, irregular scans using voxelization and transformer networks.


## How does this paper compare to other research in the same field?

This paper proposes a novel deep learning approach for point cloud reconstruction. Here are a few key ways it compares to other research in this field:- Most prior work has focused on individual tasks like point cloud denoising, upsampling or completion. This paper proposes jointly solving these problems under a unified framework of point cloud reconstruction. Combining complementary tasks improves overall performance.- The two-stage architecture using voxel generation and re-localization networks is unique. Voxelization provides robustness to noise and irregularity. The transformer refinement stage further densifies and enhances detail.- The amplified positional encoding module is a novel way to incorporate geometric priors into the transformer. By controlling the amplitude based on voxel distances, it better preserves high frequency signals needed for sharp reconstruction. - Results demonstrate state-of-the-art performance on ShapeNet, ScanNet and ICL-NUIM datasets compared to existing methods. The approach also generalizes well to real scans without fine-tuning.- Most prior learning-based techniques rely on nearest neighbors or other point-based groupings. The voxelization approach using sparse convolutions provides greater robustness to density variation.- End-to-end training on raw point cloud data rather than meshes or CAD models better reflects real use cases and measurement noise.Overall, the unified joint refinement framework, novel voxel-transformer architecture, and robustness to real scan data appear to be key innovations compared to prior point cloud reconstruction literature. The experiments comprehensively validate these advantages across diverse datasets.
