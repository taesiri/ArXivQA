# [Deep Point Cloud Reconstruction](https://arxiv.org/abs/2111.11704)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we jointly resolve the inherent shortcomings of point cloud obtained from 3D scanning devices, namely sparsity, noise, irregularity and outliers?The key hypothesis is that jointly solving the tasks of point cloud densification, denoising and completion in a unified framework will lead to significant improvements in point cloud reconstruction compared to tackling each task independently. The paper proposes a novel two-stage deep learning architecture called a "deep point cloud reconstruction network" to address this question. The two stages are:1) A voxel generation network that converts the raw point cloud to voxels and densifies/denoises it. 2) A voxel re-localization network that converts the voxels back to points and further refines them using self-attention and a proposed "amplified positional encoding" method.The central hypothesis is that this joint voxel-based framework can robustly handle unordered, sparse and noisy point clouds better than existing point-based or independent networks. The experiments aim to validate the superiority of the proposed approach on synthetic and real-world scanned point cloud datasets.In summary, the paper introduces joint point cloud reconstruction as a new problem formulation and proposes a novel deep network architecture to address the inherent issues in raw scanned point clouds in a unified manner. The central hypothesis is that this joint approach leads to better performance than tackling each problem independently.
