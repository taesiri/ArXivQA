# [MMIDR: Teaching Large Language Model to Interpret Multimodal   Misinformation via Knowledge Distillation](https://arxiv.org/abs/2403.14171)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Detecting misinformation presented in multiple modalities like text, images, video etc. is challenging as it requires assessing credibility of each modality and their combinations. 
- Existing misinformation detection methods have focused mainly on textual data and their explainability has relied on extraction methods which lack human-friendliness. 
- Utilizing the potential of large language models (LLMs) for multimodal misinformation detection and getting them to provide natural language-based explanations remains an open research area.

Proposed Solution:
- The paper proposes MMIDR, a novel framework to teach LLMs to provide fluent textual explanations for their assessments regarding multimodal misinformation.
- It presents a data augmentation pipeline to transform multimodal retrieval-enhanced misinformation data into appropriate instruction-following format for LLMs.
- Teacher LLMs like ChatGPT are prompted to extract rationales explaining their labeling of the multimodal content as misinformation.
- An efficient knowledge distillation method using LoRA is designed to transfer capability of interpreting multimodal misinformation from teacher LLMs to student LLMs like LLaMA, MiniGPT-v2.

Main Contributions:
- First exploration of using LLMs and multimodal LLMs for detecting multimodal misinformation 
- MMIDR - a novel frameork to teach LLMs to interpret multimodal misinformation and provide textual explanations for their decision making
- Data augmentation perspective and pipeline to convert multimodal data into instruction-following format
- Construction of instruction-following multimodal misinformation dataset using teacher LLM
- Knowledge distillation method to transfer expertise of teacher LLM to student LLMs like LLaMA, MiniGPT-v2
- Extensive experiments demonstrating MMIDR's detection performance and ability to provide compelling rationales

In summary, the paper explores an underexplored area of leveraging capabilities of LLMs for multimodal misinformation analysis and proposes an effective solution through instruction-based dataset creation and knowledge distillation to student LLMs.
