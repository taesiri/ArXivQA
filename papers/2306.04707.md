# [Improving Open Language Models by Learning from Organic Interactions](https://arxiv.org/abs/2306.04707)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we improve open domain conversational models by learning from real-world organic interactions and feedback data?The key hypothesis seems to be:By collecting and learning from organic user interactions and feedback in a public deployment, conversational models can be improved in terms of both conversational quality and safety.The paper details the analysis of a large dataset of organic user interactions with the BlenderBot 3 conversational agent. It studies techniques to leverage this data, including human feedback signals like thumbs up/down, to improve the model. The main contributions appear to be:1) Analysis of a large dataset of organic user interactions with BlenderBot 3. This includes over 350k conversations and over 6M utterances.2) Development of a reward model to label conversational responses as good or bad using the organic feedback data.3) Experiments with different techniques like the Cringe Loss to improve conversational quality and safety from the organic interaction data.4) Introduction of the BlenderBot 3x model, which outperforms BlenderBot 3 in terms of response quality and safety when evaluated on the organic user data.5) Release of the organic interaction dataset to spur further research.So in summary, the central hypothesis is that conversational models can be improved by collecting and learning from organic user interactions, which the paper tests through analysis, model training experiments, and human evaluations. The release of the dataset also aims to enable further research in this direction.
