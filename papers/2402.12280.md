# [Adaptive Skeleton Graph Decoding](https://arxiv.org/abs/2402.12280)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper "Adaptive Skeleton Graph Decoding":

Problem:
- Large language models (LLMs) have become very popular and achieve great success on NLP tasks, but their inference incurs high computational and memory costs due to their massive size and autoregressive generation. 
- Existing parallel decoding methods like Skeleton-of-Thought (SoT) improve efficiency but suffer from reduced quality by making strong independence assumptions between sub-problems.

Proposed Solution: 
- The paper proposes Skeleton Graph Decoding (SGD), a parallel decoding method that models dependencies between sub-problems as a directed acyclic graph (DAG). 
- SGD first uses an LLM to decompose the original question into logically dependent sub-problems with difficulty estimates.
- It then constructs a DAG representing dependencies between sub-problems. Independent nodes are batch decoded in parallel for efficiency.  
- An adaptive model selection mechanism assigns sub-problems to different sized LLMs based on estimated difficulty.

Key Contributions:
- Introduces skeleton graph structure to model dependencies between sub-problems, improving quality and exposing parallelization opportunities.
- Implements adaptive model selection to assign sub-problem nodes to appropriately sized LLMs based on difficulty.
- Achieves up to 1.69x speedup over autoregressive decoding while improving quality by up to 51.3% on benchmarks.
- Provides a framework to optimize the tradeoff between quality and performance in parallel decoding of prompts.

In summary, the key innovation of SGD is modeling causal dependencies in a skeleton graph to enhance reasoning quality while allowing batch parallel decoding, combined with an adaptive model assignment technique for further optimizations. The method demonstrates significant improvements over both autoregressive decoding and prior Skeleton-of-Thought technique.
