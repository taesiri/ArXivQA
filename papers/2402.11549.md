# [Syntactic Language Change in English and German: Metrics, Parsers, and   Convergences](https://arxiv.org/abs/2402.11549)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Syntactic dependency distance, the linear distance between syntactically dependent words, is an indicator of language processing difficulty. Past work has shown evidence of a dependency distance minimization (DDM) principle in language change, but has relied on a single parser and focused only on English. 

- This paper investigates diachronic trends in syntactic measures beyond just dependency distance in both English and German parliamentary debate data over the past ~160 years. It considers whether conclusions depend on the choice of parser and also examines cross-linguistic differences and similarities.

Methodology:
- Leverages 5 parsers: CoreNLP, StackPointer, Biaffine, TowerParse, Stanza to parse the data
- Examines 9 sentence lengths (5-7 words, up to 70-72 words)
- Computes 15 metrics capturing statistical patterns and linguistic phenomena in dependency parse trees, including mean dependency distance (mDD), normalized mDD (nDD), tree height, degree variance, etc.

- Uses Mann-Kendall trend test to detect monotonic trends over time in metrics, supported by a majority vote over parsers

Key Findings:
- Trends depend substantially on choice of parser, prompting the use of multiple parsers
- Very few cases (4%) show opposite diachronic trends in English vs. German; mostly show convergence
- Shorter/longer sentences change differently; trees become shorter/wider vs. taller/narrower  
- No clear evidence for decreasing mDD over time, contrary to some past work
- Many trends are subtle in scale and timeline due to slow nature of syntactic change

Contributions:
- Most comprehensive analysis of syntactic language change using modern NLP methods on recent English and German political language
- Analyzes importance of parser choice for detecting language change 
- Compares cross-linguistic similarities and differences in syntactic change
- Examines breadth of syntactic measures beyond just dependency distance


## Summarize the paper in one sentence.

 This paper comprehensively analyzes diachronic syntactic changes in English and German political debates over the past 160 years using multiple dependency parsers and graph-based metrics, finding mostly converging patterns between the two languages except for an increasing mean dependency distance in German.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1) The paper comprehensively analyzes syntactic language change in English and German over the past ~160 years using modern NLP methods. It investigates 15 syntactic metrics beyond just dependency distance, including tree height, degree variance etc. on political debate data. 

2) The paper examines the reliability of using modern parsers trained on treebanks for parsing historical text data with more noise. It evaluates 5 parsers on the target historical datasets and perturbed variants, finding that the parsers are legitimate for this use case.

3) The paper highlights that conclusions about syntactic language change trends are sensitive to the parser used, showing only moderate agreement among parsers. Thus relying on a single parser as done in prior work is questionable.  

4) The paper provides novel insights into the similarity and differences of syntactic changes between English and German. For instance, it discovers a clear upward trend in dependency distance for German but not English. Overall syntactic changes in both languages seem more similar than divergent.

5) The paper also analyzes which sentence lengths and syntactic metrics exhibit the most distinct or similar change patterns across the two languages. For example, shortest and longest sentences change more similarly between languages than sentences of middle lengths.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with it are:

- Syntactic language change
- Dependency distance minimization (DDM)
- Mean dependency distance (MDD)
- Normalized mean dependency distance (NDD) 
- Dependency parsers (e.g. Stanford CoreNLP, StackPointer, Biaffine, TowerParse, Stanza)
- Political debates corpora (Hansard, DeuParl)
- Syntax metrics (tree height, degree variance, head-final ratio, etc.)
- Diachronic trends
- Language convergence and divergence 
- Sentence length effects
- Data noise and parsing robustness

The paper examines syntactic changes in English and German over the past ~160 years using parliamentary debate transcripts. It leverages multiple dependency parsers to extract 15 syntax metrics and compares their diachronic trends across languages. Key goals are assessing parser reliability on historical noisy data, quantifying syntactic convergence/divergence between languages, and analyzing the effect of sentence length on observations. So the main focus is on computational analysis of syntactic language change using parsers and corpora.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. This paper argues that different parsers may lead to different conclusions about diachronic trends of syntactic metrics. Why do you think this is the case? How could the parsers' architectures or training procedures lead to these differing views of language change?

2. The paper leverages 5 parsers with different designs (transition vs graph based). Do you think these architectural choices may systematically bias certain parsers towards seeing more or less language change? Why?  

3. The majority vote approach is used to identify the most likely stable diachronic trends. What are the limitations of this approach? When might it fail to identify real trends or falsely identify non-existent ones?

4. The paper argues that prior works may have limitations in how they group sentences by length when looking at diachronic trends. What exactly is the issue identified with those prior grouping strategies? Why is it important to control for sentence length more strictly?

5. The paper explores change along 15 different syntactic measures. Do you expect all of these measures to change at the same rate over time? Why or why not? How might they interact?

6. This paper finds mostly similar syntactic changes in English and German parliamentary language. Do you think this convergence finding would also hold for other genres/domains? Why might political language be more prone to syntactic convergence?  

7. The scale of observed syntactic changes is often quite small over the 160 year periods examined. What are some ways the analysis could be improved to better capture meaningful syntactic change at larger scales?

8. The paper does not find clear evidence for dependency distance minimization in the diachronic data. What other principles or factors might be driving the observed syntactic changes instead?  

9. The paper notes genre as an important limitation. What sorts of genre differences could you expect to impact the syntactic measures explored in this analysis? How might those differences manifest?

10. The time depth of 200 years may be too short to conclusively identify syntactic changes. What is a reasonable or ideal amount of time depth for studying syntactic language change with the methods proposed here? What challenges exist in constructing datasets with longer time spans?
