# [Bandit-Feedback Online Multiclass Classification: Variants and Tradeoffs](https://arxiv.org/abs/2402.07453)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
The paper studies online multiclass classification in the mistake bound model. It investigates the impact on the optimal mistake bound of having only bandit vs full information feedback, playing against an adaptive vs oblivious adversary, and using a randomized vs deterministic learner. 

Key Contributions:

1. Quantifies price of bandit feedback: Shows the optimal mistake bound with bandit feedback is at most O(k) times higher than with full information feedback, where k is the number of labels. This resolves an open question on whether a logarithmic or linear dependence on k exists.

2. Price of adaptivity: Proves an Ω(k) lower bound on the ratio between the optimal mistake bound against an adaptive adversary vs an oblivious adversary with bandit feedback. This shows adaptivity helps the adversary. 

3. Price of randomness: Constructs concept classes where the optimal mistake bound of a randomized learner is Ω(√d) smaller than that of the best deterministic learner, where d is a parameter. This shows randomness helps the learner and resolves an open question.

4. Prediction with expert advice: Provides tight mistake bounds of Θ(k(log n + r)) for the problem with n experts, k labels and best expert making at most r mistakes. This generalizes known results for the binary case.

Proposed Solution and Techniques:

- Uses a reduction from learning with bandit feedback to an instance of prediction with expert advice based on a tree construction.

- Analyzes the optimal mistake bounds through minimax duality and potential functions.

- Constructs explicit concept classes that exhibit the separations in optimal mistake bounds.

The results significantly advance our understanding of the impact of information, adaptivity and randomness on online multiclass classification. The prediction with expert advice bounds are also of independent interest.
