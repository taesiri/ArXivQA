# [Verbing Weirds Language (Models): Evaluation of English Zero-Derivation   in Five LLMs](https://arxiv.org/abs/2403.17856)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- English allows flexibility in syntactic categories (parts of speech) of words through a process called conversion or zero-derivation. For example, nouns can be used as verbs ("to google") and verbs as nouns ("a swim").
- Little prior work has studied whether large language models (LLMs) can capture this syntactic flexibility and generalize words to non-prototypical categories.

Methodology:
- Created sets of prompts to test LLMs' ability to make inferences with words used in prototypical vs non-prototypical vs nonce (made up word) categories.
- Tested 5 LLMs: GPT-3.5, GPT-4 (commercial), and Mistral 7B, Falcon 40B, Llama 70B (open source).
- Prompts followed a natural language inference format (e.g. "If I don't swim daily, do I swim every day?").
- Compared accuracy on prototypical vs non-prototypical usage.

Results:
- GPT-4 performed best overall, followed by GPT-3.5. Mistral 7B performed surprisingly well for an open source 7B parameter model.
- Performance was better on prototypical than non-prototypical usage across models.
- Model size did not fully account for performance differences.

Contributions:
- New methodology for testing conversion ability of LLMs
- Test set that can be applied to arbitrary models
- Demonstration that lexical-syntactic flexibility does not strictly correlate with model size

Overall the paper introduces a novel test methodology and dataset to analyze an important linguistic phenomenon in LLMs. Key findings are that model size alone does not determine this ability, and that state-of-the-art models still struggle with non-prototypical syntactic usage compared to humans.
