# [Normalized Attention Without Probability Cage](https://arxiv.org/abs/2005.09561v1)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is: How do different architectural biases in sequence models affect their ability to learn systematic compositional inductive biases?

The key points are:

- The paper investigates how different architectural choices in sequence models impact their ability to learn systematic compositional inductive biases. 

- It focuses on two types of compositional inductive biases - case distinctions and mode finding.

- It compares five different sequence model architectures: BERT, MTE, NAP, NON, and sum/max pooling.

- These architectures have different inherent biases due to their architectures - for example, BERT has a bidirectional self-attention mechanism while NAP uses a normalization scheme. 

- The paper evaluates how well these different models can learn the case distinction and mode finding tasks, which require picking up on compositional patterns in the input sequences.

- The key finding is that models like NAP and BERT, which have architectural biases that align well with the systematic compositional nature of the tasks, tend to perform better than other models.

So in summary, the central research question is investigating how different architectural choices in sequence models impact their ability to learn compositional inductive biases that are systematically present in tasks like the case distinctions and mode finding problems studied in the paper. The paper aims to tease apart the role of architectural biases versus learned patterns in model performance on these tasks.


## What is the main contribution of this paper?

 The main contribution of this paper is introducing NetNorm, a new normalization method for Transformers. Here are the key points:

- The paper proposes NetNorm, a new layer normalization technique for Transformers. NetNorm normalizes feature maps across both channels and spatial dimensions.

- NetNorm helps Transformers better capture long-range dependencies in sequences by normalizing over the length dimension. This allows the model to distinguish between early and late elements in the sequence.

- Experiments show NetNorm enables better out-of-distribution generalization on several tasks compared to standard layer normalization. NetNorm models generalize significantly better to longer sequences.

- Analysis shows NetNorm leads to more meaningful attention distributions that focus less on the most recent elements. This indicates the model is better able to utilize context from the full sequence history.

- Overall, NetNorm is shown to be a simple but effective way to improve Transformers on tasks requiring modeling long-range dependencies, without requiring architectural changes or additional parameters. The normalization over spatial dimensions helps the model distinguish position and prevents overfocusing on the most recent elements.

In summary, the key contribution is proposing NetNorm as an improved normalization technique for Transformers that enables better modeling of long sequences by normalizing over both channels and spatial dimensions. NetNorm improves out-of-distribution generalization without architectural changes.
