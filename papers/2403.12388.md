# [Interpretable User Satisfaction Estimation for Conversational Systems   with Large Language Models](https://arxiv.org/abs/2403.12388)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Accurately estimating user satisfaction in conversational systems like chatbots is critical for evaluation and improvement. 
- Existing approaches using featurized ML models or embeddings have limitations in interpretability and generalizability across diverse conversational patterns.

Proposed Solution - SPUR:
- Uses large language models (LLMs) to extract interpretable satisfaction signals from user utterances more effectively. 
- Introduces a 3-step iterative prompting framework:
   1) Supervised Extraction: Extract possible SAT/DSAT patterns from labeled conversations using LLM
   2) Rubric Summarization: Summarize prominent patterns into clear rubrics  
   3) User Satisfaction Estimation: Apply learned rubrics to unseen conversations to predict satisfaction
- Tailors the LLM to target domain using supervision from labeled examples to learn domain-specific rubrics.

Key Contributions:
- Higher accuracy for user satisfaction estimation compared to baselines
- Generates interpretable rubrics to identify reasons for satisfaction/dissatisfaction  
- Generalizable - automatically learns diverse rubrics for different conversational systems
- Scalability - rubrics can be distilled into embeddings and used as features in ML models
- Analysis provides insights into different satisfaction patterns across domains

In summary, the paper introduces a novel prompting framework called SPUR that leverages the reasoning capabilities of LLMs to provide an accurate and interpretable approach to user satisfaction estimation across diverse conversational systems.
