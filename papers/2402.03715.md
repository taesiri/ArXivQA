# [Clarify: Improving Model Robustness With Natural Language Corrections](https://arxiv.org/abs/2402.03715)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Machine learning models trained with supervised learning often rely on spurious correlations in the training data, leading to poor generalization on new distributions. While additional supervision can help models learn more robust prediction rules, existing forms of supervision like additional labels are inefficient as they require annotations at a scale comparable to the original training data.

Proposed Solution: 
The paper proposes Clarify, a framework that allows humans to interactively correct model failures by providing natural language descriptions of the model's misconceptions. Compared to labels for instances or groups, these concept-level textual descriptions are substantially more information-dense. Clarify consists of an interface for collecting descriptions and an automated method for incorporating them by reweighting training data.

Key Contributions:
- Proposes targeted natural language feedback as an efficient form of human supervision for improving model robustness. This is unlike conventional annotation paradigms which require labels at a similar scale to the original training data.
- Introduces Clarify, an interactive interface for eliciting descriptions of model failures from humans. User studies (N=26) demonstrate that non-experts can successfully identify and describe model misconceptions.  
- Shows that retraining models with non-expert descriptions from Clarify improves worst-group accuracy by 17.1% on average. Also discovers and rectifies 31 novel spurious correlations in ImageNet, improving minority-group accuracy from 21.1% to 28.7%.
- Compares Clarify to automated methods and demonstrates substantially better performance in identifying relevant failure modes. Also shows it is uniquely suited to improve robustness at scale unlike specialized techniques.

In summary, the key innovation is using targeted natural language feedback about model failures to efficiently improve model robustness, enabled through an interactive interface. Experiments demonstrate that this leads to significant robustness gains in practice.
