# [Object-Centric Domain Randomization for 3D Shape Reconstruction in the   Wild](https://arxiv.org/abs/2403.14539)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Single-view 3D shape reconstruction in real-world environments remains challenging due to the scarcity of paired 3D shape and 2D image data from diverse real-world environments. Collecting such paired data at scale is very expensive and nearly infeasible.  

Proposed Solution:
The paper proposes Object-Centric Domain Randomization (ObjectDR), a framework to synthesize large-scale paired 3D shape and 2D image data via random simulation of visual variations in object appearances and backgrounds. The key ideas are:

1) Use conditional generative models like ControlNet to generate diverse 2D images conditioned on 2.5D sketches (obtained by rendering 3D shapes). This allows simulating infinite random variations.

2) Propose ObjectDR_dis to effectively tackle the trade-off between diversity and fidelity in the generated images. It disentangles object appearance and background randomization, uses initial object guidance to ensure fidelity, and filters inadequate images.  

3) Construct a dataset with 110.8K images paired with 3D shapes by rendering shapes from Objaverse-XL and randomizing appearances/backgrounds.

4) Pre-train 3D reconstruction models like AtlasNet and Mesh R-CNN on this randomized data so they learn a domain-invariant geometry prior useful for generalizing across real-world environments.

Main Contributions:

- Proposes scalable framework ObjectDR to synthesize diverse paired 3D-2D data via random simulation 

- Introduces ObjectDR_dis to address diversity-fidelity trade-off by disentangled object/background randomization

- Constructs 110.8K high-fidelity randomized paired data  

- Shows pre-training on this data boosts performance of AtlasNet by 13.4% and Mesh R-CNN by 10% on real dataset, enabling 3D shape reconstruction in the wild

In summary, the paper enables generating infinite paired 3D-2D data at scale to empower 3D perception models to handle real-world environments through an object-centric domain randomization approach. The disentangled framework ensures both diversity and fidelity. Experiments validate the efficacy of model pre-training on such randomized data.
