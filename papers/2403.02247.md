# [Birbal: An efficient 7B instruct-model fine-tuned with curated datasets](https://arxiv.org/abs/2403.02247)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) are expensive to fine-tune and access due to hardware constraints, limiting widespread usage. 
- Lack of transparency around model training methods and data leads to poor reproducibility.

Proposed Solution:
- The authors participated in the LLM Efficiency Challenge introduced at a NeurIPS workshop. The goal was to adapt an open-source foundation model to diverse tasks with fine-tuning on a single GPU within 24 hours. 
- They developed "Birbal", based on the open-source 7B parameter Mistral model. The key was curating high-quality instruction datasets covering diverse tasks rather than optimizations.

Approach:
- Curated 200k, 400k and 700k instruction datasets from quality sources like LIMA, Open-Platypus and Natural Instructions.
- Fine-tuned Mistral-7B on this dataset with 4-bit QLoRA optimization for 16 hours on an NVIDIA RTX 4090 GPU.
- Submitted 3 models for evaluation, with the 200k model (Birbal-200k) performing the best.

Results: 
- In closed eval on unseen tasks, Birbal-200k outperformed the next best model by 35%, showing the impact of data curation.
- It scored higher on more tasks compared to the base Mistral-7B model and Birbal fine-tuned with more data.
- The approach demonstrates how high quality instruction tuning rather than scale enables accessible and reproducible competitive LLMs.

In summary, the key novelty is leveraging compact, curated instruction tuning rather than scale for accessible yet strong language model fine-tuning within hardware constraints, enabling democratized access. The reproducibility and open access of the artifacts is also impactful.
