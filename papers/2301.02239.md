# [Robust Dynamic Radiance Fields](https://arxiv.org/abs/2301.02239)

## What is the central research question or hypothesis that this paper addresses?

The main research question this paper addresses is how to reconstruct dynamic radiance fields from monocular videos without requiring camera poses as input. The key hypothesis is that by jointly optimizing camera poses and separate radiance fields for static and dynamic scene elements, along with architectural designs like coarse-to-fine training and auxiliary losses, they can achieve robust reconstruction of time-varying scenes from challenging real-world videos where standard structure-from-motion techniques fail.In summary:- Research question: How to reconstruct dynamic radiance fields from monocular video without known camera poses?- Hypothesis: Jointly optimizing poses and separate static/dynamic radiance fields with careful architectural choices enables robust reconstruction from challenging real-world videos where traditional SfM fails.The ability to reconstruct dynamic scenes from monocular video without camera poses could enable new applications in VR/AR and video manipulation. The key innovation is achieving this in a way robust to issues like dynamic objects and textureless regions that affect standard SfM techniques.


## What is the main contribution of this paper?

The main contribution of this paper is developing a method to reconstruct dynamic radiance fields from monocular videos without requiring accurate camera poses as input. Specifically:- The paper presents an approach to jointly optimize camera poses and two radiance fields (static and dynamic) to model a dynamic scene. This avoids relying on potentially erroneous poses from SfM systems.- The method includes careful designs like a coarse-to-fine strategy, epipolar geometry to exclude moving pixels, deformation fields, time-dependent appearance models, and regularization losses to improve robustness. - Extensive experiments validate the approach on challenging real-world datasets where typical SfM systems fail. Both quantitative metrics and visual results demonstrate favorable performance compared to prior state-of-the-art dynamic view synthesis techniques.In summary, the key contribution is a robust approach to reconstruct time-varying scene geometry and appearance from monocular video without known camera poses. This is achieved through joint optimization of poses and static/dynamic radiance fields guided by architectural designs and losses to improve consistency. Evaluations demonstrate the effectiveness for challenging dynamic scenes.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a method to robustly reconstruct dynamic radiance fields from casual monocular videos without requiring accurate camera poses, by jointly optimizing camera poses and static and dynamic radiance fields modeled with explicit neural voxels.
