# [E2E-LOAD: End-to-End Long-form Online Action Detection](https://arxiv.org/abs/2306.07703)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we design an end-to-end framework based on Transformers to achieve both high efficiency and effectiveness for online action detection?

The key points are:

- Most prior work relies on fixed backbone networks for feature extraction, which constrains further improvements. The authors propose an end-to-end learning framework to overcome this limitation.

- They introduce novel components like a stream buffer, asymmetric spatiotemporal modeling branches, and efficient inference to balance performance and speed. 

- The overall framework aims to effectively model long-term dependencies while maintaining high computational efficiency for online processing.

In summary, the paper focuses on developing an end-to-end Transformer approach tailored for online action detection that can achieve superior accuracy and speed compared to prior feature-based methods. The core hypothesis seems to be that end-to-end training and their proposed techniques can unlock greater efficiency and effectiveness.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes E2E-LOAD, an end-to-end learning framework for online action detection (OAD) that is based on Transformers. 

2. It introduces several novel components in the architecture design:

- A Stream Buffer module that reuse computed frame features to improve efficiency. 

- An asymmetric design with separate Long-term Compression and Short-term Modeling branches to handle different lengths of historical context.

- A Long-Short-term Fusion module to integrate long-term and short-term representations.

- An Efficient Inference technique to accelerate spatiotemporal attention through token reuse.

3. Extensive experiments show E2E-LOAD achieves superior performance and efficiency compared to prior methods on three benchmark datasets, using only RGB frames as input. It obtains 17.3 FPS speed while achieving 1.2% higher mAP on THUMOS14.

4. Ablation studies validate the contribution of each proposed component. The end-to-end training framework significantly reduces memory consumption compared to prior methods.

In summary, the key contribution is an end-to-end Transformer framework for online action detection that achieves new state-of-the-art results in both accuracy and efficiency through several novel designs. The experiments comprehensively demonstrate its effectiveness.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a novel end-to-end framework called E2E-LOAD for online action detection that utilizes a shared spatial model, extended sequence caching, asymmetric spatiotemporal modeling, and an efficient inference mechanism to achieve superior efficiency and effectiveness compared to prior methods.


## How does this paper compare to other research in the same field?

 Here are a few key points comparing this paper to other research in online action detection:

- Architecture: This paper proposes an end-to-end framework with a novel stream buffer and asymmetric modeling of long-term and short-term histories. Other works rely on pre-extracted features and lightweight temporal modeling, which can limit performance. 

- Inputs: Many existing methods use optical flow as an additional input for motion modeling. This paper uses only RGB frames, making the approach more efficient.

- Performance: The experiments show this method achieves state-of-the-art results on THUMOS'14, TVSeries, and HDD datasets, outperforming prior works in accuracy and speed. For example, it obtains 72.4% mAP on THUMOS'14 at 17.3 FPS, much faster than comparable methods.

- End-to-end training: Unlike most prior works that use fixed pre-trained features, this paper demonstrates the capability to train the full model end-to-end, which helps improve accuracy.

- Long-term modeling: The long-term compression module provides an efficient way to incorporate extended historical context, which enhances detection performance compared to using only short snippets.

Overall, the key novelty of this paper is the end-to-end trainable architecture optimized specifically for online action detection. The experiments demonstrate superior accuracy and speed compared to previous state-of-the-art methods, highlighting the promise of this approach for real-time applications. The end-to-end training and long sequence modeling are particularly notable contributions.
