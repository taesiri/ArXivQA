# [Object as Query: Lifting any 2D Object Detector to 3D Detection](https://arxiv.org/abs/2301.02364)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes a new method for multi-view 3D object detection called MV2D. The main hypothesis is that exploiting 2D object detections as queries for a 3D detector can improve 3D detection performance compared to using fixed/predefined queries. 

The key research questions addressed are:

- Can generating dynamic object queries in 3D based on 2D detections provide better object location priors compared to fixed sparse queries?

- Can focusing each object query's attention on only the relevant image regions for that specific object help the query better localize the object in 3D?

- Does using object detections from a 2D detector to guide the 3D detector enable benefiting from advances in 2D detection?

To summarize, the central hypothesis is that using 2D detections to guide 3D queries can improve 3D object localization, recall, and overall detection performance. The paper explores this via the proposed MV2D framework.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. It proposes a new framework MV2D that can lift any 2D object detector to multi-view 3D object detection. This allows MV2D to leverage advances in 2D detection for 3D detection.

2. It demonstrates that using dynamic object queries conditioned on 2D detections, instead of fixed queries, improves 3D detection performance. The dynamic queries help recall objects better and provide more precise localization. 

3. It proposes a sparse cross attention module where each query only attends to relevant image features based on the 2D detection. This focuses the query on distinct object information and prevents interference from background.

4. It achieves state-of-the-art 3D detection performance on the nuScenes dataset, outperforming previous methods like DETR3D, PETR, and BEV-based methods.

5. It shows the framework can generalize to different 2D detectors like Faster R-CNN, RetinaNet, and YOLOX, highlighting its flexibility.

In summary, the key ideas are leveraging 2D detections to generate better 3D queries, attending to relevant features only, and showing strong performance and generalizability of the proposed MV2D framework. The paper demonstrates the benefit of utilizing 2D semantic information to guide 3D detection.
