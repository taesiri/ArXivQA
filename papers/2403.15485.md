# [MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression   Detection](https://arxiv.org/abs/2403.15485)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Depression is a severe mental health issue affecting many people globally. Early detection and diagnosis are crucial for effective treatment. 
- Traditional diagnosis through in-person interviews is limited due to COVID-19. Using social media for detection has gained traction.
- Prior works rely on specific features like facial expressions, limiting applicability when human faces are not visible in videos.

Proposed Solution: 
- The authors propose MOGAM, a Multimodal Object-oriented Graph Attention Model for depression detection in YouTube vlogs.

- They collect a dataset of 4767 vlogs labeled as daily, depression or high-risk depression based on clinical diagnosis.

- The model has 3 components:
   1) Object-oriented graph neural network: Detects objects in video frames and builds a graph connectivity matrix based on object co-occurrence. This captures inter-object relationships in the video.
   2) Visual features: Extracted from vlog frames using a CNN. 
   3) Metadata features: Extracted from video titles, descriptions etc. using KoBERT.

- These multimodal features are integrated via a cross-attention mechanism and used to classify if a vlog corresponds to depression or not.

Main Contributions:

- Novel object-oriented graph approach to model inter-object relationships for video understanding without reliance on human-centric cues.

- Collected reliable dataset of vlogs from users with clinical diagnosis of depression. 

- Proposed MOGAM model combining object graphs, visual and metadata features via cross-attention for robust depression detection.

- Achieved high accuracy (0.871) and F1-score (0.888) in classifying depression vlogs. Comparable performance on benchmark dataset demonstrates versatility.

- Analysis revealed differences in object distributions across mental states. Food-related objects have strong correlation.

In summary, the paper presents a novel multimodal neural architecture for depression detection in vlogs that is versatile, explainable and achieves state-of-the-art performance. The method and dataset are valuable tools for mental health assessment.
