# [Conformal Prediction in Multi-User Settings: An Evaluation](https://arxiv.org/abs/2312.05195)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper evaluates conformal prediction, a method for quantifying prediction uncertainty, in multi-user systems where data is collected from different users. Conformal models provide prediction sets rather than single predictions, with guarantees on the probability the true class is included. The authors compare performance across mixed, user-independent, user-dependent, and user-calibrated models on 4 real-world multi-user datasets, using conformal and non-conformal metrics. They propose visualizations like co-occurrence matrices and graphs to analyze prediction set patterns and relationships to non-conformal confusion matrices. Key findings are that random forests produce the smallest conformal prediction sets across models, the commonly-used mixed model overestimates performance versus a more realistic user-independent model, and calibrating with target user data, even if small in quantity, can significantly improve coverage guarantees. The paper overall advocates evaluating interactive systems using conformal prediction to provide reliability alongside accuracy.
