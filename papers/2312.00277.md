# [Text Attribute Control via Closed-Loop Disentanglement](https://arxiv.org/abs/2312.00277)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel method called Contrastive Learning Disentanglement (CLD) for controlling attributes of text while preserving content. The key idea is to disentangle text representations into separate latent spaces for content and attributes using contrastive learning. Specifically, an encoder-decoder model reconstructs the input text, and then re-encodes the reconstructed text to obtain "re-disentangled" latent representations. Contrastive losses are applied to encourage consistency between original and re-disentangled representations for unchanged attributes, while changing the representation of the attribute to be controlled. This closed-loop approach leads to better disentanglement and control compared to previous adversarial or mutual information methods. Experiments on sentiment modification in reviews and emotion transformation in text demonstrate CLD's improved performance on accuracy of attribute transfer, content preservation, and fluency. The simplicity yet effectiveness of using contrastive learning for disentanglement in a closed control loop is the key novelty and contribution. Overall, this paper presents an elegant way to achieve interpretable and controllable text generation.
