# [Towards Understanding the Capability of Large Language Models on Code   Clone Detection: A Survey](https://arxiv.org/abs/2308.01191)

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the central research question this paper aims to address is:How effective are large language models (LLMs) at detecting different types of code clones, and how can prompting strategies and code embeddings be leveraged to enhance their performance?The key hypotheses appear to be:- LLMs can leverage their natural language capabilities for code clone detection, providing a novel approach to this software engineering task.- Introducing intermediate reasoning steps through chain-of-thought prompting can improve LLM clone detection by providing a more structured thought process. - Representing code as vector embeddings enables effective clone detection, with text encoders outperforming specialized code embedding models.The authors comprehensively evaluate these hypotheses by assessing LLMs on clone detection across various dimensions like clone types, prompt formulations, multi-step reasoning, and programming languages. The goal is to gain a nuanced understanding of how prompting strategies and code representations impact LLM clone detection abilities. Their findings aim to guide future research into developing more robust LLM-based techniques for software engineering applications.In summary, this paper centers on elucidating the capabilities of LLMs for code clone detection through prompted reasoning and vector embeddings, to inform the development of enhanced LLM-based methods in this domain. The prompts, analysis, and insights presented provide a valuable benchmark for future work.
