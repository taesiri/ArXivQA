# [Do As I Can, Not As I Say: Grounding Language in Robotic Affordances](https://arxiv.org/abs/2204.01691)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we extract and leverage the knowledge encoded in large language models (LLMs) to enable robots to follow high-level, natural language instructions?

The key hypothesis is that LLMs contain a wealth of semantic knowledge about tasks and activities, but lack grounding in the physical world. By grounding the LLM's knowledge in a robot's perceptual affordances and capabilities, the robot can effectively convert high-level instructions into executable low-level actions.

Specifically, the paper proposes a method called SayCan that combines the semantic knowledge of an LLM with pretrained robotic skills and their associated value functions. The LLM scores how useful each possible skill is for the given instruction, while the value functions score how likely each skill is to succeed in the current state. Combining these scores allows the robot to choose skills that are both contextually relevant and feasible to execute.

The central hypothesis is that grounding the LLM's knowledge in this way will enable robots to follow long-horizon, abstract instructions expressed in natural language, even if the LLM alone would struggle to convert those into executable low-level actions. Experiments on real robots demonstrate that SayCan substantially outperforms non-grounded baselines, validating the importance of real-world grounding.

In summary, the key research question is how to leverage LLMs for robotic instruction following, and the core hypothesis is that grounding them in real-world affordances is critical for this task. The SayCan method provides a way to achieve such grounding.


## What is the main contribution of this paper?

 The main contribution of this paper is the proposal of SayCan, a method that enables grounding large language models in robotic agents. Specifically, the key ideas are:

- Using pretrained skills/policies for "atomic" behaviors on the robot that come with short language descriptions (e.g. "pick up the can") and value functions that can evaluate the feasibility of skills in different states. 

- Combining a large language model (LLM), which scores how useful a skill is for completing a high-level instruction, with the value functions that score how likely a skill is to succeed in the current state. This effectively grounds the LLM's knowledge in the physical world.

- Evaluating the approach on a mobile manipulator robot accomplishing long-horizon, abstract instructions in a real kitchen setting. The results demonstrate the importance of grounding for improving the performance on temporally extended tasks compared to using the LLM alone.

In summary, the key contribution is utilizing pretrained robotic skills to provide "hands and eyes" that ground a large language model's knowledge, enabling it to follow complex instructions on a real robot despite lacking physical experience itself. The paper shows this approach works significantly better than using the LLM alone.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a method called SayCan that combines large language models with pretrained robotic skills and their associated value functions to enable robots to follow complex, temporally extended instructions expressed in natural language.


## How does this paper compare to other research in the same field?

 This paper introduces SayCan, a method for grounding large language models in robotic affordances to enable robots to follow high-level natural language instructions. Here are some key ways this paper compares to related work:

- It focuses on enabling robots to follow long-horizon, abstract instructions expressed in natural language, as opposed to just short, low-level commands. This is an important direction as natural language allows more flexible and useful human-robot interaction. 

- It proposes a novel approach to extract knowledge from large language models and ground it in real-world robotic affordances. The language model provides high-level procedural knowledge, while learned value functions provide grounding for what actions are possible in the current state. 

- It demonstrates strong results on real-world robotic tasks in a kitchen environment, with a mobile robot accomplishing temporally extended instructions specified in natural language. Many prior methods have focused on simulation or more limited real-world experiments.

- It shows that grounding the language model in affordances substantially improves performance over using the language model alone. This highlights the importance of real-world grounding.

- It finds that performance scales with the size/quality of the language model, suggesting advances in language models can directly improve robotic capabilities. Most prior work has used fixed language models.

Overall, this paper makes excellent progress on enabling robots to leverage the knowledge within large language models for real-world instruction following. The ideas around affordance grounding and scale are novel and impactful compared to prior work. The real-world experiments also represent cutting-edge applications of language-conditioned robot learning.


## What future research directions do the authors suggest?

 Based on my reading of the paper, here are some of the main future research directions the authors suggest:

- Investigating how the information gained through grounding the language model via real-world robotic experience could be leveraged to improve the language model itself, both in terms of its factuality and ability to perform common-sense reasoning about real-world environments and physics.

- Examining whether natural language is the right ontology to use for programming robots, compared to other options like goal images. Natural language provides flexibility but requires more supervision.

- Extending the repertoire of low-level robotic skills that the system has available, to handle more complex instructions.

- Enabling the system to better react when individual skills fail unexpectedly, perhaps by prompting the language model to suggest corrections. 

- Exploring other ways to combine language models and robotic interaction, such as using language models for pre-training policies, incorporating planning, and leveraging other sources of grounding like human feedback.

- Applying the approach to non-robotic contexts to see if other sources of grounding could work similarly.

- Studying the limitations inherited from the underlying language models, including dependence on training data and difficulties with negation.

- Developing the interactive aspects, to enable back-and-forth dialog and clarification with users.

In summary, they suggest enhancements to the skills, language model, interactivity, and applicability to other areas as interesting future work building on their approach. The key is further integrating language with real-world physical and interactive experience.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper proposes a method called SayCan that enables robots to follow high-level, abstract instructions expressed in natural language. The key idea is to combine the knowledge and language understanding abilities of large language models (LLMs) with the real-world grounding provided by pretrained robotic manipulation skills. Specifically, the LLM is used to interpret the instruction and propose candidate low-level skills, while learned value functions for those skills determine which ones are actually feasible in the current state. By iterating this process, SayCan can decompose complex instructions into executable action sequences. The approach is evaluated on a mobile manipulator robot accomplishing long-horizon tasks described by natural language commands in a real kitchen environment. Experiments demonstrate the need for grounding the LLM using real robotic affordances, and show that performance scales with the quality of the underlying language model. Overall, the paper demonstrates an effective method for leveraging LLMs to control embodied agents in the real world.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper introduces a method called SayCan for grounding large language models (LLMs) in robotic affordances to execute complex, real-world instructions. The key idea is to combine an LLM that scores candidate skills based on their relevance to the instruction with learned value functions that score skills based on whether they can be successfully executed in the current state. Specifically, for each candidate skill, the LLM provides the probability that its textual description will help complete the instruction, while the value function provides the probability that the skill can be completed successfully. Multiplying these probabilities gives the probability that executing the skill will make progress on the instruction, allowing the robot to select the best skill to perform. This process repeats, appending the selected skill to the instruction text, until the LLM issues a termination command.

The method is evaluated on a mobile manipulator robot executing natural language instructions in an office kitchen. The robot has a set of pre-trained navigation and manipulation skills, each with a textual description, policy, and value function. Experiments across 101 long-horizon, abstract instructions, such as cleaning up a spill, demonstrate that grounding the LLM in real-world affordances substantially improves performance over non-grounded baselines. The proposed method achieves 74% end-to-end execution success. The results also show that robot performance scales with the quality of the underlying LLM, suggesting future improvements as LLMs continue to advance.


## Summarize the main method used in the paper in one paragraph.

 The paper presents SayCan, a method that enables leveraging and grounding large language models (LLMs) to complete embodied tasks on robots. The key idea is to provide real-world grounding for the LLM using pretrained robotic skills. These skills are associated with value functions that capture the probability of successful execution from a given state. To interpret a high-level natural language instruction, the LLM scores how likely each skill is to help accomplish the instruction. This language score is combined with the value function score for that skill to select the most promising skill to execute next. By iteratively selecting and executing skills in this grounded manner, the LLM's high-level knowledge can be leveraged to accomplish complex, temporally-extended instructions on a real robot. The value functions provide grounding in the physical world to make the LLM's outputs feasible, while the LLM provides high-level reasoning and knowledge. This symbiotic combination allows extracting and harnessing the knowledge within LLMs for robotic task completion.


## What problem or question is the paper addressing?

 Based on my understanding, the key problem this paper is addressing is how to leverage large language models (LLMs) to provide useful instructions and guidance to robots, while still ensuring those instructions are grounded in the physical capabilities and environment of the robot. 

Some of the key issues and questions around this problem that the paper discusses:

- LLMs contain a lot of world knowledge and semantic understanding from training on large text corpora, but they lack grounding and experience interacting in the real physical world. So their language generations may not translate well into feasible or safe actions for a robot embodiment. 

- How can we extract and harness the knowledge encoded in LLMs to enable robots to follow high-level, abstract instructions expressed in natural language?

- LLMs on their own may generate reasonable narratives for completing a task, but those narratives may not map well to the specific capabilities of a given robot or be executable in the actual environment the robot is operating in.

- Can we combine the high-level reasoning and world knowledge of LLMs with lower-level robotic skills and affordance models that are grounded in the real world?

- How can pre-trained skills provide real-world grounding to constrain the LLMs to propose feasible and contextually appropriate actions?

- Can reinforcement learning be utilized to learn "affordance functions" that quantify whether a skill can likely succeed in the current state? 

- If we have textual labels and value functions for low-level skills, can we use the LLM to score how useful those skills are for a high-level instruction, while the value functions score how feasible they are?

So in summary, the key focus is on effectively leveraging LLMs for robot instruction following, while ensuring their instructions are grounded in the physical world the robot operates in, by combining the LLM with lower-level skills and affordance models.


## What are the keywords or key terms associated with this paper?

 Based on scanning through the paper, some of the key terms and concepts that seem central to this work include:

- Large language models (LLMs) - The paper focuses on leveraging and grounding the knowledge contained in large pretrained language models like GPT-3, PaLM, etc. 

- Affordances/Affordance functions - The idea of affordances as skills or actions that are possible to execute in a given state is core. Affordance functions quantify the probability that a skill can be completed.

- Task grounding vs world grounding - The language model provides task grounding in terms ofhigh-level knowledge and instructions, while affordances provide real-world grounding of what is possible. 

- Value functions - Value functions trained with reinforcement learning are used to represent affordance functions.

- Instruction following - The goal is to follow high-level, complex instructions using the language model and affordance functions.

- Mobile manipulators - The method is evaluated on real robotic platforms combining manipulation skills and navigation.

- Prompt engineering - Prompts are designed to constrain language model outputs to useful skills and dialogue.

- Long-horizon tasks - The approach is tested on temporally extended instructions requiring many steps.

- Interpretability - The proposed method provides interpretability into the robot's step-by-step decision making process.

So in summary, key concepts revolve around grounding language models in real world robot affordances to follow instructions using learned skills and value functions. The focus is on long-horizon tasks with mobile manipulators.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to ask to create a comprehensive summary of the paper:

1. What is the key problem or research gap that the paper aims to address? 

2. What are the main contributions or innovations presented in the paper?

3. What is the proposed approach or method to address the problem? How does it work?

4. What are the key assumptions or requirements of the proposed method?

5. How was the method evaluated? What datasets or experiments were used? 

6. What were the main results of the evaluation? How does the method compare to other baselines or state-of-the-art?

7. What are the limitations of the proposed method according to the paper?

8. Does the paper discuss potential broader impacts or societal consequences of the work?

9. Does the paper identify directions for future work? What open problems remain?

10. How does this paper relate to other recent work in the field? Does it build upon or cite relevant previous research?

Asking questions that cover the key components of a research paper - including the problem statement, proposed method, experiments, results, limitations, and relation to prior work - will help generate a comprehensive summary of the paper's contributions, innovations, and remaining open issues. Focusing on the paper's own descriptions and evaluations is crucial.
