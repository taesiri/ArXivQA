# Do As I Can, Not As I Say: Grounding Language in Robotic Affordances

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we extract and leverage the knowledge encoded in large language models (LLMs) to enable robots to follow high-level, natural language instructions?The key hypothesis is that LLMs contain a wealth of semantic knowledge about tasks and activities, but lack grounding in the physical world. By grounding the LLM's knowledge in a robot's perceptual affordances and capabilities, the robot can effectively convert high-level instructions into executable low-level actions.Specifically, the paper proposes a method called SayCan that combines the semantic knowledge of an LLM with pretrained robotic skills and their associated value functions. The LLM scores how useful each possible skill is for the given instruction, while the value functions score how likely each skill is to succeed in the current state. Combining these scores allows the robot to choose skills that are both contextually relevant and feasible to execute.The central hypothesis is that grounding the LLM's knowledge in this way will enable robots to follow long-horizon, abstract instructions expressed in natural language, even if the LLM alone would struggle to convert those into executable low-level actions. Experiments on real robots demonstrate that SayCan substantially outperforms non-grounded baselines, validating the importance of real-world grounding.In summary, the key research question is how to leverage LLMs for robotic instruction following, and the core hypothesis is that grounding them in real-world affordances is critical for this task. The SayCan method provides a way to achieve such grounding.


## What is the main contribution of this paper?

The main contribution of this paper is the proposal of SayCan, a method that enables grounding large language models in robotic agents. Specifically, the key ideas are:- Using pretrained skills/policies for "atomic" behaviors on the robot that come with short language descriptions (e.g. "pick up the can") and value functions that can evaluate the feasibility of skills in different states. - Combining a large language model (LLM), which scores how useful a skill is for completing a high-level instruction, with the value functions that score how likely a skill is to succeed in the current state. This effectively grounds the LLM's knowledge in the physical world.- Evaluating the approach on a mobile manipulator robot accomplishing long-horizon, abstract instructions in a real kitchen setting. The results demonstrate the importance of grounding for improving the performance on temporally extended tasks compared to using the LLM alone.In summary, the key contribution is utilizing pretrained robotic skills to provide "hands and eyes" that ground a large language model's knowledge, enabling it to follow complex instructions on a real robot despite lacking physical experience itself. The paper shows this approach works significantly better than using the LLM alone.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a method called SayCan that combines large language models with pretrained robotic skills and their associated value functions to enable robots to follow complex, temporally extended instructions expressed in natural language.


## How does this paper compare to other research in the same field?

This paper introduces SayCan, a method for grounding large language models in robotic affordances to enable robots to follow high-level natural language instructions. Here are some key ways this paper compares to related work:- It focuses on enabling robots to follow long-horizon, abstract instructions expressed in natural language, as opposed to just short, low-level commands. This is an important direction as natural language allows more flexible and useful human-robot interaction. - It proposes a novel approach to extract knowledge from large language models and ground it in real-world robotic affordances. The language model provides high-level procedural knowledge, while learned value functions provide grounding for what actions are possible in the current state. - It demonstrates strong results on real-world robotic tasks in a kitchen environment, with a mobile robot accomplishing temporally extended instructions specified in natural language. Many prior methods have focused on simulation or more limited real-world experiments.- It shows that grounding the language model in affordances substantially improves performance over using the language model alone. This highlights the importance of real-world grounding.- It finds that performance scales with the size/quality of the language model, suggesting advances in language models can directly improve robotic capabilities. Most prior work has used fixed language models.Overall, this paper makes excellent progress on enabling robots to leverage the knowledge within large language models for real-world instruction following. The ideas around affordance grounding and scale are novel and impactful compared to prior work. The real-world experiments also represent cutting-edge applications of language-conditioned robot learning.


## What future research directions do the authors suggest?

Based on my reading of the paper, here are some of the main future research directions the authors suggest:- Investigating how the information gained through grounding the language model via real-world robotic experience could be leveraged to improve the language model itself, both in terms of its factuality and ability to perform common-sense reasoning about real-world environments and physics.- Examining whether natural language is the right ontology to use for programming robots, compared to other options like goal images. Natural language provides flexibility but requires more supervision.- Extending the repertoire of low-level robotic skills that the system has available, to handle more complex instructions.- Enabling the system to better react when individual skills fail unexpectedly, perhaps by prompting the language model to suggest corrections. - Exploring other ways to combine language models and robotic interaction, such as using language models for pre-training policies, incorporating planning, and leveraging other sources of grounding like human feedback.- Applying the approach to non-robotic contexts to see if other sources of grounding could work similarly.- Studying the limitations inherited from the underlying language models, including dependence on training data and difficulties with negation.- Developing the interactive aspects, to enable back-and-forth dialog and clarification with users.In summary, they suggest enhancements to the skills, language model, interactivity, and applicability to other areas as interesting future work building on their approach. The key is further integrating language with real-world physical and interactive experience.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper proposes a method called SayCan that enables robots to follow high-level, abstract instructions expressed in natural language. The key idea is to combine the knowledge and language understanding abilities of large language models (LLMs) with the real-world grounding provided by pretrained robotic manipulation skills. Specifically, the LLM is used to interpret the instruction and propose candidate low-level skills, while learned value functions for those skills determine which ones are actually feasible in the current state. By iterating this process, SayCan can decompose complex instructions into executable action sequences. The approach is evaluated on a mobile manipulator robot accomplishing long-horizon tasks described by natural language commands in a real kitchen environment. Experiments demonstrate the need for grounding the LLM using real robotic affordances, and show that performance scales with the quality of the underlying language model. Overall, the paper demonstrates an effective method for leveraging LLMs to control embodied agents in the real world.
