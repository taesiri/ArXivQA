# Do As I Can, Not As I Say: Grounding Language in Robotic Affordances

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we extract and leverage the knowledge encoded in large language models (LLMs) to enable robots to follow high-level, natural language instructions?The key hypothesis is that LLMs contain a wealth of semantic knowledge about tasks and activities, but lack grounding in the physical world. By grounding the LLM's knowledge in a robot's perceptual affordances and capabilities, the robot can effectively convert high-level instructions into executable low-level actions.Specifically, the paper proposes a method called SayCan that combines the semantic knowledge of an LLM with pretrained robotic skills and their associated value functions. The LLM scores how useful each possible skill is for the given instruction, while the value functions score how likely each skill is to succeed in the current state. Combining these scores allows the robot to choose skills that are both contextually relevant and feasible to execute.The central hypothesis is that grounding the LLM's knowledge in this way will enable robots to follow long-horizon, abstract instructions expressed in natural language, even if the LLM alone would struggle to convert those into executable low-level actions. Experiments on real robots demonstrate that SayCan substantially outperforms non-grounded baselines, validating the importance of real-world grounding.In summary, the key research question is how to leverage LLMs for robotic instruction following, and the core hypothesis is that grounding them in real-world affordances is critical for this task. The SayCan method provides a way to achieve such grounding.


## What is the main contribution of this paper?

The main contribution of this paper is the proposal of SayCan, a method that enables grounding large language models in robotic agents. Specifically, the key ideas are:- Using pretrained skills/policies for "atomic" behaviors on the robot that come with short language descriptions (e.g. "pick up the can") and value functions that can evaluate the feasibility of skills in different states. - Combining a large language model (LLM), which scores how useful a skill is for completing a high-level instruction, with the value functions that score how likely a skill is to succeed in the current state. This effectively grounds the LLM's knowledge in the physical world.- Evaluating the approach on a mobile manipulator robot accomplishing long-horizon, abstract instructions in a real kitchen setting. The results demonstrate the importance of grounding for improving the performance on temporally extended tasks compared to using the LLM alone.In summary, the key contribution is utilizing pretrained robotic skills to provide "hands and eyes" that ground a large language model's knowledge, enabling it to follow complex instructions on a real robot despite lacking physical experience itself. The paper shows this approach works significantly better than using the LLM alone.
