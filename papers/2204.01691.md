# [Do As I Can, Not As I Say: Grounding Language in Robotic Affordances](https://arxiv.org/abs/2204.01691)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we extract and leverage the knowledge encoded in large language models (LLMs) to enable robots to follow high-level, natural language instructions?

The key hypothesis is that LLMs contain a wealth of semantic knowledge about tasks and activities, but lack grounding in the physical world. By grounding the LLM's knowledge in a robot's perceptual affordances and capabilities, the robot can effectively convert high-level instructions into executable low-level actions.

Specifically, the paper proposes a method called SayCan that combines the semantic knowledge of an LLM with pretrained robotic skills and their associated value functions. The LLM scores how useful each possible skill is for the given instruction, while the value functions score how likely each skill is to succeed in the current state. Combining these scores allows the robot to choose skills that are both contextually relevant and feasible to execute.

The central hypothesis is that grounding the LLM's knowledge in this way will enable robots to follow long-horizon, abstract instructions expressed in natural language, even if the LLM alone would struggle to convert those into executable low-level actions. Experiments on real robots demonstrate that SayCan substantially outperforms non-grounded baselines, validating the importance of real-world grounding.

In summary, the key research question is how to leverage LLMs for robotic instruction following, and the core hypothesis is that grounding them in real-world affordances is critical for this task. The SayCan method provides a way to achieve such grounding.


## What is the main contribution of this paper?

 The main contribution of this paper is the proposal of SayCan, a method that enables grounding large language models in robotic agents. Specifically, the key ideas are:

- Using pretrained skills/policies for "atomic" behaviors on the robot that come with short language descriptions (e.g. "pick up the can") and value functions that can evaluate the feasibility of skills in different states. 

- Combining a large language model (LLM), which scores how useful a skill is for completing a high-level instruction, with the value functions that score how likely a skill is to succeed in the current state. This effectively grounds the LLM's knowledge in the physical world.

- Evaluating the approach on a mobile manipulator robot accomplishing long-horizon, abstract instructions in a real kitchen setting. The results demonstrate the importance of grounding for improving the performance on temporally extended tasks compared to using the LLM alone.

In summary, the key contribution is utilizing pretrained robotic skills to provide "hands and eyes" that ground a large language model's knowledge, enabling it to follow complex instructions on a real robot despite lacking physical experience itself. The paper shows this approach works significantly better than using the LLM alone.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a method called SayCan that combines large language models with pretrained robotic skills and their associated value functions to enable robots to follow complex, temporally extended instructions expressed in natural language.


## How does this paper compare to other research in the same field?

 This paper introduces SayCan, a method for grounding large language models in robotic affordances to enable robots to follow high-level natural language instructions. Here are some key ways this paper compares to related work:

- It focuses on enabling robots to follow long-horizon, abstract instructions expressed in natural language, as opposed to just short, low-level commands. This is an important direction as natural language allows more flexible and useful human-robot interaction. 

- It proposes a novel approach to extract knowledge from large language models and ground it in real-world robotic affordances. The language model provides high-level procedural knowledge, while learned value functions provide grounding for what actions are possible in the current state. 

- It demonstrates strong results on real-world robotic tasks in a kitchen environment, with a mobile robot accomplishing temporally extended instructions specified in natural language. Many prior methods have focused on simulation or more limited real-world experiments.

- It shows that grounding the language model in affordances substantially improves performance over using the language model alone. This highlights the importance of real-world grounding.

- It finds that performance scales with the size/quality of the language model, suggesting advances in language models can directly improve robotic capabilities. Most prior work has used fixed language models.

Overall, this paper makes excellent progress on enabling robots to leverage the knowledge within large language models for real-world instruction following. The ideas around affordance grounding and scale are novel and impactful compared to prior work. The real-world experiments also represent cutting-edge applications of language-conditioned robot learning.


## What future research directions do the authors suggest?

 Based on my reading of the paper, here are some of the main future research directions the authors suggest:

- Investigating how the information gained through grounding the language model via real-world robotic experience could be leveraged to improve the language model itself, both in terms of its factuality and ability to perform common-sense reasoning about real-world environments and physics.

- Examining whether natural language is the right ontology to use for programming robots, compared to other options like goal images. Natural language provides flexibility but requires more supervision.

- Extending the repertoire of low-level robotic skills that the system has available, to handle more complex instructions.

- Enabling the system to better react when individual skills fail unexpectedly, perhaps by prompting the language model to suggest corrections. 

- Exploring other ways to combine language models and robotic interaction, such as using language models for pre-training policies, incorporating planning, and leveraging other sources of grounding like human feedback.

- Applying the approach to non-robotic contexts to see if other sources of grounding could work similarly.

- Studying the limitations inherited from the underlying language models, including dependence on training data and difficulties with negation.

- Developing the interactive aspects, to enable back-and-forth dialog and clarification with users.

In summary, they suggest enhancements to the skills, language model, interactivity, and applicability to other areas as interesting future work building on their approach. The key is further integrating language with real-world physical and interactive experience.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper proposes a method called SayCan that enables robots to follow high-level, abstract instructions expressed in natural language. The key idea is to combine the knowledge and language understanding abilities of large language models (LLMs) with the real-world grounding provided by pretrained robotic manipulation skills. Specifically, the LLM is used to interpret the instruction and propose candidate low-level skills, while learned value functions for those skills determine which ones are actually feasible in the current state. By iterating this process, SayCan can decompose complex instructions into executable action sequences. The approach is evaluated on a mobile manipulator robot accomplishing long-horizon tasks described by natural language commands in a real kitchen environment. Experiments demonstrate the need for grounding the LLM using real robotic affordances, and show that performance scales with the quality of the underlying language model. Overall, the paper demonstrates an effective method for leveraging LLMs to control embodied agents in the real world.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper introduces a method called SayCan for grounding large language models (LLMs) in robotic affordances to execute complex, real-world instructions. The key idea is to combine an LLM that scores candidate skills based on their relevance to the instruction with learned value functions that score skills based on whether they can be successfully executed in the current state. Specifically, for each candidate skill, the LLM provides the probability that its textual description will help complete the instruction, while the value function provides the probability that the skill can be completed successfully. Multiplying these probabilities gives the probability that executing the skill will make progress on the instruction, allowing the robot to select the best skill to perform. This process repeats, appending the selected skill to the instruction text, until the LLM issues a termination command.

The method is evaluated on a mobile manipulator robot executing natural language instructions in an office kitchen. The robot has a set of pre-trained navigation and manipulation skills, each with a textual description, policy, and value function. Experiments across 101 long-horizon, abstract instructions, such as cleaning up a spill, demonstrate that grounding the LLM in real-world affordances substantially improves performance over non-grounded baselines. The proposed method achieves 74% end-to-end execution success. The results also show that robot performance scales with the quality of the underlying LLM, suggesting future improvements as LLMs continue to advance.


## Summarize the main method used in the paper in one paragraph.

 The paper presents SayCan, a method that enables leveraging and grounding large language models (LLMs) to complete embodied tasks on robots. The key idea is to provide real-world grounding for the LLM using pretrained robotic skills. These skills are associated with value functions that capture the probability of successful execution from a given state. To interpret a high-level natural language instruction, the LLM scores how likely each skill is to help accomplish the instruction. This language score is combined with the value function score for that skill to select the most promising skill to execute next. By iteratively selecting and executing skills in this grounded manner, the LLM's high-level knowledge can be leveraged to accomplish complex, temporally-extended instructions on a real robot. The value functions provide grounding in the physical world to make the LLM's outputs feasible, while the LLM provides high-level reasoning and knowledge. This symbiotic combination allows extracting and harnessing the knowledge within LLMs for robotic task completion.


## What problem or question is the paper addressing?

 Based on my understanding, the key problem this paper is addressing is how to leverage large language models (LLMs) to provide useful instructions and guidance to robots, while still ensuring those instructions are grounded in the physical capabilities and environment of the robot. 

Some of the key issues and questions around this problem that the paper discusses:

- LLMs contain a lot of world knowledge and semantic understanding from training on large text corpora, but they lack grounding and experience interacting in the real physical world. So their language generations may not translate well into feasible or safe actions for a robot embodiment. 

- How can we extract and harness the knowledge encoded in LLMs to enable robots to follow high-level, abstract instructions expressed in natural language?

- LLMs on their own may generate reasonable narratives for completing a task, but those narratives may not map well to the specific capabilities of a given robot or be executable in the actual environment the robot is operating in.

- Can we combine the high-level reasoning and world knowledge of LLMs with lower-level robotic skills and affordance models that are grounded in the real world?

- How can pre-trained skills provide real-world grounding to constrain the LLMs to propose feasible and contextually appropriate actions?

- Can reinforcement learning be utilized to learn "affordance functions" that quantify whether a skill can likely succeed in the current state? 

- If we have textual labels and value functions for low-level skills, can we use the LLM to score how useful those skills are for a high-level instruction, while the value functions score how feasible they are?

So in summary, the key focus is on effectively leveraging LLMs for robot instruction following, while ensuring their instructions are grounded in the physical world the robot operates in, by combining the LLM with lower-level skills and affordance models.


## What are the keywords or key terms associated with this paper?

 Based on scanning through the paper, some of the key terms and concepts that seem central to this work include:

- Large language models (LLMs) - The paper focuses on leveraging and grounding the knowledge contained in large pretrained language models like GPT-3, PaLM, etc. 

- Affordances/Affordance functions - The idea of affordances as skills or actions that are possible to execute in a given state is core. Affordance functions quantify the probability that a skill can be completed.

- Task grounding vs world grounding - The language model provides task grounding in terms ofhigh-level knowledge and instructions, while affordances provide real-world grounding of what is possible. 

- Value functions - Value functions trained with reinforcement learning are used to represent affordance functions.

- Instruction following - The goal is to follow high-level, complex instructions using the language model and affordance functions.

- Mobile manipulators - The method is evaluated on real robotic platforms combining manipulation skills and navigation.

- Prompt engineering - Prompts are designed to constrain language model outputs to useful skills and dialogue.

- Long-horizon tasks - The approach is tested on temporally extended instructions requiring many steps.

- Interpretability - The proposed method provides interpretability into the robot's step-by-step decision making process.

So in summary, key concepts revolve around grounding language models in real world robot affordances to follow instructions using learned skills and value functions. The focus is on long-horizon tasks with mobile manipulators.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to ask to create a comprehensive summary of the paper:

1. What is the key problem or research gap that the paper aims to address? 

2. What are the main contributions or innovations presented in the paper?

3. What is the proposed approach or method to address the problem? How does it work?

4. What are the key assumptions or requirements of the proposed method?

5. How was the method evaluated? What datasets or experiments were used? 

6. What were the main results of the evaluation? How does the method compare to other baselines or state-of-the-art?

7. What are the limitations of the proposed method according to the paper?

8. Does the paper discuss potential broader impacts or societal consequences of the work?

9. Does the paper identify directions for future work? What open problems remain?

10. How does this paper relate to other recent work in the field? Does it build upon or cite relevant previous research?

Asking questions that cover the key components of a research paper - including the problem statement, proposed method, experiments, results, limitations, and relation to prior work - will help generate a comprehensive summary of the paper's contributions, innovations, and remaining open issues. Focusing on the paper's own descriptions and evaluations is crucial.


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes combining large language models (LLMs) with pretrained robotic skills and their associated value functions to execute long-horizon, natural language instructions on a robot. How does the authors' approach for grounding LLMs in affordances compare to other methods like finetuning LLMs on interactive data or training downstream models with LLM representations? What are the tradeoffs?

2. The paper shows that performance improves when using larger LLMs like PaLM versus smaller ones like FLAN. How well does the method scale as LLMs continue to grow in size? Is there a point of diminishing returns or limitations in how much larger LLMs can improve performance on robotic instruction following?

3. The skills used in the paper seem relatively simple (pick, place, go to, etc). How does the complexity and diversity of the skill set impact the planning capabilities? Does the approach allow for hierarchical skills? 

4. The paper combines scoring and generative modes of LLMs. What are the tradeoffs of using each mode? When would one be preferred over the other? Does the type of LLM impact this choice?

5. The prompts used to constrain the LLM seem quite manually engineered. How sensitive is performance to prompt design? Can this process be automated more through meta-learning or other methods?

6. The paper uses RL to learn value functions for grounding. What other methods could provide useful affordance functions besides RL? Could simulator data help bootstrap some of this learning?

7. The approach requires pretraining skills on a particular robot morphology. How transferable are the skills and value functions to new robots with different capabilities? Does the method allow for any generalization across platforms?

8. The paper focuses on physical grounding, but does the approach allow for any generalization across environments/scenes or objects? How does the diversity of training data impact generalization?

9. The approach provides interpretable plans through natural language. How does this compare to end-to-end training that optimizes for task performance directly without explainability? What are the tradeoffs?

10. The method relies on a predefined ontology of skills. How could this approach combine high-level planning with lower-level motion planning to expand the space of possible skills? Could skills be generated procedurally instead of predefined?


## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality summary paragraph of the paper:

The paper proposes a method called SayCan that enables grounding large language models in robotic affordances to accomplish real-world, long-horizon instructions. SayCan combines probabilities from a language model, representing the usefulness of a skill for an instruction, with probabilities from a value function, representing the feasibility of executing a skill, to select skills for a robot to perform. Skills are represented as language-conditioned policies and value functions that are trained with behavioral cloning and reinforcement learning. The language model is constrained to sequences of these skills through scoring and prompt engineering. By grounding the language model in real-world affordances, SayCan is able to leverage the knowledge within large language models to complete complex, temporally extended instructions on a mobile manipulator robot in a real kitchen environment. Experiments demonstrate SayCan can accomplish multi-step instructions of 10+ primitives with an 84% planning success rate. The results also show that improvements in the underlying language model translate directly to improved robotic task planning and execution performance. Limitations of the approach include inheriting biases of the language model and being constrained by the capability of the skills. The work demonstrates an effective symbiosis between language models and real robotic systems.


## Summarize the paper in one sentence.

 The paper proposes SayCan, a method that combines large language models with learned robotic skills and their value functions to enable robots to follow long-horizon, abstract natural language instructions.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the paper:

The paper proposes SayCan, a method for grounding instructions from large language models (LLMs) in robotic affordances to enable robots to follow long-horizon, abstract instructions expressed in natural language. SayCan combines probabilities from a LLM, representing the usefulness of a skill for completing an instruction, and probabilities from learned value functions, representing the feasibility of skills, to select skills that are both useful and possible. It alternates between scoring skills with the LLM to determine what is needed and checking affordances to see what is possible. Experiments on a mobile manipulator in a real kitchen environment demonstrate that SayCan can follow temporally-extended natural language instructions through appropriate chaining of skills. It also shows improved performance from using larger LLMs and the ability to incorporate new skills. Overall, the method demonstrates an approach for extracting knowledge from LLMs in a way that is grounded for robotic control through pairing with learned affordance functions.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes combining large language models (LLMs) with pretrained robotic skills and their associated value functions to accomplish long-horizon, abstract instructions. How does encoding instructions purely with LLMs fail to provide sufficient grounding, and why are the affordances provided by value functions necessary?

2. The value functions provide grounding by scoring the feasibility of executing a particular skill in the current state. However, value functions are known to be biased estimators of true feasibility. How robust is the method to inaccuracies in the value functions? Could alternative grounding mechanisms like forward models also be used?

3. The method assumes access to a fixed set of primitive skills. How limiting is this assumption? Does the need for pretraining skills reduce the flexibility of the approach? Are there ways to acquire new skills on the fly to expand the repertoire? 

4. The factorization of the joint probability uses the naive Bayes assumption that affordance probability and LLM probability are independent. How valid is this assumption? Could dependencies between skills impact performance?

5. The LLM requires careful prompt engineering to output plans in the desired format. How sensitive is performance to the exact prompt wording? Would other techniques like demonstration learning further reduce this sensitivity?

6. The paper shows improved performance from larger LLM model size. However, larger models have also been shown to hallucinate more. How can the method be made robust to hallucinations and factual inconsistencies from the LLM?

7. The approach selects greedy actions based on the current state, without lookahead. How much would performance improve by searching over action sequences? Are there efficient search techniques compatible with the approach?

8. The method relies entirely on language for representing skills and affordances. What are the pros and cons of using language representations versus more structured representations?

9. The paper focuses on a narrow range of manipulation skills. How well would the approach extend to a more diverse set of skills and environments? What are the most limiting factors on scalability?

10. The paper proposes grounding LLMs for robotics. But the affordances provided could also potentially improve the LLMs themselves. What are some ways the interaction experience could be leveraged to improve language models?
