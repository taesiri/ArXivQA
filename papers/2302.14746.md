# [Mask3D: Pre-training 2D Vision Transformers by Learning Masked 3D Priors](https://arxiv.org/abs/2302.14746)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to effectively embed 3D priors into 2D image representations to improve performance on image understanding tasks like segmentation and detection. The key hypothesis is that pre-training a 2D vision transformer backbone on a masked 3D reconstruction task using single-view RGB-D data can teach the model useful 3D geometric priors. This pre-trained model can then be fine-tuned on downstream 2D vision tasks to achieve better performance compared to models pre-trained only on 2D image data.In summary, the main research question is: Can a self-supervised pre-training approach that reconstructs 3D structure from partial RGB-D views inject useful 3D geometric priors into a 2D vision transformer backbone to improve performance on 2D visual understanding tasks?
