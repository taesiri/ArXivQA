# Automatic Model Selection with Large Language Models for Reasoning

## What is the central research question or hypothesis that this paper addresses?

After reviewing the paper, it appears the central research question is:Can we improve reasoning performance by combining distinct reasoning methods through automatic model selection with large language models?More specifically, the key points are:- There are two effective but distinct reasoning methods: Chain-of-Thought (CoT) and Program-Aided Language Models (PAL). - CoT uses natural language while PAL uses Python code, and they have different strengths and weaknesses.- The paper proposes using a large language model (LLM) to automatically select between CoT and PAL on a per-problem basis to get the best of both methods.- Theoretically analyzes conditions for when this approach can work.- Empirically evaluates the method on 8 reasoning datasets and shows significant improvements in accuracy.So in summary, the central hypothesis is that automatically selecting between CoT and PAL with an LLM can combine their strengths and lead to better overall reasoning performance. The theoretical and empirical results support this hypothesis.


## What is the main contribution of this paper?

The main contribution of this paper appears to be proposing and demonstrating a method to combine two distinct reasoning approaches, Chain-of-Thought (CoT) and Program-Aided Language Models (PAL), by using a large language model to select the better method for each reasoning problem. Specifically, the key contributions are:- Proposing the idea of using large language models to perform automatic model selection between CoT and PAL based on their reasoning chains and results. This allows combining the strengths of both methods.- Providing a theoretical analysis on when this approach can work or fail based on the difference between the models and the success rate of model selection. The analysis shows that perfect selection is not required for improvements.- Demonstrating the effectiveness of the proposed method empirically on 8 reasoning datasets, achieving consistent performance improvements using Codex, ChatGPT and GPT-4 as the selection model.- Achieving new state-of-the-art results of 96.5% on GSM8K and 93.7% on SVAMP using the proposed model selection approach.Overall, the main contribution is a novel and effective approach for combining distinct reasoning methods using large language models for automatic model selection, supported by theoretical analysis and strong empirical results. The idea of model selection to combine complementary strengths is likely generalizable to other domains as well.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes an approach to improve reasoning performance by combining distinct methods like Chain-of-Thought and Program-Aided Language Models through model selection using large language models, achieving significant gains on multiple datasets and attaining new state-of-the-art results.
