# [OptiState: State Estimation of Legged Robots using Gated Networks with   Transformer-based Vision and Kalman Filtering](https://arxiv.org/abs/2401.16719)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: State estimation for legged robots is challenging due to their highly dynamic motion and limitations of sensor accuracy. Vision data can be unreliable due to motion blur during footsteps. Kinematic data can be error-prone due to slipping or compliant surfaces. Low computational cost is also a key requirement. Existing methods using Kalman filters, optimization, or learning alone have limitations in accuracy, generalization, or computational efficiency. 

Proposed Solution: A hybrid state estimation framework called OptiState is proposed, combining:

1) A Kalman filter using joint encoder and IMU data. It incorporates ground reaction forces from a model predictive control (MPC) optimization into its motion model predictions.

2) A gated recurrent unit (GRU) network that takes the Kalman state estimate as input over a time horizon, along with depth image features from a Vision Transformer (ViT) encoder, to refine the estimate and predict uncertainty. The GRU is trained offline using motion capture ground truth.

Main Contributions:

1) Combines strengths of model-based filtering, optimization reuse, and learning to address limitations of each method alone. Provides state estimate and uncertainty.

2) Kalman filter leverages MPC force outputs in system model. GRU considers depth image semantics and corrects for model nonlinearities.

3) Demonstrated on a quadruped performing dynamic motions on various terrains. OptiState reduces error by 65% compared to a visual-inertial odometry baseline, especially for height estimation.

In summary, a novel state estimation framework is proposed for legged robots that integrates filtering, optimization, and learning. It is more accurate and robust compared to using any one method alone, demonstrated through hardware experiments. The hybrid approach balances strengths and mitigates limitations across model-based, optimization, and data-driven techniques.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a hybrid state estimation framework for legged robots that combines a Kalman filter leveraging model predictive control outputs with a gated recurrent unit network and vision transformer encoder to correct for nonlinear errors and improve accuracy compared to visual-inertial odometry.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Combining a model-based Kalman filter with the ability to learn nonlinearities through a gated recurrent unit (GRU) neural network and vision transformer (ViT). The estimator provides both the robot's trunk state and associated predictive uncertainty.

2. For the Kalman filter, considering joint encoder and IMU measurements and reusing the control outputs from a convex model predictive control as part of the filter's system model. 

3. Demonstrating the state estimator on a quadrupedal robot in hardware on various terrains and showing a 65% improvement in root mean squared error compared to a visual-inertial odometry simultaneous localization and mapping baseline.

So in summary, the main contribution is proposing a hybrid state estimation framework that integrates Kalman filtering, optimization, and learning modalities to leverage their complementary strengths. This provides accurate state estimates for legged robots along with uncertainty evaluations.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it are:

- State estimation
- Legged robots 
- Quadrupedal robot
- Kalman filtering
- Gated Recurrent Units (GRU)
- Vision Transformer (ViT)
- Visual-Inertial Odometry (VIO) 
- Simultaneous Localization and Mapping (SLAM)
- Model Predictive Control (MPC)
- Proprioception
- Exteroception
- Depth images
- Neural networks
- Machine learning
- Root Mean Squared Error (RMSE)

The paper proposes a hybrid state estimation framework called "OptiState" that combines a Kalman filter, optimization through MPC, and learning models like a GRU and ViT. It focuses on estimating the trunk state (position, orientation, linear/angular velocity) of legged robots using proprioceptive sensors like joint encoders and IMUs along with exteroceptive information from depth cameras. The GRU network leverages outputs from the Kalman filter and ViT encoder and is shown to improve accuracy over a VIO SLAM baseline. So these are some of the main technical themes and terms associated with this work.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions employing a single-rigid body model that incorporates ground reaction force control outputs from convex Model Predictive Control (MPC) optimization. Can you explain in more detail how this MPC optimization works and how incorporating its outputs helps improve the Kalman filter state estimates? 

2. One of the key ideas in this paper is reusing control outputs like ground reaction forces from an existing controller/optimizer (MPC) to enhance the Kalman filter model. Can you think of other control outputs that could be reused in a similar way to potentially improve state estimation?

3. The Vision Transformer (ViT) autoencoder is used to encode depth images into a latent vector that is provided as input to the GRU network. What specific benefits does using a ViT provide over other encoder architectures for this application? How does it help the state estimation?

4. The paper mentions that the GRU prediction uncertainty $\mu$ can be useful for identifying instances when the Kalman filter estimate might be more reliable than the GRU output. Can you suggest other practical ways this uncertainty measure could be utilized? 

5. One limitation mentioned is that accurate global position estimate relies heavily on the motion capture system used for ground truth in training. How might you work to improve position estimate without relying as much on a limited motion capture training area?

6. How was the GRU and ViT model training schedule coordinated? Were they trained separately or jointly? What considerations went into this decision?

7. Why use a separate ViT encoder instead of just providing raw depth images as input directly into the GRU network? What are the tradeoffs?

8. Could you substitute a different learning model architecture in place of the GRU or does it provide some specific advantages? Why was GRU chosen over other sequence models?

9. The state representation uses both Euler angles and angular velocities to represent orientation and rotational motion. What are some pros and cons to this representation choice?  

10. One limitation of learned state estimation is generalizing to diverse environments. What steps could be taken to improve the ability of this method to generalize to new unseen environments?
