# [Multi-Stage Self-Supervised Learning for Graph Convolutional Networks on   Graphs with Few Labels](https://arxiv.org/abs/1902.11038)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question it addresses is: How can we improve the generalization performance of Graph Convolutional Networks (GCNs) on graphs with few labeled nodes?Specifically, the authors point out that GCNs tend to perform poorly when there are only a small number of labeled nodes in the graph, due to inefficient propagation of label information from the limited supervised signals. To tackle this problem, the paper proposes a new training algorithm called Multi-Stage Self-Supervised (M3S) Training Algorithm that combines ideas from self-supervised learning with a multi-stage training framework. The goal is to leverage unlabeled data more effectively to improve model performance when labeled data is scarce.The central hypothesis is that by using self-supervised learning techniques like DeepCluster to generate pseudo-labels for unlabeled data, and incorporating these into a multi-stage framework that gradually expands the labeled set, they can boost GCN performance on graphs with few labeled nodes compared to prior methods. The experiments aim to demonstrate the superiority of their proposed M3S algorithm in the low labeled data regime across several benchmark graph datasets.In summary, the key research question is how to improve GCN generalization on graphs with limited labeled nodes, with the central hypothesis being that a multi-stage self-supervised training approach can achieve state-of-the-art performance in this low-label setting. The paper proposes and evaluates the M3S algorithm to address this problem.
