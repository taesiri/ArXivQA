# [CKERC : Joint Large Language Models with Commonsense Knowledge for   Emotion Recognition in Conversation](https://arxiv.org/abs/2403.07260)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Emotion recognition in conversations (ERC) is challenging as it depends on dialog context, speaker identity, multi-party scenarios etc. Prior work has limitations in mining speaker information and fails to leverage commonsense knowledge that captures reactions of listeners and intentions of the speaker. 

Proposed Solution: This paper proposes CKERC, a joint framework of large language models with commonsense knowledge for ERC. It generates commonsense about potential listeners' reactions and speaker's intentions using historical utterances and LLMs. It replaces speaker identification with speaker commonsense identification to deeply explore speaker implicit information.  

Key Contributions:
- Introduces commonsense knowledge to ERC to address inadequate mining of speaker information  
- Generates speaker commonsense based on historical conversations using LLMs
- Replaces speaker identification with speaker commonsense identification and pretrains LM for this task before ERC
- Outperforms state-of-the-art methods like InstructERC on IEMOCAP, EmoryNLP and MELD datasets

In summary, this paper advances ERC by generating speaker commonsense from conversation history with LLMs and using it to enhance speaker modeling, achieving new state-of-the-art results on multiple ERC benchmarks. The introduced commonsense better captures reactions and intentions to help recognize emotions.


## Summarize the paper in one sentence.

 This paper proposes a novel framework called CKERC that jointly leverages large language models and commonsense knowledge to improve emotion recognition in conversations. Specifically, it generates speaker commonsense based on historical utterances using LLMs and introduces it to better model speakers and mine their implicit information.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Introducing commonsense knowledge to conversational emotion recognition to address the problem of inadequate implicit clue mining about speakers.

2. Generating speaker commonsense knowledge for utterances in different contexts based on historical conversations using a large language model. 

3. Achieving state-of-the-art and competitive performance on three popular datasets for the emotion recognition in conversation task.

In summary, the key contribution is using commonsense knowledge generated by a large language model from historical conversations to improve performance on emotion recognition in conversations. This helps address issues like insufficient mining of speaker information that existing methods face.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and concepts associated with it include:

- Emotion recognition in conversation (ERC) - The main task focused on in the paper, which involves predicting the emotion expressed in an utterance within the context of a conversation. 

- Commonsense knowledge - The paper proposes using commonsense knowledge about mental states, events, causal relationships etc. to better understand the emotional context.

- Large language models (LLMs) - The method uses prompts with LLMs like Llama2 to generate relevant commonsense information.

- Historical utterances - The paper generates commonsense knowledge about an utterance based on the previous context in the conversation. 

- Speaker modeling - Modeling and understanding speaker states and intentions behind utterances, not just speaker ID.

- Prompt design - Carefully designing prompts to query LLMs for desired commonsense information.

- Emotional contagion - The phenomenon of one person's emotions influencing others' emotions. Relevant to predicting listeners' reactions.

- State-of-the-art performance - The proposed CKERC method achieves new state-of-the-art results on IEMOCAP, EmoryNLP and MELD benchmark emotion recognition datasets.

In summary, the key ideas involve using commonsense knowledge and speaker modeling with large language models to advance the state-of-the-art in conversational emotion recognition.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions generating commonsense knowledge using historical utterances. Can you explain in more detail the prompt design and process used to leverage the historical utterances to generate relevant commonsense? What were some challenges faced in getting good quality commonsense generation?

2. The speaker commonsense identification task is used for pre-training the LLM before fine-tuning for ERC. Can you explain the rationale behind using this pre-training task? How does it help improve performance on the downstream ERC task? 

3. The paper uses the LLAMA-2 model for commonsense generation and LLAMA-2 is also the foundation model for the overall framework. What are some key properties and capabilities of LLAMA-2 that make it suitable for this task? Would other LLMs like GPT-3 also be appropriate?

4. Two types of commonsense are generated - potential listener's reactions and speaker's intentions. What is the relative importance of these two types for the ERC task? Are both equally useful or is one more impactful than the other?

5. The framework has two stages of training - pre-training using speaker commonsense identification and then fine-tuning for ERC. What is the benefit of having this two-stage approach? Why not directly fine-tune on the ERC task from the start?

6. How exactly is the generated commonsense incorporated into the prompt for the ERC fine-tuning stage? What modifications were made to the prompt design to accommodate the commonsense? 

7. One baseline model is InstructERC which also uses a prompt-based tuning framework. What are some key differences in prompt design between InstructERC and the proposed CKERC method?

8. The results show consistent improvements over InstructERC across 3 datasets. Is there any analysis provided on which types of conversations or emotions see the largest gains from using commonsense?

9. The framework relies extensively on carefully designed prompts for different stages. What strategies were used to create and iterate on the prompt designs? What made an effective prompt for this task?

10. The paper focuses only on conversational text. Do you think the proposed approach can be extended to a multi-modal setting with audio or visual inputs as well? Would the commonsense generation process need to be modified?
