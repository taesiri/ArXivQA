# [A&amp;B BNN: Add&amp;Bit-Operation-Only Hardware-Friendly Binary Neural Network](https://arxiv.org/abs/2403.03739)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Binary neural networks (BNNs) use 1-bit quantized weights and activations to reduce model storage and computational requirements. However, advanced BNN architectures still rely on millions of inefficient, non-hardware-friendly full-precision multiplication operations due to techniques like batch normalization, prelu activations, real-value residuals etc. This hinders their deployment on low-power edge devices.

Proposed Solution: 
The paper proposes A&B BNN, a novel BNN architecture that eliminates all multiplication operations during inference. It is based on the normalizer-free network topology and introduces two key components:

1. Removable Mask Layer: Absorbs the multiplication operations induced by variance normalization factors using mathematical transformations. Removed during inference.  

2. Quantized RPReLU: Replaces standard PReLU with a quantized version that constrains slopes to integer powers of 2, substituting multiplications with bit shift operations.

Together, these components eliminate all multiplications caused by batch norm, prelu, residuals etc. and substitute with equivalent bit operations.

Main Contributions:

- First hardware-friendly BNN that performs inference using only add and bit operations, zero multiplications.

- Reduces hardware complexity substantially - resource usage lowered by 50-100% based on FPGA synthesis results.

- Competitive accuracy - 92.3% on CIFAR10, 69.35% on CIFAR100 and 66.89% on ImageNet while removing up to 14.7M multiplications.

- Quantized RPReLU is shown to improve accuracy by 1.14% over fixed-slope activation, highlighting the impact of nonlinearity.

- Overall, the paper makes BNNs truly hardware-friendly by innovating network topology and activations, without trading off too much accuracy or adding overheads.

In summary, the paper delivers an add&bit-operation-only BNN for efficient edge deployment by creatively eliminating all multiplications from advanced architectures. The techniques open up new research directions into multiplier-less neural network design.
