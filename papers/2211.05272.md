# [GAPartNet: Cross-Category Domain-Generalizable Object Perception and   Manipulation via Generalizable and Actionable Parts](https://arxiv.org/abs/2211.05272)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to enable robots to perceive and interact with objects in a generalizable way across different object categories, including unseen categories. 

Specifically, the paper proposes learning "generalizable and actionable parts" (GAParts) as a way to achieve cross-category generalization in object perception and manipulation. The key hypothesis is that identifying parts with consistent semantics, geometry, and interaction patterns will allow developing models and policies that transfer better to novel objects compared to category-level approaches.

The main contributions to test this hypothesis are:

- Proposing the concept of GAParts and defining 9 common GAPart classes with consistent semantics and actionability across objects.

- Constructing a large-scale dataset called GAPartNet with semantic and pose labels for GAParts across 27 object categories.

- Developing a method for cross-category 3D part segmentation and pose estimation by learning domain-invariant features via adversarial training.

- Showing that simple heuristics based on estimated GAPart poses enable manipulating unseen object categories in simulation and real-world.

So in summary, the central hypothesis is that a focus on GAParts can enable more generalizable object perception and manipulation. The paper aims to demonstrate this through dataset construction, new technical approaches for part-based vision and interaction, and applications to cross-category tasks.
