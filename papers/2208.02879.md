# [PointConvFormer: Revenge of the Point-based Convolution](https://arxiv.org/abs/2208.02879)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes a novel building block called PointConvFormer for deep neural networks that process 3D point clouds. The central hypothesis is that using attention computed from feature differences to modify convolutional weights in local neighborhoods can help select more relevant points and improve generalization of point convolutional networks. 

The key research questions addressed are:

1) Can attention computed from feature differences help select better local neighborhoods and improve generalization for point convolutions? 

2) Does combining ideas from point convolution and transformers lead to better performance on point cloud tasks compared to using either one alone?

3) Can PointConvFormer provide a better accuracy-efficiency tradeoff compared to sparse convolutional approaches for point cloud tasks requiring point-level details like segmentation and scene flow?

The paper validates the PointConvFormer design through extensive experiments on semantic segmentation and scene flow estimation tasks using multiple datasets. The results demonstrate superior accuracy and efficiency over regular convolutions, transformers and sparse convolution approaches, supporting the core hypothesis.


## What is the main contribution of this paper?

 The main contribution of this paper is the proposal of a novel building block called PointConvFormer for deep neural networks that process 3D point clouds. PointConvFormer combines ideas from point convolution and Transformers to improve the generalization capability and robustness of point-based models. Specifically:

- It introduces an attention mechanism computed from feature differences to reweight points in a local neighborhood for convolution. This allows selecting only relevant points and filtering out noise/outliers. 

- It preserves the invariances from point convolution by keeping the positional encoding outside of the attention module. This helps with out-of-sample generalization.

- It combines both positive and negative contributions from neighbors through convolution instead of the non-negative softmax attention used in Transformers.

- It is more lightweight than voxel-based approaches and previous point cloud Transformers.

The paper shows through experiments on semantic segmentation and scene flow estimation tasks that PointConvFormer achieves state-of-the-art accuracy and efficiency tradeoffs compared to previous point-based and voxel-based methods. It demonstrates the potential of PointConvFormer as a powerful building block for point cloud processing tasks requiring point-level details.

In summary, the main contribution is a novel point cloud block that adaptively aggregates local neighborhoods using both position and feature information, outperforming regular convolution and Transformers, while preserving the benefits of both.


## How does this paper compare to other research in the same field?

 Based on my reading, this paper makes several notable contributions when compared to other research on point cloud processing:

1. It proposes PointConvFormer, a new building block for point cloud networks that combines ideas from point convolutions and transformers. This is a novel approach compared to prior work like PointNet, PointConv, voxel-based methods, etc. that focused more purely on one paradigm or the other. 

2. PointConvFormer shows strong performance on semantic segmentation and scene flow estimation tasks. The results in Tables 1-3 demonstrate state-of-the-art or competitive accuracy compared to other point-based and voxel-based methods on the ScanNet, SemanticKITTI, FlyingThings3D, and KITTI datasets. 

3. The ablation studies provide insights into design choices like attention types, number of heads, etc. This helps advance understanding of what works well for point cloud processing beyond standard convolutions or transformers.

4. The visualizations in Figures 1 and 4 show qualitatively how PointConvFormer is able to combine the strengths of convolution and attention. It behaves similarly to convolution in flat areas but shows a stronger neighborhood selection effect near object boundaries.

5. The paper shows point-based methods can compete with or surpass sparse convolutional approaches on dense prediction tasks. This helps make the case that point-based models warrant more exploration as an efficient alternative to voxel-based networks.

Overall, by demonstrating a new building block, strong results across multiple datasets, design insights, qualitative analysis, and potential as an alternative to sparse convolutions, this paper makes several valuable additions compared to prior work on point cloud processing and 3D deep learning. The introduction of PointConvFormer and analysis around it helps advance the state of this research area.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper introduces PointConvFormer, a new building block for deep learning on point clouds that combines point convolution and transformer-style attention mechanisms, and shows it achieves state-of-the-art performance on semantic segmentation and scene flow estimation tasks while being efficient.
