# [PointConvFormer: Revenge of the Point-based Convolution](https://arxiv.org/abs/2208.02879)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes a novel building block called PointConvFormer for deep neural networks that process 3D point clouds. The central hypothesis is that using attention computed from feature differences to modify convolutional weights in local neighborhoods can help select more relevant points and improve generalization of point convolutional networks. 

The key research questions addressed are:

1) Can attention computed from feature differences help select better local neighborhoods and improve generalization for point convolutions? 

2) Does combining ideas from point convolution and transformers lead to better performance on point cloud tasks compared to using either one alone?

3) Can PointConvFormer provide a better accuracy-efficiency tradeoff compared to sparse convolutional approaches for point cloud tasks requiring point-level details like segmentation and scene flow?

The paper validates the PointConvFormer design through extensive experiments on semantic segmentation and scene flow estimation tasks using multiple datasets. The results demonstrate superior accuracy and efficiency over regular convolutions, transformers and sparse convolution approaches, supporting the core hypothesis.


## What is the main contribution of this paper?

 The main contribution of this paper is the proposal of a novel building block called PointConvFormer for deep neural networks that process 3D point clouds. PointConvFormer combines ideas from point convolution and Transformers to improve the generalization capability and robustness of point-based models. Specifically:

- It introduces an attention mechanism computed from feature differences to reweight points in a local neighborhood for convolution. This allows selecting only relevant points and filtering out noise/outliers. 

- It preserves the invariances from point convolution by keeping the positional encoding outside of the attention module. This helps with out-of-sample generalization.

- It combines both positive and negative contributions from neighbors through convolution instead of the non-negative softmax attention used in Transformers.

- It is more lightweight than voxel-based approaches and previous point cloud Transformers.

The paper shows through experiments on semantic segmentation and scene flow estimation tasks that PointConvFormer achieves state-of-the-art accuracy and efficiency tradeoffs compared to previous point-based and voxel-based methods. It demonstrates the potential of PointConvFormer as a powerful building block for point cloud processing tasks requiring point-level details.

In summary, the main contribution is a novel point cloud block that adaptively aggregates local neighborhoods using both position and feature information, outperforming regular convolution and Transformers, while preserving the benefits of both.
