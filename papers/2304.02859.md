# [MULLER: Multilayer Laplacian Resizer for Vision](https://arxiv.org/abs/2304.02859)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research question this paper seems to address is:Can a simple, lightweight learned image resizer improve the performance of deep vision models across various tasks with little to no extra training cost?The authors propose a resizer called MULLER (Multilayer Laplacian Resizer) that operates by enhancing details in certain frequency subbands of the input image. The key aspects are:- MULLER is extremely lightweight, requiring only 4 trainable parameters. This makes it very efficient with negligible training overhead.- It learns to boost certain details/textures that are useful for downstream vision tasks. This is done via a Laplacian pyramid decomposition.- MULLER can simply replace default resizers like bilinear without re-training the full vision model.The authors demonstrate that plugging in MULLER consistently improves performance across tasks like image classification, object detection, segmentation and image quality assessment. For example, it pushes the state-of-the-art MaxViT image classifier to achieve higher accuracy with lower latency.So in summary, the central hypothesis is that a tiny learned resizer can universally improve vision models, if designed properly to enhance task-useful frequencies. The paper seems to validate this hypothesis through extensive experiments using MULLER.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing MULLER, an extremely lightweight learned image resizer using multilayer Laplacian decomposition. MULLER has only 4 trainable parameters and minimal computational overhead.- Demonstrating that MULLER can be easily integrated into various computer vision models and tasks as a drop-in replacement for standard resizing operations like bilinear interpolation. Experiments show consistent performance improvements across image classification, object detection, segmentation, and image quality assessment.- Showing that MULLER effectively boosts details and textures in images to make them more machine-friendly for downstream vision models, while also remaining highly perceptible for humans. This is attributed to the bandpass nature and strong regularization of the Laplacian filtering structure.- Highlighting that MULLER can push forward state-of-the-art vision Transformers like MaxViT to achieve better accuracy-computation tradeoffs. For example, with MaxViT, MULLER gains 0.6% ImageNet top-1 accuracy with 36% inference cost saving.- Demonstrating MULLER's superior parameter efficiency, transferability, and scalability over previous learned resizers, owing to its simplicity and minimal design. MULLER performs on par or better than heavier models while being 100x faster.In summary, the main contribution is proposing an extremely fast and simple learned resizer using multilayer Laplacian decomposition that boosts vision model performance across tasks with negligible overhead. The efficiency, generalizability and interpretability of MULLER are noteworthy.
