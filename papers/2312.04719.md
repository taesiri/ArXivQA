# [Distributed Optimization via Kernelized Multi-armed Bandits](https://arxiv.org/abs/2312.04719)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem Formulation:
The paper considers the problem of distributed optimization over a network of agents. Specifically, the aim is to maximize a global objective function $F(x)$ which is the average of local objective functions $f_i(x)$ associated with each agent $i$. The functions $f_i(x)$ are unknown, non-convex and agents can only obtain noisy observations by evaluating them. The problem is framed as a multi-agent multi-armed bandit problem, where each possible input $x$ can be viewed as an arm. The sequential decision-making aspect is captured using the notion of cumulative regret, which measures the loss in global objective value over time steps. 

Proposed Solution:
The paper proposes two decentralized bandit algorithms - MA-IGP-UCB and MAD-IGP-UCB. The core ideas are:
(1) Agents maintain estimates of the mean $\overline{\mu}(x)$ and variance $\overline{\sigma}^2(x)$ for the global function $F(x)$, not just their local $f_i(x)$. 
(2) These estimates are updated using a distributed consensus approach along with new observations of the local functions. Specifically, each agent updates its estimates by combining its local measurement and neighbors' prior estimates.
(3) An upper confidence bound (UCB) $\overline{\mu}(x) + \beta\overline{\sigma}(x)$ is constructed and optimized to select the next sample point $x$. As estimates improve over time, agents will start exploiting near the global optimum.

The MA-IGP-UCB algorithm achieves a per agent regret bound of $\mathcal{O}(N^2\sqrt{T})$, which is improved to $\mathcal{O}(\sqrt{T})$ by MAD-IGP-UCB using delayed estimates to allow better consensus per stage. The algorithms preserve privacy as agents don't share raw observations or function estimates.

Main Contributions:
- Novel problem formulation for distributed optimization of unknown non-convex functions as a multi-agent bandit problem 
- Decentralized bandit algorithms for maximizing average of functions, analyzed under reproducible kernel Hilbert space assumptions
- Regret analysis proving sub-linear growth, capturing impact of network connectivity 
- Demonstrated superiority over independent learning through numerical experiments
