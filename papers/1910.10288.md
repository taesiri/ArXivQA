# [Location-Relative Attention Mechanisms For Robust Long-Form Speech   Synthesis](https://arxiv.org/abs/1910.10288)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research question is:

How do different types of attention mechanisms compare in terms of alignment speed, consistency, naturalness, and ability to generalize to long utterances in text-to-speech synthesis systems?

The paper specifically compares content-based, hybrid location-sensitive, and purely location-relative attention mechanisms from two families - additive energy-based mechanisms and GMM-based mechanisms. The goal is to evaluate which type of attention mechanism works best for robust long-form speech synthesis.

The central hypothesis seems to be that purely location-relative attention mechanisms that do not rely on content-based query/key matching will align more quickly during training, be more consistent, achieve better naturalness on in-domain data, and generalize better to long utterances outside the training distribution compared to content-based or hybrid mechanisms.

In essence, the paper is evaluating different attention mechanism designs for end-to-end TTS to find the most effective one for producing natural, robust synthesis for long-form speech. The location-relative mechanisms are hypothesized to perform the best on these criteria.
