# [An open dataset for the evolution of oracle bone characters: EVOBC](https://arxiv.org/abs/2401.12467)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Oracle bone script is the ancestor of modern Chinese characters, with over 4,500 characters discovered, but only about 1,600 have been deciphered so far. Further research is needed to understand this ancient writing system.
- Lack of datasets mapping the evolution of oracle bone characters over history hinders the application of AI to decipher them. 

Proposed Solution:
- Construct a large-scale dataset called EVOBC tracing the evolution of Chinese characters across 6 historical stages: Oracle Bone (OBC), Bronze Inscriptions (BI), Seal Script (SS), Spring & Autumn (SAC), Warring States (WSC), and Clerical Script (CS).

- Automatically extract labeled image samples of ancient scripts from books and websites. Apply specialized pipelines tailored to different sources.  

- Dataset contains 229,170 images in 13,714 categories, sourced from authoritative books and large online repositories.

- Validate dataset quality through image classification and oracle bone character deciphering simulation tasks. 

Main Contributions:
- First dataset to digitize the evolution of Chinese characters over different historical stages in a unified framework.

- Systematic methodology to automatically construct large-scale dataset from diverse sources.

- Valuable resource to facilitate AI-assisted deciphering of oracle bone script by examining glyph form changes over time.

- Strong performance in technical validation experiments demonstrates high potential and quality of dataset.

- Establishes benchmark for future computational research on oracle bone character evolution.

In summary, the paper has proposed an extensive dataset tracing Chinese character evolution to enable AI-assisted deciphering of ancient oracle bone script. Both the dataset construction process and promising validation results showcase its reliability and usefulness.


## Summarize the paper in one sentence.

 This paper introduces EVOBC, an extensive dataset tracing the evolution of Chinese characters across six historical periods from oracle bone script to clerical script, comprising over 200k images across 13k categories to facilitate computer-assisted deciphering of ancient oracle bone inscriptions.


## What is the main contribution of this paper?

 Based on the content provided, the main contribution of this paper is the construction of an extensive dataset called EVOBC (Evolution of Oracle Bone Characters) for tracing the evolution of ancient Chinese characters across different historical periods. Specifically:

- The paper collects 229,170 images across 13,714 categories representing Chinese characters from 6 key historical stages: Oracle Bone Characters, Bronze Inscriptions, Seal Script, Spring & Autumn period Characters, Warring States period Characters, and Clerical Script.

- The images are sourced from authoritative books on ancient Chinese scripts as well as large online repositories. An automated pipeline is developed to extract and align the images from these diverse sources.

- The constructed dataset aims to facilitate computer-assisted deciphering of the yet uninterpreted Oracle Bone script by providing the evolutionary trajectory of ancient glyphs over time. 

- Technical validation experiments like image classification and oracle bone character deciphering simulation are performed on the dataset, demonstrating its utility and quality for future AI-assisted research on oracle bone scripts.

In summary, the key contribution is the introduction of the systematically constructed EVOBC dataset spanning the evolution of Chinese characters across several historical eras, which can aid in deciphering the ancient Oracle Bone script using AI methods.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and keywords associated with this paper include:

- Oracle bone script/characters: The ancient Chinese writing system used during the Shang dynasty that this paper focuses on digitizing and tracing the evolution of.

- Evolution dataset: The dataset constructed in this paper, EVOBC, that maps the evolution of Chinese characters across 6 historical stages from oracle bone script to clerical script.

- Digitalization: The process used to extract and format images of ancient texts from books and websites to build the EVOBC dataset.

- Image classification: One of the technical validation tasks used to evaluate the quality of the EVOBC dataset by training models to categorize the ancient character images.

- Deciphering simulation: The other validation task that tests using AI models to uncover meanings and find connections between undeciphered oracle bone script and later evolved character forms.

- Glyphs: The visual symbolic representations that make up writing systems and scripts.

Some other potentially relevant terms based on a skim of the content are artifact images, character annotations, conditioned diffusion model, and grammatology. Let me know if you need any clarification or have additional questions!


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions using an automated pipeline for extracting images and labels from diverse sources. Could you elaborate on the specifics of how you handled variation in layouts across different source books/websites to enable automated extraction? What were some key challenges faced?

2. In the book image extraction process, you mention using an OCR system for recognizing the header information to assign category labels to slices. What OCR architecture did you use? Did you need to fine-tune it for ancient Chinese scripts or could an off-the-shelf model handle it? 

3. The Iterative Merging of Nearest Neighbor Boxes (IMNNB) algorithm seems critical for separating ancient character images from backgrounds in book sources. Could you walk through the details of how you devised this method? What design considerations guided the merging criteria?  

4. You standardized the dataset's background, unified category labels, and imposed a naming convention. What tools/techniques did you use to handle these formatting tasks programmatically? Did you need any manual review after automation?

5. The dataset contains both simplified and traditional Chinese annotations. What conversion table or tools did you use to eliminate redundant categories across these two scripts? Did this lead to any potential issues?

6. What were some unique challenges in extracting Seal Script images from online repositories compared to other eras' texts? Did seal scripts require specialized handling in the pipeline?

7. Could you discuss the rationale behind choosing ResNet-101 and Swin Transformer for classification? What unique advantages did they offer over other architectures? Did you experiment with others?

8. The oracle bone character deciphering simulation task is highly novel. Could you expand on what inspired this direction and why image classification and generation are promising approaches?  

9. For the image classification deciphering approach, how did you design the training to teach associations between oracle bone and other eras' scripts? What loss functions or other tricks were used?

10. Qualitative results of the diffusion model show some promising translations. But could you quantify how accurately it learns to transform oracle bone images today? Any idea on paths to improve it?
