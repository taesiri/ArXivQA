# [Beyond the Pixel: a Photometrically Calibrated HDR Dataset for Luminance   and Color Prediction](https://arxiv.org/abs/2304.12372)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the main contributions of this paper are:

1. Introducing the Laval Photometric Indoor HDR Dataset, which is the first large-scale photometrically calibrated dataset of high dynamic range 360° panoramas for indoor scenes. 

2. The key idea is to take an existing uncalibrated HDR dataset and carefully calibrate it using simultaneous measurements with a professional photometric device (chroma meter) to determine per-channel correction factors. This results in a rich representation of indoor scenes with accurate luminance and color values.

3. Proposing and analyzing three novel computer vision tasks enabled by the dataset: 

- Per-pixel luminance prediction to recover the absolute luminance value at each pixel from a single input image

- Per-pixel color prediction to estimate the correlated color temperature (CCT) at each pixel

- Planar illuminance prediction to predict the total light incident on a plane, which could have applications like image relighting 

4. Studying the impact of various degradations to the input image (noise, tone-mapping, etc.) on the performance of these tasks.

5. Capturing a smaller photometric dataset using a commercial 360° camera to analyze generalization across cameras. 

So in summary, the main research contributions are introducing a novel photometrically calibrated HDR dataset, proposing new physically-based vision tasks enabled by it, and analyzing the challenges and requirements for performing accurate light estimation from images. The overall goal is to bridge the gap between predicted pixel values and real-world luminance/color measurements.


## What is the main contribution of this paper?

 The main contribution of this paper is introducing the Laval Photometric Indoor HDR Dataset, which is a large-scale dataset of high dynamic range 360° panoramas with photometric calibration. 

Specifically, the key contributions are:

- Photometrically calibrating an existing uncalibrated HDR indoor panorama dataset by capturing RAW bracketed exposures simultaneously with a professional photometric measurement device. This establishes the per-channel correction factors needed to convert the HDR images to absolute luminance and color values.

- Analyzing the resulting calibrated dataset to show it captures a wide range of illuminance levels (0-7000 lux) and color temperatures (2000-8000K), representing the diversity of real-world indoor lighting.

- Proposing three novel tasks enabled by the dataset: predicting per-pixel luminance, per-pixel color, and planar illuminance from a single input image. Baseline experiments are presented for these tasks.

- Capturing a smaller photometric dataset using a commercial 360° camera to study generalization across cameras.

Overall, the calibrated dataset along with the introduced tasks represent an important step towards physically-based vision and recovering photometric quantities from real images. The public release of the datasets and code will help advance research in this direction.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper introduces the Laval Photometric Indoor HDR Dataset, the first large-scale photometrically calibrated dataset of high dynamic range 360° panoramas, which enables novel computer vision tasks involving accurate prediction of luminance, color, and illuminance from images.


## How does this paper compare to other research in the same field?

 This paper presents the Laval Photometric Indoor HDR Dataset, which provides photometrically calibrated high dynamic range (HDR) panoramic images capturing a diverse set of indoor scenes. This enables several novel tasks like estimating per-pixel luminance, color, and planar illuminance from single view images. Here are some key ways this work compares to prior research:

- Dataset scale and diversity: At over 2300 panoramic images, this is the first large-scale dataset with photometric calibration. The scenes exhibit a wide range of luminance, correlated color temperature, and light source types. This is a significant extension of prior small-scale photometric datasets.

- Tasks enabled: The authors introduce new self-supervised training tasks like luminance, color, and planar illuminance prediction that are enabled by the photometric ground truth. This moves beyond classical vision tasks like recognition to physically-grounded ones. 

- Studying generalization: The paper investigates how photometric predictions generalize to images from unseen camera hardware. This analysis of model robustness is still relatively rare in vision datasets/benchmarks.

- Methodology: The photometric calibration process builds on prior work, but is more meticulous by using raw images and multiple camera configurations. This yields low uncertainty in the recovered luminance values.

Overall, this paper makes a valuable contribution in terms of dataset scale/diversity, introducing novel tasks and analysis, and meticulous methodology. The resulting dataset and tasks could catalyze more research at the intersection of computer vision, computational photography, and physicallly-based scene understanding.
