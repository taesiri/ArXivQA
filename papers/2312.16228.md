# [Deformable Audio Transformer for Audio Event Detection](https://arxiv.org/abs/2312.16228)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Transformers have shown great potential for audio and speech recognition tasks. However, the quadratic complexity of self-attention limits their application, especially on edge devices with limited compute resources. 
- Existing efficient Transformer designs use hand-crafted attention patterns which are data-agnostic. This may drop relevant keys/values while preserving less useful ones.

Proposed Solution:
- The paper proposes a novel Deformable Audio Transformer (DATAR) which uses a learnable attention pattern.
- It introduces a deformable attention module which flexibly generates important key/value points conditioned on the input audio query. This attends to more useful regions and is more computationally efficient.
- An Audio Offset Generator (AOG) network takes query features as input and outputs offsets to shift keys/values to important regions. 
- A learnable input adaptor is further introduced which adds signals to the input spectrogram. This makes important parts more distinguishable, improving deformable attention.

Main Contributions:
- Proposes DATAR - first work to apply deformable attention to audio classification Transformers. This flexibly focuses computations on informative regions.
- Introduces an AOG subnetwork to learn query-conditioned offsets for deformable attention.
- Proposes a learnable input adaptor module to enhance spectrogram signals fed to deformable attention.
- Achieves new state-of-the-art on Kinetics-Sounds, Epic-Kitchens and VGGSound datasets. Outperforms previous best methods substantially.

In summary, the paper makes significant contributions through its novel application of deformable attention to audio Transformers. The learnable offset generation and input enhancement allow focusing on salient regions for efficiency and accuracy.
