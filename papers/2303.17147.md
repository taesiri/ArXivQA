# [NeILF++: Inter-Reflectable Light Fields for Geometry and Material   Estimation](https://arxiv.org/abs/2303.17147)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research focus of this paper is on joint optimization of scene geometry, material properties, and lighting from multi-view images. 

Specifically, the paper proposes representing the lighting using both an incident light field that models incoming light, as well as an outgoing radiance field that models surface appearance. The key insight is that combining these two representations of the lighting through physics-based rendering and inter-reflections between surfaces allows jointly optimizing the geometry, materials, and lighting in a differentiable manner. 

The central hypothesis is that modeling both incoming and outgoing light in this way will enable disentangling the geometry, materials, and lighting of a scene from just multi-view images. This in turn can enable relighting applications as well as improve reconstruction quality compared to methods that use just a single lighting representation.

The experiments aim to validate whether the proposed joint optimization approach leads to better performance on tasks like geometry reconstruction, material estimation, and novel view synthesis compared to previous methods. The introduction of a real-world HDR dataset is also intended to better evaluate material estimation performance.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a novel differentiable rendering framework for joint geometry, material, and lighting estimation from multi-view images. 

2. It formulates an omnidirectional light field consisting of both incident and outgoing light fields. The key insight is unifying the two through physically-based rendering and inter-reflections between surfaces.

3. It presents an optimization scheme for joint optimization of geometry (signed distance field), material (BRDF parameters), incident lighting, and outgoing radiance. The framework can refine neural surfaces and estimate materials.

4. It constructs a real-world linear HDR dataset called NeILF-HDR to facilitate material estimation in the right color space.

5. Extensive experiments show the method achieves state-of-the-art in terms of geometry accuracy, material estimation, and novel view synthesis compared to previous methods.

In summary, the key contribution is proposing a general light field formulation by combining incident and outgoing light fields, which enables joint optimization of geometry and materials for 3D reconstruction. The method is shown to outperform previous techniques on various metrics.
