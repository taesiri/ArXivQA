# [Towards Human-Like Machine Comprehension: Few-Shot Relational Learning   in Visually-Rich Documents](https://arxiv.org/abs/2403.15765)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Few-shot relational learning in visually-rich documents (VRDs) is still a relatively unexplored research area. Existing models struggle to leverage layout features effectively in few-shot scenarios and learn high-dimensional class-agnostic features that can generalize across different contexts. 

- There is currently no suitable dataset for evaluating few-shot relational learning in VRDs. Most existing benchmarks focus on sentence-level relation extraction using only text, which is far from real-world document applications.

Methodology:
- The paper introduces two new few-shot VRD datasets, Few-CORD and Few-SEAB, converted from existing VRD datasets, CORD and SEAB.

- A novel variational approach is proposed that incorporates spatial priors and prototypical rectification techniques to enhance few-shot learning:

  - Spatial priors: Predict regions of interest (ROIs) containing key-value entities using layout features. This guides attention and encodes spatial context.

  - Prototypical rectification: Capture class distribution information to obtain robust class prototypes that are insensitive to variance in limited support examples.

- The overall architecture comprises ROI regression, prototypical rectification and proximity-based classification components built upon LayoutLM/LayoutLMv2 backbones.

Contributions:
- First work to address few-shot relational learning in visually-rich documents and introduce suitable benchmarks for this task.

- Novel variational approach that incorporates spatial priors and robust prototypical learning to enhance few-shot performance.

- Extensive experiments demonstrate state-of-the-art results on the new benchmarks, highlighting the efficacy of the proposed techniques.

- Opens up new research directions in adapting document AI models to unseen contexts with limited supervision.
