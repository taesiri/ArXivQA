# [Is GPT-3 all you need for Visual Question Answering in Cultural   Heritage?](https://arxiv.org/abs/2207.12101)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is:Can GPT-3 be used to automatically generate textual descriptions of artworks that can then be exploited to answer visual and contextual questions about those artworks, avoiding the need for manually annotated image captions?In particular, the key points the paper investigates are:- Whether GPT-3 can generate high quality textual descriptions of artworks when prompted with just the name of the artwork.- Whether these automatically generated descriptions can be used in place of human-annotated captions to answer visual and contextual questions about artworks through a question answering system. - Comparing different prompting strategies for GPT-3 - using a general prompt to elicit a long description versus using the question itself as the prompt to generate a more focused description.- Evaluating the quality of the generated captions using standard image captioning metrics.- Evaluating the ability to answer visual and contextual questions about artworks using the GPT-3 generated captions on a visual question answering dataset.So in summary, the central hypothesis is that GPT-3 can automatically produce usable descriptions of artworks for the task of visual question answering, removing the need for manual annotation. The experiments aim to validate whether this hypothesis holds true.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method for visual question answering in cultural heritage that relies on using GPT-3 to automatically generate descriptions of artworks. This allows answering visual and contextual questions without needing annotated image-description pairs for each artwork. Specifically, the key contributions are:- Proposing to use GPT-3 to generate descriptions of artworks that can capture both visual and contextual knowledge. This avoids the need for manual annotation by experts.- Showing that the generated descriptions can be used with a question answering model to answer visual and contextual questions about artworks. This makes the approach artwork-agnostic.- Demonstrating the applicability of large generative language models like GPT-3 for cultural heritage applications, specifically for visual question answering. - Providing an analysis of using general vs question-based prompts with GPT-3, showing their tradeoffs. General prompts give longer, more comprehensive descriptions while question-based give more focused descriptions.- Overall, showing that GPT-3 can generate high quality descriptions of artworks that allow answering questions without needing artwork-specific training data. This could enable scalable visual question answering for cultural heritage.
