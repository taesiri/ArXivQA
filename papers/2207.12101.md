# [Is GPT-3 all you need for Visual Question Answering in Cultural   Heritage?](https://arxiv.org/abs/2207.12101)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is:Can GPT-3 be used to automatically generate textual descriptions of artworks that can then be exploited to answer visual and contextual questions about those artworks, avoiding the need for manually annotated image captions?In particular, the key points the paper investigates are:- Whether GPT-3 can generate high quality textual descriptions of artworks when prompted with just the name of the artwork.- Whether these automatically generated descriptions can be used in place of human-annotated captions to answer visual and contextual questions about artworks through a question answering system. - Comparing different prompting strategies for GPT-3 - using a general prompt to elicit a long description versus using the question itself as the prompt to generate a more focused description.- Evaluating the quality of the generated captions using standard image captioning metrics.- Evaluating the ability to answer visual and contextual questions about artworks using the GPT-3 generated captions on a visual question answering dataset.So in summary, the central hypothesis is that GPT-3 can automatically produce usable descriptions of artworks for the task of visual question answering, removing the need for manual annotation. The experiments aim to validate whether this hypothesis holds true.
