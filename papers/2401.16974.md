# [CORE: Towards Scalable and Efficient Causal Discovery with Reinforcement   Learning](https://arxiv.org/abs/2401.16974)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Causal discovery (CD) aims to uncover causal relationships from observational and interventional data. While passive observation is often insufficient, interventions allow distinguishing causation from correlation. However, current CD methods face challenges in scalability, generalization, and planning informative interventions. 

Proposed Solution:
The paper proposes CORE, a deep reinforcement learning (RL) based approach to causal discovery. CORE learns a policy to sequentially reconstruct causal graphs by performing interventions and structure updates.

Key Ideas and Contributions:

1. Formulates CD through interventions as a partially observable Markov decision process (POMDP) to leverage RL.

2. Proposes a dual Q-learning setup with separate networks for recommending interventions and structural updates. Rewards informative interventions that improve structure estimates.

3. Demonstrates CORE generalizes to unseen causal graphs of up to 10 variables. Outperforms state-of-the-art method MCD in accuracy and scales further.  

4. Highlights the importance of jointly learning intervention and estimation policies. Random interventions degrade performance.

5. Discusses limitations in real-world applicability due to simplicity of training distributions and hardness of generalizing across function classes.

In summary, the paper makes a case for using RL to tackle causal discovery in an active learning setup. By learning to recommend interventions and estimate structures jointly, CORE advances state-of-the-art in accuracy, scalability and sample efficiency. The discussions also outline meaningful directions for improving real-world viability.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper introduces CORE, a deep reinforcement learning approach for causal discovery that learns to sequentially reconstruct causal graphs from data while actively planning informative interventions, demonstrating improved performance in terms of estimation accuracy and scalability over prior methods.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It formalizes the task of learning a causal discovery (CD) algorithm as a partially observable Markov decision process (POMDP). This allows bringing reinforcement learning techniques for this task.

2. It proposes a dual Q-learning setup called CORE to learn intervention design and structure estimation simultaneously. Specifically, it trains two Q-networks, one for selecting interventions and one for structural updates.

3. It demonstrates that CORE can successfully learn a CD algorithm that generalizes to unseen causal graphs of up to 10 variables in size. This is a step forward compared to prior work in terms of scalability.

4. It shows the importance of jointly learning the intervention and structure estimation policies, instead of using random interventions. Learning to pick informative interventions helps learn better CD algorithms.

In summary, the main contribution is the proposal of CORE, a reinforcement learning-based approach to learn causal discovery algorithms that scale better than prior work thanks to the dual Q-learning setup and other design choices. CORE pushes forward the state-of-the-art in learning policies for causal structure discovery and intervention planning.


## What are the keywords or key terms associated with this paper?

 Based on scanning the paper, some of the main keywords and key terms associated with it are:

- Causal Discovery
- Reinforcement Learning
- Partially Observable Markov Decision Process (POMDP)
- Interventions
- Structural Causal Models (SCMs)
- Deep Q-Learning
- Generalization
- Sample Efficiency
- Informative Interventions
- Joint Learning
- Real-World Applicability

The paper introduces CORE, a deep reinforcement learning based approach for causal discovery that learns to sequentially reconstruct causal graphs and perform informative interventions. It formulates causal discovery as a POMDP, uses concepts like SCMs, interventions, Deep Q-Learning, and aims to show generalization, sample efficiency, the importance of joint learning, and discusses real-world applicability. So these are some of the central keywords and terminology reflected in the paper content.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes a Partially Observable Markov Decision Process (POMDP) formulation for the causal discovery task. What are the key components of this formulation and how do they capture the dynamics of causal discovery? Discuss the choices made for the state space, action space, transitions and observations.

2. The paper uses a dual Q-learning setup with two networks - one for interventions and one for structure estimation. What is the motivation behind separating the policy into two networks? How does backpropagating two separate losses compare to using a single combined loss?

3. The reward function only depends on the accuracy of the estimated graph structure and not directly on the interventions. Discuss how this design choice incentivizes the agent to learn informative interventions. How sensitive is the overall approach to the choice of rewards?  

4. What assumptions does the generative process of the Structural Causal Models (SCMs) make during training? How realistic are these assumptions and what are the implications if they do not hold at test time?

5. The paper demonstrates strong generalization performance to unseen causal graphs. What factors contribute to this? Discuss the role of diversity in training graphs, neural network capacity and the overall algorithm design. 

6. From a machine learning perspective, what are the main challenges in scaling the approach to larger graphs with more variables? Specify the algorithmic and implementation bottlenecks.

7. The results show limitations in dealing with complex functional relationships like non-linearities and interactions. Elaborate why this is the case. Can you think of ways to make the method more robust?

8. How does the presence of unobserved confounders affect the performance of CORE? Suggest modifications to the algorithm to make it more robust against confounders.

9. The choice of target value for interventions is fixed in the paper. Discuss the implications of this, especially when applying CORE in real-world scenarios where good target values may not be known a priori.

10. The paper demonstrates strong performance when transferring a policy trained on simple functions to more complex functions. Discuss how this result could be leveraged to improve applicability in real-world settings and what assumptions it would rely on.
