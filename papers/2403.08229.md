# [Boosting Disfluency Detection with Large Language Model as Disfluency   Generator](https://arxiv.org/abs/2403.08229)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Disfluency detection in speech is important for applications like ASR and dialogue systems, but current methods rely heavily on scarce human-annotated data. 
- Prior augmentation techniques use simple rules or statistical features to generate disfluent sentences, but these lack diversity and authenticity.

Proposed Solution:
- Propose using large language models (LLMs) as disfluency generators to create augmented training data.
- Design effective prompts to guide LLM to generate diverse and realistic disfluent sentences without needing to fine-tune the LLM.
- Introduce an uncertainty-aware data filtering step to select high-quality generated sentences.  
- Show the generated data can enhance performance of small disfluency detection models.

Key Contributions:
- Demonstrate an efficient way to utilize the generative capabilities of LLMs to address data scarcity for disfluency detection.
- Eliminate the need to fine-tune the LLM, making the approach lightweight and cost-effective.  
- Generated sentences exhibit more complexity and authenticity compared to prior augmentation techniques.
- Achieve state-of-the-art results on Switchboard dataset by using only a small amount of augmented data, highlighting efficiency.
- Proposed data filtering provides quality control over generated sentences before using them.
- Show performance gains with multiple small detection models, proving the value of transferring LLM knowledge.

In summary, the paper introduces an effective data augmentation approach for disfluency detection that generates more realistic training examples through LLMs and a selective data filtering technique. By distilling LLM knowledge without costly fine-tuning, it enables lightweight yet performant disfluency detectors.
