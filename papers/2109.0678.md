# [Regional Adversarial Training for Better Robust Generalization](https://arxiv.org/abs/2109.0678)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research questions/hypotheses addressed in this paper are:1) Can considering the diversity and characteristics of perturbed training points in adversarial training lead to models with better robust generalization? 2) Can constructing an adversarial region around benign samples and sampling diverse perturbed points from this region improve model robustness?3) Can assigning perturbed training points different soft labels based on their distance from the benign point help capture useful information about their characteristics?4) Will the proposed Regional Adversarial Training (RAT) framework, which realizes the above ideas through an Adversarial Region-based Sampler and Distance-aware Label Smoothing, outperform standard adversarial training baselines in terms of robust accuracy against white-box and black-box attacks?5) Will RAT maintain high standard accuracy while improving robust accuracy, and exhibit smaller generalization gaps compared to other adversarial training methods?6) Will RAT show more stable robustness against PGD attacks with varying iterations and perturbation budgets?7) Will RAT demonstrate stronger robustness against natural image corruptions compared to other defenses?In summary, the key hypotheses are centered around whether considering diversity and characteristics of perturbed points in adversarial training can yield models with better standard accuracy, robust accuracy and generalization through the proposed RAT framework. The experiments aim to validate whether RAT achieves these goals compared to standard adversarial training baselines.
