# [Paraphrasing Is All You Need for Novel Object Captioning](https://arxiv.org/abs/2209.12343)

## What is the central research question or hypothesis that this paper addresses?

This paper addresses the problem of novel object captioning (NOC), where the goal is to generate descriptive captions for images containing objects that were not seen in the training data. The key research question is how to generate fluent, accurate, and adequate captions for novel objects without having ground truth captions available during training. The central hypothesis of this paper is that incorporating paraphrasing capabilities into image captioning models can help improve the fluency, fidelity (accuracy), and adequacy of novel object captions. Specifically, the authors propose a two-stage framework called "Paraphrasing-to-Captioning" (P2C) with the following main ideas:1. Use a pretrained language model to paraphrase generated captions to improve fluency.2. Perform self-paraphrasing using image-text alignment models as critics to improve fidelity and adequacy. 3. Use repetition penalties during self-paraphrasing to maintain fluency.So in summary, the central hypothesis is that learning to paraphrase, guided by language and image-text alignment models, can allow captioning models to generate better captions for novel objects without ground truth caption supervision. The paper aims to demonstrate the effectiveness of this P2C framework.
