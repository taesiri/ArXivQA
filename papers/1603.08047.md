# [Persistent self-supervised learning principle: from stereo to monocular   vision for obstacle avoidance](https://arxiv.org/abs/1603.08047)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can a robot keep performing its task when its original sensor that provides a trusted cue breaks down or becomes unavailable? 

More specifically, the paper investigates a persistent form of Self-Supervised Learning (SSL) in which a flying robot initially uses stereo vision to avoid obstacles. Over time, it learns to estimate distances using monocular appearance cues based on the stereo vision cue. The goal is for the robot to be able to switch to relying solely on monocular vision for obstacle avoidance if the stereo vision fails. 

The key hypothesis seems to be that by using the "training wheels" strategy, where the robot switches to monocular-based control but keeps stereo vision active in the background to override collisions, the robot can safely explore new situations encountered when relying on the learned monocular cue alone. This allows it to continually improve its monocular distance estimation and avoid the "feedback-induced data bias" problem.

In summary, the central research question is how a robot can keep performing a task when its original trusted sensor breaks down, using persistent SSL to learn a complementary sensor cue that remains functional after the loss of the original cue. The key hypothesis is that the "training wheels" strategy enables safe and continual learning to support this persistent form of SSL.


## What is the main contribution of this paper?

 The main contribution of this paper is the investigation of the behavioral consequences of using a persistent self-supervised learning (SSL) scheme, in which the signal from the trained algorithm remains useful even when the supervisory signal is cut off. 

Specifically, the paper studies a flying robot with stereo vision that uses SSL to learn monocular depth estimation for obstacle avoidance. It introduces a strategy where the robot initially relies on stereo vision and then switches to primarily using monocular vision, keeping stereo as "training wheels" to avoid collisions. 

The paper shows this approach handles the "feedback-induced data bias" problem known from learning from demonstration. Simulations and real-world experiments demonstrate the robot can successfully navigate using monocular vision after a short learning period.

The key findings are:

- Persistent SSL induces different training and test distributions like in learning from demonstration, requiring specific strategies. The "training wheels" method is effective.

- Real-world experiments show the potential of persistent SSL to enhance robot capabilities through online sensor-based learning.

- The abundant SSL training data enables gathering large datasets suitable for deep learning.

So in summary, the paper demonstrates persistent SSL as a promising learning approach for robotics and studies the behavioral aspects when the learned function remains useful after the supervisory signal is gone.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes and demonstrates a method called persistent self-supervised learning, in which a robot uses trusted sensor inputs (e.g. stereo vision) to train a complementary sensor (e.g. monocular vision) for the same task, and can safely switch to relying only on the trained complementary sensor by using the trusted sensor as a 'safety net' during the transition.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper on persistent self-supervised learning compares to other research on self-supervised learning and robot navigation:

- It focuses on the behavioral aspects of persistent SSL, where the robot must keep performing its task even when the original supervisory sensor cue becomes unavailable. Most prior SSL work has focused only on short-term learning within a single snapshot of data. 

- The authors frame persistent SSL as similar to learning from demonstration, with the issue of feedback-induced data bias. They propose and test behavioral strategies like "training wheels" to handle this bias. This provides a new perspective compared to typical SSL or LfD work.

- The robotic experiments demonstrate persistent SSL by training a drone to fly based solely on monocular vision after an initial period of stereo supervision. Prior SSL robot studies like on the DARPA car Stanley focused more on short-term terrain classification.

- The monocular navigation task connects SSL to contemporary computer vision research on single image depth estimation. The self-supervised aspect provides abundant training data.

- The work views persistent SSL as combining advantages of supervised learning (easy training) and reinforcement learning (adaptation to unforeseen situations) without their main downsides. This positions it as a unique learning approach for robotics.

In summary, this paper provides both a formalization of persistent SSL and demonstrations of its potential for robotic learning, with comparisons to related techniques. The behavioral strategies and framing in terms of overcoming data bias are novel contributions to the field.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors are:

- Using longer learning times to accumulate more training data over multiple flights. This could allow for the use of more complex learning methods like deep neural networks that require large amounts of data. The authors suggest that with improved hardware, close-to state-of-the-art deep learning models could be trained and run on drones.

- Using learning methods like Gaussian processes that provide uncertainty estimates along with their predictions. This uncertainty could be used to better integrate the behavior with the learning, for example by adapting the drone's speed based on the certainty of the distance estimates.

- Extending the learning from a single disparity value to full dense depth maps. Again, this could be enabled by larger datasets and more complex learning methods. 

- Applying the persistent SSL principle to other types of applications, such as using the future as ground truth or using it for advanced sensory integration where the ground truth could be partially improved by the complementary cue.

- Further investigation into the effects of imperfect ground truth data on the persistent SSL estimator. The authors encountered some issues with unreliable stereo data during experiments.

- Developing better methods to detect when the learned estimator becomes invalid, for example due to changes in the environment. This could allow the robot to switch back to using the ground truth and re-enter learning mode.

In general, the authors suggest that persistent SSL has significant potential for enhancing robot robustness by allowing for continued learning during operation. Applying it successfully will require advances in areas like uncertainty modeling, behavioral strategies, and complex learning methods that can scale to large datasets.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper investigates a novel form of Self-Supervised Learning (SSL) for robots, called persistent SSL, in which the robot continues performing its task after the original supervisory signal becomes unavailable. The authors study this in the context of a flying robot using stereo vision to avoid obstacles, while learning to estimate distances from monocular cues. They introduce a strategy where the robot initially flies with stereo vision but switches to relying primarily on monocular vision after some learning, using stereo only as "training wheels" to avoid collisions. This mitigates the "feedback-induced data bias" problem faced in persistent SSL. Simulations and real-world experiments with an AR drone show the feasibility of this approach, with the robot successfully avoiding obstacles using monocular vision after a few minutes of learning. The abundance of training data from the robot's own sensors is noted as beneficial for gathering large datasets needed for deep learning. The paper also relates persistent SSL to other machine learning techniques like reinforcement learning and learning from demonstration. Overall, it demonstrates the potential of persistent SSL as a robust learning method to enhance robot capabilities.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper introduces the concept of persistent self-supervised learning (SSL) for robots. SSL is a technique where a robot uses outputs from a trusted sensor as supervision to train a machine learning model to interpret a complementary sensor. Persistent SSL refers to continuing to use the learned model even when the trusted sensor becomes unavailable. 

The authors apply persistent SSL to train a drone to estimate distances using monocular camera images, with stereo vision providing distance ground truth for training. They show this setup is similar to learning from demonstration and compare training strategies in simulation. The best strategy is to primarily fly using monocular vision after initial training, with stereo overrides to prevent collisions. Real-world drone experiments demonstrate the feasibility of persistent SSL for monocular obstacle avoidance. The robot successfully navigates a room using vision from a single camera trained via SSL. The abundant training data enables gathering large datasets suitable for deep learning. The results illustrate the potential of persistent SSL as a robust learning technique to enhance robot capabilities.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes a persistent form of self-supervised learning (SSL) for robots to learn complementary sensor cues. In persistent SSL, the robot initially relies on a trusted sensor cue to perform its task. This trusted cue provides supervised labels that allow the robot to train online to recognize an additional complementary sensor cue. Importantly, the method enables the robot to keep performing its task even when the original trusted sensor cue becomes unavailable. The authors demonstrate this through a proof-of-concept scenario in which a flying robot uses stereo vision to avoid obstacles and simultaneously learns to estimate distances using monocular vision. The robot initially avoids obstacles using stereo disparities. Over time, it switches to navigating based on the learned monocular disparities, while still using stereo vision in the background as "training wheels" to avoid collisions. This allows the robot to safely explore new situations encountered when relying solely on monocular vision. The method is shown to enable persistent learning and successful monocular obstacle avoidance in both simulations and real-world experiments.


## What problem or question is the paper addressing?

 The paper is addressing the problem of how a robot's learning behavior should be organized in persistent self-supervised learning, so that the robot can continue performing its task when the original sensory cue becomes unavailable. 

The specific context is a flying robot that uses stereo vision to avoid obstacles. It wants to learn a mapping from monocular appearance cues to stereo-based distance estimates, so that it can rely on just a single camera if the stereo fails.

The key question is how to handle the "feedback-induced data bias" problem that arises when the robot starts acting on the learned monocular cues. Since these cues will not be identical to stereo, the robot's behavior and encountered states will differ from when it was learning. This can cause the performance to degrade over time.

The paper explores different behavioral strategies during the learning process to best enable the robot to keep avoiding obstacles using the learned monocular cues alone. This includes using the stereo solely as "training wheels" to override collisions while mainly flying by monocular vision.

Overall, the paper is studying how to organize persistent self-supervised learning so the robot can maintain its capabilities when the original sensory cue becomes unavailable, which requires addressing the feedback-induced data bias issue.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it are:

- Persistent self-supervised learning 
- Stereo vision
- Monocular depth estimation
- Flying robots
- Obstacle avoidance
- Feedback-induced data bias
- Learning from demonstration
- Machine learning

The main focus of the paper is on persistent self-supervised learning, which is a type of machine learning where a robot uses an original trusted sensor cue to train itself to recognize an additional complementary sensor cue. The paper studies this in the context of a flying robot using stereo vision to estimate distances, and learning to estimate distances from monocular cues over time.

Other key ideas explored are using persistent SSL to avoid the feedback-induced data bias problem from learning from demonstration, comparing different learning strategies in simulation, and demonstrating the approach on a real stereo-vision equipped drone learning monocular obstacle avoidance.

Overall, the key terms revolve around novel persistent self-supervised learning as a type of machine learning for robotics, applying it to monocular depth estimation for flying robots, and analyzing the resulting behavior compared to learning from demonstration.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to ask in order to create a comprehensive summary of the paper:

1. What is the key problem or challenge that motivated this research?

2. What is persistent self-supervised learning and how does it work? 

3. What is the specific proof-of-concept scenario explored in the paper (stereo vision to monocular vision)? 

4. How did the authors set up and implement the persistent SSL system for this scenario?

5. What offline experiments did the authors perform with the system and what were the results?

6. What different learning strategies did the authors compare in simulation and what did they find?

7. How did the authors test the system on a real robot (setup, experiments, results)? 

8. How does persistent SSL compare to other machine learning techniques like reinforcement learning and learning from demonstration?

9. How does persistent SSL address the feedback-induced data bias problem? 

10. What are the key conclusions about persistent SSL from this study and what future work is suggested?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a "persistent self-supervised learning principle". Can you explain in more detail what this principle entails and how it differs from regular self-supervised learning? What are the key components and how do they work together?

2. One of the main goals of this work is to allow a robot to keep performing its task when the original sensor breaks down. How does the proposed approach specifically address this challenge? How does it ensure the robot can rely on the learned complementary cue when needed?

3. The paper draws parallels between the persistent self-supervised learning problem and learning from demonstration. Can you elaborate on the similarities and differences between these two methods? How does understanding this relationship help design an effective learning strategy?

4. The paper introduces a "training wheels" scheme that uses stereo vision to override monocular decisions when close to obstacles. Why is this scheme more effective than a hard switch or mixed policy? How does it help address the feedback-induced data bias issue?

5. The visual bag of words (VBoW) method is used for monocular distance estimation. What are the key steps and parameters involved in this technique? How was it optimized for computational efficiency? What are its limitations?

6. The paper evaluates different regression algorithms for the VBoW method. What types of regressors were tested? What were the tradeoffs and how was the final choice justified? Could a deep neural network work here?

7. How does the thresholding of the distance estimates lead to a binary classification problem? How are the probabilities of collisions and spurious turns modeled based on TPR and FPR? What simplifying assumptions are made?

8. What are the key results from the simulation experiments comparing the different learning schemes? How well do they match the theory and motivate the real robot tests?

9. How well does the real robot perform using the "training wheels" scheme? What metrics are used to evaluate success? How do the results compare and contrast with simulation?

10. How does persistent self-supervised learning fit into the broader context of machine learning techniques like supervised learning, reinforcement learning, etc.? What are its advantages and limitations compared to other methods?


## Summarize the paper in one sentence.

 The paper presents a persistent self-supervised learning approach for flying robots to learn monocular depth estimation for obstacle avoidance, using stereo vision as the supervisory signal. The method allows the robot to continue performing obstacle avoidance even when the original stereo vision cue becomes unavailable.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the paper:

This paper explores a form of self-supervised learning called "persistent self-supervised learning" for obstacle avoidance in flying robots. The authors use a stereo vision system as a reliable "ground truth" to train a monocular vision system to estimate distances to obstacles. They show this is similar to learning from demonstration and compare different learning strategies in simulation, finding that using stereo overrides as "training wheels" while the robot mainly flies with monocular vision works best. They implement this on a real drone with a stereo camera, showing it can learn to avoid obstacles using only monocular vision after 4-5 minutes of training with stereo "training wheels". The abundant training data allows potential for deep learning approaches. Overall, this persistent self-supervised learning approach enhances robot capabilities and robustness by leveraging a robot's own sensors for reliable online learning without external supervision.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1. The paper proposes a "persistent self-supervised learning" approach. Why is it important that the learning is persistent, rather than just relying on the original sensor cue? What problem does the persistence help address?

2. The method learns to map from monocular appearance cues to stereo-based distance estimates. Why was this specific mapping chosen for the proof-of-concept? What other sensory mappings could this approach be applied to?

3. The paper shows formally that persistent SSL is equivalent to an learning from demonstration problem under certain assumptions. What is the significance of this equivalence? How can techniques from LfD be leveraged to improve persistent SSL?

4. The visual bag of words (VBoW) method is used for monocular distance estimation. Why was this specific method chosen? What are the tradeoffs compared to using a deep neural network?

5. Three different learning schemes ("cold turkey", DAgger, and "training wheels") are compared in simulation. Why does the "training wheels" scheme perform the best? What does this suggest about how persistent SSL should be organized behaviorally?

6. The paper identifies the "feedback-induced data bias" problem in persistent SSL. Why does this problem arise and how is it typically handled in other learning paradigms like LfD? How can the Markov model proposed help account for this bias?

7. What are the key differences between persistent SSL and other learning techniques like unsupervised, reinforcement, and traditional supervised learning? What unique advantages does the persistence provide?

8. How could the uncertainty of the learned monocular estimator be quantified during operation? How could this uncertainty estimate be used to improve the robot's behavior?

9. The paper focuses on a flying robot application, but how could persistent SSL be applied in other robotic domains? What tasks or sensory modalities could benefit from this approach?

10. What enhancements or extensions to the proposed persistent SSL method could improve the learning results? For example, could deep learning, multi-environment training, or better uncertainty characterization provide benefits?


## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper presents a novel persistent self-supervised learning approach for enabling robots to continue performing tasks when their original sensor inputs become unavailable. The authors study this for a flying robot that uses stereo vision to avoid obstacles, while training a model to estimate distances from monocular images. They frame this as analogous to learning from demonstration and propose having the robot fly based on the learned monocular cue, using the stereo vision as "training wheels" to avoid collisions. Simulations and real-world experiments with an AR drone show this is an effective strategy. The robot is able to fly for several minutes avoiding obstacles using the learned monocular estimates, with the stereo vision rarely needing to override. The abundant training data from the robot's own sensors facilitates learning for this task. The authors discuss implications for persistent self-supervised learning enhancing robot capabilities and enabling large datasets for deep learning approaches. Overall, this work demonstrates a promising approach to increasing robot adaptability and performance by persistently learning from the robot's own sensory inputs.
