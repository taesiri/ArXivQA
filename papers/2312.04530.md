# [Camera Height Doesn't Change: Unsupervised Monocular Scale-Aware   Road-Scene Depth Estimation](https://arxiv.org/abs/2312.04530)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes StableCamH, a novel self-supervised monocular depth estimation method that achieves metric scale awareness without requiring any ground truth depth or scale supervision. The key idea is to leverage prior knowledge of vehicle dimensions as a universal scale reference. However, directly using object sizes is brittle due to localization inaccuracies. Instead, StableCamH aggregates object size cues into a single invariant measure - the camera height - which is optimized as a consistency constraint across all frames. To realize this, the method introduces Learned Size Prior to robustly estimate vehicle dimensions from appearance, and Silhouette Projector to extract object silhouettes from estimated depth. By supervising the camera height estimated from depth to match a target camera height derived from prior epochs, StableCamH achieves robust metric-scale training. Experiments demonstrate state-of-the-art performance on KITTI and Cityscapes datasets compared to other weakly-supervised methods. A key advantage is the ability to leverage diverse datasets without any sensor calibration. StableCamH provides a self-supervised training framework to enable metric scale awareness for any monocular depth estimation method.


## Summarize the paper in one sentence.

 This paper proposes a novel training framework called StableCamH for scale-aware monocular depth estimation that aggregates object size priors into a camera height supervision signal optimized across frames and epochs to achieve robust metric-scale learning without any depth or scale labels.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel training framework called StableCamH for scale-aware monocular depth estimation. The key ideas are:

1) Exploiting prior knowledge of object heights (e.g. vehicles) in the scene to resolve scale ambiguity, but aggregating the object height cues into a single invariant measure - the camera height. This allows using the camera height consistency across frames and epochs as a supervision signal.

2) Devising a learning-based size prior called Learned Size Prior that can robustly estimate vehicle dimensions from appearance. This serves as the object size prior needed by StableCamH.

3) Formulating monocular depth estimation as camera height optimization achieved via end-to-end training. This results in robust and accurate unsupervised learning of metric scale.

4) Demonstrating state-of-the-art performance of StableCamH on KITTI and Cityscapes datasets without any depth or scale supervision. Showing its generalizability by training on multiple diverse datasets.

In summary, the main contribution is proposing the StableCamH training framework to enable scale-aware monocular depth estimation without reliance on auxiliary sensors or scale supervision. This is achieved by novel formulation and learning of camera height consistency.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Monocular depth estimation - Estimating depth from a single RGB image, without stereo pairs or other sensors. A challenging ill-posed problem.

- Self-supervision - Training the depth estimation models using only monocular videos, without ground truth depth data. Uses view synthesis as supervisory signal. 

- Scale ambiguity - Self-supervised models estimate depth only up to an unknown scale factor. Resolving this ambiguity is a key challenge.

- Camera height - The paper proposes optimizing this as an invariant objective across video frames to obtain metric scale.

- Object size priors - Leveraging assumed knowledge of vehicle dimensions as a source of scale cues. The paper learns an appearance-based model to predict dimensions. 

- StableCamH - The proposed training framework that aggregates frame-wise object size cues into a camera height optimization objective for scale-aware learning.

- Generalization - A key capability of StableCamH is generalization across datasets without dataset-specific scale supervision.

So in summary - self-supervised, monocular, scale ambiguity, camera height, size priors, StableCamH training framework, generalization.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The key idea of the proposed StableCamH method is to aggregate object size cues into a single invariant measure - the camera height. Why is formulating this as an optimization of the camera height effective for achieving robust and accurate unsupervised end-to-end training?

2. The Silhouette Projector module determines the scale factor by comparing the silhouette heights of objects to their height priors. How does computing the silhouette height make the method robust to partial occlusions or truncations of objects?

3. The Learned Size Prior module is used to estimate vehicle dimensions from appearance. Why is learning this prior, instead of using a fixed distribution, important for generalizability across datasets? 

4. The auxiliary rough geometric loss enforces object point clouds to be within a close region. How does this loss help with metric scale learning and why is the weight decreased over time?

5. The camera height optimization in StableCamH leads to gradual metric-aware learning over epochs. How does this result in depth estimates that are more consistent across the video sequence?

6. StableCamH trains the depth network and pose network end-to-end using self-supervision from monocular videos. What are the advantages of this framework over methods that require auxiliary sensors or ground truth data?

7. When evaluating on the KITTI and Cityscapes datasets, StableCamH outperforms other weakly supervised methods. Why is it still able to achieve state-of-the-art performance without any depth or scale supervision?

8. The results show that StableCamH can be successfully applied to enhance several network architectures for monocular depth estimation. What makes it suitable as a versatile add-on training scheme?

9. The camera height optimization formula includes a weighted moving average. How does this temporal aggregation help to stabilize the training?

10. When training on multiple datasets with different camera intrinsics, what techniques are used in StableCamH to align the estimated depths and handle the domain shift?


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Monocular depth estimation is important for autonomous driving tasks, but suffers from scale ambiguity without external supervision. Existing methods require auxiliary sensors like LiDAR or weak supervision through velocity, GPS, etc. to recover the absolute scale. However, they are limited in using arbitrary monocular driving videos for training. Humans can perceive scale using prior knowledge of object sizes, but directly using object sizes is brittle due to localization inaccuracies. 

Proposed Solution: 
The paper proposes StableCamH - a novel unsupervised monocular training framework to achieve metric scale awareness using a learned object size prior. The key idea is to aggregate object size cues into a single invariant measure - the camera height, which is constant for a video sequence. This allows formulating scale-aware depth estimation as camera height optimization during training. Specifically:

1. A learned object size prior called Learned Size Prior is introduced to robustly estimate vehicle dimensions from appearance. This helps compute an unscaled camera height from estimated depth. 

2. A differentiable Silhouette Projector leverages Learned Size Prior to determine per-frame scale factors and obtain scaled camera heights.

3. Scaled camera height is optimized across frames/epochs as supervision signal to train any monocular depth network end-to-end without ground truth scale labels.

Main Contributions:
1. First unsupervised monocular framework to achieve metric scale awareness by exploiting universal object size priors 
2. Novel learned object size prior using vehicle appearance to provide accurate and robust size estimates
3. Formulating depth learning as camera height optimization for consistency and stability  
4. Extensive experiments showing state-of-the-art performance over weakly supervised methods on KITTI and Cityscapes

The key advantage is the ability to train scale-aware depth models on any monocular video without scale labels, using StableCamH with Learned Size Prior. This simplicity and generalizability make it widely applicable for autonomous driving research.
