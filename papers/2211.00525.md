# [The Enemy of My Enemy is My Friend: Exploring Inverse Adversaries for   Improving Adversarial Training](https://arxiv.org/abs/2211.00525)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we improve adversarial training methods by better aligning the distribution of adversarial examples with their true class, rather than just aligning them with the original natural examples?

The key hypothesis is that currently adversarial training can sometimes be misguided by trying to match adversarial examples to misclassified natural examples. To address this, the authors propose a new training method using "inverse adversarial examples" that are generated to maximize likelihood and pull adversaries towards the high-likelihood region of their true class.

In summary, the main research question is how to improve adversarial training through a better alignment approach using inverse adversaries, rather than just matching adversaries to potentially misclassified natural examples. The central hypothesis is that this proposed inverse adversarial training method will improve robustness and natural accuracy.
