# [The Enemy of My Enemy is My Friend: Exploring Inverse Adversaries for   Improving Adversarial Training](https://arxiv.org/abs/2211.00525)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we improve adversarial training methods by better aligning the distribution of adversarial examples with their true class, rather than just aligning them with the original natural examples?

The key hypothesis is that currently adversarial training can sometimes be misguided by trying to match adversarial examples to misclassified natural examples. To address this, the authors propose a new training method using "inverse adversarial examples" that are generated to maximize likelihood and pull adversaries towards the high-likelihood region of their true class.

In summary, the main research question is how to improve adversarial training through a better alignment approach using inverse adversaries, rather than just matching adversaries to potentially misclassified natural examples. The central hypothesis is that this proposed inverse adversarial training method will improve robustness and natural accuracy.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

1. Proposing a novel adversarial training framework called Inverse Adversarial Training (IAT) that uses a new type of example called inverse adversarial examples. These are generated to maximize the likelihood/confidence in the neighborhood of natural examples, as opposed to standard adversarial examples that try to cross the decision boundary.

2. Designing a class-specific universal inverse adversary generation strategy to reduce computational costs compared to instance-wise inverse adversaries. This leads to the Universal Inverse Adversarial Training (UIAT) method.

3. Using inverse adversary momentum during training to stabilize the predictions and training process.

4. Showing that UIAT achieves state-of-the-art performance on CIFAR and SVHN datasets compared to other adversarial training methods, in terms of both natural accuracy and robust accuracy against strong attacks.

5. Demonstrating that a one-off version of UIAT further reduces computational costs with minimal performance loss.

6. Showing that UIAT can be combined with single-step adversarial training methods as a plug-and-play component to improve their robustness at low additional cost.

In summary, the key ideas are using inverse adversarial examples for more meaningful adversarial training, and designing efficient universal strategies to make it practical. The experiments validate its effectiveness and versatility across different settings.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a new adversarial training method called Inverse Adversarial Training (IAT) that uses "inverse adversarial examples" tailored to improve model predictions, along with other techniques like class-specific universal perturbations and momentum on inverse adversary predictions, to improve robustness against adversarial attacks while maintaining good performance on clean examples.
