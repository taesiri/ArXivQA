# [Neighborhood Attention Transformer](https://arxiv.org/abs/2204.07143)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to design an efficient and scalable sliding window attention mechanism for vision models. Specifically, the paper proposes Neighborhood Attention (NA) as a new type of localized attention pattern that:

- Localizes each pixel's attention span to its nearest neighbors, resulting in linear complexity instead of the quadratic complexity of standard self-attention. This makes NA more scalable.

- Approaches self-attention as the neighborhood size grows, unlike prior sliding window methods like SASA.

- Maintains translational equivariance, unlike blocked attention patterns like Swin's windowed self-attention. This helps introduce useful inductive biases.

- Can be implemented efficiently, allowing NA models to run even faster than Swin despite having a more localized attention pattern. This is enabled by the NATTEN Python package for NA developed in the paper.

The overall hypothesis is that NA strikes a better tradeoff between efficiency, scalability, and accuracy compared to prior attention mechanisms for vision models. The paper explores this through introducing Neighborhood Attention Transformer (NAT), evaluating it on image classification and downstream vision tasks, and comparing it to previous attention-based models like Swin and ViT.

The key innovation is the NA mechanism itself, which provides a more efficient and flexible way to incorporate localized attention patterns into vision models. The paper shows this allows building models like NAT that outperform prior methods under similar model size and computation constraints.
