# [Neighborhood Attention Transformer](https://arxiv.org/abs/2204.07143)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to design an efficient and scalable sliding window attention mechanism for vision models. Specifically, the paper proposes Neighborhood Attention (NA) as a new type of localized attention pattern that:

- Localizes each pixel's attention span to its nearest neighbors, resulting in linear complexity instead of the quadratic complexity of standard self-attention. This makes NA more scalable.

- Approaches self-attention as the neighborhood size grows, unlike prior sliding window methods like SASA.

- Maintains translational equivariance, unlike blocked attention patterns like Swin's windowed self-attention. This helps introduce useful inductive biases.

- Can be implemented efficiently, allowing NA models to run even faster than Swin despite having a more localized attention pattern. This is enabled by the NATTEN Python package for NA developed in the paper.

The overall hypothesis is that NA strikes a better tradeoff between efficiency, scalability, and accuracy compared to prior attention mechanisms for vision models. The paper explores this through introducing Neighborhood Attention Transformer (NAT), evaluating it on image classification and downstream vision tasks, and comparing it to previous attention-based models like Swin and ViT.

The key innovation is the NA mechanism itself, which provides a more efficient and flexible way to incorporate localized attention patterns into vision models. The paper shows this allows building models like NAT that outperform prior methods under similar model size and computation constraints.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing Neighborhood Attention (NA), a new efficient sliding window attention mechanism for vision. Specifically:

- NA localizes self-attention to a neighborhood around each pixel/token, reducing computational complexity from quadratic to linear while introducing useful inductive biases like locality. 

- The authors develop an extension called NATTEN with optimized CUDA/C++ kernels that allow NA layers to run faster than Swin Transformer's windowed self-attention, while using less memory.

- They propose the Neighborhood Attention Transformer (NAT), a hierarchical vision transformer using NA, which achieves strong results on image classification, object detection, and semantic segmentation. For example, NAT-Tiny reaches 83.2% top-1 accuracy on ImageNet with only 4.3 GFLOPs, outperforming similarly sized Swin and ConvNeXt models.

In summary, the key contribution is proposing NA as an efficient alternative to existing attention mechanisms like self-attention and windowed self-attention, demonstrating its effectiveness on vision tasks, and releasing an optimized implementation to facilitate further research. NA helps make attention-based models more practical for computer vision.
