# [Collecting The Puzzle Pieces: Disentangled Self-Driven Human Pose   Transfer by Permuting Textures](https://arxiv.org/abs/2210.01887)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper seeks to address is: How can we achieve effective disentanglement of human pose and texture in a self-supervised manner to enable high-quality human pose transfer without using paired training data?

The key hypothesis is that by using input permutation to shuffle image patches and remove spatial correspondence, they can eliminate pose information from the texture representation. This allows them to disentangle pose and texture in a self-supervised way without needing paired before/after images for supervision. The paper proposes and evaluates a method called PT^2 that utilizes input permutation and a dual-scale encoder to achieve this goal.

In summary, the main research question is how to do self-supervised pose/texture disentanglement for human pose transfer, and the key hypothesis is that input permutation can enable this by removing spatial/pose information from the texture representation.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- Proposing a new self-supervised human pose transfer method called PT^2 (Pose Transfer by Permuting Textures) that disentangles pose from texture at the patch-level without requiring paired training data. This is done by randomly permuting image patches to remove pose information from the texture representation.

- Using a dual-scale encoder with different kernel sizes to handle issues that arise from the patch permutations, such as spanning patch boundaries. The small-scale encoder captures fine details while the large-scale encoder captures longer visual patterns. 

- Achieving improved pose transfer performance on DeepFashion and Market-1501 datasets compared to prior self-supervised methods, with results competitive with some fully supervised approaches.

- Demonstrating benefits of the unpaired training approach by directly fitting the model to new target datasets, outperforming supervised models trained on different datasets.

- Showing through ablation studies that the input permutation, dual-scale encoders, separate pose/texture branches, and other components each provide gains over removing them.

In summary, the main contribution appears to be the proposed PT^2 approach for self-supervised pose transfer that disentangles pose and texture via patch permutations and uses dual-scale encoders to effectively transfer textures to new poses. The experiments demonstrate improved results over prior self-supervised methods and some supervised approaches.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key point of the paper:

The paper proposes a self-supervised human pose transfer method called PT^2 that randomly permutes image patches to disentangle pose from texture information and uses a dual-scale encoder to reduce noise and recover clothing shape details when transferring textures to a new pose.
