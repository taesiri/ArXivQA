# [Depthwise Convolution is All You Need for Learning Multiple Visual   Domains](https://arxiv.org/abs/1902.00927)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:Can we build a single neural network that can deal with images across different visual domains? The paper proposes a multi-domain learning approach to address this question. The key ideas and hypotheses are:- Images from different visual domains may share some universal structure that can be captured via a common parameterization in a neural network model.- Depthwise separable convolution can be used to exploit the structural regularity hidden in different domains. - Images across domains share cross-channel correlations but have domain-specific spatial correlations.- Sharing the pointwise convolution (which captures cross-channel correlations) while having domain-specific depthwise convolution (which captures spatial correlations) can lead to an effective multi-domain learning model.So in summary, the central hypothesis is that a compact and extensible multi-domain learning model can be developed based on depthwise separable convolutions, by sharing pointwise convolution across domains while keeping depthwise convolution domain-specific. The paper aims to validate this hypothesis through experiments on the Visual Decathlon benchmark.
