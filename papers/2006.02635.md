# [M3P: Learning Universal Representations via Multitask Multilingual   Multimodal Pre-training](https://arxiv.org/abs/2006.02635)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is that combining multilingual pre-training and multimodal pre-training into a unified framework via multitask learning can learn universal representations that map objects in different modalities (text, images) and languages into a common semantic space. Specifically, the paper proposes a model called M3P that aims to:- Learn multilingual representations from a large corpus of text covering 100 languages (via multilingual pre-training). - Learn multimodal representations from image-caption pairs labeled in English (via multimodal pre-training).- Use a novel "multimodal code-switched training" method to align images with non-English text to compensate for the lack of non-English labeled multimodal data.- Combine the above via multitask learning to create universal multilingual multimodal representations.The central hypothesis is that this unified model can learn improved representations that work across modalities (text, images) and languages, as evaluated on multilingual image-text retrieval tasks. The key novelty is using code-switching to align non-English text and images to overcome the lack of labeled non-English multimodal data.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:1. The authors propose M^3P, the first effort on combining multilingual pre-training and multimodal pre-training into a unified framework. M^3P aims to learn universal representations that map objects in different modalities (text, images) and languages into a common semantic space.2. A novel Multimodal Code-switched Training (MCT) method is introduced to enhance the multilingual transfer ability of M^3P, especially in low-resource settings. MCT helps enforce explicit alignments between images and non-English languages during pre-training.3. The authors achieve new state-of-the-art results on the multilingual image-text retrieval task for non-English languages on Multi30K and MSCOCO datasets, outperforming existing multilingual methods by a large margin. M^3P also obtains comparable performance to monolingual models on English.4. Extensive experiments and analysis are provided to give insights into the effectiveness of using MCT and different pre-training tasks in M^3P.In summary, the key innovation is the unified multilingual-multimodal pre-training framework M^3P and the proposed MCT method to improve multilingual transfer ability. This enables the model to achieve much better performance on non-English languages for multimodal tasks compared to previous methods.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper presents M3P, a novel pre-trained model that combines multilingual pre-training and multimodal pre-training into a unified framework via multitask learning, and proposes Multimodal Code-switched Training (MCT) to improve alignment between images and low-resource languages.


## How does this paper compare to other research in the same field?

Based on my review, here are some key ways this paper compares to other research in the field:- This is the first work attempting to combine multilingual pre-training and multimodal pre-training in a unified framework, while most existing works focus on either multilingual or multimodal pre-training separately. - The proposed Multimodal Code-switched Training (MCT) method is novel and effectively improves multilingual transfer ability, especially in low-resource settings. Other works on code-switching have focused only on text, not multimodal data.- The model achieves new state-of-the-art results on multilingual image-text retrieval, significantly outperforming prior multilingual baselines. For English, it obtains comparable results to current monolingual multimodal models.- Extensive ablation studies are provided to analyze the impact of different model components. The analyses on the number of MCT languages and different pre-training tasks give useful insights.- The qualitative analysis on MCT gives an intuitive explanation of why it is effective for non-English languages. The discussion of its potential limitation is also informative.Overall, this paper pushes forward multimodal pre-training to multilingual scenarios for the first time. The proposed approaches and thorough experiments demonstrate strong improvements over existing multilingual works. The analyses also provide valuable insights to guide future research in this direction. This paper makes significant contributions to the field of multilingual multimodal pre-training and retrieval.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Expanding M3P to support even more languages, beyond the 100 it currently handles. They suggest continuing to expand the language coverage.- Improving the multilingual transfer ability of M3P, especially in low-resource settings. They propose ideas like enhancing the Multimodal Code-switched Training (MCT) method.- Evaluating M3P on more multimodal downstream tasks beyond just image-text retrieval. The authors suggest testing it on tasks like multimodal machine translation.- Addressing limitations of the current Multimodal Code-switched Training approach, like handling inaccurate translations or grammatical/syntactic errors in the code-switched sentences.- Incorporating higher quality machine translation and multilingual datasets into the training data when they become available in the future, to further improve performance.- Expanding the qualitative and quantitative analysis of the model to better understand the impact of different components like MCT and the various pre-training tasks.- Investigating how to best fine-tune and adapt the model for optimal performance on specific multilingual-multimodal tasks.So in summary, the main directions are around expanding language support, improving multilingual transfer, testing on more downstream tasks, addressing current limitations of the MCT approach, incorporating better datasets when available, and further analysis/adaptation of the model. The authors seem to propose an extensive research agenda to build on their proposed M3P model.
