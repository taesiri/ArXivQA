# Why think step by step? Reasoning emerges from the locality of   experience

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:Why is chain-of-thought reasoning helpful for language models, and under what conditions does it provide significant benefits over direct conditional probability estimation? More specifically, the authors hypothesize that chain-of-thought reasoning is effective when the training data consists of local clusters of variables that influence each other strongly. In this case, reasoning through intermediate variables allows the model to incrementally chain together inferences between variables that were frequently observed together, in order to estimate relationships between variables that were rarely or never observed together during training.The key hypothesis is that the local structure of the training data, where subsets of highly influential variables are observed together, enables effective chain-of-thought reasoning. The authors test this hypothesis theoretically and empirically by training language models on samples from Bayesian networks with different observation structures.


## What is the main contribution of this paper?

Based on the abstract, the main contribution of this paper seems to be investigating why and how chain-of-thought reasoning is useful in language models. The authors test the hypothesis that reasoning is effective when training data consists of local clusters of variables that influence each other strongly. They prove a "reasoning gap" for the simple case of an autoregressive density estimator trained on local samples from a chain-structured probabilistic model. They also test the hypothesis empirically in more complex models, training an autoregressive language model on samples from Bayes nets with only subsets of variables in each sample. Their results suggest that chain-of-thought reasoning is useful for language models because direct prediction is inaccurate for inferences spanning variables rarely seen together in training, while reasoning can incrementally chain local statistical dependencies that are frequently observed. The combination of locally-structured training data and reasoning leads to greater data efficiency than training on more complete data. Overall, the paper provides insight into why step-by-step reasoning is useful in language models and suggests the usefulness stems from the local statistical structure of the training data.
