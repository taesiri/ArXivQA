# [OHTA: One-shot Hand Avatar via Data-driven Implicit Priors](https://arxiv.org/abs/2402.18969)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "OHTA: One-shot Hand Avatar via Data-driven Implicit Priors":

Problem:
Existing methods for creating personalized, animatable hand avatars typically require extensive input data like multi-view images or sequences, which can be cumbersome or impractical to acquire. The paper aims to develop a method that can create high-fidelity, animatable hand avatars from just a single image. This is very challenging due to the inherent lack of data.

Method: 
The paper proposes a novel two-stage framework called OHTA (One-shot Hand Avatar) that utilizes data-driven priors to enable one-shot reconstruction. 

In the first stage, a Hand Prior Network (HPNet) is trained on multiple hand identities to learn transferable geometry, albedo and shadow priors. The geometry uses an occupancy network, while the texture disentangles albedo (identity-specific) and shadows (identity-shared). A multi-resolution field based on a mesh scaffold is used to capture detailed texture priors.

In the second reconstruction stage, first texture inversion optimizes to find the closest identity latent code from HPNet for the target image. Then texture fitting keeps geometry frozen but fine-tunes parts of the texture network to fit the details of the target identity while regularizing with other views.

Contributions:

(1) Proposes first framework capable of creating high-fidelity, animatable hand avatars from just a single image using learned data-driven priors as regularization

(2) Designs a Hand Prior Network to effectively learn and transfer geometric, albedo and shadow priors for hands 

(3) Achieves state-of-the-art one-shot performance, and demonstrates versatile applications like text-to-avatar, editing, latent space manipulation

The method is comprehensively evaluated both quantitatively and qualitatively on datasets like InterHand2.6M and in-the-wild images. Comparisons to other state-of-the-art methods showcase markedly improved one-shot reconstruction ability.
