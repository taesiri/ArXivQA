# [Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised   Pre-Training](https://arxiv.org/abs/2104.01027)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research questions/hypotheses seem to be:1) How does domain mismatch between unlabeled pre-training data, labeled fine-tuning data, and test data impact performance in self-supervised speech representation learning?2) Does adding in-domain unlabeled data to pre-training improve performance even when the labeled fine-tuning data is out-of-domain? 3) Does pre-training on diverse domains improve robustness and generalization to unseen domains?4) Do the conclusions hold even with larger models and more labeled data?In particular, the paper investigates the effects of:- Adding in-domain vs. out-of-domain unlabeled data during pre-training- Fine-tuning on in-domain vs. out-of-domain labeled data - Testing on domains seen vs. unseen during pre-training/fine-tuningThe central hypothesis seems to be that using in-domain unlabeled data during pre-training is beneficial even when labeled fine-tuning data is out-of-domain, and that pre-training on diverse domains improves robustness. The paper presents experiments to test these hypotheses.
