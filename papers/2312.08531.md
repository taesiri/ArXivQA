# [Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods](https://arxiv.org/abs/2312.08531)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- The paper studies the convergence rate of the last iterate (final output) of stochastic gradient methods like stochastic gradient descent (SGD). 
- Prior works have established convergence rates for the last iterate under assumptions like compact domains, bounded noises, etc. that are restrictive. 
- Open questions remain on whether optimal convergence rates can be shown for the last iterate without restrictive assumptions and in more general settings like composite objectives, non-Euclidean norms, smooth functions, etc.

Proposed Solution
- The paper provides a unified analysis based on the Composite Stochastic Mirror Descent algorithm to study last iterate convergence.
- New convergence rates are shown for general convex and strongly convex functions in expectation and high probability without restrictive assumptions.
- Results hold for composite objectives, non-Euclidean norms, general domains beyond Euclidean space, smooth and non-smooth functions.
- Analysis framework is extended to also provide novel convergence guarantees under heavy-tailed and sub-Weibull noises.

Main Contributions
- First high probability last iterate convergence rate for SGD without compact domains or bounded noises.
- First optimal last iterate convergence rates for smooth (strongly) convex optimization. 
- Unified analysis framework that simultaneously accommodates different settings.
- First analysis of last iterate convergence under heavy-tailed and sub-Weibull noises.
- New convergence rates for composite objectives and non-Euclidean norms.

In summary, the paper provides a general unified analysis to establish optimal last iterate convergence guarantees for stochastic gradient methods without restrictive assumptions. The results advance understanding of these widely used algorithms in more practical settings.
