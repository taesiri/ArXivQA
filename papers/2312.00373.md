# [Streaming Bayesian Modeling for predicting Fat-Tailed Customer Lifetime   Value](https://arxiv.org/abs/2312.00373)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality one-paragraph summary of the key points from the paper:

This paper develops a method to enable Markov Chain Monte Carlo (MCMC) Bayesian modeling for large streaming datasets that may have concept drifts. The authors propose techniques for online categorical encoding and adapting HMC/NUTS samplers to operate online while being robust to changes in data distribution. They also develop a model for predicting customer lifetime value that uses a Student-t distribution to account for potential fat tails in the data. Their approach combines online learning, Bayesian modeling, and robust estimation to create LTV models on tall/wide datasets that can adapt to non-stationary data streams. The paper demonstrates this on a mobile app customer cohort revenue prediction task. Their method generalizes between thin and fat-tailed data via estimated Student-t degrees of freedom. Compared to a Gaussian model baseline, their approach better fits heavy-tailed empirical data and evaluates well on metrics like LPPD and RMSE. The contributions allow retaining interpretability of hierarchical Bayesian models while making them scalable for streaming commercial applications with concept drift.


## Summarize the paper in one sentence.

 This paper develops an online learning MCMC approach for hierarchical Bayesian models that can scale to tall and wide data, adapt to concept drifts, and model fat-tailed variables like customer lifetime value.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Developing a reusable workflow for converting batch Bayesian models like generalized linear models (GLMs) and hierarchical Bayesian models to mini-batch models that can handle online learning. This includes:

- An extension to the ordinal category encoding algorithm to make it online and extensible. This enables online preprocessing for index encoding of categorical features.

- An algorithm to convert HMC/NUTS samplers to online versions that are robust to concept drift.

2. Developing a fat-tailed lifetime value (LTV) model that generalizes over thin tails (Gaussian) and very fat tails (Cauchy) using the Student-t distribution. This model can handle concept drift, be updated without full retraining, and train on larger than memory data.

So in summary, the main contributions are a workflow to enable online learning for Bayesian MCMC models, as well as a specific fat-tailed LTV model demonstration leveraging this workflow.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the key terms and keywords associated with it are:

- Stream Learning
- Online Learning 
- Data Stream
- Concept drift
- Hierarchical Bayesian Modeling
- MCMC (Markov Chain Monte Carlo)
- Monte-Carlo
- Lifetime Value 
- Fat tails

The paper discusses developing an online learning MCMC approach for hierarchical Bayesian models, evaluating it on a fat-tailed lifetime value prediction problem with concept drift. The key goals are to make Bayesian MCMC modeling applicable at scale, in online/streaming settings, and adaptable to concept drift. The paper also introduces a model that generalizes over thin and fat tailed distributions.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. The paper mentions developing an extension to the ordinal category encoding algorithm to make it "infinitely extensible". Can you expand on what modifications were made to the original algorithm, and how it enables the encoding to be infinitely extensible?

2. When converting the HMC/NUTS sampler to an online version, the paper proposes doing extra warmup steps before fitting to each mini-batch. Can you explain the intuition behind why the extra warmup steps help make the modeling robust to concept drift? 

3. The Student-t distribution is used in the LTV modeling to account for potential fat tails. What are some of the advantages of using the Student-t distribution over simpler distributions like Gaussian or Lognormal in this application?

4. The paper develops a general workflow for converting Bayesian models from batch to online/mini-batch versions. What are some of the key challenges in making this conversion, especially in retaining interpretability and causal relationships?

5. How does the streaming ordinal encoding method compare to hashing techniques for handling high cardinality categorical variables in a streaming context? What are the tradeoffs?

6. What modifications need to be made to the inference process when converting a Bayesian model to an online setting compared to batch inference? How does this impact convergence guarantees?

7. The online HMC/NUTS method proposes taking multiple samples per mini-batch. What is the intuition behind this design choice and how does it impact modeling under concept drift?

8. How do the runtime and memory requirements of the online learning workflow proposed in this paper compare to batch modeling? What are some ways these could be optimized? 

9. The LTV model estimates the Student-t parameters μ, σ, ν per customer. How can decision makers leverage the uncertainty in these individual-level estimates for business optimization?

10. What kinds of concept drifts would be most problematic for the methods proposed? Are there any assumptions about the nature of drift made implicitly when designing the online learning workflow?


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Bayesian modeling with MCMC can be challenging to apply at scale (tall/wide data), in online learning settings, and under concept drift. There is a lack of reusable workflows to address these challenges.
- Modeling lifetime value (LTV) with potential fat tails is important for business decision making, but lacks approaches that can generalize over thin and fat tails.

Proposed Solutions:

1) Workflow to convert Bayesian MCMC models to online learning:
- Proposes streaming ordinal encoding to handle new categories in online setting.
- Proposes online mini-batch HMC/NUTS algorithm robust to concept drift via extra warmup. 
- Allows applying the workflow to scale GLMs and hierarchical Bayesian models for online learning.

2) LTV model with fat tails:  
- Uses Student-t distribution to generalize over thin tails (Gaussian) and fat tails (Cauchy).
- Learns which users likely have fatter tails via estimated degrees of freedom parameter.
- Applies workflow above to make model online and scalable.

Main Contributions:

- Workflow to incrementally update MCMC models on stream data, adaptable to concept drift. Applicable to common Bayesian models.
- Streaming ordinal encoding method as part of workflow.
- Robust online HMC/NUTS algorithm via extra warmup.
- LTV model generalizing over tail types and inferring tail fatness.
- Demonstrates workflow and LTV model on real commercial dataset.

The paper makes Bayesian modeling with MCMC more accessible for online and large-scale problems, with applications like LTV prediction. The workflow could enable wider use of rich Bayesian models in online settings.
