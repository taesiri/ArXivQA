# [All You Need is "Love": Evading Hate-speech Detection](https://arxiv.org/abs/1808.09115)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main research questions and hypotheses addressed in this paper are:1. How do different state-of-the-art hate speech detection models compare in terms of performance when tested on the same datasets?The authors hypothesize that model architecture may not have a major impact on performance for hate speech detection. They test this by replicating 7 models from prior work and evaluating them on 4 datasets.2. How well do hate speech detection models transfer across different datasets? The authors hypothesize that hate speech indicators do not transfer well across datasets due to differences in text types and labeling criteria. They test this by applying pre-trained models to datasets they were not trained on.3. How well can current models distinguish between hate speech and offensive but non-hateful speech?The authors hypothesize that models may conflate the two, classifying offensive non-hate speech as hate speech. They test this by evaluating model performance on offensive non-hate examples. 4. How robust are current models to simple evasion attacks that modify input text?The authors hypothesize that models rely too much on surface-level features and may be brittle against such attacks. They test this through 6 types of modifications like typos, leetspeak, whitespace changes, and word appending.In summary, the main goals are to systematically compare current models, evaluate their transferability, test their ability to distinguish hate from offensive speech, and assess their robustness to evasion attacks. The overarching hypothesis is that current models are limited in these aspects.
