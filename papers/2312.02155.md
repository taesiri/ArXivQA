# [GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for   Real-time Human Novel View Synthesis](https://arxiv.org/abs/2312.02155)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a new method called GPS-Gaussian for real-time novel view synthesis of human performers using only sparse camera views as input. The key idea is to regress 2D Gaussian parameter maps defined on the source view images which represent properties like position, color, opacity etc. for each foreground pixel. These maps are lifted to 3D Gaussians using predicted depth maps and aggregated from multiple views to render the novel view in a differentiable manner, allowing end-to-end training. The method consists of an iterative depth estimation module based on stereo matching and a Gaussian parameter regression module, which promote each other during joint training on a large human scan dataset. Experiments demonstrate the ability to synthesize 2K resolution novel views exceeding 25 FPS on one GPU, significantly outperforming prior work in terms of quality and speed. The generalizability across subjects and real-time performance enables applications like free viewpoint broadcasting and immersive telepresence.
