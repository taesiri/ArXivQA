# [On the Byzantine-Resilience of Distillation-Based Federated Learning](https://arxiv.org/abs/2402.12265)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
The paper studies federated learning (FL) algorithms that use knowledge distillation (KD), referred to as FedDistill, in the presence of Byzantine (adversarial) clients. Such algorithms have appealing properties like privacy and communication efficiency but have not been well explored under attacks. 

The paper analyzes how Byzantine clients can influence FedDistill compared to the standard FedAvg algorithm. It introduces two new attacks tailored to FedDistill and shows they outperform prior simpler attacks. It also proposes a new defense method called FilterExp that enhances resilience.

Key Differences from FedAvg:
- In FedDistill, clients influence the server only indirectly via predictions on a public dataset, whereas in FedAvg they directly control the aggregated model parameters. 
- The attack space is the probability simplex rather than the high-dimensional, unbounded parameter space.
- Formal analysis shows gradient descent on the perturbed FedDistill objective still converges to a neighborhood of the unperturbed solution.

Attacks:
- Loss Maximization Attack (LMA): Choose predictions by maximizing the loss between aggregated predictions and ground truth.
- Class Prior Attack (CPA): Use inter-class relationships to select the most misleading predictions. 

Defenses: 
- Filter: Detect colluding Byzantine clients based on increasing prediction variance.
- FilterExp: Apply Filter per round and downweight suspicious clients via exponential weighting. Combines client information over time.

Other Contributions:
- Little Is Enough for Distillation (LIED): Reduce attack magnitude to avoid detection, balancing strength and detectability.
- Evaluation showing attacks reduce accuracy of prior defenses but FilterExp neutralizes them.

The paper provides valuable analysis and insights on the Byzantine resilience of KD-based federated learning algorithms. The proposed attacks and defenses advance understanding of risks and mitigations.
