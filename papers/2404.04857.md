# [Learning Adaptive Multi-Objective Robot Navigation with Demonstrations](https://arxiv.org/abs/2404.04857)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Social robot navigation in human environments requires balancing multiple objectives like efficiency, safety, and adhering to social norms/user preferences. 
- Traditional RL methods use a fixed reward function and cannot adapt to changing user preferences without retraining.
- There is a need for flexible methods that can adapt navigation behavior to varying user preferences on-the-fly.

Proposed Solution:
- The paper proposes a multi-objective reinforcement learning (MORL) based navigation framework.
- It incorporates human demonstrations as one of the objectives to capture nuanced navigation preferences. 
- The relative weights between different objectives can be tuned to modulate the navigation behavior without retraining.

Key Contributions:
- A MORL navigation agent with tuneable objectives of efficiency, human distance keeping, and demonstration-based rewards.
- The demonstration data is distilled into a reward model using disturbance-based reward extrapolation (D-REX).
- Extensive qualitative and quantitative evaluation in simulation showing adaption to varying preferences.
- Successful sim-to-real transfer to a real robot and robot-to-robot transfer between two different robots.

In summary, the key novelty is an adaptive MORL navigation policy that balances baseline objectives like efficiency and safety along with nuanced user preferences captured via demonstrations. By exposed tuning knobs over objectives, it can modulate behavior on-the-fly without retraining. The results show preference adaptation in simulation and real-world validation.
