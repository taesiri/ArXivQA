# [Machine Translation in the Covid domain: an English-Irish case study for   LoResMT 2021](https://arxiv.org/abs/2403.01196)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Translating COVID-19 data from English to Irish poses challenges due to the low-resource nature of the Irish language. 
- There is a lack of large in-domain parallel corpora for training high-quality neural machine translation (NMT) models for this domain.

Proposed Solution:
- Apply domain adaptation techniques using a 55k general English-Irish corpus to improve translation of COVID data.
- Compare fine-tuning, mixed fine-tuning, and combined dataset approaches against models trained on an extended 13k line in-domain COVID dataset.
- Develop a custom English-Irish COVID dataset from health and education sources to augment the 8k line baseline dataset.

Methods:
- Use Transformer architecture with optimized hyperparameters (6 layers, 256-dim embeddings, 2048 batch size, 0.3 dropout, etc.)
- Train models using baseline COVID dataset (8k lines), extended dataset (13k lines), out-of-domain dataset (52k lines) and combinations.
- Evaluate models using BLEU, TER, and ChrF automated metrics.

Results:
- Extending in-domain COVID data by just 5k lines improved BLEU score by 27 points over baseline.  
- In-domain model with 13k lines outperformed out-of-domain model with 52k lines by 22.1 BLEU points.
- Best model was a Transformer trained on the 13k line extended in-domain COVID corpus.

Conclusions:
- In-domain data is far more valuable than out-of-domain data for low-resource NMT.
- Careful hyperparameter tuning enables high performance even with small datasets. 
- Main contribution is demonstrating feasibility of quality English-Irish COVID translation using only 13k parallel sentences.
