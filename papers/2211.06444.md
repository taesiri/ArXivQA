# [Probabilistic Debiasing of Scene Graphs](https://arxiv.org/abs/2211.06444)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question/hypothesis appears to be:

How can we debias scene graph generation models to improve performance on less frequent, "tail" relationships while maintaining performance on more frequent, "head" relationships? 

The key ideas and approach seem to be:

- Scene graph relationships exhibit a long-tailed distribution, where a few relationships like "on" and "wearing" are very frequent, while many others are quite rare.

- Existing models are biased towards predicting these frequent relationships, achieving good performance on them but poor performance on rare ones. 

- The authors propose using Bayesian inference to combine a prior distribution that captures the dependency between relationships and their subject/object with the uncertain outputs from existing biased models. 

- This allows debiasing the predictions to improve performance on rare relationships without overly harming performance on frequent ones.

- They also propose a novel method of augmenting the training data for the prior using sentence embeddings, to account for annotation biases.

So in summary, the main hypothesis is that this Bayesian inference approach can debias scene graph generation to improve mean recall across all relationships while balancing performance on frequent vs rare relationships.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- Proposing a Bayesian network-based framework to debias scene graph generation models by combining prior knowledge of triplets with uncertain evidence from existing models. 

- Introducing a novel learning scheme to augment the training data for the Bayesian network using embedding similarity of valid and invalid triplets. This helps alleviate the issue of insufficient minority samples.

- Performing inference on the Bayesian network to simultaneously remove bias from the marginal distribution of relationships while preserving the object-conditional dependencies. 

- Achieving improved balance between recall and mean recall metrics compared to prior debiasing techniques, without needing to retrain the original models.

- Demonstrating the effectiveness of the approach by debiasing several existing SGG models on Visual Genome and GQA datasets.

In summary, the key novelty is formulating debiasing as a probabilistic inference problem using a Bayesian network, and showing how embedding-based data augmentation can help learn the network parameters efficiently. The inference framework is model-agnostic and improves various biased SGG models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a method to debias scene graph generation models by combining prior knowledge about typical triplet relationships with the uncertain predictions from existing models, in order to improve performance on less frequent triplet relationships.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this paper compares to other research in the field of scene graph generation:

- The key contribution of this paper is using Bayesian networks and posterior inference to debias scene graph predictions. This is a novel approach compared to prior work on addressing the long-tail distribution problem in SGG. 

- Most prior work has focused on re-weighting or re-sampling training data to balance the distribution. This includes methods like DLFE-MOTIF, BGNN, and DT2-ACBS. In contrast, this paper operates only at inference time without retraining the biased model.

- Another common approach is causal intervention at test time like Unbiased-MOTIF and Unbiased-VCTree. The proposed method instead uses probabilistic modeling rather than causal reasoning.

- The embedding-based data augmentation to learn the prior network is also novel compared to standard practice of just using the annotated training triplets. This helps deal with the lack of samples for rare triplets.

- Overall, the Bayesian debiasing framework and the use of posterior inference seems to be a unique way to approach this problem. The results show strong improvements in mean recall over state-of-the-art methods, with a balanced trade-off in overall recall.

- One limitation compared to causal intervention methods is that it requires learning the prior network beforehand rather than being model-agnostic. The inference process is also slower than direct prediction.

- In summary, this paper introduces a substantially different methodology for debiasing scene graphs using probabilistic graphical models. The results demonstrate its effectiveness and it opens up a new potential direction for improving SGG models.
