# [Probabilistic Debiasing of Scene Graphs](https://arxiv.org/abs/2211.06444)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question/hypothesis appears to be:

How can we debias scene graph generation models to improve performance on less frequent, "tail" relationships while maintaining performance on more frequent, "head" relationships? 

The key ideas and approach seem to be:

- Scene graph relationships exhibit a long-tailed distribution, where a few relationships like "on" and "wearing" are very frequent, while many others are quite rare.

- Existing models are biased towards predicting these frequent relationships, achieving good performance on them but poor performance on rare ones. 

- The authors propose using Bayesian inference to combine a prior distribution that captures the dependency between relationships and their subject/object with the uncertain outputs from existing biased models. 

- This allows debiasing the predictions to improve performance on rare relationships without overly harming performance on frequent ones.

- They also propose a novel method of augmenting the training data for the prior using sentence embeddings, to account for annotation biases.

So in summary, the main hypothesis is that this Bayesian inference approach can debias scene graph generation to improve mean recall across all relationships while balancing performance on frequent vs rare relationships.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- Proposing a Bayesian network-based framework to debias scene graph generation models by combining prior knowledge of triplets with uncertain evidence from existing models. 

- Introducing a novel learning scheme to augment the training data for the Bayesian network using embedding similarity of valid and invalid triplets. This helps alleviate the issue of insufficient minority samples.

- Performing inference on the Bayesian network to simultaneously remove bias from the marginal distribution of relationships while preserving the object-conditional dependencies. 

- Achieving improved balance between recall and mean recall metrics compared to prior debiasing techniques, without needing to retrain the original models.

- Demonstrating the effectiveness of the approach by debiasing several existing SGG models on Visual Genome and GQA datasets.

In summary, the key novelty is formulating debiasing as a probabilistic inference problem using a Bayesian network, and showing how embedding-based data augmentation can help learn the network parameters efficiently. The inference framework is model-agnostic and improves various biased SGG models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a method to debias scene graph generation models by combining prior knowledge about typical triplet relationships with the uncertain predictions from existing models, in order to improve performance on less frequent triplet relationships.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this paper compares to other research in the field of scene graph generation:

- The key contribution of this paper is using Bayesian networks and posterior inference to debias scene graph predictions. This is a novel approach compared to prior work on addressing the long-tail distribution problem in SGG. 

- Most prior work has focused on re-weighting or re-sampling training data to balance the distribution. This includes methods like DLFE-MOTIF, BGNN, and DT2-ACBS. In contrast, this paper operates only at inference time without retraining the biased model.

- Another common approach is causal intervention at test time like Unbiased-MOTIF and Unbiased-VCTree. The proposed method instead uses probabilistic modeling rather than causal reasoning.

- The embedding-based data augmentation to learn the prior network is also novel compared to standard practice of just using the annotated training triplets. This helps deal with the lack of samples for rare triplets.

- Overall, the Bayesian debiasing framework and the use of posterior inference seems to be a unique way to approach this problem. The results show strong improvements in mean recall over state-of-the-art methods, with a balanced trade-off in overall recall.

- One limitation compared to causal intervention methods is that it requires learning the prior network beforehand rather than being model-agnostic. The inference process is also slower than direct prediction.

- In summary, this paper introduces a substantially different methodology for debiasing scene graphs using probabilistic graphical models. The results demonstrate its effectiveness and it opens up a new potential direction for improving SGG models.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors are:

- Extending the MAP inference approach to handle multiply connected triplets in a scene graph. The current method focuses on inference for individual triplets, but a scene graph contains multiple interrelated triplets. Developing an approach to perform joint MAP inference over multiply connected triplets could further improve performance.

- Exploring well-defined criteria for zero-shot refinement to restore the zero-shot recall capabilities of the baseline measurement models. The proposed approach relies on MLE learning of the Bayesian network, which compromises zero-shot prediction ability. Defining criteria to determine when to apply refinement could help preserve zero-shot performance. 

- Applying the proposed inference framework to other vision tasks and exploring its benefits. The authors suggest their Bayesian approach of combining priors and uncertain evidence could be beneficial in other vision domains beyond scene graph generation.

- Investigating alternatives to the embedding-based data augmentation technique for learning the Bayesian network, to deal with differences across datasets. The augmentation hyperparameter needs to be tuned for each dataset, so exploring other augmentation techniques could improve generalization.

- Extending the framework to handle more complex relationships between entities beyond triplets, such as higher-order relations. The current work models relationships between pairs of entities, but extending to higher-order relations could increase applicability.

- Applying more advanced inference techniques like variational inference to model uncertainties in a principled way during inference. The MAP inference used currently is point estimation.

In summary, the main future directions are developing the approach to handle more complex graphs, exploring ways to preserve zero-shot performance, applying the framework to other vision tasks, improving the data augmentation approach, and using more advanced inference techniques.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points from the paper:

The paper proposes a new method to reduce bias in scene graph generation models. Scene graphs represent an image by detecting objects and the relationships between them. However, existing models are biased towards predicting more frequent object and relationship types, neglecting less common ones. The authors address this by modeling triplets (subject-relation-object) in the scene graph as a Bayesian network. They incorporate the inherent dependencies between subjects, objects, and relations as the prior in the network. They also input the biased predictions from existing models as uncertain evidence. Then they perform inference to find the maximum a posteriori probability triplets. This combines the dependencies from the prior with the evidence while reducing bias. They also augment the priors by embedding-based similarity to compensate for lack of data on rare triplets. Experiments on Visual Genome and GQA show the approach significantly improves metrics related to rare classes while modestly reducing performance on frequent classes. The main limitations are loss of zero-shot prediction capability and the need to tune augmentation hyperparameters. Overall, the authors demonstrate a novel probabilistic inference method to reduce bias in scene graph generation.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper proposes a probabilistic debiasing methodology for scene graph generation (SGG) models to address the long-tail distribution of relationships. Scene graphs suffer from skewed distributions where a few frequent relationships like 'on' and 'wearing' dominate the training data. As a result, SGG models perform well on these majority relationships but poorly on rare ones. 

The authors propose a Bayesian network called the within-triplet Bayesian network that combines a prior representation of dependencies between the subject, relationship, and object with the evidence from a biased SGG model. They perform inference in this network to debias the predictions. They also use sentence embeddings to augment the learning of the prior network since rare relationships have insufficient training samples. Experiments on Visual Genome and GQA datasets show the approach significantly improves the mean recall over state-of-the-art models while moderately hurting the overall recall. The key novelty is formulating debiasing as a probabilistic inference problem.
