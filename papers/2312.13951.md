# [Typhoon: Thai Large Language Models](https://arxiv.org/abs/2312.13951)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like GPT-3 are predominantly trained on English data and may lack understanding of other languages and cultures, including Thai.  
- Thai is a low-resource language with limited publicly available datasets for pretraining LLMs. Existing multilingual models have very little Thai data.  
- There is a need for Thai-specific LLMs that encapsulate Thai linguistic knowledge and cultural understanding.

Proposed Solution - Typhoon:
- Typhoon is a 7 billion parameter autoregressive LLM specifically tailored for Thai.
- It is adapted from Mistral-7B by further pretraining on a cleaned Thai subset of Common Crawl plus some English data.
- A Thai subword tokenizer is added to improve efficiency over GPT-4 by 2.62x.  
- Typhoon outperforms all other open-source Thai LLMs on ThaiExam, a new benchmark based on Thai national exams to evaluate cultural knowledge.
- An instruction-tuned version, Typhoon-Instruct, outperforms others on Thai instruction-following tasks.

Other Contributions:
- Methodology to extract and clean a Thai subset from Common Crawl at scale.
- ThaiExam benchmark to evaluate cultural knowledge. 
- Analysis of tradeoffs between full fine-tuning vs Low-Rank Adaptation for model adaption.
- Public release of model and benchmarks to enable further research.

The paper demonstrates state-of-the-art capabilities for open-source Thai LLMs both in terms of reasoning ability as well as instruction-following.
