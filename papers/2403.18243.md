# [Boosting Conversational Question Answering with Fine-Grained   Retrieval-Augmentation and Self-Check](https://arxiv.org/abs/2403.18243)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Conversational question answering (CQA) is challenging as the questions are dependent on the conversation history and topics may frequently switch. 
- Large language models (LLMs) suffer from hallucination problems and generate factual errors, which are not reliable for knowledge-intensive CQA questions.
- Existing retrieval-augmented generation (RAG) methods focus on single-round QA, how to effectively perform RAG to boost CQA has not been well studied.

Proposed Solution:
- Propose a conversation-level RAG approach called ConvRAG, which incorporates fine-grained retrieval augmentation and self-check to boost CQA.
- It has three components:
   1) Conversational question refiner: Performs question reformulation and keyword extraction based on context for better understanding.
   2) Fine-grained retriever: Retrieves most relevant paragraphs from Webs as evidence.
   3) Self-check based response generator: Checks helpfulness of retrieved paragraphs and selectively utilizes them with LLM to generate response.

Main Contributions:
- Construct a Chinese CQA dataset with new features like reformulated questions, keywords, retrieved paragraphs and their helpfulness.
- Explore potential of RAG in conversation level, propose ConvRAG approach to boost CQA. 
- Three components effectively resolve challenges of question representation and knowledge acquisition for CQA.
- Experiments show superiority over state-of-the-art methods.
