# [Explicit Boundary Guided Semi-Push-Pull Contrastive Learning for   Supervised Anomaly Detection](https://arxiv.org/abs/2207.01463)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is:

How can we effectively exploit a few known anomalies to train more discriminative anomaly detection (AD) models that can detect both the known anomalies and generalize well to unseen anomalies?

The key points are:

- Most existing AD methods are unsupervised and learn only from normal data. This may result in insufficient discriminability to detect anomalies. 

- A few anomalies are often available in real applications, but directly using them (like in supervised learning) may bias the model towards the seen anomalies.

- This paper proposes a novel approach called Boundary Guided Anomaly Detection (BGAD) to address both issues simultaneously.

- BGAD has two main components:

1) Explicit Boundary Generating: Find an explicit separating boundary relying only on the normal data distribution. This avoids bias from limited anomalies.

2) Boundary Guided Optimizing: Use the boundary to guide a novel semi-push-pull loss that enhances discriminability by pulling normals together and pushing anomalies away, while preventing overfitting to known anomalies.

So in summary, the main hypothesis is that the proposed BGAD approach can effectively exploit few anomalies for training more discriminative AD models that detect both known and unseen anomalies.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes a novel supervised anomaly detection method called Boundary Guided Anomaly Detection (BGAD) to tackle two key issues in anomaly detection: insufficient discriminability of models trained only on normal data, and bias caused by using only a few known anomalies during training. 

2. A boundary guided semi-push-pull (BG-SPP) loss is proposed to exploit the few available anomalies more effectively. It uses an explicit separating boundary derived from just the normal data distribution to guide the optimization - pulling normal features towards this boundary while pushing anomalies away from it by a margin. This enhances discriminability while mitigating bias.

3. A method called RandAugment-based Pseudo Anomaly Generation (RPAG) is proposed to create more useful anomaly examples by randomly augmenting and pasting irregular patches from the existing anomalies onto normal images. This helps tackle the rarity of anomaly examples.

4. Experiments on multiple anomaly detection benchmarks like MVTecAD show state-of-the-art results, outperforming prior arts in supervised and unsupervised anomaly detection. The improved generalization capability to unseen anomalies is also demonstrated.

In summary, the key novelty is the proposed boundary guided optimization strategy that can effectively exploit the few available anomalies while reducing bias. RPAG also helps by synthesizing more useful anomalies. Extensive experiments validate the effectiveness of BGAD for supervised anomaly detection.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a new supervised anomaly detection method called Boundary Guided Anomaly Detection (BGAD) that uses an explicit separating boundary based on the normal data distribution and a boundary guided semi-push-pull contrastive loss to exploit the available abnormal samples more effectively, enhancing model discriminability while mitigating bias caused by limited abnormal data.


## How does this paper compare to other research in the same field?

 Here are some key ways this paper compares to other research in supervised anomaly detection:

- Motivation: It tackles two key issues in this field - insufficient discriminability of models trained only on normal data, and bias caused by limited available abnormal data. Many papers focus on only one of these issues. Addressing both is novel.

- Method: The two-step approach of explicit boundary generation then boundary-guided optimization is a new technique not used in prior works. Other semi-supervised AD methods tend to simply treat anomalies as negatives in a binary classification setup. The proposed losses are also unique.

- Evaluation: The paper demonstrates strong performance on multiple real-world anomaly detection datasets spanning industrial inspection and medical imaging. The one-class experimental setup provides a rigorous test of generalization ability to unseen anomalies. Results show the method outperforms other state-of-the-art supervised and unsupervised techniques by significant margins.

- Contributions: The core ideas of explicit boundary guidance and semi-push-pull contrastive loss are novel and address key weaknesses of prior arts. The strong empirical results validate these ideas effectively tackle the motivations.

In summary, this work introduces a novel perspective to supervised AD by generating an explicit boundary for guidance. The comparative evaluations demonstrate this approach effectively handles the limitations of existing methods and advances the state-of-the-art in this field. The proposed techniques are general enough to impact further research in semi-supervised anomaly detection.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Improving the generalization capability and theoretical analysis of the model's generalizability to unseen anomalies. The paper notes that further enhancing the model's ability to detect new, unseen types of anomalies is an important area for future work. Related to this, providing theoretical analysis to explain the model's generalization ability is noted as valuable.

- Using only pseudo anomalies during training. The authors suggest attempting to train the model using only simulated pseudo anomalies rather than requiring a few real anomaly examples. This could help tackle the rarity and insufficient samples of real anomalies.

- Addressing the imbalance between normal and abnormal samples more effectively. The paper notes handling the typically large imbalance between normal and rare anomaly examples as an ongoing challenge. More effective techniques to tackle this could improve learning.

- Extending the explicit boundary mechanism to other models. The current boundary guiding approach relies on a normalizing flow model to generate log-likelihoods. Exploring ways to enable similar explicit boundary generation in other model architectures lacking log-likelihood outputs is noted as useful future work.

- Applying the approach to other applications and datasets. While results are demonstrated on defect detection and medical imaging datasets, evaluating the method on more diverse applications and benchmark datasets could further demonstrate its generalization capability.

In summary, the main future directions focus on improving generalizability to unseen anomalies, handling the rarity of anomalies, extending the approach to other models and problem domains, and providing more theoretical analysis of the properties of the model.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points from the paper:

The paper proposes a new method for supervised anomaly detection, where models are trained using a few labeled anomaly examples to improve detection of both known and unseen anomalies. The method has two main components - generating an explicit separating boundary using only the normal data distribution to mitigate bias from limited anomalies, and a novel boundary-guided semi-push-pull contrastive loss to enhance discriminability. By finding a compact boundary close to the edge of the normal data distribution, then using it to guide optimization to pull normal features together and push anomalies apart beyond a margin, the method achieves higher discriminability while reducing bias. Experiments on industrial defect and medical lesion datasets demonstrate state-of-the-art performance and improved generalization over methods prone to overfitting on the known anomalies. The work provides an effective way to exploit limited labeled anomalies to improve anomaly detection through explicit boundary guidance and tailored contrastive learning.
