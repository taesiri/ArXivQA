# CGMH: Constrained Sentence Generation by Metropolis-Hastings Sampling

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to perform constrained sentence generation, where the generated sentences satisfy certain requirements like containing specified keywords. The key hypothesis is that constrained sentence generation can be effectively achieved by using Metropolis-Hastings sampling to sample sentences from a distribution defined to satisfy the constraints.The paper proposes a novel method called CGMH (Constrained Generation by Metropolis-Hastings sampling) to tackle constrained sentence generation. The core idea is to use Metropolis-Hastings, a Markov chain Monte Carlo sampling technique, to sample sentences from a desired distribution where sentences satisfying the constraints have higher probability. The paper shows this framework can handle both hard constraints like mandatory keywords as well as soft constraints like semantic similarity.So in summary, the central hypothesis is that Metropolis-Hastings sampling provides an effective approach to constrained sentence generation by allowing flexible manipulation of the sampling distribution to satisfy different constraints. The paper demonstrates the effectiveness of this approach on tasks like keywords-to-sentence generation, unsupervised paraphrasing, and error correction.


## What is the main contribution of this paper?

The main contribution of this paper is proposing CGMH, a novel framework for constrained sentence generation using Metropolis-Hastings sampling. The key points are:- CGMH allows imposing both hard constraints (e.g. mandatory keywords) and soft constraints (e.g. semantic similarity) on the generated sentences. This is flexible and enables many applications.- CGMH works in the inference stage without requiring parallel training data. It directly samples sentences from a specified stationary distribution. - The paper shows CGMH's effectiveness on three tasks: keywords-to-sentence generation, unsupervised paraphrase generation, and unsupervised error correction. CGMH achieves strong performance compared to previous supervised methods.- The paper provides in-depth analysis on the acceptance rate, effect of initial states, and comparison with VAE sampling. This gives insights into the sampling process.In summary, the main contribution is proposing the CGMH framework and demonstrating its flexibility for constrained sentence generation, without requiring supervised parallel data.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper: The paper proposes a novel approach called Constrained Generation by Metropolis-Hastings (CGMH) sampling for constrained natural language generation, which can handle both hard constraints like mandatory keywords and soft constraints like semantic similarity through flexible manipulation of the stationary distribution in Metropolis-Hastings sampling.
