# [Psychologically-informed chain-of-thought prompts for metaphor   understanding in large language models](https://arxiv.org/abs/2209.08141)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be whether introducing psychologically-informed "chain-of-thought" prompts based on theories of metaphor understanding can improve the performance of large language models at selecting appropriate paraphrases for metaphors. The key hypothesis appears to be that prompting large language models like GPT-3 to generate intermediate reasoning steps (latent variables and their relationships) will lead the models to better understand metaphors and choose more apt paraphrases, compared to simply showing examples of metaphors and paraphrases.Specifically, the prompts are designed to induce reasoning processes analogous to those posited in cognitive theories of human metaphor comprehension, like identifying a salient question under discussion that the metaphor addresses or finding features that the metaphor's topic and vehicle have in common.The overall goal seems to be exploring whether combining insights from cognitive psychology models and large language model prompting can lead to better metaphor interpretation, taking advantage of the reasoning structure of the former and the broad capabilities of the latter.


## What is the main contribution of this paper?

 The main contribution of this paper is using chain-of-thought prompts to introduce structures from probabilistic models of metaphor understanding into large language models (LLMs). The prompts lead the models to infer latent variables and relationships between them in order to choose appropriate paraphrases for metaphors. The latent variables and relationships are informed by theories from cognitive psychology. The authors show that these prompts can improve the performance of LLMs like GPT-3 on a metaphor paraphrase selection task.The key ideas are:- Probabilistic models of metaphor understanding posit latent variables and relationships between them, but have to be hand-designed for specific domains. - LLMs have implicit knowledge that spans many domains, but lack interpretability.- Chain-of-thought prompts can introduce latent variable structure into LLMs.- The authors test prompts based on two theories of metaphor understanding: questions under discussion and similarity comparisons. - The prompts improve GPT-3's performance on choosing metaphor paraphrases.- The prompts reduce GPT-3's reliance on metaphor familiarity, encouraging more systematic reasoning.So in summary, the main contribution is using chain-of-thought prompts to add interpretability and reasoning to LLMs in the form of latent variable relationships from cognitive psychology. This improves performance on metaphor understanding.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:The paper proposes using psychologically-informed chain-of-thought prompts to introduce structures from probabilistic models of metaphor understanding into large language models like GPT-3, and shows this can improve their performance at selecting appropriate paraphrases for metaphors.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other research on metaphor understanding and language models:- This paper focuses specifically on using rationales inspired by cognitive psychology to improve metaphor understanding in large language models. Much prior work has evaluated LLMs on benchmarks of metaphoric language, but not tried to integrate psychological theories into prompts. - The idea of using chain-of-thought prompting to induce more human-like reasoning in LLMs connects to an active area of research. However, most prior work has focused on math, logic, and common sense reasoning tasks. Using theory-driven rationales for more nuanced language understanding is novel.- The analysis relating model performance to metaphor familiarity parallels findings in cognitive psychology about familiar vs novel metaphors. However, other work has not explicitly made this connection and tested whether rationales make LLMs less reliant on familiarity.- The focus on a specific phenomenon (metaphor) and incorporating psychologically-motivated intermediate steps distinguishes this from much work that uses rationales or explanations mainly to optimize performance on a benchmark.- Using established datasets and metrics (the Katz norms) to evaluate models follows best practices, as opposed to creating new test sets. However, limitations of these resources may warrant developing better test sets in future work.In summary, this work makes innovative connections between cognitive psychology, chain-of-thought prompting, and metaphor understanding. The integration of theory and emphasis on interpretability and reasoning distinguish it from much benchmark-focused NLP research. The analysis of familiarity's role also breaks new ground in understanding these models.


## What future research directions do the authors suggest?

 Here are some key future research directions suggested in the paper:- Test whether rationales make GPT-3 DaVinci less reliant on metaphor familiarity. The authors suggest developing a dataset of very difficult, unfamiliar metaphors to evaluate this. - Explore whether rationales help language models understand novel metaphors better. The authors propose testing model performance on very novel metaphors, seeing if it struggles, and then evaluating whether rationales improve performance.- Extend the approach to other figurative language like irony, hyperbole, and understatement. The authors suggest their method could apply beyond just metaphor.- Evaluate whether the rationales actually lead the model to infer latent variables similar to humans. The authors did not directly test what the model is representing internally.- Develop corpora with human interpretations of metaphors rather than author-generated paraphrases. This could better reflect how typical speakers understand metaphors. - Collect more objective metaphor familiarity data rather than subjective ratings. Prior work has questioned subjective familiarity ratings.- Test whether the approach leads to improved metaphor generation and interpretation in free-form text rather than multiple choice tasks.In summary, the main future directions are: further testing the effect of rationales on novel metaphor understanding, applying the approach to other figurative language, directly evaluating the latent representations, using more naturalistic data, and testing free generation/interpretation.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:The paper explores using psychologically-informed chain-of-thought prompts to improve metaphor understanding in large language models like GPT-3. The prompts are designed to induce reasoning about latent variables from cognitive models of metaphor processing. The researchers test two types of prompts on GPT-3 Curie and DaVinci based on theories of metaphor comprehension: questions under discussion and similarity. The prompts lead the models to identify latent variables like the metaphor's topic and make inferences about transferring properties between the metaphor's subject and object. The prompts improve the models' performance at selecting appropriate paraphrases for metaphors compared to baselines. The researchers find that reasoning prompts reduce GPT-3 DaVinci's reliance on metaphor familiarity, suggesting they encourage systematic reasoning. The results demonstrate that prompting large language models to generate rationales based on cognitive theories can improve their nuanced language understanding.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:This paper explores using psychologically-informed chain-of-thought prompts to improve metaphor understanding in large language models like GPT-3. The prompts are designed to induce the models to infer latent variables and reason about relationships between them, similar to how humans understand metaphors according to theories in cognitive psychology. The researchers focused on the task of selecting appropriate paraphrases for metaphorical statements. They designed two types of prompts based on theories of metaphor processing: QUD prompts that identify the question under discussion being addressed, and similarity prompts that highlight properties shared between the metaphor's subject and object. The researchers evaluated these prompts with two versions of GPT-3 on a corpus of metaphors with human-generated paraphrase options. Without prompts, GPT-3 DaVinci performed very well on selecting paraphrases but Curie did not. The prompts improved Curie's performance, especially QUD prompts. Prompts also changed the reliance on metaphor familiarity for DaVinci, making it succeed similarly on more familiar and unfamiliar metaphors. Overall, the study provides a proof-of-concept that reasoning prompts can improve metaphor understanding in large language models and connect them with theories of human language processing.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:The paper explores using psychologically-informed chain-of-thought prompts to improve metaphor understanding in large language models like GPT-3. The authors test two types of prompts inspired by cognitive theories of metaphor processing. The prompts lead the models to generate intermediate reasoning steps that identify latent variables like the question under discussion being addressed and similarities between the metaphor's subject and object. After generating a reasoning chain, the model chooses the most appropriate non-metaphorical paraphrase of the metaphor from four options. The models are evaluated on their performance at this paraphrasing task using metaphors from the Katz corpus. The prompts are tuned on a small training set and evaluated on a larger test set. Performance with different types of psychologically-informed prompts is compared to several baselines, including simply prompting with examples and no explanatory text. The effects of metaphor familiarity on performance with and without prompts are also analyzed.


## What problem or question is the paper addressing?

 The main questions and goals of this paper appear to be:1) Can chain-of-thought prompting improve the ability of large language models (LLMs) like GPT-3 to choose appropriate paraphrases for metaphors? 2) Can prompts based on theories and models of metaphor understanding from cognitive psychology lead to better metaphor paraphrasing performance compared to baseline prompts?3) Does prompting with explanations make LLMs like GPT-3 less reliant on the familiarity of specific metaphors and better able to generalize?The authors are interested in whether introducing structures and variables from cognitive models of metaphor comprehension into LLMs via chain-of-thought prompting can enhance the models' capacity for nuanced metaphor understanding across a variety of domains. They test prompts based on two cognitive theories - questions under discussion and similarity comparisons. A key goal is understanding whether these psychologically-informed prompts improve paraphrasing and reduce reliance on metaphor familiarity compared to baselines.
