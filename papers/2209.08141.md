# Psychologically-informed chain-of-thought prompts for metaphor   understanding in large language models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be whether introducing psychologically-informed "chain-of-thought" prompts based on theories of metaphor understanding can improve the performance of large language models at selecting appropriate paraphrases for metaphors. The key hypothesis appears to be that prompting large language models like GPT-3 to generate intermediate reasoning steps (latent variables and their relationships) will lead the models to better understand metaphors and choose more apt paraphrases, compared to simply showing examples of metaphors and paraphrases.Specifically, the prompts are designed to induce reasoning processes analogous to those posited in cognitive theories of human metaphor comprehension, like identifying a salient question under discussion that the metaphor addresses or finding features that the metaphor's topic and vehicle have in common.The overall goal seems to be exploring whether combining insights from cognitive psychology models and large language model prompting can lead to better metaphor interpretation, taking advantage of the reasoning structure of the former and the broad capabilities of the latter.


## What is the main contribution of this paper?

The main contribution of this paper is using chain-of-thought prompts to introduce structures from probabilistic models of metaphor understanding into large language models (LLMs). The prompts lead the models to infer latent variables and relationships between them in order to choose appropriate paraphrases for metaphors. The latent variables and relationships are informed by theories from cognitive psychology. The authors show that these prompts can improve the performance of LLMs like GPT-3 on a metaphor paraphrase selection task.The key ideas are:- Probabilistic models of metaphor understanding posit latent variables and relationships between them, but have to be hand-designed for specific domains. - LLMs have implicit knowledge that spans many domains, but lack interpretability.- Chain-of-thought prompts can introduce latent variable structure into LLMs.- The authors test prompts based on two theories of metaphor understanding: questions under discussion and similarity comparisons. - The prompts improve GPT-3's performance on choosing metaphor paraphrases.- The prompts reduce GPT-3's reliance on metaphor familiarity, encouraging more systematic reasoning.So in summary, the main contribution is using chain-of-thought prompts to add interpretability and reasoning to LLMs in the form of latent variable relationships from cognitive psychology. This improves performance on metaphor understanding.
