# [EnvGen: Generating and Adapting Environments via LLMs for Training   Embodied Agents](https://arxiv.org/abs/2403.12014)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents":

Problem:
- Training embodied AI agents to accomplish long-horizon tasks in open-world games is challenging. These tasks require many prerequisite steps before a reward is given, making exploration very difficult. 
- Recent works use large language models (LLMs) directly as agents, leveraging their reasoning and world knowledge. However, iteratively querying the LLM at each step is prohibitively expensive.

Proposed Solution:
- The paper proposes EnvGen, a framework to use LLMs to generate customized training environments that teach agents the skills they currently lack. 
- An LLM is prompted to generate multiple environment configurations focused on training different skills. A lightweight RL agent is trained in these environments.
- The agent's performance on the original environment is measured to identify weak skills. This is fed back to the LLM to adapt the next set of training environments.

Key Contributions:
- Demonstrates EnvGen significantly improves agent performance on complex, long-horizon Crafter tasks over strong baselines including LLM agents, while using orders of magnitude fewer LLM queries.
- Shows agent trained with EnvGen environments learns faster than just training longer on the original environment.
- Qualitatively analyzes how LLM adapts environments over cycles to focus on improving skills agent is weaker at.
- Comprehensively ablates design choices of EnvGen like LLM model, number of environments, environment update frequency, etc.

In summary, the key innovation is efficiently utilizing LLMs to generate customized training environments that can teach agents multiple skills in parallel, while continuously adapting the environments based on feedback to focus on skills the agent lacks. This helps agents learn better without thousands of expensive LLM queries per episode.
