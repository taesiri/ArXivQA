# [Navigating Open Set Scenarios for Skeleton-based Action Recognition](https://arxiv.org/abs/2312.06330)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper tackles the novel and unexplored problem of open-set skeleton-based action recognition (OS-SAR). In real-world scenarios, human actions often fall outside the distribution of training data. Using pure skeleton data poses challenges for recognizing novel actions due to lack of visual cues and the sparse structure of body poses. Existing open-set methods for images/videos struggle for OS-SAR and have inconsistent performance across datasets/backbones.

Method:
The paper proposes CrossMax, a multimodal approach using joints, velocities and bones. It utilizes a novel Cross-Modality Mean Maximum Discrepancy (CrossMMD) suppression method to align latent spaces and reduce modality disparities during training. For testing, a Channel Normalized Euclidean (CNE) distance to nearest training sample is proposed as open-set probability. While it performs well for open-set, CNE distance struggles for closed-set classification vs vanilla Softmax. Thus, a cross-modality distance-based logits refinement technique is introduced that combines averaged logits and CNE distances, separately refining salient vs non-salient positions.

Contributions:
1) A large-scale OS-SAR benchmark with 3 datasets, 7 open-set baselines and 3 skeleton-based backbones.

2) The CrossMMD method to enable information exchange among modalities by aligning distributions.  

3) The CNE distance for open-set probability estimation and distance-based logits refinement to balance open-set and closed-set performance.

4) State-of-the-art CrossMax approach that uses both CrossMMD and refinement, achieving superior and consistent OS-SAR results across evaluations.

The key novelty is handling open-set recognition for sparse skeleton streams by using cross-modality calibration and distance-based confidence estimation. The benchmark and models advance open-set analysis for pose-based action recognition.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

This paper proposes CrossMax, a novel open-set skeleton-based action recognition method that uses cross-modality mean max discrepancy suppression during training and cross-modality distance-based logits refinement during testing to achieve superior performance in detecting and rejecting unknown actions not seen during training.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. A large-scale benchmark for Open-Set Skeleton-based Action Recognition (OS-SAR), featuring three datasets for classification from body pose sequences, seven open-set recognition baselines, and three well-established backbones for skeleton data streams.

2. A multimodal approach for OS-SAR leveraging three streams - joints, velocities, and bones - and enabling distribution-wise information exchange among them using the novel Cross-Modality Mean Max Discrepancy (CrossMMD) suppression mechanism.  

3. A distance-based confidence measure, the Channel Normalized Euclidean distance (CNE-distance), to address overconfidence in SoftMax-normalized probability estimates and enhance open-set recognition.

4. The complete CrossMax methodology that combines the aforementioned CrossMMD and distance-based logits refinement technique, achieving state-of-the-art performance across various evaluations.

In summary, the key contributions are: (1) a comprehensive OS-SAR benchmark, (2) a multimodal CrossMMD approach, (3) a CNE-distance measure, and (4) the full CrossMax pipeline for superior open-set skeleton action recognition.


## What are the keywords or key terms associated with this paper?

 Based on my review, some of the key terms and concepts associated with this paper on open-set skeleton-based action recognition include:

- Open-set skeleton-based action recognition (OS-SAR): The main problem being addressed, which involves recognizing known actions and rejecting unknown actions from skeleton data streams.

- Skeleton data streams: Sequences of body joint positions over time that are used as input for action recognition. Lack visual cues compared to video data.  

- CrossMax: The proposed methodology combining Cross-Modality Mean Maximum Discrepancy (CrossMMD) and cross-modality distance-based logits refinement.

- Cross-modality streams: The use of three complementary skeleton modalities - joints, velocities, bones. Enables better information exchange.

- CrossMMD: A novel loss function using mean maximum discrepancy to align distributions across modalities during training. 

- Distance-based logits refinement: A technique introduced to refine confidence scores using nearest neighbor distances, improving open-set probability estimates.

- O-AUROC and O-AUPR: Evaluation metrics used to measure open-set recognition capability on known vs unknown actions.

- Generalizability: A key focus, evaluated across datasets (NTU60, NTU120, ToyotaSmartHome) and backbones (CTRGCN, HDGCN, Hyperformer).

In summary, the key focus is enabling skeleton-based models to effectively recognize and reject unknown actions in an open-set scenario, using both new training strategies and inference techniques. The benchmark and method aim for cross-domain generalizability.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a multimodal approach leveraging three different streams - joints, velocities, and bones. Why is a multimodal approach better suited for open set skeleton-based action recognition compared to a single stream? What are the key advantages offered by each modality?

2. The CrossMMD loss is introduced to enable information exchange between the latent spaces of different modalities. Explain the mathematical formulation behind CrossMMD. Why is minimizing the discrepancy between intra-source and inter-source differences important here? 

3. The paper argues that softmax probability estimates struggle to disentangle in-distribution and out-of-distribution samples well in the open set scenario. Elaborate on this limitation and explain why the proposed Channel Normalized Euclidean (CNE) distance measure performs better disentanglement.  

4. While the CNE distance gives good open set recognition ability, it struggles with conventional close set accuracy compared to softmax. Explain the cross-modality distance-based logit refinement technique and how it combines the strengths of both CNE distance and softmax.

5. Analyze the ablation studies in detail - how does performance vary with changing the open set ratio? How robust is CrossMax to noise and occlusions compared to other methods? 

6. Compare and contrast the formulations of existing open set recognition techniques from the literature which are evaluated as baselines. What modifications were required to adapt them to the skeleton-based recognition task?

7. The paper identifies stability across datasets and backbones as an important criterion for generalized open set recognition. Evaluate how consistent the performance of CrossMax is when evaluated across NTU60, NTU120 and Toyota Smart Home datasets.

8. From an algorithmic perspective, what are the limitations of CrossMax? Are there any assumptions in the methodology that could fail in complex real-world deployment?

9. The paper benchmarks performance using AUROC and AUPR metrics. Justify the relevance of these metrics for the open set recognition task. Are there any other evaluation criteria that could have been used?

10. The CrossMax methodology relies on a Siamese network-based formulation leveraging multiple streams. Discuss architectural choices and design considerations for adapting this to an online recognition scenario with low latency requirements.
