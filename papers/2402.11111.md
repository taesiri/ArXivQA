# [Language Models as Science Tutors](https://arxiv.org/abs/2402.11111)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Language Models as Science Tutors":

Problem:
Recent progress has improved language models' (LMs) scientific problem-solving abilities. However, model development has not focused on real-life applications for science education. Existing evaluations also don't capture key aspects needed for science tutoring, including:

1) Simulating real situations like clarifying concepts or providing background info  
2) Evaluating reasoning process instead of just final answer
3) Handling long scientific documents

Proposed Solution:
The authors introduce two new resources:

1) TutorEval - A QA benchmark with 800+ questions about textbook chapters, requiring advanced scientific knowledge to simulate humans understanding materials. Questions are written by subject matter experts.

2) TutorChat - A dataset of 80,000 long synthetic dialogues about textbooks chapters generated by GPT-3.5 and GPT-4 covering STEM and more.

They fine-tune Llemma models on TutorChat and show it significantly outperforms using other dialogue datasets. By combining TutorChat STEM dialogues with math data (MathMix), they create well-rounded tutors with strong math skills.

They introduce two competitive models:

1) Llemma-7B-32K-MathMix 
2) Llemma-34B-MathMix

These achieve excellent performance on TutorEval while matching or exceeding scores of models like Mistral-7B-V2 on math benchmarks like GSM8K and MATH.

Main Contributions:

- TutorEval - First long-context benchmark for science QA
- TutorChat - First long-context dialogue dataset for science 
- Analysis showing importance of scientific training/tuning
- State-of-the-art models for science and math reasoning
- All data, models, and evaluations open-sourced

The paper demonstrates the value of tailoring LMs to science education applications via specialized training, datasets, and evaluations. The released resources lay the foundation for further research on applying LMs for science and math assistance.
