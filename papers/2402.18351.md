# [LatentSwap: An Efficient Latent Code Mapping Framework for Face Swapping](https://arxiv.org/abs/2402.18351)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Face swapping aims to replace the identity of a target image with that of a source image, while preserving other facial attributes like expression, lighting, and pose. Prior works require adversarial training or additional datasets, leading to unstable results. Leveraging the generative capabilities of pre-trained GANs like StyleGAN2 can improve stability, but existing methods depend on auxiliary models like segmentation networks, failing to fully exploit the latent space.

Proposed Solution:
This paper proposes LatentSwap, a simple framework to generate swapped latent codes that can be fed into a StyleGAN2 generator to produce face swaps. It consists of a "latent mixer" module with 5 fully-connected layers that mixes the source and target latent codes. LatentSwap is trained on randomly sampled latent codes, without needing any dataset besides pre-trained generator and inverter models. An optimization-based inverter like PTI maps real images to the generator's latent space for inference.  

The loss function has 3 terms: (1) identity loss between source and swap, (2) latent penalty loss to keep swap code close to target code, and (3) shape loss using facial landmarks. Varying the coefficient of latent penalty loss allows control over similarity to source or target.

Contributions:

- Simple and fast-training framework to generate swapped latent codes for arbitrary source/target pairs
- Leverages pre-trained GAN inversion model and StyleGAN2 generator, no other auxiliary models needed
- Loss formulation allows control over face swap results between source and target 
- Applicable to other generators like StyleNeRF, enabling 3D-aware face swapping
- Compatible with other StyleGAN2 editing tasks 

The model produces high quality, realistic 1024x1024 face swaps comparable to state-of-the-art, despite the simplicity and efficiency of the approach. Ablations analyze impact of different latent spaces and loss coefficients.
