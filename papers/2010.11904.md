# [Transcription Is All You Need: Learning to Separate Musical Mixtures   with Score as Supervision](https://arxiv.org/abs/2010.11904)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is whether musical scores alone can be used as a weak label to train a music source separation system without access to isolated stems. 

The key hypothesis is that by using a musical score as a training target, the model can learn to separate mixtures into individual instrument sources, even though it only has access to the mixed signal and score during training, not isolated tracks.

Some key points:

- Most prior work on score-informed source separation uses isolated tracks during training. This work explores only using mixtures and scores.

- The proposed model uses a transcriptor as a critic to guide learning of a separator. The separator tries to separate the mixture so the transcriptor can predict the correct score from each estimated source. 

- Harmonic mask constraints and adversarial losses are introduced to further improve separation and transcription performance when training with weak score labels.

So in summary, the main research question is whether score alone provides enough information to train a source separation system without isolated stems, which they test through their proposed transcriptor-separator model trained on mixtures and scores.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel weakly-supervised training approach for music source separation that only requires a music mixture and its musical score during training. The key ideas are:

- Using a musical score as a weak label to train a source separation system, instead of requiring isolated music stems. 

- A 3-step training strategy involving:
   1) Pre-training a "transcriptor" on mixtures and scores
   2) Using the transcriptor to supervise training of a "separator"
   3) Jointly fine-tuning the transcriptor and separator with adversarial losses

- Introducing harmonic mask constraints derived from the score to improve separation of harmonic instruments.

- Novel adversarial losses during joint training to improve the transcriptor's sensitivity to errors in the separated outputs.

The proposed approach achieves competitive separation performance without needing isolated training data, only requiring widely available musical scores and mixtures during training. The use of musical scores provides both temporal and harmonic supervision, outperforming methods relying only on temporal activity labels.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper: 

The paper proposes a novel weakly-supervised approach to train a music source separation system using only mixtures and their corresponding musical scores, without requiring isolated instrument tracks.


## How does this paper compare to other research in the same field?

 Here are a few key points comparing this paper to other research in music source separation and weakly supervised learning:

- Most prior work in music source separation relies on supervised training with isolated source tracks. This paper proposes a novel approach to train a separation model using only mixtures and musical scores.

- Other weakly supervised separation methods use sound event class labels or visual information as weak supervision. This paper is unique in using musical scores, which provide both temporal and harmonic supervision.

- The proposed three-step training strategy builds on prior work like Pishdadian et al. that used a classifier for weak supervision. But this paper argues musical scores can provide better supervision for separating harmonic instruments.

- The adversarial losses proposed for fine-tuning are novel compared to prior score-informed separation work, and help improve separation and transcription.

- Results demonstrate their proposed method outperforms a classifier-based baseline, but still lags supervised training. Most prior score-informed methods still require isolated tracks.

- This paper focuses on separating a few harmonic instruments. Extending the approach to drums or larger ensembles could be interesting future work.

In summary, this paper makes innovative contributions in leveraging musical scores for weakly supervised separation, outperforming prior work that relied only on temporal supervision. The adversarial training strategies are also novel for this problem domain.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Tackling the alignment problem between audio and musical scores in order to expand the range of training data that can be used. The current method assumes the audio and scores are already well-aligned, but the authors suggest incorporating alignment algorithms as a pre-processing step. 

- Separating non-harmonic instruments like drums within their proposed framework. The current experiments focus on harmonic instruments like piano, guitar and bass.

- Exploring semi-supervised approaches that combine small amounts of fully-supervised training data (with isolated sources) along with large amounts of weakly labeled data (mixtures + scores only).

- Improving the adversarial training strategies, for example by using more advanced GAN techniques. 

- Testing the approach on real (non-synthesized) music datasets to evaluate how well it generalizes.

- Incorporating score information at test time as well as training time to further improve separation performance.

- Comparing to and combining with other weakly supervised separation techniques like using other types of weak labels (class labels, video, etc).

In summary, the main directions are improving the training data and alignment, expanding the range of instruments, exploring semi-supervised and adversarial training, and evaluating on real-world datasets. The authors lay out promising future work to make their score-supervised separation approach more practical and better performing.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper proposes a novel weakly-supervised approach to train a music source separation system using only mixtures and their corresponding musical scores, without needing isolated instrument tracks. The model consists of a separator that outputs time-frequency masks for each instrument, and a transcriptor that acts as a critic to guide the separator's training. The transcriptor provides both temporal and frequency supervision derived from the score. A harmonic mask constraint is introduced to further leverage score information. Two adversarial losses are proposed to fine-tune the transcriptor and separator. Experiments on the Slakh2100 dataset demonstrate that using score supervision outperforms using only temporal activity labels. The adversarial training strategies lead to additional improvements in separation and transcription performance compared to training the components in isolation. The results show the potential of scores as a weak label for training source separation systems without access to isolated instrument tracks.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper proposes a new method for training a music source separation system using only mixtures of music and their corresponding musical scores, without needing isolated tracks. The model contains two components - a separator that outputs time-frequency masks to separate each instrument, and a transcriptor that acts as a critic to provide supervision. The transcriptor is first pre-trained to transcribe mixtures to scores. The pretrained transcriptor is then fixed and used to guide training of the separator, by updating the separator so its separated outputs can be correctly transcribed. Two novel loss functions are introduced during separator training to incorporate score information - a clip level mixture loss using activity from the score, and a harmonic mixture loss utilizing harmonic masks derived from the score. Finally, the transcriptor and separator are jointly trained with two new adversarial losses that encourage the transcriptor to be more sensitive to errors in the separated tracks. Experiments on the Slakh2100 dataset show this approach outperforms a baseline using only a classifier for supervision. The proposed harmonic loss and adversarial losses are shown to further improve separation and transcription performance compared to just using the transcriptor outputs as training targets.

In summary, this work demonstrates a music source separation system can be trained using only mixtures and scores as training data, without needing isolated tracks. The proposed method of using a pretrained transcriptor as a critic, along with harmonic and adversarial losses, is able to effectively leverage the weak labels provided by musical scores. Results approach those obtained with isolated tracks, demonstrating the feasibility of score-supervised separation.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes a three-step training method to train a weakly-supervised music source separation model using only mixtures and their corresponding musical scores, without access to isolated stems. 

The method consists of:

1) Pre-training a transcriptor to estimate the musical score from the mixture. 

2) Using the pre-trained transcriptor as a critic to train a separator, which estimates time-frequency masks for each source. The separator is trained to make the separated outputs good enough for the transcriptor to transcribe back to the original score. 

3) Jointly fine-tuning the transcriptor and separator using adversarial losses. This forces competition between the two to improve separation.

The method incorporates harmonic masking and adversarial losses to better leverage the musical score information during training. Experiments on a dataset of piano, guitar and bass mixtures show the proposed method outperforms a baseline using only temporal supervision, and approaches supervised performance despite not having access to isolated stems during training.


## What problem or question is the paper addressing?

 Based on my reading of the paper, the key problem it is addressing is how to train a music source separation system without requiring isolated audio sources for supervision, using only mixtures and their associated musical scores. 

Specifically, the paper investigates whether musical scores alone can serve as a weak label or supervision signal to train a source separation system, without access to isolated stems for each instrument. This is an important problem because large datasets of isolated musical sources are difficult to obtain due to copyright issues, while musical scores are comparatively much easier to collect.

The main research questions examined in the paper are:

- Can musical score alone be used as supervision to train a source separation system to separate mixtures into constituent instruments?

- How can musical score information best be incorporated into a source separation training framework?

- What model architectures and training strategies are most effective for learning to separate musical mixtures using only score supervision?

To summarize, the key focus is on exploring musical score as the sole supervisory signal for training source separation systems, in order to overcome the limitations in obtaining large labeled datasets of isolated musical sources.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper abstract and introduction, some of the key terms and keywords associated with this paper are:

- Music source separation
- Weakly supervised separation 
- Weak labels
- Music transcription
- Musical scores
- Source separation system
- Temporal convolutional network
- Transcriptor 
- Separator
- Adversarial training

The main focus of the paper seems to be on using musical scores, which are easier to obtain than isolated music stems, as a weak label to train a music source separation system without needing access to isolated stems. The proposed model uses a transcriptor and separator, and incorporates techniques like harmonic masking and adversarial losses to improve separation and transcription performance when trained only on mixtures and scores.

In summary, the key ideas explored are using scores as weak supervision, adversarial and harmonic masking losses, transcriptor-separator model architecture, and not needing isolated stems for training source separation. The application area is music source separation.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to ask to create a comprehensive summary of the paper:

1. What is the main goal or focus of the research? 

2. What are the key limitations or challenges with existing approaches that the paper aims to address?

3. What novel model architecture, loss functions, or training strategies does the paper propose? 

4. What datasets were used for training and evaluation? What are the key characteristics of these datasets?

5. What were the main evaluation metrics used? What were the quantitative results achieved by the proposed method?

6. How did the proposed method compare to existing baseline or state-of-the-art approaches on the key metrics?

7. What are the main findings or conclusions from the experimental results?

8. What are the key advantages or benefits of the proposed approach over prior work?

9. What are some limitations of the current work or open challenges for future work?

10. How might the proposed methods generalize or extend to other related problems beyond the specific application studied?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1. The paper proposes a 3-step training approach. Why is it beneficial to first pre-train the transcriptor before using it to train the separator? What would be the limitations of directly training them together from the start?

2. The harmonic mask mixture loss is introduced to leverage harmonic structure information from the score. However, results show using it alone degrades performance. Why might this be the case? How does combining it with the clip-level mixture loss help alleviate this issue?

3. The adversarial mixture loss randomly mixes separated tracks from different samples. What is the motivation behind this? Why is it better than just remixing tracks from the same sample?

4. The adversarial transcription loss encourages the transcriptor to recognize non-target instruments while ignoring the target in the separated track. What is the intuition behind this? How does it differ from standard transcription training?

5. The improved guitar separation with adversarial losses seems to indicate the approach helps distinguish between guitar and piano. Why might adversarial losses be especially beneficial for this challenging case? 

6. The paper assumes aligned audio and MIDI scores. How could the approach be extended to handle unaligned data? What modifications would need to be made?

7. The proposed method relies only on score for training and not for inference. What are the tradeoffs versus score-informed separation methods that require score for both?

8. The experiments focus on mixtures of 3 instruments. How might the approach scale to larger ensembles? Would any components need to be modified?

9. The transcriptor and separator use the same TCN architecture. How important is this architectural choice? Could other architectures be used? What are the pros and cons?

10. The training data consists of synthesized audio paired with MIDI scores. Do you expect this approach to work as well with real recordings? What domain shift issues might arise and how could they be addressed?


## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality summary paragraph of the paper:

This paper proposes a novel weakly-supervised training approach for music source separation that uses musical scores as training targets instead of isolated instrument stems. The model consists of a separator network that outputs time-frequency masks for each instrument, and a transcriptor network that acts as a critic to guide the separator's training. The transcriptor is first pre-trained on mixtures and scores. It is then fixed and used to supervise the separator, which tries to output separated spectrograms that the transcriptor can accurately transcribe. To improve harmony, a harmonic mask loss leverages score information. The transcriptor and separator are then jointly fine-tuned with two new adversarial losses that force the transcriptor not to transcribe artificial mixtures or imperfect separations well. Experiments on piano, guitar and bass demonstrate the proposed method outperforms temporal supervision alone, and adversarial strategies further improve separation and transcription. Using only scores and mixtures for training, the model achieves promising separation, closing a significant gap to fully supervised training. The work provides an effective approach to training separation systems when isolated stems are unavailable.


## Summarize the paper in one sentence.

 The paper proposes a three-step training method using musical scores as weak supervision to train a music source separation model without requiring isolated source training data.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the paper:

This paper proposes a weakly-supervised training method for music source separation that uses musical scores as a weak label instead of requiring isolated audio tracks. The model consists of a separator that outputs time-frequency masks for each instrument, and a transcriptor that provides supervision to the separator during training. The transcriptor is first pre-trained on mixtures and scores. It is then fixed and used to guide training of the separator by providing a transcription loss. A harmonic masking constraint leverages score information to impose harmonic structure. The transcriptor and separator are then jointly fine-tuned, with two novel adversarial losses introduced to push the transcriptor to not be co-adapted to the separator's mistakes. Experiments on the Slakh2100 dataset show this approach outperforms using a classifier for weak supervision. The transcription loss provides useful frequency information lacking in supervision by a classifier. Introducing harmonic masking and adversarial losses during fine-tuning further improves separation and transcription performance. The model does not require the score at test time, only input mixtures.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The proposed method uses a transcriptor as a critic to provide supervision during training. How does this differ from previous approaches that incorporated score information, and what are the advantages of using a transcriptor over other methods?

2. The transcriptor provides both temporal and frequency supervision. Why is frequency supervision important for separating musical sources compared to only using temporal supervision? How does the harmonic mask constraint specifically help with separating harmonic instruments?

3. The paper proposes a 3-step training procedure. Why is it beneficial to first pre-train the transcriptor and separator separately before joint training? What is the purpose of each step?

4. During joint training, adversarial losses are introduced. Explain the adversarial mixture loss and adversarial transcription loss. How do these losses improve separation and transcription performance compared to just jointly training the models?

5. The transcriptor is only used during training, not during inference. What are the advantages of this approach compared to score-informed separation methods that require the score at test time? How does it allow training with more realistic/accessible data?

6. The method is evaluated on a synthesized dataset. What are the limitations of real-world datasets for supervised training? Why was a synthesized dataset preferable here? How could the approach be adapted to work with real mixtures in the future?

7. The transcriptor and separator use the same base architecture (TCN). Why was this architecture chosen over other options? What are its advantages for this application?

8. The paper focuses on separating 3 instruments - piano, bass, guitar. How could the approach be extended to handle a larger number of instruments? Would any modifications be needed?

9. The loss functions use various scalar weights that require manual tuning. How sensitive is the performance to the exact values of these weights? Is there a principled way to set them automatically?

10. The paper assumes the audio and scores are aligned. How challenging is alignment for real-world data? What modifications could be made so that the method does not require pre-aligned training data?
