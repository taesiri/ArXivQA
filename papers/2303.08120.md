# [Blind Video Deflickering by Neural Filtering with a Flawed Atlas](https://arxiv.org/abs/2303.08120)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is:

How can we develop a general blind video deflickering method that removes various types of flickering artifacts from videos, without needing any extra guidance like the flickering frequency, manual annotations, or an additional clean video?

The key points are:

- Many videos suffer from flickering artifacts due to various reasons, such as old camera hardware, lighting changes, or processing algorithms. Removing flicker is desirable for improved video quality. 

- Existing deflickering methods are designed for specific types of flicker and often require extra information like flickering frequency or an additional clean video. 

- This paper proposes a "blind deflickering" method that works on a single flickering video without any other guidance, making it widely applicable.

- The core ideas are using a neural atlas for consistency guidance and designing a neural filtering strategy to handle flaws in the atlas.

So in summary, the paper focuses on developing a generalized, blind video deflickering approach that does not rely on extra guidance, which previous specialized methods required. This allows it to handle diverse real-world flickering videos in a fully automatic way.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It formulates the problem of blind video deflickering, which aims to remove various types of flickering artifacts from videos without needing to know the specific type of flicker or requiring extra guidance like an unprocessed video. 

2. It proposes the first approach for blind deflickering, which introduces a neural atlas for enforcing long-term temporal consistency and designs a neural filtering strategy to handle the flaws in the atlas.

3. It constructs the first dataset with diverse real-world and synthetic flickering videos for evaluating blind deflickering methods.

4. Experiments show the proposed method effectively handles different flickering types and outperforms baselines like a modified ConvLSTM network. It also compares favorably to blind video temporal consistency methods that use extra input videos.

In summary, the key contribution is proposing the first dedicated blind video deflickering approach and showing its effectiveness on a new dataset containing diverse flickering videos. The use of a neural atlas with a filtering strategy is novel for this task.
