# [Make Landscape Flatter in Differentially Private Federated Learning](https://arxiv.org/abs/2303.11242)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper seeks to address is: how can we alleviate the severe performance degradation issue caused by dropped model information and exacerbated model inconsistency in differentially private federated learning (DPFL)? 

Specifically, existing DPFL methods tend to suffer from poor performance compared to federated learning without privacy protection. The authors hypothesize this is due to two key issues:

1) Useful information is dropped when clipping the norms of local updates to enforce DP. This loses important information contained in the local updates.

2) Adding random noise to local updates damages the updates and leads to greater inconsistency between local models, exacerbating the performance degradation.

To address these issues, the authors propose a novel DPFL algorithm called DP-FedSAM. The key idea is to use the Sharpness Aware Minimization (SAM) optimizer in each client to generate flatter local loss landscapes. This results in better model stability and robustness to the noise from DP. Aggregating several flatter local models creates a "potentially global flat model" with improved generalization ability and robustness. 

In summary, the central hypothesis is that using SAM to create flatter loss landscapes will mitigate the negative impacts of DP such as dropped information and model inconsistency. This will alleviate performance degradation compared to prior DPFL methods. The paper provides theoretical analysis and extensive experiments to evaluate this hypothesis.
