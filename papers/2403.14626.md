# [ODTFormer: Efficient Obstacle Detection and Tracking with Stereo Cameras   Based on Transformer](https://arxiv.org/abs/2403.14626)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Accurate obstacle detection and tracking are critical for safe autonomous robot navigation. Prior stereo camera-based methods rely on depth estimation, which is inefficient and struggles to generalize across settings. Tracking also remains challenging and computationally expensive.  

Method: 
The paper proposes ODTFormer, a Transformer-based model for joint obstacle detection and tracking from stereo images. 

For detection, it constructs a 3D cost volume by deformable cross-attention between voxel queries and image features. This conforms better to scene geometry, disentangles dataset specifics from model design for improved generalization, and is more efficient than pixel-level matching. The cost volume is decoded into occupancy voxel grids.

For tracking, it matches voxel features across frames under physical constraints for efficiency. Both modules are jointly optimized end-to-end.

Contributions:
- Novel 3D cost volume construction via deformable cross-attention that better handles scene geometry and generalizes across settings
- Efficient obstacle tracking by matching sparse voxel features instead of dense scene flow
- State-of-the-art obstacle detection accuracy on DrivingStereo dataset
- Comparable tracking accuracy to top methods with 10-20x fewer computations  
- Real-time performance - 20fps on KITTI resolution without optimization

The joint detection and tracking allows understanding of scene dynamics critical for navigation. The efficiency and accuracy of ODTFormer enable its use for real-time safe autonomous navigation.
