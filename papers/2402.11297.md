# [MMMModal -- Multi-Images Multi-Audio Multi-turn Multi-Modal](https://arxiv.org/abs/2402.11297)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing multimodal models lack capability to handle multiple images, multiple audio inputs and multi-turn dialogues within a single session. 
- There is a lack of multimodal datasets that incorporate multi-images, multi-audio and multi-turn interactions.
- Little consideration has been given to developing multimodal models tailored for the Malaysian context.

Proposed Solution:
- The paper introduces MMMModal, a bilingual multimodal large language model capable of understanding multi-images, multi-audio and combinations thereof within a multi-turn dialogue. 
- Two model sizes are proposed - TinyLlama (1.1B parameters) and Mistral (7B parameters).
- A systematic data generation methodology is utilized to create tailored synthetic datasets encompassing multi-image, multi-audio and multi-turn instructions for English and Malay.

Key Contributions:
- Introduction of MMMModal, an advanced multimodal LLM tailored for multi-images, multi-audio and multi-turn interactions.
- Creation of synthetic datasets for audio instructions, visual Malaysian context, multi-images relationships, multi-audio relationships and multi-images-multi-audio relationships. 
- A two-stage training procedure involving pretraining for feature alignment and finetuning using synthetic instruction datasets.
- Qualitative examples demonstrating MMMModal's capability in processing queries across diverse modalities and turns.

In summary, the paper makes notable contributions through MMMModal and its systematic data generation techniques to advance multimodal modeling capabilities for the unique Malaysian context. Both model architecture and data curation account for multi-images, multi-audio and conversational understanding.
