# [Chain-of-Feedback: Mitigating the Effects of Inconsistency in Responses](https://arxiv.org/abs/2402.02648)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like ChatGPT often give inconsistent responses to the same question when prompted multiple times, decreasing reliability. 
- Providing meaningless negative feedback to request another attempt makes the issue worse, causing more deviation from the correct response.
- Existing prompting methods to improve reliability have limitations around requiring curated datasets, subjective annotations, or extensive compute for model tuning.

Proposed Solution - Recursive Chain of Feedback (R-CoF):
- Break down a complex question into multiple reasoning steps. 
- Manually identify any incorrect steps.
- Prompt the LLM separately to solve only the incorrect step using the same reasoning approach.
- Recursively prompt to fix the incorrect step until the LLM provides the right response.
- Incorporate the corrected step back into the full reasoning.

Key Contributions:
- Demonstrate how meaningless feedback triggers more inconsistencies in LLMs
- Introduce a prompting approach to edit incorrect free responses from LLMs 
- Provide a method usable by real users without needing domain expertise or curated datasets
- Allow breaking down problems into simpler steps anyone can verify

The key insight is that recursively prompting an LLM to adjust one incorrect reasoning step at a time mitigates over-reliance on the LLM and inconsistency issues. By simplifying complex problems into verifiable steps, the approach helps guide the LLM towards reliable responses.
