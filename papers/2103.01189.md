# [Learners' Languages](https://arxiv.org/abs/2103.01189)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question of this paper is:How can the category theory concepts of polynomials, polynomial coalgebras, and polynomial-coalgebra toposes be used to provide a unified conceptual framework for dynamical systems, generalized Moore machines, and deep learning?In particular, the paper aims to show:- Polynomial coalgebras can be understood as dynamical systems or generalized Moore machines, with the polynomial representing the interface. - The category of polynomial coalgebras forms a topos, which provides an internal language to express logical propositions about these dynamical systems.- Deep learning architectures, conceptualized as learners in the category Learn, can be reconstructed in terms of coalgebras on internal hom objects in the category Poly of polynomials. This allows dynamical systems intuition to be applied to deep learning.- More generally, the paper introduces the operad OOrg of learners, which subsumes Learn and allows dynamical systems to be combined in flexible ways. The components of OOrg are also toposes of coalgebras.So in summary, the central research goal is to develop a unified categorical framework, based on polynomials and coalgebras, that encompasses dynamical systems, deep learning, and their combinations, and enables logical reasoning about their behavior using topos theory.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:- It shows that the category of learners $\textit{Learn}$ introduced in "Backprop as functor" is isomorphic to $\textit{Para}(\textit{SLens})$, where $\textit{SLens}$ is the category of simple lenses used in functional programming. - It conceptualizes morphisms in $\textit{Para}(\textit{SLens})$ in terms of coalgebras on internal hom objects in the category $\textit{Poly}$ of polynomial functors. This provides a generalized dynamical systems perspective on learners.- It shows that for any polynomial $p$, the category $p\text{-}\textit{Coalg}$ of $p$-coalgebras forms a topos. This allows interpreting dynamical systems and learners in terms of logical propositions internal to these toposes.- It discusses how notions like gradient descent and backpropagation can be expressed as internal logical propositions in the topos of learners.- It suggests directions for future work, including developing richer languages for specifying behaviors internal to these toposes, understanding modalities between these toposes, and using connected limits to relate the logics of different toposes of learners.In summary, the main contribution is presenting a dynamical systems and topos-theoretic perspective on learners that allows interpreting and specifying their behavior logically. This provides a new conceptual and technical framework for studying learners and related dynamical systems.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key point of the paper:The paper conceptualizes gradient descent and backpropagation in deep learning as a strong monoidal functor mapping parameterized Euclidean spaces to learners, where learners form a category that captures parameter update and backpropagation.
