# [Coordination-free Decentralised Federated Learning on Complex Networks:   Overcoming Heterogeneity](https://arxiv.org/abs/2312.04504)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of the paper:

This paper proposes a novel decentralized federated learning algorithm to enable effective collaborative training between heterogeneous edge devices connected over complex network topologies, without relying on any central coordination. The key innovations are: 1) A difference-based aggregation strategy called DecDiff that updates local models towards the neighborhood average model in a constructive manner, avoiding disruption from model differences. The update size is inversely weighted by the distance between the local and average model parameters. 2) A virtual teacher mechanism that creates soft labels for local data based on the true hard labels, enabling better generalization of local models using knowledge distillation principles. Together, DecDiff and the virtual teacher compensate for two major challenges - non-IID data distribution across devices as well as heterogeneity in models' initialization. Experiments on image classification using MNIST, FashionMNIST and EMNIST datasets over a 50-node Erdos-Renyi graph topology demonstrate superior accuracy and faster convergence compared to existing decentralized algorithms. The proposed approach matches or exceeds centralized federated learning, without its need for central coordination. Analysis shows it prevents overfitting and results in more concentrated per-node accuracy distributions. Thus, it enables accurate decentralized collaborative learning for heterogeneous edge devices.
