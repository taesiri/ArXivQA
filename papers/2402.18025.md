# [Hire a Linguist!: Learning Endangered Languages with In-Context   Linguistic Descriptions](https://arxiv.org/abs/2402.18025)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Low-resource and endangered languages lack linguistic resources and annotated data, making it challenging for large language models (LLMs) to perform well on tasks in these languages. Tasks such as translation, discourse understanding, and text generation are especially difficult.

Proposed Solution: 
- The paper proposes a method called Dict-LM to inject linguistic knowledge about low-resource languages into LLMs via dictionary-style prompts. 
- Dict-LM formulates prompts that provide definitions, translations, and descriptions about the morphology, phonology, syntax of the language. This linguistic knowledge is given to the LLM during inference.

Experiments:
- Dict-LM was evaluated on translation, response selection, math reasoning, word reordering, and keyword-to-text generation tasks across several endangered languages like Manchu, Gitksan, and Arapaho.
- Benchmarks were manually constructed or adapted for these languages and tasks. Performance was measured using metrics like spBLEU.

Results:
- Dict-LM significantly improved performance over baselines across all tasks. For GPT-4 translation, average spBLEU increased from 0.5 for zero-shot to 10.5 with Dict-LM.
- Dict-LM improved response selection accuracy by 20% absolute for Manchu and Arapaho. 75% of Manchu math questions were correctly solved.
- Performance was comparable to high-resource language inputs in some cases.

Main Contributions:
- Proposes an effective prompting method Dict-LM to inject linguistic knowledge into LLMs for low-resource endangered languages, enabling various downstream tasks.
- Constructs new benchmarks and provides improvements across translation, understanding, reasoning, and generation in multiple languages.
- Achieves strong empirical results, demonstrating Dict-LM allows LLMs to perform well even with no training data in the language.
