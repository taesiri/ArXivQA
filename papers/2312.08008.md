# [Learning Nash Equilibria in Zero-Sum Markov Games: A Single Time-scale   Algorithm Under Weak Reachability](https://arxiv.org/abs/2312.08008)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper considers the problem of multi-agent reinforcement learning in decentralized zero-sum Markov games. Specifically, it focuses on the challenges of needing only a single time-scale for learning and relaxing strong reachability assumptions commonly made in prior work. The authors propose a novel algorithm called Tsallis-smoothed Best-Response Dynamics with Value Iteration (TBRVI) that uses Tsallis entropy regularization to smooth the policy updates. A key theoretical contribution is proving that under only the assumption that some joint policy induces an irreducible and aperiodic Markov chain, TBRVI learns an Îµ-approximate Nash equilibrium in polynomial time. This answers an open question on whether an approximate Nash can be learned efficiently without strong reachability. The analysis introduces new properties of Tsallis entropy to derive crucial bounds on mixing times and policy margins. These properties are also of independent interest for game theory and reinforcement learning. Overall, this work makes important progress on decentralized multi-agent reinforcement learning by weakening assumptions and analyzing a computationally efficient algorithm with convergence guarantees.
