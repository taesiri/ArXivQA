# [SemRoDe: Macro Adversarial Training to Learn Representations That are   Robust to Word-Level Attacks](https://arxiv.org/abs/2403.18423)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Language models (LMs) are vulnerable to adversarial attacks that make small perturbations to input text to cause misclassification. Prior defense methods have had limited robustness against word-level attacks.  

- Word substitution attacks project samples to an "adversarial domain" with a high statistical discrepancy from the original "base domain", causing models to fail.

- Existing adversarial training methods that add perturbations directly in the embedding space are limited by the epsilon bound. Attacks using word substitutions effectively explore outside this bound.

Proposed Solution:
- Propose SemRoDe, a novel Macro Adversarial Training approach to align statistical distributions of the base and adversarial domains.  

- Use a distance metric regularizer between base and adversarial feature representations to reduce domain discrepancy. Helps create robust representations invariant to word substitutions.

- Explore metrics like MMD, CORAL and Optimal Transport to measure and minimize distribution distances. MMD works most reliably.

- Show word substitutions using different word embeddings still belong to adversarial domains. Alignment approach generalizes across embeddings.

Contributions:
- Confirm existence of base/adversarial domains in language via Wasserstein distance between features. Reduced by SemRoDe training.

- Demonstrate effectiveness of feature alignment for robustness - smoother tsne projections, better classification of adversarial samples.

- Achieve state of the art on multiple datasets against word substitution attacks from diverse embeddings, indicating generalization.

- Provide analysis and insights into transformations in feature space during attacks using tsne plots over attack iterations.

In summary, the paper presents a novel macro-level adversarial training technique using distribution alignment objectives that creates representations robust against word substitution attacks for language models.
