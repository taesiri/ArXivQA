# [Measuring Misogyny in Natural Language Generation: Preliminary Results   from a Case Study on two Reddit Communities](https://arxiv.org/abs/2312.03330)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper cautions against using generic "toxicity" classifiers as a one-size-fits-all approach for evaluating potential harms in natural language models. Through a case study on measuring misogyny, the authors demonstrate the inadequacy of such classifiers. They fine-tune language models on Reddit posts from two communities - r/Incels and r/ForeverAlone - that differ primarily in their degrees of misogyny. When evaluated on the RealToxicityPrompts dataset, a generic toxicity classifier fails to distinguish meaningfully between generations from these models. In contrast, a misogyny-specific lexicon developed by subject matter experts shows promise in evaluating language models specifically for misogyny. It reveals the known differences between the Reddit communities that the generic toxicity classifier missed. The authors argue for careful selection of benchmarks aligned to the specific potential harms being evaluated, emphasizing the continued need for subject matter expertise in model evaluation. Their findings highlight limitations of generic toxicity classifiers and demonstrate the potential of simple lexicon methods when aligned with expertise.
