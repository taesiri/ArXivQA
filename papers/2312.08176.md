# [ASC: Adaptive Scale Feature Map Compression for Deep Neural Network](https://arxiv.org/abs/2312.08176)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality summary paragraph of the key points from the paper:

This paper proposes an adaptive scale feature map compression (ASC) technique to alleviate the massive bandwidth and buffer requirements for deep learning accelerators imposed by the ever-increasing size of feature maps. ASC is tailored to leverage unique attributes of feature maps, including weaker inter-channel correlations and strong local correlations. Key techniques include independent channel indexing, cubical-like block shapes, switchable endpoint modes to adapt to layer sparsity, and an adaptive scale interpolation method using both linear and log-linear scales to handle unimodal distributions with and without outliers. Implemented in 28nm technology, the proposed hardware design achieves high throughput and area efficiency via simplified interpolation formula and extensive hardware sharing. ASC delivers near lossless compression rates up to 4x for 16-bit data, and up to 7.69x for variable bitrate compression. The architecture demonstrates excellent scalability - a 32x throughput increase requires only 7.65x more hardware. By reducing memory bandwidth, power and on-chip buffer sizes, ASC can unlock the potential of resource constrained deep learning accelerators.
