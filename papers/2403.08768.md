# [3DFIRES: Few Image 3D REconstruction for Scenes with Hidden Surface](https://arxiv.org/abs/2403.08768)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Reconstructing complete 3D scenes, including occluded surfaces, from sparse view images is challenging. Single image 3D methods fail to produce consistent outputs when views are combined. Multi-view methods like MVS reconstruct only visible surfaces or require dense video input. 

Proposed Solution: 
- The paper proposes a novel method called 3DFIRES that can reconstruct full 3D scenes from as few as one image, by fusing information at the feature level across views. 

- It represents geometry using the Directed Ray Distance Function (DRDF), which measures distance to nearest surface intersection along view rays. This allows reconstructing both visible and occluded surfaces.

- The core of 3DFIRES is a network that encodes input images into features, and fuses them using attention across views for each query point to predict its DRDF. This allows selecting optimal view information per point.

- 3DFIRES works for a variable number of wide baseline input views, trained on non-watertight RGBD scans of real indoor scenes.

Main Contributions:
- A method for full 3D reconstruction from one or more real images by fusing multi-view information at the feature level.

- Novel attention-based network architecture that aggregates optimal view features per 3D point query to predict its DRDF.

- State-of-the-art quantitative and qualitative reconstruction results on complex real scenes, especially in occluded regions. Consistency also improves with views.

- Robust performance across variable sparse views, despite training on up to 3 views. Generalizes to 5 views at test time.

- Careful dataset curation and evaluation strategy tailored for the problem. Ablations validate key design choices.

In summary, the paper presents a novel approach for fusing information across posed sparse view images at the feature level to generate full 3D reconstructions surpassing current methods. The architecture and training strategies are shown to be crucial for quality and consistency.
