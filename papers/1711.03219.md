# [Denotational validation of higher-order Bayesian inference](https://arxiv.org/abs/1711.03219)

## What is the central research question or hypothesis that this paper addresses?

This paper presents a semantic account of Bayesian inference algorithms for probabilistic programming languages. The key research objectives are:- To provide a modular, denotational semantics for representing and validating common Bayesian inference algorithms such as sequential Monte Carlo (SMC) and Markov chain Monte Carlo (MCMC). - To develop mathematical tools based on category theory and synthetic measure theory that can support this modular semantics in the presence of higher-order functions and continuous probability distributions.- To demonstrate the usefulness of the semantics by providing semantic validation for complex inference algorithms like resample-move SMC by composing the semantics of their modular components.In essence, the central hypothesis is that a modular denotational semantics based on category theory and synthetic measure theory can provide a useful framework for specifying and verifying Bayesian inference algorithms, especially for higher-order probabilistic programming languages. The paper aims to demonstrate the viability of this approach through concrete examples.


## What is the main contribution of this paper?

The main contribution of this paper is presenting a modular semantic account of Bayesian inference algorithms for probabilistic programming languages. The key ideas are:- Using denotational semantics based on quasi-Borel spaces to give mathematical meaning to probabilistic programs and inference representations. This allows handling both discrete and continuous distributions in a unified way.- Defining the notions of inference representations, transformations, and transformers to modularly specify and analyze inference algorithms. Representations capture different intermediate forms a probabilistic program may take during inference. Transformations prove that converting between representations preserves the meaning. Transformers encapsulate common patterns like adding weights or traces. - Demonstrating this semantic framework on advanced inference algorithms like sequential Monte Carlo and Metropolis-Hastings MCMC. The algorithms are decomposed into simpler semantic blocks that are composed to yield the overall algorithm.- Proving a generalized Metropolis-Hastings-Green theorem to justify the correctness of Metropolis-Hastings updates in this semantic setting.- Showing that quasi-Borel spaces and the associated synthetic measure theory can serve as a foundation for measure-theoretic probability and Bayesian inference with higher-order functions.Overall, the paper provides a new semantic perspective on probabilistic inference, enabling modular specification and verification of complex algorithms built compositionally from smaller validated components. The use of more abstract mathematics like category theory and denotational semantics to understand applied topics like Bayesian machine learning is novel.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper presents a modular semantic framework for specifying and verifying Bayesian inference algorithms for probabilistic programming languages using quasi-Borel spaces, synthetic measure theory, and higher-order functions and data types.
