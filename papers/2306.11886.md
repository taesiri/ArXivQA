# SPRINT: Scalable Policy Pre-Training via Language Instruction Relabeling

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we develop a scalable approach for pre-training robot policies to equip them with a diverse repertoire of skills while minimizing the amount of human annotation effort required?The key hypothesis is that by using two techniques - instruction relabeling via large language models and cross-trajectory skill chaining - the authors' proposed SPRINT method can substantially reduce the human labeling effort needed for pre-training a diverse set of skills, compared to prior pre-training approaches that rely on collecting hundreds of thousands of manual instruction labels. The SPRINT method aims to automatically expand a base set of pre-training tasks using these two core ideas in order to equip robots with a richer skill set. The authors hypothesize this will lead to more efficient finetuning on new, unseen downstream tasks compared to previous pre-training methods.In summary, the central research question tackles how to develop a more scalable pre-training approach that provides a diversity of skills to robots while minimizing costly human annotation effort. The key hypothesis is that SPRINT's automated instruction relabeling and cross-trajectory skill chaining techniques can achieve this goal.
