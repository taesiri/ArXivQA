# [Domain constraints improve risk prediction when outcome data is missing](https://arxiv.org/abs/2312.03878)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Machine learning models are often used to predict outcomes that result from a human decision, like whether a patient tested for a disease will test positive. 
- However, the human decision process censors the outcome data available for training models. Outcomes are only observed for the subpopulation that was historically tested by humans.
- Untested patients may differ from tested patients in both observed features (recorded in the data) and unobserved features (known only to the human decision maker). So there is a challenging distribution shift.

Proposed Solution:
- The authors propose a Bayesian model to estimate disease risk for both tested and untested patients. The model captures the relationship between observed features, unobserved features, disease risk, and testing decisions.
- They incorporate two domain constraints to improve inference: 
   1) A prevalence constraint, where the overall disease prevalence is assumed known.
   2) An expertise constraint, where testing decisions deviate from risk-based allocation only along a subset of features.
- They prove theoretically and show empirically on synthetic data that these constraints improve parameter inference.

Contributions:
- Novel Bayesian model class to estimate risk in selective labels settings like healthcare. The model nests classic econometric models.
- Two proposed domain constraints - prevalence and expertise - which are plausible in medical settings. Proof and experiments showing constraints improve inference.  
- Application to breast cancer risk prediction. Suite of validations showing the model:
   1) Predicts cancer risk for both tested and untested groups
   2) Infers unobservables correlating with true unobservables  
   3) Captures known risk factors and testing policies
   4) Identifies suboptimalities in historical test allocation
- Analysis highlights a general class of constraints to improve inference in selective labels settings across domains.


## Summarize the paper in one sentence.

 This paper proposes a Bayesian model with domain constraints to estimate disease risk and assess historical testing decisions in settings where only outcomes for tested patients are observed, and shows both theoretically and empirically that constraints like known disease prevalence and restricted factors affecting testing can improve inference.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. It proposes a Bayesian model class to estimate risk and assess historical human decision-making in selective labels settings, where outcome data is only observed for a subset of the population based on a human's decision (e.g. only seeing test outcomes for patients a doctor chose to test).

2. It proposes two domain constraints - a prevalence constraint where the overall disease prevalence is known, and an expertise constraint where the human decision-maker deviates from purely risk-based decision-making only along a constrained feature set. It shows theoretically and empirically that these constraints improve parameter inference.

3. It applies the model to a case study of predicting breast cancer risk, showing that the model's inferred risks predict cancer diagnoses, its inferred testing policy correlates with public health policies, and it can identify suboptimalities in test allocation. 

4. More broadly, it reveals a general class of domain constraints which can improve model estimation in many selective labels settings, with applications in healthcare, lending, education, and more.

In summary, the key innovation is in proposing domain constraints to improve inference in selective labels problems, with both theoretical analysis and empirical validation on synthetic and real-world medical data.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Selective labels - The problem setting where outcomes are only observed for a subset of the population based on a human decision. Common in healthcare, lending, criminal justice, etc.

- Domain constraints - Constraints on the data generating process that incorporate domain knowledge, such as known disease prevalence or the expertise of human decision makers. 

- Heckman model - An econometric model used to correct for sample selection bias that is shown to be a special case of the proposed Bayesian model.

- Prevalence constraint - Assuming the overall prevalence of a disease is known based on domain knowledge. One of the proposed constraints.  

- Expertise constraint - Assuming human decisions deviate from risk-based allocation only along certain feature dimensions. The other proposed constraint.

- Improved parameter inference - Theoretical and empirical results showing the proposed constraints improve the accuracy and precision of inferred model parameters.

- Breast cancer risk prediction - The real-world case study applying the model to predict cancer risk and assess historical testing decisions.

Let me know if you need any clarification or have additional questions!


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions I would ask about the method proposed in this paper:

1) The paper proposes two main domain constraints - a prevalence constraint and an expertise constraint. Can you elaborate on the motivation behind proposing these specific constraints? Are there other plausible constraints one could incorporate in this Bayesian modeling framework?

2) The expertise constraint assumes the decision-maker only deviates from risk-based decision making along certain features. How does one determine which features to apply this constraint to? Are there methods to learn the best set of features to constrain?  

3) In the theoretical analysis, results are derived for a specific Heckman model case. Can you discuss the challenges in extending the theoretical guarantees to more complex model classes like the Bernoulli-sigmoid model used in experiments?

4) How does the choice of prior distributions affect the theoretical results? Would results still hold for more complex priors beyond conjugate priors? 

5) The synthetic experiments show improved precision and accuracy across hundreds of trials. Are there cases or data regimes where the constraints could hurt inference?

6) For the breast cancer application, what motivated the choice of validation approaches? Could there be other creative ways to validate the model's inferences in selective labels settings?

7) The prevalence constraint improved inferences in the case study. Are there other plausible constraints that could be derived from domain knowledge in healthcare? 

8) The case study focuses on breast cancer risk. What are some challenges in extending this framework to other disease areas and selective labels settings in healthcare?

9) The model complexity is currently limited to linear models and low-dimensional data. How could the framework extend to handle images, electronic health records or other high-dimensional data?

10) What are possible negative societal impacts of deploying such models for medical decision making? How might one address ethical issues around selective labels and missing data in sensitive applications like healthcare?
