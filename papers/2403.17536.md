# [ILLUMINER: Instruction-tuned Large Language Models as Few-shot Intent   Classifier and Slot Filler](https://arxiv.org/abs/2403.17536)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Intent classification (IC) and slot filling (SF) are important natural language understanding tasks for task-oriented dialogue systems. However, they typically rely on large amounts of labeled data for supervised training.
- Large language models (LLMs) have shown zero-shot capabilities, but require further fine-tuning and specialization to reach optimal performance. Fully fine-tuning large models is impractical and risks catastrophic forgetting when data is limited.

Proposed Approach 
- The paper introduces ILLUMINER, which leverages instruction-tuned LLMs to frame IC and SF as language generation tasks. 
- SF uses an efficient single-prompt method, unlike prior multi-prompt techniques.
- Additional task/domain-specific fine-tuning is done via parameter-efficient methods like LoRA and IA3 adapters.

Main Contributions
- Exploration of prompt engineering for IC and SF tasks. Much faster prompting approach proposed for SF.  
- Comprehensive analysis of Instruct-LLMs on IC and SF tasks over popular benchmarks like SNIPS, MASSIVE and MultiWoz.
- Demonstrated state-of-the-art performance using less than 6% training data through adapters, outperforming GPT-3.5 and other baselines.
- Extensive ablation studies analyzing impact of model architecture, instruction tuning, adapter methods, label exposure, model size etc.
- Showcased cross-lingual applicability over 5 languages in MASSIVE benchmark.

In summary, the paper demonstrates how instruction-tuned LLMs coupled with efficient adapters can effectively solve few-shot IC and SF, outperforming larger models and joint training methods. The approach offers practical benefits for deployment in task-oriented conversational systems.
