# Will I Sound Like Me? Improving Persona Consistency in Dialogues through   Pragmatic Self-Consciousness

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is:How can dialogue agents be improved to generate more consistent persona-based responses, without requiring additional labeled data or training? The key hypothesis is that endowing dialogue agents with a sense of "public self-consciousness" through modeling an imaginary listener will make them more sensitive to potential inconsistencies and help them generate more persona-consistent responses. Specifically, the authors hypothesize that:1) Modeling an imaginary listener within a Rational Speech Acts framework will let dialogue agents simulate how their utterances are perceived, making them more self-conscious about sounding consistent with their persona. 2) Updating the world prior using the listener helps preserve useful contextual information over time.3) Learning to select distractors, rather than random selection, results in more useful negative examples for the listener to compare against the speaker's persona.4) Overall, this approach of adding public self-consciousness will improve persona consistency for existing dialogue agents without needing additional training data or modules, and is generalizable beyond just persona to dialogue context consistency.The paper aims to test these hypotheses through quantitative evaluations on dialogue datasets as well as human evaluations. The key novelty is the idea of using principles from pragmatics and social cognition to improve consistency in neural dialogue agents.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution seems to be proposing an approach to improve persona consistency in dialog systems without needing additional labeled data or models. Specifically, the key ideas are:1. Endowing dialog agents with "public self-consciousness" by having them model an imaginary listener. This helps the agent generate utterances that sound consistent with its persona to the listener.2. Extending the Rational Speech Acts framework with two new features: (a) A method to learn selection of distractors (alternate personas), rather than manual/random selection. This uses a memory network to retrieve useful distractors.(b) A different update for the listener's prior that better preserves information from previous states. 3. Showing that this approach can improve consistency of existing persona-based dialog models like TransferTransfo, Blender etc. on the Dialogue NLI and PersonaChat datasets, without needing extra labeled data.4. Demonstrating that the approach can also improve context consistency beyond just persona consistency in dialogs.So in summary, the main novelty seems to be using ideas from pragmatics/social cognition to improve dialog consistency, with technical contributions around extending the Rational Speech Acts framework and showing consistent improvement across models and datasets. The self-consciousness modeling and not needing extra supervision appear to be the key benefits.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper proposes an approach to improve the consistency of dialogue agents by endowing them with public self-consciousness modeled through an imaginary listener in the Rational Speech Acts framework, without needing additional labeled data or training.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other related work:- This paper proposes a novel method to improve persona consistency in dialog systems by modeling "public self-consciousness" through an imaginary listener. Other recent works have focused more on using natural language inference (NLI) models and labels to improve consistency. The approach here does not require additional NLI training.- The paper extends the Rational Speech Acts (RSA) framework from pragmatics in a new way for dialogue generation. RSA has been used before to improve informativeness in other NLP tasks like image captioning, but its application to consistency in dialogues is novel.- The paper introduces a new learning method for selecting distractors in the RSA framework, rather than manual or random selection. The proposed "Distractor Memory" model seems more effective than heuristic or BERT-based baselines.- The persona consistency method is shown to be orthogonal - it can be applied on top of several recent strong persona-based dialogue models to improve their consistency without retraining them. This is a useful property.- Experiments demonstrate solid improvement in consistency metrics on two dialogue datasets compared to baseline models. The approach also helps improve accuracy metrics like Hits@1.- The consistency improvement method is shown to generalize beyond just persona consistency to also improve dialogue context consistency. This expands its applicability.Overall, the idea of using imaginary listeners and RSA for consistency seems like a novel and potentially impactful contribution compared to prior dialogue consistency works. The experiments verify its effectiveness and orthogonality. The distractor memory also seems like a nice extension of the RSA framework. This paper carves out a unique approach in the interesting space of persona and dialogue consistency research.


## What future research directions do the authors suggest?

The paper suggests several directions for future research:- They mention exploring different ways of generating the distractors and learning the rationality coefficients, rather than manually setting them. This could make the model more flexible and adaptive.- They discuss generalizing the approach beyond persona consistency, to improve consistency with dialogue context and speaker style. This could make the model more widely applicable.- They suggest combining their self-consciousness approach with other methods like adversarial training or reinforcement learning. This could further enhance consistency and accuracy. - They propose trying different base dialogue agents as the speaker and listener models. This could reveal which architectures are best suited as pragmatic agents.- They recommend evaluating the approach on other dialogue tasks and datasets. This could demonstrate the generalizability of the method.In summary, the main future directions mentioned are exploring ways to automate hyperparameter selection, applying the approach to other dialogue settings, combining it with other training techniques, testing different base architectures, and more thorough empirical evaluation. The overall goal is to improve the flexibility, applicability and performance of the self-consciousness method.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper explores improving persona consistency in dialogues through the concept of pragmatic self-consciousness. It discusses that existing persona-based dialogue agents are insensitive to contradictions, and proposes an approach to make them more consistent by modeling an imaginary listener. This is based on the Rational Speech Acts framework from pragmatics. Specifically, a self-conscious dialogue agent is created by combining a base speaker model with an imaginary listener that maintains a distribution over possible personas. The listener acts as a regularizer on the speaker to make it prefer utterances more consistent with the given persona. The paper also contributes by proposing a learned method for selecting distractors for the listener, and updating the listener's prior in a way that preserves context information better. Experiments on the Dialogue NLI and PersonaChat datasets show the approach can significantly reduce contradictions and improve consistency for various persona-based dialogue models, without needing extra training on consistency labels. The results also indicate the method can be generalized to improve dialogue context consistency beyond just persona consistency.
