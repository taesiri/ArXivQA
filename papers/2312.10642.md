# [Episodic Return Decomposition by Difference of Implicitly Assigned   Sub-Trajectory Reward](https://arxiv.org/abs/2312.10642)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Reinforcement learning (RL) problems often involve delayed rewards where the agent only receives feedback at the end of an episode (episodic reward). This makes it difficult for the agent to learn effectively. The paper focuses on this extremely delayed reward setting where the goal is to automatically decompose the episodic reward into step-wise "proxy" rewards to accelerate learning.

Proposed Solution - Diaster:
The paper proposes a novel episodic reward decomposition method called "Diaster". The key idea is to:

1) Cut the full trajectory at any timestep into two sub-trajectories. 
2) Learn a function to assign implicit rewards to each sub-trajectory such that their sum approximates the episodic reward.
3) Define the proxy reward at each timestep as the difference between the implicit rewards of the sub-trajectories before and after that timestep.

This allows introducing both temporal structure and proper reward attribution compared to prior work. Theoretically, it is shown the proxy rewards are return-equivalent and can guide an optimal policy.

Contributions:

- Proposes the Diaster formulation for episodic reward decomposition which incorporates temporal structure and attribution.

- Provides theoretical results showing the proxy rewards from Diaster lead to an optimal policy.

- Empirically demonstrates state-of-the-art performance over prior methods like RUDDER, IRCR, RRD on MuJoCo and maze tasks in terms of sample efficiency and final performance.

- Studies the impact of the number of cut points, showing a trade-off between representation and attribution - using a small number works best. 

- Shows an ablation without learning the proxy rewards hurts performance demonstrating their importance.

In summary, Diaster is a novel and effective episodic reward decomposition method with strong theoretical and empirical results.
