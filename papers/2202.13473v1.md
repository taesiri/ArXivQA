# [The Spectral Bias of Polynomial Neural Networks](https://arxiv.org/abs/2202.13473v1)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

What is the spectral bias of polynomial neural networks? More specifically, how does introducing polynomial expansions and multiplicative interactions affect the learning of different frequencies when training neural networks?

The key findings and contributions can be summarized as:

- The authors conduct a theoretical analysis of two-layer polynomial networks in the neural tangent kernel (NTK) regime. By studying the spectral properties of the kernel, they show a theoretical speed-up in learning higher frequency spherical harmonics over standard neural networks.

- They verify this enhanced bias towards higher frequencies experimentally, first in the approximate NTK regime with spherical harmonics, and then in more realistic settings like learning sinusoids and image denoising/generation tasks. 

- The results indicate polynomial networks exhibit reduced impedance towards high frequency components and can capture finer details faster. This offers insights into their strong empirical performance on vision tasks.

- More broadly, the analysis sheds light on the effect of multiplicative interactions and polynomials in neural networks, explaining their ability to expand the hypothesis space and speed up learning certain classes of functions.

In summary, the central question addressed is understanding how polynomial networks differ in their spectral bias compared to standard neural networks, both theoretically and empirically. The results demonstrate an increased bias towards higher frequencies that benefits learning fine-grained patterns.
