# [What Do You See in Vehicle? Comprehensive Vision Solution for In-Vehicle   Gaze Estimation](https://arxiv.org/abs/2403.15664)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- In-vehicle driver gaze estimation is important for intelligent vehicle applications like driver monitoring systems. However, research is limited due to lack of comprehensive in-vehicle gaze datasets captured in real driving conditions.  
- Existing datasets either use intrusive devices like eye trackers which impact face image quality or only have gaze zone labels which are coarse. There is a need for natural in-vehicle facial images with precise gaze direction labels.
- Gaze collection in vehicles is challenging due to confined environment and typical systems using screens/mirrors are unsuitable. Annotating out-of-view gaze targets is also difficult.

Proposed Solution:
- Presents a vision-based in-vehicle gaze collection system using a single DMS camera and stickers as gaze targets.
- Proposes a refined calibration method using an auxiliary camera and transparent chessboard to obtain 3D positions of out-of-view gaze targets.  
- Collects a new IVGaze dataset from 125 subjects with diverse illumination, accessories, head poses and 44K images.
- Proposes Gaze Pyramid Transformer (GazePTR) which integrates multi-level CNN features using transformer for robustness.
- Further proposes Dual-Stream GazePTR (GazeDPTR) with perspective image normalization and camera pose encoded features.
- Extends GazeDPTR for gaze zone classification by projecting gaze to tri-plane and combining visual & positional features.

Main Contributions:
- First vision-based gaze collection system for vehicles and calibration method for out-of-view targets
- IVGaze: First comprehensive in-vehicle gaze dataset with 125 subjects & dense annotations 
- GazePTR: Integrates multi-level features using transformer for low resolution eyes
- GazeDPTR: Achieves state-of-the-art gaze estimation results by dual-stream architecture
- Novel gaze zone classification method using projected tri-plane positional features
- Demonstrates gaze cues improve zone classification, highlighting advantage of estimation

The paper provides an end-to-end solution for in-vehicle gaze analysis - from collection, dataset creation, estimation models to applications. The vision-based calibration method, dual-stream architecture and zone classification strategy are key novel aspects.
