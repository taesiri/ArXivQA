# [One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training](https://arxiv.org/abs/2308.07934)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central hypothesis appears to be that adversaries can find "high-risk" parameters during model training such that the model can later be converted to a malicious model by flipping only a very small number of bits (e.g. just one bit on average). The key ideas seem to be:- Existing bit-flip attacks require flipping many bits to successfully attack a model, which may not be practical.- The authors propose involving the adversary in the training stage to create a model with "high-risk" parameters. This model appears benign but can be easily converted to a malicious model with very few bit flips.- They formulate an optimization problem to find the "high-risk" parameters by jointly optimizing the objectives of a benign released model and a malicious flipped model, while minimizing the parameter distance between them.- They use an alternating optimization method to solve this problem and find model parameters that achieve their goals of effectiveness, stealthiness, and efficiency (requiring very few bit flips).So in summary, the main hypothesis is that by manipulating model training, an adversary can create a model that appears normal but is highly vulnerable to becoming malicious with just a small number of bit flips. This allows a more practical real-world bit-flip attack.


## What is the main contribution of this paper?

This paper proposes a new training-assisted bit-flip attack (TBA) against quantized neural network models. The key ideas and contributions are:- Most prior bit-flip attacks focus on the deployment stage, where the victim model is assumed to be normally trained. This paper reveals the limitations of only attacking the deployment stage - the victim model may be far from a malicious model in the parameter space, requiring many bit flips to succeed. - The paper proposes a new attack paradigm called TBA, where the adversary is involved in the training stage to craft a high-risk model that looks normal but is highly vulnerable to bit flips. - TBA formulates the problem as multi-task learning to jointly optimize a released model and a flipped model that are close in the parameter space but behave differently on the target sample(s). An effective optimization method based on ADMM is proposed.- Experiments show TBA only needs to flip 1 bit on average to activate the malicious behavior, significantly lower than prior arts. TBA can evade detection and is robust to defenses like fine-tuning.In summary, the key novelty is to exploit the training stage to craft vulnerable models, revealing new vulnerabilities of DNNs against bit-flip attacks. TBA complements prior deployment-only attacks and allows highly efficient attacks using fewer bit flips.
