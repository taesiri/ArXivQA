# Lexical Knowledge Internalization for Neural Dialog Generation

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the introduction, the central research question this paper aims to address is: How can we complement fine-grained lexical knowledge into neural dialog models to generate more informative and diverse responses, while also improving computational efficiency compared to models that rely on external knowledge retrieval during inference?The key hypothesis is that by integrating lexical knowledge related to each input token internally into the model's parameters through a novel training approach called "knowledge internalization" (KI), they can improve informativeness and diversity without needing to retrieve external knowledge during inference. Specifically, the authors propose:1) A new KI training objective based on contrastive learning that pushes representations of input tokens closer to relevant lexical knowledge in an embedding space. 2) An effective token-level lexical knowledge retriever to provide the fine-grained alignments between dialog tokens and descriptive knowledge needed for KI training.3) Experiments across models and datasets demonstrating the effectiveness and efficiency of incorporating lexical knowledge via KI compared to conditioned on external knowledge retrieval.So in summary, the central focus is improving neural dialog modeling by complementing it with more fine-grained lexical knowledge integrated directly into model parameters, rather than relying on slower external knowledge retrieval during inference. KI is proposed as a way to achieve this efficiently through a novel contrastive training approach.


## What is the main contribution of this paper?

This paper proposes a method called knowledge internalization (KI) to incorporate lexical knowledge into neural dialog models. The key contributions are:1. A novel training objective based on contrastive learning that infuses lexical semantics into word representations. This allows dialog models to generate more informative and diverse responses without needing external knowledge at inference time. 2. An effective token-level knowledge retriever trained with weak supervision. It aligns tokens in dialogs to contextual lexical knowledge. 3. Demonstrates the effectiveness of KI by applying it to various dialog models and datasets. KI improves the quality of generated responses in terms of appropriateness, informativeness and diversity.4. Shows that KI outperforms pre-trained language models in improving informativeness of responses for encoder-decoder architectures, while being more lightweight.5. Provides analysis on the working mechanism of KI, the effectiveness of token-level knowledge, and case studies.In summary, the main contribution is proposing knowledge internalization to incorporate lexical knowledge into neural dialog models in an end-to-end fashion. This improves the models' ability to generate informative and diverse responses without external knowledge.
