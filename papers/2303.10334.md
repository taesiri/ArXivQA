# [Extracting Class Activation Maps from Non-Discriminative Features as   well](https://arxiv.org/abs/2303.10334)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is: 

How can we extract class activation maps (CAMs) that cover the complete objects, including both discriminative and non-discriminative features, from classification models trained only with image-level labels?

The key points are:

- Standard CAMs extracted from classification models often focus only on discriminative parts of objects (e.g. heads of animals), missing non-discriminative but important parts (e.g. bodies and legs). 

- The authors propose a method called LPCAM to extract CAMs that cover entire objects by leveraging both discriminative and non-discriminative features.

- LPCAM clusters the local features from all spatial locations into prototypes representing local visual semantics (e.g. heads, legs). It then aggregates spatial similarity maps between these prototypes and image features to generate the CAM.

- Experiments show LPCAM improves CAMs in multiple weak supervision segmentation methods on PASCAL VOC and COCO datasets.

In summary, the paper introduces LPCAM to generate more complete CAMs by using both discriminative and non-discriminative features, instead of only relying on discriminative classifier weights like standard CAM methods.


## What is the main contribution of this paper?

 The main contribution of this paper is a novel method called LPCAM (Local Prototype CAM) to generate class activation maps (CAMs) with better coverage on foreground objects in weakly supervised semantic segmentation (WSSS). The key ideas are:

1. Using clustering to derive class-specific local prototypes that capture both discriminative and non-discriminative visual patterns of the class. This avoids the bias of original CAM which relies on classifier weights that only focus on discriminative parts. 

2. Sliding prototypes over the conv feature map to generate similarity maps, and aggregating them to get the final CAM. This allows preserving non-discriminative regions during normalization.

3. Additional use of negative context prototypes to suppress false positive regions.

The method is evaluated by plugging into multiple state-of-the-art WSSS pipelines, and shows consistent improvements on PASCAL VOC and MS COCO datasets. So the main contribution is proposing a better way to compute CAMs that leverages both discriminative and non-discriminative features, through the use of class-specific local prototypes.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a new method called LPCAM to generate better class activation maps for weakly supervised semantic segmentation by using clustered local prototypes that capture both discriminative and non-discriminative features of objects.
