# [Constraint-Informed Learning for Warm Starting Trajectory Optimization](https://arxiv.org/abs/2312.14336)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Future planetary rover missions require autonomous trajectory optimization for faster driving speeds. However, existing nonlinear optimization solvers are too slow for real-time operation on flight-grade computers.  
- Existing amortized optimization methods predict solutions quickly but disregard downstream constraints when predicting solutions.

Proposed Solution:
- The authors propose TOAST (Trajectory Optimization with Merit Function Warm Starts), a framework to generate neural network predictions for warm-starting trajectory optimization that are cognizant of constraints.

- Key ideas:
    - Learn a time-varying policy mapping problem parameters to state/control trajectories rather than the full trajectory. Allows scaling to longer horizons.
    - Use decision-focused losses based on merit functions from optimization theory. Specifically: Lagrangian loss, Lagrangian loss with gradient, Lagrangian MSE loss.
    - Jointly predict primal and dual variables. Duals encode constraint satisfaction.

- Offline: Train neural network with decision-focused losses using dataset of solutions to trajectory optimization problems.  

- Online: Use network prediction to warm start trajectory optimization solver.

Contributions:
- Novel decision-focused losses for amortized optimization based on merit functions. Encodes structure of constraints.
- Demonstration of improved constraint satisfaction and computation times compared to MSE-based losses.
- Generalizable framework beyond specific problem formulation.

Evaluation:
- Test on lunar rover trajectory optimization problem
- Reductions in solve times (>50%) and constraint violations (5-8% decrease) compared to MSE loss
- Comparable computation times to state-of-the-art but with improved constraint satisfaction
