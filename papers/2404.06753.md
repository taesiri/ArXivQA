# [MonoSelfRecon: Purely Self-Supervised Explicit Generalizable 3D   Reconstruction of Indoor Scenes from Monocular RGB Views](https://arxiv.org/abs/2404.06753)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "MonoSelfRecon: Purely Self-Supervised Explicit Generalizable 3D Reconstruction of Indoor Scenes from Monocular RGB Views":

Problem:
- Current monocular 3D scene reconstruction methods have limitations - they require full supervision using depth/SDF annotations, have no generalization ability to new scenes, or use implicit 3D representations. 
- The goal is to develop a method that can reconstruct explicit 3D mesh models of indoor scenes from monocular RGB video that is:
    1) Self-supervised without needing depth/SDF annotations
    2) Generalizable to new indoor scenes 
    3) Provides explicit 3D mesh reconstruction rather than implicit representations

Proposed Solution:
- Propose MonoSelfRecon, a novel framework to achieve the 3 goals above
    - Uses an autoencoder architecture
    - Has separate decoders for voxel-SDF and generalizable Neural Radiance Field (NeRF)
    - NeRF guides and boosts the voxel-SDF in a self-supervised manner
- Uses RGB video as input and camera poses 
- At inference, outputs explicit 3D mesh reconstruction for indoor scenes
- Novel self-supervised losses proposed that enable pure self-supervision training without any depth/SDF annotations
    - Photometric loss between SDF and input RGB
    - Co-planar geometric loss using plane segmentation
    - Depth consistency loss between SDF and NeRF
- Framework works with any model able to estimate voxel-SDF, keeping advantages of base model

Main Contributions:
- First framework to achieve explicit 3D mesh reconstruction of generalizable indoor scenes from monocular RGB video with pure self-supervision 
- Outperforms state-of-the-art self-supervised depth estimation methods
- Comparable results to supervised methods requiring full depth/SDF annotations
- Novel self-supervised losses that boost performance and can be used with supervised losses
- Framework extends to any base voxel-SDF estimation model, maintaining advantages of base model

In summary, MonoSelfRecon advances monocular indoor 3D reconstruction by being the first method to jointly achieve pure self-supervision training, generalization ability to new scenes, and explicit 3D mesh output. The novel self-supervised losses are key to enabling the pure self-supervised training.
