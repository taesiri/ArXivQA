# [Scaling Spherical CNNs](https://arxiv.org/abs/2306.05420)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to scale spherical CNNs to larger problems so they can be competitive with other state-of-the-art models. The key hypotheses are:- Larger spherical CNN models with adequate capacity and efficiency can achieve strong performance on real-world tasks involving spherical data and rotational symmetries.- Spherical CNNs can be competitive with graph neural networks and transformers on molecule property prediction and weather forecasting tasks.Specifically, the paper investigates:- Novel variants of common neural network components like nonlinearities, normalization, and residual connections that improve expressivity and efficiency of spherical CNNs.- An efficient implementation of spherical CNN operations optimized for TPUs.- Application-specific input representations and modeling choices for molecules and weather data that allow spherical CNNs to work well.The overarching goal is to demonstrate spherical CNNs can be scaled to much larger sizes than prior work, making them viable for complex scientific applications at a scale not previously possible. The experiments on molecular property prediction and multiple weather forecasting tasks aim to validate the hypotheses.


## What is the main contribution of this paper?

The main contribution of this paper is scaling up spherical CNNs to tackle larger problems. Specifically:- They design large spherical CNN architectures with improved layers like phase collapse nonlinearity, spectral batch normalization, and efficient residual blocks. This allows them to build models with higher capacity.- They provide an optimized implementation of spherical CNN operations on TPUs, exploiting matrix multiplications and distributed training for speed.- They introduce application-specific input representations and output heads for molecules (distance-based spherical features) and weather forecasting (leveraging multiple input variables). - They evaluate the scaled spherical CNNs on molecular property prediction on QM9 and multiple weather forecasting tasks. The models reach state-of-the-art on QM9, previously dominated by graph neural nets and transformers, and are competitive on the weather tasks.In summary, the key contribution is demonstrating that with proper modeling choices and optimizations, spherical CNNs can be scaled to tackle problems an order of magnitude larger than prior work, reaching performance on par with or better than alternative approaches like graph networks and transformers. This helps establish spherical CNNs as a viable technique for problems with spherical inputs and rotational symmetries.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper scales up spherical CNNs by improving model components like activations and batch normalization, optimizing implementations for TPUs, and designing application-specific input representations, enabling spherical CNNs to achieve state-of-the-art performance on molecular property prediction and competitive results on weather forecasting tasks.


## How does this paper compare to other research in the same field?

Here is my analysis of how this paper on scaling spherical CNNs compares to other research in the field:- This paper focuses on scaling up spherical CNN models to tackle large-scale scientific problems in drug discovery and weather forecasting. Most prior work on spherical CNNs has only been applied to small datasets and tasks. By systematically scaling these models, this work shows spherical CNNs can be competitive with state-of-the-art graph neural networks and transformers on real-world benchmarks.- The paper introduces modeling contributions like phase collapse activations, spectral batch normalization, and an efficient residual block design that improve model accuracy and efficiency compared to prior spherical CNN models. These innovations allow the models to scale more effectively.- For drug discovery, the paper shows spherical CNNs achieve state-of-the-art on 8/12 targets on the QM9 molecule property prediction benchmark, outperforming recent graph neural network and transformer baselines. This is the first demonstration of spherical CNNs being competitive on this large-scale benchmark.- For weather forecasting, the paper shows spherical CNNs can match or exceed the performance of prior convolutional and graph neural network baselines on tasks like temperature and pressure forecasting. This is the first successful application of spherical CNNs to weather forecasting.- The modeling and engineering contributions allow the spherical CNNs to scale to much higher resolutions and depths than prior work. For example, models process feature maps with 8.4 million elements, compared to typical sizes in the tens of thousands for past spherical CNN research.- The work focuses on scientific applications where spherical CNNs are especially well-suited. Most prior spherical CNN papers focused on more generic computer vision tasks. The domain-specific perspective is novel.In summary, this paper pushes spherical CNNs to a new scale, demonstrating they can achieve strong performance on complex scientific tasks compared to state-of-the-art graph neural networks and transformers. The technical innovations and applications to drug discovery and weather forecasting set this work apart from prior research on spherical CNNs.


## What future research directions do the authors suggest?

Based on my reading of the paper, the main future research directions suggested by the authors are:- Applying spherical CNNs to additional real-world problems at large scale to further demonstrate their capabilities and determine best practices. The authors show promising results on molecular property prediction and weather forecasting, but suggest more work is needed on large applications to fully realize the potential of spherical CNNs.- Improving computational efficiency. The models presented still require extensive compute resources to train, taking multiple days on dozens of TPUs in some experiments. Further optimizing spherical CNN architectures and developing more efficient implementations could broaden their applicability.- Incorporating spherical CNNs into multimodal models. The paper focuses on settings with spherical data as input, but the authors suggest spherical CNNs could provide useful representations in combination with other data modalities like graphs or sequences.- Exploring applications where end-to-end differentiation is beneficial. The spherical representation of molecules is differentiable, opening opportunities for predicting interactions or dynamics rather than just properties.- Developing spherical models that do not require aligned data. The paper assumes aligned spherical data, but discussing possible methods to achieve equivariance when rotations between examples are unknown.- Continuing to compare spherical CNNs to other approaches like graph neural nets and transformers on established benchmarks. More systematic comparisons could better characterize the tradeoffs between these methods.In summary, the authors present substantial progress on scaling up spherical CNNs, but outline several directions to build on this work and further demonstrate these models can become a viable alternative for problems involving spherical data or symmetries.


## Summarize the paper in one paragraph.

The paper proposes scaling up spherical convolutional neural networks (spherical CNNs) to tackle large scientific problems in drug discovery and weather forecasting. The key contributions include:1) Designing large-scale spherical CNN architectures with efficient implementations of core operations like spin-weighted spherical harmonic transforms optimized for TPUs. 2) Introducing novel components like phase collapse nonlinearities, spectral batch normalization, and efficient residual blocks that improve model expressivity and efficiency.3) Application-specific input representations that leverage the properties of spherical CNNs, such as representing molecules as spherical functions based on atomic interactions.The models are evaluated on molecular property prediction using the QM9 benchmark, where they achieve state-of-the-art performance compared to graph neural networks and transformers. The spherical CNNs also show strong performance on multiple weather forecasting tasks using the WeatherBench and other climate datasets. Overall, the work demonstrates the feasibility of scaling up spherical CNNs and their viability as competitive models for scientific problems involving spherical data or rotational symmetries.
