# [Enhancing Robustness in Biomedical NLI Models: A Probing Approach for   Clinical Trials](https://arxiv.org/abs/2402.02558)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem Statement:
- Large language models (LLMs) have shown state-of-the-art performance on many NLP tasks but suffer from issues like shortcut learning, factual inconsistency, and performance degradation with small distribution shifts. This is particularly concerning for applications in medical domains like analyzing clinical trials.
- There is a need to evaluate LLMs more rigorously in terms of their semantic consistency and faithful reasoning abilities before deploying them. The author aims to investigate the robustness and semantic correctness of the SciFive LLM on an entailment task for clinical trials.  

Proposed Solution:
- The author fine-tunes SciFive, a T5-based text-to-text transformer, on the SemEval 2024 dataset for textual entailment in clinical trials. 
- They use "mnestic probing" to identify the specific features learned by SciFive that are relevant for the entailment task. This involves training simple neural network probes on a dataset targeting natural logic phenomena like monotonicity and concept relations.
- The probes are then used to iteratively project out less useful directions in the SciFive model's latent space through null space projection, keeping only useful directions for the task. This allows fine-tuning while preserving intended features.

Main Contributions:
- Development of a probing methodology to evaluate semantic correctness and faithfulness of reasoning in SciFive for clinical trial entailment.
- Creation of customized datasets and probes targeting assessment of monotonicity and concept relations based on natural logic.
- Demonstration that probe-guided fine-tuning can improve performance by removing spurious features (2% gain in accuracy).
- Analysis provides direction for future work on more rigorous evaluation of language models for high-stakes medical applications.

In summary, the paper develops a probing technique to refine LLMs for robust clinical entailment through iterative null space projection, contributing to trustworthiness for medical NLP.
