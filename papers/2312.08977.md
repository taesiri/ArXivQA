# [Weighted Ensemble Models Are Strong Continual Learners](https://arxiv.org/abs/2312.08977)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes a new continual learning method called Continual Fisher-weighted Model Averaging (CoFiMA) to address the stability-plasticity dilemma in class-incremental learning. The core idea is to balance acquiring new knowledge while retaining previously learned concepts by averaging model weights from the current task and previous tasks. Specifically, after training on each new task, CoFiMA averages the weights of the current model with the model from the previous task using a hyperparameter Î» to control the relative weighting. Additionally, CoFiMA weighs each parameter based on its Fisher information to selectively ensemble important weights. Experiments across diverse benchmarks and vision transformer backbones demonstrate consistent gains over state-of-the-art methods like SLCA. The simplicity and effectiveness of CoFiMA in mitigating catastrophic forgetting highlights its potential for continual learning, where balancing plasticity and stability remains an open challenge. Key strengths are selectively merging pertinent weights between successive tasks and leveraging Fisher information to determine the significance of each parameter.
