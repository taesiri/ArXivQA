# [Learning to Watermark LLM-generated Text via Reinforcement Learning](https://arxiv.org/abs/2403.10553)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Learning to Watermark LLM-generated Text via Reinforcement Learning":

Problem:
- Prior works on watermarking LLM-generated text rely on inducing token-level distortions in the LLM output to embed watermarks. This has limitations such as constrained accuracy due to readability requirements, vulnerability to paraphrasing attacks, lack of adaptability to new attacks, inability to release watermarked models publicly. 

Proposed Solution:
- The authors propose a reinforcement learning (RL) based framework to inject model-level watermarks into LLM weights. 
- A detector model is trained to identify text generated by the watermarked LLM. 
- The LLM and detector are co-trained - LLM is tuned to generate text easily detectable by the detector, detector is trained to accurately detect signals from the tuned LLM's outputs.

Key Contributions:
- A new perspective of including LLM tuning stage in watermark pipeline instead of just post-processing a fixed LLM's outputs.
- Tuning the LLM with the detector model makes detection more accurate and robust against attacks like paraphrasing.
- The framework is adaptable to incorporate new attacks through adversarial training.
- Allows releasing watermarked models publicly since signals are embedded in weights.
- Zero cost for generating watermarks during deployment.
- Can be integrated into standard LLM alignment frameworks with low overhead of just training an extra detector model.

Experiments show higher detection accuracy, robustness against perturbations/paraphrasing, and ability to adapt to new substitution attacks via adversarial training compared to token-level watermarking baselines.
