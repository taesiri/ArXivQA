# [StepCoder: Improve Code Generation with Reinforcement Learning from   Compiler Feedback](https://arxiv.org/abs/2402.01391)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Code generation using large language models (LLMs) has shown promising results. However, there are still challenges in aligning LLMs with complex human requirements. 
- Two key challenges for using reinforcement learning (RL) to enhance LLMs for code generation:
  1) Lengthy code generated by LLMs in response to complex requirements makes RL exploration difficult.  
  2) Since unit tests may not cover complicated code, optimizing LLMs using unexecuted code snippets is ineffective.

Proposed Solution:
- Introduce StepCoder, a novel RL framework for code generation, with two components:
  1) CCCS: Breaks long code generation into curriculum of code completion subtasks to ease exploration challenge. Increasingly completes larger portions of code as training progresses.
  2) FGO: Only optimizes model using executed code segments from unit tests to enable fine-grained optimization. Masks unexecuted tokens when computing loss.

- Construct APPS+ dataset - High quality dataset for RL training in code generation. Manually verified to ensure correctness of unit tests.  

Main Contributions:
- Propose StepCoder framework to improve exploration and provide fine-grained optimization for RL in code generation
  - CCCS simplifies exploration into curriculum of subtasks
  - FGO focuses optimization on relevant executed code
- Construct APPS+ dataset specifically for code generation to enable more rigorous evaluation and RL training
- Experiments show StepCoder enhances exploration and outperforms state-of-the-art approaches on benchmarks like MBPP and HumanEval

The key ideas are using a curriculum strategy to simplify the exploration process and providing fine-grained optimization by masking irrelevant tokens based on unit test coverage. The proposed methods and dataset advance the capability of applying RL to improve code generation.
