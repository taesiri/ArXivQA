# [AutoTimes: Autoregressive Time Series Forecasters via Large Language   Models](https://arxiv.org/abs/2402.02370)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "AutoTimes: Autoregressive Time Series Forecasters via Large Language Models":

Problem:
- Time series forecasting is critical for many real-world applications, but the development of foundation models for time series has been limited due to the lack of large-scale pre-training data and techniques to develop scalable models. 
- Recent work shows the feasibility of leveraging large language models (LLMs) for time series forecasting given the similarities in their sequential structure. However, existing methods may overlook consistency in aligning time series with language, limiting the potential of LLMs.

Proposed Solution:
- The paper proposes AutoTimes to repurpose LLMs as autoregressive time series forecasters by ensuring consistency in training, inference and parameters with LLMs.
- It tokenizes time series into segments that capture local variations and projects them into the embedding space of LLMs using a trainable tokenizer. 
- The LLM then makes next step predictions on these tokens using its inherent capability, with only the tokenizer modules updated during training.
- This is more efficient and provides flexibility in input lengths. Token-wise prompting aligns timestamps with series tokens to enable multimodal forecasting scenarios.

Main Contributions:
- Proposes a simple yet effective approach to adapt LLMs for time series forecasting that is aligned with their acquisition and utilization.
- Achieves competitive performance to state-of-the-art models with a single model for flexible series lengths.
- Inherits desirable LLM capabilities like zero-shot learning, in-context learning and multimodality to expand applicability.
- Analysis shows performance lifts with larger LM capacity, additional text or series, validating the approach.

In summary, the paper delivers an impactful repurposing of LLMs for time series by ensuring consistency with their fundamental aspects. The adapted forecasters showcase promising generality and room for advancement as foundation models.
