# [Late Stopping: Avoiding Confidently Learning from Mislabeled Examples](https://arxiv.org/abs/2308.13862)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question/hypothesis seems to be: How can we develop an effective method for learning with noisy labels that retains as many clean hard examples as possible in the training set throughout the learning process?The key points are:- Clean hard examples (CHEs) are critical for achieving close-to-optimal generalization performance when learning from noisy labels. - Existing methods tend to remove CHEs along with mislabeled examples when selecting confident clean examples, harming performance.- The proposed method, Late Stopping, aims to retain CHEs while removing mislabeled examples by exploiting the intrinsic robust learning ability of DNNs.- It does this by prolonging training and removing high-probability mislabeled examples identified by the proposed First-time k-epoch Learning (FkL) metric.- FkL measures when examples are first consistently classified to their given label, with late-classified ones being noisy.- Experiments show Late Stopping retains more CHEs and outperforms existing methods on noisy datasets.In summary, the central hypothesis is that retaining CHEs by exploiting robust learning dynamics will improve learning with noisy labels. The Late Stopping method and FkL metric are proposed to achieve this goal.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing a new framework called "Late Stopping" for learning with noisy labels. The key idea is to leverage the intrinsic robust learning ability of deep neural networks by prolonging the training process, and gradually removing likely mislabeled examples in the late stages of training. - Introducing a new metric called "First-time k-epoch Learning" (FkL) which measures the number of epochs it takes for an example to be consistently classified to its given label. The FkL metric is used to identify likely mislabeled examples for removal in the Late Stopping framework.- Demonstrating empirically that mislabeled and clean examples exhibit differences in the number of epochs needed to be consistently classified, with mislabeled examples requiring more epochs. Thus FkL can be used to distinguish mislabeled examples.- Evaluating Late Stopping on benchmark simulated and real-world noisy datasets, showing superior performance compared to prior state-of-the-art methods for learning with noisy labels. The prolonged training enables retaining more clean hard examples.In summary, the main contribution appears to be proposing the Late Stopping framework and FkL metric for improved learning with noisy labels by exploiting the robust learning dynamics of deep networks. The key idea is retaining clean hard examples by stopping late rather than early.
