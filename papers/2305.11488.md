# [AttriCLIP: A Non-Incremental Learner for Incremental Knowledge Learning](https://arxiv.org/abs/2305.11488)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes a new continual learning method called AttriCLIP that aims to enable a model to incrementally learn knowledge from sequentially arrived data without catastrophically forgetting previous knowledge or needing to expand model capacity. 

The key research questions and hypotheses addressed in this paper are:

- Can a non-incremental learner be designed that does not require expanding model parameters or constructing extra memory as new classes/tasks arrive? 

- Can learning attributes from images help mitigate catastrophic forgetting in continual learning by enabling more generalizable prompts to be learned?

- Will learning image attributes as textual prompts allow avoiding the need for a replay memory to fine-tune an expanding classifier?

- Will the proposed method perform well on long-sequence and cross-domain continual learning benchmarks compared to prior arts?

The central hypothesis is that by learning a fixed set of textual prompts based on visual attributes of images, the proposed AttriCLIP method can incrementally learn new classes or tasks effectively without expanding model capacity or using a replay memory. The attributes learned in the prompts can generalize across classes, avoiding catastrophic forgetting. The paper presents experiments validating this hypothesis and showing AttriCLIP outperforms prior arts, especially on long-sequence cross-dataset benchmarks.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes AttriCLIP, a novel continual learning method based on CLIP that can incrementally learn new knowledge without increasing model parameters or requiring replay memory. 

2. AttriCLIP contrasts images with their descriptive text prompts selected from an attribute word bank according to image attributes. This avoids the need for a classifier with increasing size and replay memory for previous tasks.

3. It proposes a new Cross-Datasets Continual Learning (CDCL) experimental setup to evaluate model performance on long-sequence domain-shift tasks. 

4. Experiments show AttriCLIP achieves state-of-the-art performance on class-incremental learning benchmarks like CIFAR-100 and ImageNet-100. It also demonstrates superior ability to transfer knowledge and prevent catastrophic forgetting on the CDCL setup compared to previous methods.

5. Ablation studies verify the effects of different components of AttriCLIP like the loss functions, prompt length, attribute bank size, etc. Visualizations confirm that the learned prompts do capture semantic attributes that generalize across images.

In summary, the key contribution is the novel AttriCLIP framework that can incrementally learn new visual concepts based on descriptive text prompts selected according to image attributes. This avoids the limitations of previous continual learning methods based on fixed classifiers and replay memory. The method is shown to achieve excellent performance on class-incremental and cross-dataset continual learning benchmarks.
