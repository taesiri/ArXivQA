# [AttriCLIP: A Non-Incremental Learner for Incremental Knowledge Learning](https://arxiv.org/abs/2305.11488)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes a new continual learning method called AttriCLIP that aims to enable a model to incrementally learn knowledge from sequentially arrived data without catastrophically forgetting previous knowledge or needing to expand model capacity. 

The key research questions and hypotheses addressed in this paper are:

- Can a non-incremental learner be designed that does not require expanding model parameters or constructing extra memory as new classes/tasks arrive? 

- Can learning attributes from images help mitigate catastrophic forgetting in continual learning by enabling more generalizable prompts to be learned?

- Will learning image attributes as textual prompts allow avoiding the need for a replay memory to fine-tune an expanding classifier?

- Will the proposed method perform well on long-sequence and cross-domain continual learning benchmarks compared to prior arts?

The central hypothesis is that by learning a fixed set of textual prompts based on visual attributes of images, the proposed AttriCLIP method can incrementally learn new classes or tasks effectively without expanding model capacity or using a replay memory. The attributes learned in the prompts can generalize across classes, avoiding catastrophic forgetting. The paper presents experiments validating this hypothesis and showing AttriCLIP outperforms prior arts, especially on long-sequence cross-dataset benchmarks.
