# [Adaptive Guidance: Training-free Acceleration of Conditional Diffusion   Models](https://arxiv.org/abs/2312.12487)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Adaptive Guidance: Training-free Acceleration of Conditional Diffusion Models":

Problem: 
Conditional diffusion models like DALL-E can generate high-quality images from text prompts, but sampling is slow due to the iterative denoising process. A technique called Classifier-Free Guidance (CFG) improves sample quality but doubles computation by requiring two neural network evaluations per step. Other methods like Guidance Distillation can accelerate sampling but require costly retraining and lose functionality like handling negative prompts.

Proposed Solution:
The paper first shows conditional and unconditional denoising updates become increasingly aligned over time, suggesting redundancy in applying CFG equally across steps. Leveraging this insight and neural architecture search methods, the paper proposes "Adaptive Guidance" to omit CFG selectively. This method matches CFG quality while using 25% fewer neural network evaluations. 

The paper further replaces some CFG steps with a learned linear regressor of past iterations, reducing computations by 75% in a method called "Linear Adaptive Guidance".

Main Contributions:
1) Show CFG guidance becomes redundant in later diffusion steps 

2) Propose efficient "Adaptive Guidance" method to reduce computations by 25% while matching CFG performance

3) Introduce a faster "Linear Adaptive Guidance" variant replacing CFG networks with linear models, reducing computations by 75% with minor quality loss

4) Show methods are training-free, simple to implement, and handle functionality like negative prompts lost by alternatives like Guidance Distillation

5) Demonstrate approaches translate from smaller to state-of-the-art conditional diffusion models like DALL-E and provide insights into efficiency of text-to-image generation
