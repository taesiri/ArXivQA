# [Contrastive Multiple Instance Learning for Weakly Supervised Person ReID](https://arxiv.org/abs/2402.07685)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Person re-identification (ReID) is an important computer vision task where the goal is to identify images of the same person across different cameras and environments. 
- High-quality labeled data is critical for training accurate ReID models, but manually labeling data at the instance-level is extremely time consuming and expensive.  
- Weakly supervised learning methods have been explored where only image-level labels indicating the presence of a shared identity are available, but performance still lags behind fully supervised methods.

Proposed Solution:
- The paper proposes a novel Contrastive Multiple Instance Learning (CMIL) framework tailored for more effective person ReID under weak supervision.  
- It casts the problem under the multiple instance learning paradigm where images are grouped into positive and negative bags. Each bag contains multiple person crops/instances but only a bag-level label is available.
- A feature extraction network extracts features for each crop. Then an accumulation function aggregates crops into a bag representation in a permutation invariant manner. 
- Contrastive losses like triplet loss are applied on the bag representations to bring positive bags closer and push negative bags further apart in the embedding space.
- An alignment loss is also explored to encourage similarity between bag and crop representations but is found ineffective.
- At test time, the crop level feature extractor is used like a standard ReID model.

Main Contributions:
- Introduction of a new real-world Weakly Labeled Muddy Racer Re-Identification (WL-MUDD) dataset.
- A novel CMIL framework that enables exploiting weak supervision through contrastive learning on bag-level labels unlike prior MIL approaches.
- Extensive experiments showing state-of-the-art performance of CMIL on WL-MUDD, WL-Market1501 and large-scale SYSU-30k datasets.
- Analysis providing insights like surprisingly simple average pooling working well for aggregation and counterintuitive divergence of instance vs bag representations.
