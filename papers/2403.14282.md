# [How to be fair? A study of label and selection bias](https://arxiv.org/abs/2403.14282)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There are many proposed measures and techniques for bias mitigation in machine learning models. However, it is still poorly understood when different techniques are effective and which techniques should be used under different circumstances of bias. 

- Recently, it has been shown that optimizing for certain fairness measures on biased data can sometimes lead to more accurate models on unbiased data, suggesting the traditional fairness-accuracy tradeoff may not always apply. However, a thorough theoretical analysis of when different bias mitigation techniques are effective is still lacking.

Proposed Solution:
- The paper proposes the "Fair World Framework" which assumes an underlying fair data distribution that gets distorted by a bias introduction process to produce the biased dataset that we observe. The choice of bias process and fairness criteria are assumptions to be made.

- The paper theoretically analyzes the effectiveness of bias mitigation techniques aiming to optimize certain fairness criteria, for two different bias introduction processes (label bias and selection bias) and two fairness criteria (statistical parity and "We're All Equal"). 

Key Contributions:

- Formal definitions provided for label bias, selection bias, statistical parity and "We're All Equal" fairness criteria

- For each combination of fairness criteria and bias process, derived properties the biased data must satisfy. Allows checking consistency of assumptions made.

- Showed mathematically whether optimizing for a particular fairness criteria on biased data produced by a particular bias process allows recovering the fair model that would perform well on unbiased data.

- Provided theoretical explanation for recent empirical results showing accuracy gains on fair data from fairness interventions on biased data.

- Demonstrated cases where minimizing fairness measures on biased data does not result in the fairest model, highlighting need to consider bias processes.

The theoretical analysis offers new insights into selecting appropriate bias mitigation techniques and helps explain when certain techniques can be effective.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The paper proposes a theoretical framework to establish relationships between types of bias (label and selection) and fairness criteria (statistical parity and "We're All Equal") to determine when bias mitigation techniques are effective in finding an accurate fair model from biased data.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It introduces the "Fair World Framework", which assumes the existence of an underlying fair world that we can only observe through a biased dataset. The goal is then to infer, from the biased data, a model that would perform accurately in the fair world. This framing avoids the issue of a fairness-accuracy trade-off.

2. It formally defines two types of bias - label bias and selection bias. It also considers two fairness criteria - statistical parity and "We're All Equal". 

3. For all four combinations of fairness criterion and type of bias, it analytically derives properties that the biased dataset must satisfy for consistency with the assumed fair world and bias process. These allow checking if the assumptions are reasonable.

4. For each combination, it shows whether optimizing for the corresponding fairness criterion on the biased data enables learning the fair model that would perform well on unbiased data. This explains some recent empirical results showing that debiasing can improve accuracy on unbiased data.

5. It provides guidance to practitioners on selecting appropriate debiasing methods based on assumptions about the type of bias and fairness properties of the real-world data generation process. It also shows risks of blindly minimizing fairness metrics without considering how different types of bias may affect them.

In summary, the main contribution is a theoretical analysis framework for understanding when and why different debiasing methods can be expected to work or fail based on the type of bias present.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key keywords and terms associated with it are:

- Algorithmic fairness
- Ethical AI 
- Classification
- Fairness-accuracy trade-off
- Label bias
- Selection bias
- Statistical parity
- We're All Equal (WAE)
- Demographic parity difference (DPD)
- Fair world framework
- Bias mitigation techniques
- Fairness interventions
- Fairness measures
- Fairness criteria 

The paper discusses different notions of fairness (statistical parity and WAE), different types of bias that can be introduced in datasets (label bias and selection bias), fairness measures like DPD, and presents a theoretical framework to analyze the effectiveness of different bias mitigation techniques under different bias and fairness assumptions. Key terms like algorithmic fairness, classification, bias, fairness criteria/measures, and mitigation techniques reflect the main topics and contributions of the paper.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper introduces the "Fair World Framework" as an alternative to the "legal constraint framework." How does this change the assumptions and goals of the bias mitigation techniques? What are the advantages and disadvantages of each framework?

2. The paper defines two types of bias - label bias and selection bias. How are they formally defined? What are some real-world examples that illustrate each type of bias? 

3. The paper analyzes combinations of fairness criteria (statistical parity, we're all equal) and bias types (label, selection). Walk through the analysis for one combination in detail. What conditions must the biased distribution satisfy and what does this imply?  

4. Theorem 3 shows conditions that must hold when statistical parity and label bias occur. Explain the significance of the max term in the theorem statement. What does this suggest about the relationship between label bias and predictive uncertainty?

5. For the case of statistical parity and selection bias, explain why the paper argues that minimizing demographic parity difference on the biased data does not lead to a fair distribution. What assumptions are required for this result?

6. In the discussion of "unlocking fairness," the paper explains why some bias mitigation techniques fail under selection bias. Use the theoretical results to analyze the behavior of each technique considered.

7. Focusing on one of the key theorems (e.g. Theorem 2, 5, 8), discuss how the assumptions could be relaxed to apply more broadly to real-world scenarios. What would be the limitations?

8. The paper explains how the reweighing technique of Kamiran and Calders addresses a specific type of selection bias. What is the underlying assumption of this technique under the fair world framework?

9. The experiments find unexpected performance for some bias mitigation techniques. Propose hypotheses for why the reweighing technique underperforms under selection bias.

10. The fair world framework requires assumptions about the fair distribution and bias process. Discuss the challenges of applying this methodology with real-world biased data, where these assumptions are unknown.
