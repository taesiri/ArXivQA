# [OWSM-CTC: An Open Encoder-Only Speech Foundation Model for Speech   Recognition, Translation, and Language Identification](https://arxiv.org/abs/2402.12654)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
There has been growing interest in developing large speech foundation models that can perform multiple speech tasks like automatic speech recognition (ASR), speech translation (ST), and language identification (LID) in a single model. Prior work like Whisper and OWSM adopt an encoder-decoder architecture, which suffers from slow inference speed, potential instability, and risk of hallucination during autoregressive decoding. Although some work has explored CTC-based models, they focus on ASR only and have not been scaled to diverse languages and tasks. Therefore, it remains unclear if non-autoregressive models can achieve competitive performance and efficiency compared to encoder-decoder models.

Proposed Solution:
This paper proposes OWSM-CTC, a novel encoder-only speech foundation model that utilizes multi-task self-conditioned CTC to perform multilingual ASR, any-to-any ST, and LID in one model. The core is a 27-layer E-Branchformer encoder trained on 180K hours of public audio covering 151 languages. Intermediate CTC losses are added to improve independence assumptions. The model takes a speech input and predicts language/task tokens followed by ASR/ST text tokens using CTC. An optional text prompt can also be provided through a separate prompt encoder.

Contributions:
- Propose the first public encoder-only speech model for diverse languages and tasks using CTC 
- Achieve comparable ASR performance and superior ST performance compared to similarly sized encoder-decoder OWSM, with 3-4x speedup
- Improve long-form ASR result with 20x speedup via batched parallel decoding
- Outperform baselines on robustness
- Release code, model, and logs to facilitate research 

The key finding is that properly designed CTC models can match or outperform autoregressive models on speech tasks while being faster and more stable. This demonstrates the promise of scaling up non-autoregressive speech encoders.
