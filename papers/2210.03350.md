# Measuring and Narrowing the Compositionality Gap in Language Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the abstract, the central research question this paper addresses is:How does the ability of language models to perform compositional reasoning scale with model size, and can techniques like elicitive prompting help improve compositional reasoning abilities?Specifically, the authors seem focused on investigating:- Whether the "compositionality gap" (the fraction of compositional questions the model gets wrong despite answering the sub-questions correctly) decreases as language model size increases. - Whether elicitive prompting techniques like "chain of thought" and their proposed "self-ask" method can help narrow this compositionality gap by allowing models to reason more explicitly.- Whether integrating search engines with the self-ask method can further improve compositional reasoning performance.So in summary, the main research questions revolve around measuring and trying to improve the compositional reasoning abilities of large language models using elicitive prompting and search engine integration.


## What is the main contribution of this paper?

The main contribution of this paper is developing methods to improve the compositional reasoning abilities of language models. Specifically:- The paper introduces the concept of the "compositionality gap" to quantify how often models can answer individual sub-questions but fail to compose them to answer a full compositional question. Experiments show this gap does not decrease with model scale.- The paper demonstrates that "elicitive prompting" methods like chain of thought that have models reason step-by-step can narrow the compositionality gap compared to standard prompting.- The paper proposes a new elicitive prompting method called "self-ask" where models explicitly ask and answer follow-up questions before answering the main question. This further improves compositional reasoning over chain of thought. - The explicit sub-question structure of self-ask also enables easily integrating a search engine to answer sub-questions, further boosting performance.Overall, the main contribution is developing new analysis methods and prompting techniques to measure and improve the compositional reasoning abilities of large language models. The concepts of the compositionality gap and elicitive prompting are novel ways proposed in this work to analyze and enhance compositionality.
