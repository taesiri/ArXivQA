# [Rethinking Adversarial Training with Neural Tangent Kernel](https://arxiv.org/abs/2312.02236)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Adversarial training (AT) is an important technique to improve model robustness against adversarial examples. However, AT exhibits odd properties like decreasing clean accuracy and overfitting adversarial examples early on. 
- Recent work has analyzed AT using Neural Tangent Kernel (NTK) theory, but has limitations: lacks theoretical analysis, only focuses on early training stages, studies one AT method, and does not provide practical enhancements.

Proposed Solution:
- Present a comprehensive analysis of AT with NTK from theoretical and empirical perspectives. 
- Disclose error gap between ground-truth and empirical NTK in AT. Analyze impact of batch normalization statistics on clean/robust accuracy.
- Study full training traces to reveal three-stage NTK evolution in AT: fast convergence, lazy training, further evolution. This enables practical enhancements.
- Provide three case studies to: 
  1) Show global batch norm statistics affect clean/robust accuracy differently.
  2) Propose reduced training cost paradigm utilizing lazy training phase.
  3) Address catastrophic overfitting issue in basic AT methods using NTK analysis.

Main Contributions:  
- First theoretical analysis of NTK under AT and impact of batch normalization.
- Study of full NTK evolution trajectory in different AT methods, revealing lazy training phase. Enables practical enhancements.  
- Three case studies providing better understanding and improvements to AT: effect of batch statistics, reduced training cost method, solution for catastrophic overfitting.

In summary, the paper provides valuable theoretical and empirical analysis into the odd behaviors of adversarial training using NTK theory. It also demonstrates this understanding can lead to practical improvements in current adversarial training paradigms.


## Summarize the paper in one sentence.

 This paper presents a comprehensive analysis of adversarial training using neural tangent kernel, uncovering new insights into batch normalization's impact, reducing training cost, and overcoming catastrophic overfitting.


## What is the main contribution of this paper?

 This paper presents a comprehensive analysis of adversarial training (AT) using neural tangent kernel (NTK). The main contributions are:

1) It provides theoretical analysis of the dynamics of neural networks under AT and normal training. It analyzes the impact of batch normalization statistics on clean accuracy and robust accuracy.

2) It experimentally studies the evolution of NTK during the entire training process under different AT strategies. It finds a threefold evolution pattern of NTK.

3) Based on the analysis, it provides three case studies to improve AT: 

(a) Analyzes impact of batch normalization on robustness.

(b) Proposes a new training paradigm to reduce time cost of AT without sacrificing performance. 

(c) Studies the spectrum of NTK to address catastrophic overfitting problem in single-step AT.

In summary, the key contribution is leveraging observations of kernel dynamics to provide both analysis and practical strategies to improve existing adversarial training methods. This is the first work in this direction based on neural tangent kernel.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper's content, some of the key terms and concepts associated with this paper include:

- Neural Tangent Kernel (NTK): A tool to analyze and understand deep learning models by studying the evolution of model parameters during training. Allows viewing training as evolution in function space.

- Adversarial Training (AT): A method to train models to be robust against adversarial examples by generating them on-the-fly during training.

- Kernel dynamics: Studying how the Neural Tangent Kernel evolves during the training process under different strategies like normal training and adversarial training. 

- Kernel metrics: Specific metrics used to quantify properties of kernels like distance, effective rank, and specialization strength. Examples are Kernel Distance (KD), Kernel Effective Rank (KER), and Kernel Specialization (KS).

- Batch normalization: A technique to normalize layer inputs based on batch statistics. The paper analyzes impact of batch normalization on adversarial training.

- Catastrophic overfitting: A phenomenon in adversarial training with one-step attacks where model robustness suddenly collapses. 

- Kernel alignment: The phenomenon where subkernels emerge in the neural tangent kernel, aligned to features corresponding to each output class.

So in summary, the key topics revolve around using neural tangent kernels to analyze adversarial training, the dynamics of kernels during training, overcoming challenges like catastrophic overfitting, and improving adversarial training.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1. The paper proposes studying adversarial training (AT) through the lens of Neural Tangent Kernel (NTK). What are some key advantages of using NTK to analyze AT compared to prior analysis techniques?

2. The paper discloses an error gap between the ground-truth and empirical NTK during AT. What causes this error gap and what are its implications on understanding the impact of AT on model performance? 

3. The paper reveals a threefold evolution of NTK during AT - "kernel learning", "lazy training", and "kernel learning" again. What accounts for this non-monotonic evolution of the kernel? How can we leverage this insight?

4. One key finding is that the kernel frozen during "lazy training" - how transferable is this frozen kernel between different AT methods? Can we exploit this to reduce training costs?

5. The paper proposes a new training paradigm to reduce AT costs by switching from adversarial to clean examples. How do we determine the optimal switching point? What are the tradeoffs with robustness?

6. For Batch Normalization (BN), how do the global statistics compared to batch statistics affect robustness versus accuracy? What causes this difference?

7. The paper identifies "catastrophic overfitting" in single-step AT methods. What intrinsic properties of the kernel cause this phenomenon and how does the proposed solution overcome it?

8. Kernel metrics like KD, KER and KS are used to analyze NTK evolution. What are the relative merits and demerits of these metrics? Are better metrics conceivable? 

9. What intrinsic differences does the paper find between kernels and features learned for clean versus adversarial data? Why do these kernels disagree?

10. The paper focuses on image classifiers. To what extent do you expect the insights on NTK evolution during AT to carry over or need reassessment for other data modalities?
