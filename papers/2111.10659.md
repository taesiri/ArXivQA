# [Are Vision Transformers Robust to Patch Perturbations?](https://arxiv.org/abs/2111.10659)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is:How robust are vision transformers compared to convolutional neural networks when individual input image patches are perturbed with either natural corruptions or adversarial perturbations?The key hypotheses seem to be:1) Vision transformers will be more robust to natural patch corruptions compared to CNNs.2) Vision transformers will be more vulnerable to adversarial patch perturbations compared to CNNs. The paper investigates these hypotheses through empirical evaluations on vision transformer models like DeiT and CNN models like ResNet. The goal is to understand how the unique patch-based architecture and attention mechanism of vision transformers affect robustness to different types of patch-wise perturbations.In summary, the central research question is about understanding the robustness of vision transformers to patch-level perturbations by comparing to CNNs, with a focus on how architectural differences like attention lead to different robustness properties.


## What is the main contribution of this paper?

The main contributions of this paper appear to be:1. Finding: Based on a fair comparison, the authors discover that Vision Transformers (ViT) are more robust to natural patch corruption than Convolutional Neural Networks (CNNs like ResNet), but more vulnerable to adversarial patch perturbations. 2. Understanding: The authors reveal that the self-attention mechanism of ViT can effectively ignore natural corrupted patches to maintain correct predictions, but can also be easily fooled by adversarial patches to make mistakes. 3. Improvement: Inspired by their analysis, the authors propose Smoothed Attention to improve the robustness of ViT against adversarial patch attacks by discouraging attention to focus too strongly on any single patch.In summary, the key contributions are carefully evaluating the robustness of ViT versus CNNs to different types of patch perturbations, analyzing the role of the self-attention mechanism in ViT's robustness properties, and proposing a method to improve ViT's robustness against adversarial patches based on these insights. Thecombination of empirical findings, analysis to develop understanding, and an improvement method based on that understanding make up the main contributions.
