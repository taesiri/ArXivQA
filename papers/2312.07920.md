# [DrivingGaussian: Composite Gaussian Splatting for Surrounding Dynamic   Autonomous Driving Scenes](https://arxiv.org/abs/2312.07920)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Reconstructing large-scale dynamic autonomous driving scenes from sparse vehicle-mounted sensor data is challenging, especially when the ego vehicle moves at high speeds. The static background and dynamic objects undergo rapid changes depicted through limited outward multi-camera views. It becomes difficult to model such a 360-degree driving scene due to complex geometry, diverse optical degradation, spatiotemporal inconsistency, and multiple fast moving objects. Existing methods like NeRF struggle with such scenes due to reliance on ray sampling, while Gaussian Splatting methods fail to handle combined static-dynamic regions with multiple moving objects.

Proposed Solution:
The paper proposes DrivingGaussian, a novel framework to represent surrounding dynamic autonomous driving scenes using Composite Gaussian Splatting. It decomposes the scene into a static background and dynamic objects. 

1) For the static background, Incremental Static 3D Gaussians are introduced to progressively model the background with ego vehicle movement using multi-camera images from sequential timesteps.

2) For dynamic objects, a Composite Dynamic Gaussian Graph is proposed to individually reconstruct each object and restore their positions and occlusion relationships by transforming and integrating them into the static background.

3) A LiDAR prior is incorporated for accurate geometry and consistency across views. LiDAR points are fused with images to obtain better Gaussian initialization.

Main Contributions:

- First framework to represent large-scale dynamic driving scenes using Composite Gaussian Splatting
- Proposes two novel modules - Incremental Static 3D Gaussians and Composite Dynamic Gaussian Graph
- LiDAR prior provides accurate geometry and multi-view consistency
- Achieves state-of-the-art performance on autonomous driving datasets 
- Enables dynamic scene construction and corner case simulation to validate driving systems

In summary, the paper decomposes complex dynamic driving scenes into static and dynamic regions, representing them using novel Gaussian modules, aided by LiDAR prior. This enables high-fidelity scene modeling and synthesis across tasks.
