# [Self-Consistency Training for Hamiltonian Prediction](https://arxiv.org/abs/2403.09560)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Hamiltonian prediction aims to predict the Hamiltonian matrix of a molecule directly from its structure using machine learning models. It can provide all properties computable from DFT at once and serve to accelerate DFT calculations.
- However, its applicability is limited by the lack of labeled data (precomputed Hamiltonian matrices), restricting its application to small molecules. 

Proposed Solution:
- The paper highlights that Hamiltonian prediction has a unique self-consistency principle based on the basic Kohn-Sham equation of DFT. 
- This allows designing a training loss that enforces the self-consistency between the predicted Hamiltonian and the one reconstructed from the eigenvectors of the prediction.
- As the loss purely relies on the Kohn-Sham equation that determines the target, no label is required. It allows leveraging abundant unlabeled molecular structures.

Main Contributions:
- Proposes self-consistency training for Hamiltonian prediction, which enables training without labeled data.
- Shows self-consistency training substantially improves generalization in data-scarce and out-of-distribution scenarios by leveraging more data.
- Demonstrates self-consistency training is more efficient for improving generalization than generating more labels, due to its amortization effect over data.
- Pushes the applicability of Hamiltonian prediction to larger molecules (56 atoms) than previously feasible, showing practical relevance. Overall addresses the data scarcity problem, a main difficulty of the formulation.

In summary, the paper proposes a principled training approach for Hamiltonian prediction that compensates data scarcity with physical laws. This distinguishes the formulation from other property prediction tasks. The benefits of improved efficiency and generalizability push the applicability of the formulation to larger scale.
