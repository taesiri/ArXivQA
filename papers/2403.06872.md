# [Exploring Large Language Models and Hierarchical Frameworks for   Classification of Large Unstructured Legal Documents](https://arxiv.org/abs/2403.06872)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Legal judgment prediction from long, unstructured case documents is challenging due to the lack of structure and lengthy texts (thousands of words).
- Existing methods don't work well on such lengthy, unstructured texts.

Proposed Solution:
- The authors propose a multi-stage hierarchical framework called MESc (Multi-stage Encoder-based Supervised with-clustering) for judgment prediction. 
- MESc splits the document into chunks, extracts embeddings from last layers of a fine-tuned LLM encoder for each chunk.
- It applies unsupervised clustering on the chunk embeddings to approximate document structure. 
- The chunk embeddings and structure labels are then processed through transformer encoders to learn inter-chunk representations.
- Finally a classifier makes the judgment prediction based on chunk representations and structure labels.

Contributions:
- Test the proposed MESc framework with legal datasets ILDC and LexGLUE having long, unstructured texts.
- Explore adaptability of multi-billion parameter LLMs like GPT-Neo, GPT-J with MESc framework.
- Analyze last layer embedding combination, impact of approximated structure labels in MESc.  
- Study intra-domain transfer learning capability of GPT variants between different legal domains.
- Achieve new SOTA results on ILDC (+2%) and LexGLUE ECtHR/SCOTUS subsets (+2 points in micro F1 score).
- Show MESc is more reliable for long documents than standalone fine-tuned LLM, especially when important sections are unknown.

In summary, the paper explores judgment prediction for lengthy, unstructured legal texts by proposing a hierarchical framework MESc and shows performance gains over prior state-of-the-art by using clustering to approximate document structure.


## Summarize the paper in one sentence.

 This paper explores classification of long, unstructured legal documents by developing a multi-stage hierarchical framework, MESc, that extracts embeddings from fine-tuned language models, approximates document structure through clustering, and processes the embeddings and structure labels through transformer encoders for final classification.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1) The authors propose a multi-stage hierarchical classification framework called MESc (Multi-stage Encoder-based Supervised with-clustering) for judgment prediction from large, unstructured legal documents. 

2) They explore the adaptability of large language models (LLMs) with billions of parameters (GPT-Neo, GPT-J) to this framework, and analyze the impact of combining embeddings from the last layers of the LLMs.

3) They study the intra-domain (legal) transfer learning capability of these LLMs, comparing fine-tuning to using the MESc framework. 

4) They perform extensive experiments on four datasets (ILDC and 3 subsets of LexGLUE) and achieve new state-of-the-art results, with total performance gains of approximately 2 points over previous methods.

In summary, the main contribution is the proposed MESc framework for hierarchical classification of long, unstructured legal documents, along with analysis of large LLMs and achieving improved performance over prior benchmarks.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key keywords and terms associated with it are:

- Legal judgment prediction
- Long document classification 
- Multi-stage hierarchical classification framework
- Large language models (LLMs)
- Billion parameter LLMs (GPT-Neo, GPT-J)
- Intra-domain (legal) transfer learning
- Indian Legal Document Corpus (ILDC)
- LexGLUE dataset (ECtHR, SCOTUS)
- Hierarchical attention networks
- Document structure approximation
- Unsupervised clustering

The paper explores using large language models and a hierarchical framework called MESc (Multi-stage Encoder-based Supervised with-clustering) to classify long, unstructured legal documents for judgment prediction. It tests the approach on the ILDC and subsets of the LexGLUE dataset, analyzing the adaptability of multi-billion parameter LLMs like GPT-Neo and GPT-J, their transfer learning ability, and the impact of approximating document structure via clustering of LLM embeddings. The key focus areas are legal judgment prediction from raw case texts, handling long document classification, and developing hierarchical neural network frameworks.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a multi-stage hierarchical classification framework called MESc. Can you explain in detail the four stages of this framework and how they work together for document classification?

2. Clustering is used in Stage 3 of MESc to approximate the structure of documents. Why is clustering used for this purpose instead of some supervised method? How does the clustering help improve classification performance?

3. The paper experiments with combining embeddings from the last layers of transformer models like BERT and GPT. What is the intuition behind combining these embeddings? How does using 2 layers vs 4 layers impact performance?

4. How does MESc handle long input sequences during training and inference? What are the advantages of the hierarchical approach over methods that take the full document as input? 

5. The paper analyzes the performance of MESc relative to just fine-tuning the backbone LM. Under what conditions does MESc outperform the standalone LM? When does the standalone LM do better?

6. Multi-billion parameter LMs like GPT-Neo and GPT-J are evaluated. How do these large LMs compare to smaller domain-specific LMs like LEGAL-BERT? What does this suggest about transfer learning?

7. The paper tests MESc on both European and Indian legal documents. How well does it transfer across these domains? What modifications would be needed to apply MESc to other legal domains?

8. What metrics are used to evaluate MESc? Why are certain metrics preferred for the multi-label and multi-class datasets? How should the metrics be interpreted?

9. Analyze the results in Table 2. For the LLM and MESc variants tested, what achieve the overall best performance? How do the scores compare to the SOTA baselines?

10. The paper states certain limitations of MESc from the experiments. What are some ways the framework could be extended or improved in future work based on these limitations?
