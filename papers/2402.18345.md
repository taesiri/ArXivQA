# [Solving Multi-Entity Robotic Problems Using Permutation Invariant Neural   Networks](https://arxiv.org/abs/2402.18345)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
This paper aims to develop robotic control strategies for effectively solving multi-entity problems, which involve managing multiple dynamic entities such as neighboring robots, objects to be manipulated, and navigation goals. Existing approaches face two key challenges: 1) scaling up to handle flexible numbers of entities, and 2) automatically prioritizing and assigning entities among agents without relying on handcrafted heuristics.

Proposed Solution: 
The authors propose a decentralized multi-agent reinforcement learning framework using permutation invariant neural network architectures called Global Entity Encoders (GEEs). The key ideas are:

1) Decentralized control maintains constant inference times regardless of number of agents, distributing computational costs. 

2) Model-free reinforcement learning eliminates reliance on heuristics for entity assignment.

3) GEEs process state vectors of arbitrary numbers of entities in each category (e.g. robots, boxes), outputting fixed-size feature vectors via max pooling. This allows handling variable entity counts.

4) Permutation invariance of GEEs ensures consistent decision making regardless of input order, enabling assessment of entity importance without ordering bias.

Contributions:
The main contributions are:

1) A complete system including decentralized policies with GEEs to solve multi-entity problems, validated on wheeled quadruped robots with communication via gRPC.

2) Real robot experiments demonstrating learned collision avoidance and dynamic goal assignment in navigation tasks. 

3) Simulation experiments analyzing emergent collaborative strategies and task performance improvements with larger, unseen numbers of entities. 

4) Ablation studies proving importance of GEE architectures and communication for coordination.

5) Comparisons to centralized optimization methods showing decentralized policies can learn near-optimal solutions.

In summary, this work introduces a promising learning-based approach to control robot teams in complex, dynamic multi-entity environments without task-specific engineering. The experiments clearly showcase its advantages.
