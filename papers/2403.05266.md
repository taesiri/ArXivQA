# [ERBench: An Entity-Relationship based Automatically Verifiable   Hallucination Benchmark for Large Language Models](https://arxiv.org/abs/2403.05266)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Large language models (LLMs) have shown impressive capabilities, but evaluating their tendency to hallucinate remains an important challenge. Existing benchmarks for hallucination either use static datasets that lack complexity and adjustability or rely solely on final answers rather than the reasoning process. 

Proposed Solution - ERBench:
The paper proposes ERBench, a new benchmark for evaluating hallucination in LLMs based on entity-relationship models and relational databases. The key ideas are:

1. Use the schema, data and integrity constraints in databases to automatically generate factual questions of arbitrary complexity that can be automatically verified.

2. Evaluate both the final answers as well as the reasoning process using the database constraints such as functional dependencies.

3. Construct multi-hop questions by joining relations using foreign keys to test multi-step reasoning.

4. Support multimodal questions by utilizing multimodal databases.

5. Provide a general framework to convert any relational database into a benchmark.

Main Contributions:

1. A new hallucination benchmark called ERBench that uses entity-relationship models and relational databases.

2. Methodology to automatically construct single-hop, multi-hop and multimodal factual questions with verifiable answers. 

3. Techniques to verify not only final answers but also the reasoning using database constraints.

4. Extensive experiments on 5 databases evaluating several LLMs. Observations about relative strengths/weaknesses of different LLMs.

5. Directions for future work such as prompt engineering and fine-tuning to further improve LLM performance.

The main impact is a comprehensive and adjustable benchmark to evaluate different facets of hallucination in LLMs by exploiting the knowledge encoded in relational databases.
