# [Generating Likely Counterfactuals Using Sum-Product Networks](https://arxiv.org/abs/2401.14086)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Explainable AI systems need to provide counterfactual explanations (CEs) to individual users to explain the decisions made by the AI models. CEs answer the question - "how should an input be changed to get a different output". Many criteria determine the quality of a CE, with plausibility being an important one. Plausibility refers to whether the CE seems realistic and likely to occur based on the data distribution. Existing methods to generate CEs often produce implausible ones by focusing too much on proximity to the input.

Proposed Solution:
The paper proposes a new method called LiCE to generate likely, and thus plausible, counterfactual explanations. LiCE models the problem as a mixed-integer optimization problem with constraints encoding common desiderata for CEs like validity, similarity, sparsity etc. It uses a Sum-Product Network (SPN), a type of tractable probabilistic model, to estimate the likelihood of candidate CEs during optimization. This allows generating high-likelihood CEs while satisfying other criteria.  

The optimization variables encode the input features of a candidate CE using the mixed polytope formulation. The constraints ensure validity of the CE and bounds its distance from the factual input based on Median Absolute Deviation. Causality and actionability can also be encoded as constraints. The SPN is formulated with binary indicator variables for leaf histogram bins and linearized computations for inner sum and product nodes. The root node value lower bound then serves as the plausibility constraint.

The proposed LiCE method is compared to several baselines on a variant of the Adult dataset for income classification. Evaluation uses out-of-sample Kernel Density Estimation to measure plausibility along with distance and sparsity metrics. LiCE generates closer and sparser counterfactuals than most methods while achieving high density values close to the data distribution median.

Main Contributions:
- Novel formulation of an SPN to tractably estimate CE likelihood in a mixed-integer optimization framework 
- LiCE method combining MIO and SPN likelihood to generate plausible counterfactual explanations
- Comparison against baselines showing LiCE CEs are proximate, sparse and have high estimated density

The main novelty is in using SPNs to guide MIO CE search towards high-likelihood areas of the input space. This balances proximity against plausibility better than existing methods. The MIO representation of an SPN can also enable new applications.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper presents a method called Likely Counterfactual Explanations (LiCE) that uses mixed-integer optimization and sum-product networks to generate counterfactual explanations for model predictions that optimize for plausibility while satisfying common desiderata such as validity, similarity, sparsity, actionability, and causality.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a method called Likely Counterfactual Explanations (LiCE) for generating counterfactual explanations that have high likelihood of occurring, making them more plausible. Specifically:

- They propose using a Sum-Product Network (SPN) to estimate the likelihood of a counterfactual explanation in order to measure its plausibility. They also provide a mixed-integer optimization (MIO) formulation of an SPN.

- They present a MIO model called LiCE that can generate counterfactual explanations while satisfying common desiderata like validity, similarity, sparsity, actionability, and causality constraints. Crucially, it also includes a plausibility constraint based on the SPN likelihood estimate.

- They numerically compare LiCE against several other counterfactual explanation methods on a variant of the Adult dataset. The results show LiCE generates more plausible counterfactuals compared to other methods, although it takes longer to compute.

In summary, the key contribution is a new method called LiCE for generating likely, and hence more plausible, counterfactual explanations by modeling likelihood estimation as a constraint in a MIO formulation. This combines traditions of tractable probabilistic models and MIO for counterfactual search.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper's content, some of the key terms and concepts associated with this paper include:

- Counterfactual explanations (CEs) - The paper focuses on generating high-likelihood, plausible counterfactual explanations to explain AI model decisions to users. 

- Mixed-integer optimization (MIO) - The method proposed models the counterfactual search problem as a mixed-integer optimization problem to satisfy common desiderata.

- Sum-Product Networks (SPNs) - SPNs are used to estimate the likelihood of proposed counterfactuals and quantify their plausibility. An MIO formulation of SPNs is also proposed.  

- Plausibility - The paper aims to generate counterfactuals that are likely under the data distribution, making them more useful explanations.

- Likelihood estimation - Techniques like SPNs and variational autoencoders are used to estimate counterfactual likelihood.

- Validity, similarity, sparsity, actionability - These are some of the common desiderata for counterfactuals that the method aims to satisfy.

In summary, the key focus is on generating plausible and likely counterfactual explanations to explain AI model decisions using mixed-integer optimization and likelihood estimation with sum-product networks.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. How exactly does the MIO formulation of the SPN allow bounding the likelihood estimate from above and below? What are the implications of the conservative lower bound versus the loose upper bound that includes the logarithm of the number of predecessors?

2. In what ways could the constraints around actionability and causality be expanded or modified to handle more complex causal relationships in the data? For example, could an entire causal graph be encoded? 

3. The paper mentions diversity and robustness of counterfactuals as areas for future work. What specific techniques could be incorporated into the MIO formulation to directly maximize diversity or improve robustness?

4. What modifications would need to be made to the likelihood constraints in order to work for more complex density models beyond histogram representations in the SPN leaves? Could kernel density estimates or Gaussian distributions be encoded?

5. How efficiently can the proposed MIO formulation scale in terms of number of features and sample size? What bindings and solvers would be best suited for tackling large problem instances?

6. Could the SPN structure and weights be trained jointly with the MIO optimization in some way rather than using a fixed, pre-trained model? If so, what would the training process look like?

7. Are there any ways the flexibility of the MIO could be used to optimize additional objectives beyond likelihood and distance simultaneously, such as simplicity of the explanation?

8. What adjustments need to be made to the method when targeting regression problems rather than classification? How would validity and distance metrics change?

9. For categorical features, what impact would directly modeling the catalogical values in the SPN rather than mapping back from numerical encodings have?

10. How well does the method extend to non-neural network models? What care needs to be taken for encoding other model types like random forests or SVMs?
