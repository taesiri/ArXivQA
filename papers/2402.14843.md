# [Text Diffusion with Reinforced Conditioning](https://arxiv.org/abs/2402.14843)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing text diffusion models have two main limitations: 
  1) Degradation of self-conditioning during training, where the model starts to ignore the diffused latent and focuses more on just reconstructing the previous prediction.  
  2) Misalignment between training and sampling distributions, leading to error accumulation.

Proposed Solution: 
- Reinforced Conditioning: Uses RL to provide direct reward signals to mitigate degradation of self-conditioning. Compares outputs with and without self-conditioning and rewards quality improvements.
- Time-Aware Variance Scaling: Scales the variance added during forward diffusion to make training distribution have higher variance than sampling. Makes model robust to potential errors.

Main Contributions:
- Identifies and analyzes two key limitations of current text diffusion models: degradation of self-conditioning and misalignment during sampling.
- Proposes a novel text diffusion model called TReC that addresses the limitations through reinforced conditioning and time-aware variance scaling.
- Achieves strong performance across machine translation, paraphrasing and question generation tasks, outperforming autoregressive, non-autoregressive and previous diffusion models.
- Analysis shows TReC can leverage diffusion for iterative refinement and mitigates degradation of self-conditioning for better utilization.

In summary, the paper performs an in-depth analysis of limitations of text diffusion models and contributes a new method called TReC that uses reinforced conditioning and variance scaling to empower text diffusion with higher quality and better alignment between training and sampling.
