# [PSVT: End-to-End Multi-person 3D Pose and Shape Estimation with   Progressive Video Transformers](https://arxiv.org/abs/2303.09187)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to perform end-to-end multi-person 3D human pose and shape estimation from monocular video. Specifically, it proposes a new method called PSVT to capture long-range spatio-temporal global interactions for multi-person pose and shape estimation in video.

The key hypothesis is that modeling global context dependencies among different people spatially and temporally in video can improve multi-person 3D pose and shape estimation compared to prior methods.


## What is the main contribution of this paper?

 The main contributions of this paper can be summarized as:

1. It proposes PSVT, the first end-to-end multi-person 3D human pose and shape estimation framework with video Transformer. This allows capturing long-range spatio-temporal context for multi-person pose and shape estimation in videos.

2. It proposes a novel progressive decoding mechanism (PDM) for the decoder of video Transformer, which updates the queries at each frame using the output tokens from the previous frame. This improves the pose and shape decoding performance. 

3. It proposes a novel pose-guided attention (PGA) module, which aligns the pose and shape tokens to better guide the shape decoder using pose information. This improves shape estimation performance.

4. Extensive experiments on four benchmarks show state-of-the-art results, demonstrating the effectiveness of the proposed PSVT framework and the new components PDM and PGA.

In summary, the key innovation is an end-to-end Transformer framework for multi-person pose and shape estimation in videos, with novel components for progressive decoding and using pose to guide shape estimation. The experiments validate its state-of-the-art performance.
