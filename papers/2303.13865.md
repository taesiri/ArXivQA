# [Compositionality in algorithms for smoothing](https://arxiv.org/abs/2303.13865)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main goals of this paper are:1. To provide a categorical perspective on the Backward Filtering Forward Guiding (BFFG) algorithm for hidden Markov models using the concept of optics from category theory. 2. To prove compositionality results that show different ways of composing the building blocks of BFFG correspond to equivalent optics. Specifically, the main results are Theorem 3 on equivalence for sequential composition and Theorem 4 on equivalence for parallel composition.3. To connect the compositional structure of BFFG to sampling from the smoothing distribution in a hidden Markov model. Theorems 3 and 4 imply compositionality for common sampling algorithms like Forward Filtering Backward Sampling.In summary, the paper aims to give a categorical understanding of BFFG and related smoothing algorithms, establishing formal compositionality results using the language of optics. This provides a foundation for modular implementation and helps clarify the algorithms' structure. The categorical perspective abstracts away details to focus on compositionality.


## What is the main contribution of this paper?

This paper proposes a categorical perspective on the Backward Filtering Forward Guiding (BFFG) algorithm for Bayesian smoothing in state space models. The key contributions are:1. BFFG is interpreted as an optic, a concept from category theory for modeling systems with bidirectional data flow. The backward and forward passes in BFFG correspond to the backward and forward maps in an optic.2. Compositionality results are proven for BFFG. In particular, it is shown that composing the building blocks of BFFG sequentially or in parallel results in equivalent optics. This allows flexible composition while preserving the overall smoothing distribution.3. The results are connected to well-known algorithms like the Kalman filter and Forward Filtering Backward Sampling. Compositionality for these algorithms follows directly from the main results.4. BFFG is also analyzed under a sampling perspective, where weighted samples are propagated rather than measures. This is useful for Bayesian computation. Again, compositionality is established.5. Overall, the categorical viewpoint provides a clean framework for understanding BFFG and its compositional properties. Representing BFFG as an optic elucidates its bidirectional data flow and makes implementation using basic categorical concepts straightforward. The theoretical results on compositionality guarantee consistency across different compositions.In summary, this paper demonstrates the benefits of applying category theory to elucidate the structure of BFFG and related Bayesian smoothing algorithms. The categorical abstractions allow focusing on the essence of these procedures.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper provides a categorical perspective on the Backward Filtering Forward Guiding algorithm for smoothing in state space models, showing that different ways of composing the building blocks correspond to equivalent optics.


## How does this paper compare to other research in the same field?

This paper presents a categorical perspective on the Backward Filtering Forward Guiding (BFFG) algorithm for smoothing in hidden Markov models. It makes connections between BFFG and optics, a concept from category theory used to model bidirectional data flow. The main contributions are:- Framing the backward and forward maps in BFFG as an optic, a categorical construct consisting of a backward map, forward map, and shared internal state. - Proving compositionality results showing that composing optics derived from BFFG is equivalent to composing the Markov kernels and forming a single optic (for both sequential and parallel composition).- Connecting BFFG's forward sampling map to monoidal categories of randomizations, providing a categorical understanding of sampling within BFFG.- Demonstrating how BFFG and the compositionality results can be applied to Kalman smoothing as a special case.Overall, this provides a novel categorical perspective on BFFG and establishes formal connections to optics and monoidal categories. This appears to be the first work framing BFFG categorically.The categorical viewpoint yields valuable insights into BFFG's compositional structure. It also opens up potential new directions, like using category theory to suggest extensions or variations of BFFG. More broadly, this contributes to the growing body of research applying category theory in machine learning, joining other recent works connecting optics to backpropagation and neural networks. The compositionality results resemble those for backpropagation. This suggests optics may provide a unifying framework for bidirectional algorithms like BFFG and backpropagation.In summary, the categorical perspective and formal results offer new theoretical insights into BFFG and related algorithms. The work fits into the broader trend of using category theory for machine learning systems.


## What future research directions do the authors suggest?

Based on my reading of the paper, here are some of the main future research directions suggested by the authors:- Develop more sophisticated sequential Monte Carlo methods that can handle complex, high-dimensional problems. The authors suggest ideas like adaptive resampling, using quasi Monte Carlo points, and exploring sequentialized MCMC.- Explore automated transformations of probabilistic programs to make inference more efficient, for example by transforming programs into forms more amenable to parallelization or analytic solutions.- Develop new probabilistic programming languages and systems focused on different domains like causality, decision-making, and control.- Create better tools and visualizations for debugging, analyzing, and transforming probabilistic programs. This could help make probabilistic programming more accessible.- Integrate probabilistic programming more tightly with deep learning, for example by connecting to differentiable programming techniques.- Explore ways to make inference more efficient through program analysis and optimization, such as staging analysis.- Develop theoretical foundations to better understand properties of probabilistic programs like convergence rates.- Apply probabilistic programming to new application domains like natural language processing, computer vision, robotics, and the sciences.- Build up libraries and abstractions for probabilistic programming to make it easier for non-experts to use these techniques.In summary, the authors see many open research challenges in developing more powerful and usable probabilistic programming systems, integrating probabilistic ideas into other fields, and deepening the theoretical understanding of these models.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper explores compositionality in algorithms for smoothing of stochastic processes on directed trees. In particular, it connects the Backward Filtering Forward Guiding (BFFG) algorithm with optics from category theory. Optics provide a categorical perspective for systems with bidirectional data flow, as in BFFG which has both a backward filtering and forward guiding pass. The main results show that different ways of composing the building blocks of BFFG correspond to equivalent optics. This establishes that BFFG has an inherent compositional structure, with the composition of optics mirroring the composition of Markov kernels and duplication mappings in the underlying graphical model. Overall, the categorical view of BFFG through optics enhances understanding of the algorithm and its modularity.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:This paper connects the Backward Filtering Forward Guiding (BFFG) algorithm with the notion of optics from category theory. BFFG provides a general framework for smoothing in state space models, where the latent Markov process is only partially observed. It involves a bidirectional data flow, with backward filtering to compute messages that are used in forward guiding to sample from a target distribution. Optics formalize this notion of bidirectional data flow, with forward and backward maps that are composed. The main results show that different ways of composing the building blocks of BFFG correspond to equivalent optics. In particular, the optic obtained from sequentially composing Markov kernels is equivalent to composing the corresponding optics. A similar result holds for parallel composition of Markov kernels. This establishes that the algorithm has a compositional structure that is made explicit through the language of optics. Overall, the categorical perspective enhances understanding of the BFFG algorithm and simplifies its implementation in terms of composing optics.


## Summarize the main method used in the paper in one paragraph.

The paper presents a compositional approach to algorithms for smoothing in Bayesian hidden Markov models using category theory and optics. The key method is representing the forward-backward algorithm using optics, which allows composing the algorithm in sequential and parallel ways that preserve equivalence. Specifically, the forward-backward algorithm involves a backward filtering pass to compute messages, followed by a forward guiding pass that uses the messages. The authors represent this bidirectional structure using optics, with the backward and forward passes as the optics' backward and forward maps. They then prove equivalence results showing that sequentially composing Markov kernels and composing the resulting optics yields equivalent smoothing algorithms (Theorem 1). A similar result holds for parallel composition (Theorem 2). These compositionality results allow flexibly building up smoothing algorithms while preserving correctness. Overall, the categorical perspective and use of optics provides a principled way to compose and understand smoothing algorithms.


## What problem or question is the paper addressing?

The paper is addressing the problem of developing a categorical perspective and formalism for the Backward Filtering Forward Guiding (BFFG) algorithm for smoothing in state space models. Specifically, it aims to:- Connect BFFG with the concept of optics from category theory, which have been used to model bidirectional data flow. - Show that different ways of composing the building blocks of BFFG correspond to equivalent optics. This establishes compositionality results for BFFG.- Provide a categorical framework for BFFG using optics that highlights its compositional structure. This enhances understanding and simplifies implementation.The key contributions are:- Formalizing the backward and forward maps in BFFG as an optic (Section 3). - Proving that sequential composition of optics is equivalent to composing the underlying Markov kernels and forming an optic (Theorem 1). This shows compositionality under sequential composition.- Proving that parallel composition of optics is equivalent to forming an optic from the product of Markov kernels (Theorem 2). This shows compositionality under parallel composition.- Connecting forward sampling in BFFG with optics and establishing similar compositionality results (Section 4). - Providing an example of applying the framework to a simple tree-structured model (Section 5).Overall, the categorical perspective and optic formalism provides a principled way to understand the compositional structure of BFFG and its variants, enhancing understanding and opening up connections to other areas using category theory.
