# [DefInt: A Default-interventionist Framework for Efficient Reasoning with   Hybrid Large Language Models](https://arxiv.org/abs/2402.02563)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) have shown impressive reasoning abilities, but face challenges in handling complex reasoning problems efficiently due to rapidly increasing token costs. This is especially problematic for open-ended real-world tasks with huge solution spaces.  

- Prior works have focused predominately on enhancing reasoning accuracy but overlook efficiency, lacking a balance between accuracy and cost.

Solution - DefInt Framework:  
- Motivated by the dual process theory of human cognition, the authors propose a Default-Interventionist framework (DefInt) to unleash the synergistic potential of hybrid LLMs. 

- DefInt efficiently generates "default" low-cost reasoning thoughts using smaller-scale LLMs, resembling fast intuitions of System 1. 

- If default thoughts are low-confidence, DefInt intervenes with scaled-up LLMs for high-effort reflective reasoning, akin to System 2 override.

- Besides intervention when needed, DefInt also periodically invokes System 2 reasoning as "gatekeeping" to ensure reasoning stays on course.

Main Contributions:
- DefInt achieves state-of-the-art reasoning accuracy and solution diversity on 5 representative reasoning tasks, including both close-ended and open-ended problems.

- Compared to the second best baselines, DefInt reduces token costs substantially by 49-79%, with even higher 75% average reduction on open-ended tasks.

- Analysis shows DefInt improves efficiency by leveraging smaller LLM intuitions as defaults, while retaining accuracy via reflective interventions - unleashing the synergistic potential of hybrid LLMs.

- Results provide insights on designing cost-effective LLM reasoning models by balancing intuitive and reflective reasoning.

In summary, the paper introduces DefInt, an efficient hybrid LLM reasoning framework achieving superior accuracy-cost trade-offs by adaptively synergizing smaller and larger language models. DefInt draws ideas from dual process theory to reconcile intuitive and reflective thinking for human-like efficient reasoning.
