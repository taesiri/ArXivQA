# [Enhancing NeRF akin to Enhancing LLMs: Generalizable NeRF Transformer   with Mixture-of-View-Experts](https://arxiv.org/abs/2308.11793)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main research focus of this paper is on developing a generalizable neural radiance field (NeRF) model that can synthesize novel views of unseen scenes without requiring per-scene optimization. The key hypothesis is that incorporating a Mixture-of-Experts (MoE) module into the NeRF architecture can help balance between generalization across diverse scenes and specialization for modeling individual scenes closely. Specifically, the paper proposes a model called GNT-MOVE, which augments the Generalizable NeRF Transformer (GNT) architecture with customized MoE modules. The goal is to leverage the flexibility and increased capacity of MoE to improve the generalization of GNT to novel scenes in both zero-shot and few-shot settings.The two main research questions addressed are:1) Does incorporating MoE help the GNT model scale up in terms of scene coverage and improve generalizability across diverse scenes?2) Can GNT-MOVE achieve better per-scene specialization compared to GNT by using the MoE to capture nuances of distinct scenes?To summarize, the central hypothesis is that a properly customized MoE-based architecture can enhance NeRF's capability for cross-scene generalization while retaining per-scene specialization. The paper evaluates this through extensive experiments on complex scene datasets.


## What is the main contribution of this paper?

This paper proposes a Generalizable NeRF Transformer with Mixture-of-View-Experts (GNT-MOVE) for better cross-scene generalization in novel view synthesis. The key ideas and contributions are:- Introduces Mixture-of-Experts (MoE) into the generalizable NeRF framework to help balance between higher model capacity for general scene coverage and flexible per-scene specialization. - Customizes MoE for NeRF's demands by proposing a shared permanent expert to enforce consistency across scenes, and a geometry-aware spatial consistency objective for smooth view transitions.- Achieves state-of-the-art performance on complex scene benchmarks under both zero-shot and few-shot settings. Remarkably outperforms prior arts in rendering novel views of unseen scenes.- Provides analysis on the expert selection behaviors to demonstrate that the proposed model can effectively divide and conquer different components in novel view synthesis while maintaining cross-view/cross-scene consistency.In summary, the key contribution is introducing and properly customizing MoE into the generalizable NeRF framework to enhance its generalization capability, via an architecture that balances between overall capacity and specialized flexibility tailored for individual scenes. The experiments validate superior cross-scene generalization ability.
