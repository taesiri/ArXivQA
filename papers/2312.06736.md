# [SqueezeSAM: User friendly mobile interactive segmentation](https://arxiv.org/abs/2312.06736)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Segment Anything Model (SAM) enables powerful interactive segmentation, but the original model is too slow and large for mobile devices. This limits adoption for mobile photography apps. 
- Many users don't realize they can click to activate segmentation on their phones.
- When users click an object, SAM often segments just that part rather than the whole object (e.g. clicks on person's shirt but only shirts gets segmented not the whole person).

Proposed Solution:
- Develop SqueezeSAM architecture that is 50x faster and 100x smaller than original SAM while maintaining quality. Uses efficient UNet backbone with transformers.
- Initialize segmentation using Salient Object Detection (SOD) to automatically identify likely objects of interest and generate click points to feed into SqueezeSAM. Enables segmentation without user clicks.
- Augment training data to merge sub-object masks and crop around salient objects. Improves whole object segmentation.  

Key Contributions:
- SqueezeSAM model architecture that runs segmentation in real-time on smartphones with only 12.5MB model size
- Incorporate SOD to automatically activate interactive segmentation on mobile devices
- Data augmentations and model tuning tailored to improving segmentation of salient objects and whole objects like humans/pets

In summary, they made SAM practical for mobile apps via a much faster and smaller model, enabled automatic initialization of segmentation using saliency detection, and improved quality on segmenting whole objects vs individual parts. This facilitates adoption in mobile photography applications.
