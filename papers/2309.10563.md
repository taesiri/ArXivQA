# [A Hierarchical Neural Framework for Classification and its Explanation   in Large Unstructured Legal Documents](https://arxiv.org/abs/2309.10563)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Legal case documents can be very long (10,000s of words) and unstructured, making judgment prediction and explanation challenging. 
- Lack of structure annotations and long lengths define the problem of "scarce annotated legal documents".
- Need methods to predict judgments and explain predictions on such long, unstructured legal documents.

Proposed Solution:
- Propose a multi-stage neural classification framework called "MESc" (Multi-stage Encoder-based Supervised with-clustering).
- Uses a transformer encoder (e.g. BERT) to encode document chunks. Approximates structure labels by clustering chunk embeddings. 
- Combines embeddings from last layers of encoder with structure labels for final classification.  
- Also propose an extractive explanation method called "ORSE" based on model input sensitivity to extract relevant sentences.

Main Contributions:
- Explore judgment prediction on scarce annotated legal documents using MESc framework. Shows performance gains over benchmarks.
- Study adaptability of large language models (LLMs) like GPT-Neo and GPT-J for legal text classification.
- Propose ORSE algorithm for extractive explanation from hierarchical models. Achieves 50% avg gain over baseline on explanation task.
- New SOTA results on judgment prediction for ILDC and LexGLUE legal datasets. New explanation benchmarks on ILDC expert annotations.
- Analyze limits of MESc w.r.t LLMs and document lengths. Provide insights on handling long texts.

In summary, the paper explores classification and explanation for long, unstructured legal documents using neural approaches. The MESc framework and ORSE algorithm offer ways to predict judgments and explain predictions which outperform previous methods.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

This paper proposes a multi-stage hierarchical framework for legal judgment prediction and explanation from large, unstructured documents, developing methods to approximate structure labels for classification and rank sentences by their impact on predictions for generating extractive explanations.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1) It defines and explores the problem of classification and explanation of large, unstructured legal documents with scarce or no annotations, which the authors refer to as "scarce annotated legal documents".

2) It proposes a multi-stage neural classification framework called "Multi-stage Encoder-based Supervised with-clustering" (MESc) to handle judgment prediction for such long, unstructured legal documents. MESc works by extracting and clustering representations from different layers of a pretrained language model to approximate structure labels, and uses this along with the representations for final classification.

3) It explores the adaptability of large language models like GPT-Neo and GPT-J for legal text classification, studying their intra-domain (legal) transfer learning capacity. MESc is evaluated with these models.

4) It proposes an extractive explanation algorithm called "Occlusion sensitivity based Relevant Sentence Extractor" (ORSE) to explain predictions of hierarchical models like MESc by extracting the most relevant sentences using input occlusion sensitivity.

5) It demonstrates improved performance over previous benchmarks with MESc for judgment prediction on legal datasets ILDC and LexGLUE subsets. ORSE also shows improved performance for explanation extraction on ILDC compared to baseline.

So in summary, the main contributions are: defining and tackling the problem of scarce annotated legal documents, proposing the MESc framework for judgment prediction, evaluating large language models for legal text classification, proposing the ORSE algorithm for explanation, and demonstrating improved results on legal datasets using these methods.


## What are the keywords or key terms associated with this paper?

 Based on my analysis of the paper, some of the key keywords and terms associated with this paper include:

- Classification of large unstructured legal documents
- Scarce annotated legal documents
- Long document classification
- Multi-stage classification framework (MESc)
- Approximating structure labels via clustering
- Extractive explanation algorithm (ORSE)
- Input occlusion sensitivity
- Legal judgment prediction 
- Relevant sentence extraction
- Hierarchical neural framework
- Intra-domain (legal) transfer learning
- Large language models (LLMs)
- Indian Legal Document Corpus (ILDC)
- LexGLUE legal dataset
- European Convention on Human Rights (ECHR) cases
- U.S. Supreme Court (SCOTUS) cases

The paper explores the challenge of classifying and explaining predictions on long, unstructured legal documents with scarce annotations. It proposes a multi-stage classification framework called MESc that uses clustering to approximate structure labels in the documents. It also develops an explanation algorithm called ORSE based on a model's sensitivity to occluded input to extract relevant sentences. Experiments using large LLMs are conducted on Indian, European, and US legal datasets. So the key terms reflect this focus on scarce-annotated legal text classification and explanation using neural and hierarchical techniques.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper defines the problem of "scarce annotated legal documents". What are the key characteristics of such documents that make them challenging for classification and explanation tasks?

2. The paper proposes a multi-stage classification framework called MESc. Can you explain in detail the 4 key stages of this framework and how they aim to handle scarce annotated legal documents? 

3. The paper experiments with combining embeddings from the last layers of transformer encoder models. What is the intuition behind this? How do the results vary for BERT-based vs GPT-based models?

4. The paper approximates structure labels using clustering on chunk embeddings. Why is having structure information important for such documents? How does adding these approximated labels impact model performance?

5. How does the performance of MESc compare when using smaller LLM architectures like GPT-Neo vs larger architectures like GPT-J? What conclusions can you draw about model scale and adaptability to legal texts?

6. When using maximum input length fine-tuning, how does MESc compare to just using the fine-tuned backbone LLM? Under what conditions does MESc show better performance?

7. Explain the key idea behind the proposed ORSE algorithm for extractive explanation. How does it leverage input sensitivity at different hierarchy levels of the model?

8. Analyze the results of ORSE on the ILDC expert explanations. How does performance vary with the percentage of sentences extracted? How does it compare to baseline?

9. What ethical considerations need to be kept in mind while developing judgment prediction and explanation frameworks for legal documents? 

10. What are interesting future research directions that can build upon the ideas in this paper related to classification and explanation of legal documents?
