# [CostFormer:Cost Transformer for Cost Aggregation in Multi-view Stereo](https://arxiv.org/abs/2305.10320)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is how to improve the cost aggregation step in learning-based multi-view stereo (MVS) methods using Transformers. The key hypothesis is that applying Transformers to cost aggregation can help explore global correspondences and refine ambiguous matching points effectively, overcoming limitations of CNNs like limited receptive fields.Specifically, the paper proposes CostFormer, a novel Transformer-based cost aggregation network, with two main components:1) Residual Depth-Aware Cost Transformer (RDACT) to aggregate long-range features on the cost volume via self-attention along depth and spatial dimensions.2) Residual Regression Transformer (RRT) to enhance spatial attention before depth regression.The overall hypothesis is that plugging CostFormer into existing MVS networks can improve their cost volumes and 3D reconstruction performance. Experiments on standard MVS datasets validate this hypothesis, showing improved accuracy and completeness with CostFormer.In summary, the paper explores using Transformers to improve cost aggregation in MVS, proposing an efficient CostFormer module that brings long-range contextual reasoning to this core MVS step.
