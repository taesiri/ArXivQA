# [Computing Voting Rules with Elicited Incomplete Votes](https://arxiv.org/abs/2402.11104)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
Traditional voting rules assume voters submit complete ordinal rankings over all candidates. However, when the number of candidates is large, eliciting full rankings can be cognitively demanding and lead to voter frustration or incomplete ballots. The paper studies voting rules that only require queries about subsets of candidates, addressing the tension between limited voter cognition and implementing common voting rules.

Proposed Solution:
The paper introduces a formal model where algorithms can query voters' ordinal rankings over any subset of up to $t$ candidates, for some $t < m$ where $m$ is the total number of candidates. It aims to characterize which common voting rules like positional scoring rules and STV can or cannot be computed correctly using such limited-sized queries.

Key Contributions:

- Shows plurality winners cannot be determined by any algorithm, even randomized, using queries smaller than the full set of candidates. Constructs indistinguishable profile pairs that enable impossibility.

- Fully characterizes the positional scoring rules computable for any query size $t$, proving they coincide with a specific $t$-dimensional subspace. Visualizes the nested subspaces.

- Extends impossibility result to STV, demonstrating limitations of commonly used rules.

- Analyzes the query complexity of computable scoring rules, giving matching upper and lower bounds for deterministic algorithms. Identifies gaps for randomized algorithms, providing instances that show complexity.

The results provide both negative and positive insights into the compatibility of standard voting rules with the realistic constraint of limited voter cognition/effort during preference elicitation. They introduce a novel framework for studying the axiomatic implications of such cognitive barriers in social choice.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The paper characterizes which positional scoring rules can be computed given access only to voters' ordinal preferences over subsets of candidates, providing positive algorithmic results as well as information-theoretic impossibilities including for widely used rules like Plurality and STV, while also analyzing the query complexity for computable scoring rules.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1) It provides a full characterization of which positional scoring rules can be computed with limited-sized queries of size t < m, where m is the number of candidates. Specifically, it shows that the space of such rules corresponds exactly to the subspace $R_{m,t}$ spanned by certain scoring vectors. As a consequence, rules like Plurality cannot be computed for any t < m.

2) It proves that other common rules like Single Transferable Vote (STV) also cannot be computed with limited query sizes t < m. 

3) For scoring rules that are computable, it provides upper and lower bounds on the query complexity - the number of limited-sized queries needed to determine the winner. It shows tight results for deterministic algorithms but leaves an open problem for closing the gap for randomized algorithms.

4) As a case study, it exactly determines the optimal query complexity for computing the Borda winner with m=3 candidates and queries of size t=2. This illustrates the complexity of analyzing the randomized setting.

In summary, the paper provides a theoretical understanding of which voting rules can and cannot be implemented with limited preference information, as well as quantifying the amount of information needed when possible. The results have implications for voting systems where eliciting full ordinal ballots across many candidates is infeasible.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper's content, some of the main keywords and key terms are:

- Limited preference elicitation
- Query complexity
- Positional scoring rules 
- Plurality
- Single Transferable Vote (STV)
- Information-theoretic characterization
- Randomized algorithms

The paper studies voting rules and social choice when voters provide preferences over only a limited set of candidates, rather than a full ranking. It analyzes the query complexity and information-theoretic limits of computing common voting rules like plurality and STV in such a setting. Key contributions include characterizing which scoring rules can be computed for a given query size and proving bounds on the number of queries needed by deterministic and randomized algorithms.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1. The paper introduces a model where voters arrive randomly to a platform and can be queried about subsets of candidates of size at most $t$. How does the analysis change if instead of random arrivals, voters arrive adversarially? For example, could an adversary coordinate arrivals to prevent accurate estimation of the underlying distribution?

2. The paper focuses mainly on positional scoring rules. How might the characterization and query complexity results extend to other common voting rules like Kemeny, Slater, or Copeland? Would similar constructions work?

3. For scoring rules in the characterized subspace $R_{m,t}$, can the number of queries be reduced below the covering number if approximation guarantees are allowed? For example, can we identify an $\varepsilon$-approximate score winner using fewer queries?

4. The construction proving the Plurality impossibility result is quite intricate. Are there more intuitive constructions that also yield indistinguishable profiles with different Plurality winners? Or is some complexity inherent?

5. The randomized query complexity bound has a gap between upper and lower bounds. CanInstances constructed using properties of Fibonacci numbers are used to prove the tight bound for $m=3, t=2$. Would similar recurrences work for larger parameter settings? Or is a different approach needed?

6. Instead of a single winner, if the goal was to select a committee of size $k$, how would the characterization and query complexity results change?

7. The model assumes queries reveal the exact distribution over preference rankings. How would results change if responses were only approximate due to limited samples?

8. What if instead of submitting complete rankings over subsets, voters submitted top-$t$ partial rankings? How would this alternate model compare?

9. What other voting rules besides Plurality and STV fail to be computable for any $t < m$? Are there broad classifications that lead to limitations?

10. The paper focuses on queries about candidates. What if queries asked about comparisons between pairs of candidates instead? Would this allow more rules to be computed or require more queries?
