# [Self-Training for End-to-End Speech Recognition](https://arxiv.org/abs/1909.09116)

## What is the central research question or hypothesis that this paper addresses?

The central research question of this paper is whether self-training can be an effective semi-supervised learning approach for end-to-end speech recognition models. Specifically, the authors investigate whether training sequence-to-sequence models on pseudo-labels generated from a baseline model can improve accuracy compared to the baseline, and how factors like filtering mechanisms and model ensembling impact the effectiveness of self-training. The main hypothesis is that self-training with proper pseudo-label filtering and model ensembling can substantially improve the accuracy of end-to-end speech recognition models by taking advantage of unlabelled data.
