# [NVFi: Neural Velocity Fields for 3D Physics Learning from Dynamic Videos](https://arxiv.org/abs/2312.06398)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a new method called NVFi for modeling dynamic 3D scenes from multi-view video frames. The key idea is to simultaneously learn a disentangled representation of scene geometry, appearance, and physical velocity fields, without needing any mask or type information about objects. The method consists of two components: a keyframe dynamic radiance field to capture geometry and appearance over time, and an interframe velocity field to model scene dynamics. A joint optimization strategy with physics-based losses is used to effectively train both components. Extensive experiments on synthetic and real datasets demonstrate NVFi's superior performance on future frame extrapolation, unsupervised 3D scene decomposition, and motion transfer across scenes. The disentangled velocity representation unlocks these applications not achievable by existing dynamic scene modeling techniques. Overall, this is an ambitious work towards physical scene understanding, with promising results on learning meaningful scene dynamics purely from videos.
