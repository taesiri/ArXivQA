# [Rethinking Loss Functions for Fact Verification](https://arxiv.org/abs/2403.08174)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- The standard cross-entropy loss for training verdict predictors in the FEVER fact verification task fails to capture the heterogeneity among the three verdict classes - Supported (SUP), Refuted (REF), and Not Enough Info (NEI). 
- Treating all misclassification types uniformly is problematic as SUP and REF assume evidence is present while NEI means evidence is missing. So misclassifying SUP as REF or NEI should not be considered equal errors.

Proposed Solution:
- Develop two new loss functions tailored to FEVER - SRN and SR losses - to impose penalties of varying magnitudes based on the prediction error type.
- The SRN loss reduces penalties for false NEI predictions compared to SRC and REF errors.
- The SR loss focuses only on the contradictory SUP vs REF classes and disregards NEI.
- Both objectives are also combined with class weighting to handle training data imbalance.

Main Contributions:
- Propose two new loss functions specifically designed for the FEVER dataset to capture the heterogeneity of verdict classes.
- Demonstrate improved accuracy over standard cross-entropy loss using the new objectives.
- Show additional gains from combining with class weighting to mitigate label imbalance.
- Provide comprehensive empirical evaluation on the FEVER dataset with multiple classifier backbones.

The key insight is to develop objectives tailored to the nuances of the prediction classes rather than treating all errors uniformly. The proposed approaches outperform the standard loss, confirming their advantage for the FEVER task.
