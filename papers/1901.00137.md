# [A Theoretical Analysis of Deep Q-Learning](https://arxiv.org/abs/1901.00137)

## What is the central research question or hypothesis that this paper addresses?

This paper focuses on theoretically understanding the deep Q-network (DQN) algorithm for reinforcement learning. The main research questions/goals are:- To provide theoretical justifications for the key techniques used in DQN, namely experience replay and target networks. - To analyze the algorithmic and statistical rates of convergence for DQN when using deep neural networks as function approximators. Specifically, the paper aims to characterize how the errors propagate through the iterative updates in DQN and bound the bias/variance incurred when approximating the action-value function with a neural network.- To extend the analysis and theoretical guarantees to a modified DQN algorithm for two-player zero-sum Markov games.So in summary, the central goals are to rigorously understand the properties of DQN from an algorithmic perspective and establish statistical error bounds for DQN and its extension to Markov games. The key contributions are providing theoretical justifications for the techniques used in DQN, as well as characterizing the algorithmic and statistical convergence rates of DQN when using deep neural network function approximation.
