# [Towards best practices in AGI safety and governance: A survey of expert   opinion](https://arxiv.org/abs/2305.07153)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main research question this paper seeks to address is: What safety and governance practices do leading experts think AGI labs should implement? The authors surveyed 51 experts from AGI labs, academia, and civil society organizations. They presented these experts with 50 statements about potential safety and governance practices that AGI labs could implement. The experts were then asked to indicate their level of agreement with each statement. The central goal was to gauge expert opinions on what AGI labs should do to safely develop artificial general intelligence (AGI). The results provide insights into areas of consensus and disagreement among experts regarding best practices for AGI labs. This can help inform efforts by the industry, regulators, and standard-setting bodies to establish safety protocols, regulations, and standards for organizations pursuing AGI development.In summary, the key research question is focused on eliciting expert opinions on safety and governance best practices that should be implemented by companies/labs trying to develop AGI. The authors aggregate these expert views to provide guidance on emerging consensus in this important area.


## What is the main contribution of this paper?

Based on my reading, the main contribution of this paper is presenting the results of a survey of expert opinions on safety and governance practices that AGI labs should implement. The key findings are:- There was broad consensus among the 51 experts surveyed that AGI labs should implement most of the 50 safety and governance practices listed in the survey. On average, 85% of respondents agreed that AGI labs should follow each practice. - Practices receiving the highest levels of agreement (98% agreement) were: conducting pre-deployment risk assessments, evaluating models for dangerous capabilities, commissioning third-party model audits, establishing safety restrictions on model usage, and red teaming.- Respondents from AGI labs showed significantly higher overall agreement with the practices than respondents from academia or civil society. However, no significant differences were found at the item-level.- Respondents suggested an additional 50 unique practices, indicating the list in the survey was not comprehensive. The authors suggest these findings can serve as an initial foundation to develop best practices and standards for AGI labs. The results indicate areas of consensus to build on as well as areas needing further discussion and research.In summary, the key contribution is presenting expert opinions on AGI safety and governance practices, revealing a high level of consensus on implementing most practices as well as areas needing further research and discussion. The results provide an initial evidence base to inform efforts to develop standards and regulations for AGI labs.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper presents the results of a survey of 51 leading experts in AI safety and governance, finding broad consensus that AGI labs should implement a wide range of safety and governance practices to reduce risks.
