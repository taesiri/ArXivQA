# [UniDream: Unifying Diffusion Priors for Relightable Text-to-3D   Generation](https://arxiv.org/abs/2312.08754)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes UniDream, a novel text-to-3D generation framework capable of producing relightable 3D objects with physically-based rendering (PBR) materials. The key idea is training an albedo-normal aligned multi-view diffusion model on paired albedo and normal maps to provide geometry and lighting priors. A three-stage pipeline is then used: 1) Generate multi-view albedo and normal images from the diffusion model; 2) Reconstruct a 3D coarse model from the albedo maps using a transformer-based model; 3) Refine the geometry and albedo texture with score distillation sampling; 4) Optimize for PBR properties while fixing albedo and normals. This allows disentangling lighting and texture to achieve superior realism and relighting capabilities compared to previous text-to-3D methods. Experiments demonstrate UniDream's ability to produce 3D objects with clearer albedo, smoother surfaces, and advanced relighting effects under varying lighting conditions. The user study and CLIP evaluations also show UniDream significantly outperforming other state-of-the-art text-to-3D approaches.
