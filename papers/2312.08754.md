# [UniDream: Unifying Diffusion Priors for Relightable Text-to-3D   Generation](https://arxiv.org/abs/2312.08754)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes UniDream, a novel text-to-3D generation framework capable of producing relightable 3D objects with physically-based rendering (PBR) materials. The key idea is training an albedo-normal aligned multi-view diffusion model on paired albedo and normal maps to provide geometry and lighting priors. A three-stage pipeline is then used: 1) Generate multi-view albedo and normal images from the diffusion model; 2) Reconstruct a 3D coarse model from the albedo maps using a transformer-based model; 3) Refine the geometry and albedo texture with score distillation sampling; 4) Optimize for PBR properties while fixing albedo and normals. This allows disentangling lighting and texture to achieve superior realism and relighting capabilities compared to previous text-to-3D methods. Experiments demonstrate UniDream's ability to produce 3D objects with clearer albedo, smoother surfaces, and advanced relighting effects under varying lighting conditions. The user study and CLIP evaluations also show UniDream significantly outperforming other state-of-the-art text-to-3D approaches.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper "UniDream: Unifying Diffusion Priors for Relightable Text-to-3D Generation":

Problem:
Recent text-to-3D generation methods can convert textual descriptions to 3D objects with intricate geometry and textures. However, most methods bake lighting and shadows into the texture, limiting realism and usability in applications demanding relighting capabilities. 

Solution - UniDream Framework:
1) Proposes a new framework to generate relightable 3D objects from text by disentangling lighting and texture. 

2) Core idea is training a diffusion model providing both geometry prior and Physically-Based Rendering (PBR) material prior.

3) Has 3 main components:
   (i) Dual-phase training of diffusion & reconstruction models to align albedo & normals
   (ii) Progressive 3D generation procedure using the trained models 
   (iii) Novel use of Score Distillation Sampling (SDS) to finalize PBR properties

4) Three stage generation pipeline:
   (i) Diffusion model generates multi-view albedo & normals
   (ii) Reconstruction model converts albedo maps to coarse 3D model
   (iii) SDS optimization refines into detailed 3D model with albedo texture 
   (iv) Fix albedo & optimize for PBR properties like roughness, metallic

Main Contributions:
1) Ability to disentangle lighting and surface properties to enable relighting the generated 3D objects
2) More geometrically complete shapes due to normal supervision in optimization
3) More stable text-to-3D generation compared to prior arts

The experiments validate UniDream's advantages in producing realistic materials, complete geometries and stability over state-of-the-art text-to-3D approaches. The limitations are potential constraints in semantic generalization and material generalization.
