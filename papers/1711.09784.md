# Distilling a Neural Network Into a Soft Decision Tree

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we create a model that generalizes well like a deep neural network, but whose decisions are more interpretable and explainable?The authors propose using a trained neural network to help create a soft decision tree model that makes hierarchical decisions based on learned filters. The goal is for this soft decision tree to gain some of the generalization abilities of the neural net through a process called "distillation", while being more interpretable since one can examine the sequence of filters leading to a prediction.In summary, the key research question is how to get the benefits of neural networks (strong generalization) along with the benefits of decision trees (interpretability), by using the neural net to help train a soft decision tree model. The paper explores methods to accomplish this transfer of knowledge from the neural net to the decision tree.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method to create a soft decision tree model that is more interpretable than a neural network but can leverage the generalization abilities of a neural network. The key ideas are:- Using a trained neural network to generate soft target distributions for training data, which are then used to train a soft decision tree model. This allows the tree to benefit from the representations learned by the neural net.- Using a specific type of soft decision tree with learned filters at internal nodes and static probability distributions at leaf nodes. This structure allows the model's classifications to be explained by examining the sequence of filters along the path taken for a given input. - Introducing regularizers and design choices like exponential decay penalties to enable effective training of the soft decision tree with stochastic gradient descent.- Showing experimentally that soft decision trees trained this way can reach better accuracy than trees trained directly on data, while being more interpretable than neural networks.So in summary, the main contribution is a method to get the benefits of neural nets' generalization while also gaining interpretability, through training soft decision trees guided by the neural nets' knowledge. The paper demonstrates this approach and analyzes the resulting models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The authors propose a method to train a soft decision tree to mimic a neural network in order to create a more interpretable model that retains some of the neural network's generalization abilities.
