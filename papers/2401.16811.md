# [Reviving Undersampling for Long-Tailed Learning](https://arxiv.org/abs/2401.16811)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- In long-tailed recognition, the training data follows a highly imbalanced distribution where a few head classes have abundant data while most tail classes have scarce data. 
- Most existing methods focus on improving average accuracy across all classes. However, tail classes with very few samples often achieve near zero accuracy, severely limiting model deployment. 
- Metrics like harmonic mean and geometric mean which capture the performance of tail classes are more important, but improving these metrics is very challenging.

Proposed Solution:
- The paper proposes a revived balanced undersampling strategy called Balanced Training and Merging (BTM) to improve tail class performance. 
- Key findings: Fine-tuning on a few-shot balanced dataset surprisingly boosts harmonic/geometric mean a lot while barely decreasing average accuracy. Ensembling these fine-tuned models via weight averaging further lifts the metrics.  
- BTM trains models on multiple small balanced datasets, merges them via weight averaging, and finally fine-tunes the classifier, requiring very small overhead.

Main Contributions:
- First work showing that few-shot balanced fine-tuning of the whole network significantly enhances tail class accuracy, measured by harmonic/geometric mean.
- Proposes BTM - an efficient and plug-and-play training strategy to improve worst-performing categories in long-tailed recognition. 
- Achieves new state-of-the-art harmonic/geometric mean while maintaining competitive average accuracy on multiple datasets. Demonstrates wide compatibility by applying BTM to various existing methods.

In summary, the paper makes key observations about the benefits of balanced fine-tuning and proposes the BTM training strategy to greatly enhance tail class performance in long-tailed recognition. The method provides large gains in harmonic/geometric mean with negligible overhead.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a plug-and-play training strategy called Balanced Training and Merging (BTM) that finetunes models on balanced subsets and ensembles them to improve the worst-performing categories in long-tailed learning while maintaining overall accuracy.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. The authors discover that balanced training drives the model to produce a more uniform recall distribution across categories, and averaging the fine-tuned models can further improve the harmonic and geometric mean. 

2. Based on their observations, they propose a novel plug-and-play training strategy called Balanced Training and Merging (BTM). BTM can significantly improve the worst-performing categories with only a small number of samples and little additional training overhead, and it incurs no additional inference overhead.

3. BTM is easy-to-implement, light-weight and can be easily integrated with other long-tailed classification algorithms. The authors conduct extensive experiments and demonstrate BTM's effectiveness on improving harmonic and geometric mean accuracy while maintaining similar arithmetic mean accuracy.

In summary, the main contribution is the proposal of the BTM training strategy, which is a simple yet effective approach to improve the performance of worst-performing categories in long-tailed recognition. BTM achieves this through balanced fine-tuning and model merging, requiring minimal overhead.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, here are some of the key terms and keywords associated with it:

- Long-tailed learning
- Imbalanced data
- Worst-performing categories
- Harmonic mean
- Geometric mean 
- Undersampling
- Few-shot balanced datasets
- Model ensemble
- Balanced Training and Merging (BTM)

The paper focuses on improving the performance of models on long-tailed datasets, where there is an extreme imbalance between the number of examples in different classes. It aims to improve the accuracy of the "worst-performing categories" that have very few examples, using metrics like harmonic mean and geometric mean that are more sensitive to these categories. The main techniques it proposes are reviving undersampling to create few-shot balanced datasets, fine-tuning models on these datasets, and ensembling the fine-tuned models. This leads to the proposed BTM training strategy. So the key terms revolve around long-tailed learning, model evaluation metrics, undersampling strategies, and model ensembling.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper argues that harmonic mean is a better metric than geometric mean for evaluating performance on the worst categories. Why does the harmonic mean better reflect the performance on the worst categories compared to other metrics like geometric mean or average accuracy?

2. The key idea of the proposed BTM method is balanced fine-tuning using few-shot datasets. Why does this simple strategy work so well and how does it avoid the underfitting problem when using severely undersampled balanced datasets? 

3. The paper shows that fine-tuning improves harmonic/geometric mean while slightly hurting average accuracy. Why does this phenomenon happen? Is there a trade-off between improving the worst categories versus maintaining high average accuracy?

4. Model averaging/merging is found beneficial after balanced fine-tuning. Why can averaging models fine-tuned on different balanced datasets lead to better performance? Does this indicate diversity among these fine-tuned models?

5. Why is the performance gain more significant on Places-LT compared to ImageNet-LT and iNaturalist2018? Does the method not work as well for larger datasets and why?

6. The paper explores fine-tuning the backbone versus classifier after the first training stage. Why does fine-tuning the whole network work better than individual components? 

7. Why is applying balanced fine-tuning between stage 1 and 2 better than after stage 2? What is special about the model after stage 1 that leads to better gains?

8. How sensitive is the method to the number of sampled datasets and shots per class? Is there a sweet spot and why?

9. The method shows strong gains in harmonic mean but minimal change in minimum per-class accuracy. Why does the lowest recall remain unchanged and how can it be further improved?

10. The method is shown to combine well with GML. What is the reason behind the complementarity of these two methods? Why can both harmonic and geometric mean be improved together?
