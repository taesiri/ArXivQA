# [Can LLMs Generate Human-Like Wayfinding Instructions? Towards   Platform-Agnostic Embodied Instruction Synthesis](https://arxiv.org/abs/2403.11487)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Generating natural language navigation instructions for embodied agents is challenging and time-consuming, requiring extensive human annotation. 
- Existing instruction datasets are exclusive to specific simulation platforms, limiting generalizability of instruction-following methods.
- There is a need for platform-agnostic approaches to synthesize human-like navigation instructions without environment-specific training. 

Proposed Solution: 
- Present a novel approach using large language models (LLMs) to generate wayfinding instructions via in-context learning, without any training.
- Given a path in any simulator, first gather spatial knowledge by performing visual question answering on images using LLM + visual encoder.  
- Condition the LLM on different instruction styles using a few reference texts to generate multi-style instructions.

Key Contributions:
- First platform-agnostic approach to generate human-like wayfinding instructions for embodied agents without training, via in-context learning.  
- Demonstrated to work across multiple simulators: Matterport3D, Habitat and ThreeDWorld.
- Validate instruction quality both via user study (83% find instructions capture environment details) and navigation experiments (comparable performance to human annotations).
- Established practical viability by showing minimal change (<1%) in navigation metrics when replacing human annotations with generated instructions.

In summary, this paper introduces a scalable LLM-based approach to synthesize natural instructions for embodied agents without requiring environment-specific training data or annotations. The platform-agnostic nature and strong empirical validation make this a valuable contribution towards advancing embodied AI.
