# [VXP: Voxel-Cross-Pixel Large-scale Image-LiDAR Place Recognition](https://arxiv.org/abs/2403.14594)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Performing accurate image-LiDAR cross-modal place recognition is challenging due to the huge differences between images (2D, photometric) and point clouds (3D, depth). Prior works either transform the data into an intermediate representation leading to information loss or do not properly establish local correspondences between modalities.  

Proposed Solution:
The paper proposes Voxel-Cross-Pixel (VXP), a novel approach to establish voxel (from point cloud) and pixel (from image) correspondences in a self-supervised manner to bring them into a shared feature space. 

Key ideas:
- Use two separate networks to process point cloud and image data.
- Explicitly exploit local feature correspondences in the first training stage by projecting 3D voxel features onto the 2D image plane.
- Enforce similarity of global descriptors in the second training stage after convergence on local descriptors.
- Teacher-student paradigm: Pre-train image network, then train point cloud network to match image features.

Main Contributions:
- Voxel-Cross-Pixel module to establish local correspondences between modalities in a self-supervised manner, effectively bridging domain gap.
- Two-stage training strategy - first optimize for local then global descriptors, capturing both fine details and broader context.
- State-of-the-art cross-modal retrieval performance on Oxford RobotCar, ViViD++ and KITTI datasets. Up to 16% improvement in top-1 recall.
- Model is fast, compact and does not need expensive pre-processing of raw data.

The key insight is that learning an effective shared space for cross-modal place recognition requires accurate establishment of local correspondences between modalities. The two-stage training and voxel-pixel projection module allows VXP to achieve this effectively.
