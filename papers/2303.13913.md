# [GarmentTracking: Category-Level Garment Pose Tracking](https://arxiv.org/abs/2303.13913)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we track the pose of garments in videos, in a category-level manner?

The key aspects of this research question are:

- Pose tracking of garments: Estimating the complete 3D shape and configuration of garments over time in a video. This is challenging due to the complex deformations and self-occlusions of garments.

- Category-level: The method aims to work on novel garment categories not seen during training. This requires learning representations that can generalize across garment types rather than just memorizing shapes.

- Videos: The research focuses on the sequential tracking setting, leveraging temporal information across frames rather than just single image pose estimation.

To summarize, the paper proposes a category-level garment pose tracking method that can estimate the complete time-varying 3D pose of garments in videos, even for garment categories not seen during training. The core research question is how to design a model that can learn generalized garment pose representations and effectively leverage temporal information for accurate sequential tracking.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. They propose a VR-based garment manipulation recording system called VR-Garment. This allows collecting a large-scale dataset with complex garment poses and annotations. 

2. They create a new dataset called VR-Folding for garment pose tracking. It contains about 100k videos of garment manipulation with 790K frames annotated with garment pose, hand pose, etc. The dataset focuses on two tasks - flattening and folding.

3. They propose an end-to-end framework called GarmentTracking for category-level garment pose tracking. It takes point cloud sequences as input and predicts complete garment geometry with inter-frame correspondence. The method operates in three stages - NOCS prediction, NOCS refinement, and canonical to task space mapping.

4. They demonstrate the effectiveness of GarmentTracking on the VR-Folding dataset, showing it can achieve real-time performance and is more accurate than baseline methods. The method also generalizes well to real-world data.

5. The VR-Garment system, VR-Folding dataset, and GarmentTracking framework provide a platform to facilitate future research on garment pose estimation and tracking.

In summary, the key contribution is a complete pipeline for garment pose tracking, including data collection, dataset creation, and a strong baseline method. The VR-based data collection and large-scale annotation are also significant contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 The paper proposes a complete framework for category-level garment pose tracking, including a VR system for data collection, a large-scale simulation dataset, and an end-to-end online tracking approach. The key idea is to leverage temporal information and shape priors to achieve more stable and accurate garment pose estimation compared to single-frame methods.
