# [Online Informative Sampling using Semantic Features in Underwater   Environments](https://arxiv.org/abs/2402.03636)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Underwater environments remain largely unexplored and autonomous underwater vehicles (AUVs) play a key role in underwater explorations and monitoring. However, continuous monitoring generates a lot of data and live data feeds require large onboard storage on AUVs. 
- Existing informative sampling techniques offer a solution by condensing observations but lack semantic awareness and real-time adaptability.

Proposed Solution:
- The paper proposes a Semantic Online Informative Sampling (SON-IS) approach that samples an AUV's visual experience in real-time while aligning the sampling outcomes with desired semantic information.

- SON-IS has two key modules:
   1) Feature Extraction Module: Obtains visual features from a DETR model fine-tuned on an underwater dataset to encode semantic information
   2) Online Informative Sampling Module: Built upon the ROST algorithm, selects the most informative and semantically distinct frames 

Main Contributions:
- A novel SON-IS algorithm for semantically-aware online informative sampling by combining an object detection model with an online semantic sampler

- A user study to validate that SON-IS identifies more semantically meaningful and representative frames compared to the state-of-the-art

- A new evaluation metric called Semantic Representative Uniqueness Metric (SRUM) that scores the semantic meaningfulness and representativeness of automated samples against human-picked samples

The results demonstrate that SON-IS outperforms prior work in capturing informative and semantically unique frames from underwater footage in real-time. The proposed SRUM metric provides a way to benchmark automated sampling approaches against human judgment.
