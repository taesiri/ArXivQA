# [L3Cube-IndicNews: News-based Short Text and Long Document Classification   Datasets in Indic Languages](https://arxiv.org/abs/2401.02254)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is a shortage of comprehensive datasets for Indian regional languages (Indic languages) to support natural language processing (NLP) research. Existing datasets have limitations in diversity of categories, sources, and consistency of classification criteria.
- Most Indic languages have linguistic complexity and low-resource status which has hindered NLP progress. 
- There is a need for specialized datasets with varying sequence lengths to develop models like LongFormer which are sensitive to text length.

Proposed Solution:
- The authors introduce L3Cube-IndicNews, an extensive multilingual news article classification dataset covering 10 major Indic languages with 10-12 categories per language. 
- The corpus has over 3 lakh records and includes 3 subsets - Short Headlines Classification (SHC), Long Paragraph Classification (LPC), and Long Document Classification (LDC) to handle varying document lengths.
- The datasets are scraped from diverse Indian news websites and cleaned to ensure optimal use.

Main Contributions:
- Introduction of a large-scale, high-quality dataset for text classification in Indic languages with consistent labeling between headline, paragraph and full document versions.
- The dataset can enable topic classification models and cross-lingual analysis for Indian languages due to high label overlap.
- Benchmarking of models like monolingual BERT, IndicSBERT, IndicBERT on the new datasets for each language. 
- The best performance was shown by L3Cube's monolingual BERT models on most datasets.
- Public availability of the datasets to advance Indic language NLP research.

In summary, the paper introduces much-needed text classification datasets for Indic languages, analyzed with state-of-the-art models, to significantly enrich resources for regional language NLP. The datasets and models have been publicly released to enable further research.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper introduces L3Cube-IndicNews, a multilingual text classification dataset for 10 Indian languages, comprising over 3 lakh news headlines and articles systematically categorized into 10 or more classes, which is benchmarked using state-of-the-art BERT models to demonstrate its utility.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1) Introduction of L3Cube-IndicNews, an extensive document classification dataset spanning ten significant Indian languages, each consistent with a range of 12 target labels. The dataset can also be used for news article headline-generation tasks.

2) The corpus comprises three sub-datasets (IndicNews- SHC, LPC, and LDC) catering to short, medium, and long documents, each with varying sentence lengths but consistent target labels. 

3) The datasets are bench-marked using state-of-the-art pre-trained BERT models: L3Cube monolingual BERT, L3Cube monolingual SBERT, L3Cube IndicSBERT (multilingual) and IndicBERT.

In summary, the paper introduces a comprehensive set of classified news datasets in 10 Indian languages that can enable further research in text classification and headline generation for low-resource Indic languages. The datasets are evaluated using several BERT-based models as a benchmark.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the key terms and keywords associated with it include:

- Indic languages: The paper focuses on 10 prominent Indic languages including Hindi, Bengali, Marathi, Telugu, Tamil, Gujarati, Kannada, Odia, Malayalam, and Punjabi.

- News articles datasets: The paper introduces L3Cube-IndicNews, a multilingual news article classification dataset for Indian regional languages. 

- Text classification: The datasets are aimed at text classification tasks, categorizing news articles based on their content.

- BERT models: The paper evaluates the datasets using monolingual BERT, multilingual IndicSBERT, and IndicBERT models.

- Dataset types: Three dataset types are introduced - Short Headlines Classification (SHC), Long Document Classification (LDC), and Long Paragraph Classification (LPC) to handle varying text lengths.

- Low resource languages: The goal is to expand NLP resources for low resource Indic languages that lack abundant quality datasets.

- Web scraping: The news articles were scraped from various Indian news websites in each language.

Some other related terms are news headlines, supervised learning, target labels, fine-tuning, accuracy metrics, confusion matrices, etc. Let me know if you need any clarification or have additional questions!


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions scraping news articles from various websites. What was the rationale behind selecting those specific websites as sources for the datasets? Were any inclusion or exclusion criteria used?

2. The paper states that the data was cleaned by filtering out tokens not matching the character set of each language. Can you expand more on this process? Were there any other data cleaning steps involved? 

3. The Long Paragraph Classification (LPC) dataset was created by taking a subset from the full news articles. What was the rationale behind taking only 35% instead of a different percentage? How was this subset selected - randomly or based on some criteria?

4. The paper benchmarks performance using accuracy. Were any other evaluation metrics considered during model development like F1 score, precision, recall etc? If not, what was the reason to focus only on accuracy?

5. For the Short Headlines Classification task, the accuracy scores were comparatively lower across models. Does the paper analyze the possible reasons behind this in more depth? Are there any error analysis results on where the models are struggling?

6. The best results seem to be with the Long Document Classification dataset across models. Does the paper do any comparative analysis on if there is a correlation between document length and model performance? 

7. The paper mentions unifying the model selection by choosing monolingual SBERT. What was the criteria used to select SBERT over the other models? Were there any ablation studies or statistical significance testing done?

8. The paper talks about potential future work in cross-dataset analysis. Can you expand more on what specific experiments are planned for cross-dataset model evaluation?

9. For real-world deployment, what would be the recommended model and dataset combinations based on the empirical results?

10. The paper utilizes pretrained models like MuRIL and IndicBERT. Was there any analysis done on the impact of pretraining data size or domain on downstream performance?
