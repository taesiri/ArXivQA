# [Linking Emergent and Natural Languages via Corpus Transfer](https://arxiv.org/abs/2203.13344v1)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: How can emergent languages developed through multi-agent communication games be evaluated and related to natural languages? 

Specifically, the authors are interested in developing computational approaches to study how perceptual grounding and communicative goals shape emergent languages, and relating these emergent languages to natural human languages. The key hypotheses appear to be:

1) Emergent languages developed in multi-agent games can provide benefits when transferred to natural language tasks like language modeling and image captioning, especially in low-resource scenarios.

2) Emergent-to-natural language translation can serve as a proxy metric to evaluate emergent languages and predict their utility for natural language tasks. This translation-based metric correlates better with downstream performance than commonly used in-game metrics like accuracy and topographic similarity.

3) Structural properties like compositionality in emergent languages may be better captured through translation proximity to natural language rather than disentanglement of input attributes.

Overall, the paper aims to link emergent and natural languages by proposing computational techniques to transfer and translate between them. The central goal is developing better evaluation methods for emergent languages using natural language tasks and resources.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- Proposing a novel approach to link emergent and natural languages by using corpus transfer, i.e. pretraining on a corpus of emergent language messages for downstream natural language tasks like language modeling and image captioning. 

- Showing that pretraining on an emergent language corpus can provide non-trivial transfer benefits for natural language tasks, especially in low-resource setups. For example, pretraining on 2 million emergent tokens reduced perplexity by 24.6% on average across 10 languages compared to training from scratch on 2 million natural tokens.

- Introducing a new metric to evaluate emergent languages based on translating them to corresponding natural language captions. This translation-based metric better correlates with downstream performance than commonly used in-game metrics like accuracy or topographic similarity.

- Providing analysis and ablations on the emergent communication setup and transfer process to understand what properties contribute to successful transfer, such as the need for grounding on perceptual stimuli and retaining sentence structure.

In summary, the main contribution appears to be proposing and demonstrating a novel corpus transfer technique to link emergent and natural languages in a way that provides practical benefits and new insights compared to prior work. The paper highlights the potential of leveraging natural language resources and tasks to analyze and improve emergent communication research.
