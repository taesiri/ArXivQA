# [TriVol: Point Cloud Rendering via Triple Volumes](https://arxiv.org/abs/2303.16485)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper aims to address is how to generate photo-realistic and view-consistent images from point cloud inputs. The key hypothesis is that a novel 3D representation called TriVol, composed of three slim feature volumes, can be used with NeRF rendering to effectively solve the point cloud rendering task.

Specifically, the paper hypothesizes that:

1. The proposed TriVol representation can capture both local and non-local features from the point cloud in an efficient way, enabling high-resolution 3D feature volumes to be generated. 

2. The feature volumes in TriVol are continuous and discriminative, allowing accurate and consistent feature querying via trilinear interpolation.

3. By combining TriVol with NeRF volume rendering, the model can generate high-quality rendered images from point clouds that are free of hole artifacts and inconsistent views.

4. The category-specific TriVol representation enables rendering novel scenes/objects of the same category without fine-tuning.

The key innovation is the TriVol 3D representation and how it is integrated into a NeRF-based renderer. Experiments demonstrate state-of-the-art performance in generating photo-realistic point cloud renderings.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel 3D representation called TriVol for point cloud rendering. The key points are:

- TriVol consists of three slim volumes encoded from the input point cloud. Compared to dense voxels, TriVol is more lightweight and allows for higher resolution 3D representation. 

- An effective encoder-decoder framework is proposed to transform the point cloud to dense and continuous Feature TriVol, which enables accurate feature querying via trilinear interpolation.

- By combining TriVol with NeRF for volume rendering, the method can generate photo-realistic and view-consistent results from point clouds.

- Experiments on scene- and object-level datasets demonstrate the advantages of TriVol over other representations and point cloud rendering methods. The framework also shows excellent generalization ability without fine-tuning on unseen data.

In summary, the main contribution is proposing the TriVol representation that enables efficient yet accurate point cloud rendering, with both quantitative and qualitative improvements over prior arts. The effectiveness is validated on various benchmarks.
