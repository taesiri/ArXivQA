# [Label-Noise Learning with Intrinsically Long-Tailed Data](https://arxiv.org/abs/2208.09833)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question it addresses is: 

How to learn from label-noisy data that has an intrinsically long-tailed class distribution?

The key points are:

- The paper presents a more general and realistic problem setting where the training data has both noisy labels and an intrinsically long-tailed class distribution. 

- This joint problem setting poses two main challenges:

1) Distribution inconsistency between the observed and intrinsic class distributions due to the label noise. 

2) Difficulty in distinguishing clean and noisy samples in the intrinsic tail classes.

- The paper proposes a learning framework called TABASCO to address these challenges. The main contributions are:

1) Two new sample separation metrics (WJSD and ACD) designed specifically to separate clean and noisy samples in the tail classes.

2) A two-stage sample selection strategy combining dimension selection and cluster selection to effectively identify clean samples in the tail classes. 

3) Introduction of two new benchmarks with real-world noise and intrinsic long-tail distributions for method evaluation.

- Experiments demonstrate TABASCO's effectiveness in learning from noisy labels with intrinsic long-tail distributions, outperforming existing methods.

In summary, the central hypothesis is that the proposed TABASCO framework can effectively address the key challenges that arise in label-noise learning with intrinsic long-tail data distributions. The paper's experiments aim to validate this hypothesis.
