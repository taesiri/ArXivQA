# SPG-Net: Segmentation Prediction and Guidance Network for Image   Inpainting

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can semantic segmentation information be exploited to improve image inpainting results, particularly along object boundaries? The key hypotheses appear to be:1) Existing deep generative models for image inpainting do not effectively utilize segmentation information to constrain object shapes, leading to blurry results on boundaries between objects.2) Introducing semantic segmentation as an intermediate representation can disentangle inter-class differences and intra-class variations, enabling sharper recovered boundaries and better texture generation. 3) A multi-network framework that first predicts segmentation labels in the missing region and then uses them to guide image synthesis will outperform existing end-to-end generative models.4) Allowing interactive editing of the predicted segmentation maps enables multi-modal image inpainting results.In summary, the central research question is how semantic segmentation can be integrated into deep generative models to improve image inpainting quality, especially along object boundaries. The key hypotheses are that explicit modeling of segmentation will lead to better disentanglement of shape and texture, and that a multi-step prediction process enables better utilization of the segmentation signal.
