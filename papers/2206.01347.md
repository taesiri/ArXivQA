# [MultiHiertt: Numerical Reasoning over Multi Hierarchical Tabular and   Textual Data](https://arxiv.org/abs/2206.01347)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing QA datasets over hybrid textual and tabular data only contain a single flat table per document. They lack complex examples requiring multi-step reasoning across multiple hierarchical tables and paragraphs.
- Hierarchical tables with multi-level headers are common in real-world documents like financial reports. Reasoning on them is challenging as it requires multi-level and bi-dimensional indexing.
- No existing benchmarks focus on numerical reasoning questions over documents with multiple hierarchical tables and long free text.

Proposed Solution:
- The authors construct a new large-scale QA dataset called MultiHiertt with 10,440 examples. 
- Each document in MultiHiertt contains multiple hierarchical tables, longer free text passages, and more complex reasoning is required to answer questions.
- The dataset has rich annotations including supporting facts and numerical reasoning programs.
- The authors also propose a QA model called MT2Net that first retrieves relevant facts then performs multi-step reasoning to answer questions.

Main Contributions:
- MultiHiertt is the first dataset for studying numerical reasoning over hybrid content with multiple hierarchical tables per document.
- MultiHiertt requires retrieving facts from multiple tables and text then performing more complex multi-step reasoning.
- MultiHiertt has 10,440 expert-annotated examples along with supporting facts and reasoning programs.
- A new model MT2Net is proposed and shown to outperform baselines, though there is still a large gap vs. human performance.
- MultiHiertt serves an important benchmark to drive progress on numerical reasoning over complex hybrid documents.


## Summarize the paper in one sentence.

 This paper presents MultiHiertt, a new large-scale question answering dataset for numerical reasoning over documents containing multiple hierarchical tables and long free text passages.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Proposing a new large-scale dataset MultiHiertt with 10,440 QA pairs over documents containing multiple hierarchical tables and paragraphs. The dataset has full annotations of numerical reasoning processes and supporting facts.

2. The documents in MultiHiertt are more complex than existing QA datasets, with longer texts, more tables per document, and questions requiring more reasoning steps across multiple tables.

3. Introducing a new QA model MT2Net that consists of a facts retrieving module to extract relevant facts and a reasoning module to perform multi-step reasoning to answer questions. 

4. Conducting comprehensive experiments showing that MT2Net outperforms other baselines but still lags behind human performance, indicating that MultiHiertt presents a challenging testbed for future research.

In summary, the key contribution is proposing the new MultiHiertt dataset to facilitate research on complex numerical reasoning over documents with multiple hierarchical tables, along with a baseline model MT2Net.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- MultiHiertt - The name of the dataset presented in the paper. Stands for "Multi Hierarchical Tabular and Textual data".

- Numerical reasoning - A key focus of the paper is on numerical reasoning over hybrid data containing both text and tables.

- Financial reports - The MultiHiertt dataset is constructed from financial reports and contains textual paragraphs as well as multiple hierarchical tables.

- Question answering - The paper presents MultiHiertt as a question answering benchmark and introduces a model called MT2Net for this question answering task.

- Supporting facts - The dataset contains annotations of supporting facts needed to answer each question.

- Reasoning programs - Along with questions and answers, reasoning programs detailing the numerical operations necessary to derive answers are provided. 

- Multi-step reasoning - Many examples require complex, multi-step numerical reasoning across both the text and multiple tables.

So in summary, key terms cover the dataset itself, the task of numerical question answering, the financial report domain, and aspects like supporting facts and multi-step reasoning that make the problem challenging.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. What is the motivation for combining both facts retrieving and reasoning modules in the proposed MT2Net model rather than using an end-to-end approach? How do the two modules complement each other?

2. Why does the proposed model linearize each table cell along with its hierarchical row and column headers rather than simply flattening the table rows? What is the benefit of preserving hierarchical structure information?  

3. The proposed model uses different sub-modules for arithmetic program answers and span answers. Why is this dual approach used instead of a single unified answer prediction module? What are the limitations of each sub-module?

4. One core challenge mentioned is reasoning across multiple tables. What modifications could be made to the proposed model architecture to better handle multi-table reasoning?

5. For questions requiring multiple reasoning steps, what method could be used to decompose them into simpler sub-questions? How would you integrate the answers to the sub-questions? 

6. What recent advances in encoding tabular data could be incorporated into the facts retrieving module to better understand complex table structures?

7. What types of external structured knowledge could be utilized to inject financial domain knowledge into the model? How would you integrate this effectively?

8. What adjustments need to be made to the loss function and output layers to support more complex symbolic reasoning operators beyond just arithmetic?

9. How suitable is the proposed model for handling completely unstructured documents without tabular data? What modifications would be needed?

10. The model performance lags significantly behind human experts. What direction of work is most promising to close this gap? What specific architectural changes or training approaches should be explored?
