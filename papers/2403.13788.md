# [DepthFM: Fast Monocular Depth Estimation with Flow Matching](https://arxiv.org/abs/2403.13788)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "DepthFM: Fast Monocular Depth Estimation with Flow Matching":

Problem:
- Monocular depth estimation is important for many computer vision tasks, but remains challenging. Discriminative methods suffer from blurry edges and lack of detail. Generative diffusion models (e.g. Marigold) produce high quality results but have very slow sampling. 

Proposed Solution:
- The paper proposes a generative flow matching approach called DepthFM for fast and high quality monocular depth estimation.
- It transfers knowledge from an image diffusion model (SD2.1) to the flow matching model, allowing it to be trained on only synthetic data while generalizing to real images.
- An auxiliary surface normal loss is used during training to improve depth estimates.
- Data-dependent couplings are utilized for efficient training. The model regresses vector fields between input image latents and output depth latents.

Main Contributions:
- DepthFM achieves state-of-the-art monocular depth estimation results, with sharp detail and realistic geometry.
- It is much faster than diffusion models, producing high quality results in just 1 function evaluation.
- Despite being trained only on synthetic data, it generalizes very well to complex real world images.
- The integration of an image diffusion model prior and surface normal loss allows training with minimal data.
- As a generative model, DepthFM also provides uncertainty estimates of its depth predictions.
- DepthFM enables state-of-the-art performance on depth completion and conditional image synthesis tasks.

In summary, DepthFM advances monocular depth estimation through an efficient flow matching approach that leverages diffusion model priors and surface normals training to achieve fast yet accurate results even when trained on synthetic data only.
