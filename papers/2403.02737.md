# [Neural Fractional Differential Equations](https://arxiv.org/abs/2403.02737)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Real-world systems often exhibit complex dynamics with memory effects and dependencies on past states beyond immediate previous states. Traditional ordinary differential equations (ODEs) used in modeling may not adequately capture such intricate dynamics.

- Recently introduced Neural ODEs adjust an ODE to fit dynamics of data, but are still limited by ODE assumptions like locality and lack of memory.

Proposed Solution:
- The paper proposes Neural Fractional Differential Equations (Neural FDEs) - a novel neural network architecture that adjusts a fractional differential equation (FDE) to data dynamics. 

- FDEs expand derivatives and integrations to non-integer orders, enabling representation of dynamics with memory effects. The proposed architecture has 3 main components:
   1) A neural network adjusting the FDE by learning the function f(h(t), t).
   2) A neural network adjusting the order α of the derivative.
   3) An FDE solver that computes the solution.

- During training, the FDE solver propagates gradients back through entire time history to optimize weights/biases of both networks to minimize error between FDE solution and data.

Main Contributions:

- First neural network architecture proposed to fully fit an FDE to data dynamics, including learning the derivative order α.

- Provides background on Neural ODEs, necessary concepts of FDEs and justification for using FDEs to model memory.

- Analyzes computational complexity and memory costs of Neural FDEs.

- Evaluates proposed Neural FDE on various synthetic datasets from dynamical systems and compares performance to Neural ODE baseline.

- Demonstrates superior performance of Neural FDE in modeling memory effects and faster convergence, establishing it as a competitive architecture.

In summary, the paper proposes Neural FDEs that leverage fractional calculus to effectively capture intricate dynamics with memory, outperforming Neural ODEs. The architecture, experiments and analyses provide a comprehensive basis for further research into fractional-order neural networks.
