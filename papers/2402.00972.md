# [Closure Discovery for Coarse-Grained Partial Differential Equations   using Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2402.00972)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Reliable simulations of critical real-world phenomena like weather, wildfires, and epidemics often rely on models described by partial differential equations (PDEs). However, fully resolving all scales in the PDEs with numerical simulations can be prohibitively expensive. As an alternative, coarse-grained simulations using lower resolutions and empirical closure models are frequently employed but have limitations in accuracy. The paper aims to develop a systematic approach for identifying closure models to improve the accuracy of coarse-grained PDE simulations.

Proposed Solution:
The paper proposes a novel multi-agent reinforcement learning (MARL) framework called CNN-MARL to discover closure models that correct errors introduced by coarse-grained discretization of PDEs. 

In CNN-MARL, agents are placed at each grid point of the coarse simulation and take local actions to introduce a forcing term that compensates for the numerical error. The agents collectively learn a central policy represented by a fully convolutional neural network (FCN) that maps simulation states to actions. Locality serves as an inductive bias as each agent only observes information from neighboring grid points through the FCN architecture. 

The local reward signal for each agent is based on the difference between the coarse and associated fine grid simulation, incentivizing actions that improve accuracy. Adaptive truncation also helps stabilize training.

Key Contributions:

- Proposes a MARL framework to systematically identify closure models for under-resolved PDE simulations in a more general, automated manner compared to prior physics-specific approaches

- Utilizes locality and shared central policy architecture for efficient training with many agents 

- Achieves accurate predictions for both in-distribution and extrapolative test cases, indicating actual discovery of missing dynamics rather than just overfitting

- Demonstrates interpretable agent actions that strongly correlate with theoretical numerical error, effectively correcting the numerical discretization 

- Obtains speedup over fully resolved simulation by compressing some fine-scale computations

The capabilities and limitations of the method are analyzed through numerical experiments on the advection and viscous Burgers' equation.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a multi-agent reinforcement learning framework with a central policy network to systematically identify closure models that compensate for errors in coarse-grained discretizations of time-dependent partial differential equations.


## What is the main contribution of this paper?

 According to the paper, the main contribution is proposing a novel methodology called CNN-MARL (Convolutional Neural Network based Multi-Agent Reinforcement Learning) for the automated discovery of closure models in coarse-grained discretizations of time-dependent partial differential equations (PDEs). Specifically, the CNN-MARL framework uses a central policy represented by convolutional neural networks and exploits locality as an inductive bias to compensate for numerical errors in a coarse grid simulation of a PDE. The method is shown to accurately predict both in-distribution and out-of-distribution test cases for the advection equation and Burgers' equation, while also providing a significant speedup compared to resolving all scales. So in summary, the key contribution is a new MARL approach for learning closure models that can improve coarse-grained PDE simulations.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, here are some of the key terms and keywords associated with it:

- Multi-Agent Reinforcement Learning (MARL)
- Closure Modeling 
- Partial Differential Equations (PDEs)
- Coarse-Graining
- Convolutional Neural Networks (CNNs)
- Locality/Local Rewards
- Extrapolative Predictions
- Inductive Bias
- Truncation Error Correction
- Advection Equation
- Burgers' Equation

The paper proposes a MARL framework called CNN-MARL for discovering closure models in coarse-grained discretizations of time-dependent PDEs like the advection and Burgers' equations. Key ideas include using a central CNN policy to leverage locality, defining local rewards based on the truncation error between coarse and fine simulations, incorporating inductive bias, and demonstrating improved accuracy and stability for both in-distribution and extrapolative predictions. So the main keywords revolve around MARL, PDEs, coarse-graining, closure modeling, CNN policies, locality, and inductive bias.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a multi-agent reinforcement learning (MARL) framework for discovering closure models in coarse-grained partial differential equations (PDEs). How does the use of MARL help discover effective closure models compared to using a single agent reinforcement learning framework? What are the advantages and disadvantages?

2. The paper uses a central policy represented by convolutional neural networks (CNNs) that all agents share. Why is using a CNN beneficial for this task compared to other neural network architectures? How does it help exploit locality and inductive bias?

3. The local rewards in the MARL framework are based on the difference between the coarse-grid simulation (CGS) and fine-grid simulation (FGS). Why is this an effective reward formulation? How sensitive are the results to changes in the specific reward function?

4. The actions predicted by the MARL framework are shown to be highly correlated with the truncation errors of the numerical scheme used in the CGS. Why does this correlation emerge? What does it tell us about what the agents are learning?

5. How suitable is the proposed framework for very large-scale simulations where computational constraints necessitate highly coarse discretizations? Would the CNN-based policy still be effective or would modifications be needed?

6. The receptivity field analysis shows each agent can observe a 33x33 patch of the domain. How does the size of this observation impact learning and resulting policies? Is there an optimal observation size?

7. Could inductive biases other than locality be effectively incorporated? For example, using parameterized mappings based on known physical constraints as done in works like Greydanus et al. (2019).  

8. The method trains agents by truncating episodes when the CGS and FGS diverge too much. What is the rationale behind this? How sensitive are the results to the specific truncation threshold?

9. The results demonstrate generalization to out-of-distribution test cases. What properties of the method enable this? Are there ways generalization could be further improved?

10. What other PDE systems could this method be applied to? Would the same CNN-MARL approach work for very complex multiscale PDE models like turbulent flow simulations? What adaptations would be needed?
