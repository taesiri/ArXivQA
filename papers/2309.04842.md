# [Leveraging Large Language Models for Exploiting ASR Uncertainty](https://arxiv.org/abs/2309.04842)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: Can large language models leverage and exploit the uncertainty information in ASR n-best hypotheses to improve performance on downstream spoken language understanding tasks like intent classification and keyword spotting?The key hypothesis appears to be:By exposing the LLM to n-best lists of ASR hypotheses instead of just the error-prone 1-best output, the LLM can better exploit the ASR uncertainties and ambiguities to positively impact the downstream SLU tasks.The authors propose using n-best lists as a "prompting-friendly" way to convey ASR uncertainty information to the LLM. They hypothesize that this will allow the LLM to correct or account for potential ASR errors when making predictions for intent classification or keyword spotting. They test this via prompt engineering to invoke the LLM's capabilities, as well as by finetuning Low-Rank Adapters with n-best prompt examples. Their experiments on device-directed speech detection and keyword spotting on the Google Speech Commands dataset aim to validate whether n-best ASR hypotheses can improve LLM performance on downstream SLU tasks compared to using just 1-best outputs.
