# [LTGC: Long-tail Recognition via Leveraging LLMs-driven Generated Content](https://arxiv.org/abs/2403.05854)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Long-tail recognition is challenging as models need to learn good representations from tail classes despite scarce data and class imbalance. Existing methods have limitations in obtaining correct and diverse knowledge for augmenting tail classes.  

Proposed Solution:
- The paper proposes a novel framework called LTGC that leverages large language models (LLMs) and large multimodal models (LMMs) to generate diverse and accurate content for augmenting tail classes.

- It first uses an LMM to extract textual descriptions of images from tail classes. These are input to the LLM to generate extended tail class descriptions covering missing features/scenes.  

- Text descriptions are converted to images via text-to-image models. A cyclic evaluation module ensures quality and diversity of generated images.

- A BalanceMix module is proposed to address domain shift and class imbalance during model fine-tuning with original + generated data.

Main Contributions:
- First work to leverage large models for long-tail recognition via generated content.

- Novel modules designed for controlled content generation, quality assurance of generated data, and efficient fine-tuning.

- Outperforms state-of-the-art methods on ImageNet-LT, Places-LT and iNaturalist 2018 datasets. Demonstrates effectiveness of generated content for handling tail data scarcity.

In summary, the key novelty is using large models to generate tailored content that augments scarce tail data for enhanced long-tail recognition, enabled via carefully designed modules in the overall framework.
