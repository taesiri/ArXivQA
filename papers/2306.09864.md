# [AvatarBooth: High-Quality and Customizable 3D Human Avatar Generation](https://arxiv.org/abs/2306.09864)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research goals and hypotheses of this paper are:- To develop a novel method for generating high-quality, customizable 3D human avatars from text prompts and/or images. The central hypothesis is that using dual fine-tuned diffusion models for the face and body along with other techniques will allow higher quality avatar generation compared to previous approaches.- To enable identity-customized avatar generation from arbitrary input images while still supporting text-based editing. The hypothesis is that fine-tuning diffusion models on personal photos along with introducing pose-consistent constraints will transfer facial and body appearance details to the generated avatar. - To achieve detailed 3D avatar generation through a coarse-to-fine optimization strategy. The hypothesis is that a multi-resolution score distillation scheme will improve rendering quality and robustness compared to fixed-resolution supervision.- To demonstrate that the proposed techniques of dual model fine-tuning, pose-consistent constraints, and multi-resolution score distillation allow higher quality and more customizable avatar generation compared to prior arts. The hypothesis is that the avatars generated by the proposed AvatarBooth framework will be more realistic, detailed, and controllable.In summary, the central goal is generating customizable, high-fidelity 3D avatars using diffusion model guidance and image/text inputs. The key hypotheses are around the benefits of the proposed model fine-tuning strategies, constraints, and multi-resolution supervision in achieving improved avatar quality and control compared to previous state-of-the-art.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. They propose a new framework AvatarBooth for generating high-quality 3D avatars from text prompts or images. The key idea is to use separate latent diffusion models to supervise the generation of the face and body. This allows capturing intricate facial details as well as clothing/accessories.2. They introduce a pose-consistent constraint during diffusion model fine-tuning. This enhances the consistency of synthesized head images across different poses and improves avatar geometry. 3. They present a multi-resolution score distillation sampling strategy that enables coarse-to-fine optimization of the avatar model. This enhances both rendering quality and training stability/robustness.4. Their method supports three modes: text prompt only, appearance customization from images, and a hybrid mode that allows further text-based editing of customized avatars. This provides flexibility in generating avatars.5. Experiments show their approach outperforms previous text-to-3D and image-to-3D avatar generation methods in terms of visual quality, geometry, and faithfulness to input prompts/images.In summary, the main contribution is a new avatar generation framework that leverages separate diffusion models for face/body along with innovations like pose-consistent fine-tuning and multi-resolution optimization. This allows high-quality customizable avatar creation from both text and images.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a novel framework called AvatarBooth for generating high-quality and customizable 3D human avatars from text prompts or images, using dual fine-tuned diffusion models to separately model the face and body, a pose-consistent constraint for better personalization, and a multi-resolution strategy for stable and detailed generation.
