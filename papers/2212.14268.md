# [Detection of out-of-distribution samples using binary neuron activation   patterns](https://arxiv.org/abs/2212.14268)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to effectively detect out-of-distribution (OOD) samples using binary neuron activation patterns (NAPs) extracted from hidden layers of deep neural networks. 

The key hypothesis is that the binary NAPs contain useful information about whether a sample comes from the distribution seen during training, and can be used to accurately identify OOD inputs. Specifically, the authors hypothesize that the Hamming distance between the binary NAPs of a test sample and training samples can indicate if the test sample is OOD or not.

The paper proposes a novel NAP-based method to extract binary activation patterns from both fully connected and convolutional layers of neural networks. It hypothesizes that comparing these binary NAPs to patterns collected during training allows measuring the model's predictive uncertainty and detecting OOD inputs.

The central research questions are:

1) Can binary NAPs extracted from hidden layers be effectively used for OOD detection? 

2) How should convolutional layer activations be pooled and binarized to obtain useful NAPs?

3) How should NAP-based distances from multiple layers be combined for optimal OOD detection?

4) Does the proposed NAP method outperform current state-of-the-art approaches for OOD detection?

The paper aims to answer these questions through extensive experiments on image classification models and datasets. Overall, it hypothesizes and shows that the proposed NAP approach provides an effective way to leverage hidden layer activations for OOD detection that outperforms existing methods.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes a novel method (NAP) for detecting out-of-distribution (OOD) samples in deep neural networks based on analyzing binary neuron activation patterns. 

2. It provides an extensive empirical evaluation comparing the proposed NAP method with 17 state-of-the-art OOD detection methods on two DNN architectures and 7 image datasets.

3. It introduces a technique to extract binary activation patterns from convolutional layers of DNNs by pooling and thresholding activations.

4. It presents the largest evaluation framework for OOD detection methods with all the code made publicly available. 

5. The experiments demonstrate that the proposed NAP method outperforms existing methods by a significant margin in terms of both AUROC and accuracy metrics.

In summary, the key contribution is the novel NAP technique for OOD detection that leverages binary activation patterns. This is shown through comprehensive experiments to achieve superior performance compared to prior art. The paper also makes several secondary contributions in terms of the evaluation framework, analysis of patterns from convolutional layers, and release of implementation code.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 The paper proposes a new method called Neuron Activation Patterns (NAP) to detect out-of-distribution samples in deep neural networks for image classification. The key idea is to extract binary activation patterns from hidden layers, compare them to patterns from the training data using Hamming distance, and identify outliers. The main finding is that NAP significantly outperforms prior state-of-the-art methods for out-of-distribution detection across various deep network architectures and image datasets.
