# [JMI at SemEval 2024 Task 3: Two-step approach for multimodal ECAC using   in-context learning with GPT and instruction-tuned Llama models](https://arxiv.org/abs/2403.04798)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Effectively capturing emotions in human conversations requires integrating multiple modalities like text, audio and video. However, the complexity of these diverse modalities poses challenges in developing an efficient multimodal Emotion Cause Analysis (ECA) system.  
- The paper tackles the Multimodal Emotion Cause Analysis in Conversations (ECAC) task on the Emotion-Cause-in-Friends (ECF) dataset which provides text, audio and video modalities. The task involves extracting emotion-cause utterance pairs from conversations.

Proposed Solution:
- A two-step framework is proposed:
   1. Predict emotion of each utterance in the conversation
   2. Predict causes of utterances labeled with emotions other than neutral
- Two approaches are presented:
   1. Instruction-tuning of two separate Llama 2 models for emotion and cause prediction
   2. In-Context Learning (ICL) using GPT-3.5 model. GPT-4V used for video captioning.
- Llama 2 models fine-tuned using prompt-based supervised learning. Entire conversation provided as context.
- GPT leverages ICL by retrieving similar conversations from training set and explaining their annotations to guide GPT's predictions.

Main Contributions:
- Novel two-step LLM-based framework for multimodal ECA decomposing it into emotion recognition and cause prediction
- Instruction-tuning of Llama 2 models treating tasks separately resulted in performance gains 
- Introducing ICL for multimodal ECA using GPT models and conversation retrieval system
- Use of GPT-4V for extracting conversation-level descriptions from videos
- System ranks 4th out of 25+ teams on competition leaderboard

In summary, the paper presents an effective two-step approach using LLMs for multimodal emotion cause analysis in conversations, validated through strong competition performance. The techniques of instruction-tuning Llama models and in-context learning with GPT models provide promising research directions.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper presents two large language model based approaches, instruction-tuned Llama models and in-context learning with GPT, for extracting emotion-cause pairs from multimodal conversations by first predicting emotions and then predicting causes of those emotions while utilizing conversation-level video descriptions from GPT-4V to provide additional context.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1) The authors propose a two-step framework for multimodal emotion cause analysis (ECA) in conversations. The first step predicts emotions of utterances and the second step predicts causes of emotional utterances using the predicted emotions.

2) Two approaches are presented - (i) Instruction-tuned Llama models, where two separate Llama 2 models are fine-tuned for emotion recognition and cause prediction tasks (ii) In-context learning with GPT-3.5 using demonstration examples to guide the model. 

3) Conversation-level video descriptions are generated using GPT-4V to provide additional context.

4) The system achieves competitive performance, ranking 4th on the ECAC leaderboard among over 25 teams. Ablation studies demonstrate the utility of the proposed instruction-tuning, in-context learning and video captioning.

In summary, the main contribution is a two-step multimodal ECA framework using LLMs with instruction/in-context learning and video captioning that achieves state-of-the-art performance on the ECAC task.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and keywords associated with it are:

- Multimodal emotion cause analysis (ECA)
- Emotion-Cause-in-Friends (ECF) dataset
- Text, audio, video modalities
- Emotion-cause pair extraction
- Two-step framework
- Instruction tuning
- Llama models
- In-context learning
- GPT models
- Video captioning
- Emotion recognition
- Cause prediction 
- Performance evaluation
- Weighted F1 score
- Ablation studies

The paper presents two approaches for multimodal emotion cause analysis: 1) Instruction tuning of Llama models, and 2) In-context learning with GPT models. It utilizes the ECF dataset containing text, audio and video for conversations. The key focus is on extracting emotion-cause pairs through a two-step process - emotion recognition followed by cause prediction. Performance is evaluated using weighted F1 and ablation studies are conducted. These are some of the central keywords and terminology associated with this paper.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes two approaches: instruction-tuned Llama models and in-context learning with GPT. What are the key differences between these two approaches and what are the relative advantages/disadvantages of each?

2. The instruction-tuned Llama approach trains separate models for emotion prediction and cause prediction. What is the motivation behind separating these two tasks? Does the paper experimentally validate if this is better than a joint model?

3. The in-context learning approach uses retrieval to find similar examples from the training set to aid GPT in making predictions. What encoding method is used to represent the examples and what similarity metric is used to find nearby neighbors? 

4. The paper incorporates video captions from GPT-4V to provide additional context. For the instruction-tuned Llama approach, adding captions degraded performance. Why does this happen and how is incorporating captions more effective in the GPT approach?

5. The cause prediction module of the GPT approach uses a fixed-sized context window instead of full conversations. What were the factors that motivated this design decision? How big is the context window used?

6. The paper reports improved performance from adding self-causes as a post-processing step. Why are self-causes so prevalent in this dataset and should they be explicitly modeled rather than just added as post-processing?

7. Both approaches seem to struggle with minority emotion categories like disgust and fear. What could be done to improve recognition of these emotions and properly handle the class imbalance?

8. How exactly is the Llama model instruction-tuned? What prompts are provided to the model as examples for emotion prediction and cause prediction tasks?

9. For the GPT in-context learning approach, what specific examples are retrieved from the training set and how are they formatted to explain the prediction tasks to GPT?

10. The error analysis reveals confusion matrices. What kinds of emotions are commonly confused by each model? Are there observable patterns and can we hypothesize why certain emotions are hard to discriminate?
