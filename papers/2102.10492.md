# [Deep ReLU Networks Preserve Expected Length](https://arxiv.org/abs/2102.10492)

## What is the central research question or hypothesis that this paper addresses?

This paper proves bounds on the expected length/volume distortion of deep ReLU networks at initialization. The main results are:1) The expected length distortion does not grow exponentially with depth, contrary to prior belief. In fact, it decreases slightly with depth. 2) Higher moments of the length distortion, as well as volume distortion of higher dimensional manifolds, are also bounded and well-behaved.3) These theoretical bounds are tight and accurately predict the empirical behavior of networks at initialization, unlike previous looser lower bounds.The central hypothesis is that deep ReLU networks at standard initialization have low complexity in terms of how they distort lengths/volumes. This is in contrast to the belief that length distortion grows exponentially with depth, which was based on prior theoretical lower bounds that are shown here to be loose. The paper proves tight upper bounds showing length/volume distortion is well-controlled.


## What is the main contribution of this paper?

This paper proves upper bounds on the expected length and volume distortion of deep ReLU networks at initialization. The key contributions are:- It shows that the expected length distortion of a 1D curve does not grow with network depth, contrary to prior belief. In fact, it decreases slightly with depth. Previous lower bounds suggesting exponential growth were loose. - It generalizes this to prove upper bounds on higher moments of length distortion, showing they are well controlled. For example, the variance is bounded by the ratio of output to input dimension.- It extends the analysis to consider distortion of higher dimensional manifolds, proving analogous upper bounds on expected volume distortion. - It provides experiments confirming that the theoretical predictions accurately capture subtle dependencies on network architecture, while prior bounds fail to do so.Overall, this rigorous analysis shows that with proper initialization, the functions computed by deep ReLU networks have low complexity according to length/volume distortion measures. This counters the common intuition that depth necessarily leads to exponential complexity, providing a piece towards demystifying why deep networks can generalize well in practice despite high parameter counts.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other related work:- The paper focuses specifically on analyzing length distortion in deep ReLU networks at initialization, whereas much prior work has studied expressivity and complexity more generally. The paper argues that analyzing the typical behavior at initialization is more relevant for understanding generalization.- The paper proves tight upper bounds on expected length distortion that show it does not grow, and actually shrinks slightly, with depth at initialization. This contrasts with prior work such as Raghu et al. (2017) and Poole et al. (2016) that provided lower bounds suggesting exponential growth. The authors point out a typo in the prior work that led to this incorrect conclusion. - The methodology relies on analyzing products of random matrices to derive precise expressions for the moments of length distortion, improving upon prior approaches. This allows the authors to show length distortion is tightly concentrated around its mean.- The results apply specifically for standard architectures and weight initializations used in practice, like He initialization, as opposed to worst-case or overly simple scenarios considered previously.- The paper generalizes the analysis from 1D curves to higher dimensional manifolds, showing similar upper bounds on volume distortion. This robustness helps confirm the overall picture.- Experiments are provided to empirically validate the new theoretical predictions and contrast with prior loose bounds. The experiments also verify subtle effects like the dependence on width predicted by the theory.Overall, the paper provides significantly tighter theoretical characterization of length distortion for modern deep neural networks compared to prior work. The methodology also serves as a template for how to rigorously analyze other notions of complexity.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors are:- Analyzing how their results on length and volume distortion extend to neural networks after training. The current results apply to networks at initialization, but the behavior may change during training. Studying length/volume distortion during and after training could shed light on the implicit regularization and generalization properties of neural network training.- Extending the analysis to convolutional networks, residual networks, and recurrent networks. The current proofs apply to fully-connected feedforward ReLU networks, but convolutional and residual architectures are widely used, so generalizing the results could be useful. The authors mention this as an interesting direction.- Relating length/volume distortion to other proposed complexity measures for neural networks, like curvature, compressibility, margins, etc. The authors suggest their techniques could extend to bound other notions of complexity. Making connections to measures that are known to correlate with generalization could be valuable.- Using properties like low distortion explicitly to design new training algorithms that control generalization. The authors suggest it could be promising to leverage this kind of theory to improve learning in practice. - Further analyzing the functions neural networks learn in practice through the lens of length/volume distortion or other complexity measures. While networks can represent complex functions, understanding which of these they actually fit to data is an open question.So in summary, the main suggestions are to extend and generalize the theoretical results, connect distortion to generalization, and use the theory to improve training, in order to better understand the functions learned by deep networks in practice. Analyzing trained networks and relating distortion to generalization seem to be the core recommended directions.
