# [Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural   Machine Translation](https://arxiv.org/abs/2005.10283)

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the central research question this paper addresses is whether maximum a posteriori (MAP) decoding, which aims to find the most likely translation, is adequate for neural machine translation (NMT) systems trained with maximum likelihood estimation (MLE). The paper argues that many of the known problems or pathologies with NMT, such as length bias and the beam search curse, are actually due to the inadequacy of MAP decoding rather than inherent flaws with the NMT model or MLE training. The authors contend that the probability distributions learned by MLE capture important aspects of translation well in expectation, but MAP decoding fails to utilize the full distribution.So in summary, the main question is whether MAP decoding is suitable for MLE-trained NMT systems, or whether alternative decoding methods that consider the full learned distribution would be better. The paper aims to show empirically that the model and training are reasonable, but MAP decoding contributes to observed problems.


## What is the main contribution of this paper?

The main contribution of this paper is arguing that many of the observed pathologies and biases in neural machine translation (NMT) are due to the use of maximum a posteriori (MAP) decoding rather than inherent problems with the NMT model or its training objective of maximum likelihood estimation (MLE). The key points are:- MAP decoding is not well suited as a decision rule for MLE-trained NMT models, as the mode/highest scoring translation often accounts for very little probability mass.- Many pathologies like length bias and beam search curse are partially caused by biases in MAP decoding rather than just the NMT model or MLE training.- Sampling-based decision rules like minimum Bayes risk (MBR) decoding that consider the full translation distribution holistically show promise as alternatives.- Experiments show NMT distributions capture statistics of training data well in expectation, while beam search outputs stray from those statistics.- An MBR approximation gives competitive results, confirming the potential of sampling-based decision rules that leverage the full distribution.Overall, the paper argues for moving beyond relying just on properties of the mode/MAP decoding when evaluating and predicting with MLE NMT models, and considering decision rules based on the full distribution.
