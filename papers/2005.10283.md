# [Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural   Machine Translation](https://arxiv.org/abs/2005.10283)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the central research question this paper addresses is whether maximum a posteriori (MAP) decoding, which aims to find the most likely translation, is adequate for neural machine translation (NMT) systems trained with maximum likelihood estimation (MLE). 

The paper argues that many of the known problems or pathologies with NMT, such as length bias and the beam search curse, are actually due to the inadequacy of MAP decoding rather than inherent flaws with the NMT model or MLE training. The authors contend that the probability distributions learned by MLE capture important aspects of translation well in expectation, but MAP decoding fails to utilize the full distribution.

So in summary, the main question is whether MAP decoding is suitable for MLE-trained NMT systems, or whether alternative decoding methods that consider the full learned distribution would be better. The paper aims to show empirically that the model and training are reasonable, but MAP decoding contributes to observed problems.


## What is the main contribution of this paper?

 The main contribution of this paper is arguing that many of the observed pathologies and biases in neural machine translation (NMT) are due to the use of maximum a posteriori (MAP) decoding rather than inherent problems with the NMT model or its training objective of maximum likelihood estimation (MLE). 

The key points are:

- MAP decoding is not well suited as a decision rule for MLE-trained NMT models, as the mode/highest scoring translation often accounts for very little probability mass.

- Many pathologies like length bias and beam search curse are partially caused by biases in MAP decoding rather than just the NMT model or MLE training.

- Sampling-based decision rules like minimum Bayes risk (MBR) decoding that consider the full translation distribution holistically show promise as alternatives.

- Experiments show NMT distributions capture statistics of training data well in expectation, while beam search outputs stray from those statistics.

- An MBR approximation gives competitive results, confirming the potential of sampling-based decision rules that leverage the full distribution.

Overall, the paper argues for moving beyond relying just on properties of the mode/MAP decoding when evaluating and predicting with MLE NMT models, and considering decision rules based on the full distribution.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper argues that many of the known problems with neural machine translation systems, such as length and lexical biases, are actually caused by the use of maximum a posteriori decoding rather than being inherent flaws in the model itself or its training objective.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other research in neural machine translation:

- It focuses specifically on criticizing the use of maximum a posteriori (MAP) decoding and beam search in NMT. Many papers have observed issues like the beam search curse, length bias, etc. but this paper directly argues these are due to MAP, not the NMT model itself.

- It provides extensive empirical analysis on multiple translation tasks to support its claims about the inadequacy of MAP decoding. This includes examining the full translation distribution, number of likely translations, sampling the mode, and sample quality. 

- It advocates for using the full translation distribution for prediction, rather than just the mode. It demonstrates promising results with an approximation to minimum Bayes risk decoding. Most prior work uses MAP/beam search for evaluation.

- It links many known issues in NMT like length bias and beam search curse to the use of MAP decoding. Other papers have identified these issues but not traced them back specifically to MAP as this paper does.

- It argues many criticisms of NMT based on the mode may not apply to the full distribution learned via MLE. Most prior analysis has focused just on the mode, so this perspective is unique.

Overall, this paper provides a thorough probabilistic perspective on analyzing and decoding from NMT models. It makes a compelling case against reliance on MAP decoding compared to prior work. The analysis and experiments looking at the full distribution and alternative decoding also set it apart from other research on known issues in NMT.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Further research into scalable sampling-based decision rules for NMT. The authors show promising results with their MBR approximation, but note it requires further investigation to close the performance gap with beam search in some settings. They advocate for developing better sampling-based alternatives to MAP decoding.

- Assessing improvements to MLE training from a probabilistic perspective. Rather than just evaluating model changes in terms of the mode (e.g. BLEU on beam outputs), the authors argue for also analyzing the impact on the full translation distribution.

- Exploring training objectives beyond MLE that still admit probabilistic interpretation. The authors note most alternatives to MLE optimize a decision boundary directly rather than a probability distribution.

- Analysis of other potential causes of the inadequacy of the mode problem beyond MAP decoding. The authors argue MAP is a major cause, but note other factors may play a role as well.

- Extending the comparative analysis of different decoding methods to other text generation tasks beyond machine translation.

- Developing better automatic evaluation metrics aligned with sampling-based decoding methods rather than focused on the mode.

In summary, the main directions are around developing improved sampling-based alternatives to MAP decoding, and critically analyzing model changes from a probabilistic perspective.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper argues that maximum a posteriori (MAP) decoding, which aims to find the most likely translation, is not a good decision rule for neural machine translation (NMT) models trained with maximum likelihood estimation (MLE). The authors show that NMT models learn distributions that spread probability mass over many possible translations, rather than concentrating mass on a single high-quality translation. As a result, the most likely translation under the model often has very little probability mass and can be of low quality. The paper demonstrates that many known issues with NMT models, like a length bias and beam search curse, are partially caused by using MAP decoding rather than being inherent flaws with the models or MLE training. The authors advocate for using decision rules based on sampling from the full learned distributions rather than only looking at the maximum likelihood translation. Experiments with minimum Bayes risk decoding, which considers the expected quality over samples from the distribution, give competitive results. Overall, the paper argues for evaluating and decoding from NMT models in a probabilistically principled way rather than relying only on MAP decoding.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper argues that maximum a posteriori (MAP) decoding, which aims to find the most likely translation, is not a suitable decision rule for neural machine translation (NMT) systems trained with maximum likelihood estimation (MLE). The authors show that the translation distributions learned by MLE assign probability mass across many candidate translations, with the most likely translation often accounting for only a tiny fraction of the total probability mass. This means the mode or most likely translation is essentially arbitrary and may not represent a good translation. 

The authors demonstrate issues with using MAP decoding such as length bias, beam search curse, and inadequacy of the mode. They show these issues are partially caused by the decision rule rather than the model or training algorithm. The paper advocates using decision rules based on the full translation distribution, such as minimum Bayes risk decoding. Experiments confirm this approach is competitive, suggesting the issues lie more with MAP decoding rather than NMT or MLE itself. Overall, the paper argues for moving away from MAP decoding towards approaches that utilize the full translation distribution.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes using minimum Bayes risk (MBR) decoding as an alternative to maximum a posteriori (MAP) decoding for making predictions in neural machine translation (NMT). MBR decoding selects the hypothesis that maximizes expected utility under the model rather than selecting the single most likely hypothesis like MAP. Since the translation distributions learned by NMT models are often quite flat, with the mode containing little probability mass, MAP decoding can result in low-quality translations. The authors show that samples from the learned distributions capture important statistics of the training data, indicating the model has learned meaningful distributions. MBR decoding allows them to leverage multiple samples from the distribution to select a high quality hypothesis. They approximate MBR by sampling candidate translations and selecting the sample that maximizes the average METEOR score against other samples. Experiments show this MBR approximation produces competitive results compared to beam search MAP decoding. Overall, the main method is using sampling and MBR decoding rather than MAP to leverage the full learned distributions.


## What problem or question is the paper addressing?

 The main problem this paper is addressing is the issue that maximum a posteriori (MAP) decoding, which is commonly used for predictions in neural machine translation (NMT), may not be well-suited for NMT systems. The authors argue that many of the known problems or "pathologies" of NMT, like length bias and beam search curse, are actually caused more by the use of MAP decoding rather than issues with the NMT model or training. 

The key questions the paper seems to be exploring are:

- Is MAP decoding an appropriate decision rule for NMT systems? 

- Are the known problems/biases of NMT really inherent to the model/training, or are they caused by the use of MAP decoding?

- Can alternative decision rules that consider the full translation distribution lead to better performance?

So in summary, the main focus is critically examining the use of MAP decoding in NMT and proposing that many issues attributed to NMT may stem from this, rather than the model itself. The authors suggest exploring alternative decoding methods that leverage the full distribution.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Neural machine translation (NMT)
- Maximum a posteriori (MAP) decoding
- Maximum likelihood estimation (MLE) 
- Beam search
- Length bias
- Beam search curse
- Inadequacy of the mode problem
- Label bias
- Exposure bias
- Ancestral sampling
- Minimum Bayes risk (MBR) decoding
- Translation distribution 
- Mode seeking predictions
- Sampling-based decision rules

The main concepts discussed are related to critiquing MAP decoding and mode seeking predictions in NMT, arguing that many observed pathologies are due to the use of MAP decoding rather than inherent problems with NMT models or MLE training. Key alternatives proposed are ancestral sampling to explore translation distributions and MBR decoding as a sampling-based decision rule.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to ask to create a comprehensive summary of the paper:

1. What is the main argument or thesis of the paper? 

2. What are the key pathologies or problems with neural machine translation that the paper discusses?

3. How does the paper argue that maximum a posteriori (MAP) decoding is inadequate for neural machine translation? What evidence does it provide?

4. What are some of the biases and problems introduced by using MAP decoding according to the paper?

5. How does the paper suggest using ancestral sampling to analyze neural machine translation models instead of MAP decoding? 

6. What statistics and properties of neural machine translation models does the paper analyze using ancestral sampling?

7. What are the results when analyzing neural machine translation models using ancestral sampling instead of MAP decoding?

8. How does the paper evaluate the quality of samples from neural machine translation models?

9. What is minimum Bayes risk (MBR) decoding? How does the paper suggest it could improve on MAP decoding?

10. What are the overall conclusions and implications of the analyses done in the paper? How does it aim to change perspectives on neural machine translation?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 potential in-depth discussion questions about the method proposed in this paper:

1. The paper argues that maximum a posteriori (MAP) decoding is not well-suited as a decision rule for neural machine translation (NMT). Do you agree with this assessment? Why or why not? What are some potential alternatives to MAP decoding that could better capture the full translation distribution?

2. The authors show that beam search outputs often diverge from training data statistics. What factors contribute to this divergence? How could beam search be modified to better reflect training data statistics in its outputs?

3. The paper advocates using sampling-based decision rules like minimum Bayes risk (MBR) decoding. What are the main challenges in scaling MBR decoding to large NMT systems and datasets? How could these challenges be addressed? 

4. The approximate MBR decoding proposed utilizes a limited sample size (30). How would performance change with larger sample sizes? What tradeoffs need to be considered in selecting the sample size?

5. The paper analyzes translation distributions using statistics like sequence length, unigram/bigram frequencies, etc. What other statistics could provide useful insights into properties of the translation distribution?

6. Could the conclusions from this analysis transfer to other conditional neural sequence models besides NMT, such as summarization or dialog systems? Why or why not?

7. The authors find translation distributions are often quite flat, with no clear preferences within the high-probability set. What properties of NMT models and training lead to this characteristic?

8. For low resource language pairs, the gap between beam search and MBR decoding was smaller. Why might this be the case? How does training data size affect the suitability of different decoding methods?

9. The paper studies MLE-trained models. How might the conclusions change for NMT systems trained with other objectives like label smoothing or minimum risk training?

10. The authors focus their analysis on Transformer models. How might the translation distributions and appropriate decoding strategies differ for other NMT architectures like RNNs?


## Summarize the paper in one sentence.

 The paper argues that maximum a posteriori (MAP) decoding is not well-suited as a decision rule for neural machine translation (NMT) due to the inadequacy of the mode in capturing important aspects of the translation distribution, and advocates for sampling-based decision rules that take the full distribution into account.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the key points from the paper:

This paper argues that maximum a posteriori (MAP) decoding, which seeks the highest scoring translation, is not an appropriate decision rule for neural machine translation (NMT). The authors show that NMT models learn probability distributions that spread mass across many possible translations, often with the most likely translation accounting for very little total probability mass. They demonstrate that criticisms of NMT based on properties of the MAP translation, such as the length bias, are not necessarily indicative of problems with the model itself. Rather, MAP decoding introduces biases that do not accurately reflect the full distribution learned by the model. The authors advocate for using the entire distribution, through techniques like sampling and minimum Bayes risk decoding, to make translation predictions. They show experimentally that sample quality is decent on average and that an approximation of minimum Bayes risk decoding can achieve strong performance, supporting their claim that the full distribution contains useful information not captured by MAP. Overall, this paper makes a compelling argument that we should move beyond MAP decoding in NMT to decision rules based on the full distribution.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1. The paper proposes using maximum a posteriori (MAP) decoding as the primary decision rule for neural machine translation (NMT). What are some potential weaknesses or limitations of relying solely on MAP decoding for predictions? Could other decision rules like minimum Bayes risk (MBR) decoding complement MAP decoding in certain scenarios?

2. The authors argue that criticisms of MAP decoding and its inadequacy as a decision rule do not necessarily imply issues with the NMT model itself or its training via maximum likelihood estimation (MLE). Do you agree with this view? Why or why not? 

3. How does the non-admissible heuristic search bias induced by beam search approximate MAP decoding potentially impact the translation distributions learned by NMT models? Could this bias explain some of the length and lexical biases observed?

4. The paper shows that translation distributions place probability mass across a very large space of possible translations. What does this suggest about the flatness of the distributions learned via MLE? How could the training procedure be altered to produce more peaked distributions?

5. For minimum Bayes risk (MBR) decoding, the choice of utility function is crucial. What types of utility functions would be most appropriate for capturing translation adequacy? How could the utility function be tailored to specific use cases?

6. The paper demonstrates that an approximation to MBR decoding shows promising results compared to MAP decoding via beam search. What are some ways the MBR approximation could be improved to get closer to true MBR performance?

7. How does ancestral sampling provide an unbiased view into the capabilities of an NMT model? What are some potential ways to leverage insights gained from sampling to improve the training process?

8. The inadequacy of the mode problem suggests the highest probability translations are often of low quality. Why might this problem occur, and how could the training process be altered to avoid it?

9. For low resource language pairs, the paper shows translation distributions place even less mass on any single high-quality translation. How could we design more suitable decision rules or training procedures for low-resource NMT?

10. The paper argues criticisms of MAP decoding do not necessarily apply to MLE-trained NMT models themselves. Do you agree? How could the training process itself be improved while still relying on MBR or sampling-based decoding?


## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the paper:

This paper argues that maximum a posteriori (MAP) decoding, the predominant decision rule in neural machine translation (NMT), is not well-suited for NMT systems trained with maximum likelihood estimation (MLE). The authors show through experiments on various translation tasks that the probability distributions learned by MLE-trained NMT models are quite flat, with the most likely translation often accounting for very little probability mass. They demonstrate that many known biases and pathologies of NMT, like the length bias and beam search curse, are not inherent to the model itself but rather due to the use of MAP decoding. The paper advocates for using decision rules like minimum Bayes risk (MBR) decoding that take into account the full translation distribution rather than just the mode. An approximation of MBR decoding is shown to give strong results, confirming the adequacy of MLE-trained NMT models if used appropriately. Overall, the paper provides evidence against criticisms of NMT based solely on properties of the MAP translation, and argues for assessing NMT systems from a probabilistic perspective using sampling and holistic decision rules.
