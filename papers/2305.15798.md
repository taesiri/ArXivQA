# [On Architectural Compression of Text-to-Image Diffusion Models](https://arxiv.org/abs/2305.15798)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is:Can classical architectural compression techniques be effectively applied to large-scale text-to-image diffusion models like Stable Diffusion to obtain smaller, faster, and more efficient models while retaining strong generation capabilities?The key hypothesis seems to be that by eliminating certain architectural components like blocks from the U-Net model in Stable Diffusion through approaches like fewer blocks, mid-stage removal, and inner stage removal, it should be possible to significantly reduce the model size, computational requirements, and latency while maintaining competitive performance. The authors propose compressed "BK-SDM" models obtained by removing blocks from the U-Net of Stable Diffusion and show they can be effectively pretrained with knowledge distillation using very limited computational resources. Experiments demonstrate these compact models achieve results on par with much larger models on zero-shot benchmarks and can be applied for personalized text-to-image generation.In summary, the paper explores architectural compression of diffusion models as a promising direction orthogonal to prior work on reducing sampling steps or model quantization to obtain efficient text-to-image generation. The effectiveness of this compression approach is the key hypothesis examined.
