# [A Light Weight Model for Active Speaker Detection](https://arxiv.org/abs/2303.04439)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to design a lightweight and efficient model for active speaker detection. The key hypothesis is that it is possible to achieve state-of-the-art performance on active speaker detection with a much smaller and faster model by:

1. Inputting only a single candidate face sequence instead of multiple candidates. 

2. Splitting 3D convolutions into separate 2D and 1D convolutions for more efficient visual feature extraction.

3. Splitting 2D convolutions into 1D convolutions for more efficient audio feature extraction.

4. Using a simple GRU module instead of complex attention modules for cross-modal modeling.

The paper proposes a full framework incorporating these ideas and conducts extensive experiments on the AVA-ActiveSpeaker benchmark to test the hypothesis. The results validate the hypothesis, showing the proposed lightweight model achieves 94.1% mAP accuracy using 23x fewer parameters and 4x less computation than prior state-of-the-art methods. This demonstrates it is possible to build highly accurate yet extremely efficient models for active speaker detection.

In summary, the key hypothesis is that with careful, lightweight design, active speaker detection can be done precisely and efficiently. The experiments confirm this central hypothesis and research question of the paper.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing a lightweight end-to-end framework for active speaker detection. The framework reduces computation and model size in three aspects: 

- Using a single candidate input instead of multiple candidates.

- Splitting 3D convolutions into separate 2D and 1D convolutions for more efficient visual and audio feature extraction. 

- Using a simple GRU module for cross-modal modeling instead of complex attention modules.

2. Designing a tailored loss function to train the model based on its single candidate input characteristics.

3. Demonstrating through experiments that the proposed framework achieves competitive performance to state-of-the-art methods on the AVA-ActiveSpeaker benchmark while being much more lightweight. It reduces parameters by 95.6% and FLOPs by 76.9% compared to previous best method while achieving just 0.1% lower mAP.

4. Showing through performance breakdown that the method outperforms previous methods in scenarios with different numbers of people and different face sizes.

In summary, the main contribution is proposing a highly efficient and lightweight end-to-end framework for active speaker detection that matches state-of-the-art accuracy while being much more suitable for deployment in resource-constrained real-time applications. The lightweight design and tailored training approach enable these advantages.
