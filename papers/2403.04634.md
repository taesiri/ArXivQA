# [Pix2Gif: Motion-Guided Diffusion for GIF Generation](https://arxiv.org/abs/2403.04634)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Pix2Gif: Motion-Guided Diffusion for GIF Generation":

Problem:
The paper tackles the problem of generating animated GIFs from a single image, conditioned on a text description and a measure of motion magnitude. Generating high-quality and temporally coherent GIFs is challenging compared to image generation. Existing video generation methods use 3D diffusion models which are expensive and provide limited control over frame-to-frame dynamics. 

Method:
The paper proposes "Pix2Gif", which formulates GIF generation as an image-to-image translation problem. It takes a source image, text prompt and numeric motion magnitude as input. A motion-guided warping module transforms the source image features based on the motion input, while maintaining consistency using a perceptual loss. This produces the warped features. The final output GIF frame is generated by the latent diffusion model conditioned on the warped features and text embedding. As this process rolls out, it generates a sequence of coherent frames comprising the GIF.

Contributions:
- First work to formulate GIF generation as an image translation problem guided by text and motion.
- Proposes a flow-based warping module to control temporal dynamics using motion magnitude input.
- Introduces a perceptual loss to retain visual consistency after warping.
- Curates a new dataset from TGIF for training, containing 78,692 short GIF clips.
- Achieves better coherence and control compared to recent video generation methods, along with emerging action compositionality.

The method is simple, efficient and provides fine-grained control over each frame's contents and motion. Both quantitative metrics and visual results demonstrate its effectiveness for high-quality controllable GIF generation across diverse domains.
