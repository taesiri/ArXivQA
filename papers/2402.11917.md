# [A Mechanistic Analysis of a Transformer Trained on a Symbolic Multi-Step   Reasoning Task](https://arxiv.org/abs/2402.11917)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Existing work has focused on developing sophisticated benchmarks to evaluate the reasoning capabilities of transformers, but does not provide insights into the internal mechanisms driving these capabilities. 
- This paper aims to improve our understanding of the internal mechanisms used by transformers for reasoning through a mechanistic analysis.

Methods:
- The authors train a small 6-layer transformer model on a symbolic path finding task in trees and analyze the mechanisms it learns.
- The model is given an edge list of a binary tree, a goal node, the root node, and must predict the path from root to goal.
- They use techniques like linear probes, activation patching, and causal scrubbing to validate hypotheses about internal mechanisms.

Key Findings:
- The model implements a backward chaining algorithm using "deduction heads", which start from the goal node and traverse the tree upwards. 
- It executes this algorithm in parallel from multiple "register token" positions to handle longer paths.
- It also uses a simple heuristic to predict if child nodes of current position are leaf nodes.
- Together, these mechanisms allow the model to perform multi-step deductive reasoning to solve the task.  

Contributions:
- Identified interpretable mechanisms like deduction heads and path merging that transformers use for reasoning.
- Showed how transformers adopt highly parallelized strategies involving register tokens when search/reasoning.
- Demonstrated that transformers are capable of meaningful reasoning beyond just pattern memorization.
- The motifs found could provide insights into internal mechanisms of more complex transformers.

In summary, the key contribution is a mechanistic analysis elucidating how transformers can perform structured symbolic reasoning for path finding using parallelizable subroutines. The identified motifs shed light on the inductive biases and operating principles of transformers for reasoning tasks.
