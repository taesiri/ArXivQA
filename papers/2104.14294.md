# [Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.14294)

## What is the central research question or hypothesis that this paper addresses?

This paper presents a self-supervised learning method called DINO (which stands for Distillation with No Labels) and studies its application to Vision Transformer (ViT) models. The central hypothesis is that self-supervised pre-training can provide unique benefits to ViT models compared to convolutional neural networks (CNNs), such as:- The self-attention layers in ViT can learn to segment objects in images, without any pixel-level supervision. - The global image features from ViT pretrained with DINO perform very well on nearest neighbor retrieval, outperforming CNNs.- ViT models pretrained with DINO transfer better to downstream tasks compared to supervised pretraining, unlike CNNs where supervised pretraining transfers better.In summary, the central hypothesis is that self-supervised pretraining with DINO provides complementary benefits to ViT models that are not realized with CNNs or supervised pretraining, enabling ViTs to learn implicit spatial/structural information about images. The paper explores this through extensive experimentation and analysis.
