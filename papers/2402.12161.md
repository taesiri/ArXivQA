# [Endowing Pre-trained Graph Models with Provable Fairness](https://arxiv.org/abs/2402.12161)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Endowing Pre-trained Graph Models with Provable Fairness":

Problem:
- Pre-trained graph models (PGMs) aim to capture transferable inherent structural properties of graphs and apply them to different downstream tasks. 
- Similar to language models, PGMs also inherit societal biases from the data, resulting in discriminatory and unfair predictions towards sensitive attributes like gender, race, etc.
- Existing methods to debias GNNs couple the debiasing process with model training, making them inflexible and inefficient for debiasing PGMs. Also, they lack theoretical guarantees on fairness.

Proposed Solution:
- The paper proposes GraphPAR, an adapter-tuning framework to efficiently and flexibly endow PGMs with provable fairness.
- It freezes PGM parameters and trains an adapter module instead to remove sensitivity dependencies. This makes it flexible as the same PGM can handle different downstream tasks and sensitive attributes.
- A sensitive semantic augmenter extends node representations with different sensitive attribute semantics. The extended representations are used to train the adapter to prevent propagation of sensitivity semantics.
- Formal guarantees on fairness are provided by constructing smoothed adapter and classifier versions and comparing their robustness radii. If the adapter radius is smaller, predictions are provably robust to sensitivity changes.  

Main Contributions:
- First work to identify and mitigate bias in PGMs instead of vanilla GNNs
- GraphPAR allows efficient and flexible debiasing of PGMs for downstream tasks via adapter-based tuning
- Sensitive semantic augmenter helps capture sensitivity information to train debiased adapter
- Provides formal guarantees on fairness based on robustness radii of smoothed adapter and classifier
- Extensive experiments show GraphPAR achieves state-of-the-art performance and fairness on multiple datasets. Over 90% nodes have provable fairness.

In summary, GraphPAR enables mitigating bias in PGMs to ensure fair predictions in downstream tasks with theoretical guarantees, outperforming prior fairness techniques.
