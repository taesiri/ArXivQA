# [MISC: Ultra-low Bitrate Image Semantic Compression Driven by Large   Multimodal Model](https://arxiv.org/abs/2402.16749)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Existing image compression algorithms face a trade-off between consistency with the original image and perceptual quality, especially at ultra-low bitrates (<0.024 bpp). Recently, with the rise of AI-generated images (AIGIs), compressing them effectively is also an open challenge.

Proposed Solution:
This paper proposes a new compression framework called Multimodal Image Semantic Compression (MISC) to achieve both high consistency and perceptual quality at ultra-low bitrates for both natural images and AIGIs. The key components are:

1) LMM Encoder: Uses GPT-4 Vision to extract textual descriptions of overall image and key objects, compressing images into semantic information.

2) Map Encoder: Uses CLIP to align text descriptions to spatial image regions, outputting positional maps.  

3) Image Encoder: Extremely compresses images into bitstreams as additional input.

4) Decoder: Controls diffusion models conditioned on above modalities to reconstruct high quality images.

Main Contributions:

1) First image compression method powered by large multimodal models in both encoder and decoder for optimal consistency and perception.

2) Constructed a high-quality database of 500 AIGIs for compression evaluation.

3) Extensive experiments showed the proposed MISC framework can save 50% bitrate while achieving the best balance of consistency and perceptual quality for both natural images and AIGIs at ultra-low bitrates.

In summary, this paper pioneers a new LMM-driven compression paradigm to achieve optimal visual quality at extremely low bitrates for both traditional and AI-generated visual content. The complete framework and new datasets open up many possibilities for next-generation visual communication systems.
