# [JustiLM: Few-shot Justification Generation for Explainable Fact-Checking   of Real-world Claims](https://arxiv.org/abs/2401.08026)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing methods for generating justifications in automated fact-checking oversimplify the task by summarizing existing fact-check articles authored by human fact-checkers. However, during inference, fact-check articles are not available for new claims that need to be verified. 
- Therefore, there is a need for a more realistic approach that can generate justifications based on retrieved evidence documents rather than relying on fact-check articles.

Proposed Solution:
- The paper proposes JustiLM, a novel justification generation model based on a retrieval-augmented language model that generates justifications using retrieved evidence documents. 
- A new dataset called ExClaim is introduced, containing real-world claims, human-written justifications, and reference documents. The documents are split into short chunks to enable fine-grained evidence retrieval.
- JustiLM utilizes fact-check articles only during training to distill signals at the article-level and chunk-level to guide justification generation based on retrieved documents.

Main Contributions:
- Realistic justification generation approach that does not rely on fact-check articles during inference.
- New ExClaim benchmark dataset containing claims, justifications and chunked reference documents.  
- JustiLM model that outperforms prior work like Atlas, Flan-T5 and shows promising performance compared to GPT-4.
- Demonstrates that incorporating fact-check articles via distillation techniques during training can enhance justification generation at inference time without needing articles.
- Shows that JustiLM can also improve veracity prediction when extended for joint training.

In summary, the paper presents a more realistic justification generation approach using an end-to-end retrieval-augmented LM trained with distillation techniques and a new benchmark dataset. The proposed JustiLM model outperforms prior work and also shows potential for joint veracity prediction.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The paper proposes JustiLM, a novel few-shot justification generation method for explainable fact-checking of real-world claims based on a retrieval-augmented language model framework that utilizes fact-check articles to provide training signals, along with a new benchmark dataset ExClaim derived from WatClaimCheck.


## What is the main contribution of this paper?

 The main contributions of this paper are threefold:

1. It proposes JustiLM, the first realistic justification generation method based on a retrieval-augmented language model that is trained end-to-end for explainable fact checking of real-world claims. It leverages fact-check articles as auxiliary information for model training only.

2. It constructs ExClaim, a new benchmark dataset derived from the WatClaimCheck dataset for explainable fact-checking. ExClaim contains 6,951 real-world claims and their corresponding veracity labels, human-written justifications, and a large searchable corpus of 957,949 chunk-level documents for fine-grained evidence retrieval. 

3. Experiments show that JustiLM achieves promising performance in justification generation compared to strong baselines including In-Context Learning enabled language models and the state-of-the-art few-shot RAG model Atlas. A straightforward extension of JustiLM for joint veracity prediction and justification generation also improves the veracity prediction task.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- Justification generation: The main task focused on generating explanations to support fact-checking verdicts.

- Explainable fact-checking: Producing explanations to enhance credibility and gain user trust in automated fact-checking systems. 

- Real-world claims: The paper uses real-world news claims rather than synthetic claims.

- Evidence retrieval: Retrieving relevant reference documents as evidence to fact-check claims, rather than relying on fact-check articles. 

- Few-shot learning: Training the justification generation model using only a small number of training examples.

- Retrieval-augmented language model (RAG): A framework that consists of a retriever to search evidence and a language model to generate text.

- Distillation techniques: Leveraging fact-check articles to provide supervisory signals during training phase to enhance justification quality.

- ExClaim dataset: A new benchmark dataset constructed based on WatClaimCheck dataset for explainable fact-checking.

- JustiLM: The proposed few-shot justification generation language model that utilizes fact-check articles via distillation techniques to improve performance.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes a justification generation method called JustiLM. What are the key components of JustiLM and how do they work together to generate justifications?

2. The paper constructs a new benchmark dataset called ExClaim. What are some key characteristics and statistics of this dataset? How is it derived and what challenges does it aim to address?  

3. The paper proposes two types of distillation techniques - article-level and chunk-level distillation. What is the key intuition behind each of these techniques and how are they implemented in JustiLM?

4. How does JustiLM incorporate fact-check articles to provide training signals? What is the rationale behind using fact-check articles only during training phase?

5. The paper compares JustiLM with several baselines. What are the key findings from the comparison? What insights do the results provide about the effectiveness of JustiLM?  

6. JustiLM is evaluated on a new test set containing emerging claims. How does JustiLM perform on this dataset compared to other methods? What does this suggest about the generalizability of JustiLM?

7. An extension of JustiLM is proposed for joint verification and justification. How is this implemented and what improvements does it achieve over the base JustiLM model?

8. What are some limitations of the experimental setup and evaluation employed in this work? What future directions are discussed to address these limitations?

9. The paper provides an ablation study analyzing different distillation techniques. What key observations can be made about their relative impact on model performance?

10. The case study highlights the key characteristics of justifications generated by JustiLM compared to other methods like Atlas and GPT-4. What are the main takeaways from this qualitative analysis?
