# A Pre-training Based Personalized Dialogue Generation Model with   Persona-sparse Data

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we build personalized dialogue agents that can generate coherent and persona-consistent responses when only persona-sparse dialogue data is available for training?The key points are:- The paper proposes a method to train personalized dialogue agents using persona-sparse real-world dialog data, where speakers don't intentionally reveal personas. This differs from prior work that uses persona-dense crowd-sourced data. - The proposed model uses a pre-trained language model, adds attribute embeddings to the encoder, and develops an attention routing mechanism in the decoder to dynamically control the amount of persona features to exhibit.- Experiments show the model can produce more coherent and persona-consistent responses compared to baselines when fine-tuned on persona-sparse dialogues. The persona weighting can also be adjusted at test time.In summary, the core research question is how to effectively leverage persona-sparse real-world dialog data to train personalized dialogue agents that can generate coherent responses with adjustable persona consistency. The key novelty is the dynamic integration of persona features using attention routing.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Proposing a pre-training based personalized dialogue model that can generate coherent responses using persona-sparse dialogue data. Previous pre-training based methods require persona-dense data for fine-tuning, while this method can utilize the more readily available persona-sparse real-world dialogues. 2. An attention routing mechanism is proposed in the decoder to dynamically incorporate the target persona. This allows balancing the contribution of the persona in the decoding process.3. Experiments show the proposed model outperforms previous methods in generating more coherent and persona-consistent responses when fine-tuned on persona-sparse dialogues. The persona weight can also be adjusted to control the amount of persona features exhibited.In summary, the key innovation is a pre-training based model that can effectively leverage persona-sparse dialogues for personalized response generation, enabled by the proposed attention routing mechanism. This provides a more practical solution for building personalized dialogue agents using real-world conversational data that are mostly persona-sparse.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a pre-training based personalized dialogue generation model that uses attribute embeddings and an attention routing mechanism to effectively incorporate persona information from sparse training data and generate coherent, persona-consistent responses.
