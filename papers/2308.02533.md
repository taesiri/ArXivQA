# [Improving Generalization of Adversarial Training via Robust Critical   Fine-Tuning](https://arxiv.org/abs/2308.02533)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be:How can we improve the generalization performance and out-of-distribution robustness of adversarially trained deep neural network models without compromising their adversarial robustness?In particular, the paper investigates whether adversarially trained models exhibit "redundant capacity for robustness", analogous to the redundant capacity for generalization observed in standard trained models. The key hypothesis is that by identifying and fine-tuning the "non-robust-critical" modules of an adversarially trained model (i.e. modules that are redundant for robustness), it may be possible to enhance generalization and OOD robustness while maintaining adversarial robustness. To test this hypothesis, the paper introduces a new metric called "module robust criticality" (MRC) to quantify the robustness contribution of each module. The module with the lowest MRC is deemed "non-robust-critical" and fine-tuned using clean data. The fine-tuned weights are interpolated with the original adversarially trained weights to find the best tradeoff between standard accuracy, OOD robustness and adversarial robustness.In summary, the central question is whether redundant capacity for robustness exists in adversarially trained models, and whether exploiting this via fine-tuning "non-robust-critical" modules can simultaneously improve generalization and OOD robustness without compromising adversarial robustness. The concept of module robust criticality and the proposed RiFT method aim to address this question.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It proposes a new concept called Module Robust Criticality (MRC) to quantify the robustness contribution of each module in a neural network. The module with the lowest MRC value is considered non-robust-critical, meaning it has redundant capacity for robustness. 2. It proposes a method called Robustness Critical Fine-Tuning (RiFT) to exploit the redundant robustness capacity in adversarially trained models to improve their generalization performance. RiFT fine-tunes the non-robust-critical module identified by MRC on clean examples, and then interpolates between the fine-tuned weights and original adversarially trained weights to find the optimal balance between accuracy and robustness.3. Through experiments on various models and datasets, it demonstrates that RiFT can significantly enhance both the standard accuracy and out-of-distribution robustness of adversarially trained models by around 1-2%, while maintaining or slightly improving their adversarial robustness. 4. The results provide several insights, such as the existence of redundant robustness capacity in adversarially trained models, the potential for both accuracy and robustness to be improved simultaneously, and the promise of fine-tuning to further enhance out-of-distribution robustness.In summary, the key contribution is the proposal of MRC to identify redundant capacity in robust models, and RiFT to exploit this redundancy to enhance generalization without compromising robustness. The empirical results demonstrate the effectiveness of this approach across different settings.
