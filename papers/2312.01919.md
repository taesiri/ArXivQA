# [COTR: Compact Occupancy TRansformer for Vision-based 3D Occupancy   Prediction](https://arxiv.org/abs/2312.01919)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes Compact Occupancy TRansformer (COTR), a novel approach for vision-based 3D occupancy prediction. COTR constructs a compact yet informative 3D occupancy representation through an efficient combination of explicit and implicit view transformations. Specifically, it first generates a high-resolution but sparse occupancy feature using explicit view transformation. This feature is downsampled to obtain a compact representation enriched by implicit view transformation, which handles sparsity while retaining geometric details. Additionally, COTR enhances semantic discrimination via a coarse-to-fine grouping strategy coupled with transformer-based mask classification. This balances supervision signals across categories and improves recognition of rare classes. Experiments on nuScenes and SemanticKITTI datasets demonstrate state-of-the-art performance. When integrated into prevailing approaches like TPVFormer and BEVDet4D, COTR provides consistent and significant improvements of 8-15% in key metrics. The gains are especially pronounced for small and rare objects. Overall, COTR advances the capabilities of vision-based 3D scene understanding through compact yet informative occupancy modeling.
