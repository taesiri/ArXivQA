# [PolyFormer: Referring Image Segmentation as Sequential Polygon   Generation](https://arxiv.org/abs/2302.07387)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we formulate referring image segmentation (RIS) as a sequence-to-sequence prediction problem to improve performance?The key points are:1. The paper proposes to represent the segmentation mask as a sequence of polygon vertices rather than predicting the dense pixel masks directly. 2. It introduces a new sequence-to-sequence model called PolyFormer to generate the polygon vertices sequentially.3. A regression-based decoder is designed to output continuous floating point coordinates directly without quantization errors.4. This allows the paper to unify RIS and referring expression comprehension (REC) tasks into one seq2seq framework by outputting both polygon vertices and bounding box coordinates.5. Experiments show this approach outperforms previous state-of-the-art methods on major RIS and REC benchmarks by a significant margin.In summary, the central hypothesis is that formulating RIS as sequential polygon generation within a seq2seq framework can lead to better performance compared to existing methods. The paper provides substantial experiments to validate this hypothesis.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes PolyFormer, a new sequence-to-sequence framework for referring image segmentation (RIS) and referring expression comprehension (REC). PolyFormer takes a sequence of image patches and text query tokens as input, and autoregressively outputs a sequence of polygon vertices to represent the segmentation mask. 2. It introduces a regression-based decoder that directly predicts the continuous 2D coordinates of polygons without quantization. This is more accurate for localization compared to previous approaches that formulate it as a classification task over discrete bins.3. It shows that the polygon-based PolyFormer outperforms previous mask-based RIS methods by a large margin across three major benchmarks. It also generalizes well to the referring video segmentation task in a zero-shot manner.4. The simple seq2seq formulation of PolyFormer provides a unified framework for both RIS and REC tasks. The text and image features can be naturally fused as the input sequence, and the output sequence contains both polygon vertices and bounding box coordinates.5. The polygon representation is more structured and interpretable compared to pixel-level masks. The paper shows that generating polygons sequentially in an autoregressive manner enables modeling complex shapes and occlusions.In summary, the main contribution is proposing PolyFormer, a novel seq2seq model that formulates RIS and REC as polygon generation, and demonstrates superior performance and generalization ability compared to prior arts. The regression-based decoder is also a key contribution for accurate localization in this framework.
