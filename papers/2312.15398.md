# [Fairness-Aware Structured Pruning in Transformers](https://arxiv.org/abs/2312.15398)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Fairness-Aware Structured Pruning in Transformers":

Problem:
- Large language models (LLMs) like GPT-3 are gaining widespread adoption but also raise concerns about fairness and bias towards certain groups. 
- Existing methods to prune LLMs to reduce their size focus solely on maintaining performance, not fairness.
- There is a need for pruning techniques that improve fairness without significant drops in language modeling performance.

Proposed Solution:
- The paper proposes a novel structured pruning method called Fairness-Aware Structured Pruning (FASP) that considers both performance and fairness when deciding which attention heads to prune.
- FASP computes separate scores to quantify each head's contribution to bias and performance. 
- Heads most critical for performance are preserved. Among the remaining heads, those contributing most negatively to fairness are prioritized for pruning first.

Main Contributions:
- Investigates impact of pruning heads on bias and finds standard techniques don't improve fairness.
- Proposes FASP, which prunes heads most responsible for bias while ensuring minimal performance loss.
- Shows FASP reduces gender bias by 8-39% across models like GPT-2, GPT-Neo, GPT-J while preserving perplexity.
- Demonstrates pruning heads for gender bias also reduces nationality, race, and sexual orientation biases.
- Provides both quantitative and qualitative results to demonstrate improved fairness with comparable language modeling ability.

In summary, the paper introduces a pruning approach called FASP that significantly enhances fairness towards multiple groups by selectively removing attention heads most contributing to bias, while retaining performance.
