# [Plant 'n' Seek: Can You Find the Winning Ticket?](https://arxiv.org/abs/2111.11153v2)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research questions and hypotheses addressed in this paper are:

1. What is the optimal sparsity of lottery tickets that can be discovered through pruning? Is the suboptimal sparsity found by current algorithms merely an artifact of existence proofs, or a more fundamental limitation of pruning randomly initialized neural networks?

2. Are current pruning algorithms able to find very sparse lottery tickets, either weak tickets that require some training or strong tickets that work well at initialization?

The authors hypothesize that the suboptimal sparsity of tickets found by current algorithms is likely an algorithmic rather than fundamental limitation. They also hypothesize that current algorithms are not able to find extremely sparse tickets, especially strong tickets. 

To test these hypotheses, the authors develop a framework to plant ground truth lottery tickets of desired sparsity into larger neural networks. They use this to construct sparse tickets for three machine learning tasks, and evaluate the ability of state-of-the-art pruning algorithms to recover the planted tickets.

The key findings are:

- None of the current algorithms can find the extremely sparse planted strong tickets in a single shot. Iterative multishot pruning enables finding moderately sparse weak tickets.

- The best algorithm tested (\edgepopup) can find sparse strong tickets, but not as sparse as the planted tickets even with modifications.

- All algorithms struggle more with sparse tickets on regression tasks compared to classification.

Based on these results, the authors conclude that the limitations in finding very sparse tickets are likely algorithmic rather than fundamental. The planting framework provides a way to benchmark progress on developing better pruning algorithms.


## What is the main contribution of this paper?

 The main contribution of this paper is developing a framework to plant and hide arbitrary winning lottery tickets in randomly initialized neural networks. The authors use this framework to construct sparse tickets that reflect common machine learning challenges and evaluate state-of-the-art pruning algorithms against these planted tickets. The key findings are:

- None of the pruning methods can recover the extremely sparse tickets in a single shot. With multiple shots of pruning and resetting weights, some methods recover moderately sparse tickets.

- The strongest algorithm for finding tickets before training, edge-popup, can at best find tickets around 0.5 sparsity but fails to recover more extremely sparse planted tickets. 

- All methods struggle more with sparse tickets on a regression task compared to a classification task.

- There is no single best pruning method, performance depends on the task and sparsity level.

The planted tickets act as a ground truth benchmark to rigorously evaluate pruning algorithms. The results highlight limitations of current methods and indicate that substantial improvements are needed to find extremely sparse tickets matching the planted ones. The proposed framework enables generating custom tickets to systematically analyze algorithmic deficiencies and drive progress.
