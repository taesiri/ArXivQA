# [Deep Safe Multi-Task Learning](https://arxiv.org/abs/2111.10601v2)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes a Deep Safe Multi-Task Learning (DSMTL) model to address the problem of "negative sharing" in multi-task learning (MTL). The key research questions are:

1. How to formally define "negative sharing" and "safe multi-task learning" where no negative sharing occurs?

2. How to design MTL models that can theoretically and/or empirically guarantee no negative sharing?

3. How to improve the scalability of safe MTL models to handle a large number of tasks? 

The main hypothesis is that by combining shared and task-specific representations properly, the proposed DSMTL model can achieve safe MTL both theoretically and empirically.

Specifically, the paper introduces formal definitions of "negative sharing" and different versions of "safe MTL". It proposes the DSMTL model consisting of a shared encoder, task-specific encoders, gates to combine them, and task-specific decoders. Two learning strategies called individual learning and joint learning are introduced, which are proved to achieve some versions of safe MTL theoretically. To improve scalability, an extension called DSMTL with Architecture Learning is proposed to learn a compact architecture automatically. Experiments verify the effectiveness of the proposed methods in achieving safe MTL.

In summary, this paper aims to address the lack of safeness guarantees in MTL by proposing the DSMTL model along with theoretical safeness analysis and empirical verification. The key novelty is introducing the formal definitions and designing the model architecture to enable safe MTL.
