# [MelGAN: Generative Adversarial Networks for Conditional Waveform   Synthesis](https://arxiv.org/abs/1910.06711)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the main contributions of this paper are:

1. It proposes MelGAN, a non-autoregressive feed-forward convolutional architecture to perform fast and high quality mel-spectrogram inversion using GANs. This is the first model that successfully trains GANs for raw audio generation without needing additional losses or objectives.

2. It shows MelGAN can replace autoregressive models in various audio synthesis tasks like text-to-speech, music translation, and unconditional music synthesis to achieve faster synthesis while maintaining decent quality. 

3. It provides a set of guidelines and architectural choices for building effective generators and discriminators for conditional sequence synthesis using GANs.

4. It demonstrates that MelGAN is an order of magnitude faster than previous models like WaveGlow while having comparable quality. The model is very lightweight with only 4.26 million parameters.

The key research question addressed is: how can we successfully train GANs for high quality and efficient speech/audio synthesis? The paper tackles the challenges like long-range temporal dependencies and instability of GAN training that have prevented prior works from using GANs effectively for raw audio generation.

In summary, the main contribution is developing a fast, lightweight and high quality neural vocoder using GANs to replace autoregressive models in speech/audio synthesis applications.
