# [Human Guided Ground-truth Generation for Realistic Image   Super-resolution](https://arxiv.org/abs/2303.13069)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key points of this paper are:

- The paper proposes a new approach for generating training data (ground truth images) for realistic image super-resolution (Real-ISR). 

- The key hypothesis is that the perceptual quality of existing HR images used as ground truths can be further improved, and incorporating human perception into ground truth generation can help train better Real-ISR models.

- To test this hypothesis, the paper introduces a human guided ground truth generation pipeline involving:
  - Training multiple image enhancement models to improve HR image quality.
  - Having humans annotate enhanced HR patches as positive (higher quality) or negative (lower quality) samples.
  - Constructing a dataset with positive and negative ground truth pairs.
  - Training Real-ISR models on this dataset and evaluating performance.

- The main research questions are:
  - Can enhancing and manually annotating HR images provide better ground truths for Real-ISR?
  - Can the proposed human guided dataset help train Real-ISR models that generate sharper and more realistic details with less artifacts?

- Experiments on benchmark datasets and models validate the effectiveness of the proposed approach and dataset in improving perceptual quality of Real-ISR results.

In summary, the key hypothesis is that incorporating human perception through guided annotation of enhanced HR images can lead to improved ground truths and Real-ISR performance. The paper introduces and validates a pipeline to test this hypothesis.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing a human guided ground-truth (GT) generation method for realistic image super-resolution (Real-ISR) training. 

2. Training multiple image enhancement models to generate enhanced HR images with improved perceptual quality.

3. Extracting textural patches from the enhanced HR images and having human subjects annotate them as positive or negative GTs.

4. Constructing a human guided GT (HGGT) dataset with both positive and negative samples.

5. Proposing training strategies to utilize the positive and negative GTs in the HGGT dataset.

6. Validating the effectiveness of the HGGT dataset and the training strategies through experiments on multiple Real-ISR models.

In summary, this paper makes the key contribution of introducing human perception guidance into the GT generation process for Real-ISR training. By annotating the enhanced HR images as positive and negative samples, the resulting HGGT dataset enables training more perceptually realistic Real-ISR models.
