# FlowEval: A Consensus-Based Dialogue Evaluation Framework Using Segment   Act Flows

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research focus of this paper is exploring the potential of using dialog act information, specifically segment-level dialog acts called "segment acts", for evaluating open-domain dialog systems. The authors point out that hardly any previous dialogue evaluation methods explicitly model dialog acts, even though dialog acts convey important information about the function or intent of each utterance. To incorporate dialog act information into evaluation, the authors propose "segment acts" which extend dialog acts to the segment level within utterances, allowing for finer-grained modeling of utterance function.To enable use of segment acts, the authors create a new dataset called ActDial with segment act annotations on two existing dialog datasets. They then propose a new consensus-based dialog evaluation framework called FlowEval which utilizes segment act flows (sequences of segment acts). The key hypothesis seems to be that explicit modeling of segment act flows can improve open-domain dialog evaluation by providing useful complementary information compared to methods focused solely on semantic meaning. The authors test this via experiments on benchmark dialog datasets.In summary, the central research question is whether segment act flows can be effectively modeled to improve open-domain dialog evaluation, providing complementary benefits to existing semantic meaning-focused methods. The key hypothesis is that FlowEval, through its use of segment acts, can achieve state-of-the-art or comparable correlation with human judgments of dialog quality.


## What is the main contribution of this paper?

This paper proposes FlowEval, a new framework for evaluating dialogue systems. The key contributions are:1. They propose modeling dialogue flows using "segment acts" - extending dialog acts to the segment level within an utterance. This allows capturing finer-grained communicative intent compared to regular dialog acts. 2. They collect a large dataset of segment act annotations on two dialogue datasets - ConvAI2 and DailyDialog. This segment act dataset enables modeling segment act flows.3. They propose a consensus-based dialogue evaluation framework called FlowEval that can assess dialogues without requiring reference responses. It works by retrieving pseudo-references from a dataset based on segment act and content features, then evaluating the dialogue using consensus of the pseudo-references. 4. Experiments show FlowEval reaches state-of-the-art or comparable performance to existing methods on three dialogue datasets. It also provides complementary information to existing semantic similarity metrics.5. This is the first work to adapt consensus-based evaluation from image captioning to open-domain dialog. The proposed framework allows integrating various kinds of features for retrieval and assessment.Overall, the key novelty is using fine-grained segment acts and a consensus-based framework to evaluate dialog without needing true references. This provides a new direction for improving open-domain dialogue evaluation.
