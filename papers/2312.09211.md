# [Mitigating Outlier Activations in Low-Precision Fine-Tuning of Language   Models](https://arxiv.org/abs/2312.09211)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Fine-tuning large pre-trained language models like BERT on downstream tasks requires substantial compute and memory resources, limiting their accessibility. 
- Using low-precision numerics (int8) helps efficiency but suffers from "outlier activations" which degrade performance.

Proposed Solution:
- Represent outlier activations in int12 while keeping other activations and gradients in int8 to balance precision.
- Introduce method to split outlier activations into two int8 values to enable efficient int8 matrix multiplication.
- Analyze information loss theory for low-precision and mixtures like outliers. Show treating outliers separately reduces variance and improves informativeness.

Key Contributions:
- Novel fully int8 linear layer design to handle outlier activations in integer format while keeping backprop gradients int8.
- Adaptive integer formatting method to use int12 for outliers (<5%) but int8 for other parameters.
- Operator tiling strategy to split outlier activations into multiple int8 values to enable efficient int8 GEMM.
- Theoretical analysis that separating outlier activations reduces variance and improves information preservation.
- Experiments showing the methods improve int8 fine-tuning performance over baseline on GLUE and SQuAD tasks.

In summary, the paper introduces techniques to handle problematic outlier activations to make low-precision int8 fine-tuning of large language models more robust and hardware-efficient, while providing supporting analysis. The methods and analysis help advance the state-of-the-art in efficient deployment of large pre-trained language models.
