# [Post-Training Quantization for Re-parameterization via Coarse &amp; Fine   Weight Splitting](https://arxiv.org/abs/2312.10588)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Re-parameterization techniques like RepVGG have emerged as a promising approach to enhance model performance while reducing computational costs. However, directly applying quantization on re-parameterized models leads to significant accuracy drops. The key challenge is the large variation in weight distribution across branches, resulting in an unfavorable weight distribution after fusion.  

Proposed Solution: 
The paper proposes a novel post-training quantization (PTQ) technique tailored for re-parameterized networks:

1. It introduces a Coarse & Fine Weight Splitting (CFWS) method to separately quantize the center weights and surrounding weights after fusion. This handles the challenge of large weight variation effectively.  

2. An improved KL divergence metric is proposed to determine optimal clipping thresholds for activations. Many large activation values are insensitive to clipping, motivating a calibration technique based on distribution similarity rather than just error.

Main Contributions:

1) First work to enable direct PTQ on re-parameterized models without modifications or retraining, facilitating their deployment.

2) Proposes CFWS to address the core challenge of weight variation by selective quantization.

3) Develops an optimized KL metric that smoothly handles clipping of insensitive large activations.

4) Achieves state-of-the-art PTQ accuracy (e.g. 0.3% drop for RepVGG-A1) that matches training-based methods, with the simplicity of pure PTQ.

5) Demonstrates generalization over various vision tasks like image classification and object detection.

In summary, the paper delivers an effective PTQ solution tailored for re-parameterized networks, unlocking their practical deployment. By selective handling of weight and activations, it retains accuracy while enabling computational and memory benefits.
