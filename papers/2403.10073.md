# [Revisiting Adversarial Training under Long-Tailed Distributions](https://arxiv.org/abs/2403.10073)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Deep neural networks are vulnerable to adversarial attacks. Adversarial training is recognized as one of the most effective defenses, but prior work focused on balanced datasets. Real-world data often exhibits a long-tailed distribution, so efficacy of adversarial training needs to be re-assessed for such scenarios.

Proposed Solution:  
- Revisit adversarial training method RoBal, discover Balanced Softmax Loss (BSL) is the most critical component while other components can be removed to reduce overheads. The resulting AT-BSL method matches RoBal's effectiveness.
- Observe AT-BSL suffers from robust overfitting, use data augmentation techniques not just to mitigate it but unexpectedly find they also substantially improve robustness.
- Hypothesize data augmentation improves robustness by increasing diversity of examples, allowing models to learn richer representations. Validate via ablation studies on RandAugment.

Main Contributions:
- Discover BSL alone achieves comparable performance to full RoBal approach for long-tailed adversarial training while significantly reducing training overheads.
- Reveal that contrary to findings on balanced datasets, data augmentation significantly improves robustness of adversarially trained models on long-tailed datasets. 
- Propose and validate hypothesis that increased example diversity from augmentation enables learning richer representations that improve robustness.
- Demonstrate findings generalize across various augmentation strategies, models and datasets. AT-BSL with augmentation outperforms prior state-of-the-art by +6.66% on CIFAR-10-LT.

In summary, the key findings significantly advance adversarial training towards real-world long-tailed distributions by streamlining prior methods and showing data augmentation itself can substantially improve robustness.
