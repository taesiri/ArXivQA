# [Confidence Ranking for CTR Prediction](https://arxiv.org/abs/2307.1206)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is:How can we train a model to perform better than the currently deployed online model in a real-world machine learning application like ads and recommendation systems? The key hypotheses are:- Modeling the prediction confidence distribution of the currently deployed online model can help train a better model.- Designing the optimization objective as a ranking function between two models (base and retrained) rather than just minimizing cross-entropy loss can improve model performance.- A ranking-based loss function that optimizes the logits output for different convex surrogate functions of metrics like AUC and accuracy can outperform cross-entropy loss.So in summary, the main question is how to train a model that outperforms the currently deployed online model, with hypotheses around using the online model predictions and a ranking-based loss function. The experiments aim to validate these hypotheses.


## What is the main contribution of this paper?

The main contributions of this paper are:- Proposing a novel framework called "Confidence Ranking" to optimize the loss function as a ranking function between two models (a base model and a retrained model) for CTR prediction. This allows directly optimizing the logits output for different convex surrogate functions of metrics like AUC and Accuracy.- Introducing two loss functions - point-wise CR loss and relational CR loss - that are based on ranking the outputs of the base and retrained models. These losses aim to maximize metrics like accuracy and AUC respectively. - Showing through experiments on public and industrial CTR prediction datasets that the proposed confidence ranking framework outperforms baselines like standard cross-entropy training and knowledge distillation methods.- Deploying the proposed methods in a real-world ads system for CTR prediction and demonstrating 1.75% CTR gain on average in online A/B tests.In summary, the main contribution is proposing a novel way to optimize CTR prediction models to perform better than the online deployed models by framing the objective as a ranking between model outputs rather than a typical cross-entropy loss. The confidence ranking framework and associated loss functions are shown to improve CTR prediction performance.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a novel Confidence Ranking loss framework that optimizes the ranking of logits outputs from two different models to improve test performance for click-through rate prediction compared to standard cross-entropy loss and knowledge distillation techniques.
