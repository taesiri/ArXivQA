# [Learning to Separate Object Sounds by Watching Unlabeled Video](https://arxiv.org/abs/1804.01665)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to learn audio-visual object models from unlabeled video in order to perform audio source separation on novel videos. Specifically, the paper proposes an approach to learn what different objects sound like by looking at and listening to unlabeled videos containing multiple sounding objects. The key idea is that observing sounds in a variety of visual contexts can reveal cues to isolate individual audio sources, even though the sounds are mixed together in the audio track. The main hypothesis is that by discovering associations between audio frequency bases and visual objects in a large collection of unlabeled videos, the learned associations can be used to guide separation of object-level sounds in new videos.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Proposing to enhance audio source separation in videos by using visual information from image recognition results as a form of "weak supervision". 2. Introducing a novel deep multi-instance multi-label learning framework to learn prototypical spectral patterns of different acoustic objects, and injecting this learned prior into an NMF source separation framework.3. Being the first to study audio source separation learned from a large scale of unlabeled "in the wild" online videos containing multiple audio sources per video. 4. Demonstrating state-of-the-art results on visually-aided audio source separation and audio denoising using this approach.In summary, the key innovation is using unlabeled video containing both visual and audio channels to learn audio-visual associations and models of how different objects sound. This learned prior knowledge is then used to separate and isolate sounds from individual objects in new videos with mixed audio. The main advantage is the ability to do audio source separation without clean labeled training data of isolated sounds.
