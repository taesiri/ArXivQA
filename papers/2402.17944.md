# [Large Language Models on Tabular Data -- A Survey](https://arxiv.org/abs/2402.17944)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper provides a comprehensive survey on the application of large language models (LLMs) for modeling tabular data across diverse tasks such as prediction, data augmentation, question answering, and table understanding. 

The paper first introduces key characteristics and challenges of tabular data such as heterogeneity, sparsity, dependency on preprocessing, context-based interconnections, order invariance, and lack of prior knowledge. It then provides background on traditional machine learning and deep learning methods for tabular data tasks as well as an overview of the development of language models leading up to large LLMs.

The paper categorizes common techniques for adapting tabular data as inputs for LLMs, including serialization (converting tables to text), table manipulation (compacting, adding metadata), and prompt engineering (formatting, in-context learning, chain-of-thought). It also covers end-to-end systems connecting LLMs to external programs.

For prediction tasks, the paper systematically examines LLM-based methods on both standard tabular data and time series forecasting. It compares model architectures, datasets, metrics, preprocessing techniques, target augmentation strategies and inference vs fine-tuning approaches across existing literature.

For data augmentation, the paper summarizes and analyzes recent LLM-based generative models for producing synthetic tabular data. It describes pipelines, architectures and evaluation metrics used in state-of-the-art methods.

For question answering and reasoning, the paper recommends benchmark datasets and surveys abilities of LLMs on tasks like numerical QA, text-to-SQL generation. It also highlights key components of QA systems including intent disambiguation, search/retrieval, multi-turn dialogue and output evaluation. 

Finally, the paper discusses limitations around bias, hallucination, numerical representations, lack of standardized benchmarks as well as open challenges and future directions to advance LLM-based tabular data modeling.

In summary, this paper offers an extensive taxonomy and review of the current landscape in leveraging capabilities of LLMs for structured data across a diverse set of tasks. It provides practitioners structured guidelines and insights to effectively apply LLMs on tabular data across different real-world applications.
