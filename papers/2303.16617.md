# [NeFII: Inverse Rendering for Reflectance Decomposition with Near-Field   Indirect Illumination](https://arxiv.org/abs/2303.16617)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we develop an end-to-end inverse rendering pipeline that can decompose materials and illumination from multi-view images, while also considering near-field indirect illumination effects like inter-reflections?

The key ideas and contributions towards addressing this question appear to be:

- Representing materials and indirect illuminations as neural implicit fields, and jointly optimizing them along with explicit environment illumination parameters. This allows modeling of high-frequency inter-reflection details compared to using a blurred Spherical Gaussian approximation. 

- Introducing Monte Carlo path tracing with caching of bounced radiance in a neural radiance field. This provides a differentiable and physically based rendering for optimization.

- Using importance sampling and Spherical Gaussians for efficiency of the Monte Carlo estimator.

- Adding a radiance consistency constraint for unobserved rays to supervise the learning of indirect illumination and reduce ambiguity between materials and lighting.

So in summary, the central hypothesis seems to be that by combining these ideas - joint optimization, Monte Carlo path tracing, and the unobserved ray consistency constraint - they can develop an effective approach to inverse rendering that handles complex near-field lighting effects. The results on both synthetic and real data seem to validate this hypothesis.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

- It proposes an end-to-end inverse rendering pipeline that can decompose materials and illumination from multi-view images, while considering near-field indirect illumination. 

- It introduces Monte Carlo sampling based path tracing to model inter-reflections, while using spherical gaussians to represent smooth environment illumination. This results in a physics-based and optimizable inverse rendering process.

- It employs importance sampling techniques to improve the efficiency of the Monte Carlo estimator.

- It introduces a new radiance consistency constraint for learning indirect illuminations from unobserved directions. This helps reduce ambiguity between materials and indirect illumination.

In summary, the key contribution is an end-to-end differentiable inverse rendering framework that can decompose materials, environment illumination and near-field indirect illumination in a joint manner. The path tracing based rendering and radiance consistency constraint allow modeling inter-reflections and reducing ambiguity.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key point from the paper:

The paper proposes an end-to-end inverse rendering method that jointly optimizes materials and illumination from multi-view images while modeling near-field indirect illumination using Monte Carlo path tracing and a novel radiance consistency constraint.


## How does this paper compare to other research in the same field?

 Here are a few key points comparing this paper to other research on inverse rendering:

- This paper proposes an end-to-end inverse rendering pipeline for jointly estimating materials, illumination and near-field indirect illumination from multi-view images. Most prior works like NeRF, IDR, and PhySG focus only on novel view synthesis and do not aim to decompose the scene into materials and lighting.

- For modeling indirect illumination, this paper uses Monte Carlo path tracing instead of spherical Gaussian (SG) approximation used in InvRender. Path tracing can better preserve high-frequency lighting details compared to SG.

- The proposed method represents materials, illumination and indirect lighting all using neural implicit representations. This allows end-to-end joint optimization, unlike InvRender which requires staged training.

- A key novelty is the radiance consistency loss term for supervising the learning of indirect lighting from unobserved directions. This helps resolve ambiguity between materials and lighting.

- Experiments show the proposed method outperforms InvRender and other baselines in decomposition quality, especially for inter-reflections and roughness estimation. It also enables relighting with estimated properties.

- Limitations include not handling transparency/translucency, and some failure cases with extreme shadows. Geometry optimization is also not handled currently.

In summary, this paper pushes forward inverse rendering research by enabling joint decomposition of materials, lighting and near-field effects using differentiable path tracing and implicit neural representations. The radiance consistency loss helps resolve a key ambiguity. Results are state-of-the-art on both synthetic and real data.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Jointly optimizing the shape along with materials and illumination. The current method optimizes materials and illumination but uses a fixed pretrained shape. Allowing the shape to also be optimized could improve the overall decomposition. 

- Handling more complex material models beyond the simplified Disney BRDF used in this work. Extending the method to handle things like specular albedo and more complex BRDFs could expand the applicability.

- Exploring different ray tracing techniques to better handle visibility gradients. The current ray tracing limits optimizing shape, so new techniques could help enable end-to-end shape and appearance optimization.

- Applying the method to transparent and translucent materials. The current scope is limited to opaque materials, but extending to transparency could be an interesting direction.

- Exploring ways to handle failure cases like shadows. The method struggles with roughness estimation in large shadow regions, so ways to address illumination ambiguity in shadows could help.

- Testing on a wider range of real world data. While results on real captures look promising, more extensive real world evaluation could better examine the practical usefulness.

- Investigating ways to improve efficiency and reduce computation cost. The Monte Carlo sampling remains expensive, so reductions in ray sampling needed could help scale the approach.

In summary, the key suggested future work revolves around extending the method to handle more complex shapes, materials, and illumination scenarios in order to increase the general applicability and practicality of the approach. Testing on more expansive real data could also help validate the usefulness.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper presents an end-to-end inverse rendering pipeline that decomposes materials and illumination from multi-view images, while considering near-field indirect illumination. The method represents geometry and materials with implicit neural fields, and models illumination with spherical Gaussians and cached Monte Carlo path tracing. This allows jointly optimizing materials, environment illumination, and indirect illumination in a differentiable manner. To make this computationally tractable, the method uses importance sampling and trains the model with both observed camera rays and unobserved secondary bounce rays. The unobserved rays provide additional supervision by enforcing consistency between the implicit neural fields and path tracing.

The experiments demonstrate that explicitly modeling and optimizing indirect illumination results in more accurate material estimation compared to prior work, especially for inter-reflections and roughness. The method is evaluated on synthetic scenes with complex global illumination effects as well as real world captures. The recovered models support editing materials and relighting in a 3D engine. Limitations include lack of geometry optimization and difficulty estimating materials in areas with extreme shadows. Overall, the physics-based inverse rendering approach produces high quality results by integrating Monte Carlo ray tracing differentiably into a neural representation.
