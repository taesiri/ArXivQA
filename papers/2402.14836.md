# [Stealthy Attack on Large Language Model based Recommendation](https://arxiv.org/abs/2402.14836)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Recently, large language models (LLMs) have been instrumental in advancing recommender systems (RS) by modeling user preferences and item features through text. 
- However, the reliance on textual content makes LLM-based RS more vulnerable to attacks where attackers can boost an item's exposure by subtly modifying its text during testing, without affecting overall performance.

Proposed Solution:
- The paper demonstrates textual attacks on LLM-based RS by using model-agnostic strategies like inserting positive words or rewriting with GPTs, as well as black-box attacks like DeepWordBug, TextFooler, etc.
- The attacks aim to imperceptibly modify an item's title to mislead the RS model into ranking it higher, thereby promoting its exposure.

Main Contributions:
- First work to highlight and attack the vulnerability of LLM-based RS due to their reliance on textual content.
- Comprehensive experiments across four mainstream LLM-based RS models demonstrate the superior efficacy and stealthiness of textual attacks compared to traditional shilling attacks.
- Further experiments reveal the impact of item popularity and model fine-tuning on attacks, and explore the transferability of attacks across models and tasks.
- Finally, a simple rewriting defense is proposed, which can mitigate character-level attacks but struggles with more complex word substitution attacks.

In summary, this work unveils a significant security gap in LLM-based recommendation systems and calls for more research into protecting these models against such adversarial attacks on text.
