# [Predicting Sustainable Development Goals Using Course Descriptions --   from LLMs to Conventional Foundation Models](https://arxiv.org/abs/2402.16420)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
Universities are adopting UN Sustainable Development Goals (SDGs) into their curricula to promote sustainability. However, it is challenging for universities to understand which SDGs are being taught across different degree programs and courses at an aggregate level. 

Proposed Solution:
- Gathered course description data from a university spanning 2021-2023
- Used the PaLM-2 large language model (LLM) to generate SDG predictions for each course
- Cleaned the LLM-generated training data 
- Trained smaller foundation models like BERT and BART on this data to predict SDGs from course descriptions

Key Contributions:
- Presented a novel approach to mapping university courses to SDGs using LLMs 
- Showed how noisy course description data can be used alongside LLMs to create training data
- Demonstrated that smaller foundation models can be fine-tuned to effectively predict SDGs from course descriptions
- The best performing model was BART with an F1-score of 0.786 for multi-label SDG classification
- This approach allows universities to understand SDG adoption in curricula to facilitate sustainability practices

The paper makes important contributions regarding the application of NLP techniques to promote sustainability in university education by predicting alignment with SDGs from course-level metadata.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper presents a method for predicting United Nations sustainable development goals for university courses by using a large language model to generate training data from course descriptions and then training smaller models on this data, with the best performing model being BART which achieved an F1-score of 0.786.


## What is the main contribution of this paper?

 Based on reviewing the paper, the main contribution appears to be presenting a novel approach to predicting United Nations sustainable development goals (SDGs) for university courses. Specifically:

- The authors employ the large language model PaLM 2 to generate training data for predicting SDGs, given university course descriptions as input. 

- They use the generated training data to train several smaller language models such as BERT, RoBERTa, XLM-RoBERTa, and BART to predict SDGs based on course descriptions.

- Their approach contributes towards better integration of SDGs at the university level by providing a methodology for universities to understand which SDGs are covered in their course offerings. 

- The best performing model in their experiments for predicting SDGs was BART, which achieved an F1-score of 0.786.

In summary, the key contribution is using large language models to generate training data, and then training smaller models for the practical task of predicting relevance of SDGs for university courses. This contributes towards SDG adoption in higher education.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the key terms and keywords associated with it are:

- SDG (sustainable development goals)
- multi-label classification 
- LLM (large language model)
- PaLM 2
- BART
- university courses
- course descriptions
- model training
- precision
- recall 
- F1-score

The paper focuses on predicting UN sustainable development goals for university courses using course descriptions. It leverages a large language model called PaLM 2 to generate training data. Several smaller foundation models like BERT, RoBERTa, XLM-RoBERTa, and BART are fine-tuned and evaluated for the multi-label classification task of assigning SDGs based on course information. The best performing model was BART with an F1-score of 0.786. So the key themes relate to sustainable development goals, multi-label classification, large and small language models, and evaluating model performance on a university course description dataset.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper uses PaLM 2 to generate training data for the SDG prediction models. What are some potential issues with using a large language model like this to generate training data, and how could the authors mitigate these issues?

2. The authors select several foundation models like BERT, RoBERTa, and BART for multi-label classification. What motivated the choice of these specific models? Are there any other models that may have been appropriate to try? 

3. The dataset used contains course descriptions and objectives from a single university. How could the authors modify their approach to incorporate data from multiple universities to improve diversity and generalization?

4. The authors use a prompt-based approach with PaLM 2 to generate SDG labels. What other methods could be used to automatically generate labels besides prompting a large language model?

5. The paper excludes SDG 4 (Quality Education) from the analysis. What impact could including this goal have on the models and results? How would the authors need to modify the approach?

6. Precision, recall and F1-score are used as evaluation metrics. Are there any other relevant metrics that could provide additional insights into model performance?

7. The results show varying performance across SDGs, with lower F1 scores for some goals. What analysis could be done to further understand these differences? How could the dataset or models be improved?  

8. How suitable is the proposed approach for a production system at a university? What practical challenges need to be addressed for real-world deployment?

9. The foundation models are pretrained on general text. Would further pretraining the models on an educational domain corpus improve performance? Why or why not?

10. How well would this approach generalize to other labeling tasks for course content besides SDG prediction, such as predicting knowledge units or skills gained? Would any modifications need to be made?
