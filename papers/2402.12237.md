# [Learning to Defer in Content Moderation: The Human-AI Interplay](https://arxiv.org/abs/2402.12237)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper studies the problem of content moderation in online platforms like social media. Specifically, it considers the collaboration between humans and AI systems in moderating content. The platform needs to quickly remove harmful content while avoiding mistakenly removing benign content. However, relying solely on either humans or AI has limitations - humans have limited review capacity while AI models can be unreliable for complex content. Thus, the paper proposes a framework that combines the responsiveness of AI with the reliability of human reviewers.

Solution:
The paper models the content moderation pipeline as follows. In each time period, a new post arrives which has a contextual feature vector and an unknown "cost" indicating its harmfulness. The platform first makes an automated classification on whether to keep or remove the post. It then decides whether to admit the post into a review queue for human evaluation. Finally, when a human reviewer becomes available, it selects one post from the queue for the human to review, which reveals the true cost of that post. 

The algorithm, termed BALANCED, makes classification, admission and scheduling decisions to minimize total cost by balancing three sources of loss - idiosyncrasy loss from keeping harmful or removing benign posts without review, delay loss from congestion in the review system causing long wait times, and classification loss from incorrectly estimating the harmfulness of unreviewed posts.

When model parameters are known, BALANCED admits posts whose avoided idiosyncrasy loss exceeds the incurred delay loss. For scheduling, it prioritizes posts from types with higher workload. This achieves near optimal average regret that scales as sqrt(maximum lifetime).

When model parameters are unknown, solely using optimistic estimates fails due to the selective sampling nature of human reviews. To address this, BALANCED employs additional label-driven admission and forced scheduling to ensure enough labels for future classification decisions. The full algorithm achieves low average regret even without knowing model parameters.

To avoid dependence on the number of content types, the paper extends BALANCED to a contextual bandit setting. It introduces type aggregation to estimate system congestion and adapts techniques from contextual bandits to handle many contexts. This extension enjoys regret guarantees without dependence on the number of types.

Contributions:
- Proposes a formal model that captures key elements of the human-AI interplay in online content moderation
- Develops algorithm BALANCED that provides performance guarantees by balancing three sources of loss (idiosyncrasy, delay and classification)
- Identifies and addresses fundamental limitations of solely optimism-based approaches 
- Extends model to contextual setting and develops type aggregation and contextual learning techniques to provide scalable guarantees

The model provides useful insights into designing human-AI collaborative systems. The analysis framework may also inspire efficient algorithms in other online learning problems with limited feedback.
