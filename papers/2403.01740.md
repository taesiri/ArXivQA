# [DEMOS: Dynamic Environment Motion Synthesis in 3D Scenes via Local   Spherical-BEV Perception](https://arxiv.org/abs/2403.01740)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
The paper addresses the problem of synthesizing human motions in 3D scanned point cloud scenes. Previous methods have focused on motion synthesis in static environments. However, real-world scenes often contain dynamic elements like other people moving around. Existing methods fail to respond in real-time to such changes in the environment. 

Proposed Solution:
The paper proposes a Dynamic Environment Motion Synthesis (DEMOS) framework that can generate motions adapted to changes in the surrounding point cloud scene. The key ideas are:

1) Local Spherical-BEV Perception: A novel way to capture local geometry of the scene around the person using spherical and bird's eye view projections. This allows for instant perception of scene for motion generation.

2) Motion Blending: Newly hypothesized short-term motions are blended with previous latent motions to get responsive updates while maintaining stability from motion priors.

3) Anchor-based State Annotation: Automatic annotation of human pose state and phase based on body-scene contacts, which aids networks in generating consistent motions.

Main Contributions:

- First framework, DEMOS, to handle dynamic changes in environments for motion synthesis 

- Designed local spherical and BEV projections specifically for instant scene-aware motion generation

- Introduced time-variant motion blending to iteratively update latent motions, balancing responsiveness and stability

- Aligned and evaluated on two datasets - PROX and GTA-IM

- State-of-the-art performance on motion metrics like trajectory, pose and contacts compared to previous methods

- Demonstrated ability to respond to dynamic environments with moving people and vehicles

The key novelty is in enabling responsive motion synthesis in dynamic 3D scenes by using tailored scene representations and introducing motion blending idea from trajectory optimization literature. Evaluations validate effectiveness over other methods on diverse metrics.
