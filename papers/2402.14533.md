# [Whose LLM is it Anyway? Linguistic Comparison and LLM Attribution for   GPT-3.5, GPT-4 and Bard](https://arxiv.org/abs/2402.14533)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper investigates whether different large language models (LLMs) like GPT-3.5, GPT-4 and Bard exhibit distinct linguistic styles in the text they generate, similar to how human authors have unique writing styles. It is unclear if LLMs also display such variability. 

Methods:
The authors build on an existing corpus (HC3) containing human and GPT-3.5 responses, and extend it (LC2 corpus) to also include matched GPT-4 and Bard responses over 5 datasets. They analyze linguistic differences across LLMs in vocabulary, part-of-speech distribution, dependency parsing and sentiment. Statistical tests compare the differences, which are then used to train a model to attribute text to the LLM it came from.

Key Findings:
The results reveal statistically significant differences in vocabulary size/density, part-of-speech tag usage for common tags like nouns as well as rare tags like interjections. Differences were also found in dependency parses, with Bard differing most from the other two. But no major differences occurred in sentiment. 

Using these linguistic indicators, the attribution model could correctly classify which LLM generated a given text with 88% accuracy on average, with linguistic markers from all examined aspects being the top features.

Main Contributions:
- The first comprehensive analysis showing distinct linguistic styles for major LLMs, similar to human author styles
- The style differences, especially in vocabulary, POS and dependencies, enable effective automated attribution of text to the LLM source 
- Has theoretical implication that LLMs reproduce some language diversity like humans
- Practical uses include LLM evaluation, selection, guiding detection of AI-written text

Limitations acknowledged include small corpora size, zero-shot scenario for LLMs, and English language only analysis.
