# [Human Preference Score: Better Aligning Text-to-Image Models with Human   Preference](https://arxiv.org/abs/2303.14420)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper seeks to address is: How can text-to-image generative models like Stable Diffusion be better aligned with human aesthetic preferences? The key hypotheses appear to be:1) Existing metrics used to evaluate generative image models like Inception Score and FID may not correlate well with human aesthetic preferences.2) Fine-tuning a model like CLIP on a dataset of human choices can produce a better "Human Preference Score" that aligns more closely with human preferences. 3) Guiding a generative model like Stable Diffusion with this Human Preference Score during training can produce a model that generates images more in line with human aesthetic preferences.In summary, the main research goal is to improve the alignment of text-to-image generative models with human aesthetic preferences, by collecting human preference data, training a metric to predict human preferences, and using that to guide model training. The key hypothesis is that this will produce generative models that create images people find more aesthetically pleasing.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a method to better align text-to-image models like Stable Diffusion with human aesthetic preferences. The key ideas are:- Collecting a large dataset of human choices on generated images to study human aesthetic preferences. The dataset contains over 25k instances of human selections between 2-4 images generated from the same text prompt. - Analyzing existing image quality metrics like IS, FID, and CLIP score and finding they do not correlate well with human choices. This motivates developing a better metric.- Proposing a Human Preference Score (HPS) based on fine-tuning a CLIP model on the collected human preference dataset. Experiments show HPS aligns better with human choices than original CLIP.- Using HPS to guide adapting Stable Diffusion to generate images more aligned with human preferences, via appending a special prompt to guide the model to avoid generating non-preferred images.- Conducting user studies validating the adapted Stable Diffusion model generates images with fewer artifacts and better captures user intentions compared to the original model.In summary, the key contribution is collecting human preference data on generated images and using it to develop a human preference score that can guide improving text-to-image models like Stable Diffusion. The overall goal is better aligning these models with human aesthetic preferences.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:The paper collects a dataset of human choices on AI-generated images to show that existing metrics do not correlate well with human preference, then trains a classifier to predict human preference and uses it to adapt an image generation model to create more human-preferred results.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other research in the field of adapting text-to-image models with human feedback:- The idea of collecting human feedback data to help align generative models with human preferences has been explored in some other recent works, such as [Hao et al., 2022] and [Lee et al., 2023]. However, this paper introduces a more large-scale and diverse dataset of human choices compared to previous efforts. The scale of the dataset enables more robust training and evaluation of the proposed human preference classifier.- The use of the CLIP model as a starting point for the human preference classifier, and fine-tuning it on the collected dataset of human choices, is a logical approach given CLIP's strong capabilities as an image-text matcher pre-trained on a massive dataset. Fine-tuning CLIP for this specialized task allows tailoring it better to predict human aesthetic preferences.- Adapting Stable Diffusion by incorporating human preference signals directly into the model training is an intuitive idea. However, the proposed method of using a special prompt prefix to indicate non-preferred images and tuning the model to associate that prefix with undesired artifacts is novel. This simple prompt engineering strategy seems effective for guiding the model without major architectural changes.- The paper demonstrates rigorous evaluation of the proposed human preference score (HPS) and the adapted Stable Diffusion model from both quantitative and qualitative perspectives. The human studies provide compelling evidence that the HPS matches human preferences better than general CLIP similarity, and that the adapted model generates images more aligned with human aesthetic sensibilities.- An important contribution of this work is highlighting limitations of common generative model evaluation metrics like IS and FID in capturing human aesthetic preferences and image quality aspects like odd limb topology. The new dataset and HPS provide means to assess these subjective qualities that are not well addressed by existing metrics.Overall, this paper pushes forward the important goal of adapting generative models to better match subjective human preferences through direct human feedback signals. Both the dataset and proposed model adaptation approach offer promising directions to help close the loop between text-to-image models and real human evaluators.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some future research directions suggested by the authors include:- Collecting more diverse human preference data from different user groups to reduce biases and improve generalization. The current dataset is limited to preferences of users on a single Discord channel.- Extending the methodology to other generative models besides Stable Diffusion, such as DALL-E 2, Imagen, etc. The human preference classifier currently focuses on Stable Diffusion generated images.- Exploring different model architectures and training techniques for the human preference classifier. The current model uses a fine-tuned CLIP, but other architectures could be explored.- Applying the human preference score to additional applications such as image retrieval, editing, and manipulation. The current work focuses on improving image generation.- Developing interactive frameworks that allow generative models to iteratively improve based on direct user feedback. The current method relies on static training data.- Combining human preference modeling with controllable generation methods to give users more fine-grained control over image attributes.- Exploring the societal impacts and ethical considerations of aligning AI with subjective human preferences.In summary, the main future directions are around expanding the data, models, and applications for human preference alignment in generative AI systems, as well as studying the broader impacts. More interactive frameworks and controllable generation based on preferences are also interesting areas for future work.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points from the paper:The paper proposes a method to better align text-to-image models like Stable Diffusion with human aesthetic preferences. The authors first collect a large dataset of 25,205 human preference choices on images generated by Stable Diffusion prompts. They find that existing image quality metrics like Inception Score and FID do not correlate well with human choices in their dataset. The authors then train a human preference classifier by fine-tuning CLIP on their dataset and derive a Human Preference Score (HPS) from it. Experiments show HPS better predicts human choices than CLIP and generalizes to other models like DALL-E. Finally, the authors use HPS to guide adapting Stable Diffusion to generate images more aligned with human preferences, demonstrating improved results in user studies. The key contribution is using human preference data to align generative models with aesthetic judgments through metrics like HPS.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:This paper introduces a new dataset and method for better aligning text-to-image models with human aesthetic preferences. The authors collected a large dataset of human choices on images generated by Stable Diffusion from the same prompt. Using this dataset, they found that common evaluation metrics like Inception Score and Fr√©chet Inception Distance did not correlate well with human preferences. To address this, the authors fine-tuned a CLIP model on their dataset to create a Human Preference Score (HPS) that better matches human judgements. They show HPS outperforms CLIP at predicting human choices. The authors use HPS to adapt Stable Diffusion using a simple method to make it generate more human preferable images. Experiments and user studies validate their adapted model captures user intentions better and creates fewer artifacts like awkward limbs. Overall, this paper demonstrates the importance of tracking human preferences for improving text-to-image models, and introduces a dataset and method to better align models to what users find aesthetically pleasing.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes a method to better align text-to-image models like Stable Diffusion with human preferences. The key ideas are:1) They collect a large dataset of human choices on images generated from the same prompt to study human aesthetic preferences. The dataset contains 25,205 instances with a total of 98,807 images. 2) They find that common image quality metrics like Inception Score and Fr√©chet Inception Distance do not correlate well with human choices. However, fine-tuning the CLIP model on their dataset yields better correlation.3) Based on the fine-tuned CLIP model, they derive a Human Preference Score (HPS) to quantify how well an image aligns with human preferences.4) They use HPS to guide the training of Stable Diffusion. Specifically, they construct a dataset labeling preferred and non-preferred images using HPS thresholds. The non-preferred images are associated with a special prompt prefix. They then adapt Stable Diffusion using this labeled dataset to make it associate non-preferred images with the special prompt. 5) During inference, they use the special prompt as a negative prompt for classifier-free guidance to avoid generating non-preferred images. Experiments and human studies demonstrate their adapted model generates more human-preferable images.In summary, the key method is collecting human preference data to train an HPS model, then using HPS thresholds to construct a dataset for adapting the generative model. This allows guiding the model to align better with human aesthetic preferences.


## What problem or question is the paper addressing?

 Based on my reading, the key points about the problem this paper is addressing are:- Recent text-to-image models like Stable Diffusion often generate images that do not align well with human aesthetic preferences. For example, they may produce awkward limb positions or facial expressions.- It is unclear if current evaluation metrics like Inception Score and FID actually correlate with human aesthetic judgments on generated images. These metrics may be biased towards texture rather than shape/content. - The goal of the paper is to better understand human aesthetic preferences for generated images, and adapt models like Stable Diffusion to align better with those preferences.- They collect a large dataset of human choices on Stable Diffusion images to analyze preferences. - They find current metrics do not correlate well with human choices, but fine-tuning CLIP on this dataset improves correlation.- They propose a Human Preference Score to guide models to generate more human-preferred images.- They adapt Stable Diffusion using this score to make it generate images that better match human aesthetic judgments and intentions.In summary, the key problem is the misalignment between current text-to-image models and human aesthetic preferences, and the paper aims to analyze preferences and adapt models to better match them. The human choice dataset and proposed Human Preference Score are ways to achieve this goal.
