# Human Preference Score: Better Aligning Text-to-Image Models with Human   Preference

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper seeks to address is: How can text-to-image generative models like Stable Diffusion be better aligned with human aesthetic preferences? The key hypotheses appear to be:1) Existing metrics used to evaluate generative image models like Inception Score and FID may not correlate well with human aesthetic preferences.2) Fine-tuning a model like CLIP on a dataset of human choices can produce a better "Human Preference Score" that aligns more closely with human preferences. 3) Guiding a generative model like Stable Diffusion with this Human Preference Score during training can produce a model that generates images more in line with human aesthetic preferences.In summary, the main research goal is to improve the alignment of text-to-image generative models with human aesthetic preferences, by collecting human preference data, training a metric to predict human preferences, and using that to guide model training. The key hypothesis is that this will produce generative models that create images people find more aesthetically pleasing.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method to better align text-to-image models like Stable Diffusion with human aesthetic preferences. The key ideas are:- Collecting a large dataset of human choices on generated images to study human aesthetic preferences. The dataset contains over 25k instances of human selections between 2-4 images generated from the same text prompt. - Analyzing existing image quality metrics like IS, FID, and CLIP score and finding they do not correlate well with human choices. This motivates developing a better metric.- Proposing a Human Preference Score (HPS) based on fine-tuning a CLIP model on the collected human preference dataset. Experiments show HPS aligns better with human choices than original CLIP.- Using HPS to guide adapting Stable Diffusion to generate images more aligned with human preferences, via appending a special prompt to guide the model to avoid generating non-preferred images.- Conducting user studies validating the adapted Stable Diffusion model generates images with fewer artifacts and better captures user intentions compared to the original model.In summary, the key contribution is collecting human preference data on generated images and using it to develop a human preference score that can guide improving text-to-image models like Stable Diffusion. The overall goal is better aligning these models with human aesthetic preferences.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper collects a dataset of human choices on AI-generated images to show that existing metrics do not correlate well with human preference, then trains a classifier to predict human preference and uses it to adapt an image generation model to create more human-preferred results.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in the field of adapting text-to-image models with human feedback:- The idea of collecting human feedback data to help align generative models with human preferences has been explored in some other recent works, such as [Hao et al., 2022] and [Lee et al., 2023]. However, this paper introduces a more large-scale and diverse dataset of human choices compared to previous efforts. The scale of the dataset enables more robust training and evaluation of the proposed human preference classifier.- The use of the CLIP model as a starting point for the human preference classifier, and fine-tuning it on the collected dataset of human choices, is a logical approach given CLIP's strong capabilities as an image-text matcher pre-trained on a massive dataset. Fine-tuning CLIP for this specialized task allows tailoring it better to predict human aesthetic preferences.- Adapting Stable Diffusion by incorporating human preference signals directly into the model training is an intuitive idea. However, the proposed method of using a special prompt prefix to indicate non-preferred images and tuning the model to associate that prefix with undesired artifacts is novel. This simple prompt engineering strategy seems effective for guiding the model without major architectural changes.- The paper demonstrates rigorous evaluation of the proposed human preference score (HPS) and the adapted Stable Diffusion model from both quantitative and qualitative perspectives. The human studies provide compelling evidence that the HPS matches human preferences better than general CLIP similarity, and that the adapted model generates images more aligned with human aesthetic sensibilities.- An important contribution of this work is highlighting limitations of common generative model evaluation metrics like IS and FID in capturing human aesthetic preferences and image quality aspects like odd limb topology. The new dataset and HPS provide means to assess these subjective qualities that are not well addressed by existing metrics.Overall, this paper pushes forward the important goal of adapting generative models to better match subjective human preferences through direct human feedback signals. Both the dataset and proposed model adaptation approach offer promising directions to help close the loop between text-to-image models and real human evaluators.


## What future research directions do the authors suggest?

Based on my reading of the paper, some future research directions suggested by the authors include:- Collecting more diverse human preference data from different user groups to reduce biases and improve generalization. The current dataset is limited to preferences of users on a single Discord channel.- Extending the methodology to other generative models besides Stable Diffusion, such as DALL-E 2, Imagen, etc. The human preference classifier currently focuses on Stable Diffusion generated images.- Exploring different model architectures and training techniques for the human preference classifier. The current model uses a fine-tuned CLIP, but other architectures could be explored.- Applying the human preference score to additional applications such as image retrieval, editing, and manipulation. The current work focuses on improving image generation.- Developing interactive frameworks that allow generative models to iteratively improve based on direct user feedback. The current method relies on static training data.- Combining human preference modeling with controllable generation methods to give users more fine-grained control over image attributes.- Exploring the societal impacts and ethical considerations of aligning AI with subjective human preferences.In summary, the main future directions are around expanding the data, models, and applications for human preference alignment in generative AI systems, as well as studying the broader impacts. More interactive frameworks and controllable generation based on preferences are also interesting areas for future work.
