# [MonoHuman: Animatable Human Neural Field from Monocular Video](https://arxiv.org/abs/2304.02001)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we create an animatable digital avatar that can be controlled in free viewpoint and arbitrary novel poses from only a monocular video?The key challenges they identify in addressing this question are:1) How to learn an accurate and generalizable deformation field from limited monocular video data. Previous methods tend to overfit to observed poses in the training data. 2) How to render photorealistic novel views and poses using the deformed points from the canonical space. There is ambiguity in finding correspondence features to guide rendering with only monocular input.To address these challenges, the main technical contributions of this paper are:1) A Shared Bidirectional Deformation module that disentangles skeletal motion and non-rigid deformation to learn a more generalizable deformation field.2) A Forward Correspondence Search module that queries correspondence features from keyframes to guide the rendering network.3) Extensive experiments showing their method can synthesize high-fidelity view-consistent results on challenging novel poses compared to prior state-of-the-art.In summary, the central hypothesis is that by modeling deformation bidirectionally and using correspondence features, they can create an animatable avatar from monocular video that generalizes to novel views and poses. The experiments aim to validate this hypothesis.
