# [MEMORYLLM: Towards Self-Updatable Large Language Models](https://arxiv.org/abs/2402.04624)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key aspects of the paper:

Problem:
- Existing large language models (LLMs) remain static after deployment, making it difficult to integrate new knowledge. 
- Prior solutions have limitations: retrieval-based methods have redundancy and logistical issues; model editing focuses on sentences and struggles with longer context; long context methods overload the context.

Proposed Solution: 
- Introduce MemoryLLM, comprising a transformer and fixed-size memory pool within the transformer's latent space. 
- Memory pool contains compressed knowledge as memory tokens in each layer. Allows efficient knowledge integration.
- Devise self-update mechanism to update portion of memory tokens with new knowledge, enabling gradual forgetting of old knowledge.  

Contributions:
- Integrate substantial 1B parameter memory pool into 7B parameter LLM.
- MemoryLLM demonstrates strong performance on:
   - Model editing benchmarks: Effectively incorporates new facts.
   - Long context QA: Retains and recalls knowledge over long contexts.  
   - Custom evaluation for knowledge retention.
- Shows integrity without degradation after nearly 1M memory updates.

In summary, MemoryLLM introduces an integrated memory pool design that allows efficient and continual knowledge integration while minimizing forgetting. Evaluations validate its versatility for absorbing new facts, handling long context, and retaining knowledge over extensive updates.
