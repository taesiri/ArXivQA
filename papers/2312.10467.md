# [TrojFSP: Trojan Insertion in Few-shot Prompt Tuning](https://arxiv.org/abs/2312.10467)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Prior prompt-based backdoor attacks require expensive full model fine-tuning or a large training dataset. They cannot achieve both high attack success rate (ASR) and high clean data accuracy (CDA) via few-shot prompt tuning.  
- Challenges in few-shot prompt backdoor attacks: (1) Imbalanced poisoned dataset issue where target class has more samples, hurting CDA (2) Overfitting due to high-dimensional prompt space (3) Lack of attention awareness between clean and poisoned samples.

Proposed Solution - TrojFSP:  
- Uses only 16-shot samples and freezes the language model parameters. Tunes a small set of prompt tokens.
- Target-Class Shrink (TC-Shrink): Dynamically reduces number of target class samples during data poisoning to balance classes.  
- Selective Token Poisoning: Only inserts Trojan into the least important prompt token based on expected sensitivity to combat overfitting.
- Trojan-Trigger Attention: Maximizes attention of poisoned token on triggers and minimizes it on clean samples.   

Main Contributions:
- First prompt backdoor attack via few-shot prompt tuning that keeps model frozen.
- Achieves over 97% ASR and less than 2% CDA loss across models and datasets. 
- Outperforms prior works by 9-48% higher ASR and 4-9% higher CDA in few-shot setting.
- Analyzes challenges in few-shot backdoor attacks and provides tailored solutions.

The paper raises awareness about emerging threat of few-shot prompt backdoor attacks and stimulates further research into defenses against such attacks.
