# [PartDistill: 3D Shape Part Segmentation by Vision-Language Model   Distillation](https://arxiv.org/abs/2312.04016)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes PartDistill, a novel cross-modal distillation framework for zero-shot 3D shape part segmentation using 2D vision-language models (VLMs). It addresses three main challenges: lack of 3D segmentation for occluded/undetected regions, inaccurate VLM predictions, and lack of knowledge transfer across shapes. The core idea is to distill 2D semantic knowledge from a VLM teacher network into a 3D student network. The student network learns from incomplete 2D knowledge while extracting geometric features from multiple shapes. A bi-directional distillation is carried out - forward distillation to transfer 2D knowledge, and backward distillation to refine the 2D knowledge based on student predictions. This enhanced 2D knowledge further improves the 3D segmentation. PartDistill works for both bounding-box and pixel-wise VLMs. It also incorporates generated shapes from existing models as supplementary knowledge. Experiments on ShapeNetPart and PartE datasets show over 15% and 12% higher mean IoU than prior arts. Both qualitative and quantitative results demonstrate PartDistill's ability to address key limitations and effectively perform zero-shot 3D part segmentation using 2D supervision.
