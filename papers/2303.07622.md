# RE-MOVE: An Adaptive Policy Design Approach for Dynamic Environments via   Language-Based Feedback

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the key research questions/hypotheses appear to be:1) How can reinforcement learning policies be adapted at test-time to handle changes in the environment that were not seen during training? The paper notes that RL policies often fail to generalize to new obstacles/configurations during real-world deployment.2) When should a robot request human assistance (via feedback) to handle unfamiliar situations? The paper aims to develop a principled approach to deciding when to query a human, rather than asking for constant guidance. 3) How should human feedback be incorporated to adjust the policy on-the-fly? The paper explores using natural language instructions and converting them to action sequences.4) How does the design of the observation/input space impact uncertainty estimation and the ability to detect novel scenarios? The paper studies different observation configurations and their effect on quantifying epistemic uncertainty.In summary, the central focus seems to be on improving test-time adaptation of RL policies by leveraging human feedback. The key research questions revolve around deciding when to request human guidance, how to interpret it, and how the agent's observation space impacts uncertainty-driven learning. The overall goal is to enable robots to handle novel objects and environments not seen during training.


## What is the main contribution of this paper?

The main contribution of this paper appears to be proposing a new approach called RE-MOVE (Request help and MOVE on) for enabling reinforcement learning policies to adapt to changes in the environment during real-time deployment. The key ideas presented are:- Using epistemic uncertainty quantification to determine when the policy is uncertain and needs to request human feedback. This allows the robot to identify when it encounters situations that differ from the training data.- Leveraging natural language feedback from humans to guide the robot's actions when uncertainty is high. This allows incorporating human knowledge to handle novel scenarios.- Demonstrating the approach in both simulated and real-world robot navigation tasks. The results show that RE-MOVE enables robots to successfully navigate environments with obstacles and configurations not seen during training by requesting help from humans when needed.In summary, the main contribution appears to be developing a method for reinforcement learning policies to adapt at test time by monitoring uncertainty and incorporating human feedback through language. The experiments demonstrate that this approach allows robots to handle novel situations and continue to reach goals despite changes in the environment.
