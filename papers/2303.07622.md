# RE-MOVE: An Adaptive Policy Design Approach for Dynamic Environments via
  Language-Based Feedback

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the key research questions/hypotheses appear to be:1) How can reinforcement learning policies be adapted at test-time to handle changes in the environment that were not seen during training? The paper notes that RL policies often fail to generalize to new obstacles/configurations during real-world deployment.2) When should a robot request human assistance (via feedback) to handle unfamiliar situations? The paper aims to develop a principled approach to deciding when to query a human, rather than asking for constant guidance. 3) How should human feedback be incorporated to adjust the policy on-the-fly? The paper explores using natural language instructions and converting them to action sequences.4) How does the design of the observation/input space impact uncertainty estimation and the ability to detect novel scenarios? The paper studies different observation configurations and their effect on quantifying epistemic uncertainty.In summary, the central focus seems to be on improving test-time adaptation of RL policies by leveraging human feedback. The key research questions revolve around deciding when to request human guidance, how to interpret it, and how the agent's observation space impacts uncertainty-driven learning. The overall goal is to enable robots to handle novel objects and environments not seen during training.
