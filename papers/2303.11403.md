# eP-ALM: Efficient Perceptual Augmentation of Language Models

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to efficiently adapt unimodal pretrained models (e.g. large language models and visual encoders) to multimodal tasks like visual question answering and image/video/audio captioning without large amounts of multimodal pretraining data or fine-tuning many parameters. Specifically, the paper investigates augmenting language models with perception by freezing most parameters and only training a small number of adaptation parameters (e.g. a linear projection layer and soft prompt).The key hypothesis is that it is possible to devise very efficient approaches, in terms of number of trainable parameters, training data, and compute, to adapt existing unimodal models for multimodal tasks by better aligning the visual and language representations.
