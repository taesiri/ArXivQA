# [NEMTO: Neural Environment Matting for Novel View and Relighting   Synthesis of Transparent Objects](https://arxiv.org/abs/2303.11963)

## What is the central research question or hypothesis that this paper addresses?

 Based on my review, this paper focuses on the problem of modeling and rendering transparent 3D objects with unknown refractive indices. The key hypotheses/questions it addresses are:

1) Can we develop an end-to-end neural rendering pipeline that can model both the complex geometry and appearance of transparent objects for tasks like novel view synthesis and relighting? 

2) Can we design a neural network module to better handle light refraction through the object compared to analytical/physics-based methods? This is critical as small geometry errors can significantly impact rendered views.

3) Can we leverage implicit neural representations like SDFs to model the geometry and a ray bending network for refractive effects to achieve high quality rendering without knowing the object's refractive index?

4) Will the proposed approach generalize well to real captured data of transparent objects compared to existing methods that often rely on controlled capture or synthesized training data?

In summary, the main research goals are developing an end-to-end neural approach for modeling and rendering transparent objects that can handle complex geometry, unknown refractive indices, and real world data by combining implicit geometry networks with a learned ray bending module for refraction. Key hypotheses are that this will improve over analytical refractive models and generalize better than existing learning-based methods.


## What is the main contribution of this paper?

 Based on my understanding, the main contribution of this paper is proposing an end-to-end neural rendering pipeline called NEMTO to model and render novel views and relighting of 3D transparent objects with complex geometry and unknown refractive indices. 

Specifically, the key contributions are:

- Leveraging implicit SDFs to model the complex geometry of transparent objects.

- Proposing a Ray Bending Network (RBN) to model light refraction through the object by directly mapping input ray directions to output refracted ray directions. This is more tolerant to geometric inaccuracies than analytical refraction models.

- An end-to-end differentiable rendering module that combines reflected and refracted radiance based on Fresnel equations. 

- Demonstrating high quality novel view synthesis and relighting on both synthetic and real transparent objects, outperforming prior neural rendering techniques.

The main significance is developing an end-to-end learnable pipeline to model transparent objects with complex and unknown properties. This is useful for rendering transparent objects in mixed reality and other applications. The RBN in particular helps disentangle geometry from refractive appearance, improving performance over analytical models.
