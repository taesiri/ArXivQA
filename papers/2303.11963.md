# [NEMTO: Neural Environment Matting for Novel View and Relighting   Synthesis of Transparent Objects](https://arxiv.org/abs/2303.11963)

## What is the central research question or hypothesis that this paper addresses?

 Based on my review, this paper focuses on the problem of modeling and rendering transparent 3D objects with unknown refractive indices. The key hypotheses/questions it addresses are:1) Can we develop an end-to-end neural rendering pipeline that can model both the complex geometry and appearance of transparent objects for tasks like novel view synthesis and relighting? 2) Can we design a neural network module to better handle light refraction through the object compared to analytical/physics-based methods? This is critical as small geometry errors can significantly impact rendered views.3) Can we leverage implicit neural representations like SDFs to model the geometry and a ray bending network for refractive effects to achieve high quality rendering without knowing the object's refractive index?4) Will the proposed approach generalize well to real captured data of transparent objects compared to existing methods that often rely on controlled capture or synthesized training data?In summary, the main research goals are developing an end-to-end neural approach for modeling and rendering transparent objects that can handle complex geometry, unknown refractive indices, and real world data by combining implicit geometry networks with a learned ray bending module for refraction. Key hypotheses are that this will improve over analytical refractive models and generalize better than existing learning-based methods.
