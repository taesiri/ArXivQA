# [Long-form factuality in large language models](https://arxiv.org/abs/2403.18802)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key aspects of the paper:

Problem:
- Large language models (LLMs) often generate faulty responses containing factual errors when asked open-ended questions requiring in-depth, multi-paragraph answers. However, there are no comprehensive benchmarks or reliable evaluation methods to measure the "long-form factuality" of LLMs.

Proposed Solutions:
- Introduce LongFact, a benchmark containing 2,280 prompts across 38 topics that require LLMs to give long-form, factual responses.
- Propose SAFE, which uses a search-enabled LLM to break down responses into facts, check each fact's relevance, and verify the facts against Google Search.
- Introduce F1@K metric that balances precision (percentage of supported facts in response) and recall (percentage of provided facts out of desired number K).

Main Contributions:
- LongFact benchmark for evaluating long-form factuality over diverse topics.
- SAFE method for automatic evaluation that outperforms human annotators in both quality and cost. 
- F1@K metric that considers both precision and recall tailored to long-form open-ended responses.
- Extensive benchmarking showing larger LLMs have better long-form factuality.

In summary, this paper makes significant contributions in datasets, evaluation methods, and metrics to advance the understanding and improvement of factuality in long-form open-ended question answering for LLMs. The solutions provide the means to reliably measure this challenging capability at scale.
