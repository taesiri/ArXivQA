# [Space Time Recurrent Memory Network](https://arxiv.org/abs/2109.06474v2)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we develop an efficient space-time memory network architecture that can handle long video sequences while maintaining a constant memory size?

The key ideas and contributions appear to be:

- Proposes a novel space-time recurrent memory network (STReMN) with a fixed number of memory slots that can be updated adaptively over time. 

- Learns a memory update strategy using a Gumbel-softmax attention mechanism to select which slot to replace when updating the memory. This avoids having to hand-engineer memory update rules.

- Evaluates STReMN on video object segmentation and video prediction tasks. Shows it can achieve strong performance on these tasks while keeping the memory size constant regardless of video length.

- Outperforms recent transformer-based methods on video object segmentation while using less memory. Also shows competitive results on video prediction compared to state-of-the-art approaches.

- Provides ablation studies analyzing the learned memory update module and visualizations showing what kind of frames the model retains in its limited memory slots.

In summary, the main contribution seems to be presenting a constant-size recurrent memory architecture for spatio-temporal reasoning that can scale to long videos and adaptively determine what to store in its fixed memory slots. The experiments demonstrate its effectiveness on two challenging video analysis tasks.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- Proposing a novel space-time recurrent memory network (STReMN) architecture for spatio-temporal reasoning tasks. The key aspects are:

1) It maintains a fixed-size memory with a constant number of slots that get updated over time. This allows efficient online processing for long videos without increasing memory size.

2) It uses a learned memory update module based on Gumbel-Softmax to decide which slot to replace when updating the memory. This adaptively determines what to store in the limited memory.

3) The memory stores spatial feature maps rather than vectors, to retain spatial information needed for visual tasks.

- Applying the STReMN architecture to two challenging spatio-temporal tasks:

1) Video object segmentation (VOS), where it achieves state-of-the-art results compared to recent transformer models while using constant memory.

2) Video prediction, where it outperforms prior memory network architectures.

- Demonstrating the learned memory update module outperforms hand-designed rules for updating memory slots.

- Analyzing the behavior of the learned memory module, showing it tends to store frames with significant appearance changes.

In summary, the key novelty seems to be the constant-size spatio-temporal memory architecture with the learned update module, which enables efficient online processing for spatial vision tasks on long videos. The experiments on VOS and video prediction showcase its strengths.
