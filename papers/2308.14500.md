# [LAC: Latent Action Composition for Skeleton-based Action Segmentation](https://arxiv.org/abs/2308.14500)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we learn better representations for skeleton-based action segmentation in untrimmed videos containing complex composable actions? The key hypothesis appears to be:Learning from synthesized composable skeleton motions and applying self-supervised contrastive learning can help train a visual encoder that better captures subtle action details and dynamics, improving performance on skeleton-based action segmentation tasks.In more detail:- Current skeleton-based action segmentation methods rely on visual encoders pre-trained on trimmed single-action datasets, which limits their ability to handle complex composable actions in untrimmed videos. - This paper proposes a new self-supervised framework called LAC that involves:1) A novel generation module that can synthesize composable skeleton motions by linearly combining latent codes.2) A contrastive learning module that trains the visual encoder on the synthesized data to learn representations invariant to data augmentations.- By learning from diverse synthesized composable motions and maximizing similarity of augmented examples, the hypothesis is that the visual encoder will gain stronger representational power for subtle action details.- This improved encoder can then be effectively transferred to skeleton-based action segmentation tasks, capturing composable actions better and improving performance.In summary, the central hypothesis is that leveraging synthesized composable data and self-supervised contrastive learning can enable learning improved skeleton representations for complex action segmentation. The experiments aim to demonstrate and validate this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing Latent Action Composition (LAC), a new self-supervised framework for learning skeleton-based action representations by synthesizing and learning from composable motions. - Introducing a novel Linear Action Decomposition (LAD) mechanism within an autoencoder framework to disentangle "static" and "motion" features of skeleton sequences into an interpretable latent space. This allows combining motions from multiple videos through linear operations.- Using the synthesized composable skeleton sequences for self-supervised contrastive pre-training of a skeleton visual encoder, with losses applied at both the video and frame levels. - Demonstrating the benefits of pre-training with LAC by transferring to downstream action segmentation tasks, where it outperforms prior state-of-the-art approaches on multiple datasets.In summary, the key innovation seems to be using the proposed LAC framework to synthesize more complex and realistic composable skeleton motions, and leveraging these to learn improved action representations that transfer well to fine-grained action segmentation problems. The linearly disentangled latent space and multi-level contrastive losses during pre-training appear to be important components enabling this.
