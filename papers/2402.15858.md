# [FedMM: Federated Multi-Modal Learning with Modality Heterogeneity in   Computational Pathology](https://arxiv.org/abs/2402.15858)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Multimodal fusion of data from different sources (e.g. medical images, genomic data) can improve accuracy in computational pathology tasks like cancer diagnosis. However, existing multimodal learning methods require access to raw patient data, posing privacy risks. Federated Learning (FL) allows privacy-preserving collaborative model training, but struggles with heterogeneous (partially overlapping) data distributions across hospitals.

Proposed Solution:
The paper proposes Federated Multi-Modal learning (FedMM) to address multimodal heterogeneity in a privacy-preserving manner. Instead of training a joint multimodal model like in traditional FL, FedMM trains multiple single-modal feature extractors in a federated way. Hospitals can then leverage these pre-trained extractors locally to extract features from their data and perform downstream tasks. 

Key ideas:
- Introduce global class prototypes for each modality as "pseudo-labels" for federated training
- Dynamic loss balancing true label and prototype distance losses 
- Modular design extracts single modalities separately

Main Contributions:
- Propose FedMM framework to enable federated learning with heterogeneous multimodal medical data
- Innovative dynamic loss function to overcome lack of labels for federated training 
- Comprehensive experiments on two medical datasets demonstrate accuracy improvements over baselines

In summary, the paper makes a novelFedMM system to unlock the benefits of multimodal learning in practical clinical scenarios with distributed heterogeneous data sources. The proposed techniques outperform alternatives while preserving data privacy.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a Federated Multi-Modal (FedMM) learning framework that trains multiple single-modal feature extractors in a privacy-preserving federated manner to enhance subsequent classification performance for heterogeneous multimodal medical data distributed across hospitals.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing FedMM, a Federated Multi-Modal learning framework that trains multiple single-modal feature extractors in a federated manner to help improve subsequent classification performance. Specifically:

- FedMM addresses the issue of modality heterogeneity in computational pathology by training single-modal feature extractors federatedly, allowing each hospital to leverage these extractors locally for feature extraction and classification. 

- FedMM uses an innovative dynamic loss function that incorporates both the local true label and global prototype as "pseudo-labels" to overcome the challenge of updating federated feature extractors without access to labels due to privacy constraints.

- Through comprehensive evaluations on two public datasets, FedMM is shown to significantly outperform two baseline methods in terms of accuracy and AUC metrics. This demonstrates its effectiveness for multimodal and privacy-sensitive computational pathology.

In summary, the key innovation of FedMM is transforming a complex heterogeneous multimodal input into multiple manageable single-modal inputs to effectively tackle the issue of modality heterogeneity in federated learning systems, while ensuring data privacy.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the key keywords and terms associated with this paper include:

- Multimodal fusion: The paper focuses on fusing complementary multimodal information, such as histology images and genomic data, for computational pathology applications.

- Federated learning (FL): The paper proposes a federated learning framework to enable collaborative training of models across multiple hospitals/clients while preserving data privacy. 

- Modality heterogeneity: The paper aims to tackle the issue of heterogeneous (yet possibly overlapped) modalities data across various hospitals/clients in the federated learning setting.

- Computational pathology: The proposed methods are applied to computational pathology tasks such as classification of lung and kidney cancer subtypes. 

- Privacy-preserving: The federated learning approach allows collaborative model training without sharing raw patient data, thereby preserving privacy.

- Feature extraction: The proposed FedMM framework trains multiple single-modal feature extractors in a federated manner to generate discriminative embeddings for downstream tasks.

- Classification: The locally extracted multimodal features are classified using models trained on each client to predict cancer subtypes.

In summary, the key focus is on multimodal fusion, federated learning, modality heterogeneity, computational pathology, privacy preservation, feature extraction, and classification.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes a novel Federated Multi-Modal (FedMM) learning framework to address the issue of modality heterogeneity in computational pathology. What is the key intuition and innovation behind this proposed method compared to existing federated learning approaches? 

2. The paper introduces an innovative dynamic loss function consisting of two components - an L2 distance loss and a binary cross-entropy loss. Explain the rationale behind using these two loss components and how the dynamic weight Î»(t) allows adaptive transition between emphasizing these losses during training.

3. The global prototype serves as a "pseudo-label" in the absence of real labels across clients in federated learning. Discuss the role of the global prototype in enabling effective collaborative training of the feature extractors in FedMM and why this is useful.

4. The proposed method extracts modality-specific features separately using federated trained single-modal feature extractors, instead of training a unified multimodal fusion model. Elaborate on why this strategy effectively handles heterogeneous modalities across different hospitals. 

5. Discuss the differences in optimization objectives between the proposed FedMM framework and conventional federated learning formulations. What modifications were made to the typical client and server update procedures?

6. The ablation study investigates the impact of factors like transition point of losses, modalities used, and fusion mechanisms on performance. Analyze these results - which factors matter most and what insights do they provide about FedMM?

7. What customizations need to be made to real-world medical datasets from different hospitals to evaluate the proposed method? Explain the data splits and simulation of modality heterogeneity performed in the paper.  

8. The paper adopts multiple instance learning and a self-normalizing network for feature extraction from pathology slides and genomic data respectively. Justify the rationale behind choosing these methods.

9. Discuss the effectiveness of FedMM in balancing performance gains while preserving data privacy, compared to the two baseline methods evaluated. What additional metrics could be used to assess data privacy?

10. Beyond computational pathology, what other potential applications could the proposed federated multi-modal learning framework be beneficial for? What challenges need to be addressed to extend it?
