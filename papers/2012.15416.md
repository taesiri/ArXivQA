# Directed Beam Search: Plug-and-Play Lexically Constrained Language   Generation

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we control large transformer-based language models to generate text that meets hard lexical constraints in a plug-and-play manner, without needing to retrain the models?Specifically, the paper proposes a method called "Directed Beam Search" (DBS) that can guide language generation models like GPT-2 to include specified words in the generated text. The key goals are for DBS to:- Be plug-and-play, meaning it can work with pre-trained models without retraining them- Work with large transformer models like GPT-2- Allow controlling text generation to meet hard lexical constraints (require certain words) - Be suitable for general free-form text generation tasks, not just narrow domainsThe paper hypothesizes that DBS can achieve these goals through its directed beam search algorithm that modifies the models' logits to encourage generating words similar to the target words, and ranks beam search candidates based on a quality score rewarding target word occurrence and fluency.So in summary, the central research question is how to control transformer language models to meet lexical constraints in a plug-and-play manner suitable for general text generation. DBS is proposed and evaluated as a method to address this question.


## What is the main contribution of this paper?

The main contribution of this paper is proposing Directed Beam Search (DBS), a plug-and-play method for lexically constrained language generation. Key points about DBS:- It is a beam search method that guides language generation towards meeting lexical constraints (containing certain words). - It modifies the logits of a language model to increase the probability of generating words similar to the target word. - It uses a quality score to select beams that contain the target word while maintaining fluency.- It is model-agnostic and can be combined with any language model without training or fine-tuning.- It is evaluated on keyword-to-phrase generation and story generation using GPT-2, showing it can successfully guide a large pre-trained model to meet lexical constraints.- Compared to existing methods, DBS works with transformer models, is suitable for general language generation (not just restricted domains like machine translation), and is efficient since it effectively reduces the search space.In summary, the main contribution is proposing Directed Beam Search, a simple yet effective plug-and-play method for guiding language models to generate text that contains specific words.
