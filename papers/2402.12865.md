# [Backward Lens: Projecting Language Model Gradients into the Vocabulary   Space](https://arxiv.org/abs/2402.12865)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Understanding how knowledge is acquired, stored, and recalled in large language models (LMs) like Transformers is an open research question. 
- Recent methods have projected model weights and activations into the vocabulary space to interpret LMs, but not gradients.

Proposed Solution: 
- The paper develops methods to project gradient matrices into vocabulary tokens during backpropagation.
- It shows gradients are low-rank matrices that can be decomposed into sparse outer products of forward/backward pass vectors.  
- This allows interpreting gradients by projecting small representative subspaces rather than huge matrices.

Key Contributions:

1) Proves gradient matrix ranks match number of input tokens, except the last layer which is rank 1.

2) Introduces Backward Lens to project gradients to tokens using logit lens on forward inputs or backward error vectors.

3) Identifies "imprint and shift" mechanism in MLP layers where gradients imprint forward inputs into first layer and shift second layer towards target embedding.

4) Achieves strong editing performance with a fast 1-step "forward shift" method that approximates gradients by outer product of input and target embedding.  

5) Provides extensive analysis and examples showing evolution of projected tokens across layers/tokens in forward and backward passes during editing.

Overall, the key innovation is interpreting gradients by projecting them into human-readable tokens. This reveals new insights into how models store knowledge and how backpropagation modifies that knowledge. A simple 1-step editing method is also introduced based on these discoveries.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper develops methods to project language model gradients into the vocabulary space in order to interpret how models acquire and store knowledge during training, revealing a "imprint and shift" mechanism in feed-forward layers where information from the forward pass is imprinted into the weights while outputs are shifted towards new targets.


## What is the main contribution of this paper?

 The main contributions of this paper are:

(i) Analyzing the rank of gradients in transformer language models and showing that they are low-rank matrices. Specifically, the rank is equal to the number of tokens in the input sequence.

(ii) Interpreting gradients by inspecting relatively small spanning sets rather than the full gradient matrices. The spanning sets consist of either the input vectors or vector-Jacobian products from the forward and backward passes. 

(iii) Projecting these spanning sets into vocabulary space using logit lens to reveal the information contained in gradients and understand how models store knowledge during training.

(iv) Uncovering a "imprint and shift" mechanism that captures how information is stored in the feedforward layers during backpropagation - imprinting copies of inputs into the first layer and shifting outputs towards the target embedding in the second layer.

(v) Leveraging this mechanism to develop a novel editing method that requires only a single forward pass yet achieves competitive performance to state-of-the-art editing techniques.

In summary, the key innovation is projecting gradients to vocabulary space and using the low-rank structure to interpret how knowledge is stored and updated during backpropagation. The analysis led to both insights into model learning and a new editing technique.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper summary, some of the key terms and concepts associated with this paper include:

- Backpropagation - The process of propagating error gradients backwards through a neural network to update the weights. The paper analyzes the gradients produced during backpropagation in language models.

- Transformers - The paper focuses specifically on analyzing gradients in Transformer-based language models.

- Logit Lens - A method for projecting internal representations in language models to the vocabulary space to aid interpretation. The paper extends this to projecting gradients. 

- Low-rank matrices - The paper shows that gradient matrices tend to be low-rank and leverages this to decompose them into interpretable spanning vectors.

- Vocabulary projection - Projecting gradient vectors into probabilities over vocabulary words using the Logit Lens method to understand what information they encode. 

- Imprint and shift - A proposed mechanism by which transformer layers update their weights during backpropagation, first "imprinting" new information then "shifting" activations.

- Forward pass editing - An editing method proposed based on directly injecting target tokens into model layers using only a forward pass.

In summary, the key terms cover gradient analysis, Transformer architectures, vocabulary projection techniques, the low-rank structure of gradients, a proposed imprint and shift learning mechanism, and editing methods based on forward passes.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper introduces the concept of "imprint and shift" to describe how information is stored in the MLP layers during backpropagation. Can you elaborate on what "imprint" and "shift" refer to and how they enable learning in the MLP?

2. The paper projects gradient matrices into the vocabulary space using Logit Lens. What motivates this approach and what new insights does it provide about how models acquire and store knowledge compared to only examining forward pass activations? 

3. The paper shows that gradient matrices have low rank and can be interpreted as linear combinations of a small set of input/VJP vectors. How does exploiting this low-rank structure simplify analysis and why is it preferable to examining full gradient matrices directly?

4. What is the key difference in how the paper interprets gradients of the FF1 vs FF2 MLP layers and why is this distinction important? How do the roles of FF1 vs FF2 differ in the "imprint and shift" concept?

5. The VJP vectors passed during backpropagation are proposed to encode information about the target embedding. What evidence supports this claim? How do VJP projections qualitatively change across layers?

6. How is the ranking of tokens via Logit Lens interpreted differently for FF1 inputs vs FF2 VJPs? What causes ranks to flip when moving from inputs to VJPs?  

7. The paper introduces a "forward pass shifting" method that approximates backpropagation gradients using only a feedforward pass. How is this method motivated by the analysis of gradients and VJPs? What are its limitations?

8. What might the low-rank structure of gradients imply about the nature of information storage in MLPs? Could examining gradient ranks give insight into model capacity or selectivity of fine-tuning?

9. How might the concept of input "imprinting" in FF1 help explain phenomena like in-context learning? Could the approach be extended to study attention layers?

10. The paper focuses on analyzing gradients rather than propose a new editing method. What future work could better leverage these analyses of gradients and imprint/shift mechanisms to improve LM editing?
