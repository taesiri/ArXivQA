# [Structure Your Data: Towards Semantic Graph Counterfactuals](https://arxiv.org/abs/2403.06514)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Explainable AI (XAI) methods aim to make machine learning model predictions more interpretable to humans. Counterfactual explanations (CEs) are a type of XAI method that explain model predictions by finding an alternative (counterfactual) input that would change the prediction to a different target class. 
- Existing CE methods have limitations in leveraging semantics and representing relationships between concepts. Pixel-level methods focus on visual features rather than concepts. Concept-based methods represent concepts as flat sets, which fails to capture relationships between concepts. This limits the interpretability and meaningfulness of explanations.

Proposed Solution:
- The paper proposes a new method to generate counterfactual explanations using semantic graphs to represent images or other inputs. 
- Semantic graphs accurately capture concepts (nodes) and relationships between them (edges). This allows for more expressive explanations.
- Graph edit distance (GED) is used to find counterfactuals that require minimal edits to the semantic graph to change the prediction. However, computing GED is expensive. 
- To efficiently approximate GED, graph neural networks (GNNs) are trained to embed semantic graphs into a vector space that preserves inter-graph proximity. GED is computed only once per query during retrieval by finding the closest embedding to the query graph that belongs to the target class.

Contributions:
- Demonstrates quantitative and qualitative superiority over prior concept-based and pixel-based CE methods, using semantic graph structure to produce more interpretable, expressive and meaningful explanations.
- Achieves efficient GED approximation using GNNs without compromising representation of concept relationships.
- Highlights importance of graph structure through user studies showing even "blind" explanations containing only graphs and edits enabled accurate prediction of model behavior.
- Establishes unified quantitative evaluation based on GED rankings and qualitative human evaluation applicable across explanation methods using different features.
- Proposes adaptable model-agnostic framework shown to be effective across neural and non-neural classifiers, visual and non-visual modalities.

In summary, the paper introduces a novel method for generating counterfactual explanations using semantic graphs and GNN-based approximation of graph edit distance. Both quantitative metrics and human studies demonstrate the superiority of this approach in producing meaningful and interpretable explanations.
