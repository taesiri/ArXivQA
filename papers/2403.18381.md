# [Improving Attributed Text Generation of Large Language Models via   Preference Learning](https://arxiv.org/abs/2403.18381)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Verifiable generation requires LLMs to generate answers with supporting evidence documents to increase trustworthiness. The retrieval stage is critical to find relevant documents.  
- However, existing retrievers become the bottleneck that limits overall pipeline performance. They have much fewer parameters than LLMs and have not been shown to scale well.
- In the typical pipeline, the LLM passively receives low-quality retrieval results and cannot provide feedback, overshadowing the LLM's capabilities.

Proposed Solution:
- LLatrieval - Lets the LLM iteratively update and verify retrieval results until it can generate a verified, supported answer.

Key Features:
- Retrieval Verification: LLM verifies if current retrieved docs can support answering the question. Avoids low-quality retrieval.
- Retrieval Update: Progressive Selection - LLM progressively selects better docs from candidates. Missing-Info Query - LLM generates query for missing info to supplement docs.

Main Contributions:  
- First framework enabling LLMs to fully provide feedback to improve retrieval results.
- Significantly outperforms extensive baselines and achieves new SOTA results.
- Takes first step in scaling retrieval by scaling LLMs, shows potential.
- Provides important design choices for LLM-augmented retrieval.

In summary, the paper introduces a novel iterative LLM-based retrieval refinement approach to improve evidence retrieval in verifiable generation. By enabling LLMs to verify and update retrieval, it avoids low-quality retrieval that limits answer quality and outperforms existing methods.
