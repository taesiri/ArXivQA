# [Visualization-of-Thought Elicits Spatial Reasoning in Large Language   Models](https://arxiv.org/abs/2404.03622)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Spatial reasoning is crucial for human cognition but has been relatively underexplored for large language models (LLMs). Humans utilize mental images to enhance spatial reasoning through "the mind's eye". 
- Existing works rely mainly on linguistic semantics and verbal reasoning for spatial tasks, which may not require genuine spatial understanding. There is a need to evaluate the spatial awareness and reasoning skills of LLMs from a cognitive perspective.

Proposed Solution - Visualization-of-Thought (VoT) Prompting:
- The paper proposes VoT prompting to elicit the "mind's eye" of LLMs by visualizing their reasoning traces in a 2D grid world, guiding subsequent reasoning steps.  
- VoT generates reasoning traces and visualizations in an interleaved manner, enabling visual state tracking at each step. The subsequent step is conditioned on prior thoughts and visualizations.
- This grounded approach enhances spatial reasoning by manipulating mental images of unseen states.

Key Contributions:
- Sheds light on LLMs' ability for spatial reasoning from a cognitive view through analysis of reasoning traces.
- Develops visual navigation and visual tiling tasks with synthetic datasets to evaluate spatial reasoning.
- Proposes VoT prompting that significantly improves LLMs' performance by eliciting their "mind's eye" across spatial reasoning tasks.
- VoT enables LLMs to outperform multimodal LLMs without additional training, indicating promise for integrating visualization to enhance reasoning.

In summary, the paper demonstrates LLMs' emergent capability for spatial reasoning by eliciting their "mind's eye". VoT prompting enables visual state tracking to guide multi-hop spatial reasoning, outperforming existing models. The visualized reasoning traces provide insights into LLMs' spatial cognition.
