# [Not Just a Black Box: Learning Important Features Through Propagating   Activation Differences](https://arxiv.org/abs/1605.01713)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we assign importance scores to features in neural networks in a way that addresses limitations of gradient-based methods?Specifically, the paper argues that prevailing methods like saliency maps and guided backpropagation rely on gradients, which can be problematic when gradients are zero even though a feature is informative (e.g. with ReLU activations). To address this, the paper proposes DeepLIFT, a method that assigns feature importance scores by comparing a neuron's activation to its 'reference' activation. The key hypothesis is that this reference-based approach can assign importance more accurately than gradient-based methods.The experiments on image classification and genomics data aim to test this hypothesis by comparing DeepLIFT results to gradient-based saliency maps. The authors conclude that DeepLIFT is able to assign importance to features overlooked by gradients, demonstrating the limitations of gradient-based methods and the advantages of their proposed approach.In summary, the central research question is how to assign feature importance in neural nets in a way that improves upon gradient-based methods, and DeepLIFT is proposed as a solution based on the hypothesis that using references is better than using gradients. The experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution is the DeepLIFT method for assigning importance scores to features in a neural network. The key ideas of DeepLIFT are:- It compares each neuron's activation to its "reference activation", which is the activation it has on some reference input. This allows it to assign importance even when gradients are zero.- It satisfies properties like "summation to delta" (contributions sum to the difference between the activation and reference activation) and "linear composition" (contributions propagate through linear operations). - It provides specific backpropagation rules to efficiently compute the contributions in a neural network.- It avoids issues like gradient attenuation that exist in other methods. In summary, DeepLIFT provides an interpretable way to understand which features are most important for a neural network's output, overcoming limitations of gradient-based methods. The paper shows improved feature attribution over gradients on image and genomics tasks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper presents DeepLIFT, an efficient and effective method for computing importance scores in a neural network by comparing each neuron's activation to its 'reference activation'.


## How does this paper compare to other research in the same field?

This paper presents DeepLIFT, a method for assigning importance scores to input features in a neural network model. Here are some key points on how it compares to other related work:- It improves on gradient-based methods like saliency maps, guided backpropagation, and deconvolutional nets by not relying solely on gradients, which can be zero and miss important contributions even when a feature is informative. - It is related to layer-wise relevance propagation (LRP) in propagating relevance scores backwards through the network layers. However, it shows LRP reduces to a gradient*input method when activations are piecewise linear, and DeepLIFT improves on this by using a reference activation rather than zero.- Compared to LRP, DeepLIFT avoids numerical stability issues by using multipliers rather than dividing relevance scores. It also incorporates bias terms more cleanly.- It provides specific backpropagation rules for various activation functions and layers to enable computation of the importance scores.- It demonstrates improved feature attribution over gradients on image classification and genomics tasks, highlighting relevant input patterns that gradients missed.Overall, DeepLIFT advances feature attribution for neural nets by addressing limitations of gradients, offering a principled and efficient method to propagate relevance through layers, and showing improved empirical performance over existing methods. It enables better interpretation of neural net models compared to purely gradient-based approaches.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors are:- Developing improved reference strategies beyond setting the reference input to all zeros. The authors note that different reference strategies may be more appropriate for different tasks. - Extending DeepLIFT to recurrent neural networks (RNNs) like LSTMs. The paper shows results for convolutional neural networks but does not evaluate RNNs.- Comparing DeepLIFT to other methods like integrated gradients on additional complex models and tasks. The paper makes comparisons primarily to gradient-based approaches on image classification and genomics examples. - Applying DeepLIFT to gain scientific insights and develop novel hypotheses in domains like genomics, healthcare, and drug discovery. The authors suggest DeepLIFT could help provide interpretable results to guide scientific discovery.- Developing improved methods to visualize and understand the importance scores produced by DeepLIFT. Better visualization approaches could further enhance interpretability.- Evaluating whether the importance scores from DeepLIFT correlate with human intuition and domain knowledge to quantify interpretability.- Extending DeepLIFT to other network architectures besides feedforward neural networks. The method may need to be adapted for other models like graph neural networks.In summary, the main suggested future directions are developing improved reference strategies, testing on more complex models like RNNs, comparing to other methods, applying to gain scientific insights, improving visualization, evaluating correlation with human intuition, and extending to other architectures. The overarching goal is to enhance the interpretability and applicability of DeepLIFT.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:This paper proposes DeepLIFT, a method for assigning importance scores to features in a neural network. It compares a neuron's activation to its 'reference activation', defined based on a reference input. DeepLIFT assigns contribution scores based on the difference between the actual activation and reference activation. This allows it to assign importance even when gradients are zero, overcoming limitations of gradient-based methods like saliency maps. The authors define DeepLIFT contribution scores mathematically to satisfy properties like summation to the difference-from-reference. They derive backpropagation rules to efficiently compute the scores and apply DeepLIFT to image classification and genomic sequence models, showing advantages over gradient-based approaches. Overall, DeepLIFT provides an improved way to understand which input features are most important for a neural network's output.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:This paper presents DeepLIFT, a method for assigning importance scores to features in a neural network. The key idea is to compare a neuron's activation to its 'reference' activation, defined as the activation it has when given a reference input. This allows DeepLIFT to assign importance scores even when the gradient is zero, which is a limitation of previous gradient-based methods like saliency maps and guided backpropagation. The method satisfies properties like the contributions summing to the difference between the output and reference output, and allows propagating contributions backwards through the network similar to backpropagation. The authors apply DeepLIFT to image classification on the Tiny ImageNet dataset and genomic sequence classification. On images, DeepLIFT produces superior saliency maps compared to gradient-based methods, highlighting meaningful parts of objects even when the gradient is zero. On genomic data, DeepLIFT is able to identify relevant sequence patterns that gradient-based methods miss. The results demonstrate that DeepLIFT provides an efficient and effective way to interpret neural network predictions by assigning importance scores to input features.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method described in the paper:The paper presents DeepLIFT (Learning Important FeaTures), a method for assigning importance scores to features in a neural network. DeepLIFT computes the contribution of each neuron to the output by comparing the neuron's activation to its 'reference' activation. The reference activation is defined as the activation the neuron has when the network is given a reference input, which is chosen appropriately for the task. DeepLIFT satisfies the properties of summation to delta (the contributions sum to the difference between the output and reference output) and linear composition (neurons propagate contributions to downstream neurons proportional to their own contribution). The method allows importance scores to be computed using simple chain rule-like backpropagation, avoiding issues like vanishing gradients. DeepLIFT is applied to image classification and genomics tasks and shown to give superior results compared to gradient-based methods.
