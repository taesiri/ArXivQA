# [Unsupervised Video Domain Adaptation with Masked Pre-Training and   Collaborative Self-Training](https://arxiv.org/abs/2312.02914)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes a novel video domain adaptation approach called UNITE (Unsupervised Adaptation with Teacher-Enhanced Learning) for unsupervised action recognition. UNITE leverages a powerful image-based teacher model (CLIP) to guide the adaptation process of a spatiotemporal student model to the target video domain. The approach has three main stages: 1) The student model is pre-trained on unlabeled target videos using a masked self-supervised objective with the guidance of the CLIP teacher's features, promoting discriminative feature learning. 2) The student model is fine-tuned on labeled source data with a classification objective. 3) A collaborative self-training procedure is used, where the student and teacher models work together to generate improved pseudolabels for unlabeled target videos. This collaborative self-training allows the image strengths of CLIP to complement the spatiotemporal modeling of the video student network. Experiments on three video domain adaptation benchmarks show UNITE provides significant gains over prior state-of-the-art methods. Ablations demonstrate the importance of both the masked pre-training stage and the collaborative self-training stage in achieving effective domain transfer of the student model.
