# [Cross-GAN Auditing: Unsupervised Identification of Attribute Level   Similarities and Differences between Pretrained Generative Models](https://arxiv.org/abs/2303.10774)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we perform an unsupervised, attribute-level comparison between two generative adversarial networks (GANs) in order to identify similarities and differences between them? 

The key ideas proposed in the paper to address this question are:

1) Introducing a cross-GAN auditing (xGA) framework that automatically discovers and categorizes attributes into:

- Common: Attributes shared between the GANs
- Missing: Attributes present in the reference GAN but not the client GAN 
- Novel: Attributes present in the client GAN but not the reference GAN

2) Using a robust feature extractor to enable effective alignment of attributes across GANs, even when there are challenging distribution shifts between them.

3) Leveraging the idea that attribute manipulations unique to one GAN will be out-of-distribution for the other GAN, allowing discovery of missing/novel attributes. 

4) Introducing quantitative metrics to evaluate the quality of discovered common, missing, and novel attributes.

5) Demonstrating through experiments on StyleGANs trained on various datasets that xGA provides an effective fine-grained characterization of similarities and differences between GAN models.

So in summary, the main hypothesis is that by discovering aligned attributes across GANs and identifying unique attributes, the proposed xGA framework enables interpretable auditing and comparison of generative models. The paper aims to demonstrate the viability of this approach.
