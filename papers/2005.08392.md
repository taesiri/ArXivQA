# [Vector-Quantized Autoregressive Predictive Coding](https://arxiv.org/abs/2005.08392)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:What are the key constituents in the representations learned by Autoregressive Predictive Coding (APC) that allow it to achieve good performance on the self-supervised future frame prediction task?The authors propose that incorporating vector quantization (VQ) layers into APC can reveal the important components in the learned representations by limiting model capacity. As the capacity becomes more constrained, the model has to prioritize retaining only the information most critical for the prediction task. By studying a sequence of APC models with decreasing codebook sizes, the authors aim to understand what information is preserved vs discarded in order to accomplish the future prediction task. They use phonetic and speaker classification probing tasks to quantify the phonetic and speaker information encoded in the representations.In summary, the central hypothesis is that adding VQ bottlenecks to APC will force the model to learn more selective representations that encode the core constituents needed for future frame prediction. Analyzing these representations can provide insights into the key components that lead to effective self-supervised learning.


## What is the main contribution of this paper?

The main contribution of this paper is proposing Vector-Quantized Autoregressive Predictive Coding (VQ-APC), a novel self-supervised speech representation learning method. The key ideas are:- Incorporating vector quantization (VQ) layers into Autoregressive Predictive Coding (APC) to impose a bottleneck that forces the model to learn more meaningful representations.- Studying a sequence of VQ-APC models with decreasing codebook sizes to reveal the constituents of the learned representations and the model's preference in retaining information.- Using probing tasks and mutual information estimates to show evidence for the presence and absence of phonetic and speaker information in the representations. - Demonstrating that the learned VQ codes correspond well with English phones when phonetic information is present.- Showing VQ-APC outperforms other self-supervised models and raw features on phonetic and speaker classification tasks.In summary, the main contribution is proposing VQ-APC to better understand self-supervised speech representation learning through explicitly controlling the model capacity. The approach reveals constituents of the learned representations and connections to the self-supervised objective.
