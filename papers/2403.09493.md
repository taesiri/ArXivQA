# [Anomaly Detection by Adapting a pre-trained Vision Language Model](https://arxiv.org/abs/2403.09493)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Anomaly detection is an important but challenging computer vision task with many industrial applications. Most existing methods follow a one-model-one-class paradigm which trains one model per image category, making it resource intensive. Recently proposed unified anomaly detection aims to train a single model on multiple categories, but faces challenges in learning a joint representation across diverse image categories.  

- Directly applying large vision-language models like CLIP also has limitations - there is a domain gap from natural images used in pre-training, and CLIP produces image-level representations less suited for precise anomaly localization.

Method - CLIP-ADA:
- Proposes a unified anomaly detection framework that adapts CLIP by using learnable text prompts and a coarse-to-fine localization strategy. 

- Introduces learnable text prompts inserted into the text template input to CLIP. The prompts are optimized using a self-supervised objective to align with anomaly regions across categories. This allows learning a unified representation for anomaly detection.

- Further refines localization using a coarse-to-fine strategy. The initial similarity map between image and text features is used as attention to focus the model on anomalous regions. This improves discrimination of anomalies from normal regions.

Main Contributions:
- Achieves new state-of-the-art performance on MVTec-AD and VisA datasets for unified anomaly detection and localization across categories.

- Shows improved generalization with marginal training data compared to previous methods.

- Provides a simple and effective way to adapt large vision-language models like CLIP to industrial anomaly detection by using learnable prompts and refinement strategy.
