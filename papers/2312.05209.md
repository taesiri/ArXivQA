# [HALO: An Ontology for Representing Hallucinations in Generative Models](https://arxiv.org/abs/2312.05209)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality one-paragraph summary of the key points from the paper:

This paper proposes HALO, an extensible ontology for formally representing and analyzing different types of hallucinations commonly observed in large language models (LLMs) and other generative AI systems. HALO is organized into two main modules - a Hallucination module that defines categories and subcategories of hallucinations, and a Metadata module that captures experimental data and provenance. Six hallucination types across two broad categories - factuality and faithfulness - are currently supported. The authors follow established guidelines and principles in developing HALO to ensure extensibility, interoperability and documentation quality. They evaluate HALO on a real-world dataset of LLM hallucinations gathered from diverse Web sources, defining competency questions that showcase HALO's ability to represent metadata and support analytical queries around comparing hallucination rates across models. Future avenues include expanding HALO's categories as more hallucination phenomena are discovered through advances in LLMs and generative AI.
