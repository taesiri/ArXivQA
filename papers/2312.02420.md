# [Towards Granularity-adjusted Pixel-level Semantic Annotation](https://arxiv.org/abs/2312.02420)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes GranSAM, a novel framework for automated pixel-level semantic annotation without requiring manual supervision. GranSAM builds on the Segment Anything Model (SAM) by enhancing it with semantic recognition capabilities using synthetic or web-crawled images. Specifically, a classifier head is trained on top of SAM's mask decoder using multiple instance learning, enabling SAM to recognize masks at a user-defined granularity level. At inference, SAM generates mask embeddings which are passed through the classifier to predict semantic labels for each mask. Compared to unsupervised methods reliant on in-distribution unlabeled data, GranSAM demonstrates superior performance when evaluated on PASCAL VOC and COCO datasets despite using out-of-distribution synthetic or web-crawled images for training. The incorporation of uncertainty distillation further improves results by enhancing the model's ability to handle uncertainties. Overall, GranSAM provides an automated annotation system that generates pixel-level semantic masks for user-specified categories without manual supervision, optimizing the segmentation process with a user-centric approach focused on desired object granularity.
