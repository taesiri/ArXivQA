# [Towards Granularity-adjusted Pixel-level Semantic Annotation](https://arxiv.org/abs/2312.02420)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Pixel-level semantic segmentation annotation is labor intensive and expensive. 
- Existing methods require large unlabeled datasets from the same distribution as the test set for unsupervised training.
- Goal is to develop a system that can automatically generate pixel-level semantic masks for user-defined categories without any manual supervision.

Proposed Solution:
- Propose GranSAM, which enhances Segment Anything Model (SAM) with semantic recognition capability using synthetic or web crawled images. 
- Collect single-object images for each user-defined category using Stable Diffusion or web crawling. 
- Train a classifier head on SAM's mask embeddings using these images in a multiple instance learning setup.
- Classifier maps SAM's mask embeddings to semantic labels to recognize regions.

Key Contributions:
- Propose first annotation framework that provides pixel-level semantic masks without any manual supervision.
- Introduce novel strategy to enable SAM with granularity-adjusted mask recognition using synthetic/web images.
- Achieve superior performance compared to unsupervised methods trained on synthetic/web images.  
- Eliminate need for in-distribution unlabeled data unlike other unsupervised techniques.
- User-centric approach focuses masks on user-defined categories rather than all categories.
- Robust to distribution shifts owing to SAM's domain agnostic embeddings.
- Enhances model's uncertainty handling capability using uncertainty distillation.

In summary, GranSAM automates semantic segmentation annotation by leveraging SAM and synthetic/web images to provide targeted pixel-level masks without manual supervision for user-defined categories. It demonstrates improved adaptation across distributions.
