# [GRAM-HD: 3D-Consistent Image Generation at High Resolution with   Generative Radiance Manifolds](https://arxiv.org/abs/2206.07255)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we generate high-resolution, 3D-consistent images using generative adversarial networks (GANs) trained on unstructured 2D image collections? Specifically, the paper aims to address the limitation of previous 3D-aware GAN methods that cannot generate high-resolution images (e.g. 1024x1024) with strong 3D consistency when varying the viewpoint. This is due to either the high computational cost of volumetric rendering with neural radiance fields, or the use of 2D CNNs for image upsampling which breaks 3D consistency. To tackle this problem, the paper proposes a novel GAN approach called GRAM-HD that can achieve high-resolution, multiview consistent image generation. The key ideas are:1) Leverage the generative radiance manifold (GRAM) representation to define a set of surface manifolds for efficient 3D scene representation and rendering. 2) Apply 2D convolutions to upsample the radiance and features on these manifolds to super-resolve them while retaining 3D consistency.3) Use dedicated adversarial and consistency losses to enable effective GAN training at high resolution.In summary, the central hypothesis is that by combining the GRAM representation with 2D super-resolution of radiance manifolds, the proposed GRAM-HD approach can achieve the new capability of high-resolution, 3D-consistent generative modeling from unstructured image collections. The experiments aim to demonstrate this capability and compare to previous state-of-the-art methods.
