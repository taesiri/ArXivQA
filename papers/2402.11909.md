# [One2Avatar: Generative Implicit Head Avatar For Few-shot User Adaptation](https://arxiv.org/abs/2402.11909)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Creating high-quality, personalized 3D head avatars typically requires capturing extensive videos of a subject performing various expressions. This is cumbersome and hinders scalability. The goal is to create photo-realistic avatars from sparse inputs (e.g. just a few images).

Solution:
1) Capture a multi-view, multi-expression dataset of 2407 subjects with 13 expressions captured from 13 viewpoints each. 

2) Propose a generative model to learn an avatar prior from this data. The model uses a 3DMM-anchored neural radiance field to represent identity and expression features attached to mesh vertices. It is trained via auto-decoding to reconstruct input images.

3) For few-shot adaptation to a new subject, jointly optimize the target identity latent code, expression parameters, camera poses and model weights to fit the given input images.

Main Contributions:
- Show that a reasonable avatar prior can be learned from a dataset with balanced identity, camera and expression diversity. Extensive variation is essential unlike single-view datasets.

- Demonstrate that the proposed 3DMM-anchored neural radiance field backbone is more effective than tri-planar methods for avatar creation via auto-decoding.

- Propose joint optimization of parametric face model fitting during few-shot adaptation to stabilize avatar creation.

- Achieve state-of-the-art few shot avatar creation results, especially for very sparse inputs (e.g. one image).
