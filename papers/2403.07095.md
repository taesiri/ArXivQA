# [Overcoming the Paradox of Certified Training with Gaussian Smoothing](https://arxiv.org/abs/2403.07095)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Training neural networks to be certifiably robust against adversarial examples while maintaining high standard accuracy remains an open challenge. 
- Prior work showed that tighter convex relaxations, which compute more precise bounds on the worst-case loss, paradoxically perform worse in training than looser relaxations. This is because tighter relaxations induce loss surfaces that are discontinuous and highly sensitive to perturbations.

Proposed Solution: 
- The paper theoretically shows that Gaussian Loss Smoothing, where the loss is convolved with a Gaussian kernel, can alleviate both the discontinuity and perturbation sensitivity issues of tighter relaxations. This induces continuity and infinite differentiability.
- The paper proposes a novel certified training method combining Policy Gradients with Parameter-based Exploration (PGPE), which recovers Gaussian Loss Smoothing in expectation, with different convex relaxations.

Key Results:
- Empirically evaluating PGPE training shows that, unlike standard training, tighter bounds now lead to better networks - thereby confirming PGPE helps overcome issues with discontinuity and sensitivity.
- Combining PGPE with the DeepPoly relaxation outperforms state-of-the-art methods on the same networks by leveraging tight bounds while ensuring continuity via smoothing.
- While computationally expensive currently, results clearly demonstrate promise of Gaussian Loss Smoothing for certified training to overcome accuracy-robustness tradeoff.

Main Contributions:
- Theoretical analysis showing Gaussian Loss Smoothing addresses discontinuity and sensitivity of tight relaxations.
- Novel PGPE-based certified training method achieving DeepPoly tightness while ensuring continuity.  
- Large-scale evaluation confirming importance of continuity and sensitivity, and demonstrating potential of loss smoothing approaches.
