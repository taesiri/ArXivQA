# [Introducing Language Guidance in Prompt-based Continual Learning](https://arxiv.org/abs/2308.15827)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: How can language guidance be introduced into prompt-based continual learning methods to improve performance and mitigate catastrophic forgetting? The key hypothesis seems to be:- Although the visual data distributions change between continual learning tasks, the label space can be mapped to a common language space.  - By introducing language guidance into prompt-based continual learning methods at both the task level and class level, the model can learn to map features to this common semantic language space.- This will allow the model to better share knowledge across tasks and mitigate catastrophic forgetting, thus improving overall performance in a continual learning setting without needing additional model parameters or memory.In summary, the central hypothesis is that introducing language guidance into prompt-based continual learning can help the model generalize better across tasks by mapping representations to a common semantic space, thereby improving performance while reducing catastrophic forgetting. The paper aims to demonstrate this through the proposed LGCL method.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. The paper proposes a new method called Language Guidance for Prompt-based Continual Learning (LGCL) for mitigating catastrophic forgetting in continual learning. 2. LGCL introduces language guidance at two levels:- At the task level, it aligns the keys of the prompt pool with a language representation of the task using a cosine triplet loss. This helps select better prompts for each image.- At the class level, it aligns the output features of the visual encoder with a language representation of the ground truth class using a cosine triplet loss. This helps map features to a shared semantic space. 3. LGCL is model agnostic and can work with any prompt-based continual learning method as a plug-in. The paper shows consistent improvements when applying LGCL to recent prompt-based methods L2P and DualPrompt.4. LGCL achieves state-of-the-art results on two benchmarks - Split CIFAR-100 and Split ImageNet-R - for class incremental continual learning, without needing any additional learnable parameters.5. The paper provides a novel perspective of exploiting language guidance in continual learning to mitigate catastrophic forgetting.In summary, the key contribution is a new technique LGCL to introduce language guidance into prompt-based continual learning methods, which consistently improves performance across models and datasets. The method is simple, model-agnostic and achieves state-of-the-art results.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on my understanding, here is a one sentence summary of the key points from the paper:The paper proposes a method called Language Guidance for Prompt-based Continual Learning (LGCL) which introduces language knowledge at both the task and class levels into prompt-based continual learning approaches to help mitigate catastrophic forgetting, leading to improved performance without requiring additional parameters or memory overhead.


## How does this paper compare to other research in the same field?

Here are a few key points on how this paper compares to other research in the field of continual learning:- It focuses on prompt-based continual learning methods, which is a relatively new direction of research. The two main methods it builds on and compares to are L2P and Dual Prompt, which were published in 2021-2022. So this is quite cutting-edge.- The core idea of using language guidance to improve continual learning is novel. I'm not aware of other works that have proposed integrating language supervision into prompt-based continual learning before. - The experiments use standard continual learning benchmarks (Split CIFAR-100 and Split ImageNet-R) and metrics, making the results directly comparable to a lot of prior work. The consistent improvements over strong baselines demonstrate the effectiveness of the proposed approach.- It sets new state-of-the-art results on these benchmarks by improving upon the previous best prompt-based methods L2P and Dual Prompt. This shows it is pushing the boundaries of what's possible in prompt-based continual learning.- The method requires no additional parameters or memory overhead compared to baseline methods. This makes it very practical and scalable.- It's model-agnostic and can work with different text encoders, showing the broad applicability of the language guidance concept.Overall, this paper makes both conceptual and practical contributions to the field. The idea of using language to guide continual learning is novel, principled and supported by intuitive arguments and ablations. At the same time, the method achieves impressive empirical results, outperforming prior state-of-the-art approaches. The comparisons and experiments are rigorous and set a new benchmark for prompt-based continual learning methods.
