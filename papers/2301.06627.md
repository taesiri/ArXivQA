# Dissociating language and thought in large language models: a cognitive   perspective

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How do contemporary large language models (LLMs) compare to humans in terms of formal linguistic competence versus functional linguistic competence? The key concepts in this research question are:- Formal linguistic competence: Knowledge of the rules and statistical patterns that characterize a language (syntax, morphology, phonology, etc.)- Functional linguistic competence: The ability to use language in context, which depends on non-linguistic cognitive capacities like reasoning, social cognition, world knowledge, etc. - Large language models (LLMs): AI systems trained on massive text corpora to predict upcoming words, like BERT, GPT-3, etc.The main hypothesis appears to be that while LLMs have made impressive progress at acquiring formal linguistic competence, they still lack human-like functional linguistic competence. The authors evaluate this hypothesis by reviewing evidence on:- The formal vs functional linguistic capacities of humans, based on cognitive science and neuroscience research- The successes of LLMs at capturing many complex linguistic phenomena, arguing they are good models of human language processing- The limitations of LLMs when it comes to reasoning, world knowledge, pragmatic language use, and other markers of functional competenceThe overall goal seems to be to clarify where contemporary LLMs succeed and fail as cognitive models of language, and outline paths forward for developing models that can use language in more complete, human-like ways. Let me know if you need any clarification on the key research question or hypothesis!


## What is the main contribution of this paper?

This paper makes a key distinction between formal linguistic competence and functional linguistic competence. The main contributions are:1. Formal linguistic competence refers to knowledge of the rules and statistical patterns that characterize a language. Functional linguistic competence refers to the cognitive abilities needed to use language in real-world situations, which draw on non-linguistic capacities like reasoning, world knowledge, situation modeling, and social cognition. 2. Evidence from cognitive science and neuroscience shows that language relies on distinct mechanisms from the rest of cognition in the human brain. This motivates functionally separating language skills from broader reasoning skills when evaluating models.3. Contemporary large language models (LLMs) like GPT-3 have made impressive progress at acquiring formal linguistic competence. They capture complex linguistic phenomena like long-distance dependencies and abstraction. 4. However, LLMs still fail at many tasks requiring functional competence. They struggle with mathematical reasoning, lack flexible world knowledge, cannot model evolving situations, and lack pragmatic inferential abilities.5. The authors argue that progress in language AI requires combining language models with additional components specialized for reasoning, planning, etc. The brain's modularity provides a guide. Separate benchmarks for formal and functional competence are also needed.In summary, the key distinction is between language-specific skills (formal competence) and general cognitive skills needed for using language (functional competence). LLMs succeed at the former but not the latter. Advancing language AI requires integrating language modules with broader reasoning modules, guided by the brain's modularity.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper: The paper argues that while large language models like GPT-3 have made impressive progress in acquiring formal linguistic competence (knowledge of rules and patterns), they still lack functional linguistic competence (the ability to use language appropriately in context), which requires non-linguistic cognitive skills like reasoning and common sense.


## How does this paper compare to other research in the same field?

This paper makes a useful distinction between formal linguistic competence and functional linguistic competence in large language models. Some key aspects of how it relates to other work:- It builds on prior work distinguishing language abilities from general reasoning abilities in humans and AI systems. The concepts of formal vs functional competence are similar to the competence vs performance distinction from linguistics, and the distinction between language-specific vs domain-general cognitive abilities in cognitive science. - The paper reviews evidence that large language models have made impressive progress on acquiring formal linguistic competence (syntax, morphology, etc), but have major limitations when it comes to functional competence (reasoning, world knowledge, pragmatics). This aligns with much recent AI research showing strengths and limitations of large LMs.- The proposal that future progress requires combining language models with specialized reasoning modules connects to other work on modular and multi-task AI architectures. The idea of architectural vs emergent modularity also relates to debates around end-to-end vs modular AI systems.- The argument that models should be evaluated separately on linguistic vs more general tasks echoes proposals for standardized benchmarks that test specific abilities, rather than relying on superficial impression of coherence.Overall, this paper synthesizes and extends various ideas that have been emerging about the capabilities and limitations of large neural network models for language tasks. The formal vs functional competence framing provides a useful lens for interpreting the progress and challenges faced by this line of AI research.


## What future research directions do the authors suggest?

The authors suggest several future research directions:1. Developing modular architectures for language models that separate a core language system from components supporting other cognitive processes like reasoning and social cognition. This modularity could be architectural (explicitly building in separate modules) or emergent (arising naturally during training). 2. Using curated training data and multiple training objectives beyond next-word prediction in order to develop functional linguistic competence. For example, models could be trained on math and logic corpora to acquire reasoning abilities. 3. Creating separate benchmarks for evaluating models on formal linguistic competence (knowledge of rules and patterns) versus functional competence (real-world language use). This would allow clearer assessment of models' language abilities separately from their reasoning abilities.4. Exploring whether key aspects of language can be learned from more realistic/smaller datasets, which may require developing architectures and training procedures that are better aligned with human learning.5. Building models that integrate language with other capacities like perceiving, reasoning, and planning, moving beyond a "one-size-fits-all" model trained only to predict words. A modular, multifaceted model would be better aligned with the human mind.In summary, the authors advocate for more targeted, modular approaches tailored to acquiring both language-specific and general cognitive skills, evaluated separately, as a promising path towards more humanlike language models and artificial general intelligence.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:This paper argues that large language models (LLMs) like GPT-3 have made impressive progress in acquiring formal linguistic competence - the ability to understand and generate well-formed sentences by learning the rules and statistical patterns of language. However, LLMs still lack functional linguistic competence, which requires integrating language with other cognitive skills like reasoning, world knowledge, and social cognition. The authors ground this distinction between formal and functional competence in evidence from neuroscience showing that language relies on a selective brain system separate from domains like logic and social reasoning. They review evidence that contemporary LLMs succeed at tests of syntactic knowledge but fail at commonsense reasoning and tracking entities across long texts. The authors conclude that while LLMs are promising models of core language skills, developing artificial general intelligence will require combining language models with components for diverse aspects of thinking, or training models with more varied data and objectives to develop well-rounded cognitive abilities. Overall, the paper clarifies the debate around LLMs by separating their linguistic strengths from non-linguistic weaknesses.
