# [Space-Time Correspondence as a Contrastive Random Walk](https://arxiv.org/abs/2006.14613)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is how to learn visual representations for establishing temporal correspondence in videos in a self-supervised manner, without requiring manually annotated ground truth data. Specifically, the paper proposes a method to learn features such that temporal correspondences are represented by strong connections in a space-time graph constructed from the video. The nodes in this graph are image patches sampled from each frame, and edges represent affinities between patches in adjacent frames based on feature similarity. The main idea is to learn the feature representation by training the model to perform random walks on this graph that follow paths of high visual similarity, using only the raw video data itself as supervision.The key hypotheses are:- Temporal correspondence in video can be modeled as path finding on a space-time similarity graph, where transition probabilities of a random walk depend on learned feature similarity.- The feature representation can be learned in a self-supervised manner by using cycle consistency, where the objective is for walks on a "palindrome" sequence to return to their starting node. This provides implicit supervision for intermediate correspondences along the walk.- Modeling correspondence as a soft attention random walk allows considering many possible paths to handle ambiguity, and provides a dense learning signal from all patches in the video.In summary, the main research question is self-supervised learning of representations for temporal correspondence, which is addressed through the idea of modeling video as a graph and supervising representation learning through consistency of random walks.
