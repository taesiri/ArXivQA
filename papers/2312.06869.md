# [Adversarial Estimation of Topological Dimension with Harmonic Score Maps](https://arxiv.org/abs/2312.06869)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing methods for estimating the intrinsic dimension (number of degrees of freedom) of data have limitations such as reliance on careful hyperparameter tuning, poor scalability to high dimensions, and lack of robustness to noise. 
- Score based models (SBMs) are powerful deep generative models but can be sensitive to small input perturbations (adversarial examples) and lack interpretability.

Proposed Solution:
- The paper proposes enhancing SBMs by encouraging the "local averaging property" of score functions, meaning the score at a point should match the average score in its neighborhood. This is achieved by regularizing the model with Dirichlet energy.
- It is shown theoretically and empirically that this regularization adds variance specifically along directions normal to the learned manifold, allowing the use of adversarial attacks to measure the dimension of the variance learned normal to the manifold. This provides an estimate of the topological dimension captured by the SBM.

Main Contributions:
- Establishes connection between Dirichlet energy regularization of SBMs and increasing robustness to adversarial examples by smoothing likelihood surface
- Proves Dirichlet energy regularization leads specifically to extra variance learned normal to the manifold direction
- Introduces new method to estimate topological dimension by using adversarial attacks to probe variance learned normal to manifold
- Achieves state-of-the-art topological dimension estimates, especially on higher-dim and noisy data

In summary, the paper enhances deep generative models using Dirichlet energy regularization, which provides adversarial robustness and a way to interpretably estimate topological dimension based on the learned manifold geometry. This represents an advance in enhancing model robustness and interpretability.


## Summarize the paper in one sentence.

 This paper proposes a novel method to estimate the topological dimension of data by using adversarial attacks to probe the additional variance learned normal to the data manifold when training score-based generative models with Dirichlet energy regularization.


## What is the main contribution of this paper?

 The main contribution of this paper is a novel method to estimate the topological dimension (local intrinsic dimension) of data using adversarial attacks on score-based models. Specifically:

1) The paper shows that adding Dirichlet energy regularization to the training objective of score-based models corresponds to increasing the learned variance in the normal (off-manifold) direction. 

2) Leveraging this insight, the paper proves that the level of Dirichlet energy regularization is directly related to the additional off-manifold variance learned by the model. 

3) Based on this relationship, the paper introduces an algorithm to estimate the topological dimension by using adversarial attacks to measure the learned off-manifold variance, and then inferring the dimension from the strength of regularization and the attack budget.

4) Experiments demonstrate that this approach can accurately estimate the topological dimension on various synthetic datasets, being competitive or superior to statistical methods, especially on higher-dimensional and noisy data.

In summary, the key innovation is connecting robustness of score-based models to the geometry they capture, and thereby developing a way to reveal the topological dimension of data by analyzing adversarial attacks on regularized score-based models.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it include:

- Topological dimension estimation
- Local intrinsic dimension estimation 
- Score based models
- Denoising score matching
- Dirichlet energy regularization
- Manifold learning
- Adversarial robustness
- Additive variance property
- Langevin dynamics
- Harmonic maps
- Minimal surfaces

The paper introduces a novel method to estimate the topological dimension (local intrinsic dimension) of data based on regularizing score based models with Dirichlet energy and then using adversarial attacks to probe the learned manifold structure. Key ideas include connecting score based models to Langevin dynamics, using Dirichlet energy to encourage harmonic/minimal surface properties of score maps, deriving the additive variance property to relate regularization strength to learned noise variance, and leveraging adversarial attacks to estimate dimensions. The goal is to simultaneously improve adversarial robustness of score models while also enabling topological dimension estimation.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper argues that promoting a locally-averaging property for the score map can enhance robustness to adversarial attacks. Could you expand more on the intuition behind why enforcing local averaging reduces the potential for log-likelihood adversaries?

2. Theorem 1 relates the level of Dirichlet energy regularization to the amount of additional off-manifold variance learned. Could you walk through the key steps in the proof of this result? What are the key assumptions that enable you to make this connection?

3. The method estimates topological dimension by leveraging adversarial attacks to measure the off-manifold variance learned. However, the estimate relies on knowing the noise variance and Dirichlet energy regularization strength. In practice, how would you determine suitable values for these hyperparameters? 

4. Algorithm 1 outlines the overall approach for estimating topological dimension using adversarial attacks. What are some limitations or potential failure modes of this algorithm? When would you expect it to work well or poorly?

5. The experiments demonstrate improved robustness to adversarial attacks from Dirichlet energy regularization. However, clean likelihood generally degrades. Is there a principled way to balance likelihood on clean data vs robustness?

6. Figure 2 visualizes the additive variance property in practice. What explains the variability in KL divergence across trials for the same noise level? How might this impact topological dimension estimates?

7. For the experiments on real datasets, what determines the choice of attacked point and attack budget when generating adversarial samples? What impact could this choice have on the topological dimension estimates?  

8. How does the proposed method compare to other techniques like local PCA that could estimate topological dimension from model activations near a point? What are relative advantages and disadvantages?

9. The method relies on accurate estimation of the Dirichlet energy via Jacobian power iteration. How many iterations are needed for good estimates? What factors influence the approximation error?

10. The method was evaluated primarily on low-dimensional toy datasets. What challenges do you foresee in scaling the approach to estimate intrinsic dimension of complex, high-dimensional datasets like ImageNet?
