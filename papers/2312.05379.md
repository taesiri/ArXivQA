# [Exploring Parity Challenges in Reinforcement Learning through Curriculum   Learning with Noisy Labels](https://arxiv.org/abs/2312.05379)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Determining parity is essential for evaluating positions and finding optimal moves in impartial games like Nim. However, modeling parity functions with neural networks faces challenges, especially on long bitstrings sampled uniformly. 

- In reinforcement learning, noisy/incorrect labels can impede learning, an issue that likely applies to the self-play training process used in AlphaZero-style algorithms.

Methods & Contributions:  
- The paper investigates neural networks' ability to learn parity under two scenarios meant to simulate self-play training:
  1) Learning from a latent curriculum, where easier sparse bitstrings help prime learning on longer dense bitstrings
  2) Adding noisy labels proportional to 1 minus the model's accuracy, emulating noise from an initially weak model

- Key findings:
  - On latent curriculum data, failures increased with longer bitstrings, as did training time variability
  - With over 5% label noise, a neural net struggled to learn parity on length 100 bitstrings, versus immunity to 45% noise on length 20 strings
  - Even with a latent curriculum, small amounts of noise hampered parity learning on long bitstrings

- This indicates noisy labels could impede impartial game-playing agents' strategy learning in AlphaZero-style self-play training, particularly on larger game positions.

Implications:
- Strategies are needed to counter noisy label issues in self-play reinforcement learning for impartial games and more broadly. The paper lays groundwork for studying this challenge and demonstrates it poses an obstacle to parity function learning in neural networks.
