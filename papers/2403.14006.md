# [On Prompt Sensitivity of ChatGPT in Affective Computing](https://arxiv.org/abs/2403.14006)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Prompt engineering has become important with the rise of large language models (LLMs) like GPT-3, where prompting is crucial to accessing their capabilities. However, the field is still rapidly evolving and many prompting techniques require further analysis. 

- There is a need for methods to evaluate the sensitivity of LLM performance to different prompts and text generation parameters. 

Method:
- The authors introduce a method to evaluate prompting sensitivity in LLMs, demonstrated on ChatGPT for 3 affective computing tasks: sentiment analysis, toxicity detection, sarcasm detection.

- They conduct sensitivity analysis on the temperature parameter T and nucleus sampling's top-p parameter, which control conservativeness of text generation.

- They test various prompting ideas: specifying expertise, incentives, step-by-step thinking prompts, and "magic sentences". 

- The analysis focuses on model accuracy on the tasks as well as how helpful prompts are in yielding easy-to-parse responses.

Key Contributions:

- Finding lower T ≤ 0.3 and top-p ≤ 0.7 yield most stable performance, while higher values degrade performance.

- Straightforward prompts and expertise specification prompts generally achieve best performance. Chain-of-thought prompts excel sometimes but fail other times.

- Tested "magic sentences" like "take a deep breath" do not improve performance. Irrelevant expertise or misaligned incentives severely harm performance.  

- Detailed output formats significantly facilitate easy parsing of responses.

- Demonstrate LLM sensitivity and prompt engineering's crucial role in extracting capabilities from models like ChatGPT.
