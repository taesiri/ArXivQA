# [Emotional Speech-driven 3D Body Animation via Disentangled Latent   Diffusion](https://arxiv.org/abs/2312.04466)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the paper:

This paper presents AMUSE, a novel framework for generating emotional 3D body gestures directly from speech input. The key insight is that content (words spoken), emotion expressed, and personal style are separable factors in speech that impact the generated motions. To enable control over these, AMUSE incorporates a speech disentanglement model to map the input audio to three disentangled latent code vectors representing content, emotion, and style. These vectors then condition a temporal latent diffusion model that is trained to generate realistic and smooth motions. Once trained, AMUSE synthesizes gestures from speech and allows editing of emotion by combining the content latent from one speech clip with emotion and style latents from another. Experiments demonstrate AMUSE generates motions better aligned to the speech rhythms and more appropriately expressing the emotions compared to previous state-of-the-art methods. Both quantitative metrics and human perceptual studies show the high quality of the results. The disentanglement also enables sampling the stochastic diffusion model to produce variation in motions with the same emotion. This represents an important advance in building virtual characters that can gesture realistically and emotionally when speaking.
