# [Scaling Clinical Trial Matching Using Large Language Models: A Case   Study in Oncology](https://arxiv.org/abs/2308.02180)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:How can large language models (LLMs) be applied to scale clinical trial matching, using oncology as a case study?More specifically, the key questions investigated in this paper appear to be:- Can LLMs structure elaborate eligibility criteria of clinical trials and extract complex matching logic (e.g. nested AND/OR/NOT)? - How do LLMs compare to prior strong baselines and expert systems for structuring trial eligibility criteria?- Can LLMs be applied to end-to-end clinical trial matching against patient records? What are the challenges and limitations?So in summary, the central hypothesis is that LLMs can be used to scale clinical trial matching by automating the structuring of eligibility criteria and matching against patient data. The paper explores this hypothesis through a case study in oncology, comparing LLMs like GPT-4 against other methods and evaluating their capabilities and limitations for real-world clinical trial matching.


## What is the main contribution of this paper?

 The main contribution of this paper is presenting the first systematic study on using large language models (LLMs) like GPT-3.5 and GPT-4 for scaling clinical trial matching, with a focus on oncology. Specifically, the key contributions are:- Demonstrating that out-of-the-box, GPT-4 can already structure elaborate eligibility criteria of clinical trials and extract complex matching logic involving disease histology and genomic biomarkers. This substantially outperforms prior strong baselines like Criteria2Query and biomedical entity extraction tools.- Conducting both intrinsic evaluation on trial structuring and end-to-end matching evaluation using expert-annotated test sets and legacy enrollment data. The results show GPT-4 is competitive even compared to an expert system developed with extensive domain-specific heuristics. - Exploring the application of GPT-4 for end-to-end clinical trial matching. While preliminary, the results illustrate the potential of harnessing general cognitive capabilities of LLMs.- Identifying key growth areas for LLMs in clinical trial matching, such as addressing context limitation and accuracy issues in extracting information from patient electronic medical records.Overall, the paper demonstrates the promise of LLMs in scaling clinical trial matching and provides a systematic study to motivate further research in this direction. The techniques may generalize to trial matching beyond oncology.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:The paper presents a case study on using large language models like GPT-4 for clinical trial matching in oncology, showing promising results but also revealing challenges like context limitations and accuracy issues in extracting information from patient records.


## How does this paper compare to other research in the same field?

 Here are a few key points comparing this paper to other research in clinical trial matching:- Focus on using large language models (LLMs): This paper provides the first systematic study on leveraging the capabilities of LLMs for clinical trial matching. Most prior work has focused on rule-based systems, supervised learning models, or end-to-end neural matching models. The use of LLMs is a novel direction.- Application to oncology trials: While some previous work has looked at clinical trial matching in general, this paper grounds the study in oncology trials specifically. Oncology trials tend to have more complex eligibility criteria, providing a good test case. - Real-world system evaluation: The authors evaluate the LLM approach not just intrinsically, but also in the context of a real-world clinical trial matching system currently in deployment. This provides more practical insight compared to only intrinsic evaluations.- Identifies key challenges: In addition to demonstrating promising results, the paper also highlights limitations of LLMs for this task and areas for improvement. Structuring complex patient data from EMRs is called out as a key challenge.- Provides generalizable insights: Despite the oncology focus, the authors outline insights and future directions that could generalize to LLMs for clinical trial matching in other therapeutic areas.In summary, while building on prior work, this paper provides novel contributions in its LLM-based approach, grounding in oncology trials, real-world system evaluations, identification of challenges, and generalizable insights. The results demonstrate the promise of LLMs in this application while also shedding light on limitations to guide future work.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some key future research directions the authors suggest include:- Enhancing LLMs to better handle the context limitation and accuracy issues, especially for extracting and structuring patient data from electronic medical records (EMRs). As the paper notes, a cancer patient may have hundreds of longitudinal notes with key information like tumor histology scattered across them, which can exceed the context size limits of even the largest LLMs like GPT-4. The authors suggest more research into prompt engineering and fine-tuning to help address this challenge.- Exploring different prompt formatting techniques and tuning to further improve the accuracy and recall of LLMs for clinical trial structuring and matching. The paper shows promising initial results but there is still substantial room for improvement.- Expanding the study to other disease areas beyond oncology to evaluate the generalizability of the LLM-based approach for clinical trial matching. The paper focuses on oncology as an initial case study.- Incorporating human-in-the-loop techniques to combine the strengths of LLMs and human experts for clinical trial matching. This could help address some of the accuracy limitations of LLMs.- Comparing different LLMs like GPT-3/4 vs BLOOM and exploring which architectural innovations are most impactful for clinical trial matching specifically.- Developing more sophisticated evaluation benchmarks and datasets to better analyze the end-to-end performance of LLMs on clinical trial matching.In summary, the key directions center on improving LLMs' capabilities for handling clinical text data and integrating human expertise, evaluating the approach across disease areas, and developing better evaluation protocols tailored for this application.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:This paper presents the first systematic study on using large language models (LLMs) like GPT-4 to scale clinical trial matching, with a focus on oncology. The authors ground their exploration in a real-world clinical trial matching system currently being tested at a large U.S. health network. Initial findings show that out-of-the-box, GPT-4 can already structure elaborate clinical trial eligibility criteria and extract complex logic for factors like disease histology and biomarkers. While still imperfect, GPT-4 substantially outperforms strong baselines like Criteria2Query and is competitive with an expert system requiring extensive manual effort. The study also reveals key challenges for LLMs in clinical trial matching, like context limitations and accuracy in extracting longitudinal patient data from electronic medical records. Overall, the paper demonstrates promising capabilities of LLMs for clinical trial matching but also growth areas to address for end-to-end solutions.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:This paper presents a systematic study on using large language models (LLMs) like GPT-4 for clinical trial matching in oncology. The authors ground their exploration in a real-world clinical trial matching system currently being tested at a large U.S. health network. They focus on using LLMs for structuring eligibility criteria of trials and matching against structured patient data. Initial results are promising - out of the box, GPT-4 can already handle complex eligibility criteria, extracting entities like disease histology and biomarkers as well as nested logic. It substantially outperforms prior strong baselines like Criteria2Query. The authors also conduct end-to-end matching evaluation using real enrollment data, where GPT-4 achieves decent recall. The study reveals key areas for improvement in applying LLMs for clinical trial matching, especially in handling patient data from longitudinal medical records. A cancer patient may have hundreds of notes with key info like biomarkers scattered across them, exceeding the context limit of current LLMs. The authors thus rely on structured patient data extracted by state-of-the-art systems. While not feasible yet for patient data, the capabilities demonstrated by LLMs on eligibility criteria structuring are promising. The general nature of LLMs also bodes well for expanding this approach across disease areas. Overall, the paper presents an encouraging first systematic study on harnessing LLMs to address the challenging problem of clinical trial matching.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:The paper presents a systematic study on scaling clinical trial matching using large language models (LLMs). The authors focus on oncology as a case study and ground their exploration in a real-world clinical trial matching system currently in test deployment at a large U.S. health network. For structuring clinical trial eligibility criteria, the authors apply cutting-edge LLMs like GPT-3.5 and GPT-4 using prompt engineering techniques and few-shot learning. They evaluate the LLMs' performance on extracting entities like disease histology and biomarkers as well as complete logic extraction using expert-annotated test sets. For end-to-end clinical trial matching evaluation, they apply the structured eligibility criteria from the LLMs along with structured patient data to simulate matching against historical enrollment data and user feedback data from the deployed system. The results demonstrate promising performance of LLMs compared to prior methods and expert systems, while also revealing growth areas like context limitations and accuracy issues in handling longitudinal patient records.


## What problem or question is the paper addressing?

 The paper appears to be addressing the problem of scaling clinical trial matching using large language models (LLMs). Specifically, it focuses on the challenges of structuring eligibility criteria from clinical trials and patient data from electronic medical records in order to determine patient-trial matches. The key questions seem to be:- Can LLMs help overcome limitations of prior methods for structuring clinical trial eligibility criteria and extracting complex logic?- How do LLMs compare to existing rule-based systems and prior methods on structuring trial criteria and end-to-end matching?- What are the limitations and growth areas for applying LLMs to clinical trial matching, especially in terms of handling the large amounts of unstructured patient data?Overall, the paper examines whether LLMs can provide a more scalable solution for clinical trial matching compared to prior approaches, using a case study grounded in a real-world system focused on oncology trials.
