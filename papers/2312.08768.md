# [Local Conditional Controlling for Text-to-Image Diffusion Models](https://arxiv.org/abs/2312.08768)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper introduces a new paradigm called local control for text-to-image synthesis using diffusion models. Local control allows users to specify image conditions to control the generation process in selective local regions of the image, while letting the rest of the image be guided solely by the text prompt. The key challenge is local control dominance, where concepts related to the local control overwhelm prompt concepts during generation. To address this, the authors propose a training-free method that uses object regeneration to enhance ignored objects in the cross-attention map, focused token response to reduce interference, and feature mask constraints to maintain image quality. Their method enables fine-grained and flexible control over specific areas of the generated image per user-defined conditions, while accurately reflecting the overall textual description. Extensive experiments demonstrate the approach's ability to produce high quality images that precisely align with both local image controls and global text prompts. The introduced local control paradigm and proposed resolution provide an effective and practical means for users to manipulate image generation at a granular level.
