# Learning to Break the Loop: Analyzing and Mitigating Repetitions for   Neural Text Generation

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: Why do neural language models with maximization-based decoding algorithms (e.g. greedy search) tend to get stuck generating consecutive sentence-level repetitions, which is counter to the patterns found in human text corpora?The authors investigate this through quantitative analysis of how the probabilities of repetitive tokens relate to the number of previous repetitions in the context. Their key findings are:1) Models tend to increase the probability of repeating the previous sentence, even with just one repetition in the context. 2) There is a "self-reinforcement effect" where probability of repetition increases monotonically as the number of historical repetitions grows.3) Sentences with higher initial probabilities tend to have a stronger self-reinforcement effect. Based on these analyses, the authors propose that models get stuck in repetitive loops due to the tendency to repeat previous high-probability sentences combined with the self-reinforcement effect. They then develop a training method called DITTO to mitigate repetition by penalizing repetition probabilities on artificially constructed repetitive data.So in summary, the central research question is understanding the underlying factors behind models' tendency for repetitive text generation, with the goal of developing methods to reduce repetition. The hypothesis is that analyzing and mitigating the self-reinforcement effect of repetitions will improve text generation quality.


## What is the main contribution of this paper?

Based on my reading, the key contributions of this paper are:1. The authors conducted quantitative analyses to investigate the underlying reasons why neural language models with maximization-based decoding (e.g. greedy search) tend to generate repetitive text, especially getting stuck in consecutive sentence-level repetitions. Their analyses reveal three key findings:- Models have a preference to repeat the previous sentence even with just one repetition in context. - Repetition demonstrates a self-reinforcement effect - the probability of repetition increases monotonically as the number of historical repetitions grows.- Sentences with higher initial probabilities tend to have a stronger self-reinforcement effect.2. Motivated by the analysis, the authors propose a simple and effective training method called DITTO. It constructs pseudo repetitive data by repeating sentences from the training set, and teaches the model to learn to penalize the probabilities of sentence-level repetitions from the pseudo data.3. Extensive experiments show DITTO not only reduces repetition issues without hurting perplexity, but also improves text generation quality measured by both automatic metrics and human evaluation. The method demonstrates effectiveness on both open-ended generation (Wikitext-103) and summarization (CNN/DailyMail).In summary, the key contribution is conducting in-depth quantitative analyses to uncover the root cause of text repetition issue, and proposing an effective training method to mitigate repetition and improve generation quality. The analyses and solutions provide useful insights on improving neural text generation.
