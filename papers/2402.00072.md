# [Explainable AI for survival analysis: a median-SHAP approach](https://arxiv.org/abs/2402.00072)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper focuses on explaining predictions from black-box survival analysis models. It argues that using standard Shapley values for explaining such models can be problematic because:

1) Taking the expectation as a summary statistic is not suitable when the distribution of model outcomes is skewed, which is common in survival analysis where some patients may not experience the event during the study period. 

2) Using the sample mean to estimate the expectation makes the explanations sensitive to outliers.

3) The "anchor point" induced by using the expectation and mean acts as a point of comparison for the instance being explained. But comparing to the global mean prediction lacks interpretability as it does not correspond to a real patient.

Solution - median-SHAP:
The paper proposes median-SHAP, a variant of Shapley values tailored for explaining survival models. Median-SHAP has three key features:

1) It uses the median instead of expectation as the summary statistic when averaging over coalitions. This makes it robust to skewed distributions.

2) It uses the median instead of mean for estimation. This makes it robust to outliers. 

3) By using the median, the "anchor point" becomes the median patient rather than the global mean. This enhances interpretability as explanations reference a real patient for comparison.

Contributions:
1) Identifying issues with using standard Shapley values for survival models - related to the choice of summary statistic, estimator and the resulting "anchor point". 

2) Proposing median-SHAP as a tailored method for explaining survival models by addressing the above issues.

3) Demonstrating experimentally that median-SHAP better captures feature importances related to predicting patient survival rankings compared to standard Shapley values.

So in summary, the key contribution is a specialized explainability method called median-SHAP that is designed specifically for explaining predictions from black-box survival analysis models.


## Summarize the paper in one sentence.

 This paper introduces median-SHAP, a method to explain black-box survival analysis models by using the median as the summary statistic and estimator in Shapley values to generate more robust and interpretable feature attributions compared to the original mean-based Shapley values.


## What is the main contribution of this paper?

 The main contribution of this paper is the introduction of median-SHAP, a new method for explaining black-box models that predict individual survival times. Specifically:

1) The paper analyzes issues with using standard Shapley values for explaining survival analysis models, relating to the use of the expectation as a summary statistic and mean estimator. This can result in misleading interpretations when comparing predictions to a "mean anchor point".

2) The paper proposes median-SHAP, which uses the median as the summary statistic and estimator instead. This compares predictions to a "median anchor point", which is an actual individual from the reference population rather than an artificial mean individual. 

3) Experiments demonstrate that median-SHAP better captures feature importances relating to how individuals rank compared to the cohort median, supporting its interpretability for survival analysis use cases.

In summary, the key contribution is the proposal and experimental validation of median-SHAP as an interpretable explanation method specifically tailored for survival analysis models.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key keywords and terms associated with this paper include:

- Interpretable ML
- Healthcare
- Explainable AI (XAI) 
- Shapley values
- Survival analysis
- Median-SHAP
- Feature attribution 
- Anchor point
- Summary statistic
- Estimator

The paper introduces a new method called "median-SHAP" for explaining black-box survival analysis models. Key ideas discussed include using the median as a summary statistic and estimator in Shapley values to generate more robust and interpretable feature attributions, as well as the concept of an "anchor point" that instances are compared against in generating the attributions. The method aims to provide better explanations for survival analysis models used in healthcare applications.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the median-SHAP method proposed in the paper:

1. The paper argues that the choice of summary statistic and estimator jointly define an "anchor point" that instances are compared against in Shapley value explanations. Can you further explain this concept of the anchor point and why the choice of anchor point impacts interpretability? 

2. When explaining survival analysis models, the authors argue that using the mean as an anchor point can be problematic since the distribution of survival times is often right-skewed. Can you walk through an example to demonstrate how a mean anchor point could lead to counterintuitive or misleading explanations in a survival analysis context?

3. Median-SHAP uses the median survival time prediction as its anchor point instead of the mean. Why is the median a more appropriate summary statistic and anchor point for explaining survival analysis model predictions? How does this enhance interpretability?

4. The paper experiments with both regression and classification models for survival analysis. Can you explain the purpose of the classification model experiment and how the results support the benefits of median-SHAP?

5. Observational SHAP is used as the basis for median-SHAP instead of interventional SHAP. What are the key differences between these two SHAP variants and why is observational SHAP better suited for the clinical application context that median-SHAP targets?

6. How exactly does median-SHAP modify the standard SHAP algorithm? Walk through the equation changes step-by-step. Why do the original SHAP axioms still hold?

7. The breast cancer survival dataset has a fairly small sample size. How could this impact the reliability of explanations if using the mean versus the median? Why is median-SHAP more robust in small sample settings?

8. What are some potential limitations or disadvantages to using median-SHAP instead of standard SHAP? Can you think of any model types or data contexts where a mean anchor point would still be preferred?

9. The method is tailored specifically to survival analysis as opposed to being a general solution for right-skewed data. What considerations went into this design choice? Could the ideas be generalized further?

10. Can you think of any other medical prediction tasks where the proposed ideas around revisiting summary statistics and anchor points could improve interpretability of explanations?
