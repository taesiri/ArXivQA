# [Model Pairing Using Embedding Translation for Backdoor Attack Detection   on Open-Set Classification Tasks](https://arxiv.org/abs/2402.18718)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Machine learning models are increasingly being deployed in critical applications, making them targets for adversaries to implement backdoors. Backdoors allow attackers to cause intentional mispredictions by presenting a specific trigger pattern at test time. Detecting backdoors is challenging, especially for open-set classification tasks like face recognition. Prior detection methods have limitations - they require clean data, clean models, whitebox access, make assumptions about the backdoor, or don't work for open-set problems.  

Solution:
This paper proposes a novel backdoor detection approach using model pairs. Two models are used jointly to compute an agreement score indicating if a sample activates a backdoor. This works by:

1) An embedding translator projects embeddings from one model (probe) into the other's space (reference) using an affine transformation. 

2) A similarity score is computed between the translated and reference embeddings to quantify agreement on the prediction. Disagreement indicates a backdoor.

The method makes no assumptions about backdoor presence, type or location. It works for open-set classification, with blackbox access, without clean data/models. The ensemble nature also raises the attack difficulty.

Contributions:
1) A new runtime detection method using model pairs without assuming either model is clean.

2) Extensive experiments with clean/backdoored models of different architectures/datasets in both roles. Promising detection results are shown.

3) A versatile approach compatible with open-set classification, all-to-one and one-to-one backdoors, blackbox access and little computation.

Limitations are that both models must run and the worst performing bounds detection. But better backdoors lead to better detection. The method alleviates single point of failure and challenges attackers.
