# [Open3DIS: Open-vocabulary 3D Instance Segmentation with 2D Mask Guidance](https://arxiv.org/abs/2312.10671)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
The paper addresses the challenging problem of open-vocabulary 3D point cloud instance segmentation (OV-3DIS). Given a 3D scene represented as a point cloud, the goal is to obtain binary instance masks for objects of any classes of interest, including those not present during training. This is important for applications like robotics and VR where the capability to identify and localize objects based on free-form textual queries is needed. However, existing methods either rely on 3D networks that struggle with small or geometrically ambiguous objects, or 2D networks whose projections do not fully capture 3D object shapes.

Proposed Solution:
The paper proposes a new method called \Approach that effectively combines proposals from both 3D point cloud networks and 2D image networks. The key idea is a "2D-guided 3D Proposal Module" that creates high-quality 3D proposals by hierarchically aggregating and merging geometrically consistent point cloud regions using 2D instance masks from multiple views. This complements the proposals from a 3D instance segmentation network, allowing the capture of small and uncommon objects. A pointwise feature extraction module is also introduced to relate 3D proposals to textual queries for classification.

Main Contributions:
1) A 2D-guided 3D proposal module to generate precise 3D proposals using aggregated 2D masks across views.
2) A novel pointwise feature extraction method to associate 3D proposals with text embeddings. 
3) State-of-the-art performance on ScanNet200, S3DIS and Replica datasets, outperforming prior arts by 50%, 80% and 40% respectively. Comparable results to supervised methods are also achieved.

The method demonstrates enhanced understanding and segmentation of diverse objects in 3D scenes based on free-form text queries.
