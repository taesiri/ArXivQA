# [On Robust Prefix-Tuning for Text Classification](https://arxiv.org/abs/2203.10378)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:Can we improve the robustness of prefix-tuning for text classification while preserving its efficiency and modularity, without modifying the pretrained model parameters?The authors motivate this question by discussing how prefix-tuning is a lightweight and modular approach for adapting large pretrained language models to downstream tasks. However, prefix-tuning still lacks robustness to adversarial text attacks. Many existing defense methods require modifying the pretrained model, which would go against the benefits of prefix-tuning. So the key question is whether it's possible to make prefix-tuning more robust to attacks like universal adversarial triggers, while still keeping its lightweight tuning of only the prefix parameters. The authors propose a method to add batch-level robust prefixes during inference to steer the model activations in a more robust way, without changing the underlying pretrained model.In summary, the central hypothesis is that you can achieve greater robustness for prefix-tuning without sacrificing its efficiency or modularity, if you properly tune robust prefixes to regulate the model's activations against adversarial inputs. The paper aims to demonstrate this via their proposed framework.


## What is the main contribution of this paper?

Based on my understanding, the main contribution of this paper is proposing a robust prefix-tuning framework for text classification that improves model robustness against textual adversarial attacks while preserving the efficiency and modularity of prefix-tuning. Specifically, the key ideas and contributions are:- The core idea is to leverage the layerwise activations of the language model triggered by correctly classified training data as the "standard", and tune an extra batch-level prefix during test time to minimize the distance between the activations triggered by test inputs and this standard.- The method constructs canonical manifolds using the activations of correctly classified training data, projects activations by test inputs onto these manifolds, and uses the projection distance as the loss to tune the extra test-time prefix. - This allows improving robustness against textual attacks like character/word perturbation and universal adversarial triggers, without modifying the pretrained language model or using auxiliary models like adversary detectors.- The proposed method preserves the lightweight and modular nature of prefix-tuning, since only a small amount of extra parameters (the test-time prefix) need to be tuned per batch.- The method is interpreted from an optimal control perspective, with prefix-tuning seen as open-loop control and the proposed robust tuning as closed-loop control for robustness.- Extensive experiments demonstrate improved robustness over strong baselines on multiple text classification benchmarks and against textual attacks of different types, while maintaining efficiency.In summary, the key contribution is a lightweight and modular way to improve robustness of prefix-tuning against textual attacks by leveraging activations of correct predictions as the standard to tune an extra prefix. This maintains the strengths of prefix-tuning while enhancing robustness.
