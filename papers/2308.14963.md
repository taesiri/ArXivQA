# [Vector Search with OpenAI Embeddings: Lucene Is All You Need](https://arxiv.org/abs/2308.14963)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is whether a dedicated vector store is necessary to support vector search capabilities using transformer-based embeddings, or if existing search infrastructure centered around Lucene is sufficient. The paper challenges the prevailing narrative that a vector store is a required new component in an enterprise "AI stack" to enable dense retrieval with embeddings. Instead, it argues that Lucene's existing capabilities for indexing and searching vectors are adequate, making a separate vector store hard to justify from a cost-benefit perspective.The hypothesis is that Lucene provides "good enough" vector search to leverage the benefits of transformer embeddings, without the downside of increased complexity from introducing a wholly new software component into an organization's existing search infrastructure.The paper aims to support this hypothesis through an experimental demonstration of using OpenAI's Ada embeddings with Lucene indexing and search on the MS MARCO passage ranking task. The results show that this combination achieves effectiveness comparable to other state-of-the-art techniques, supporting the claim that Lucene meets the vector search needs for deploying bi-encoder dense retrieval in practice.In summary, the central research question is whether an organization really needs a dedicated vector store for production readiness with neural embeddings, or if Lucene can provide the necessary vector search capabilities without major downsides. The hypothesis is the latter, which the paper attempts to demonstrate empirically.


## What is the main contribution of this paper?

The main contribution of this paper is to show that vector search using state-of-the-art OpenAI embeddings can be implemented directly in Lucene, without the need for a dedicated vector store. Specifically:- The authors index OpenAI's ada2 embeddings for the MS MARCO passage corpus directly in Lucene using HNSW indexes.- Experiments on MS MARCO and TREC DL benchmark datasets show that effectiveness is comparable to models that use dedicated vector stores like Faiss. - The implementation only relies on off-the-shelf components - OpenAI's embedding API for dense vectors and Lucene for indexing/search. No custom AI-specific code is needed.- This demonstrates that Lucene's capabilities are sufficient for vector search in a bi-encoder architecture, challenging the prevailing narrative that a dedicated vector store is required for state-of-the-art effectiveness.In summary, the paper argues that the additional complexity of introducing a new vector store into an enterprise architecture is hard to justify given Lucene's capabilities. The authors posit that Lucene is adequate for providing vector search in a cost-effective manner by building on existing infrastructure.
