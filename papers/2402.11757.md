# [Large Language Models for Stemming: Promises, Pitfalls and Failures](https://arxiv.org/abs/2402.11757)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Text stemming is commonly used in information retrieval (IR) pipelines to reduce words to their root forms and improve keyword matching between queries and documents. However, traditional stemming methods like Porter and Krovetz focus solely on individual terms without considering context, which can impact meaning and appropriate stemming.

Proposed Solution:  
- Investigate using large language models (LLMs) for text stemming to leverage their contextual understanding capabilities. Identify and evaluate 3 methods:
  1) Vocabulary Stemming (VS): Use LLM to stem vocabulary of all unique words in collection
  2) Contextual Stemming (CS): Use LLM to stem each document independently
  3) Entity-based Contextual Stemming (ECS): Use LLM to extract entities from each doc, stem non-entities with Porter, index both forms

Experiments:
- Compared VS, CS and ECS with ChatGPT, LLaMA-2 and SOLAR on 2 datasets against Porter and Krovetz stemmers
- Found VS fails to outperform Porter, and CS underperforms significantly and has high compute costs
- ECS with LLaMA-2 entity extraction and Porter stemming significantly outperforms Porter alone 

Main Contributions:
- First comprehensive study investigating use of LLMs for text stemming in IR pipelines
- Identified and evaluated 3 methods for LLM-based stemming 
- Demonstrated failures of VS and CS to outperform traditional stemmers
- Showed promise of ECS by combining LLM entity extraction with Porter stemming
