# [Orthogonal Annotation Benefits Barely-supervised Medical Image   Segmentation](https://arxiv.org/abs/2303.13090)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is:Can we develop a novel annotation method and semi-supervised model that effectively exploits the complementary information from different directions in 3D medical images to achieve efficient and accurate segmentation with minimal annotation effort?Specifically, the paper proposes and investigates:1) A new annotation method called "orthogonal annotation" that only labels two orthogonal slices in each 3D medical image volume. This aims to greatly reduce annotation effort while preserving disparity and complementary information.2) A coupled segmentation method named "Dense-Sparse Co-Training (DeSCO)" framework that utilizes the proposed orthogonal annotation. It first generates dense pseudo-labels through registration, then trains dual networks that leverage both dense pseudo-labels and sparse labels in a co-training manner. The goal is to steadily utilize the sparse orthogonal annotation and achieve performance close to fully-supervised methods.So in summary, the central hypothesis is that by utilizing the proposed orthogonal annotation method and DeSCO framework, it's possible to achieve highly efficient and accurate 3D medical image segmentation with minimal annotation effort. The experiments conducted in the paper aim to validate the effectiveness of the proposed techniques.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Proposing a novel annotation method called "orthogonal annotation" that only labels two orthogonal slices in a 3D medical image volume. This greatly reduces the annotation burden compared to labeling every slice.2. Developing a barely-supervised 3D medical image segmentation framework that can effectively utilize the proposed sparse orthogonal annotation. This includes:- Using registration to propagate the sparse labels to generate dense pseudo labels.- Proposing a Dense-Sparse Co-Training (DeSCO) framework with two networks that exploits dense pseudo labels first and then relies more on sparse labels, while using unlabeled volumes for cross-supervision.3. Demonstrating the effectiveness of the proposed orthogonal annotation and DeSCO framework through experiments on 3 public datasets. Using only 10 annotated slices, the method achieves comparable or better performance than semi-supervised methods using the full volumetric annotation. For example, on the KiTS19 dataset, the method reaches 86.93% Dice using 10 slices, compared to 84.98% for a semi-supervised approach using 320 fully labeled slices.In summary, the key contribution is developing an efficient annotation strategy and coupled segmentation framework to enable high-quality 3D medical image segmentation using only sparse annotation of two orthogonal slices per volume. This greatly reduces the annotation burden while still achieving strong performance.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper proposes a novel barely-supervised 3D medical image segmentation method that uses a highly efficient orthogonal annotation to label only two slices per volume coupled with a Dense-Sparse Co-training framework that leverages dense pseudo labels and sparse labels to effectively utilize both labeled and unlabeled data.


## How does this paper compare to other research in the same field?

Here are some thoughts on how this paper compares to other related research:- The focus on using orthogonal annotation and barely-supervised learning for 3D medical image segmentation is relatively novel. Most prior work has focused on semi-supervised or weakly-supervised methods that still require more complete labeling of the training data. The use of just two orthogonal labeled slices is an extreme form of sparse annotation that can greatly reduce labeling effort.- The idea of using registration to propagate labels from the sparse annotations to generate pseudo-labels for model training has been explored before, but combining it with a dense-to-sparse training approach in a dual-network co-training framework is new. The dense-to-sparse scheduling and emphasis on consensus via co-training helps address issues with noise in the pseudo-labels.- The dual-network co-training framework draws on ideas from prior semi-supervised learning methods, like Mean Teacher and co-training, but modifies them to work well with sparse orthogonal annotation and dense-to-sparse training. The modifications like uncertainty-guided cross-supervision are novel.- The experiments comprehensively compare with current state-of-the-art semi-supervised methods adapted for this sparse setting. The results demonstrate sizable improvements in accuracy over these methods when using just the sparse orthogonal annotation. This supports the effectiveness of the proposed approach.- The work does not require complex modeling or architectures. The methods primarily provide a novel annotation approach and training procedure to make extremely sparse annotation viable. This could make adoption more practical.- The sensitivity analysis provides useful insight into the impact of key hyper-parameters. Monitoring of accuracy over training iterations also gives valuable perspective into the model convergence behaviors.Overall, this paper introduces a unique annotation strategy and training framework tailored to learning effectively from sparse annotation. The comparisons and analysis provide evidence of its capabilities and benefits over existing approaches. The methods could help reduce annotation effort in 3D medical image analysis.
