# [ESTextSpotter: Towards Better Scene Text Spotting with Explicit Synergy   in Transformer](https://arxiv.org/abs/2308.10147)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to better realize the synergy between text detection and recognition in end-to-end scene text spotting. The key hypothesis is that modeling explicit interaction and distinct features between text detection and recognition within a unified framework can significantly improve text spotting performance.Specifically, the paper proposes:- Using task-aware queries to model discriminative features for detection and recognition instead of a shared query.- An explicit vision-language communication module to enable interaction between detection and recognition queries. - Task-aware query initialization and denoising training strategies to facilitate training.Through explicit modeling of distinct features and interactions, the paper hypothesizes this will lead to better synergy and performance compared to previous implicit parameter/feature sharing approaches. Experiments across several datasets aim to validate this hypothesis.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes ESTextSpotter, a new Transformer-based model for end-to-end text spotting that adopts task-aware queries within a single decoder to achieve explicit synergy between text detection and recognition. 2. It introduces a vision-language communication module to enhance the explicit interaction between detection and recognition queries from a cross-modal perspective. It also proposes a task-aware query initialization to ensure stable training.3. It achieves state-of-the-art results on multiple scene text spotting benchmarks, including multi-oriented, arbitrarily-shaped, and multilingual datasets. The performance improvements demonstrate the effectiveness of modeling explicit synergy compared to previous implicit synergy approaches.In summary, the key innovation is introducing explicit modeling of the synergy between detection and recognition in a unified Transformer framework, which significantly improves text spotting performance by mutually enhancing the two tasks. The proposed vision-language communication module and task-aware training strategies further boost the efficacy of explicit synergy.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a new transformer-based model for text spotting called ESTextSpotter that achieves better synergy between text detection and recognition by using task-aware queries to explicitly model discriminative and interactive features within a single decoder, and introduces a vision-language communication module to further enhance the interaction.
