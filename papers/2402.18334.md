# [Learning to Generate Instruction Tuning Datasets for Zero-Shot Task   Adaptation](https://arxiv.org/abs/2402.18334)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper introduces Bonito, an open-source model for conditional task generation. The goal is to enable zero-shot task adaptation of large language models to users' specialized, private data without requiring human annotations. 

The key idea is to train a model to automatically convert unannotated text from specialized domains into task-specific training datasets that can be used for instruction tuning. This is achieved by creating a large-scale dataset called CTGA (Conditional Task Generation with Attributes) by remixing existing instruction tuning datasets into meta-templates. 

The input to the model is unannotated text and a task attribute specifying the type of task (e.g. extractive QA). The output is a full instruction tuning example with an instruction referencing the input text and the desired response.

Experiments adapt pretrained and instruction-tuned LM variants (e.g. Mistral, Llama) to 7 target datasets across 3 task types. Results show Bonito outperforms a next word prediction baseline by 22.1 F1 points when adapting instruction-tuned models, demonstrating effectiveness of synthetic instruction data for domain adaptation.

Analyses study the impact of domain, training set size, and alternative synthetic task generators. Overall, the work introduces an open-source conditional task generation model to easily create instruction tuning datasets tailored to users' specialized domains and data.
