# [PDP: Parameter-free Differentiable Pruning is All You Need](https://arxiv.org/abs/2305.11203)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key points of this paper are:- The paper proposes a new network pruning algorithm called Parameter-free Differentiable Pruning (PDP). The goal is to achieve efficient and effective pruning without introducing extra trainable parameters or complicating the training process. - The core of PDP is generating soft pruning masks directly from the weights using a dynamic threshold parameter t. This allows pruning decisions to be differentiable while avoiding extra parameters for masks.- PDP is shown to achieve state-of-the-art results for random, structured, and channel pruning across vision and language tasks. For example, it improves accuracy over prior arts for MobileNetV1 and BERT while reducing computations.- The simplicity of PDP allows it to be readily applied to different pruning methods like structured pruning and channel pruning. This argues that extra parameters or complex techniques are not mandatory for high-quality pruning.- Overall, the key hypothesis seems to be that PDP's parameter-free mask generation can enable efficient yet accurate pruning across tasks and methods without extra parameters or training overhead. The results aim to demonstrate the effectiveness of this simple but novel pruning approach.In summary, the central focus is on introducing and evaluating the proposed PDP pruning algorithm for improved accuracy and efficiency.
