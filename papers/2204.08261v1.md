# [Visio-Linguistic Brain Encoding](https://arxiv.org/abs/2204.08261v1)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research questions and hypotheses addressed in this paper are:

1) How well can neural representations from deep neural networks predict brain activity patterns in response to visual stimuli? Specifically, how do different layers in convolutional neural networks (CNNs) correspond to levels of visual processing in the brain?

The hypotheses are:

- Intermediate layers in deep CNNs will correspond best to intermediate stages of visual processing in the brain. 

- Higher layers in CNNs will match better to higher stages of visual processing.

2) How do different CNN architectures compare in terms of predicting brain activity? 

The hypothesis is:

- More recent and deeper CNN architectures will not necessarily result in better prediction of brain activity patterns, despite improved performance on computer vision benchmarks.

3) How does a recurrent anatomical network called CORnet compare to CNNs in predicting brain activity?

The hypothesis is: 

- CORnet will provide better predictions of brain activity compared to CNNs, even though it has fewer layers.

4) Can tuning CNN representations to be more brain-like (through Brain-Score benchmark) improve predictions of brain activity?

The hypothesis is:

- CNN representations tuned to be more brain-like will better predict brain activity compared to the original CNN representations.

In summary, the key goals are to 1) Evaluate how well neural nets predict brain activity 2) Compare different architectures 3) Propose modifications to improve brain-likeness of representations. The overarching theme is understanding similarities and differences between artificial and biological vision systems.
