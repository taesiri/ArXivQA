# [Self-Supervised Point Cloud Completion via Inpainting](https://arxiv.org/abs/2111.10701)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research goals of this paper are:1. To develop a self-supervised method for point cloud completion that does not require complete point clouds for supervision. The paper aims to train a model using only partial point clouds.2. To propose an inpainting-based approach where regions are randomly removed from partial point clouds and the model learns to complete the entire cloud. This allows the model to be trained without ground truth completions. 3. To design a multi-scale architecture with global and local encoders/decoders that learns both global shape priors and specialized embeddings for completing local regions. This is aimed at improving generalization.4. To demonstrate state-of-the-art performance compared to previous unsupervised methods on standard point cloud completion benchmarks like ShapeNet and SemanticKITTI.In summary, the main research goals are developing a self-supervised point cloud completion method using only partial scans, leveraging ideas like inpainting and multi-scale processing, and showing improved performance over prior work. The key hypothesis is that the proposed inpainting approach and architecture can learn effective shape priors and completion without full supervision.


## What is the main contribution of this paper?

The main contribution of this paper is presenting a self-supervised method for point cloud completion that can be trained using only partial point clouds, without requiring complete ground truth shapes. The key ideas are:- Using an inpainting-based approach with random region removal to enable the network to complete full shapes in a self-supervised manner. - A multi-level encoder-decoder architecture that partitions the point cloud into local regions to learn specialized embeddings and also reasons globally. This allows combining local and global shape priors.- The inpainting approach makes the method robust to alignment errors in the estimated pose normalization, compared to prior work.- Experiments show the method outperforms prior unsupervised completion techniques on both synthetic (ShapeNet) and real (Semantic KITTI) datasets.In summary, the main contribution is developing a self-supervised point cloud completion method using ideas of inpainting and multi-level reasoning that achieves state-of-the-art results while only requiring partial point clouds during training. This could enable completion on real-world lidar data where ground truth shapes are not available.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper presents a self-supervised point cloud completion method called PointPnCNet that uses inpainting and random region removal to train a network using only partial point clouds, without requiring complete ground truth shapes.


## How does this paper compare to other research in the same field?

This paper presents a self-supervised method for point cloud completion that does not require complete ground truth point clouds for training. Here is a summary of how it compares to other related work:- Most prior work on point cloud completion uses complete point clouds for supervision during training. This includes methods like PCN, TopNet, PFNet, etc. In contrast, this paper proposes a self-supervised approach using only partial point clouds.- A few recent papers have also explored unsupervised or weakly-supervised point cloud completion. DPC uses an image reprojection loss for supervision while Gu et al. use a multi-view consistency loss. However, both still rely on multiple views of an object during training. This paper shows improved performance using only single partial views via inpainting.- The proposed method adopts an inpainting approach by randomly removing regions and training the network to fill them in. This is different from prior point cloud inpainting papers which operate on more structured inputs like images or voxels. The region removal induces self-supervision.- The network architecture uses an encoder-decoder with local and global streams to capture both local shape details and global shape structure. This is unlike DPC and Gu et al. which use a single global shape encoding. - Experiments show the method outperforms DPC and Gu et al. on ShapeNet and KITTI datasets. The ablation studies demonstrate the importance of the inpainting and multi-scale architecture components.In summary, this work pushes the boundary of unsupervised point cloud completion by removing the reliance on multi-view supervision. The novel inpainting approach and network design allow training on single partial scans. The performance exceeds prior unsupervised methods, helping close the gap to fully supervised techniques.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the key future research directions suggested by the authors are:- Exploring other methods for point cloud partitioning besides using intersecting half-spaces defined by coordinate planes. The paper mentions this could be an interesting direction for future work.- Improving performance on categories like lamps, sofas, tables, etc beyond just cars, planes, and chairs. The paper presents results on only 3 ShapeNet categories, so expanding to more categories could be useful. - Applying the method to additional real-world datasets beyond just KITTI to demonstrate generalizability.- Comparing to more recent supervised methods to continue closing the gap between self-supervised and fully-supervised performance. The paper shows the gap reduced compared to PCN, but more comparisons could be done.- Exploring alternatives to using a canonical frame alignment as pre-processing, to make the method more robust. The paper analyzes robustness to errors in alignment, but removing this dependency could be useful. - Extending the inpainting idea to related tasks like point cloud upsampling. The core inpainting concept could potentially transfer.- Improving completion of finer details and thin structures. The paper shows some cases where finer details like legs of chairs are not completed well.- Handling more significant missing regions. The paper analyzes robustness when removing up to 3 of 8 regions, but more extreme occlusion could be tested.- Leveraging topological or higher-level shape information to aid completion. The current approach focuses on geometry and point distributions. Those seem to be some of the key potential future directions discussed or suggested based on the results and analysis in the paper. Advancing self-supervised completion and inpainting appears to be the central theme.
