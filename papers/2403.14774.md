# [Few-Shot Adversarial Prompt Learning on Vision-Language Models](https://arxiv.org/abs/2403.14774)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Deep neural networks are vulnerable to adversarial attacks - small perturbations to inputs that cause misclassification. This limits their use in critical applications.
- Recent works use vision-language models like CLIP to achieve adversarial robustness through alignment of adversarial visual features with text supervision. However, they have limitations:
\begin{itemize}
\item Require abundant data andcompute for robustness adaptation on large datasets. 
\item Static handcrafted text prompts lack adversary-related information to supervise adversarial examples effectively.
\item Disregard model's natural generalization ability which is crucial for downstream tasks.
\end{itemize}

Proposed Solution:
- Propose a few-shot adversarial prompt (FAP) framework that adapts input sequences instead of model parameters using limited data.
- Learn adversarially-correlated text supervision end-to-end from adversarial examples instead of using static prompts.
- Novel training objective that:
\begin{itemize} 
\item Enforces consistency between natural and adversarial text-image embeddings to avoid failures in natural generalization.
\item Encourages differentiation between natural and adversarial visual features to aid learning of adversarial text supervision.  
\end{itemize}

Main Contributions:
- Identify limitations of prior adversarial vision-language models and propose a lightweight yet effective solution.  
- Adversarially-correlated text supervision notably improves alignment and achieves state-of-the-art adversarial robustness using only 1% training data.
- Novel objective enhances robustness by exploiting dual-encoder nature of vision-language models through cross-modal consistency and uni-modal divergence.
- Significantly outperforms prior arts across diverse recognition tasks in adversarial few-shot, zero-shot transfer and base-to-new generalization settings.

The paper makes vision-language models more robust to adversarial attacks in a data and compute efficient way by providing better text supervision and training strategy.
