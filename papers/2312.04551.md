# [Free3D: Consistent Novel View Synthesis without 3D Representation](https://arxiv.org/abs/2312.04551)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper introduces Free3D, a simple yet effective approach for consistent novel view synthesis from a single image without relying on an explicit 3D representation. The method builds on a pre-trained 2D image generator (Stable Diffusion) to leverage its prior knowledge about realistic images. To accurately capture the target camera pose, a novel ray conditioning normalization (RCN) layer is proposed, which tells each pixel its specific viewing direction in a distributed way. This leads to significantly more precise viewpoints compared to prior works. In addition, to improve multi-view consistency without 3D supervision, the approach employs a computationally cheap pseudo-3D cross-attention module to exchange information between views, as well as shares noise vectors across views during sampling. Trained only on Objaverse dataset, Free3D generalizes very well to other datasets of unseen categories like OmniObject3D and GSO, outperforming recent state-of-the-art open-set novel view synthesis techniques. The consistent high-quality results suggest ray conditioning and simple yet effective consistency regularization are key factors for single-image novel view synthesis.
