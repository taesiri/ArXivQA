# [Scaling may be all you need for achieving human-level object recognition   capacity with human-like visual experience](https://arxiv.org/abs/2308.03712)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:Can current self-supervised learning methods reach human-level visual object recognition capabilities if model size, training data size, and input image resolution are scaled up to be more comparable to humans, using generic architectures and learning algorithms?The key hypothesis appears to be that human-level visual object recognition abilities can be achieved by simply scaling up model size, training data size, and input resolution simultaneously, without needing more specialized model architectures or learning algorithms. The authors test this by conducting experiments training vision transformer models of varying sizes on different amounts of human-like egocentric video data and at different image resolutions. They model how accuracy on ImageNet scales with these factors to project the model size, data size and resolution needed to reach human-level performance. Their main conclusion is that human-level accuracy seems achievable at sub-human scales of these resources using current self-supervised approaches.
