# [Enhancing Plausibility Evaluation for Generated Designs with Denoising   Autoencoder](https://arxiv.org/abs/2403.05352)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Evaluating generated images is an unsolved challenge in deep generative models (DGMs). Commonly used metrics like Fréchet Inception Distance (FID) rely on pre-trained ImageNet models and are often inconsistent with human judgment, especially for structured images like product designs.  
- Human designers care more about structural plausibility rather than absence of visual artifacts. But FID and other metrics over-penalize visual noise and are not sensitive to structural failures like missing components.
- Hence there is a need for a metric tailored to evaluating generated designs that focuses on structure rather than textures/noise.

Proposed Solution:
- Replace the ImageNet-trained Inception-V3 model in FID with a Denoising Autoencoder (DAE) trained on ImageNet. DAEs are robust to noise and focus on reconstructing the underlying structure.  
- Propose Fréchet Denoised Distance (FDD) which encodes real and fake images with the DAE and computes Fréchet distance between them like FID. Also propose variants using other distances.
- Additionally train a DAE on the target dataset (e.g. bikes) itself to get better feature representations.

Experiments & Results:
- Test FDD on structured datasets like BIKED (bikes), 3DChairs (chairs) and general dataset FFHQ (faces).
- Sensitivity test shows FDD distinguishes between visual vs structural disturbances unlike FID/DINO-FID. More consistent across groups.
- Consistency test shows FDD reliably detects increasing disturbance levels.
- Model ranking experiment shows FDD aligns better with human rankings than SOTA metrics.
- Visualizations using Grad-CAM show DAE focuses on structure while Inception-V3 focuses on textures.

Conclusion:
- FDD outperforms SOTA metrics in evaluating plausibility of generated designs.
- Robust to visual noise, sensitive to structure, consistent across experiments and aligns better with humans.
- Could guide DGMs to generate more reliable and plausible designs.
- Potential to assess 3D generative models too by using 3D DAEs.
