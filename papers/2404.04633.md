# [Context versus Prior Knowledge in Language Models](https://arxiv.org/abs/2404.04633)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
Language models often need to integrate prior knowledge learned during pretraining with new information presented in a prompt's context when answering questions. The authors hypothesize that models do this integration predictably for different questions and contexts - relying more on prior knowledge for familiar entities and being more persuadable by certain contexts. 

Solution: 
The authors propose two mutual information-based metrics - the persuasion score and susceptibility score - to quantify a model's reliance on context vs prior knowledge. 

The persuasion score measures how much a given context impacts a model's answer distribution for a particular query about an entity. It captures how persuasive that context is at altering the model's answers.

The susceptibility score measures how much a model's answer distribution for a query about an entity can be impacted by contexts in general. It captures how susceptible that entity is for that query across contexts.

Main Contributions:

- Formally define persuasion and susceptibility scores grounded in information theory to capture context persuasiveness and entity susceptibility.

- Empirically validate that the scores meaningfully measure what they intend to through comparisons to similar metrics and tests of variance across samples/paraphrases.

- Analyze model behavior using the scores, finding:
   - Relevant contexts are more persuasive than irrelevant ones
   - Unfamiliar entities are more susceptible than familiar ones
   - Entities more frequent in training data/with higher graph degree have lower susceptibility

- Demonstrate applied use cases of the scores for analyzing model bias in stance detection and gender bias contexts.

In summary, the main contribution is a novel formalization of model reliance on context vs prior knowledge through grounded, validated metrics that enable more granular analysis of model behavior across contexts and entities.
