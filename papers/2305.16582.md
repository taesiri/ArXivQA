# Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large   Language Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is:How can large language models (LLMs) be enhanced to better capture the non-sequential, graph-like nature of human reasoning and problem solving? The key hypothesis is that modeling reasoning processes as graphs rather than linear chains will allow LLMs to perform more complex, human-like deductive reasoning and generate more accurate answers to reasoning tasks.In particular, the paper proposes representing reasoning as a "Graph-of-Thought" (GoT) rather than just a Chain-of-Thought (CoT). The GoT models reasoning steps as connected nodes in a graph structure rather than a simple linear chain. The authors hypothesize that integrating GoT graph representations along with textual and visual features will improve the performance of LLMs on reasoning tasks compared to only using CoT chains or textual/visual features alone.The paper aims to test this central hypothesis by implementing GoT reasoning in LLMs and evaluating on text-only and multimodal reasoning datasets. The goal is to demonstrate that modeling reasoning as graph structures rather than chains enables more human-like deductive reasoning and stronger performance on complex reasoning tasks.In summary, the core research question is whether Graph-of-Thought can enhance reasoning abilities in LLMs beyond current Chain-of-Thought and multimodal methods. The central hypothesis is that the graph structure will better capture human reasoning.
