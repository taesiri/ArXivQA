# [How Important Is a Neuron?](https://arxiv.org/abs/1805.12233)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we extend the notion of attribution (i.e. explaining a deep network's prediction in terms of input variables) to also understand the importance of hidden units within the network?The key idea they introduce is the concept of "conductance", which aims to quantify the importance of a hidden neuron by calculating the "flow" of attribution through that neuron. So conductance allows attributing a network's predictions not just to the input variables, but also to the hidden units.The paper evaluates conductance both theoretically (proving desirable properties) and empirically on image and text networks. The evaluations aim to demonstrate the effectiveness of conductance in identifying important insights into how these networks work internally.In summary, the main research contribution is introducing conductance to extend attribution to hidden units, in order to better understand the internal workings and importance of different parts of deep networks. The paper aims to show this is an effective approach through theoretical analysis and empirical demonstrations.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It introduces the notion of "conductance" to extend attribution methods to understand the importance of hidden units in deep neural networks. 2. It proposes a specific definition of conductance based on Integrated Gradients attribution. The key idea is to decompose the computation of Integrated Gradients using the chain rule to attribute importance scores to hidden units.3. It evaluates conductance against other methods like activations, gradient*activations, and internal influence on theoretical properties, ablation studies, and feature selection tasks. The evaluations are done on Inception Net for image classification and a sentiment analysis model.4. It demonstrates the effectiveness of conductance in identifying insights into the internal workings of the two neural networks evaluated. For example, finding influential filters in Inception Net, observing redundancy in the sentiment model, and identifying filters capturing negation.5. It discusses applications of conductance like improving model interpretability, aiding debugging, analyzing model architectures, and extracting rules from models.In summary, the main contribution is proposing the notion of conductance to attribute importance to hidden units in neural networks, with empirical demonstrations of its effectiveness on real models. Theoretical analysis and comparisons to other methods are also provided.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the main points from the paper:The paper introduces the concept of conductance to measure the importance of hidden neurons in deep networks, evaluates it theoretically and empirically on image and text models, and shows it can provide insights into how the networks function.


## How does this paper compare to other research in the same field?

This paper introduces the concept of "conductance" to measure the importance of hidden neurons in deep neural networks. Here are some key ways it compares to prior work:- It builds on the idea of attribution methods like Integrated Gradients that attribute a model's predictions to its input features. Conductance extends this by propagating attributions through the network to measure importance of hidden units.- Prior work has tried to understand hidden units via optimization approaches like activation maximization or feature visualization. However, those don't directly measure a unit's importance. This paper quantifies importance through conductance.- It compares against using activations or gradients * activations as importance measures. The paper argues conductance is theoretically better motivated. It provides ablation studies showing conductance correlates better with model changes.- A concurrent paper on "internal influence" has a similar goal of measuring neuron importance. This paper compares against that method, showing conductance satisfies desirable properties like "completeness" that internal influence lacks.- For evaluations, this paper uses a combination of theoretical analysis, ablation studies, and feature selection experiments. The ablation studies are a fairly direct way to validate importance measures.- It demonstrates the approach on both an image classification model (Inception-Net) and a text sentiment analysis model. Showing effectiveness on two different modalities strengthens the generality of the method.In summary, this paper makes both theoretical and empirical contributions over prior work to better measure the importance of hidden units. The ablation studies in particular help validate conductance over alternatives like activation or internal influence. The analysis also provides some interesting insights into the studied models.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Studying conductance in other types of networks beyond image classification and sentiment analysis, such as sequence-to-sequence networks. The authors suggest that conductance could potentially help analyze the behavior of attention neurons in these models.- Further evaluating the effectiveness of conductance, for example by using it as part of the training process to help identify areas of model saturation or redundancy. The authors suggest conductance could be useful for improving model architecture and training.- Using conductance to help build more interpretable models, for instance by manually labeling important filters and providing natural language explanations of model behavior based on the influence of different filters. - Applying conductance analysis to additional datasets and models to gain more insights into model behavior, negations, redundancies, etc.- Using conductance to help extract symbolic rules from neural networks, for example identifying phrases with high conductance for certain filters related to negation.- Comparing conductance to other related attribution methods like DeepLIFT and Layerwise Relevance Propagation in terms of properties and empirical evaluations.- Developing more formal axiomatic characterization of conductance to better understand its theoretical properties.So in summary, the authors propose many different directions for extending the analysis of model internals via conductance, ranging from model debugging and improvement to interpretation and rule extraction. More empirical analysis is needed, as well as comparisons to other methods.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the key points from the paper:The paper introduces the notion of conductance to quantify the importance of hidden units in deep networks. Conductance extends attribution methods like Integrated Gradients to hidden neurons by decomposing the attributions via the chain rule. The conductance of a neuron represents the flow of attribution through that neuron. Empirically, conductance is evaluated on image and text models by comparing to ablation studies, showing stronger agreement than other methods. It also performs better on a feature selection task. Theoretically, conductance satisfies desirable properties like completeness and appropriate sensitivity. Overall, conductance helps explain predictions by identifying influential hidden units and their function. It is an interpretable measure of feature importance that could aid analysis and improvement of deep networks.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the key points from the paper:The paper introduces the notion of conductance to extend attribution methods to understand the importance of hidden units in deep neural networks. Attribution methods attribute a network's prediction to its input features. Conductance adapts the method of Integrated Gradients to instead measure the flow of attribution through hidden neurons. Formally, the conductance of a hidden neuron is defined as the integrated gradients attribution flowing through that neuron from the inputs. The paper evaluates conductance against other methods like activation values and influence scores. It shows theoretically and empirically that conductance better captures the true importance of hidden units. Experiments on image classification and sentiment analysis models demonstrate how conductance can provide insights into the internal workings of networks. The method identifies influential hidden units, shows redundancy and division of labor between units, and finds units implementing higher level concepts like negation. Overall, conductance enables interpreting predictions in terms of higher level network components versus just input features.
