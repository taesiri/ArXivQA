# [EmoGen: Eliminating Subjective Bias in Emotional Music Generation](https://arxiv.org/abs/2307.01229)

## What is the central research question or hypothesis that this paper addresses?

This paper does not seem to explicitly state a central research question or hypothesis. However, based on my reading, the main focus of the paper appears to be on proposing a new method called EmoGen for emotional music generation. The key ideas and goals of EmoGen seem to be:- To generate music that conveys desired emotions more accurately compared to previous methods.- To eliminate the subjective bias in emotion labels that can negatively impact previous end-to-end methods for emotional music generation. - To leverage emotion-related music attributes as an intermediate representation between emotions and music to help improve emotion control and avoid subjective bias.- To use a two-stage approach with supervised clustering for emotion-to-attribute mapping and self-supervised learning for attribute-to-music generation.- To achieve better emotion controllability and music quality compared to prior approaches.- To be able to leverage arbitrary datasets without needing emotion label annotations for training the generative model.So in summary, while no explicit research question/hypothesis is stated, the central focus appears to be on proposing the EmoGen method to address limitations of prior work and achieve more accurate and flexible emotional music generation. The paper seems aimed at demonstrating the advantages of EmoGen both qualitatively and quantitatively.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing EmoGen, an emotional music generation system that can eliminate subjective bias from emotion labels. EmoGen leverages emotion-related attributes as a bridge between emotions and music sequences.- Breaking down the task into two stages - emotion-to-attribute mapping using supervised clustering, and attribute-to-music generation using self-supervised learning. The supervised clustering helps obtain attribute values representing general emotions. The self-supervised learning disentangles the generation from emotion labels to avoid subjective bias.- Experimental results showing EmoGen outperforms previous methods on emotion control accuracy and music quality. EmoGen is also shown to be effective at eliminating subjective bias and can leverage arbitrary unlabeled datasets for training.- The two-stage framework with supervised clustering and self-supervised learning is demonstrated to be beneficial for precise emotion control in music generation while eliminating issues with subjective bias in emotion labels. The use of music attributes provides an interpretable way to control the generation process.In summary, the key contribution appears to be proposing a new emotional music generation system EmoGen that can achieve better emotion control and quality by eliminating subjective bias in emotion labels through a two-stage framework leveraging supervised clustering and self-supervised learning.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The paper provides instructions and guidelines for preparing submissions to ICML 2023. The key point is that submissions should use the icml2023.sty style file and conform to the formatting requirements outlined in the paper.


## How does this paper compare to other research in the same field?

This paper proposes EmoGen, a new approach for generating emotional music. Here are some key ways it compares to prior work in emotional music generation:- Most prior work directly maps emotion labels to music sequences in an end-to-end manner. In contrast, EmoGen introduces emotion-related music attributes as an intermediate representation between emotions and music. This allows it to avoid some of the subjectivity biases in emotion labels.- EmoGen consists of two stages - emotion-to-attribute mapping and attribute-to-music generation. The first stage uses supervised clustering to map emotions to attribute values representing the general emotion. The second stage trains a Transformer model using the attributes in a self-supervised manner, completely disentangled from emotion labels.- Previous methods require labeled emotion data for training. EmoGen's attribute-to-music stage allows training on unlabeled datasets, giving it more flexibility.- Experiments show EmoGen has better emotion control accuracy and music quality compared to prior work. Both subjective and objective metrics demonstrate its effectiveness.- The authors analyze different design choices like mapping methods, attribute selection, and number of attributes. This provides insights into what makes EmoGen work well.- EmoGen is demonstrated to work on both piano-only and multi-instrumental datasets. The disentangled framework allows training the music generation module on any dataset without emotion labels.Overall, by using music attributes as an intermediate bridge and a two-stage training approach, EmoGen represents an advance over prior work in controllable emotional music generation. The comprehensive experiments and analyses also provide useful insights into this problem domain.


## What future research directions do the authors suggest?

The authors suggest a few potential future research directions:1. Exploring different clustering methods for emotion-to-attribute mapping. In the current EmoGen model, they simply use the closest sample to the clustering center to represent the general emotion. They suggest exploring other clustering algorithms to obtain finer-grained emotion classes and more diverse emotional mappings. 2. Controlling the generation process dynamically at different levels. Currently EmoGen controls the global attributes of the entire song. The authors propose exploring methods to control the generation dynamically at the bar, phrase or section level to achieve emotion transitions.3. Extending the framework to other generation tasks and domains, such as emotion/style controlled text generation. The idea of using a two-stage process with supervised clustering and self-supervised learning to eliminate subjective bias could potentially be applied to other conditional generation tasks.4. Improving the diversity of the generated outputs. The current EmoGen model maps each emotion to one set of attributes, which limits diversity. The authors suggest mapping multiple sets of attributes for each emotion to generate more diverse outputs.5. Evaluating on more multi-instrumental datasets. They showed promising results on the TopMAGD dataset, but suggest evaluating on more diverse multi-instrument datasets.In summary, the main future directions are around improving controllability and diversity, extending the framework to new tasks/domains, and more rigorous evaluation. The core ideas of using supervised clustering and self-supervised learning to eliminate subjective bias appear promising for conditional generation tasks in general.
