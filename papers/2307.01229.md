# [EmoGen: Eliminating Subjective Bias in Emotional Music Generation](https://arxiv.org/abs/2307.01229)

## What is the central research question or hypothesis that this paper addresses?

This paper does not seem to explicitly state a central research question or hypothesis. However, based on my reading, the main focus of the paper appears to be on proposing a new method called EmoGen for emotional music generation. The key ideas and goals of EmoGen seem to be:- To generate music that conveys desired emotions more accurately compared to previous methods.- To eliminate the subjective bias in emotion labels that can negatively impact previous end-to-end methods for emotional music generation. - To leverage emotion-related music attributes as an intermediate representation between emotions and music to help improve emotion control and avoid subjective bias.- To use a two-stage approach with supervised clustering for emotion-to-attribute mapping and self-supervised learning for attribute-to-music generation.- To achieve better emotion controllability and music quality compared to prior approaches.- To be able to leverage arbitrary datasets without needing emotion label annotations for training the generative model.So in summary, while no explicit research question/hypothesis is stated, the central focus appears to be on proposing the EmoGen method to address limitations of prior work and achieve more accurate and flexible emotional music generation. The paper seems aimed at demonstrating the advantages of EmoGen both qualitatively and quantitatively.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing EmoGen, an emotional music generation system that can eliminate subjective bias from emotion labels. EmoGen leverages emotion-related attributes as a bridge between emotions and music sequences.- Breaking down the task into two stages - emotion-to-attribute mapping using supervised clustering, and attribute-to-music generation using self-supervised learning. The supervised clustering helps obtain attribute values representing general emotions. The self-supervised learning disentangles the generation from emotion labels to avoid subjective bias.- Experimental results showing EmoGen outperforms previous methods on emotion control accuracy and music quality. EmoGen is also shown to be effective at eliminating subjective bias and can leverage arbitrary unlabeled datasets for training.- The two-stage framework with supervised clustering and self-supervised learning is demonstrated to be beneficial for precise emotion control in music generation while eliminating issues with subjective bias in emotion labels. The use of music attributes provides an interpretable way to control the generation process.In summary, the key contribution appears to be proposing a new emotional music generation system EmoGen that can achieve better emotion control and quality by eliminating subjective bias in emotion labels through a two-stage framework leveraging supervised clustering and self-supervised learning.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The paper provides instructions and guidelines for preparing submissions to ICML 2023. The key point is that submissions should use the icml2023.sty style file and conform to the formatting requirements outlined in the paper.
