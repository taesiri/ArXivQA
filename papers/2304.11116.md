# Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via   Prompt Augmented by ChatGPT

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the key research question it aims to address is:How to empower existing large language models (LLMs) with the ability to conduct reasoning on graph structured data?The paper proposes a framework called Graph-ToolFormer to teach LLMs to use external graph data loading and reasoning tools to handle various graph reasoning tasks. The goal is to give LLMs the capabilities to handle tasks involving complex graph data, such as computing graph properties, analyzing bibliographic networks, predicting molecular graph functions, making recommendations, detecting communities, and reasoning on knowledge graphs. The central hypothesis is that by fine-tuning LLMs on a dataset of prompts augmented with graph API calls, the models can learn to automatically generate appropriate API calls to external graph tools in order to accomplish diverse graph reasoning tasks. The prompts are generated based on a small number of hand-crafted examples, then expanded via ChatGPT.In essence, the paper explores methodologies to overcome weaknesses of current LLMs in areas like mathematical calculation, multi-step logic, spatial/topological reasoning, and temporal progression. The Graph-ToolFormer framework aims to imbue LLMs with enhanced capacities for graph data reasoning across various real-world domains.


## What is the main contribution of this paper?

Based on my review, the main contributions of this paper appear to be:1. Proposing Graph-ToolFormer (GTF), a framework to empower large language models (LLMs) like GPT with the ability to perform graph reasoning tasks. 2. Using ChatGPT to annotate and augment a large graph reasoning dataset with API calls to external graph reasoning tools. This allows teaching the LLM how and when to leverage these tools.3. Conducting extensive experiments on diverse graph reasoning tasks using real-world benchmark datasets. Tasks include graph property calculations, paper topic inference, molecular graph function prediction, recommendation, community detection, and knowledge graph reasoning.4. Releasing the source code for GTF, the annotated graph reasoning datasets, and pre-trained checkpoints for the graph reasoning models to facilitate further research.In summary, the key innovation seems to be developing GTF to adapt LLMs to handle graph reasoning, which they currently struggle with due to limitations in mathematical calculations, logic reasoning, and spatial/topological perception. Augmenting the training data using ChatGPT to provide examples of API usage allows efficient teaching of the LLM when and how to leverage external tools. The extensive experiments demonstrate the effectiveness of this approach across a variety of graph reasoning tasks. By open-sourcing the key components, the authors aim to bridge graph learning and LLMs to advance research at the intersection of these areas.
