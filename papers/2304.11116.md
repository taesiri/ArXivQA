# Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via
  Prompt Augmented by ChatGPT

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the key research question it aims to address is:How to empower existing large language models (LLMs) with the ability to conduct reasoning on graph structured data?The paper proposes a framework called Graph-ToolFormer to teach LLMs to use external graph data loading and reasoning tools to handle various graph reasoning tasks. The goal is to give LLMs the capabilities to handle tasks involving complex graph data, such as computing graph properties, analyzing bibliographic networks, predicting molecular graph functions, making recommendations, detecting communities, and reasoning on knowledge graphs. The central hypothesis is that by fine-tuning LLMs on a dataset of prompts augmented with graph API calls, the models can learn to automatically generate appropriate API calls to external graph tools in order to accomplish diverse graph reasoning tasks. The prompts are generated based on a small number of hand-crafted examples, then expanded via ChatGPT.In essence, the paper explores methodologies to overcome weaknesses of current LLMs in areas like mathematical calculation, multi-step logic, spatial/topological reasoning, and temporal progression. The Graph-ToolFormer framework aims to imbue LLMs with enhanced capacities for graph data reasoning across various real-world domains.
