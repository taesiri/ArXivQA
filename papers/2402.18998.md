# [COFT-AD: COntrastive Fine-Tuning for Few-Shot Anomaly Detection](https://arxiv.org/abs/2402.18998)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Anomaly detection models typically require a large amount of normal/anomaly-free data for representation learning. However, in many practical applications, acquiring substantial anomaly-free data upfront is expensive or time-consuming. This paper tackles the problem of few-shot anomaly detection (FSAD) where only a few normal samples are available for training anomaly detection models.

Proposed Solution:
The paper proposes a novel FSAD method called COFT-AD which incorporates two key techniques - (1) Initialize model weights from a backbone network pre-trained on large source dataset like ImageNet. This enables reuse of powerful low-level feature extractors. (2) Adopt contrastive training on the few target normal samples to adapt the pretrained model to the target domain, alleviating negative impact of covariate shift between source and target distributions. 

Additionally, two customized loss functions are proposed:
(i) Cross-instance positive pair loss that encourages tight clustering of embeddings of normal samples to facilitate density-based anomaly detection. 
(ii) Negative pair loss with synthesized anomalies using prior domain knowledge, that encourages separation between embeddings of normal and abnormal samples.

Anomaly detection is performed using density estimation by fitting multivariate Gaussian to the normal sample embeddings. Testing samples are assigned anomaly scores via Mahalanobis distance to the Gaussian.

Main Contributions:
- Approach FSAD from a transfer learning perspective by adapting pretrained model to target domain using contrastive fine-tuning on few target samples.
- Introduce cross-instance positive pair loss to encourage tight cluster of normal samples in embedding space.
- Incorporate negative pair loss when prior knowledge on anomalies is available to improve separation. 
- Demonstrate state-of-the-art performance on 3 controlled AD datasets and 4 real-world industrial defect datasets.
- Empirically demonstrate benefit of synthesized anomalies is task-dependent. The approach without negative pairs is robust when prior knowledge unclear or unavailable.

In summary, the paper presents a principled transfer learning based method for FSAD that is simple, hyperparameter-friendly and achieves versatile strong performance on diverse datasets.
