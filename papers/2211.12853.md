# [BAD-NeRF: Bundle Adjusted Deblur Neural Radiance Fields](https://arxiv.org/abs/2211.12853)

## What is the central research question or hypothesis that this paper addresses?

 The central research question addressed in this paper is how to train neural radiance fields (NeRF) on motion blurred images to jointly reconstruct the 3D scene and recover the camera motion trajectories within exposure time. 

The key ideas and contributions are:

- Proposes a bundle adjustment formulation to jointly optimize NeRF and camera motion trajectories given motion blurred images. 

- Models the physical image formation process of motion blur by rendering and averaging sharp frames along the trajectory.

- Achieves state-of-the-art performance in deblurring, novel view synthesis, and pose estimation on synthetic and real datasets. 

The main hypothesis is that by explicitly modeling the image formation process of motion blur and bundle adjusting both scene geometry and camera motion, they can overcome the limitations of training NeRFs on blurry images with inaccurate poses. The experiments validate this hypothesis and show quantitative improvements over prior work.

In summary, this paper addresses the problem of training high-quality NeRFs from degraded inputs by jointly optimizing the neural representation and camera trajectories in a physically based manner. The novel bundle adjustment framework is the main contribution.


## What is the main contribution of this paper?

 This paper proposes a method called BAD-NeRF (Bundle Adjusted Deblur Neural Radiance Fields) for training NeRF using motion blurry images and inaccurate camera poses. The main contributions are:

- They propose a photometric bundle adjustment formulation for motion blurry images using NeRF. This jointly optimizes the NeRF network parameters and camera motion trajectories within exposure time to match the real motion blurry images. 

- They model the camera motion trajectory within exposure time with start and end poses, and linearly interpolate intermediate poses in SE(3) space. This allows jointly optimizing the poses together with NeRF using the differentiable rendering process.

- Experiments show the proposed method can effectively deblur images, render high quality novel views, and accurately recover camera poses from blurry images. It outperforms prior image deblurring and novel view synthesis methods.

In summary, the key contribution is proposing a joint optimization framework to simultaneously deblur images, reconstruct 3D scene, and refine camera poses by incorporating the image formation model of motion blur into NeRF. This makes NeRF more robust to blurry inputs for novel view synthesis.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key point from the paper:

The paper proposes a new method called Bundle Adjusted Deblur Neural Radiance Fields (BAD-NeRF) which can jointly learn the neural radiance fields and recover camera motion trajectories from a set of blurry images, enabling high quality novel view synthesis.


## How does this paper compare to other research in the same field?

 This paper presents Bundle Adjusted Deblur Neural Radiance Fields (BAD-NeRF), a method that jointly learns neural radiance fields and camera motion trajectories from sets of motion blurred images. Here are some key points on how it compares to prior work:

- Most prior work on neural radiance fields (NeRFs) assumes clean, sharp input images. This paper focuses specifically on handling motion blur, which violates the common NeRF assumption of infinitesimal exposure time.

- Compared to Deblur-NeRF, which also aims to train NeRFs from blurry inputs, BAD-NeRF explicitly models the full camera motion trajectory within each exposure rather than just a single pose. This makes it more robust to inaccurate initial poses and severe motion blur.

- Unlike other learning-based single image deblurring methods, BAD-NeRF leverages a full set of multi-view images and the 3D scene geometry from NeRF to achieve more consistent deblurring.

- Compared to classic multi-view deblurring methods like Park et al., BAD-NeRF represents the scene implicitly with a neural network rather than explicit meshes or depth maps. This allows more powerful 3D scene representations.

- For camera pose estimation from blurry images, BAD-NeRF demonstrates superior accuracy over prior pose estimation methods like COLMAP and BARF.

- Overall, by directly modeling the full physical image formation process under motion blur, BAD-NeRF achieves state-of-the-art results in deblurring, novel view synthesis, and pose estimation compared to previous NeRF and deblurring techniques.

In summary, this paper introduces a principled approach to handle motion blur in NeRFs, advancing the capability of neural scene representations to deal with non-ideal capture conditions. The photographic bundle adjustment formulation is also generalizable to other vision tasks.


## What future research directions do the authors suggest?

 The authors suggest several potential future research directions at the end of the paper:

- Integrating their method with a motion blur aware visual odometry system. The estimated poses from the visual odometry front-end could be used to initialize their method. This could enable robust 3D vision in low-light conditions.

- Extending their formulation to handle rolling shutter cameras, to make NeRF robust to rolling shutter distortions.

- Replacing the current NeRF network with a more efficient voxel-based NeRF representation to improve computational efficiency. The current implementation is quite slow.

- Exploring the integration of their photometric bundle adjustment idea with other vision pipelines, beyond NeRF, as it provides a general formulation for motion blurred images.

- Evaluating the performance on more complex dynamic scenes with moving objects, not just camera motion blur.

- Extending it to video input with temporal consistency modeling.

In summary, the main future directions are around improving efficiency, handling more complex camera models and scenes, and integrating the motion blur aware bundle adjustment idea into other vision systems beyond just NeRF. Overall, it provides a general framework for making 3D vision systems robust to motion blur.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points of the paper:

This CVPR 2022 paper proposes a new method called Bundle Adjusted Deblur Neural Radiance Fields (BAD-NeRF) for training neural radiance fields (NeRF) from motion blurred images. The key idea is to model the physical image formation process of motion blur during NeRF training. Specifically, the method represents the camera motion trajectory within exposure time with start and end poses, and samples virtual poses along this trajectory to render sharp images from NeRF. These virtual sharp images are averaged to synthesize the blurry input image. By explicitly modeling this image formation process and jointly optimizing for both the NeRF network weights and the camera motion trajectories, BAD-NeRF is able to achieve superior performance in deblurring, novel view synthesis, and camera pose estimation compared to prior methods. Experiments on synthetic and real datasets demonstrate that BAD-NeRF can successfully handle severe motion blur and inaccurate camera poses during NeRF training. A key advantage is that by modeling the physical image formation process, BAD-NeRF can make better use of the motion information contained in blurry images.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper proposes a novel bundle adjusted deblur neural radiance field (BAD-NeRF) method to jointly learn neural radiance fields and recover camera motion trajectories from a set of motion blurred images. Neural radiance fields (NeRFs) have shown impressive performance for novel view synthesis and 3D scene reconstruction. However, they usually require accurately posed sharp images as input during training. Motion blurred images violate these assumptions and can degrade NeRF's performance. 

To address this issue, the authors model the physical image formation process of motion blurred images in NeRF's volume rendering framework. They represent each image's motion trajectory with camera poses at start and end of exposure time, and linearly interpolate poses in between. Virtual sharp images are rendered from NeRF along this trajectory and averaged to synthesize the final blurred image. Both the neural radiance field and camera motion trajectories are jointly optimized to match the synthesized and real blurry images. Experiments on synthetic and real datasets demonstrate the proposed BAD-NeRF achieves state-of-the-art performance in deblurring, novel view synthesis, and camera pose estimation compared to prior methods. It delivers robust performance even with inaccurate initial camera poses and severe motion blur.


## Summarize the main method used in the paper in one paragraph.

 The paper presents a new method for training neural radiance fields (NeRF) from motion blurred images. The key ideas are:

1) They model the physical image formation process of motion blurred images, where a blurry image is formed by integrating sharp images over the camera's exposure time. 

2) For each blurry input image, they estimate a start and end pose representing the camera motion trajectory during exposure. The poses in between are interpolated to approximate the full trajectory.

3) They render sharp images along each pose in the trajectory using NeRF, then average to synthesize a blurry image. 

4) They jointly optimize the NeRF network weights and the start/end poses of each trajectory by minimizing the error between the rendered and real blurry images.

So in summary, by explicitly modeling the image formation process and camera motion blur within NeRF, they are able to train the neural radiance field robustly from blurred images and inaccurate poses. This allows rendering of sharp novel views.


## What problem or question is the paper addressing?

 This paper proposes a new method called BAD-NeRF (Bundle Adjusted Deblur NeRF) to address the problem of training neural radiance fields (NeRFs) from sets of motion blurred images with inaccurate camera poses. 

The key problems and questions it aims to address are:

- NeRFs assume input images are sharp with accurate camera poses. But in real scenarios, images can be degraded by motion blur and poses may be inaccurate, which degrades NeRF performance. 

- How can we train high quality NeRFs that are robust to motion blur in input images and inaccurate poses?

- How to jointly optimize NeRF scene representation and recover latent sharp images and accurate camera motion trajectories from blurry inputs?

To address these, the main contributions of this paper are:

- A photometric bundle adjustment formulation that jointly optimizes NeRF and camera motion trajectories from blurry images.

- Modeling the physical image formation process of motion blur into NeRF rendering.

- Recovering latent sharp images, accurate poses and high quality NeRFs from severely blurred images and inaccurate poses.

- Demonstrating superior performance over prior NeRFs and learning based/multi-view deblurring methods on both synthetic and real datasets.

In summary, the key problem addressed is training high quality NeRFs robust to common issues of motion blur and inaccurate poses in real images, via jointly optimizing scene representation and camera motion trajectories.
