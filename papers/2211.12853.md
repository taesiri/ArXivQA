# [BAD-NeRF: Bundle Adjusted Deblur Neural Radiance Fields](https://arxiv.org/abs/2211.12853)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is how to train neural radiance fields (NeRF) on motion blurred images to jointly reconstruct the 3D scene and recover the camera motion trajectories within exposure time. The key ideas and contributions are:- Proposes a bundle adjustment formulation to jointly optimize NeRF and camera motion trajectories given motion blurred images. - Models the physical image formation process of motion blur by rendering and averaging sharp frames along the trajectory.- Achieves state-of-the-art performance in deblurring, novel view synthesis, and pose estimation on synthetic and real datasets. The main hypothesis is that by explicitly modeling the image formation process of motion blur and bundle adjusting both scene geometry and camera motion, they can overcome the limitations of training NeRFs on blurry images with inaccurate poses. The experiments validate this hypothesis and show quantitative improvements over prior work.In summary, this paper addresses the problem of training high-quality NeRFs from degraded inputs by jointly optimizing the neural representation and camera trajectories in a physically based manner. The novel bundle adjustment framework is the main contribution.


## What is the main contribution of this paper?

This paper proposes a method called BAD-NeRF (Bundle Adjusted Deblur Neural Radiance Fields) for training NeRF using motion blurry images and inaccurate camera poses. The main contributions are:- They propose a photometric bundle adjustment formulation for motion blurry images using NeRF. This jointly optimizes the NeRF network parameters and camera motion trajectories within exposure time to match the real motion blurry images. - They model the camera motion trajectory within exposure time with start and end poses, and linearly interpolate intermediate poses in SE(3) space. This allows jointly optimizing the poses together with NeRF using the differentiable rendering process.- Experiments show the proposed method can effectively deblur images, render high quality novel views, and accurately recover camera poses from blurry images. It outperforms prior image deblurring and novel view synthesis methods.In summary, the key contribution is proposing a joint optimization framework to simultaneously deblur images, reconstruct 3D scene, and refine camera poses by incorporating the image formation model of motion blur into NeRF. This makes NeRF more robust to blurry inputs for novel view synthesis.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key point from the paper:The paper proposes a new method called Bundle Adjusted Deblur Neural Radiance Fields (BAD-NeRF) which can jointly learn the neural radiance fields and recover camera motion trajectories from a set of blurry images, enabling high quality novel view synthesis.


## How does this paper compare to other research in the same field?

This paper presents Bundle Adjusted Deblur Neural Radiance Fields (BAD-NeRF), a method that jointly learns neural radiance fields and camera motion trajectories from sets of motion blurred images. Here are some key points on how it compares to prior work:- Most prior work on neural radiance fields (NeRFs) assumes clean, sharp input images. This paper focuses specifically on handling motion blur, which violates the common NeRF assumption of infinitesimal exposure time.- Compared to Deblur-NeRF, which also aims to train NeRFs from blurry inputs, BAD-NeRF explicitly models the full camera motion trajectory within each exposure rather than just a single pose. This makes it more robust to inaccurate initial poses and severe motion blur.- Unlike other learning-based single image deblurring methods, BAD-NeRF leverages a full set of multi-view images and the 3D scene geometry from NeRF to achieve more consistent deblurring.- Compared to classic multi-view deblurring methods like Park et al., BAD-NeRF represents the scene implicitly with a neural network rather than explicit meshes or depth maps. This allows more powerful 3D scene representations.- For camera pose estimation from blurry images, BAD-NeRF demonstrates superior accuracy over prior pose estimation methods like COLMAP and BARF.- Overall, by directly modeling the full physical image formation process under motion blur, BAD-NeRF achieves state-of-the-art results in deblurring, novel view synthesis, and pose estimation compared to previous NeRF and deblurring techniques.In summary, this paper introduces a principled approach to handle motion blur in NeRFs, advancing the capability of neural scene representations to deal with non-ideal capture conditions. The photographic bundle adjustment formulation is also generalizable to other vision tasks.


## What future research directions do the authors suggest?

The authors suggest several potential future research directions at the end of the paper:- Integrating their method with a motion blur aware visual odometry system. The estimated poses from the visual odometry front-end could be used to initialize their method. This could enable robust 3D vision in low-light conditions.- Extending their formulation to handle rolling shutter cameras, to make NeRF robust to rolling shutter distortions.- Replacing the current NeRF network with a more efficient voxel-based NeRF representation to improve computational efficiency. The current implementation is quite slow.- Exploring the integration of their photometric bundle adjustment idea with other vision pipelines, beyond NeRF, as it provides a general formulation for motion blurred images.- Evaluating the performance on more complex dynamic scenes with moving objects, not just camera motion blur.- Extending it to video input with temporal consistency modeling.In summary, the main future directions are around improving efficiency, handling more complex camera models and scenes, and integrating the motion blur aware bundle adjustment idea into other vision systems beyond just NeRF. Overall, it provides a general framework for making 3D vision systems robust to motion blur.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the key points of the paper:This CVPR 2022 paper proposes a new method called Bundle Adjusted Deblur Neural Radiance Fields (BAD-NeRF) for training neural radiance fields (NeRF) from motion blurred images. The key idea is to model the physical image formation process of motion blur during NeRF training. Specifically, the method represents the camera motion trajectory within exposure time with start and end poses, and samples virtual poses along this trajectory to render sharp images from NeRF. These virtual sharp images are averaged to synthesize the blurry input image. By explicitly modeling this image formation process and jointly optimizing for both the NeRF network weights and the camera motion trajectories, BAD-NeRF is able to achieve superior performance in deblurring, novel view synthesis, and camera pose estimation compared to prior methods. Experiments on synthetic and real datasets demonstrate that BAD-NeRF can successfully handle severe motion blur and inaccurate camera poses during NeRF training. A key advantage is that by modeling the physical image formation process, BAD-NeRF can make better use of the motion information contained in blurry images.
