# [Rethinking Data Selection for Supervised Fine-Tuning](https://arxiv.org/abs/2402.06094)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Supervised finetuning (SFT) of large language models (LLMs) is important for aligning them to be helpful to humans. However, SFT is considered superficial, only teaching styles rather than new knowledge.  
- Recent works show that finetuning on subsets of SFT data leads to better performance than using all data. Subset selection strategies focus on quality and diversity.
- But given the superficial nature of SFT, the author questions if quality and diversity should be the focus for data selection.

Proposed Solution: 
- Hypothesize that SFT data selection should focus on instances that reflect human-like styles and interactions.
- As an initial attempt, use a simple heuristic of selecting demonstrations with long responses. The intuition is that if a short response already meets the instruction, a longer version with more detail is more helpful, mimicking human style.

Experiments & Results:
- Finetune LLaMA on 3 datasets - Alpaca, WizardLM, Dolly. Compare models finetuned on full data vs subsets selected based on longest responses, diversity, and quality.
- Selecting longest responses substantially outperforms all baselines across datasets and test sets. For example, on Alpaca test set, longest 1K beats full data by 68% vs 20%.
- Analysis shows models finetuned on longest responses generate more detailed and helpful responses preferred by human evaluation.

Main Contributions:
- Question relevance of existing quality and diversity focused selection strategies for SFT.
- Propose new perspective to select SFT demonstrations reflecting human-like styles. 
- Show that even a simple heuristic of selecting long responses works much better than strong baselines, validating the proposed perspective.
- Shed light on better curating SFT data instead of only selecting from existing pools.

In summary, this paper provides a new way of thinking about data selection for supervised finetuning of LLMs, focusing on human-style demonstrations rather than just quality and diversity. The strong empirical results validate this perspective and highlight the need for better strategies to identify human-like data.


## Summarize the paper in one sentence.

 This paper proposes selecting demonstrations with long responses for supervised finetuning of large language models, based on the hypothesis that detailed responses better reflect human-like interactions and are more effective for the superficial learning process of finetuning.


## What is the main contribution of this paper?

 The main contribution of this paper is rethinking the intuition behind data selection for supervised finetuning (SFT) of large language models (LLMs). 

Specifically, the key points are:

- Considering SFT is superficial in nature where models mainly learn styles rather than new knowledge, the paper questions the relevance of existing data selection strategies based on quality and diversity.

- The paper proposes that SFT data selection should focus on picking demonstrations that reflect human-like styles the most. However, directly assessing human-likeness is difficult. 

- As an initial attempt, the paper shows selecting instances with long responses is surprisingly effective for SFT. This naive heuristic implicitly mimics a human-style conversation where detailed responses are more helpful.

- Experiments on multiple datasets and LLMs validate that selecting long responses outperforms common selection methods based on quality and diversity as well as using the full dataset.

So in summary, the main contribution is rethinking SFT data selection from the perspective of human-style demonstration instead of quality or diversity, and providing strong empirical evidence that even a simple heuristic of selecting long responses works better than existing selection strategies.


## What are the keywords or key terms associated with this paper?

 Based on my review, some of the key terms and keywords associated with this paper include:

- Supervised finetuning (SFT)
- Language models (LLMs) 
- Data selection
- Quality and diversity 
- Human-like style
- Long responses
- Benchmark evaluations

To summarize, this paper rethinks the principles behind data selection for supervised finetuning of language models. It questions the focus on quality and diversity, proposing instead to select data that reflects human-like style and interactions. As an initial attempt, the authors show that simply selecting instances with long responses, which tend to be more detailed, leads to better performance compared to common selection strategies based on quality and diversity. The effectiveness is evaluated on various benchmarks.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes that data selection for supervised finetuning (SFT) should focus more on picking demonstrations that reflect human style rather than just data quality or diversity. Could you expand more on why mimicking human style is important for SFT given its superficial nature?

2. The method selects demonstrations with long responses as a heuristic to mimic human style. Could you discuss other potential signals in demonstrations that could reflect human style, beyond just response length?

3. The paper shows strong results by finetuning on a small subset selected by the proposed heuristic. Could you analyze the tradeoffs between subset size and model performance in more depth? For example, does increasing the size beyond a certain point lead to diminishing returns? 

4. Could you expand more on potential biases that could affect the evaluation, beyond just verbosity bias? For example, could the selection criteria inadvertently favor certain types of instructions over others?

5. You mention that directly identifying human-like demonstrations is challenging. What are some ideas or future work to better automatically identify human style in demonstrations?

6. What are some of the limitations of using response length as a heuristic? When might this heuristic fall short in selecting helpful demonstrations?

7. The paper focuses on selecting subsets from existing datasets. What are some ideas to proactively create better SFT datasets rather than selecting from an existing pool?

8. How robust is the proposed heuristic across different domains beyond just conversational AI? For example, could it be applied to instruction tuning datasets for other downstream tasks?

9. The study utilizes GPT-4 explanations during evaluation. What are some ideas to make the evaluation more robust, for example by combining GPT-4 with human evaluation?  

10. The method outperforms diversity and quality-based selection. Could an ensemble model combining all these selection criteria lead to further improvements? What are some other potential selection criteria to explore?
