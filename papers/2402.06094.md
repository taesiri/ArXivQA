# [Rethinking Data Selection for Supervised Fine-Tuning](https://arxiv.org/abs/2402.06094)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Supervised finetuning (SFT) of large language models (LLMs) is important for aligning them to be helpful to humans. However, SFT is considered superficial, only teaching styles rather than new knowledge.  
- Recent works show that finetuning on subsets of SFT data leads to better performance than using all data. Subset selection strategies focus on quality and diversity.
- But given the superficial nature of SFT, the author questions if quality and diversity should be the focus for data selection.

Proposed Solution: 
- Hypothesize that SFT data selection should focus on instances that reflect human-like styles and interactions.
- As an initial attempt, use a simple heuristic of selecting demonstrations with long responses. The intuition is that if a short response already meets the instruction, a longer version with more detail is more helpful, mimicking human style.

Experiments & Results:
- Finetune LLaMA on 3 datasets - Alpaca, WizardLM, Dolly. Compare models finetuned on full data vs subsets selected based on longest responses, diversity, and quality.
- Selecting longest responses substantially outperforms all baselines across datasets and test sets. For example, on Alpaca test set, longest 1K beats full data by 68% vs 20%.
- Analysis shows models finetuned on longest responses generate more detailed and helpful responses preferred by human evaluation.

Main Contributions:
- Question relevance of existing quality and diversity focused selection strategies for SFT.
- Propose new perspective to select SFT demonstrations reflecting human-like styles. 
- Show that even a simple heuristic of selecting long responses works much better than strong baselines, validating the proposed perspective.
- Shed light on better curating SFT data instead of only selecting from existing pools.

In summary, this paper provides a new way of thinking about data selection for supervised finetuning of LLMs, focusing on human-style demonstrations rather than just quality and diversity. The strong empirical results validate this perspective and highlight the need for better strategies to identify human-like data.
