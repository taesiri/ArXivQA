# [Surfacing Biases in Large Language Models using Contrastive Input   Decoding](https://arxiv.org/abs/2305.07378)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research questions/hypotheses appear to be:1) Can a new decoding strategy called Contrastive Input Decoding (CID) be used to help surface subtle biases and sensitivity to perturbations in large language models (LLMs)?2) Can CID highlight context-specific biases in LLMs that are difficult to detect using standard decoding strategies? 3) Can CID be used to quantify the relative effect of different types of perturbations to LLMs (e.g. syntactic vs semantic)?In particular, the authors propose CID as a way to generate text continuations that are likely under one input but unlikely under a contrastive/perturbed version of that input. By increasing the contrast level, CID aims to reveal differences in how the LLM treats the two inputs. The two main applications explored are:1) Using CID to detect subtle, context-specific biases related to notions like fairness and counterfactual fairness.2) Using CID to quantify the sensitivity of LLMs to different perturbation types, with the goal of testing alignment with user expectations.So in summary, the main research questions focus on whether CID can surface biases and quantify perturbation effects in large language models in order to audit them.


## What is the main contribution of this paper?

The main contribution of this paper is proposing Contrastive Input Decoding (CID), a new decoding strategy for large language models. CID takes as input two sequences - the original input text and a "contrastive" perturbed version. It then generates text that is likely under the original input but unlikely under the contrastive input. The key ideas are:- Modify the next token probabilities during decoding based on the difference between the original and contrastive contexts. Tokens more likely under the original are upweighted, while tokens more likely under the contrastive are downweighted.  - A hyperparameter λ controls the degree of contrasting. Setting λ=0 recovers standard decoding.- Increasing λ surfaces subtle differences in how the language model responds to the two inputs.The authors show two applications of CID:1. Auditing language models for fairness. CID can reveal biases that are hard to detect with standard decoding.2. Quantifying the effect of different input perturbations. CID provides a way to measure the relative impact of various modifications like spelling mistakes or semantic changes.So in summary, the key contribution is proposing CID as a novel decoding algorithm for interpreting differences in language model behavior on contrastive inputs. This facilitates auditing models and understanding their sensitivity to perturbations.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The paper proposes a new decoding method called Contrastive Input Decoding (CID) to generate text continuations for a language model that are likely for one input text but unlikely for a contrastive perturbed version of that text. This allows surfacing subtle differences in how the language model treats the two inputs, which can be used for auditing biases or quantifying the impact of different input perturbations. The key idea is to modify the next-token probabilities during decoding based on the difference between the two inputs.
