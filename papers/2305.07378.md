# [Surfacing Biases in Large Language Models using Contrastive Input   Decoding](https://arxiv.org/abs/2305.07378)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research questions/hypotheses appear to be:1) Can a new decoding strategy called Contrastive Input Decoding (CID) be used to help surface subtle biases and sensitivity to perturbations in large language models (LLMs)?2) Can CID highlight context-specific biases in LLMs that are difficult to detect using standard decoding strategies? 3) Can CID be used to quantify the relative effect of different types of perturbations to LLMs (e.g. syntactic vs semantic)?In particular, the authors propose CID as a way to generate text continuations that are likely under one input but unlikely under a contrastive/perturbed version of that input. By increasing the contrast level, CID aims to reveal differences in how the LLM treats the two inputs. The two main applications explored are:1) Using CID to detect subtle, context-specific biases related to notions like fairness and counterfactual fairness.2) Using CID to quantify the sensitivity of LLMs to different perturbation types, with the goal of testing alignment with user expectations.So in summary, the main research questions focus on whether CID can surface biases and quantify perturbation effects in large language models in order to audit them.
