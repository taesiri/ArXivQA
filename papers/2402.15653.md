# [Low-Frequency Black-Box Backdoor Attack via Evolutionary Algorithm](https://arxiv.org/abs/2402.15653)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Convolutional neural networks (CNNs) are vulnerable to backdoor attacks, where a model is tricked to misclassify images with a specific trigger pattern to a target label.
- Existing backdoor attacks mainly insert triggers in the spatial domain, which may degrade image semantics. Recent frequency domain attacks also introduce artifacts detectable by frequency inspection.
- There lacks a robust backdoor attack that achieves imperceptibility in both spatial and frequency domains, especially in the challenging black-box setting where the attacker has no knowledge of the victim model.

Proposed Solution: 
- The paper proposes a Low-Frequency Black-box Backdoor Attack (LFBA) that inserts minimal perturbations in the low-frequency region of images' frequency spectrum.
- It formulates an optimization problem to search for optimal frequency bands and perturbations that maximize attack effectiveness while minimizing disparities in dual space for stealthiness.  
- Simulated annealing, a gradient-free evolutionary algorithm, is used to solve this optimization without relying on victim model knowledge.

Main Contributions:
- LFBA achieves state-of-the-art attack effectiveness (ASR â‰¥ 99%) and functionality preservation across 5 datasets and 3 CNN models.
- It provides superior spatial and frequency imperceptibility over existing attacks.
- LFBA demonstrates robustness against mainstream backdoor defenses like Neural Cleanse, STRIP, Fine-Pruning, and frequency inspection.
- It is also resilient to image preprocessing operations like filtering and JPEG compression.
- Extensive experiments verify LFBA's effectiveness and robustness in the challenging black-box setting, posing security threats to ML systems.

In summary, the paper explores a new frequency attack surface and proposes an optimization framework to craft robust and stealthy backdoor triggers without model knowledge, highlighted by empirically demonstrated attack performance.
