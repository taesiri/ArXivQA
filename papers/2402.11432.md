# [Can Deception Detection Go Deeper? Dataset, Evaluation, and Benchmark   for Deception Reasoning](https://arxiv.org/abs/2402.11432)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Deception detection is an important capability but suffers from data scarcity issues. Existing datasets have high cost for data collection or difficulty acquiring real-world deceptive content. This limits progress in this field.

Solution:
- Proposes using GPT-4 to automatically generate mock dialogues between a suspect and police officer containing lies/deception. 
- Extracts key "target content" and "actions" from legal case documents to provide context. The suspect gets complete info, police officer gets incomplete.
- Generates 191 dialogues through role-play interrogation. Creates reasoning questions to assess deception detection abilities.  

Contributions:
- Provides low-cost way to construct deception detection dialog dataset using GPT-4 without real human data.
- Extends deception detection to deception reasoning, requiring models to provide explanations to support judgments.
- Defines multi-faceted evaluation metrics: accuracy, completeness, logic, depth.
- Tests 11 LLMs on new benchmark. GPT-4 performs best, demonstrating strong reasoning abilities.
- Framework allows generating wide variety of unseen dialogues to mitigate test data leakage issues in LLM evaluation.
- Overall, paper explores an automatic approach to create reasoning-focused deception detection datasets to further advance research in this area.
