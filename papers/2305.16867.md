# Playing repeated games with Large Language Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How do large language models (LLMs) behave in interactive social settings, specifically when playing repeated games against each other and human-like strategies? The authors use behavioral game theory to study LLMs' cooperation and coordination behaviors by having them play various two-player, two-action repeated games. The key hypothesis appears to be that analyzing LLMs' performance across different game families can uncover persistent behavioral signatures related to selfishness, unforgivingness, and lack of coordination. The paper seems focused on elucidating these behavioral tendencies of LLMs through game theoretic analyses.


## What is the main contribution of this paper?

The main contribution of this paper is using behavioral game theory to study the cooperation, coordination, and social behavior of large language models (LLMs) like GPT-3, GPT-3.5, and GPT-4. Specifically, the authors:- Let LLMs play iterated 2x2 games against each other and simple strategies, focusing on games from different families like Prisoner's Dilemma and Battle of the Sexes.- Found LLMs perform well in games valuing self-interest like Prisoner's Dilemma but underperform in coordination games like Battle of the Sexes. - Analyzed GPT-4's behavior in depth, finding it acts selfishly/unforgivingly in Prisoner's Dilemma but fails to coordinate with simple alternating strategies in Battle of the Sexes.- Showed GPT-4's behavior can be improved by providing information about the other player and prompting predictions before actions.Overall, the paper demonstrates using game theory to systematically study LLMs' interactive behavior, shedding light on strengths, flaws, and ways to improve alignment with human conventions. It lays groundwork for a behavioral game theory approach to analyzing machine social intelligence.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The paper investigates the behavior of large language models like GPT-3 and GPT-4 in repeated social interactions modeled as game theory games. It finds strengths in competitive games but deficiencies in coordination, with specific behavioral signatures like unforgivingness in the Prisoner's Dilemma and failure to establish conventions in the Battle of the Sexes. Overall, the work demonstrates the utility of behavioral game theory for understanding the social abilities and flaws of large language models.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in the field of studying the behavior of large language models:- The use of game theory and behavioral economics experiments to study LLMs is relatively novel. Most prior work has focused on benchmarking LLMs on standard NLP tasks or studying their abilities in more open-ended ways. Using well-defined games allows for more controlled study of interactive behaviors.- The focus on repeated games rather than one-shot games is important. Studying iterated interactions provides insights into how LLMs develop conventions and adapt over time, rather than just reacting to a single scenario.- Analyzing a broad set of 2x2 games gives a more comprehensive view of strengths/weaknesses compared to just looking at one game like Prisoner's Dilemma or Battle of the Sexes. The large-scale analysis highlights areas LLMs do well at like self-interest games as well as struggles like coordination.- The direct comparison to simple heuristic strategies reveals flaws in LLM behavior. Even alternating in Battle of the Sexes is challenging, indicating issues in adapting to opponents. This goes beyond just evaluating overall performance.- The paper builds on prior work studying social reasoning in LLMs using theory of mind tasks. The games provide another angle to evaluate capabilities and limitations related to modeling others.- The robustness checks on prompt variations are important to verify the results reflect intrinsic behaviors rather than prompt engineering. This helps strengthen the claims made about behavioral signatures.Overall, the use of game theory provides a new lens for studying LLMs through interactive tasks with precise payoffs and equilibria. The results illuminate both impressive strategic capabilities of modern LLMs as well as areas where human-like conventions and theory of mind remain lacking. More research building on this paradigm could further deepen our understanding of the social cognition of LLMs.
