# [Fairness in Serving Large Language Models](https://arxiv.org/abs/2401.00588)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
This paper studies the problem of fair serving in Large Language Models (LLMs). LLM inference services like ChatGPT need to serve a wide range of client requests concurrently. To ensure all clients are treated fairly, most LLM services impose simple request rate limits per client. However, this can result in under-utilization of resources when spare capacity exists. On the other hand, traditional fair queueing algorithms used in networking cannot be directly applied due to unique characteristics of LLM serving: unpredictable request lengths, variable cost per token, and variable server capacity over time.

Solution:
The paper first defines fairness for LLM serving based on a cost function that captures both number of input tokens (parallelizable) and output tokens (sequential) processed. It then proposes a novel scheduling algorithm called Virtual Token Counter (VTC) to achieve fairness. 

VTC maintains a virtual counter for each client tracking cumulative service received. It prioritizes clients with lower counters when adding new requests, with a counter lift when a client becomes newly backlogged. Counters are updated on-the-fly at token granularity. This allows seamless integration with the continuous batching mechanism commonly used in LLM systems, addresses unpredictable output lengths, and adapts to fluctuating server capacity.

Contributions:
- Identifies unique challenges for fair scheduling in LLM serving and provides a configurable definition of fairness based on a cost function.

- Develops VTC, a simple yet effective token-based fair scheduling algorithm tailored to LLM serving systems.

- Provides rigorous proofs that VTC ensures max-min fairness for backlogged clients within 2x of optimal bound and isolation for non-backlogged clients sending under capacity.

- Evaluates VTC extensively under synthetic and real-world workloads. Results demonstrate superior fairness over baselines while maintaining high resource utilization.
