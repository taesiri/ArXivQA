# [Video is All You Need: Attacking PPG-based Biometric Authentication](https://arxiv.org/abs/2203.00928)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can remote photoplethysmography (rPPG) signals extracted from video clips be used to spoof photoplethysmography (PPG)-based biometric authentication systems? The authors pose this question because PPG signals collected from wearable devices are increasingly being used for biometric authentication, under the assumption that they are difficult for remote adversaries to obtain. However, recent advances in rPPG allow an adversary to extract PPG signals from videos of a person's face. The authors investigate whether these rPPG signals can be used to spoof PPG-based biometric systems.To address this question, the authors:1) Propose a new method (called SigR) to restore rPPG signals extracted from videos to match the victim's real PPG signals.2) Evaluate the effectiveness of using the restored rPPG signals to spoof a state-of-the-art PPG-based biometric authentication system.3) Analyze the impact of different video quality factors (frame rate, resolution, etc) on the success rate of the spoofing attack.So in summary, the central hypothesis is that rPPG signals from video can be restored and used to spoof PPG-based biometric authentication, which the authors evaluate through both signal analysis and spoofing attack experiments.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a novel spoofing attack on PPG-based biometric authentication using only video clips of the victim's face. This is the first attack that uses video to spoof PPG-based authentication without requiring any leaked PPG signals from the victim. 2. It develops a new PPG signal restoration model called SigR to accurately restore rPPG signals extracted from videos to PPG signals. SigR uses a generative adversarial network (GAN) architecture to learn the mapping from rPPG to PPG.3. It evaluates the effectiveness of the attack using the UBFC-PHYS dataset with videos of subjects in different states (resting, talking, calculating). The attack achieves high false acceptance rates, with the best attack success rate of 0.62 using SigR.4. It analyzes the impact of various video quality factors like frame rate, resolution, bit rate, and beauty filter on the attack success rate. The results show rPPG signals can still pose a threat even with degraded video quality.In summary, this paper demonstrates the vulnerability of PPG-based authentication to spoofing attacks using just video data, made possible by the new rPPG restoration model SigR. It highlights the need for defensive strategies to protect against such video-based spoofing attacks on PPG authentication systems.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key point of the paper:The paper proposes a novel spoofing attack using only video clips to fool PPG-based biometric authentication by restoring rPPG signals extracted from videos to spoof PPG signals.


## How does this paper compare to other research in the same field?

Here are some key points comparing this paper to other research on attacks against PPG-based biometric authentication:- It proposes the first attack using only video clips of a victim's face, without needing access to actual PPG signals. Previous attack methods required obtaining leaked PPG signals from the victim through close physical contact.- The paper introduces a new signal restoration method called SigR to convert rPPG signals extracted from videos into PPG signals. This allows spoofing the authentication system. Prior work has not focused on accurately restoring the waveform morphology. - Experiments show the attack is effective across different victim states (resting, talking, calculating), achieving higher false acceptance rates than random attacks. Previous attacks were limited by requiring specific victim conditions.- The study evaluates how different video quality factors like frame rate, resolution, etc. impact attack success rates. This provides new insight on mitigation strategies by controlling video quality. - Limitations are that it relies on a single public dataset which may not generalize fully. Defenses like adding authentication steps or degrading video quality could deter the attack.Overall, this paper makes notable contributions in demonstrating serious vulnerabilities of PPG-based authentication to remote video-based spoofing. The novel restoration method and thorough experiments advance knowledge in this emerging area of biometric security threats. More research is still needed to develop effective countermeasures.


## What future research directions do the authors suggest?

Based on my reading of the paper, here are some of the future research directions suggested by the authors:- Train the PPG signal restoration model (SigR) on more high-quality datasets to improve its ability to generalize across different camera parameters, shooting distances, lighting conditions, etc. The results in the paper are derived from just one dataset (UBFC-PHYS) so expanding the training data could improve performance.- Experiment with more video clips captured under different conditions to keep improving the restoration model. The scope of this paper limited testing to just the UBFC-PHYS dataset. - Evaluate the attack on more complex PPG-based biometric authentication systems. The authentication system used in the experiments is relatively simple, so testing on more sophisticated systems could reveal new insights.- Consider defensive strategies like adding an authentication component before the biometric system, restricting access to high quality video of potential victims, and processing released videos with filters to mitigate leaking rPPG signals. This could help estimate the effectiveness of countermeasures.- Explore how factors like compressed video, occlusion, illumination changes etc. affect the attack success rate. The impact of video quality is tested but other factors could also be influential.- Examine combining the restored PPG signal with synthesized PPG signals to try to further improve attack performance. The current attack uses just the restored signal.- Investigate using the attack framework on other unobservable physiological signals that could be remotely estimated like EEG. This would demonstrate if the threat extends beyond just PPG signals.So in summary, the authors suggest enhancements to the signal restoration model, testing on more diverse and complex conditions, evaluating defensive strategies, and extending the attack approach to other modalities as interesting future work.


## Summarize the paper in one paragraph.

The paper proposes a novel spoofing attack against PPG-based biometric authentication using only video clips of the victim's face. The key idea is to extract remote PPG (rPPG) signals from the face video and restore them to match the victim's actual PPG signals that would be used for authentication. A new generative model called SigR is developed to restore the rPPG signals into PPG signals. Experiments on a dataset with subjects in different states ('resting', 'talking', 'calculating') show the attack is effective, with restored signals achieving over 60% attack success rate. The impact of video quality factors like frame rate, resolution, bitrate, and beauty filter is also analyzed. The study demonstrates rPPG poses a severe threat to PPG-based authentication, and the proposed restoration model significantly amplifies this threat. Defensive strategies like protecting HD video of users and adding authentication components are recommended.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the key points from the paper:The paper proposes a novel spoofing attack against PPG-based biometric authentication using only a video clip of the victim's face. PPG signals from wearable devices are increasingly used for biometric authentication due to their distinctiveness and unobservability. However, remote PPG (rPPG) extraction from videos allows adversaries to obtain PPG signals without physical contact. The authors develop a new PPG restoration model called SigR that converts rPPG signals from videos to PPG signals for spoofing authentication systems. SigR uses a GAN architecture to learn the relationship between rPPG and PPG signals and accurately restores rPPG waveforms to PPG waveforms. Experiments on the UBFC-PHYS dataset show the attack is highly effective, with over 60% false acceptance rate using restored signals. The attack works for videos in different states (resting, talking, calculating) and is robust to variations in video quality. The results demonstrate rPPG signals pose a severe threat to PPG-based authentication. The authors recommend defenses like adding authentication components, restricting video quality, and using beauty filters when releasing videos to mitigate such spoofing attacks. Overall, the work presents the first feasible spoofing attack on PPG-based biometrics using only public videos of a victim's face.
