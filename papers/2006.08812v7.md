# [Augmented Sliced Wasserstein Distances](https://arxiv.org/abs/2006.08812v7)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

How to develop an efficient and flexible distance metric between probability distributions that can capture complex structures of high-dimensional data? 

The key points are:

- The paper proposes a new family of distance metrics called augmented sliced Wasserstein distances (ASWDs). 

- The ASWD is constructed by first mapping samples to higher-dimensional hypersurfaces parameterized by neural networks. This enables flexible nonlinear slicing of data distributions.

- The hypersurfaces can be optimized efficiently by gradient ascent to project samples onto discriminating hypersurfaces, where different distributions have significantly different values. 

- The paper proves that the ASWD is a valid metric under certain conditions and shows how injective neural networks can be used to meet those conditions.

- Experiments demonstrate that the ASWD significantly outperforms other Wasserstein variants on both synthetic and real-world problems in terms of efficiency and accuracy.

In summary, the central hypothesis is that augmenting the sliced Wasserstein distance with learned nonlinear projections can lead to an efficient and flexible distance metric for comparing complex high-dimensional distributions. The ASWD is proposed as a method to achieve this.
