# [Imbalanced Adversarial Training with Reweighting](https://arxiv.org/abs/2107.13639)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research questions/hypotheses appear to be:1) How does adversarial training behave under imbalanced training data scenarios, compared to natural training? 2) Can existing imbalanced learning strategies like reweighting be directly applied to improve adversarial training under imbalanced data?3) What causes the poor performance of adversarial training with reweighting under imbalanced data? 4) Can modifying adversarial training to learn more separable features facilitate reweighting and improve performance on imbalanced data?The authors first empirically show that adversarial training suffers more on under-represented classes compared to natural training when trained on imbalanced data. They also find that simply applying reweighting strategies from natural training to adversarial training does not work well. To explain these observations, the authors theoretically analyze linear classifiers and show that poor data separability can lead reweighting to hurt performance on over-represented classes. Based on this analysis, the authors propose Separable Reweighted Adversarial Training (SRAT) which adds a feature separation loss to enable reweighting to work better for adversarial training under imbalance. Experiments validate the effectiveness of SRAT.In summary, the main goal is to understand the issues with adversarial training on imbalanced data and develop an effective algorithm to address them. The theoretical analysis provides justification for the proposed SRAT method.
