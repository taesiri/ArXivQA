# [Imbalanced Adversarial Training with Reweighting](https://arxiv.org/abs/2107.13639)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research questions/hypotheses appear to be:1) How does adversarial training behave under imbalanced training data scenarios, compared to natural training? 2) Can existing imbalanced learning strategies like reweighting be directly applied to improve adversarial training under imbalanced data?3) What causes the poor performance of adversarial training with reweighting under imbalanced data? 4) Can modifying adversarial training to learn more separable features facilitate reweighting and improve performance on imbalanced data?The authors first empirically show that adversarial training suffers more on under-represented classes compared to natural training when trained on imbalanced data. They also find that simply applying reweighting strategies from natural training to adversarial training does not work well. To explain these observations, the authors theoretically analyze linear classifiers and show that poor data separability can lead reweighting to hurt performance on over-represented classes. Based on this analysis, the authors propose Separable Reweighted Adversarial Training (SRAT) which adds a feature separation loss to enable reweighting to work better for adversarial training under imbalance. Experiments validate the effectiveness of SRAT.In summary, the main goal is to understand the issues with adversarial training on imbalanced data and develop an effective algorithm to address them. The theoretical analysis provides justification for the proposed SRAT method.


## What is the main contribution of this paper?

The main contribution of this paper seems to be proposing a novel framework called Separable Reweighted Adversarial Training (SRAT) to improve the performance of adversarial training on imbalanced datasets. Specifically, the key ideas and contributions are:- Conducted preliminary studies to show that standard adversarial training performs poorly on imbalanced datasets, with very low accuracy on under-represented classes.- Showed that simply applying common reweighting strategies from imbalanced learning to adversarial training is ineffective, as it creates a strong tension between performance on under-represented vs well-represented classes.- Provided theoretical analysis to show that poor separability of learned features is a key reason for the ineffectiveness of reweighting in adversarial training. - Proposed the SRAT framework to improve feature separability in adversarial training via an added separation loss term. This facilitates more effective reweighting.- Demonstrated through experiments on multiple imbalanced image datasets that SRAT improves accuracy on under-represented classes and overall robustness compared to baseline adversarial training methods.So in summary, the main novelty is identifying the issue of poor feature separability in adversarial training on imbalanced data, and addressing it with the proposed SRAT framework to enable more effective reweighting.


## How does this paper compare to other research in the same field?

This paper proposes a novel method called Separable Reweighted Adversarial Training (SRAT) to handle class imbalance in adversarial training. Compared to prior work, it makes the following key contributions:- Investigates the challenges of applying standard adversarial training to imbalanced datasets. The empirical studies reveal that adversarial training suffers from much lower accuracy on underrepresented classes compared to natural training. - Provides theoretical analysis on why reweighting strategies commonly used in imbalanced learning do not work well for adversarial training. The analysis shows that the poor separability of learned features is a key reason.- Proposes the SRAT framework to enable reweighting in adversarial training by enhancing feature separability. It incorporates a supervised contrastive loss to encourage more separable feature learning.- Achieves improved accuracy on underrepresented classes and overall robustness over strong baselines on multiple imbalanced image datasets. The gains are especially significant on highly imbalanced data.Overall, this paper offers new insights into the distinct behaviors of adversarial training on imbalanced data. The proposed SRAT framework guided by theoretical understanding is shown to be an effective solution.Compared to prior work on adversarial training and imbalanced learning, this paper is unique in studying their intersection and adapting adversarial training for imbalanced data. The analysis of poor feature separability and solution of enhancing it are novel. The empirical verification on multiple datasets also goes beyond most existing work.


## What future research directions do the authors suggest?

Based on my reading of the paper, some key future research directions suggested by the authors include:- Investigating how other types of defense methods like certified robustness perform under imbalanced datasets. The authors mainly focused on studying adversarial training, so examining other defense strategies would provide more comprehensive understanding.- Exploring how other balanced learning strategies like oversampling and undersampling behave when integrated into adversarial training. The authors primarily studied reweighting, so looking at other techniques could offer additional insights. - Extending the theoretical analysis to non-linear models and more complex data distributions beyond Gaussian mixtures. The current analysis is limited to linear models and simple Gaussian data. Expanding the theory could make it more applicable to real-world deep neural networks and datasets. - Considering multi-class imbalanced classification scenarios. Much of the empirical and theoretical study was constrained to binary classification, so scaling up to multiple imbalanced classes is an important next step.- Evaluating the proposed method on larger benchmark datasets like ImageNet. The experiments were on smaller datasets like CIFAR-10, so testing on bigger and more complex data would better validate the approach.- Investigating other potential solutions that could facilitate reweighting for adversarial training under imbalance, beyond just enhancing feature separability. There may be other complementary techniques worth exploring as well.- Comparing adversarial training combined with common oversampling/undersampling strategies against the proposed reweighting approach. This could reveal which strategy works best for imbalance in adversarial training.So in summary, the main future work suggested is broadening the study to other defense methods, data distributions, network architectures, and imbalance learning techniques, as well as more extensive empirical validation on larger datasets. Advancing the theoretical understanding is also highlighted as an important direction for future investigation.
