# [Imbalanced Adversarial Training with Reweighting](https://arxiv.org/abs/2107.13639)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research questions/hypotheses appear to be:1) How does adversarial training behave under imbalanced training data scenarios, compared to natural training? 2) Can existing imbalanced learning strategies like reweighting be directly applied to improve adversarial training under imbalanced data?3) What causes the poor performance of adversarial training with reweighting under imbalanced data? 4) Can modifying adversarial training to learn more separable features facilitate reweighting and improve performance on imbalanced data?The authors first empirically show that adversarial training suffers more on under-represented classes compared to natural training when trained on imbalanced data. They also find that simply applying reweighting strategies from natural training to adversarial training does not work well. To explain these observations, the authors theoretically analyze linear classifiers and show that poor data separability can lead reweighting to hurt performance on over-represented classes. Based on this analysis, the authors propose Separable Reweighted Adversarial Training (SRAT) which adds a feature separation loss to enable reweighting to work better for adversarial training under imbalance. Experiments validate the effectiveness of SRAT.In summary, the main goal is to understand the issues with adversarial training on imbalanced data and develop an effective algorithm to address them. The theoretical analysis provides justification for the proposed SRAT method.


## What is the main contribution of this paper?

The main contribution of this paper seems to be proposing a novel framework called Separable Reweighted Adversarial Training (SRAT) to improve the performance of adversarial training on imbalanced datasets. Specifically, the key ideas and contributions are:- Conducted preliminary studies to show that standard adversarial training performs poorly on imbalanced datasets, with very low accuracy on under-represented classes.- Showed that simply applying common reweighting strategies from imbalanced learning to adversarial training is ineffective, as it creates a strong tension between performance on under-represented vs well-represented classes.- Provided theoretical analysis to show that poor separability of learned features is a key reason for the ineffectiveness of reweighting in adversarial training. - Proposed the SRAT framework to improve feature separability in adversarial training via an added separation loss term. This facilitates more effective reweighting.- Demonstrated through experiments on multiple imbalanced image datasets that SRAT improves accuracy on under-represented classes and overall robustness compared to baseline adversarial training methods.So in summary, the main novelty is identifying the issue of poor feature separability in adversarial training on imbalanced data, and addressing it with the proposed SRAT framework to enable more effective reweighting.


## How does this paper compare to other research in the same field?

This paper proposes a novel method called Separable Reweighted Adversarial Training (SRAT) to handle class imbalance in adversarial training. Compared to prior work, it makes the following key contributions:- Investigates the challenges of applying standard adversarial training to imbalanced datasets. The empirical studies reveal that adversarial training suffers from much lower accuracy on underrepresented classes compared to natural training. - Provides theoretical analysis on why reweighting strategies commonly used in imbalanced learning do not work well for adversarial training. The analysis shows that the poor separability of learned features is a key reason.- Proposes the SRAT framework to enable reweighting in adversarial training by enhancing feature separability. It incorporates a supervised contrastive loss to encourage more separable feature learning.- Achieves improved accuracy on underrepresented classes and overall robustness over strong baselines on multiple imbalanced image datasets. The gains are especially significant on highly imbalanced data.Overall, this paper offers new insights into the distinct behaviors of adversarial training on imbalanced data. The proposed SRAT framework guided by theoretical understanding is shown to be an effective solution.Compared to prior work on adversarial training and imbalanced learning, this paper is unique in studying their intersection and adapting adversarial training for imbalanced data. The analysis of poor feature separability and solution of enhancing it are novel. The empirical verification on multiple datasets also goes beyond most existing work.
