# [Small Models, Big Insights: Leveraging Slim Proxy Models To Decide When   and What to Retrieve for LLMs](https://arxiv.org/abs/2402.12052)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) sometimes produce incorrect or hallucinated content despite being trained on large datasets. Integrating retrieval systems with LLMs has been proposed to provide them with relevant external knowledge and improve reliability. 

- However, determining when retrieval is necessary vs when the LLM already knows the answer is challenging. Existing solutions either fine-tune the LLM, which is computationally expensive, or assess retrieval need based on preliminary LLM outputs, which increases inference costs.

Proposed Solution:
- This paper proposes SlimPLM, which employs a smaller "proxy" LLM to generate a preliminary "heuristic" answer to judge the retrieval need. 

- If proxy model's quality is high, retrieval may not be needed. If not, the heuristic answer is decomposed into distinct claims which are used to query only the missing knowledge.

Main Contributions:
- Proposes using a slim proxy LLM to perceive LLM knowledge gaps and guide selective retrieval, avoiding full fine-tuning or multiple inferences of the LLM itself.

- Devises query rewriting method based on decomposing heuristic answer into factual claims related to the question. Rewritten queries undergo further filtering to improve retrieval relevance.

- Achieves superior performance over baselines on five QA datasets while notably reducing computational overhead of determining and performing retrieval. Validates feasibility and effectiveness of proxy model approach.

In summary, the key innovation is using a smaller proxy model to guide targeted knowledge retrieval for large models, increasing efficiency and reliability. The claim decomposition and filtering mechanisms also help improve retrieval quality.
