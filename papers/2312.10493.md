# [Debiasing Multimodal Sarcasm Detection with Contrastive Learning](https://arxiv.org/abs/2312.10493)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Existing multimodal sarcasm detection (MSD) models rely heavily on textual cues and overlook spurious correlations between words and labels, limiting their generalization ability. 
- The paper defines a new out-of-distribution (OOD) MSD task to evaluate model generalization under different training/testing word distributions.

Proposed Solution: 
- A novel debiasing MSD framework (DMSD-CL) with contrastive learning to mitigate reliance on superficial word biases.
- It has two key components:
   1) Counterfactual data augmentation to construct positive/negative sample pairs with dissimilar/similar word biases but same/opposite labels.
   2) Adapted debiasing contrastive learning to discriminate samples based on task-relevant semantics rather than biased words.

Main Contributions:
- Formalizes the novel OOD MSD problem to assess model generalization.
- Develops the DMSD-CL framework to debias MSD models via contrastive learning.
   - Devises tailored augmentation strategies for sarcastic/non-sarcastic samples.
   - Employs a re-weighted contrastive loss to focus on challenging samples.
- Constructs a new OOD testing set based on an existing MSD dataset.
- Experiments show DMSD-CL outperforms state-of-the-art methods on both IID and OOD settings.
   - Ablations validate the utility of individual framework components.

In summary, the paper tackles the issue of superficial word bias in MSD by proposing a novel debiasing framework DMSD-CL using contrastive learning and counterfactual augmentation. Experiments demonstrate its effectiveness for generalization under distribution shift.
