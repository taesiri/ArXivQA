# [U-MixFormer: UNet-like Transformer with Mix-Attention for Efficient   Semantic Segmentation](https://arxiv.org/abs/2312.06272)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes U-MixFormer, a novel UNet-like transformer decoder architecture for efficient semantic image segmentation. The key idea is to leverage the inherent strengths of the UNet architecture to capture and propagate hierarchical visual features, while also benefiting from the global contextual modeling capabilities of transformers through a unique mix-attention mechanism. Specifically, U-MixFormer utilizes lateral connections from the encoder as queries to the decoder attention modules, while mixing multi-scale encoder and decoder features as keys/values to enable refined segmentation. This allows combining high-level semantics with low-level spatial details. The mix-attention module is shown to be more effective than self- and cross-attention designs. Experiments on ADE20K and Cityscapes datasets demonstrate state-of-the-art trade-offs between accuracy and efficiency. For example, U-MixFormer-B0 outperforms SegFormer-B0 by 3.8% better mIoU on ADE20K while using 27.3% less computation. Additional ablation studies highlight the benefits of the mix-attention and UNet-like architecture. Thus, U-MixFormer sets a new state-of-the-art for transformer-based semantic segmentation.
