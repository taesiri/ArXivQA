# [Linking Emergent and Natural Languages via Corpus Transfer](https://arxiv.org/abs/2203.13344)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we effectively link emergent and natural languages to enable transfer of knowledge between them?Specifically, the authors aim to investigate whether an emergent language developed through a referential game can provide beneficial transfer to downstream natural language tasks like language modeling and image captioning. They propose and explore a novel corpus transfer approach, where they pretrain models on a corpus of emergent language messages before fine-tuning on natural language data. The key hypotheses seem to be:1) Emergent languages developed through grounded multi-agent communication can provide non-trivial benefits when transferred to natural language tasks, especially in low-resource scenarios.2) Corpus-level transfer is more effective than transfer at the level of emergent communication agents.3) Translation from emergent to natural language provides a better measure of emergent language quality than metrics based on game accuracy or topological similarity.So in summary, the central research question is whether and how emergent and natural languages can be effectively linked to enable mutually beneficial transfer, with a focus on corpus-level transfer and translation-based evaluation of emergent languages. The authors aim to bridge the gap between emergent communication research and natural language processing.


## What is the main contribution of this paper?

Based on the abstract, it seems this paper proposes a novel method to link emergent and natural languages by using corpus transfer, i.e. pretraining a model on a corpus of emergent language from a referential game for downstream natural language tasks like language modeling and image captioning. The key contributions appear to be:- Showing that pretraining on an emergent language corpus can provide non-trivial benefits for downstream natural language tasks, especially in low-resource setups. For example, pretraining on 2 million emergent tokens reduces perplexity by 24.6% on average for modeling 10 different languages with only 2 million natural tokens each.- Proposing a new emergent-to-natural language translation metric to evaluate emergent languages, and showing it correlates better with downstream performance than common in-game metrics like accuracy and topographic similarity.- Demonstrating that corpus transfer is more effective for transferring emergent languages compared to directly transferring trained EC model parameters as in prior work.- Highlighting the potential of leveraging natural language resources and models to improve emergent communication research, instead of focusing only on synthetic setups.In summary, the key contribution seems to be presenting corpus transfer as a novel paradigm to link emergent and natural languages for mutual benefits, supported by experiments showing non-trivial transfer results and analysis into what properties contribute to transferability.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other research in the field of emergent communication:- This paper proposes a new approach of evaluating emergent languages by transferring them to natural language tasks, rather than just analyzing properties within the communication game itself. Most prior work focuses on in-game metrics like accuracy or attribute disentanglement. This allows for assessing emergent languages in terms of real-world usefulness.- The paper shows that an emergent language corpus can help pre-train models for natural language tasks, especially in low-resource settings. This provides evidence that emergent languages can transfer outside of the game they are developed in. Prior work has not extensively explored such out-of-game transfer.- The paper introduces a new metric based on emergent-to-natural language translation, and shows it better correlates with transfer performance than game accuracy or topographic similarity. This challenges common assumptions on what properties of emergent languages are most important.- The approach relies on standard natural language resources (e.g. Wikipedia corpora) and models (e.g. Transformers). Many prior emergent communication studies use synthetic environments and simple recurrent models. This work demonstrates the potential benefits of leveraging advanced NLP techniques.- Overall, the core idea of directly linking emergent and natural languages is novel. The paper makes good progress toward bridging the gap between the emergent communication and natural language processing fields. Evaluating based on natural language tasks and models could become a paradigm shift.In summary, this paper pushes emergent communication research to go beyond in-game metrics and synthetic setups, toward more standardized evaluations grounded in real language data and tasks. It opens up many new directions at the intersection of emergent communication and natural language processing.
