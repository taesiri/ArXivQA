# [Jumping through Local Minima: Quantization in the Loss Landscape of   Vision Transformers](https://arxiv.org/abs/2308.10814)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research question it addresses is:

How can we effectively quantize vision transformer (ViT) models to very low bitwidths (e.g. 3-4 bits) while maintaining high accuracy?

The key hypotheses behind their proposed method, Evol-Q, seem to be:

- Small perturbations in quantization scales can lead to significant improvements in quantized ViT accuracy.

- Quantized ViTs have an extremely non-smooth loss landscape with respect to these perturbations, making gradient-based optimization ineffective. 

- Evolutionary search can effectively traverse this non-smooth landscape to find improved quantization scales.

- Using an infoNCE loss helps smooth the landscape and prevents overfitting during the evolutionary search.

So in summary, the central research question is how to effectively quantize ViTs to very low bitwidths. The key hypotheses are that evolutionary search with an infoNCE loss can handle the non-smooth landscape and lead to optimized quantization scales and accuracy.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a new method called Evol-Q for post-training quantization of vision transformers (ViTs). The key ideas are:

- Small perturbations in quantization scales can lead to significant improvements in accuracy for low-bit quantized ViTs (e.g. 4-bit). 

- ViTs have a highly non-smooth loss landscape with respect to quantization scales, making gradient-based methods ineffective.

- Evolutionary search is used to effectively traverse the non-smooth landscape and find good quantization scales.

- An infoNCE loss is used to evaluate quantization scales during search. This helps prevent overfitting to the small calibration set and makes the loss landscape smoother.

- Experiments show Evol-Q improves accuracy significantly over prior methods on a variety of ViT models for extreme quantization schemes like 4-bit and 3-bit weights.

In summary, the main contribution is proposing Evol-Q, an evolutionary search based method to optimize quantization scales for low-bit ViTs by leveraging the observations around the non-smooth loss landscape and effects of small perturbations.
