# [Beyond Scale: the Diversity Coefficient as a Data Quality Metric   Demonstrates LLMs are Pre-trained on Formally Diverse Data](https://arxiv.org/abs/2306.13840)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the key research questions and hypotheses appear to be:1) How can we quantify the diversity of Large Language Model (LLM) pre-training datasets in a formal and grounded way? The paper proposes using the Task2Vec diversity coefficient as a metric to quantify the diversity of LLM pre-training datasets. This provides a concrete way to measure the diversity of datasets instead of relying on vague notions of diversity.2) Are publicly available LLM pre-training datasets formally diverse based on the diversity coefficient metric? The paper hypothesizes that publicly available LLM pre-training datasets (e.g. C4, WikiText-103, The Pile) exhibit high diversity coefficients compared to conceptually motivated lower and upper bounds. This would indicate that the datasets are formally diverse.3) Does the diversity coefficient align with intuitive properties and expected trends of a dataset diversity metric?The paper conducts experiments to validate that the diversity coefficient increases in intuitive ways, such as when concatenating multiple datasets, increasing the number of latent concepts, and using a larger vocabulary. This builds confidence that the diversity coefficient reliably captures properties of data diversity.In summary, the central goals are to propose the diversity coefficient as a formal grounded metric for dataset diversity, demonstrate it indicates existing LLM pre-training datasets are highly diverse, and validate that the metric aligns with intuitive notions of diversity. Quantifying diversity could enable more systematic data curation for capable LLM pre-training.
