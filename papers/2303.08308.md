# [SpaceEvo: Hardware-Friendly Search Space Design for Efficient INT8   Inference](https://arxiv.org/abs/2303.08308)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

How can we automatically design a hardware-friendly search space for efficient INT8 inference that produces neural network models with high accuracy and low latency on real-world edge devices?

The key hypothesis is that directly applying NAS (neural architecture search) with existing manually designed search spaces leads to poor performance for INT8 quantized models on edge devices. This is due to the diverse quantization efficiency of different operators and configurations, as well as hardware-specific preferences. 

To address this, the authors propose a method called SpaceEvo to automatically design specialized quantization-friendly search spaces for target hardware. The goal is to discover hardware-preferred operators and configurations to construct the search space, guided by a metric called Q-T score that quantifies how quantization-friendly a search space is. This allows NAS to find larger and superior quantized models that achieve both high accuracy and low INT8 latency for efficient deployment.

In summary, the paper aims to address the limitations of using existing NAS techniques and search spaces directly for finding efficient quantized models, by automatically designing hardware-aware quantization-friendly search spaces. The key hypothesis is that this approach will produce models with better accuracy-latency trade-offs on real devices compared to prior NAS methods.
