# [TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and   logical intermediate representations](https://arxiv.org/abs/2402.06608)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
The paper studies the problem of automatically generating plans from natural language descriptions of planning tasks. While large language models (LLMs) excel at natural language processing, they do not perform well at planning tasks that require finding a sequence of actions to achieve a goal state. On the other hand, classical planners are very effective at planning but require the planning task to be specified in a structured language like PDDL. 

Proposed Solution - Translate-Infer-Compile (TIC):
The paper proposes a three-step approach called Translate-Infer-Compile (TIC) that combines the strengths of LLMs and classical planners:

1. Translate: Use an LLM to translate the natural language description into an intermediate logical representation that captures facts, rules and constraints. This results in fewer errors compared to using an LLM to directly generate PDDL.

2. Infer: Use a logical reasoner like Answer Set Programming (ASP) to deterministically infer additional logically dependent facts from the intermediate representation and domain knowledge. This results in a materialized representation.

3. Compile: Transform the materialized representation into target PDDL that can be input to a classical planner.

By decomposing the end-to-end process, TIC is able to achieve high accuracy in generating task PDDLs across seven planning benchmark domains.

Main Contributions:
- Introduction of an intermediate logical representation that bridges the gap between natural language and target PDDL
- Using logical reasoning to augment and validate information extracted by LLMs
- Demonstrating high accuracy in task PDDL generation across multiple planning domains
- Evaluating two approaches for generating intermediate representations - using in-context examples vs. generic prompts

The TIC approach combines strengths of both neural and symbolic methods to address a complex language-to-code generation problem with competitive results. The modular architecture also makes it adaptable to other structured task specifications beyond PDDL.


## Summarize the paper in one sentence.

 This paper proposes the Translate-Infer-Compile (TIC) approach that leverages large language models to translate natural language planning tasks to logical intermediate representations, then infers additional logical facts, and finally compiles formal planning problem descriptions to enable efficient and accurate planning with classical planners.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing the Translate-Infer-Compile (TIC) approach for generating accurate task PDDLs automatically from natural language planning task descriptions. The key ideas of TIC are:

1) Introducing an intermediate logical representation of the natural language task description that captures the information present in the description without needing to generate all facts required in the final task PDDL. This allows leveraging the strength of LLMs for translation while reducing LLM errors.

2) Using a logical reasoner and domain knowledge rules to infer additional facts from the intermediate representation to generate a complete materialized representation containing all information needed in the task PDDL. This allows deterministic and accurate inference of logically dependent information. 

3) Compiling the final target task PDDL from the materialized representation.

The paper shows experimentally that by combining strengths of LLMs and logical reasoning, the TIC approach achieves high accuracy in generating task PDDLs across multiple planning domains. The approach also generalizes well to variations in the language of task descriptions.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Large language models (LLMs): The paper discusses using large language models like GPT-3 and PaLM-2 for natural language understanding and generation.

- Classical planning: The paper compares LLMs to classical planning techniques for generating plans to achieve specified goals. Concepts like planning domains, Planning Domain Definition Language (PDDL), and classical planners are discussed.

- Intermediate representations: A key idea in the paper is generating a logical intermediate representation of natural language planning tasks that can be reasoned over and compiled into PDDL.

- Answer Set Programming (ASP): ASP is used in the paper as the logic language for creating intermediate representations. ASP provides rules and constraints for logical reasoning.

- Translate-Infer-Compile (TIC): This is the name of the proposed approach that uses an LLM for translation to an intermediate representation, ASP inference over that, and compilation to final PDDL.

- Accuracy of PDDL generation: A major focus is improving accuracy of mapping natural language to planning task PDDLs compared to direct LLM generation.

- Generalization: The paper also examines how the approach generalizes to variations in the natural language input.

So in summary - LLMs, classical planning, intermediate representations, logical reasoning, and accuracy/generalization of mapping language to planning problems are key topics.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper introduces an intermediate representation (IR) of the natural language task description. What are some key benefits of using an IR compared to generating the task PDDL directly from the natural language description?

2. The paper uses Answer Set Programming (ASP) as the IR language. What are some properties of ASP that make it suitable for representing the IR? Could other logical languages like Prolog also be used instead? What would be the tradeoffs?

3. The inference step uses additional domain knowledge rules to deterministically derive more facts from the IR. What are some example types of rules that would be relevant for a planning domain? How feasible would it be to semi-automate the authoring of such rules?

4. The compilation step converts the materialized representation to target PDDL syntax. Could this step also be performed using an LLM instead of code? What would be the tradeoffs?

5. How does the approach handle ambiguity or uncertainty in interpreting the natural language description? Could probabilistic representations be incorporated?

6. Could the approach be extended to support conditional goals and effects in planning domains? What enhancements would be required? 

7. The approach currently focuses on classical planning. How could the ideas be extended to support temporal and numeric planning domains?

8. What enhancements could make the approach learn domain-specific translation, inference and compilation more automatically over time?

9. How do the results compare between using in-context examples vs generic prompts? Why does the accuracy vary for different planning domains?

10. The approach achieves high accuracy on a dataset with variation in language of task descriptions. What are some practical benefits of this outcome? How could the robustness be improved further?
