# [DivClust: Controlling Diversity in Deep Clustering](https://arxiv.org/abs/2304.01042)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is how to efficiently produce multiple, diverse partitionings (clusterings) of a dataset using deep learning frameworks. The key points are:- Existing deep clustering methods focus on producing a single clustering solution. However, consensus/ensemble clustering using multiple diverse base clusterings can produce better and more robust results. - Generating diverse clusterings typically requires training models multiple times, which is computationally costly. - This paper proposes a method called DivClust to address this gap. DivClust can be incorporated into existing deep clustering frameworks to efficiently produce multiple clusterings with controlled diversity.- DivClust uses a diversity controlling loss function to restrict the similarity between pairs of clusterings produced by the model. This allows tuning the clusterings to have a desired degree of diversity.- Experiments show DivClust can effectively control diversity without reducing clustering quality. The diverse clusterings can be aggregated via consensus clustering to improve performance over single clustering baselines.In summary, the key research question is how to efficiently generate diverse clusterings with deep learning models, which DivClust addresses by controlling inter-clustering diversity via a novel loss function.
