# [Hierarchical Visual Primitive Experts for Compositional Zero-Shot   Learning](https://arxiv.org/abs/2308.04016)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we improve compositional zero-shot learning (CZSL) by enhancing the visual discrimination and contextuality of attribute and object representations, while also addressing the issue of biased predictions caused by imbalanced training data?The key hypotheses appear to be:1) Employing attribute and object experts in a hierarchical manner using both bottom-up and top-down pathways in a visual backbone network can help generate more distinct and contextual primitive embeddings for CZSL. 2) Explicitly modeling contextuality between attributes and objects with an object-guided attention module can improve attribute embedding discrimination.3) A simple minority attribute augmentation technique can help balance biased predictions from imbalanced training data distributions in CZSL.In summary, the paper proposes and evaluates a new framework called Composition Transformer (CoT) with a minority attribute augmentation method to improve CZSL through more discriminative and contextual primitive embeddings while also addressing data imbalance issues. The experimental results seem to validate these hypotheses and show state-of-the-art performance on several CZSL benchmarks.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper seem to be:1. It proposes a simple and scalable framework called Composition Transformer (CoT) for compositional zero-shot learning. The key ideas are:- Using object and attribute experts in distinctive manners to generate representative embeddings, by utilizing the visual backbone hierarchically. - The object expert extracts object embeddings from the final layer in a bottom-up manner.- The attribute expert generates attribute embeddings in a top-down manner, using a proposed object-guided attention module to model contextuality.2. It develops a simple yet effective minority attribute augmentation (MAA) methodology to address the biased prediction issue caused by imbalanced data distribution in compositional zero-shot learning. 3. It achieves state-of-the-art performance on several benchmarks like MIT-States, C-GQA, and VAW-CZSL. The results demonstrate the effectiveness of CoT and MAA in improving visual discrimination of features and handling model bias.4. Through comprehensive analysis and visualizations, it provides insights into how CoT and MAA help mitigate the hubness problem in embedding space and generate discriminative attribute-object features.In summary, the main contribution appears to be proposing a new compositional zero-shot learning framework CoT and a tailored data augmentation method MAA, which achieves improved performance and provides better feature discrimination compared to prior arts. The simple yet effective design of CoT and MAA are highlighted as strengths.
