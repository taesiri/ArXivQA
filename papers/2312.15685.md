# [What Makes Good Data for Alignment? A Comprehensive Study of Automatic   Data Selection in Instruction Tuning](https://arxiv.org/abs/2312.15685)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Instruction tuning is important for aligning large language models (LLMs) to human preferences, but relies heavily on high-quality data. 
- It's unclear what defines "good data" for instruction tuning and how to automatically select effective data examples from a large pool.

Method:
- Propose metrics to assess data along 3 key dimensions: complexity, quality, and diversity.
- Introduce "Evol Complexity" and "Evol Quality" methods to automatically generate data variants and have ChatGPT rank them to obtain fine-grained scores.  
- Propose a simple yet effective strategy called "Score-First, Diversity-Aware" selection that combines complexity, quality, and diversity measures to select optimal data.

Experiments:  
- Train \deita models by fine-tuning LLaMA and Mistral LM checkpoints on 6K-10K automatically selected data samples.
- Show \deita models match or exceed SOTA open-source models aligned on much larger datasets.
- Demonstrate over 10x reduction in data while maintaining strong performance.

Contributions:
- First comprehensive study defining metrics to measure "good" instruction tuning data.
- New automatic methods to effectively score data for complexity and quality.
- Simple but highly effective strategy for selecting optimal data. 
- \deita models showing substantial improvements in data efficiency for instruction tuning.

In summary, the paper conducts an extensive study to understand effective data for alignment, and proposes data selection methods that can greatly reduce the amount of data needed while preserving strong model performance. The techniques could facilitate more efficient LLM alignment.
