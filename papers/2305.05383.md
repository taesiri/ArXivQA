# [Code Execution with Pre-trained Language Models](https://arxiv.org/abs/2305.05383)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we teach pre-trained language models to execute arbitrary programs and predict their execution traces?The key points are:- Existing pre-trained models for code intelligence rely only on source code and syntactic structures like AST, but do not leverage execution traces which capture the dynamic semantics and behavior of code. - Execution traces reflect how code behaves during execution, including control flow and state changes of variables. They capture the "formal" semantics of code.- The authors propose to train a Transformer-based model named CodeExecutor to execute arbitrary programs and predict their execution traces, in order to teach pre-trained models the real-world code execution process.- They construct a large-scale Python dataset for code execution using a mutation-based data augmentation approach.- CodeExecutor is pre-trained on predicting execution traces using a curriculum learning strategy to handle programs of increasing difficulty.- Experiments show CodeExecutor outperforms existing models on code execution and also improves performance on downstream tasks, indicating execution traces are useful for code intelligence.In summary, the central hypothesis is that training on predicting execution traces can enhance pre-trained models' ability to execute and understand code, which is tested through pre-training CodeExecutor and evaluating it on code execution and related tasks.
