# [A Simple Fine-tuning Is All You Need: Towards Robust Deep Learning Via   Adversarial Fine-tuning](https://arxiv.org/abs/2012.13628)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is:Can effective learning rate scheduling during adversarial training significantly reduce overfitting and improve robustness, to the point where one may not even need full adversarial training but can instead just adversarially fine-tune a pre-trained model?The key hypothesis is that proper learning rate scheduling can mitigate overfitting during adversarial training, allowing for much simpler and faster adversarial fine-tuning to achieve improved robustness compared to full adversarial training from scratch.The main contributions summarized in the paper related to this central question are:- Demonstrating how learning rate scheduling impacts overfitting and robustness during adversarial training. - Proposing a simple yet effective adversarial fine-tuning approach based on 'slow start, fast decay' learning rate scheduling that reduces computational cost and improves robustness compared to full adversarial training.- Showing the ability to improve robustness of any pre-trained model without full adversarial re-training from scratch, enabled by the proposed fine-tuning approach.So in summary, the central hypothesis is focused on the role of learning rate scheduling in adversarial training and how it can enable a much simpler adversarial fine-tuning approach to improve robustness and reduce overfitting. The experiments and results aim to validate this hypothesis.
