# [Bridging Generative Networks with the Common Model of Cognition](https://arxiv.org/abs/2403.18827)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
There is currently no consensus on how to effectively integrate symbolic, rule-based AI (GOFAI) with modern statistical approaches like deep learning. One less explored method is integrating generative AI models like large language models into cognitive architectures that aim to model human cognition, like the Common Model of Cognition (CMC). However, the CMC currently lacks a way to make the outputs of neural networks interpretable at the cognitive level.

Proposed Solution:
The authors propose several significant adjustments to the CMC to allow it to incorporate and interpret the outputs of large generative neural networks:

1) Add an interface layer called "Middle Memory" (MM) between the CMC modules and the neural networks. MM receives vector representations from the networks and assigns activations to make some outputs more likely to reach working memory.

2) Model all CMC modules except procedural and working memory as "shadow production systems" - sets of if-then rules that operate in parallel to interface between networks and central production system. 

3) On each cycle, combine working memory contents with active MM vectors to form inputs for the generative networks. This allows the networks to anticipate what outputs will be useful.

4) Use the same temporal difference learning rule to update utilities of central and shadow productions, allowing the entire system to learn as a whole.

Main Contributions:
- A novel method to incorporate and interpret the outputs of large generative neural networks within the modular structure of the CMC
- The concept of "shadow production systems" as a standardized way to implement peripheral modules in cognitive architectures
- A system that combines predictive statistical learning with higher level symbolic reasoning and metacognition, allowing it to model a broader range of human cognitive capacities.

The proposed adjustments provide both a theoretical framework and practical path to unite cognitive architectures and deep learning. This could allow for AI systems with more robust reasoning abilities.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper proposes integrating generative AI models like large language models into cognitive architectures like the Common Model of Cognition by adding a middle layer that contextualizes and refines the outputs of the generative networks before they enter working memory.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a reformulation of how ACT-R conceives of modules. Specifically, the paper proposes:

1) An interface called "Middle Memory" (MM) between the Common Model of Cognition (CMC) architecture and underlying generative neural networks. The MM receives predictions from the networks and assigns activations to them to determine what gets passed to working memory. 

2) Modeling all CMC modules except procedural and working memory as "shadow production systems" - sets of if-then rules that operate in parallel to the main production system. The shadow productions manage bottom-up information from the peripheral modules and select what to pass to working memory. 

3) Having the contents of working memory combine with the contents of MM to form inputs to the generative networks on every cycle. This allows the networks to anticipate what information will be useful to provide. 

4) Potentially bringing all modules under the same learning algorithm, so that when the central production system achieves a reward, the contributing shadow productions also get a utility boost.

In summary, the main contribution is proposing a restructuring of modules within the CMC to allow it to integrate with and leverage generative neural networks. This novel structure could enable seamless connections between cognitive architectures and deep learning.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts include:

- Common Model of Cognition (CMC)
- ACT-R cognitive architecture
- Production systems
- Shadow production systems
- Buffers
- Modules
- Declarative memory
- Generative neural networks
- Integration of symbolic reasoning and neural networks
- Middle Memory 
- Vector representations
- Holographic Declarative Memory
- Causal reasoning
- Metacognition

The paper proposes reformulating the ACT-R cognitive architecture and the broader Common Model of Cognition to integrate generative neural networks. It introduces the concept of "shadow production systems" within modules and an interface layer called "Middle Memory" to enable this integration. Key goals are leveraging the strengths of neural networks and symbolic reasoning, and modeling complex cognitive abilities like causal reasoning and metacognition. The use of vector representations like holographic vectors is also noted as an implementation approach.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a "Middle Memory" interface between the Common Model of Cognition and underlying generative networks. What is the purpose of this Middle Memory and how does it function? 

2. The paper conceptualizes cognitive modules like perception and motor control as "shadow production systems." What are shadow production systems and what is their proposed role according to the framework outlined in the paper?

3. The paper discusses representing information in the Middle Memory using both vectors and symbolic structures. What are the potential advantages and disadvantages of this mixed representation? How could issues like translating between representations be handled?

4. The paper proposes that shadow production systems select and filter information before allowing it into working memory. What criteria might guide this selection process? How is relevant or important information identified? 

5. The framework proposes delivering combined context and attention vectors to generative networks on every cycle. How might this focusing process work? What mechanisms could be used to construct and update these vectors?

6. How exactly would generative networks be trained within this framework to anticipate useful outputs? What types of objectives or rewards could guide this training process?

7. The paper suggests all production systems could be included in temporal difference learning. How would utility propagation to shadow productions work in this framework? What implementation challenges might arise?

8. The proposal speculates that Middle Memory could relate to thalamic activity. What evidence exists for or against this idea? How does the proposed functionality of Middle Memory compare to theories about the role of the thalamus?

9. The paper suggests catastrophic interference could be avoided by using holographic vectors. How might these vectors help mitigate interference effects in networks? What are the potential limitations?  

10. What types of complex human behavior, like causal reasoning or metacognition, might emerge from the interactions between symbolic reasoning and predictive networks outlined in this proposal? What key capacities would still need to be demonstrated?
