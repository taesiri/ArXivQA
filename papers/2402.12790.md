# [From Movements to Metrics: Evaluating Explainable AI Methods in   Skeleton-Based Human Activity Recognition](https://arxiv.org/abs/2402.12790)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is a lack of testing on the applicability and reliability of explainable AI (XAI) evaluation metrics in the domain of skeleton-based human activity recognition (HAR). Established metrics like "faithfulness" and "stability" have not been evaluated in this context.

- There is also no comparative analysis between different XAI methods like Class Activation Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) to understand their relative efficacy. 

- Existing approaches to perturb skeleton data for analysis may distort the standard human skeletal structure that models are trained on. Biomechanically inaccurate perturbations can potentially lead to misleading conclusions.

Methods:
- The paper tests "faithfulness" and "stability" metrics on CAM and Grad-CAM explanations from an EfficientGCN model trained on the NTU RGB+D dataset.

- A novel perturbation approach is introduced that respects human biomechanical constraints to ensure skeleton graph variations are realistic.

- The impact of varying perturbation magnitudes on the XAI metrics is assessed. 

- A random attribution method serves as a baseline to compare against CAM and Grad-CAM.

Key Contributions:

- Testing established XAI metrics in the skeleton-based HAR domain and evaluating their applicability. "Faithfulness" is found to falter while "stability" emerges as more reliable.

- Introducing a biomechanically-valid skeleton graph perturbation technique for XAI evaluation.

- Revealing issues with relying on prediction probability shifts to assess explanation fidelity for certain models like EfficientGCN. 

- Finding that CAM and Grad-CAM produce very similar explanations and metric outcomes, highlighting a need for more diverse XAI methods.

- Identifying opportunities for developing novel metrics and testing different explanation techniques tailored to skeleton-based HAR.

In summary, the key gap addressed is the lack of analysis on XAI evaluation approaches for the emerging domain of skeleton-based action recognition. Both the shortcomings of certain metrics and the need for more diverse techniques are highlighted through systematic experimentation.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

This paper tests established explainable AI metrics of faithfulness and stability on Class Activation Mapping and Gradient-weighted Class Activation Mapping applied to an Efficient Graph Convolutional Network model for skeleton-based human activity recognition, introducing a biomechanically-constrained perturbation approach to generate realistic skeletal graph variations for evaluation.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Testing established metrics for evaluating explainable AI (XAI) methods on skeleton-based human activity recognition (HAR) models, and assessing their applicability in this domain. 

2. Introducing a controlled approach to perturb 3D skeleton data for XAI evaluation that ensures biomechanically correct variations to represent realistic human movements.

3. Assessing the impact of different perturbation magnitudes on the XAI evaluation metrics. 

4. Comparing the performance of Class Activation Mapping (CAM), Gradient-weighted Class Activation Mapping (Grad-CAM), and a random feature attribution method on a skeleton-based HAR model using the evaluation metrics.

In essence, the paper examines the reliability and suitability of common XAI assessment techniques in the emerging field of skeleton-based HAR, where explainability of models is becoming more critical. It also contributes a biomechanics-based data perturbation method for more rigorous testing of XAI methods.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key keywords and terms associated with it are:

- explainable AI (XAI)
- Class Activation Mapping (CAM) 
- Gradient-weighted Class Activation Mapping (Grad-CAM)
- faithfulness
- stability 
- skeleton-based human activity recognition (HAR)
- NTU RGB+D 60 dataset
- EfficientGCN
- perturbation method
- biomechanical constraints
- 3D skeleton data

The paper tests established XAI evaluation metrics like faithfulness and stability on methods like CAM and Grad-CAM for skeleton-based HAR. It uses the NTU dataset and EfficientGCN model, and introduces a perturbation approach that respects biomechanical constraints of human movement. The key focus areas are explainable AI, skeleton data, and human activity recognition.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper introduces a perturbation method that respects human biomechanical constraints to ensure realistic variations in human movement. Can you explain in more detail how this perturbation method works and how it differs from previous approaches? 

2. When testing the faithfulness metric, the paper found irregularities suggesting the hypothesis of faithfulness is not upheld for the EfficientGCN model. Why do you think the faithfulness metric fails in this context and what could be an alternative approach?

3. The stability metric emerged as more dependable compared to faithfulness when evaluating CAM and Grad-CAM on the EfficientGCN model. In your view, what are the key reasons the stability metric proves to be more reliable?

4. The paper concludes that CAM and Grad-CAM produce almost identical explanations on the EfficientGCN model. What are the implications of this finding and how can this issue of similarity between explanation methods be addressed?  

5. Do you think the perturbations used in the paper to evaluate the XAI metrics cover enough of the space of biomechanically realistic human motions? If not, what other perturbation strategies could be used?

6. The paper evaluates the explanation methods on the most accurately classified activity (jump up) and the most misclassified one (writing). Should additional activity classes with intermediate classification performance also be tested? Why or why not?

7. How suitable do you think the CAM and Grad-CAM explanation methods evaluated in the paper are for real-world skeleton-based HAR applications like healthcare monitoring or human-computer interaction?

8. What are some of the challenges and open research questions that need to be addressed to make XAI methods more useful for skeleton-based HAR in practice? 

9. The paper uses PGI, PGU and stability metrics for evaluation. Can you suggest some other quantitative XAI evaluation metrics not covered in the paper that could provide additional insights?

10. Do you think the findings of this paper on limitations of certain XAI metrics and similarity of CAM and Grad-CAM explanations apply only to graph convolution-based models like EfficientGCN or more broadly to other types of deep learning models for skeleton-based HAR?
