# [Spatiotemporal Entropy Model is All You Need for Learned Video   Compression](https://arxiv.org/abs/2104.06083)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be:Can a simple deep learning framework without motion prediction achieve state-of-the-art performance for learned video compression? The key points are:- Existing learned video compression methods use complex frameworks involving motion prediction modules and separate compression of motion vectors and residuals. This leads to issues like error propagation and high complexity. - The authors propose a simplified "motion-free" framework that does not do motion prediction. It uses a single autoencoder network to compress each frame independently. - A spatiotemporal entropy model is used to capture redundancy between frames in the latent space. This avoids doing motion prediction explicitly.- Experiments show this simple framework achieves state-of-the-art MS-SSIM performance compared to prior learned video compression methods. It also has much lower complexity.So in summary, the central hypothesis is that a simple motion-free framework can match or exceed the performance of more complex motion-based learned video compression schemes. The results appear to validate this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing a motion-free video compression (MFVC) framework that directly compresses raw pixel frames without using motion prediction modules like traditional methods. This is achieved by using a unified autoencoder to compress each frame independently and a spatiotemporal entropy model to capture redundancies between frames. - The spatiotemporal entropy model consists of a joint hyperprior encoder-decoder, spatial prior module, and temporal prior module to minimize the entropy of the autoencoder latent representations.- Achieving state-of-the-art performance under the MS-SSIM metric while having a simpler framework compared to previous learned video compression methods. The method also enables variable rate control in a single model.In summary, the key contribution seems to be proposing and demonstrating the effectiveness of a motion-free framework for learned video compression, which is simpler than traditional schemes relying on motion estimation/compensation. The core of this framework is the spatiotemporal entropy model that captures spatial and temporal redundancies in the latent space to minimize rate. The results show this approach can achieve competitive or better performance compared to prior art.
