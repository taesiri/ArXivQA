# [Self-supervised Video Representation Learning Using Inter-intra   Contrastive Framework](https://arxiv.org/abs/2008.02531)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we design an effective self-supervised method to learn spatio-temporal feature representations from videos that capture both spatial and rich temporal information? The key hypotheses appear to be:1) By generating intra-negative samples that break down the temporal relationships within a video, the model can be encouraged to learn more temporal information in addition to spatial cues. 2) By combining both inter-sample and intra-sample contrastive learning, the model can jointly leverage positives from different views of the same video and negatives from different videos as well as transformed versions.3) The proposed Inter-Intra Contrastive (IIC) framework with these components can learn improved video representations compared to existing self-supervised approaches, as evaluated on video retrieval and recognition tasks.So in summary, the central research question is how to design an effective self-supervised method for spatio-temporal video representation learning, with the core hypothesis being that the proposed IIC framework can achieve this goal. Let me know if you would like me to clarify or expand on any part of the summary.


## What is the main contribution of this paper?

The main contributions of this paper are:- Proposing a self-supervised method called Inter-Intra Contrastive (IIC) learning framework to learn video representations from unlabeled videos.- Generating intra-negative samples by breaking the temporal relationships within a video clip to encourage the model to learn rich temporal information. - Extending the contrastive multiview coding framework by introducing these intra-negative samples as additional negatives.- Providing various options like using different modalities as the second view and different intra-negative sample generation strategies within this framework.- Showing through experiments that models trained with IIC significantly outperform prior state-of-the-art self-supervised methods on video retrieval and recognition tasks. For example, IIC achieves 16.7% and 9.5% higher top-1 accuracy on UCF101 and HMDB51 for video retrieval compared to previous best methods.In summary, the key contribution is proposing the IIC framework that uses inter- and intra-sample contrastive learning along with intra-negative samples to learn effective spatio-temporal video representations in a self-supervised manner.
