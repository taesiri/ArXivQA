# [HNeRV: A Hybrid Neural Representation for Videos](https://arxiv.org/abs/2304.02633)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to design an efficient neural video representation that combines the benefits of implicit and explicit methods. Specifically, the paper proposes a hybrid neural video representation called HNeRV that uses:- A learnable encoder to generate compact, content-adaptive embeddings for each frame (similar to explicit methods).- A learnable decoder modeled on each video to reconstruct frames from the embeddings (similar to implicit methods). The key hypothesis is that by combining tiny content-adaptive embeddings with a video-specific decoder, HNeRV can achieve better video reconstruction, faster convergence, and improved generalizability compared to fully implicit methods like NeRV. The embeddings provide a stronger visual prior while most information is still stored compactly in the decoder weights.The paper evaluates this hypothesis through extensive experiments showing HNeRV outperforms NeRV and other baselines on metrics like PSNR, convergence speed, and interpolation. It also demonstrates the potential of HNeRV for tasks like video compression and inpainting. Overall, the core research question is how to design an efficient hybrid neural video representation merging the strengths of implicit and explicit approaches.
