# [Microstructures and Accuracy of Graph Recall by Large Language Models](https://arxiv.org/abs/2402.11821)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Graph-structured data is ubiquitous and the ability to accurately encode and recall graphs described in text is a pivotal yet understudied capability needed for large language models (LLMs) to perform well on downstream graph reasoning tasks. While there have been many benchmark tasks proposed for testing LLMs' graph reasoning abilities, none have studied the fundamental task of graph recall. Additionally, decades of research in cognitive science have uncovered biased patterns and systematic errors in human graph recall that can provide inspiration and context for better understanding LLMs.

Methods & Contributions:
This paper proposes using the task of graph recall, where an LLM must encode a graph described in text and later reconstruct that graph, as a basic test of LLM competency. The recall performance and patterns of errors are analyzed using statistical models from the cognitive science literature on human graph recall. Additional factors that may influence recall ability are studied, including narrative style, memory interference, and priming LLMs with different gender roles. 

The main contributions are:
(1) Proposing graph recall as a simple yet pivotal task for understanding LLM graph reasoning
(2) Conducting the first systematic studies analyzing accuracy, biased microstructures and human comparisons in LLM graph recall 
(3) Revealing interesting findings about factors influencing LLM recall and correlations with downstream task performance

Key Results:
- LLMs exhibit clear shortcomings in recalling real-world graphs 
- Biased microstructures favoring more triangles and alternating 2-paths emerge consistently
- Performance strongly depends on matching the narrative style to the graph's original domain
- Patterns in recall errors correlate with behaviors in link prediction

In summary, this paper highlights the importance of studying the fundamental graph recall abilities of LLMs using inspiration from human cognition research, in order to better understand their remaining limitations in advanced graph reasoning tasks involving encoding structure from text.
