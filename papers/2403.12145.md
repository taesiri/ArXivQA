# [Syn-QA2: Evaluating False Assumptions in Long-tail Questions with   Synthetic QA Datasets](https://arxiv.org/abs/2403.12145)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

This paper introduces Syn-(QA)$^2$,  synthetic question answering (QA) datasets for evaluating the effect of false assumptions in question answering across both single-hop factual questions and multi-hop questions.

The key motivation is that false assumptions or premises in questions pose substantial challenges for QA systems. However, recent work has mostly studied naturally occurring questions. So there is a gap in analyzing how models perform with the long tail of possible questions and there are only modest dataset sizes available (only hundreds of test examples in some cases).

To address this, the authors generate two synthetic datasets using minimal perturbation of Wikidata triples and the HotpotQA dataset:

(1) The single-hop questions are created by sampling Wikidata relation triples, perturbing one entity to create false triples and then generating questions that assume those triples are true. 

(2) The multi-hop questions are created by swapping entity mentions in the HotpotQA dataset with similar entity mentions from distractor documents, leading to false assumptions.

This process results in 1812 question pairs where each pair contains a question with and without a false assumption.

Experiments evaluate several state-of-the-art language models on false assumption detection and on generative QA.

The key findings are:

(1) False assumptions remain challenging, confirming previous work. 

(2) Detection is surprisingly more challenging than generative QA, possibly due to complex linguistic structure.  

(3) Detection is harder on synthetic long-tail examples than natural examples, showing the value of the datasets.

Overall, this work makes available new resources for analyzing robustness and provides analysis highlighting remaining challenges in avoiding false assumptions. The generation methodology enables minimal pair analysis and studies of the long tail of possible questions.
