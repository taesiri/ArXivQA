# [Joint Unsupervised Learning of Deep Representations and Image Clusters](https://arxiv.org/abs/1604.03628)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we jointly learn deep image representations and cluster assignments in an unsupervised manner on unlabeled image data?The key ideas and contributions are:- Proposing a recurrent framework that combines agglomerative clustering with convolutional neural networks (CNNs) into a single end-to-end model. - Formulating agglomerative clustering as a recurrent process with successive merge operations expressed as steps in time. The CNN learns representations supervised by the clustering results.- Deriving a unified weighted triplet loss function that guides both the agglomerative clustering and representation learning.- Showing that alternating between clustering and representation learning improves both - better representations enable more precise clustering, and cluster assignments provide supervision for representation learning.- Demonstrating superior performance on image clustering across datasets compared to prior methods. The learned representations also transfer well to other tasks like image classification.So in summary, this paper jointly addresses unsupervised representation learning and image clustering in a unified framework with a single loss function, and shows both tasks can benefit each other when addressed together.


## What is the main contribution of this paper?

The main contribution of this paper is a recurrent framework for jointly learning deep representations and image clusters in an unsupervised manner. The key ideas are:- Formulating agglomerative clustering as a recurrent process where cluster merging operations are expressed as steps in a recurrent neural network. - Combining agglomerative clustering and convolutional neural network (CNN) based representation learning into a single end-to-end model. The clustering guides representation learning via a weighted triplet loss and the representations improve clustering.- A partially unrolling training strategy where the model is unrolled for only a few timesteps before updating CNN parameters. This prevents early noisy clustering from degrading representations.- Demonstrating that the jointly learned representations generalize well to other clustering algorithms and transfer learning tasks like image classification and face verification.In summary, the core contribution is a principled joint training framework for unsupervised learning of representations and clusters. The recurrent interpretation of agglomerative clustering allows end-to-end optimization with a CNN for representation learning. The joint modeling improves both tasks, outperforming prior state-of-the-art methods.
