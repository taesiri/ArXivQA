# [Invertible Neural Skinning](https://arxiv.org/abs/2302.09227)

## What is the central research question or hypothesis that this paper addresses?

 This paper introduces a new method called Invertible Neural Skinning (INS) for animating humans in 3D using raw scans and poses. 

The key research question it aims to address is:

How can we build an animatable 3D representation of clothed humans that overcomes the limitations of prior methods like:

- Limited expressivity of Linear Blend Skinning (LBS) for modeling complex cloth and tissue deformations

- Requirement of expensive per-pose mesh extraction during animation 

- Lack of surface correspondences across different poses

The main hypothesis is that by incorporating Pose-conditioned Invertible Networks (PINs) around an LBS formulation, the authors can create an expressive and invertible pipeline to achieve fast animation of clothed humans while maintaining surface correspondences across poses.

The key contributions are:

1) Proposing a Pose-conditioned Invertible Network (PIN) architecture that learns additional pose-varying deformations to extend LBS.

2) Combining PINs with a differentiable LBS module into an end-to-end Invertible Neural Skinning (INS) pipeline.

3) Demonstrating INS outperforms prior state-of-the-art on clothed humans, while being an order of magnitude faster at reposing and preserving correspondences.

4) Performing ablations to analyze the usefulness of different components of INS.

In summary, the paper introduces INS to address limitations of prior works in animating clothed humans from raw scan data. The main hypothesis is that using pose-conditioned invertible networks around LBS can lead to an expressive, fast, and topology-preserving reposing approach.
