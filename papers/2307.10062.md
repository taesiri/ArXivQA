# [Unsupervised Accuracy Estimation of Deep Visual Models using   Domain-Adaptive Adversarial Perturbation without Source Samples](https://arxiv.org/abs/2307.10062)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: How can we estimate the accuracy of a deep visual model on unlabeled target data from a different domain, without needing access to any labeled source data used to train the original model?The key hypothesis seems to be:By leveraging recent advances in source-free domain adaptation to obtain a pseudo-labeling model adapted to the target data distribution, and using disagreement rates between this adapted model and the original model on target samples, we can accurately estimate the target accuracy of the original model without needing the source training data.In summary, the paper is investigating whether accurate unsupervised accuracy estimation is possible in a source-free setting, which removes the assumption made in prior work that labeled source data is available. The proposed method aims to address this question by using pseudo-labeling via domain adaptation on the target data alone.


## What is the main contribution of this paper?

Based on my reading, the main contribution of this paper is proposing a novel framework for unsupervised accuracy estimation (UAE) of deep visual models on target data without requiring access to source data. The key ideas are:- Employing source-free unsupervised domain adaptation (UDA) methods to obtain a pseudo-labeling function on the target data that approximates the true labeling function. This allows estimating accuracy via the disagreement rate between the source model and adapted target model on the target data.- Enhancing the quality of estimation by using target-adaptive virtual adversarial perturbations (VAPs) that account for predictive uncertainty and domain discrepancy. This helps mitigate the impact of inaccurate pseudo-labels. - Introducing the overall proposed framework called SF-DAP that integrates source-free UDA and target-adaptive VAPs for effective source-free UAE.- Developing a simple yet effective source-free UDA method called PAFA that aligns target features with the source classifier. PAFA achieves strong performance on UDA benchmarks.- Extensive experiments showing SF-DAP outperforms existing UAE methods reliant on source data access across various domain shift scenarios, even without using any source samples.In summary, the main contribution is a novel source-free UAE framework that leverages source-free UDA and adaptive adversarial perturbations to accurately estimate model accuracy on unlabeled target data without needing source access. This is the first work to address the more practical source-free setting for UAE.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper proposes a new framework to estimate the accuracy of visual recognition models on unlabeled target data without requiring access to the original labeled source data used to train the models, by employing recent advances in source-free domain adaptation and perturbation techniques.
