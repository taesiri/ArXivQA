# High-Resolution Image Inpainting using Multi-Scale Neural Patch   Synthesis

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the abstract, the main research question addressed in this paper is: How can we develop an effective approach for high-resolution image inpainting that preserves both global structure and local texture details in the filled regions?The key points I gathered are:- Recent deep learning methods for image inpainting like Context Encoder can capture semantics but struggle with texture details, especially for higher resolution images.- Traditional texture synthesis methods can propagate textures well but don't understand global structure and semantics. - This paper proposes a multi-scale neural patch synthesis approach to get the benefits of both - it uses a convolutional neural network for structured prediction of image content along with a texture matching loss to synthesize high-frequency details.- The method involves jointly optimizing an image to match a learned global content prediction and match local neural patches from surrounding areas, in a coarse-to-fine manner across scales.- Experiments on ImageNet and Paris StreetView datasets demonstrate state-of-the-art inpainting accuracy and ability to generate sharper, more coherent results than prior methods.In summary, the core research contribution is a hybrid deep learning approach for high-quality high-resolution image inpainting by combining learned global structure and neural texture synthesis.
