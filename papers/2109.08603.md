# [Is Curiosity All You Need? On the Utility of Emergent Behaviours from   Curious Exploration](https://arxiv.org/abs/2109.08603)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:Can the emergent behaviors that arise during curiosity-driven learning be harnessed to accelerate learning on downstream tasks? The key hypotheses appear to be:1) Optimizing an intrinsic curiosity objective leads to the emergence of diverse and complex behaviors in continuous control environments like robot manipulation and locomotion.2) The intermediate behaviors that emerge and disappear during curiosity learning can serve as useful skills for solving related downstream tasks. 3) Retaining and reusing these emergent behaviors as modular skills could reduce the need for manually engineering task curricula in reinforcement learning.The experiments seem designed to test these hypotheses - first demonstrating the emergence of behaviors when optimizing a curiosity objective, and then showing how snapshots of the curiosity policy can be used as reusable skills to accelerate learning on a downstream task. The overall goal is to shift the focus towards retaining and leveraging emergent behaviors from curiosity-driven exploration.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:1. The introduction of SelMo, an off-policy realization of a self-motivated, curiosity-based method for exploration. This method is applied to two robotic manipulation and locomotion domains in simulation.2. A focus on identifying and retaining the behaviors that emerge during curiosity-based learning, rather than just using curiosity for fast environment exploration or as a bonus reward. The paper argues that the emergent behaviors can serve as valuable skills for solving related tasks. 3. An analysis showing the continuous shift in behavior over the course of training when optimizing only for the curiosity objective. Diverse and human-interpretable behaviors emerge in both the manipulation and locomotion domains.4. A baseline experiment demonstrating the benefits of reusing discovered behaviors for transfer tasks. The paper shows that using policy snapshots as modular skills in a hierarchical RL setup can perform comparably to a hand-designed curriculum.5. A discussion of remaining challenges and future work on the automatic identification and retention of useful emerging behaviors from curious exploration. The paper suggests this is a promising research direction for unsupervised reinforcement learning.In summary, the main contributions are the introduction of the SelMo method, an analysis of emergent behaviors, and initial experiments showing the potential for harnessing these behaviors for downstream tasks. The paper also discusses the open problems and future work in this domain.


## How does this paper compare to other research in the same field?

Here are some thoughts on how this paper compares to other research in self-motivated and curiosity-driven reinforcement learning:- The authors build on existing work in curiosity-driven RL that uses prediction error as an intrinsic reward signal. However, they implement this idea in an off-policy setting which improves data efficiency and allows for more diverse emerging behaviors compared to typical on-policy implementations. - The focus on retaining and reusing emergent behaviors from curiosity is novel compared to most prior work, which uses curiosity objectives solely for exploration or pre-training. The authors make a case that these behaviors can serve as useful skills for downstream tasks.- The proposed method of taking policy snapshots during curiosity training and reusing them as modular skills is simple but effective. It provides a baseline for more sophisticated techniques to identify, retain, and leverage emergent behaviors in the future.- Evaluating the approach on complex continuous control tasks (robotic arm, humanoid) is a strength compared to much prior work in discrete or simple domains. The emergent behaviors like grasping and lifting are more impressive and meaningful.- The combination of off-policy learning and hierarchical skill reuse seems more scalable than some alternative techniques like planning-based exploration or adversarial/self-play methods for emergent behaviors.Overall, the work makes nice contributions in adapting curiosity-driven RL to complex robotics domains and shifting the focus to harnessing emergent skills. The experiments provide a proof of concept for this direction. There is clearly more work to be done in developing better methods for extracting reusable behaviors, but this provides a solid baseline.


## What future research directions do the authors suggest?

Based on my reading of the paper, here are some of the main future research directions suggested by the authors:- Developing better methods for identifying and characterizing the emergent behaviors during curiosity-driven learning. The authors mention diversity-based approaches like DIAYN as one possibility. However, automatically identifying the most useful behaviors to retain in an open-ended learning setting remains an open challenge.- Improved techniques for retaining and leveraging discovered behaviors from curiosity learning. The authors mention latent skill spaces, distillation of play data, and using different versions of the world model as reward functions as possibilities. Figuring out the best way to capture and reuse behaviors without catastrophic forgetting is an important direction.- Applying the ideas to real-world robotic systems beyond simulation. The authors demonstrate their method in simulated domains, but applying emergent curiosity to real robots and studying the transferability of skills is an important next step.- Extending the approach to even more complex tasks and environments, such as long-horizon manipulation skills. The authors suggest emerging curiosity behaviors could remove the need for manually engineered task curricula in these settings.- Understanding the factors that lead to useful versus useless skill discovery during curiosity learning. Developing methods to focus curiosity on behaviors likely to be reusable is suggested.- Studying whether intrinsic motivations beyond curiosity, like empowerment, can produce valuable emerging skills. The generality of the approach should be explored.- Combining self-supervised skill discovery with other paradigms like self-play which have been shown to produce complex behaviors. Integrating multiple approaches for open-ended unsupervised learning is proposed.In summary, better understanding and utilization of emergent behaviors in curiosity-driven RL seems to be the key theme for future work based on this paper. The authors lay out a promising research program in this direction.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper presents SelMo, a self-motivated exploration method based on curiosity rewards derived from a forward dynamics model prediction error. SelMo is implemented in an off-policy fashion and applied to manipulation and locomotion domains in simulation. The authors observe that complex behaviors like grasping, lifting, balancing, and walking emerge when the agent explores based solely on maximizing curiosity rewards over time. They argue that these emergent behaviors can serve as useful skills for learning new downstream tasks. To demonstrate this, the authors take policy snapshots from curiosity training and use them as fixed auxiliary skills in a hierarchical reinforcement learning setup, showing performance on par with hand-designed curricula. The authors posit that identifying and retaining emergent behaviors from curiosity-driven exploration could reduce the need for manually engineered task curricula in complex control domains like robotics.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes shifting the focus of curiosity-based learning methods towards retaining and reusing the emergent behaviors that arise during training, rather than only using curiosity as an exploration bonus, in order to build up a repertoire of skills that can help solve downstream tasks.


## Summarize the paper in two paragraphs.

Here is a summary of the paper in two paragraphs:This paper proposes a curiosity-based reinforcement learning method called SelMo for robotic control tasks. SelMo uses a forward dynamics model to assign rewards based on prediction error, encouraging the agent to explore novel state-action transitions. The method is implemented in an off-policy fashion, allowing for more efficient data usage and diverse emerging behaviors compared to on-policy approaches. Experiments are conducted in two simulation environments - a 9DOF robotic arm and a 20DOF humanoid. When trained solely with curiosity rewards, complex and human-interpretable behaviors like grasping, lifting, balancing, and walking emerge over the course of learning. The paper also examines the utility of leveraging these emergent behaviors for downstream tasks through a simple policy snapshot approach. The behaviors discovered during curiosity training are provided as fixed skills to a hierarchical policy learning method. Even this simple behavior reuse technique results in accelerated learning on target tasks compared to learning from scratch. The self-discovered skills scaffold learning similarly to hand-designed rewards. This indicates promise in harnessing emergent behaviors from curiosity as a substitute for human-designed curricula in complex control problems. Overall, the work provides a useful off-policy approach for curiosity learning and demonstrates the value of emergent behaviors as skills for transfer learning.


## Summarize the main method used in the paper in one paragraph.

The paper presents SelMo, an off-policy self-motivated exploration method based on curiosity learning. The key components are a forward dynamics model and a policy. The dynamics model approximates the environment's transition function and assigns a curiosity reward to transitions based on its prediction error. The policy aims to take actions that maximize this curiosity reward. Data collection is done with an actor in the environment following the latest policy. The trajectories are stored in a model replay buffer and relabeled with curiosity rewards when sampled to update the dynamics model. The relabeled data is stored in a separate policy replay buffer for off-policy optimization of the policy via MPO. Having separate model and policy components and buffers allows asynchronous and independent optimization of each.The method is evaluated in continuous control tasks on a simulated robotic arm and humanoid robot. Complex emergent behaviors like grasping, lifting, balancing etc. are analyzed when the agent explores the environment guided solely by the changing curiosity objective. The utility of these emergent behaviors is demonstrated by using policy snapshots as modular skills in hierarchical RL, showing performance on par with hand-designed curricula.


## What problem or question is the paper addressing?

Based on my reading, the key points of this paper are:- Curiosity-based reward schemes can facilitate exploration and help discover solutions for complex, sparse, or long-horizon reinforcement learning tasks. - Existing approaches often use curiosity just for faster environment exploration or as a bonus reward for a specific downstream task. This may miss useful skills that emerge during curiosity-driven learning.- The paper proposes shifting focus to retaining and reusing the diverse behaviors that emerge during curiosity learning, rather than just using curiosity as a means to an end. These emergent behaviors can serve as skills to help solve related downstream tasks.- They present an off-policy implementation of curiosity learning called SelMo and apply it in simulated robotic manipulation and locomotion domains. Diverse and meaningful behaviors emerge from optimizing the curiosity objective alone.- A simple policy snapshot approach is proposed to reuse discovered behaviors for transfer to new tasks. Experiments show benefits comparable to using a hand-designed curriculum of tasks/rewards.- Overall, the work suggests identifying and exploiting emergent curiosity-driven behaviors can be promising for learning complex robotics tasks by providing a repertoire of self-discovered skills.In summary, the key focus is on retaining and reusing the diverse skills that emerge as a by-product of curiosity-driven exploration, rather than just using curiosity for exploration itself. The experiments demonstrate this possibility and provide a baseline for future work on exploiting self-discovered behavior.
