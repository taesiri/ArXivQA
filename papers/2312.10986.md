# [Long-Tailed 3D Detection via 2D Late Fusion](https://arxiv.org/abs/2312.10986)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Long-Tailed 3D Detection via 2D Late Fusion":

Problem:
The paper addresses the problem of long-tailed 3D object detection (LT3D) for autonomous vehicles. LT3D refers to detecting 3D objects from both common classes (e.g. cars) as well as rare classes (e.g. strollers, debris) that are critical for safe navigation. Contemporary LiDAR-based detectors like CenterPoint struggle to detect rare classes, achieving only 5.1 AP on "stroller". RGB images provide useful visual evidence to help resolve ambiguities, motivating RGB-LiDAR fusion.

Proposed Solution: 
The paper proposes a simple late-fusion framework that ensembles independently trained 2D RGB detectors (e.g. YOLOv7, DINO) and 3D LiDAR detectors (e.g. CenterPoint). This avoids needing paired training data. The paper examines 3 key aspects: (1) Using 2D instead of 3D RGB detectors since they are more mature and can leverage diverse external datasets; (2) Matching detections in 2D image plane instead of 3D BEV to avoid depth errors; (3) Score calibration and Bayesian fusion to combine detections.  

Main Contributions:
(1) Extensive analysis on design choices, revealing benefits of using 2D detectors, 2D matching, score calibration and probabilistic fusion.
(2) A simple yet effective late-fusion approach combining calibrated scores of 2D RGB and 3D LiDAR detections.
(3) State-of-the-art results on nuScenes LT3D benchmark, improving rare class AP by 10.6 and overall AP by 5.9. Qualitative results show correctly relabeling geometrically similar but visually distinct detections.

In summary, the paper presents insightful analysis into fusing 2D and 3D detectors for addressing long-tail distribution in 3D detection. The proposed simple late fusion method sets a new state-of-the-art on the task.
