# [Don't Overlook the Grammatical Gender: Bias Evaluation for Hindi-English   Machine Translation](https://arxiv.org/abs/2312.03710)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Neural machine translation (NMT) models often exhibit gender bias, by making stereotypical or biased translations. 
- Prior work on evaluating gender bias in NMT has focused on English as the source language.
- Evaluation methods used for English don't extend well to other languages, especially ones with grammatical gender like Hindi.
- Using gender-neutral sentences to evaluate bias (e.g. with TGBI score) doesn't expose the bias present in NMT models.

Proposed Solution:
- Create two new test sets for evaluating gender bias in Hindi-English NMT:
  - OTSC-Hindi: Sentences with occupational terms and grammatical gender cues about the speaker and their friend.
  - WinoMT-Hindi: 704 sentences with contextualized grammatical gender markers.
- Use these test sets to evaluate several Hindi-English NMT models.

Key Results:
- Evaluation shows most models exhibit heavy bias against the female gender, preferring masculine default translations.
- Models perform no better than random guessing on WinoMT-Hindi in discerning gender from context.
- TGBI score fails to expose gender bias present in NMT models.
- Google Translate performs best overall in utilizing grammatical gender cues for translation.

Main Contributions:
- Show importance of contextualizing bias evaluation for non-English source languages with grammatical gender markers. 
- Create two new test sets tailored for Hindi-English NMT bias evaluation.
- Demonstrate clear gender bias in several Hindi-English NMT models using new test sets.
- Establish that gender-neutral evaluation fails to expose NMT gender bias compared to gender-specified context.

The paper highlights the need for bias evaluation methods that account for properties of the source language, rather than just adapting approaches used for English. The new Hindi test sets reveal substantial gender bias in modern NMT models.
