# [Kandinsky 3.0 Technical Report](https://arxiv.org/abs/2312.03511)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

The paper presents Kandinsky 3.0, an improved large-scale text-to-image generative model based on latent diffusion with 11.9 billion parameters. Compared to previous Kandinsky versions, Kandinsky 3.0 uses a 2x larger U-Net backbone, a 10x larger text encoder, and removes diffusion mapping for a simplified single-stage pipeline. Key architecture details include the U-Net design with BigGAN-deep blocks and transformer layers, the 8.6B parameter Flan-UL2 text encoder, and the Sber-MoVQGAN 270M image decoder. Training leveraged over 150 million text-image pairs over multiple stages to handle various resolutions. Applications highlighted include high-quality inpainting and outpainting, converting images to video, and full text-to-video generation. Comparisons to models like DALL-E 3 and SDXL based on human evaluation over 2.1k prompts indicate Kandinsky 3.0 achieves state-of-the-art performance on text comprehension and approaches the visual quality of other leading models. Limitations center on further improving semantic text-image coherence and image quality. Ethical considerations like filtering training data and generated content are discussed as well.
