# [Self-supervised Monocular Depth Estimation: Let's Talk About The Weather](https://arxiv.org/abs/2307.08357)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can self-supervised monocular depth estimation be made more robust to different weather conditions and times of day?

The key hypotheses appear to be:

1) Current self-supervised monocular depth estimation methods rely too heavily on sunny, clear weather training data and thus do not generalize well to other conditions like rain, fog, nighttime, etc.

2) Data augmentations like weather effects, nighttime, and image corruptions can help make self-supervised monocular depth more robust. However, naively applying these tends to hurt performance. 

3) A novel bi-directional pseudo-supervision loss and consistent training framework can allow data augmentations to improve robustness without sacrificing performance on clear, sunny data.

So in summary, the main research question is how to improve generalizability and robustness of self-supervised monocular depth to different weather conditions and times of day. The key hypothesis is that a certain training framework with bi-directional pseudo-supervision loss can allow data augmentations to help achieve this goal without hurting original performance.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions seem to be:

- Proposing a novel bi-directional pseudo-supervision loss function that enforces consistency between depth maps estimated from original and augmented images. This allows the original depth maps to guide the learning for augmented images and vice versa. 

- Putting forward a set of recommendations/components for a robust data augmentation framework for self-supervised monocular depth estimation, including using original images for warping, training on original+augmented image pairs, and pseudo-supervision for pose estimation.

- Introducing a variety of weather and time related data augmentations (rain, fog, night etc.) using graphics/GANs to make the model more robust to different environments.

- Adding positional augmentations like vertical cropping and tiling to reduce the network's reliance on naive cues like vertical position.

- Demonstrating through experiments that the proposed method achieves similar or better performance on KITTI while significantly outperforming prior state-of-the-art on challenging weather datasets.

In summary, the key contribution seems to be developing an augmentation scheme and associated training methodology to make self-supervised monocular depth estimation more robust to different adverse weather conditions and environments, without sacrificing performance on normal sunny conditions. The bi-directional pseudo-supervision loss plays a key role in enabling effective learning from augmented data.
