# [Distraction is All You Need for Fairness](https://arxiv.org/abs/2203.07593)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, it seems the central research question is how to train deep learning models to make fair and accurate predictions, even when the training data contains biases. The paper proposes a new approach called the "Distraction module" to control for bias during model training. The key hypotheses appear to be:1) The proposed Distraction module can theoretically be proven to help learn classifiers that are invariant to protected attributes like gender or race. 2) Adversarially training the Distraction module against the classifier network enables optimizing for both accuracy and fairness simultaneously.3) This approach can work with different data types like tabular data, graphs, and images. 4) The method can outperform current state-of-the-art techniques for bias mitigation across different datasets.5) The self-attention mechanism enables explainability and identification of proxy variables contributing to bias.So in summary, the central research question seems to be how to create an accurate and fair classifier using a novel adversarial training procedure with the proposed Distraction module. The key hypotheses are that this approach can achieve state-of-the-art performance on bias mitigation across data types while retaining accuracy and interpretability.
