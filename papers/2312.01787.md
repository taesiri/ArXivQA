# [Developing Linguistic Patterns to Mitigate Inherent Human Bias in   Offensive Language Detection](https://arxiv.org/abs/2312.01787)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a linguistic data augmentation approach to mitigate human bias in offensive language detection datasets. The authors utilize linguistic features to automatically identify and extract offensive tweets, balancing the typically skewed class distributions in such datasets. Evaluated on Turkish and English datasets, this method improved model recall on offensive classes by 17.46% and 8.1% respectively over baseline. Comparative analyses between statistical (Word2Vec) and contextual (BERT) embeddings demonstrated superior performance by BERT models. Additionally, deep learning models (BERT-CNN-BiLSTM) outperformed traditional machine learning (SVM) in capturing nuanced expressions. While text normalization boosted statistical model scores, it degraded contextual model performance, indicating the importance of an unaltered linguistic context. By enhancing diversity and representativeness in training data, this linguistic augmentation technique reduces model reliance on biased human judgment and enhances generalization across contextual variations. Applicable across languages, it is an effective strategy to develop fairer natural language technologies. The authors suggest further augmenting data with positive context to build more holistic models less prone to biased inferences. Overall, this study offers valuable insights into mitigating bias in sentiment analysis datasets.
