# [Large-scale variational Gaussian state-space models](https://arxiv.org/abs/2403.01371)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Performing inference in nonlinear state-space models with large latent state dimensionality is challenging. Standard amortized variational autoencoders (VAEs) typically use simple diagonal Gaussian approximations which cannot capture temporal dependencies. More structured approximations are computationally expensive, requiring sampling of full trajectories or large matrix operations. 

Proposed Solution:
The paper introduces a structured variational approximation and inference algorithm that:

(i) Combines the prior dynamics with low-rank data updates to parameterize dense Gaussian distributions without resorting to diagonality. 

(ii) Conceptualizes the approximate smoothing problem as an approximate filtering problem for "pseudo observations" that encode current and future data. This simplifies computations.

(iii) Uses an inference network that approximates the Bayesian update step with low-rank precision matrix updates.

The key benefits are:

- Efficient evaluation of the ELBO and low-variance stochastic gradients without sampling full trajectories.

- Ability to capture temporal dependencies with a structured covariance matrix.

- Handles missing data and computational complexity that scales as O(TL(Sr + S^2 + r^2)) where T is the timeseries length, L is the latent dimensionality, S is the number of samples for dynamics propagation, and r is the rank of precision matrix updates.

Main Contributions:

(i) A structured variational approximation and inference network architecture that incorporates the prior dynamics while allowing efficient propagation of uncertainty.

(ii) Framing the approximate smoothing problem as filtering of "pseudo observations", enabling simpler posterior computations. 

(iii) An approximate nonlinear filtering algorithm with structured covariances from low-rank updates and Monte Carlo approximations.

(iv) Demonstration of modeling accuracy and uncertainty quantification on real neural datasets with reduced computational complexity.

In summary, the paper introduces a way to perform structured Bayesian inference in nonlinear state-space models by transforming the problem into an approximate filtering task. This provides an accurate and computationally cheaper alternative to sampling-based approaches.
