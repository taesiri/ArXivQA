# [GLOCALFAIR: Jointly Improving Global and Local Group Fairness in   Federated Learning](https://arxiv.org/abs/2401.03562)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Federated learning (FL) enables multiple clients to collaboratively train a shared machine learning model without directly sharing private data. However, the inherent characteristics of FL, such as client heterogeneity and non-IID data distributions, can introduce bias against certain demographic groups in the trained global model. Most prior FL fairness research focuses on global fairness based on the overall data distribution while overlooking local fairness on individual clients. Existing local fairness methods require sharing sensitive client statistics, raising privacy concerns.

Proposed Solution:
This paper proposes GLocalFair, a client-server co-design framework to jointly improve global and local group fairness in FL without needing sensitive client data. 

On the client side, a constrained optimization approach is used to enforce local fairness by bounding the false positive rate (FPR) and false negative rate (FNR) for sensitive groups below preset thresholds. This allows customization of fairness metrics per client. The constrained optimization is transformed into a two-player zero-sum game and solved efficiently.

On the server side, a novel fairness-aware clustering based aggregation method is proposed. Client updates are clustered based on their Gini coefficient, which correlates with fairness level. Fair clusters get higher weight when aggregating to the global model. This harmonizes contributions from diverse clients and improves global fairness.

Main Contributions:

- First work to jointly address both global and local group fairness in federated learning without needing sensitive client statistics

- Customizable local fairness constraints allow adapting to each client's requirements

- Novel fairness-aware clustered aggregation technique effectively improves global fairness

- Evaluated on image and tabular federated datasets, the method achieves significantly higher global and local fairness compared to state-of-the-art methods like FairFed and FedFB

- Maintains high utility while improving fairness, robust to heterogeneous FL data distributions

In summary, the paper presents an innovative client-server co-design approach that can customize local fairness and harmonize updates to improve global fairness, with empirical validation of enhanced performance.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a federated learning framework called GLocalFair that jointly improves global and local group fairness by using constrained optimization on the client side and fairness-aware clustering-based aggregation on the server side.


## What is the main contribution of this paper?

 Based on my understanding, the main contribution of this paper is proposing a client-server co-design fairness framework called \methodName that can jointly improve global and local group fairness in federated learning without needing sensitive statistics about clients' private datasets. Specifically, it utilizes constrained optimization on the client side to enforce local fairness and adopts a fairness-aware clustering-based aggregation method on the server side to ensure global model fairness across different sensitive groups while maintaining high utility. The key benefits are improved data privacy, customizable fairness configuration on the client models, and the ability to handle multiple sensitive attributes. Experiments on image and tabular datasets demonstrate \methodName's effectiveness in achieving enhanced fairness under both global and local data distributions compared to other state-of-the-art fairness methods in federated learning.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and concepts associated with it include:

- Federated learning (FL): A distributed machine learning approach that enables model training on decentralized data located on multiple devices without requiring the data to be sent to a central server. The paper focuses on improving fairness in the federated learning setting.

- Global and local group fairness: The paper distinguishes between fairness across the overall global dataset from multiple clients/devices vs fairness on each individual client's local dataset. It aims to improve both simultaneously.  

- Constrained optimization: The paper uses constrained optimization techniques on each client device to enforce fairness constraints related to false positive and false negative rates in order to improve local group fairness.

- Fairness-aware clustering: On the server side, the proposed method clusters client model updates based on fairness metrics to perform a weighted aggregation that improves global fairness across groups. 

- Gini coefficient: Used as a proxy measure of fairness level across model weight distributions. Models with higher bias tended to have higher Gini coefficients.

- Non-IID data: The non-identically and independently distributed data in federated learning across clients is a key challenge addressed.

- Client-server co-design: The dual optimization approach operates jointly on clients and the central server to enhance both local and global fairness.

Let me know if you need any clarification or have additional questions!


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1. The paper proposes a client-server co-design framework called \methodName to improve both global and local group fairness in federated learning. What is the key motivation behind this co-design approach compared to solely focusing on the client or server side?

2. On the client side, \methodName utilizes constrained optimization to enforce local fairness. Explain the formulation of the constraints and how they aim to minimize false positive rate (FPR) and false negative rate (FNR) across sensitive groups. 

3. The constrained optimization problem is transformed into a two-player zero-sum game formulation. Walk through the details of this formulation and explain the rationale behind it.  

4. On the server side, \methodName employs a clustering-based aggregation method to improve global fairness. Explain how k-means clustering is applied on client updates and the use of Gini coefficient as a proxy for fairness level.

5. The paper claims enhanced data privacy for \methodName compared to other methods. Elaborate on how the clustering-based approach on the server side protects sensitive client data.

6. One claimed benefit of \methodName is the ability to customize fairness configuration on the client models. Discuss how this is enabled through the constrained optimization approach and its practical usefulness.  

7. Walk through the empirical evidence provided on the correlation between model fairness metrics like EOD and the Gini coefficients calculated from model weights. What does this suggest?

8. The authors evaluate the individual contributions of the client-side and server-side fairness enhancement strategies. Summarize the key results and discuss how the two strategies complement each other.  

9. Parameter selection experiments are conducted in the paper around $\tau_{FPR}$, $\tau_{FNR}$ and $\gamma$. Discuss the impact observed by varying these parameters and how the default values are determined.

10. The model interpretability analysis reveals some interesting insights. Summarize the comparison of heat maps generated and discuss what they indicate regarding fairness of the different methods.
