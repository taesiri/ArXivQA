# [PSUMNet: Unified Modality Part Streams are All You Need for Efficient   Pose-based Action Recognition](https://arxiv.org/abs/2208.05775)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How can we design an efficient and scalable model for pose-based action recognition that achieves state-of-the-art performance with fewer parameters compared to existing methods?The key hypotheses of the paper appear to be:1) Using part-based streams instead of treating the skeleton input in a monolithic fashion will enable richer, dedicated representations for actions involving only subsets of joints (e.g. hands or legs). 2) Unifying multiple modalities (joint, bone, velocity) into a single processing pipeline instead of separate streams will enable more efficient training and utilization of inter-modality correlations.3) The proposed model, PSUMNet, will achieve state-of-the-art accuracy on standard pose-based action recognition benchmarks while using significantly fewer parameters than competing approaches.4) The part-based stream design will allow PSUMNet to generalize well to both sparse pose inputs (e.g. hand gestures) and dense pose inputs (e.g. full body with many joints).So in summary, the main research question is around developing an efficient yet accurate model for pose-based action recognition, with hypotheses related to part-based processing and unified modality processing. The experiments then aim to validate these hypotheses and show PSUMNet achieves superior efficiency and performance compared to prior state-of-the-art techniques.


## What is the main contribution of this paper?

The main contributions of this paper are:1. A part stream based approach for pose-based action recognition, as opposed to conventional methods that treat the skeleton input in a monolithic fashion. The part streams allow dedicated representations for actions involving subsets of joints. 2. A unified modality processing approach within each part stream, as opposed to having separate streams for each modality (joint, bone, velocity). This enables efficient weight sharing and reduction in parameters.3. The proposed architecture PSUMNet achieves state-of-the-art performance on NTU RGB+D and dense skeleton datasets using significantly fewer parameters than previous methods. 4. PSUMNet generalizes well to sparse skeleton datasets like SHREC for hand gestures.5. The efficiency of PSUMNet in terms of accuracy vs number of parameters makes it suitable for deployment on embedded and edge devices.In summary, the main contribution is a novel part stream unified modality network (PSUMNet) for efficient and scalable pose-based action recognition that achieves excellent performance using relatively few parameters. The architecture choices allow it to work well across sparse, normal, and dense skeleton datasets.


## How does this paper compare to other research in the same field?

This paper proposes a novel approach called PSUMNet for pose-based action recognition from skeleton data. Here are some key ways it compares to other research in this field:- Uses part streams rather than treating the entire skeleton as a monolithic input. This allows dedicating specialized processing for subsets of joints like hands and legs. Other methods tend to process the full skeleton jointly.- Employs a unified modality processing approach instead of separate streams for joints, bones, etc. This shares parameters across modalities to greatly reduce the number of trainable parameters. Most other methods train separate models per modality. - Achieves state-of-the-art accuracy on major pose datasets (NTU RGB+D 60/120, NTU-X) while using far fewer parameters than competing techniques. For example, it attains higher accuracy than methods with 100-400% more parameters.- Generalizes well to both sparse (e.g. hand gestures) and dense (full body with many joints) pose representations. Many competing techniques focus only on a single density.- Is designed to be efficient for deployment on embedded devices compared to other graph-based models. The part streams and unified modality approach helps minimize compute requirements.In summary, this paper introduces innovations in part-based processing and unified modality fusion that achieve superior accuracy and efficiency compared to existing research. The results demonstrate state-of-the-art pose recognition with far fewer parameters and good generalization across domains.


## What future research directions do the authors suggest?

Based on my reading of the paper, here are some of the main future research directions suggested by the authors:- Exploring other types of part streams besides body, hands, and legs streams. The part stream approach is flexible and could incorporate other logical groupings of joints.- Applying the unified modality pipeline and part streams approach to other pose-based tasks beyond action recognition, such as pose estimation or motion prediction. - Developing end-to-end learned approaches for automated partition of skeletons into logical part streams. Currently the part streams are predefined based on common groups of joints.- Exploring the application of part streams and unified modality processing to multi-person pose datasets. The paper focuses on single person pose but the concepts could extend to multi-person scenarios.- Reducing the computational complexity and number of parameters further to enable deployment on more resource constrained devices. For example, through network pruning or quantization techniques.- Incorporating additional modalities beyond joint positions, bone vectors, and velocities into the unified pipeline, such as rotation matrices or higher order derivatives.- Combining the proposed approach with complementary video or RGB based action recognition techniques for multimodal learning.- Extending the unified modality processing to jointly handle both pose and motion dynamics in an integrated architecture.In summary, the authors propose improving the efficiency and scalability of part streams, incorporating additional modalities and joint groupings, applying the approach to new tasks and datasets, and reducing complexity even further through compression or pruning as some potential future directions.
