# [Robust Knowledge Extraction from Large Language Models using Social   Choice Theory](https://arxiv.org/abs/2312.14877)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Large language models (LLMs) like GPT-3 can answer queries, but are prone to hallucination and lack robustness - even the same query prompted repeatedly can give different answers.  
- There are three key uncertainties: query uncertainty (different answers for the same query), syntax uncertainty (different answers for equivalent queries with minor syntactic variations), and distraction uncertainty (answers change with meaningless additions to the query).
- Existing work tries to quantify uncertainty by looking at token probabilities or getting the model to verbalize its confidence, but these are not reliable indicators.

Proposed Solution:
- Use ranking queries, where the model provides a ranked list of possible diagnoses/explanations according to their plausibility. 
- Prompt the ranking query multiple times, aggregate the results using the Partial Borda ranking method from social choice theory. This scores outcomes based on how often and how highly they are ranked.
- Claim: If the LLM has clear information on an answer, it will consistently rank it higher, whereas random hallucinated answers will vary. So aggregation improves robustness.

Key Contributions:
- Novel way to quantify and improve robustness of LLM question answering using ideas from social choice theory
- Define ranking queries suited for diagnostic tasks like medical and fault diagnosis
- Show how Partial Borda scoring can aggregate multiple query answers into robust rankings
- Empirically demonstrate improved robustness against both query uncertainty and syntax uncertainty on three real-world diagnostic datasets
- Establish desirable properties like consistency, faithfulness and agreement preservation for the proposed approach

In summary, the paper presents a way to make LLM question answering more robust by prompting ranking queries multiple times and aggregating the results using social choice theory. This is shown to work well empirically across various diagnostic datasets.


## Summarize the paper in one sentence.

 This paper proposes using methods from social choice theory to improve the robustness of answers from large language models to ranking queries by repeatedly sampling answers and aggregating them with the Partial Borda Choice function.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is proposing a method to improve the robustness of answers from large language models (LLMs) to ranking queries. Specifically:

- They propose using ranking queries where the LLM provides a ranked list of possible diagnoses/explanations for a condition. This allows capturing uncertainty in the answers.

- They prompt the same ranking query multiple times and aggregate the results using a method from social choice theory called the Partial Borda Choice function. This allows them to quantify the uncertainty and obtain a more robust ranking.

- They evaluate their approach on diagnostic tasks from manufacturing, finance, and medicine. Experiments show their method significantly improves robustness against both query uncertainty (asking the same question multiple times) and syntax uncertainty (minor variations in the question format).

In summary, the key contribution is leveraging ideas from social choice theory to improve the robustness of answers from LLMs to ranking queries in diagnostic settings. The method allows quantifying and reducing uncertainty in the LLM's responses.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper content, some of the main keywords or key terms associated with this paper include:

- Large language models (LLMs)
- Robustness 
- Query uncertainty
- Syntax uncertainty 
- Social choice theory
- Ranking queries
- Partial Borda choice function
- Diagnostic settings
- Medical diagnosis
- Fault diagnosis

The paper focuses on using methods from social choice theory, specifically the Partial Borda choice function, to improve the robustness of answers from large language models when used for ranking queries in diagnostic contexts. Key ideas include aggregating multiple LLM query responses and using the Partial Borda scoring method to quantify answer plausibility and uncertainty. Experiments evaluate the approach on medical, manufacturing, and finance diagnostic queries.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes using ranking queries to improve the robustness of answers from large language models (LLMs). What are some key advantages and limitations of using ranking queries compared to other types of queries for this purpose?

2. The paper focuses on applying the method to diagnostic problems like medical and fault diagnosis. What are some other potential application areas where this method could be useful? What adaptations would need to be made?  

3. The paper uses the Partial Borda Choice function to aggregate multiple rankings obtained from an LLM. What are some pros and cons of this function compared to other social choice theory methods for aggregating rankings?

4. The normalization of the PBW scores is an important step described in the paper. What impact would using non-normalized scores have? What are some other normalization strategies that could be explored?

5. The authors establish several analytical guarantees satisfied by the PBW scoring, like consistency and neutrality. Why are these properties desirable when quantifying the plausibility of LLM answers? Could violating them potentially lead to problems?

6. The transformation method T(Q,N,t) plays a key role in the overall approach. What are some ways T could be designed differently? What effect might that have on the resulting robustness? 

7. The criteria for mapping ranking outcomes to base outcomes could impact how diagnoses are scored. What are some alternative mapping criteria one could consider and what tradeoffs do they present?  

8. The paper focuses on uncertainty caused by repeated/variant queries. What are some other significant sources of uncertainty in LLM outputs and how suitable would this method be for handling those?

9. The choice of similarity measure for evaluating robustness is application-dependent per the authors. What are some factors to consider when selecting an appropriate similarity measure?

10. The method relies on access to reliable domain-specific LLMs. What steps could be taken to adapt the approach for widely available models that may have been trained on noisy data?
