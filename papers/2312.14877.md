# [Robust Knowledge Extraction from Large Language Models using Social   Choice Theory](https://arxiv.org/abs/2312.14877)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Large language models (LLMs) like GPT-3 can answer queries, but are prone to hallucination and lack robustness - even the same query prompted repeatedly can give different answers.  
- There are three key uncertainties: query uncertainty (different answers for the same query), syntax uncertainty (different answers for equivalent queries with minor syntactic variations), and distraction uncertainty (answers change with meaningless additions to the query).
- Existing work tries to quantify uncertainty by looking at token probabilities or getting the model to verbalize its confidence, but these are not reliable indicators.

Proposed Solution:
- Use ranking queries, where the model provides a ranked list of possible diagnoses/explanations according to their plausibility. 
- Prompt the ranking query multiple times, aggregate the results using the Partial Borda ranking method from social choice theory. This scores outcomes based on how often and how highly they are ranked.
- Claim: If the LLM has clear information on an answer, it will consistently rank it higher, whereas random hallucinated answers will vary. So aggregation improves robustness.

Key Contributions:
- Novel way to quantify and improve robustness of LLM question answering using ideas from social choice theory
- Define ranking queries suited for diagnostic tasks like medical and fault diagnosis
- Show how Partial Borda scoring can aggregate multiple query answers into robust rankings
- Empirically demonstrate improved robustness against both query uncertainty and syntax uncertainty on three real-world diagnostic datasets
- Establish desirable properties like consistency, faithfulness and agreement preservation for the proposed approach

In summary, the paper presents a way to make LLM question answering more robust by prompting ranking queries multiple times and aggregating the results using social choice theory. This is shown to work well empirically across various diagnostic datasets.
