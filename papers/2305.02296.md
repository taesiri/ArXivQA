# [DynamicStereo: Consistent Dynamic Depth from Stereo Videos](https://arxiv.org/abs/2305.02296)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the main research question this paper addresses is: 

How can we improve the temporal consistency of depth estimates from stereo videos?

The key ideas and contributions are:

1) They propose a new method called DynamicStereo that uses a transformer architecture to estimate disparity (depth) from stereo videos in a temporally consistent manner. It processes sequences of frames jointly rather than individual frames.

2) They introduce a new synthetic dataset called Dynamic Replica containing stereo videos of animated humans and animals. This provides training data for temporally consistent depth estimation.

3) They demonstrate improved results over prior methods in terms of both accuracy and temporal consistency when evaluating on standard benchmarks as well as their new dataset.

In summary, the paper focuses on the problem of temporally inconsistent depth estimates from stereo methods, especially for dynamic non-rigid scenes. Their proposed solution is a novel transformer-based architecture that processes sequences of frames together to improve consistency. They also contribute a new dataset to support learning and benchmarking in this area.
