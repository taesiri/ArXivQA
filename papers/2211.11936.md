# [One Eye is All You Need: Lightweight Ensembles for Gaze Estimation with   Single Encoders](https://arxiv.org/abs/2211.11936)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we improve gaze estimation performance using lightweight neural network architectures and ensemble methods while requiring only a single eye image as input?The key points related to this question are:- The paper investigates using small ResNet, Inception, and InceptionResNet architectures for gaze estimation, compared to standard CNNs used in prior work. The goal is to improve accuracy while keeping the model lightweight. - The paper proposes and tests gaze estimation using just a single eye image as input, rather than requiring both eyes or the full face. This makes the method more practical for real-world usage.- The paper proposes an ensemble approach to gaze calibration, combining predictions from multiple models to get improved subject-specific calibration. - Overall, the paper aims to push gaze estimation accuracy higher using these techniques while keeping compute and data requirements low by only needing a single eye image.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Showing the effectiveness of ResNet and Inception architectures for gaze estimation, which tend to outperform standard CNNs commonly used for this task. 2. Demonstrating accurate gaze estimation with only a single eye image as input, achieving average errors of 2.312 cm without calibration and 1.951 cm with calibration. This could allow gaze estimation for cases where only one eye is visible.3. Proposing an ensemble calibration approach using predictions from multiple models to improve subject-specific gaze estimation. With this, they achieve errors of 1.439 cm with two eyes and 1.774 cm with one eye.4. Achieving strong results on the GazeCapture dataset while using lightweight model architectures, with their best Inception model having only 1.59M parameters. This could enable deployment of accurate gaze estimators on devices with limited compute.In summary, the key innovations seem to be using more advanced CV architectures like Inception for gaze estimation, showing one eye is sufficient for accurate predictions, and leveraging model ensembles to improve calibration. The results demonstrate high performance gaze estimation is possible even with small models and a single eye image.
