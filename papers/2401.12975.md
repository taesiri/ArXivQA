# [HAZARD Challenge: Embodied Decision Making in Dynamically Changing   Environments](https://arxiv.org/abs/2401.12975)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing embodied AI simulators lack support for dynamically changing environments characterized by unexpected events like fires, floods, or storms. Agents need to be able to perceive, reason about, and respond to such unpredictable environmental changes. 

Proposed Solution:
The authors propose a new simulated embodied benchmark called HAZARD (Embodied Decision Making in Dynamically Changing Environments) consisting of three disaster scenarios - indoor fire, indoor flood, and outdoor wind. They implement these scenarios by developing a simulation framework in ThreeDWorld that realistically models the visual effects, physics, and dynamics of spreading fire, rising floodwaters, and strong winds.

The benchmark requires agents to rescue target objects by transferring them to safe zones while contending with these environmental hazards which continuously evolve over time. The actions available to agents include navigation, picking up objects, and dropping them. The benchmark also provides an API to incorporate large language models that can take textual descriptions as input to select actions. 

The authors evaluate various baselines like random, rule-based, RL, Monte Carlo tree search agents as well as LLMs. The LLMs demonstrate effective zero-shot decision making by reasoning about factors like object distance and temperature. However, they struggle with effectively handling more complex dynamics of environmental changes.

Main Contributions:
1. Simulation of realistic fire, flood and wind effects that spontaneously change embodied environments over time
2. A novel benchmark (HAZARD) to test embodied agents' perception, reasoning and planning abilities in dynamic situations 
3. Analysis of different decision making pipelines (rule-based, RL, MCTS, LLM) in changing environments
4. Framework to integrate LLMs for selecting actions based on textual scene descriptions and history


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a new embodied AI benchmark called HAZARD for evaluating decision-making abilities of agents in dynamically changing disaster environments like fires, floods, and winds, and provides an analysis of using large language models as decision-makers.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1) Designing and implementing a new feature that enables the simulation of complex fire, flood, and wind effects for both indoor and outdoor virtual environments in the ThreeDWorld platform.

2) Developing a comprehensive benchmark, called HAZARD, for evaluating embodied decision-making in dynamically changing environments, as well as incorporating the LLM API into this benchmark.

3) Conducting an in-depth analysis of the challenges posed by perception and reasoning for existing methods, especially LLM-based agents in tackling the proposed HAZARD benchmark.

In summary, the key contribution is proposing the HAZARD benchmark to assess decision-making abilities of embodied agents in dynamic situations involving disasters like fires, floods, and winds. The paper also provides an analysis of different agent pipelines on this new benchmark.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this paper include:

- HAZARD - The name of the proposed benchmark for embodied decision making in dynamically changing environments.

- Fire, flood, wind - The three disaster scenarios included in the HAZARD benchmark, which present dynamic and challenging situations for embodied agents. 

- ThreeDWorld (TDW) - The simulation platform that HAZARD builds on top of to enable the fire, flood and wind effects.

- Procedural scene generation - A technique used in HAZARD to automatically generate diverse disaster scenes with dynamic changes. 

- Language models (LLMs) - The paper explores using large language models to assist with decision making and common sense reasoning for embodied agents in HAZARD.

- Evaluation metrics - Key metrics used to evaluate performance in HAZARD including rescued value rate, average rescue step, and average damage rate.

- Reinforcement learning, rule-based methods, search-based methods - Different agent pipelines analyzed in the paper for decision making in dynamic environments.

- Perception - A key challenge highlighted, as disaster effects obscure objects, hence the paper introduces a "with perception" variant of HAZARD.

In summary, the key focus is on using simulation, goal-based tasks, and evaluation metrics to systematically analyze decision making by embodied agents in dynamically changing disaster scenarios involving fire, flood or wind.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions using A* path planning to compress navigation actions for the LLM agent. What are the key challenges in designing an effective heuristic cost function for A* in these dynamic environments? How can historical observations be leveraged to construct better heuristics?

2. The LLM agent converts visual observations and historical memories into textual descriptions. What are some limitations of this conversion process? How can the textual encoding be improved to better capture aspects like spatial relationships, dynamics, etc.?  

3. The paper evaluates LLM agents based on GPT-3.5, GPT-4 and LLaMA. What are the key architectural differences between these models that lead to differences in performance on this benchmark? How can these models be adapted specifically for embodied AI tasks?

4. The LLM agent seems to struggle with effectively considering dynamics during decision making according to the failure cases. What enhancements can be made to the prompt design or model architecture to improve dynamic reasoning capabilities?

5. Could declarative memory systems that separately store episodic, semantic and procedural knowledge help improve the reasoning abilities of LLM agents in dynamic environments? If so, how can they be integrated into the current framework?

6. What mechanisms can be added to model the spreading dynamics in the fire and flood scenarios more realistically? How will more complex and stochastic dynamics affect the decision making process?  

7. The paper focuses only on object rescue tasks. What other complex multi-step tasks could be designed on top of the simulator to evaluate planning, collaboration, etc?

8. How suitable is the LLM agent framework for real-time decision making? What optimizations in perception, planning and control would be needed for deployment on physical robots?

9. The disaster scenarios are predefined in the current benchmark. How can more open-ended environment dynamics be introduced through physics simulation while retaining evaluation rigor?

10. The LLM relies largely on manually designed prompts. How can techniques like prompt tuning or on-policy prompt optimization be applied to autonomously learn better prompts for this task over time?
