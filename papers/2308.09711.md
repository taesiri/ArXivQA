# [Robust Monocular Depth Estimation under Challenging Conditions](https://arxiv.org/abs/2308.09711)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we develop robust monocular depth estimation methods that work reliably across diverse conditions, including challenging illumination (e.g. nighttime) and weather (e.g. rain)?The key hypotheses appear to be:1) Existing self-supervised monocular depth estimation methods fail in adverse conditions due to inability to establish accurate pixel correspondences across frames. 2) Existing supervised monocular depth methods fail in adverse weather due to learning artifacts from unreliable sensor (e.g. LiDAR) measurements.3) A simple and effective solution can be developed by always providing the model with valid training signals from ideal conditions, even when adverse samples are given as input. This allows using standard losses and exploiting existing methods' effectiveness in perfect settings.4) The same principles can be applied under both self-supervised and fully supervised settings to make models robust across different conditions with a single architecture.In summary, the central goal is developing monocular depth estimation techniques that work reliably in all conditions, which existing methods fail to do. The key hypotheses are that providing always valid training signals from ideal conditions can make standard models robust.


## What is the main contribution of this paper?

Based on my reading, the main contribution of this paper is proposing a simple and effective approach called md4all to enable monocular depth estimation models to work reliably under diverse conditions, including challenging ones like nighttime and rain. The key ideas are:- They show that existing state-of-the-art models fail under adverse conditions due to violations of learning assumptions (for self-supervised methods) or sensor artifacts (for supervised methods). - They propose to train the model by providing always valid training signals, as if it was sunny daytime. This is done by generating challenging images (e.g. night) corresponding to normal daytime images, but computing losses only on the normal daytime images.- They apply this idea to both self-supervised and fully supervised settings with simple modifications. - Extensive experiments show their method significantly outperforms prior works on nuScenes and Oxford RobotCar datasets. A single model can reliably estimate depth in day, night, rain etc.In summary, the main contribution is proposing a simple and effective training scheme to make existing models robust in diverse conditions, without complex architecture changes or inference modifications. The effectiveness is shown through extensive experiments outperforming prior works.
