# [Conditional Variational Autoencoder for Sign Language Translation with   Cross-Modal Alignment](https://arxiv.org/abs/2312.15645)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Sign language translation (SLT) aims to convert continuous sign language videos into textual sentences. This is a challenging cross-modal task due to the inherent modality gap between visual sign language videos and textual spoken language. Previous methods rely on an intermediate sign gloss representation to bridge this gap, but this may compromise results due to insufficient alignment across modalities. 

Proposed Solution:
The paper proposes a novel Conditional Variational Autoencoder framework for SLT (CV-SLT) to facilitate direct cross-modal alignment without gloss supervision. The model has two paths:

1) Prior path: Relies solely on visual input to predict target text. Models the marginal distribution of the visual modality.

2) Posterior path: Encodes both visual and textual input to reconstruct target text. Models the joint distribution of both modalities.  

Two KL divergences are used - one optimizes the CVAE and aligns encoder outputs by closing the uni-modal and bi-modal distributions. The second performs self-distillation from posterior to prior path, ensuring output consistency.

An Attention Residual Gaussian Distribution (ARGD) is proposed to better integrate textual information in the posterior path by modeling relative instead of absolute location/scale using cross-attention between modalities.

Main Contributions:

- First application of CVAE for sign language translation to align visual and textual modalities

- Introduction of a two-path prior/posterior framework with ARGD distribution and two KL regularizations for effective cross-modal alignment

- State-of-the-art performance on PHOENIX14T and CSL-daily datasets while mitigating the need for intermediate gloss, showing the promise of variational alignment for SLT.
