# [Utilizing Local Hierarchy with Adversarial Training for Hierarchical   Text Classification](https://arxiv.org/abs/2402.18825)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Hierarchical text classification (HTC) aims to categorize text into a set of hierarchically structured labels. Existing methods mainly focus on modeling the global label hierarchy but ignore the local hierarchy specific to each input text, which contains useful structured label co-occurrence information. 

Proposed Solution:  
The paper proposes a hierarchy-aware adversarial framework (\modelname) to incorporate local hierarchy into existing HTC models. The framework contains:

(1) A generator that encodes text and global hierarchy to get a text representation. This can be any existing HTC model. 

(2) An encoder that takes the local hierarchy as input and reconstructs an oracle representation. The encoder has an autoencoder structure to find the best representation for the local hierarchy.

(3) A discriminator that tries to distinguish between the generator's representation and the encoder's representation.

The generator is trained to fool the discriminator so its representation becomes similar to the oracle representation containing local hierarchy information. This is done through an adversarial loss.

Main Contributions:

- First framework to incorporate the full structure of local hierarchy for HTC using adversarial training
- Model-agnostic framework that can enhance various HTC models with a graph encoder 
- Achieves new SOTA results by enhancing latest models 
- Demonstrates the framework is adept at handling complex hierarchies and benefits rare classes

The core idea is to use adversarial training to inject local hierarchy information into existing models without relying on specific architectures. Experiments show consistent and significant improvements across datasets and backbones.
