# [Black-box Adversarial Attacks Against Image Quality Assessment Models](https://arxiv.org/abs/2402.17533)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Image quality assessment (IQA) models are used to automatically predict the perceptual quality of images. Recently, deep neural networks (DNNs) based no-reference IQA (NR-IQA) models have achieved state-of-the-art performance. 
- However, DNNs models are vulnerable to adversarial examples - small perturbations to input images that cause the models to make incorrect predictions. It is important to study potential vulnerabilities in NR-IQA models. 
- Prior work has studied white-box attacks on NR-IQA models. However, white-box attacks are impractical. Black-box attacks, where the adversary can only query the model, are more realistic.

Proposed Solution:
- The paper formulates the problem of black-box adversarial attacks on NR-IQA models. The goal is to maximize the deviation between the predicted quality scores of the original and adversarial images, while constraining the distortion to preserve visual quality.

- A bi-directional loss function is designed to directly mislead the predicted quality scores of adversarial examples in the opposite direction of original images. 

- An efficient black-box attack method is developed using this loss function. It has an initialization stage and an iterative optimization stage. The optimization uses a patch-based perturbation algorithm to generate adversarial examples.

Main Contributions:

- First study on black-box adversarial attacks against NR-IQA models.

- Effective bi-directional loss function tailored for the problem.

- Efficient black-box attack method combining the loss function and optimization algorithm.

- Extensive experiments showing NR-IQA models are vulnerable to the attacks, but perturbations are not transferable across models.

- New metric (RGO) to evaluate attack performance on IQA models.

- Observations that attacks can help investigate different properties of IQA models.

In summary, the paper provides significant new insights into vulnerabilities of NR-IQA models via black-box adversarial attacks, and paves the way for future research into hardening and evaluating these models.
