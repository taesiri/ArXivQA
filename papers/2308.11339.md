# ProAgent: Building Proactive Cooperative AI with Large Language Models

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: how can large language models (LLMs) be leveraged to build proactive cooperative AI agents that can effectively coordinate and adapt their behavior when collaborating with different types of teammates, including both AI agents and humans? The key hypothesis is that by harnessing the reasoning and planning capabilities of LLMs, it is possible to create cooperative AI agents (ProAgent) that can anticipate teammates' actions, dynamically formulate plans, and calibrate their own strategy to align with the teammate for more efficient cooperation. Unlike existing methods that rely on self-play or population-based training, this approach does not require prior experience interacting with specific teammates, enabling generalization to novel partners.In summary, the paper introduces a novel framework, ProAgent, to investigate the potential of LLMs for building cooperative AI agents that can understand teammates' intentions and adapt their own behavior accordingly, with the goal of enhancing coordination across diverse teammates without needing tailored training for each scenario.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Proposes a novel framework called ProAgent that leverages large language models (LLMs) to build a proactive agent for multi-agent cooperation. The key capabilities enabled by ProAgent include:- Actively predicting teammates' intentions and plans to enhance collaboration.- Dynamically adapting behavior to coordinate effectively with different teammates without prior training. - Interpretable reasoning through natural language interactions.2. Demonstrates ProAgent's effectiveness at cooperating with both AI agents and human proxy models in the Overcooked-AI environment. Experiments show it outperforms prior state-of-the-art methods like self-play, population-based training, and zero-shot coordination techniques.3. Provides an extensive analysis of ProAgent's reasoning process and how the different components like memory, planner, verificator and belief correction contribute to its cooperative skills. Reveals insights into how LLMs can be leveraged for cooperative AI.In summary, this paper proposes a novel LLM-based framework for building proactive and adaptive agents specialized for cooperation, and shows strong empirical results surpassing prior methods. The design and analysis provide useful guidelines on integrating LLMs into multi-agent systems.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the key points from the paper:The paper proposes ProAgent, a novel framework based on large language models that enables agents to dynamically adapt their behavior through cooperative reasoning and planning in order to collaborate effectively with other agents, either AI or human, across diverse coordination scenarios without requiring any prior training or finetuning.


## How does this paper compare to other research in the same field?

Here is a brief comparison of the key aspects of this paper to other related research:- This paper proposes ProAgent, a novel framework for building proactive cooperative AI agents using large language models (LLMs). The use of LLMs for cooperative AI is still relatively new and underexplored compared to more common approaches like deep reinforcement learning. - A key innovation of ProAgent is its ability to dynamically adapt behavior when cooperating with novel agents without any prior training, known as zero-shot coordination. Most existing methods rely on self-play or population-based training with different partners. ProAgent demonstrates superior generalization abilities.- ProAgent incorporates explicit modules and mechanisms for cooperative reasoning, planning, belief tracking, and memory. This contrasts with end-to-end learned policies that lack interpretability. The modular design also makes ProAgent easily adaptable to new tasks.- The Overcooked-AI environment used for evaluation requires tight coordination between agents. Compared to multi-agent environments with fully or partially observable state, it poses a greater challenge for cooperative skills.- While some recent works have also proposed LLM-based agents for interactive tasks, ProAgent is the first tailored for multi-agent coordination and demonstrates strong performance even with unfamiliar teammates.- The results provide new state-of-the-art performance on Overcooked-AI across multiple layouts and teammates. ProAgent outperforms prior algorithms including self-play, population-based training, and theory of mind methods.In summary, ProAgent makes important contributions in advancing LLM-based agents for the complex challenge of multi-agent coordination. The proactive adaptation, modular design, and strong empirical results help push forward research at the intersection of cooperative AI and large language models.
