# [Chain-of-Knowledge: Grounding Large Language Models via Dynamic   Knowledge Adapting over Heterogeneous Sources](https://arxiv.org/abs/2305.13269)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the key research focus of this paper is on augmenting large language models (LLMs) to enhance their factual correctness and reduce hallucination when handling knowledge-intensive tasks. 

Specifically, the paper proposes a new framework called "chain-of-knowledge" (CoK) that dynamically incorporates external knowledge from heterogeneous sources to ground the LLM's generated rationales and answers. The central hypothesis is that by progressively adapting relevant knowledge to correct the preliminary rationales step-by-step, the final answer consolidation will be more accurate and factually consistent. 

The authors identify three main limitations of prior work on incorporating knowledge into LLMs - using a single fixed knowledge source, relying primarily on unstructured text, and lacking progressive correction to prevent error propagation. CoK aims to address these limitations by:

1) Utilizing knowledge from multiple domains via an adaptive query generator that can leverage both structured and unstructured sources.

2) Correcting rationales progressively using retrieved knowledge to minimize inaccuracy propagation across steps. 

3) Consolidating the final answer using the corrected rationales as a more reliable foundation.

In summary, the central research question is whether the proposed CoK framework can effectively reduce hallucination and improve factual correctness of LLMs on knowledge-intensive tasks by dynamically adapting relevant knowledge to progressively refine the reasoning process. The hypothesis is that CoK will outperform baseline methods, as demonstrated through extensive experiments on various benchmark datasets.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. It proposes a new framework called chain-of-knowledge (CoK) to augment large language models (LLMs) with external knowledge from heterogeneous sources to reduce factual errors and hallucination. 

2. CoK has three main stages - reasoning preparation, dynamic knowledge adapting, and answer consolidation. It first generates preliminary rationales and identifies relevant knowledge domains. Then it corrects the rationales by retrieving knowledge from sources in those domains, doing so progressively to minimize error propagation. Finally, it produces the answer based on the corrected rationales.

3. CoK uses an adaptive query generator to query different knowledge sources in their native formats like SPARQL, SQL, or natural language. This allows accessing both structured and unstructured knowledge.

4. Experiments across different domains like factual, medical, physics, and biology show CoK consistently improves performance of LLMs on knowledge-intensive tasks compared to baselines.

5. The framework is modular allowing easy integration of different LLMs and knowledge sources. This helps address challenges like privacy, reliance on sources, and updating information.

In summary, the key contribution is a new knowledge-grounded framework to reduce factual errors in LLMs by progressively adapting external knowledge from diverse sources using tailored queries. The modular design also helps address important limitations.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a new framework called chain-of-knowledge (CoK) that improves the factual correctness of large language models on knowledge-intensive tasks by progressively incorporating external knowledge from heterogeneous sources and correcting rationales to minimize error propagation.
