# [SOTOPIA-$Ï€$: Interactive Learning of Socially Intelligent Language   Agents](https://arxiv.org/abs/2403.08715)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Current large language models (LLMs) lack strong social intelligence compared to humans, struggling with theory of mind, following social norms, and navigating diverse social scenarios. Bridging this gap to empower LLMs with human-like social decision-making abilities is an important and challenging problem.

Proposed Solution: The authors propose an interactive learning method called \model to improve the social intelligence of LLMs. The key ideas are:

(1) Automatically generate a diverse set of new social tasks using GPT-4, involving goals like negotiation, collaboration and competition between two characters.

(2) Collect conversational data between the LLM agents and an expert LLM agent (GPT-4) or between two instances of the LLM agent itself that role-play the characters.  

(3) Update the LLM policy using the conversational data filtered based on goal achievement ratings from GPT-4, through either behavior cloning (learning from expert) or self-reinforcement (learning from self).

(4) Evaluate using human ratings and GPT-4 based automated evaluation in the \sotopia social intelligence benchmark.

Main Contributions:

- Propose a novel interactive learning paradigm \model that combines automatic task generation, offline conversational data collection and policy update to improve LLM social intelligence.

- Demonstrate that self-reinforcement after behavior cloning boosts goal achievement on \sotopia to near expert (GPT-4) performance.

- Find that relying solely on GPT-4 based evaluation overestimates improvements compared to human judgment, indicating issues in current automated evaluation.

- Show that this training paradigm also improves LLM safety without hurting general question answering capability or causing catastrophic forgetting.

Overall, this work provides a way to efficiently and automatically train more socially intelligent LLMs, while highlighting open problems around evaluation and alignment.
