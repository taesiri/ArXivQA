# [On the Stability-Plasticity Dilemma of Class-Incremental Learning](https://arxiv.org/abs/2304.01663)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we effectively balance stability and plasticity in class-incremental learning models, so that they are able to retain knowledge about old classes while continuing to learn about new classes?The key hypotheses/claims explored in the paper are:- Most current class-incremental learning algorithms focus too heavily on stability (avoiding catastrophic forgetting of old classes) at the expense of plasticity (learning new classes). - This leads to feature representations that remain mostly static after initial training and do not accumulate much new knowledge as more data is encountered incrementally.- Analytic tools like centered kernel alignment (CKA) and classifier retraining can be used to evaluate the plasticity of class-incremental learning models.- Using these tools reveals that many recent algorithms have high stability but low plasticity in their learned feature representations.- Methods should aim for a better balance, even if the initial pretrained features seem reasonably good, in order to maximize the potential of continual learning.- Architectures that isolate/expand parameters per task (like DER) may be a promising direction, and efficiency can be improved (like with the proposed pDER).So in summary, the main focus is on analyzing and improving how class-incremental learning algorithms handle the stability-plasticity tradeoff, especially in terms of feature representation learning. Let me know if I have misinterpreted or missed any key aspects!


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:- It conducts an in-depth analysis on recent class-incremental learning (CIL) algorithms to understand how they balance stability and plasticity in the learned feature representations. - It finds that many CIL algorithms overly focus on stability while neglecting plasticity, such that the feature representations are mostly static after the initial training stage.- It introduces tools like Centered Kernel Alignment (CKA) and classifier finetuning for analyzing the stability and plasticity of CIL models.- It presents two simple but effective CIL algorithms - Partial-DER and Exploit - inspired by the findings from the analysis. Partial-DER improves an existing method while Exploit highlights issues with standard CIL evaluation metrics.- It suggests that the lack of plasticity in many CIL algorithms is partly due to limitations of commonly used evaluation metrics, which fail to properly measure continual learning of feature representations.In summary, the key contribution is providing new insights into modern CIL algorithms through systematic analysis, demonstrating issues like lack of plasticity and limited evaluation metrics, and presenting techniques to improve CIL based on these findings. The paper aims to encourage more focus on continual feature representation learning in future CIL research.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes and analyzes methods to measure the stability and plasticity of feature representations in class-incremental learning models, finding that most algorithms focus too heavily on stability over plasticity when learning new concepts incrementally.
