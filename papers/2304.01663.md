# [On the Stability-Plasticity Dilemma of Class-Incremental Learning](https://arxiv.org/abs/2304.01663)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we effectively balance stability and plasticity in class-incremental learning models, so that they are able to retain knowledge about old classes while continuing to learn about new classes?The key hypotheses/claims explored in the paper are:- Most current class-incremental learning algorithms focus too heavily on stability (avoiding catastrophic forgetting of old classes) at the expense of plasticity (learning new classes). - This leads to feature representations that remain mostly static after initial training and do not accumulate much new knowledge as more data is encountered incrementally.- Analytic tools like centered kernel alignment (CKA) and classifier retraining can be used to evaluate the plasticity of class-incremental learning models.- Using these tools reveals that many recent algorithms have high stability but low plasticity in their learned feature representations.- Methods should aim for a better balance, even if the initial pretrained features seem reasonably good, in order to maximize the potential of continual learning.- Architectures that isolate/expand parameters per task (like DER) may be a promising direction, and efficiency can be improved (like with the proposed pDER).So in summary, the main focus is on analyzing and improving how class-incremental learning algorithms handle the stability-plasticity tradeoff, especially in terms of feature representation learning. Let me know if I have misinterpreted or missed any key aspects!


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:- It conducts an in-depth analysis on recent class-incremental learning (CIL) algorithms to understand how they balance stability and plasticity in the learned feature representations. - It finds that many CIL algorithms overly focus on stability while neglecting plasticity, such that the feature representations are mostly static after the initial training stage.- It introduces tools like Centered Kernel Alignment (CKA) and classifier finetuning for analyzing the stability and plasticity of CIL models.- It presents two simple but effective CIL algorithms - Partial-DER and Exploit - inspired by the findings from the analysis. Partial-DER improves an existing method while Exploit highlights issues with standard CIL evaluation metrics.- It suggests that the lack of plasticity in many CIL algorithms is partly due to limitations of commonly used evaluation metrics, which fail to properly measure continual learning of feature representations.In summary, the key contribution is providing new insights into modern CIL algorithms through systematic analysis, demonstrating issues like lack of plasticity and limited evaluation metrics, and presenting techniques to improve CIL based on these findings. The paper aims to encourage more focus on continual feature representation learning in future CIL research.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes and analyzes methods to measure the stability and plasticity of feature representations in class-incremental learning models, finding that most algorithms focus too heavily on stability over plasticity when learning new concepts incrementally.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in the field of class-incremental learning (CIL):- The paper provides an in-depth analysis of the stability and plasticity of CIL models, which many prior works have not focused on. Past CIL papers have concentrated more on overall metrics like average incremental accuracy rather than investigating the properties of the learned features. This work sheds light on an important but understudied aspect.- Most prior CIL methods aim to mitigate catastrophic forgetting, often at the cost of plasticity. This paper shows through extensive experiments that many recent CIL algorithms overlook plasticity too much, to the point where feature representations stay largely static after the first incremental training stage. This is an important finding.- The paper introduces useful analysis techniques like classifier retraining and CKA to quantify stability and plasticity. These allow clearer evaluation compared to just using overall accuracy metrics. The t-SNE visualizations also help reveal how feature distributions evolve.- The proposed partial-DER method modifies an existing technique (DER) to improve scalability and performance, showing the benefit of the analysis. The exploitative method highlights flaws in common CIL metrics.- Overall, this paper stands out for its in-depth focus on feature representations, rigorous analysis and evaluation, and findings that question the progress of recent CIL methods. The analysis techniques and insights could influence future research directions.In summary, this paper provides a valuable contribution by taking a deeper look at an overlooked but critical aspect of CIL - the balance of stability and plasticity in learned features. The analysis techniques and findings suggest new ways of designing and evaluating continual learning algorithms.
