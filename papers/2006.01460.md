# Situated and Interactive Multimodal Conversations

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, here is a summary of the key research focus:The paper introduces a new task of Situated Interactive MultiModal Conversations (SIMMC) aimed at building next generation virtual assistants that can handle evolving multimodal inputs and actions grounded in a shared, co-evolving context. The central hypothesis is that task-oriented dialog agents need to be able to process multimodal inputs (e.g. vision, dialog history, user utterances) and execute multimodal actions (e.g. manipulate objects in a 3D environment, highlight images) that are situated within and dynamically update a shared multimodal context. To study this hypothesis, the paper presents two new multimodal dialog datasets collected using a Wizard-of-Oz setup - SIMMC-Furniture grounded in a shared VR environment, and SIMMC-Fashion grounded in a stream of images.The key research questions addressed using these datasets are:- How to model task-oriented dialog agents that can understand user requests and intents based on both dialog history and a situated multimodal context? - How to generate system responses and actions that manipulate the shared multimodal context in a meaningful way?- How to build systems that can track dialog state and coreferences across modalities over multiple turns?The paper proposes several tasks like action prediction, response generation and dialog state tracking on the datasets to study these questions. It also provides baseline results using adaptations of existing models like memory networks, transformers etc.In summary, the central focus is on studying situated, interactive multimodal conversations where the dialog is grounded in an evolving, shared multimodal context, which is hypothesized to be important for building real-world assistants. The new datasets and tasks are proposed to facilitate research in this direction.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:1. The introduction of Situated Interactive MultiModal Conversations (SIMMC) as a new research direction towards building next-generation virtual assistants that can handle evolving multimodal inputs and contexts. 2. The creation of two new multimodal dialog datasets collected using a Wizard-of-Oz setup: SIMMC-Furniture (grounded in a shared virtual environment) and SIMMC-Fashion (grounded in a shared set of images). The datasets consist of around 13k human-human dialogs comprising 169k utterances.3. A novel SIMMC dialog annotation schema that provides semantic annotations like contextual NLU, NLG, coreference etc. using a unified ontology for user and assistant utterances. This enables richer grounding of conversations in the shared multimodal context.4. Formulation of several tasks within the SIMMC framework like assistant API prediction, response generation, dialog state tracking etc. that can leverage the collected datasets. Strong initial baselines are presented using adaptations of existing models.5. Public release of the datasets, annotation schema, models and leaderboards to facilitate further research in this new direction at the intersection of dialog systems and multimodal machine learning.In summary, the paper aims to catalyze the development of next-gen assistants that can perceive and interact with users in multimodal environments, by providing novel multimodal corpora, annotations, tasks and baselines as a unified framework. The key novelty lies in the situated, interactive nature of the dialogs grounded in dynamically evolving multimodal contexts.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper introduces two new multimodal dialog datasets for situated conversations grounded in evolving visual contexts, along with a flexible annotation framework, tasks, and benchmark results using adaptations of existing dialog models.
