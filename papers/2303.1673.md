# [Near Optimal Memory-Regret Tradeoff for Online Learning](https://arxiv.org/abs/2303.1673)

## What is the central research question or hypothesis that this paper addresses?

This paper addresses the fundamental question of whether it is possible to obtain low regret in the online learning with experts problem using limited memory. The key hypothesis is that there exist algorithms that can achieve vanishing regret (i.e. regret that is o(T) where T is the number of rounds) while using only sublinear memory in the number of experts n and the number of rounds T. Specifically, the paper makes the following main contributions:1. For the oblivious adversary setting, the paper presents an algorithm that obtains ~O(sqrt(nT/S)) regret using only S memory, nearly matching the lower bound of Ω(sqrt(nT/S)) from prior work. This resolves the open question of whether vanishing regret is possible with limited memory against an oblivious adversary.2. For the adaptive adversary setting, the paper gives an algorithm that obtains ~O(sqrt(nT/S)) regret with ~O(sqrt(n)) memory, proving that sublinear memory suffices to obtain vanishing regret even against an adaptive adversary. 3. The paper also provides a new lower bound showing that Ω(sqrt(n)) memory is necessary against an adaptive adversary, proving the optimality of the proposed algorithm.Overall, this paper significantly advances our understanding of the memory-regret tradeoffs for online learning with experts, obtaining nearly tight upper and lower bounds in both the oblivious and adaptive settings. The techniques introduced, including robust pooling/pruning methods and novel regret amortization schemes, are important contributions.


## What is the main contribution of this paper?

Based on my understanding, the main contributions of this paper are:1. It provides a new online learning algorithm against an oblivious adversary that achieves near-optimal memory-regret tradeoff. Specifically, the algorithm uses $\text{polylog}(nT)$ space and obtains $\tilde{O}(\sqrt{nT})$ regret, nearly matching the lower bound of Ω(\sqrt{nT/S}) proved in prior work. This resolves the open question on optimal memory-regret tradeoff posed by previous work. 2. It gives the first online learning algorithm against an adaptive adversary that achieves sublinear regret using sublinear space. In particular, the algorithm uses $\tilde{O}(\sqrt{n})$ space and achieves $o(T)$ regret.3. It provides a novel lower bound showing that $\tilde{\Omega}(\sqrt{n})$ space is necessary to obtain $o(T)$ regret against an adaptive adversary. This lower bound is based on a reduction to the direct sum problem in communication complexity.4. The techniques introduced, including the eviction rules for maintaining experts, interval regret guarantees, and the accounting scheme for amortizing regret, seem novel and potentially useful for other online learning problems.In summary, this paper significantly advances our understanding of the interplay between memory and regret in online learning against oblivious and adaptive adversaries. The memory-regret tradeoffs obtained are essentially optimal, resolving open questions from prior work.
