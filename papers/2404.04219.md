# [Continual Policy Distillation of Reinforcement Learning-based   Controllers for Soft Robotic In-Hand Manipulation](https://arxiv.org/abs/2404.04219)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Developing effective controllers for soft robotic hands to perform complex in-hand object manipulation is challenging. Typically requires extensive online reinforcement learning (RL) which is time-consuming. 
- After deployment, the training environment may not be accessible anymore to improve the controllers.
- Research question: How to continually enhance the manipulation skills of a soft robotic hand by integrating knowledge from different pre-trained controllers without needing access to original training environments?

Proposed Solution:
- Develop individual expert controllers for manipulating different objects using online RL.
- Propose a Continual Policy Distillation (CPD) framework to integrate multiple expert policies into one unified policy in an offline setting without access to original environments. 
- Formulate it as a domain-incremental continual learning problem with a limited memory buffer.
- Employ replay-based rehearsal strategies like exemplar reservoir sampling to retain crucial experiences and mitigate catastrophic forgetting.

Key Contributions:
- Customized PyBullet env with various objects for benchmarking in-hand manipulation.
- Learned 5 distinct expert policies using PPO RL algorithm for manipulating different objects.
- Formalized CPD algorithm combining policy distillation and exemplar replay for continual learning.
- Demonstrated CPD enables efficient integration of multiple experts alleviating the need for online RL.
- Evaluate various experience replay strategies w.r.t buffer size constraints.
- Proposed reward-based reservoir sampling strategy strikes a balance between performance and diversity of stored experiences.

In summary, the key novelty is in formulating a CPD approach to continually enhance soft robotic manipulation by integrating multiple specialized policies without needing access to original training environments. The core ideas combine imitation learning and continual learning concepts to develop versatile robotic hand controllers.
