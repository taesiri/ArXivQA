# [Multi-Agent Reinforcement Learning with a Hierarchy of Reward Machines](https://arxiv.org/abs/2403.07005)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Existing works on multi-agent reinforcement learning (MARL) with reward machines (RMs) suffer from several limitations when dealing with complex cooperative tasks:
1) They rely on the assumption of weak interdependencies among agents, thus cannot handle scenarios where agents are highly interdependent. 
2) They are limited to simple prior knowledge where each high-level event only consists of a single proposition. This makes it hard to specify tasks with multiple concurrent events.

Proposed Solution:
This paper proposes Multi-Agent Reinforcement Learning with a Hierarchy of Reward Machines (MAHRM). The key ideas are:

1) Utilize a hierarchical structure of propositions where higher level propositions temporally abstract lower level ones. Each proposition represents a subtask assigned to a group of agents.  

2) Derive a hierarchy of RMs from this structure, with each RM defining rewards for the subtask of one proposition.

3) Learn policies similarly to hierarchical RL: higher level policy chooses lower level subtasks to execute while lowest level policy determines actions of agents.  

4) Eliminate unreasonable selections of subtasks using internal structure of RMs to improve learning efficiency.

5) Enable dynamic decomposition of joint task by assigning different subtasks to agents over time.

Main Contributions:

1) Proposes MAHRM framework that handles complex cooperative MARL scenarios with highly interdependent agents and concurrent events.

2) Reduces size of state/action spaces by hierarchical decomposition into subtasks over groups of agents.

3) Coordinates agents via hierarchical policies derived from hierarchy of RMs specifying rewards.

4) Outperforms baselines using same high-level knowledge on cooperative navigation, Minecraft and multi-agent passage domains.

In summary, this paper introduces a novel MARL approach MAHRM that leverages hierarchical abstraction of events as prior knowledge to efficiently decompose complex cooperative tasks over interdependent agents. Experiments demonstrate state-of-the-art performance on several multi-agent domains.
