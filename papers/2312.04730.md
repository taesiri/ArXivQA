# [DeceptPrompt: Exploiting LLM-driven Code Generation via Adversarial   Natural Language Instructions](https://arxiv.org/abs/2312.04730)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper explores the security vulnerabilities in code generated by Large Language Models (LLMs) which are being increasingly used for code generation from natural language descriptions. Specifically, it examines if existing LLMs can consistently generate functionally correct and vulnerability-free code when presented with variations of natural language instructions that preserve the original semantics. This is an important open question as LLMs are being deployed in many applications without a thorough understanding of their robustness.

Proposed Solution - DeceptPrompt:
The paper proposes a novel framework called DeceptPrompt that can generate adversarial natural language prompts to attack LLMs and compel them to generate functionality-preserving code with specific vulnerabilities. It has three main components:

1) Prefix/Suffix Generation: Generates benign non-indicative prefixes/suffixes to provide contextual framing without vulnerability signals. 

2) Fitness Function: Guides optimization towards adversarial objectives by defining target vulnerable code and custom loss functions focused on preserving functionality while increasing probability of targeted vulnerabilities.

3) Semantic Preserving Evolution: Optimizes prefixes/suffixes using genetic algorithms to maintain semantic meaning while reducing loss, through operations like crossover, mutation and word substitution.

Main Contributions:

- Formulation of a practical threat model to evaluate robustness of LLMs for code generation using adversarial natural language attacks.

- A systematic framework, DeceptPrompt, to generate such attacks using semantic preserving prompts and tailored optimization.

- Extensive analysis of different LLMs including CodeLlama, StarCoder and WizardCoder revealing high attack success rates, highlighting significant weaknesses in existing models.

- Investigation of impact of factors like programming languages, vulnerability injection strategies, location/length/diversity of prompts etc. on attack performance.

In summary, the paper undertakes a comprehensive exploration around security of LLMs for code generation to reveal vulnerabilities that need to be urgently addressed before their widespread deployment.
