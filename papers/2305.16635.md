# [Impossible Distillation: from Low-Quality Model to High-Quality Dataset   &amp; Model for Summarization and Paraphrasing](https://arxiv.org/abs/2305.16635)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be whether language models can learn to summarize and paraphrase sentences without requiring massive scale, instruction data, or human feedback. The key hypothesis appears to be that small, off-the-shelf language models possess latent knowledge about these tasks, even if the models themselves cannot reliably solve the tasks. The paper proposes that this latent knowledge can be identified and amplified into a high-quality dataset and task-specific model, allowing efficient and effective training without the typical resources used for unsupervised summarization and paraphrasing.In summary, the central research question is whether task-specific models for summarization and paraphrasing can be distilled from small language models, without scale or supervision. The hypothesis is that small LMs contain latent knowledge that can be extracted and amplified to create high-quality datasets and models for these tasks.


## What is the main contribution of this paper?

The main contribution of this paper seems to be proposing a new framework called Impossible Distillation that can distill a high-quality task-specific dataset and model from an off-the-shelf language model, without requiring large scale or human supervision. Specifically, the key ideas are:1) Generating candidate input-output pairs for a task (e.g. summarization) directly from a pre-trained LM using constrained decoding strategies.2) Filtering high-quality pairs using task-specific filters based on entailment, length, diversity etc. 3) Using the generated dataset to train an initial task model, then further amplifying its capability via self-distillation.The end result is a compact yet powerful model that can outperform much larger LMs like GPT-3 on summarization and paraphrasing, as demonstrated through both automatic metrics and human evaluation.Additionally, the framework produces a large high-quality dataset as a byproduct, which exhibits more diversity and effectiveness than human-authored datasets based on their analysis.Overall, the key novelty seems to be distilling task knowledge directly from a pre-trained LM into a dataset and model without relying on scale or supervision, while achieving strong performance. The proposed framework and analysis around the dataset quality are the main contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a novel framework called Impossible Distillation that can distill high-quality datasets and models for summarization and paraphrasing tasks directly from off-the-shelf language models, without requiring massive scale or human supervision.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other related research:- The approach of distilling task knowledge directly from an off-the-shelf language model, without large-scale training or human supervision, is quite novel. Most prior work on unsupervised summarization/paraphrasing relies on task-specific losses or human-written instruction data. This paper shows such specialized resources may not be necessary.- The idea of constraining language model decoding to generate candidate pairs, then filtering with separate criteria, is clever. This avoids having to fine-tune the model directly for the tasks. Similar ideas have been explored for commonsense reasoning, but not as much for text generation.- Demonstrating strong performance by a 770M parameter model, surpassing 175B GPT-3, is impressive. It suggests that model scale alone does not determine summarization/paraphrasing capability; the distillation process matters. Comparisons to models 20x-200x larger are not frequently shown.- Analyzing the diversity and usefulness of the generated dataset is novel. Most work evaluates the end model rather than the data itself. The analyses show advantages over human-written datasets in terms of diversity and applicability to new domains.- Overall, the paper makes excellent contributions in showing how we can unlock latent knowledge in standard LMs, without scale or supervision. The distillation framework is general and the analyses shed light on properties of synthetic vs human datasets. I would say this paper significantly pushes forward the state of the art in task-oriented language model distillation.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Applying Impossible Distillation to a broader range of tasks beyond sentence summarization and paraphrasing, such as translation. The authors suggest generating a parallel corpus for translation by leveraging multilingual LMs and cross-lingual evaluation metrics.- Adapting Impossible Distillation for longer input-output pairs, like paragraph-level summarization. The authors propose a strategy of first generating the input article, then sequentially generating zero-shot summaries with a fixed separator.- Generalizing Impossible Distillation to more complex tasks like commonsense reasoning, where defining high-quality examples is non-trivial. The authors suggest co-evolving the task model and filter model throughout the distillation stages. - Incorporating techniques for automatic bias detection and reduction into Impossible Distillation, to allow for safer knowledge transfer between language models.- Releasing code and models to allow for further research and application of Impossible Distillation.In summary, the main future directions focus on extending Impossible Distillation to new tasks and settings, adapting it to longer texts, improving the filtering process, mitigating risks, and sharing resources to enable further research. The authors frame Impossible Distillation as a promising and reusable framework for distilling knowledge from language models.
