# [WhisBERT: Multimodal Text-Audio Language Modeling on 100M Words](https://arxiv.org/abs/2312.02931)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper introduces WhisBERT, a novel masked language model architecture for multimodal text-audio pretraining. WhisBERT contains separate encoders for text and audio data streams, which are trained on matched text-audio pairs from a 100 million word subset of the People's Speech dataset. The model employs a combination of unimodal and multimodal training objectives, including masked language modeling, masked audio modeling, multimodal contrastive loss, masked multimodal modeling, and audio-text matching. WhisBERT is evaluated by comparing a text-only version against one trained on both text and audio. Results are mixed - the text-only model achieves higher scores on 12/17 test suites, while the multimodal model shows improvements on tests involving complex syntax. Both models outperform previous baselines. Limitations of the current work include challenges with the dataset and restrictions from the BabyLM setup. Future work involves scaling up training data and modifications to the architecture. Overall, this work provides a first step towards exploring multimodal text-audio pretraining for improving model efficiency.
