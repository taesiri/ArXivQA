# [LANCE: Stress-testing Visual Models by Generating Language-guided   Counterfactual Images](https://arxiv.org/abs/2305.19164)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the key research question seems to be:How can we automatically generate challenging and realistic counterfactual examples to systematically stress-test visual recognition models?The paper proposes an approach called LANCE (Language-guided Counterfactual Examples) to address this question. The key ideas are:- Use language as a discrete intermediate representation to perform targeted interventions on images. Perturbing text is easier than perturbing pixels directly.- Leverage recent advances in language models and image generation models to edit image captions and generate corresponding counterfactual images.- Benchmark models on counterfactual test suites to quantify drops in performance and sensitivity to different types of edits (e.g. changing object, background, etc).- Discover class-specific failure modes and biases by analyzing model performance on tailored counterfactual examples.So in summary, the main hypothesis is that language-guided counterfactual image generation can serve as an automated way to stress-test vision models by creating challenging and realistic example sets that standard IID test sets lack. The paper aims to demonstrate this methodology and its applications.
