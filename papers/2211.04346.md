# [Cross-Attention is all you need: Real-Time Streaming Transformers for   Personalised Speech Enhancement](https://arxiv.org/abs/2211.04346)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to improve personalised speech enhancement (PSE) by using more adaptive representations of the target speaker's voice profile, rather than a fixed embedding vector. Specifically, the paper proposes a novel cross-attention approach to generate flexible speaker embeddings for PSE, instead of using a constant single vector extracted from enrollment audio. The hypothesis is that a fixed speaker embedding may not capture variations in the target speaker's voice over time and across different utterances. To test this, the paper develops streaming Transformer models with cross-attention between the target speaker enrollment states and the input noisy speech states. This allows the model to dynamically attend to suitable target speaker representations when enhancing the input audio.The key hypotheses tested are:- Using cross-attention over enrollment states instead of a fixed mean/last pooling vector improves PSE performance.- Cross-attention provides more adaptive speaker embeddings compared to concatenation of a fixed embedding.- The improvements are due to more flexible speaker embeddings, not just model architecture.- Cross-attention helps more for babble noise than ambient, as it relies more on precise speaker information.- The benefits hold for both single and multiple enrollment utterances.So in summary, the paper focuses on improving PSE through more adaptive speaker embeddings generated via cross-attention. The experiments aim to validate that this approach outperforms baselines that use a fixed embedding vector.
