# [Segment Beyond View: Handling Partially Missing Modality for   Audio-Visual Semantic Segmentation](https://arxiv.org/abs/2312.08673)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper introduces a new semantic segmentation task called "out-of-view semantic segmentation" for augmented reality user safety. The key challenge is that AR devices have a limited field of view, so cannot see potential hazards approaching from outside their view. To address this, the authors propose Segment Beyond View (SBV), an audio-visual semantic segmentation model. SBV takes first-person view images and binaural audio as input, and leverages distillation from a visual teacher with panoramic view and an auditory teacher with 8-channel audio at training time. This allows SBV to effectively segment sound-making objects even when they are outside the field of view at test time. Experiments on a public dataset show SBV outperforms state-of-the-art methods, especially for out-of-view segmentation. The model also maintains performance across varying field of view sizes and with mono audio input. The task and SBV model have implications for improving safety for AR users and pedestrians navigating real world environments with potential unseen hazards.
