# [DragTex: Generative Point-Based Texture Editing on 3D Mesh](https://arxiv.org/abs/2403.02217)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "DragTex: Generative Point-Based Texture Editing on 3D Mesh":

Problem:
- Existing methods for generative 3D texture editing rely on text prompts or scribbles, which lack precise spatial control. 
- Directly applying 2D image drag editing techniques to 3D meshes leads to issues like inconsistent textures across views, error accumulation, and long training times.

Proposed Solution:
- DragTex - a generative point-based texture editing method for 3D meshes, enabling direct dragging interactions on the mesh surface.

Key Ideas:
- Noisy Latent Image Blending: Blend the latent representations near object silhouettes between the dragged view and neighboring views. Eliminates texture inconsistency across views.
- Detail Reconstruction: Fine-tune the decoder to reconstruct details in non-drag regions while preserving drag effects. Mitigates error accumulation. 
- Multi-View Training: Pre-train the model using multi-view images of the mesh. Significantly reduces training time compared to per-view training.

Main Contributions:
- First point-based texture editing method for 3D meshes based on generative models
- Noisy latent image blending and detail reconstruction techniques to enhance quality
- Multi-view training strategy to improve efficiency
- Qualitative and quantitative experiments demonstrating high-quality texture editing aligned with user drag interactions

In summary, DragTex advances state-of-the-art in intuitive 3D texture editing by adapting generative 2D drag techniques through innovations like cross-view fusion, detail reconstruction and multi-view training.
