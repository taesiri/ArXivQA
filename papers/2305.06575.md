# [Chain-of-Dictionary Prompting Elicits Translation in Large Language   Models](https://arxiv.org/abs/2305.06575)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research question this paper addresses is:How can we leverage chained multilingual dictionaries to improve the machine translation capabilities of large language models (LLMs) when translating low-resource languages?The paper proposes a new framework called CoD (Chain-of-Dictionary Prompting) that incorporates chained multilingual dictionary knowledge directly into the prompt to guide the LLM's translation decisions, especially for rare/unseen words. Specifically, the prompts consist of:1) The standard translation request (e.g. "Translate from French to English:")2) Chained multilingual dictionary entries linking words in the source, target, and auxiliary languages (e.g. "limite means limit means Grenze means ...")The hypothesis is that providing this lexical knowledge in a chained multilingual format will improve the LLM's ability to translate low-resource languages compared to standard prompting alone or other techniques like bilingual dictionaries or few-shot learning. Experiments on 200 languages in the FLORES benchmark dataset are conducted to evaluate this hypothesis.In summary, the key research question is whether chained multilingual dictionaries can enhance prompting-based machine translation for low-resource languages when used to augment large pre-trained LLMs.
