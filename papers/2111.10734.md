# [Deep Probability Estimation](https://arxiv.org/abs/2111.10734)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question addressed in this paper is:How can we build models that reliably estimate probabilities for events with inherent uncertainty, using high-dimensional data and deep neural networks?The authors note that deep neural networks trained for classification often produce inaccurate probability estimates. They point out that existing work on calibrating classifier outputs focuses on model uncertainty and does not address cases where there is inherent, aleatoric uncertainty in the problem itself. The key hypotheses appear to be:1) Probability estimation is fundamentally different from classification when there is aleatoric uncertainty. Existing calibration methods developed for classification may not work well.2) Overfitting is a key challenge, and will cause neural network models to eventually just memorize training outputs instead of learning to estimate probabilities. 3) New methods are needed to properly train neural networks for probability estimation with aleatoric uncertainty. The authors propose a method called CaPE that alternates between reducing a discrimination loss and a calibration loss during training.So in summary, the main research question is how to develop models that can reliably estimate probabilities in problems with inherent uncertainty, using deep neural networks. The key hypotheses relate to the limitations of existing calibration methods, the issue of overfitting, and a proposed solution method called CaPE.
