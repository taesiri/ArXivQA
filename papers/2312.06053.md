# [IEKG: A Commonsense Knowledge Graph for Idiomatic Expressions](https://arxiv.org/abs/2312.06053)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed summary of the key points from the paper:

This paper proposes a novel knowledge graph called IEKG (Idiomatic Expression Knowledge Graph) that focuses specifically on representing commonsense knowledge related to the figurative interpretations and usage of idiomatic expressions (IEs). The goal is to provide explicit IE knowledge to enable neural models to better comprehend IEs. IEKG extends the ATOMIC knowledge graph by adding 56k knowledge tuples covering over 1200 IEs using 11 relation types that describe causes, effects, intents, reactions, etc. related to the subject and object of an IE event. 

Experiments demonstrate IEKG's high quality via human and automatic evaluation. When used to train knowledge models, IEKG generalizes better to unseen IEs and unseen relations compared to only using ATOMIC. Applications show that injecting IEKG knowledge significantly benefits neural models on IE comprehension tasks like natural language inference and continuation classification, outperforming both baseline pretrained models and models fine-tuned only on task-specific datasets. For example, on the IMPLI natural language inference benchmark containing IEs, an IEKG-injected BART model achieves state-of-the-art performance, even generalizing to unseen IEs. Overall, explicitly representing figurative IE knowledge in IEKG enables neural models to achieve better IE comprehension abilities.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Idiomatic expressions (IEs) are challenging for natural language processing systems to comprehend due to their non-compositional nature. Prior work has focused on learning IE representations implicitly from limited idiomatic sentences. However, the contextual information in these sentences is often sparse, making it difficult for models to learn the meanings of IEs. 

Proposed Solution:
The paper proposes IEKG, a commonsense knowledge graph focused on figurative interpretations of IEs. IEKG organizes knowledge related to 1,229 IEs and 11 relation types covering causes, effects, attributes etc. It has over 56K knowledge tuples created via human annotation. 

The paper shows IEKG can be used to train knowledge models by transforming various pre-trained language models like BERT, BART etc. on the knowledge tuple completion task. Experiments demonstrate trained knowledge models have improved ability to complete unseen knowledge tuples of seen IEs and generalize to unseen IEs.

The paper also shows injecting knowledge from IEKG improves IE comprehension. A BART model injected with IEKG knowledge achieves state-of-the-art results on natural language inference using the IMPLI benchmark containing IEs. It also shows significant gains on a continuation classification task using the Figurative Narrative Benchmark.

Main Contributions:

1) Proposes IEKG, a commonsense knowledge graph focused on figurative interpretations of idioms with over 56K tuples.

2) Demonstrates IEKG can transform various pre-trained language models into knowledge models for idiom knowledge inference and generalization.

3) Shows injecting IEKG knowledge improves pre-trained language model's IE comprehension ability, achieving SOTA results on IE NLI and sizable gains on continuation classification.
