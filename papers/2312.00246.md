# [Curvature Explains Loss of Plasticity](https://arxiv.org/abs/2312.00246)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
The paper investigates the phenomenon of "loss of plasticity" in neural networks, which refers to the gradual loss of a neural network's ability to continue learning on new tasks over time. Specifically, the paper studies continual supervised learning settings where the distribution of data periodically changes, requiring the model to continually adapt. It is observed that model performance tends to degrade on later tasks, exhibiting the loss of plasticity, but the exact mechanisms leading to this are not well understood. 

Proposed Explanation:  
The paper hypothesizes that loss of curvature, measured by a shrinking of the rank of the Hessian matrix of the loss, is a primary cause of loss of plasticity. Intuitively, lower curvature implies fewer directions that the loss can move to continue improving, hindering further learning. Empirically, the paper shows that measures of curvature align closely with loss of plasticity over time across various continual learning benchmarks.

Proposed Solution:
To mitigate loss of curvature, the paper proposes a "Wasserstein initialization regularizer" that keeps the distribution of weights close to their initial distribution, while still allowing flexibility. This is shown to preserve curvature better and sustain plasticity compared to alternatives like L2 regularization.  

Key Contributions:
- Systematically investigates and provides counterexamples refuting previous hypothesized explanations for loss of plasticity 
- Establishes empirical evidence across benchmarks demonstrating correlation and precedance between loss of curvature and loss of plasticity
- Proposes loss of curvature as a consistent underlying explanation for loss of plasticity
- Introduces Wasserstein initialization regularizer that mitigates curvature loss and preserves plasticity across tasks

The paper offers loss of curvature as a novel lens for understanding, analyzing and addressing the longstanding challenge of loss of plasticity in continual learning. The proposed regularizer also offers a simple and effective technique to sustain plasticity.
