# [Understanding Survey Paper Taxonomy about Large Language Models via   Graph Representation Learning](https://arxiv.org/abs/2402.10409)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
As research on Large Language Models (LLMs) proliferates rapidly, it has become difficult for researchers, especially newcomers, to keep up with all the new models and survey papers summarizing progress in this field. The increasing volume of survey papers itself poses a challenge. This paper aims to develop a method to automatically categorize LLM survey papers into a taxonomy to aid researchers in seeing new trends and focusing on papers relevant to their work.

Proposed Solution:
1. Collected metadata of 144 LLM survey papers and designed a taxonomy with 16 categories, including applications-focused and model techniques-focused branches.

2. Constructed 3 types of attributed graphs - text graphs, co-author graphs, and co-category graphs from paper metadata. Text graphs connect papers to words, co-author graphs connect papers by shared authors, and co-category graphs connect papers by shared arXiv categories.  

3. Evaluated graph neural networks (GCN specifically) on graph representation learning (GRL) for classifying papers into the designed taxonomy on 3 data subsets with differing categories.

4. Compared GRL to fine-tuning pretrained language models on paper text and zero-shot classification by LLMs like Claude and GPT-3.5. Also compared to human/student classification performance.

Key Results:
1. GRL on co-category graphs significantly outperforms LMs and even exceeds average human recognition accuracy, overcoming challenges like small dataset size and class imbalance.

2. Ablation studies on co-category graphs show both computer science categories aid GCN classification despite not mapping directly to designed taxonomy.

3. Fine-tuning LMs on text data using GCN-generated weak labels outperforms ground truth labels, demonstrating potential for weak-to-strong generalization.

Main Contributions:  
1. New taxonomy for categorizing LLM survey papers.

2. Showing GRL on co-category graphs can effectively categorize papers, overcoming data challenges.

3. Demonstrating GRL surpasses LMs for taxonomy classification on this data.

4. Revealing potential for improving LM fine-tuning using GRL-generated weak labels.
