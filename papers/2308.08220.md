# [Low-Light Image Enhancement with Illumination-Aware Gamma Correction and   Complete Image Modelling Network](https://arxiv.org/abs/2308.08220)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we develop an effective deep learning model for low-light image enhancement that overcomes the limitations of previous methods? Specifically, the paper proposes a new model called Illumination-Aware Gamma Correction (IAGC) network that aims to address two key challenges:1) Existing methods are insensitive to learning effective illumination-recovering representations from low-light images. The paper proposes using adaptive gamma correction modules (GGCM and LGCM) to overcome this limitation.2) Convolutional neural networks have inductive biases like locality that make them ineffective for modeling large-scale dark regions in images. The paper proposes a novel COMO-ViT transformer block with hierarchical self-attention to model both local and global dependencies.So in summary, the central hypothesis is that by combining adaptive gamma correction and hierarchical self-attention in the IAGC network architecture, they can develop a more effective model for low-light image enhancement compared to prior arts. The experiments aim to demonstrate the superiority of IAGC over other methods quantitatively and qualitatively.


## What is the main contribution of this paper?

This paper presents a new method for low-light image enhancement called Illumination-Aware Gamma Correction (IAGC). The main contributions are:- Proposing to use adaptive gamma correction to enhance illumination. They introduce two modules - Global Gamma Correction Module (GGCM) and Local Gamma Correction Module (LGCM) to predict global and local gamma factors. This makes the model adaptively enhance images based on content. - Using Taylor series approximation for gamma correction to reduce computational complexity.- Proposing a new vision Transformer called COMO-ViT that models dependencies between all pixels using a hierarchical local-global attention mechanism. This allows using context from bright regions to infer dark regions. - Combining the gamma correction modules and COMO-ViT transformer in an end-to-end framework called IAGC that achieves state-of-the-art performance on benchmark datasets.In summary, the key novelty is using adaptive gamma correction guided by CNNs/Transformers and modelling long-range dependencies with the COMO-ViT transformer to effectively recover illumination and details from low-light images.
