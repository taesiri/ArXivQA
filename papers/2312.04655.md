# [ECLIPSE: A Resource-Efficient Text-to-Image Prior for Image Generations](https://arxiv.org/abs/2312.04655)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Text-to-image (T2I) diffusion models like DALL-E 2 achieve state-of-the-art performance but require massive computational resources. Specifically, the "unCLIP" models used in DALL-E 2 employ a separate text-to-image prior module with over 1 billion parameters, greatly increasing model size and data requirements compared to Latent Diffusion Models. The key questions are whether this prior module contributes substantially to performance, or if simply scaling up model size is the reason for improved results. There is a need for more efficient unCLIP models.

Proposed Solution:
This paper proposes ECLIPSE, a novel contrastive learning strategy to train compact yet high-performing text-to-image prior models for the unCLIP framework. Specifically:

1) ECLIPSE trains non-diffusion prior models which are more parameter-efficient and converge faster than diffusion priors. Empirical analysis shows diffusion priors offer negligible benefits. 

2) A projection loss maps text embeddings to vision embeddings. However, this can lead to overfitting on the training distribution.

3) Contrastive learning with CLIP provides additional supervision by preserving semantic alignment between text and estimated image embeddings. This improves generalization.

4) The final ECLIPSE training objective balances projection and contrastive losses to estimate the vision distribution aligned with text semantics.

ECLIPSE trains 33M parameter priors using only 2.8% of the typical training data.

Contributions:

1) First use of contrastive learning to train text-to-image priors in unCLIP models.

2) State-of-the-art performance with 97% fewer parameters and 350x less training data.

3) Consistent improvements over baselines when using ECLIPSE with Karlo and Kandinsky decoders. 

4) Empirical analysis showing limitations of existing diffusion priors and benefits of contrastive learning.

In summary, ECLIPSE enables training highly performant unCLIP priors with tremendous reductions in model size and data needs. It shows promise for efficiently scaling up text-to-image generation.
