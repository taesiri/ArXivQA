# [Token Contrast for Weakly-Supervised Semantic Segmentation](https://arxiv.org/abs/2303.1267)

## What is the central research question or hypothesis that this paper addresses?

This paper proposes a new method called Token Contrast (ToCo) to address the problem of weakly-supervised semantic segmentation (WSSS) using image-level labels. The key research questions/hypotheses are:- Vision Transformers (ViT) are promising for WSSS due to their ability to model global contexts, but they suffer from an over-smoothing issue that impairs generating high-quality class activation maps (CAM). Can we address the over-smoothing issue in ViT to unlock its potential for WSSS?- The class token in ViT is known to capture high-level semantics. Can we exploit this property to further improve CAM and pseudo labels for WSSS? To summarize, the central research questions are:1) How to address the over-smoothing issue in ViT to generate better CAM for WSSS?2) How to exploit the semantic aggregation ability of the class token in ViT to further improve pseudo labels?The key hypotheses are:- By supervising the final tokens with intermediate tokens, the over-smoothing issue can be alleviated.- By contrasting class tokens of global and local views, the activation completeness and foreground-background discrepancy can be improved.So in essence, this paper hypothesizes that by properly addressing the over-smoothing and exploiting the class token, the potential of ViT for WSSS can be unlocked, allowing it to generate more accurate and integral pseudo labels.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a Patch Token Contrast (PTC) module to address the over-smoothing issue in Vision Transformers (ViTs) for weakly-supervised semantic segmentation (WSSS). PTC supervises the final patch tokens with pseudo token relations derived from an intermediate layer to counter the token uniformity.2. It proposes a Class Token Contrast (CTC) module that facilitates representation consistency between uncertain local regions and global objects by contrasting their class tokens. This further differentiates low-confidence regions in the class activation maps.3. Based on PTC and CTC, it develops Token Contrast (ToCo), a method to generate more accurate pseudo labels for WSSS using only image-level labels. 4. Experiments on PASCAL VOC and MS COCO datasets show ToCo significantly outperforms other single-stage methods for WSSS and achieves comparable performance to state-of-the-art multi-stage approaches.In summary, the key contribution is proposing PTC and CTC to address the over-smoothing issue in ViTs and exploit the representational power of class tokens. This allows ToCo to produce higher quality pseudo labels for WSSS using only image-level supervision. The strong experimental results validate the effectiveness of ToCo.
