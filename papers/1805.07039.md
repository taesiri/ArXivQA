# A Theoretical Explanation for Perplexing Behaviors of   Backpropagation-based Visualizations

## What is the central research question or hypothesis that this paper addresses?

This paper appears to address the following central research question:What is the theoretical explanation for why certain backpropagation-based visualizations like Guided Backpropagation (GBP) and Deconvolutional Networks (DeconvNet) generate more visually pleasing but less class-sensitive visualizations compared to plain saliency maps?The key points seem to be:- The paper provides a theoretical analysis to explain the behaviors of different backpropagation-based visualizations like saliency maps, GBP, and DeconvNet. - It reveals that GBP and DeconvNet are essentially doing partial image recovery rather than highlighting class-relevant pixels or visualizing learned weights. This means they are not directly related to the actual decision-making in neural networks.- The analysis shows that the backward ReLU introduced in GBP/DeconvNet along with the local connections in CNNs are the main reasons why GBP/DeconvNet generate crisper visualizations compared to saliency maps. - But this comes at the cost of reduced class-sensitivity. GBP/DeconvNet visualizations remain largely the same irrespective of the class, while saliency maps change more noticeably.- The theory and analysis are supported through extensive experiments on CNNs with different architectures and weights (random vs trained).In summary, the paper provides a theoretical lens to understand and explain the behaviors of popular backpropagation-based visualizations, revealing their limitations in terms of reflecting actual model decisions while explaining their visually appealing nature.


## What is the main contribution of this paper?

This paper provides a theoretical analysis of backpropagation-based visualization methods for convolutional neural networks (CNNs), with a focus on explaining why methods like Guided Backpropagation (GBP) and Deconvolutional Networks (DeconvNet) produce visually appealing but class-insensitive visualizations compared to simpler methods like saliency maps. The key contributions are:- They formally analyze GBP, DeconvNet and saliency maps in a simplified 3-layer CNN model with random weights, showing that GBP approximates the input image while saliency maps and DeconvNet behave like random noise. This demonstrates the importance of the backward pass ReLU for image recovery in GBP.- They extend the analysis to CNNs with max-pooling layers, showing that the pooling operation allows DeconvNet to also approximate image recovery like GBP, explaining its improved visualizations.- For trained CNNs, they argue GBP and DeconvNet approximate "partial image recovery", where trained weights determine which image patches form an "active path". This explains why they highlight interpretable features like edges consistently across images. - Their analysis reveals the backward pass ReLU and local connectivity are key for the visually appealing GBP/DeconvNet visualizations, and that these methods do not highlight class-specific features unlike saliency maps.- They support the theoretical results with experiments on simple CNNs and VGG networks, showing GBP quality improves with more filters and DeconvNet benefits from max-pooling. Adversarial examples also confirm GBP/DeconvNet are insensitive to model decisions.Overall, the paper provides a theoretical lens to understand and explain the behaviors of these visualization techniques, highlighting their limitations in showing meaningful class-specific explanations.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR of the paper:The paper provides a theoretical explanation that guided backpropagation (GBP) and deconvolutional networks (DeconvNet), two popular visualization techniques for convolutional neural networks, are actually doing partial image recovery rather than highlighting class-relevant pixels, which means they are essentially unrelated to the network's decision making process.In short, the paper shows through theory and experiments that GBP and DeconvNet produce visually appealing results by reconstructing parts of the input image, not by revealing insights about the model.


## How does this paper compare to other research in the same field?

This paper provides a theoretical explanation for why certain backpropagation-based visualizations like Guided Backpropagation (GBP) and Deconvolutional Networks (DeconvNet) generate visually appealing but class-insensitive visualizations, while other methods like saliency maps are noisier but more class-sensitive. The key contributions are:- Mathematically showing that GBP and DeconvNet rely on backward ReLUs and local connections in CNNs to perform partial image recovery, rather than highlighting class-relevant features. This explains their good visual quality but lack of class-sensitivity.- Proving that with enough filters/units, GBP can recover the input image in random shallow CNNs regardless of class, contradicting the common "visualizing learned weights" view based on linear models.- Showing DeconvNet relies on max-pooling to enable image recovery, explaining why it recovers less perfectly than GBP.- Analyzing how trained weights bias GBP/DeconvNet to recover "active" patches while filtering out others, losing class-relevance. This provides a more rigorous nonlinear model-based understanding compared to prior intuitions based on linear approximations. The analysis also concretely pinpoints architectural properties like local connectivity and backward ReLUs as causes of such behaviors.Other related works have empirically observed the lack of class-sensitivity in GBP/DeconvNet compared to saliency maps. But this paper offers a theoretical justification rooted in the method formulations and network architectures. The insights on image recovery being unrelated to model decisions are also novel and insightful. Overall, this provides a solid theoretical foundation to interpret behaviors of these widely used visualization methods.\section{Conclusions}\label{others}In this paper, we proposed a theoretical explanation for backpropagation-based visualizations, where we started from a random three-layer CNN and later generalized it to more realistic cases. % Different from the approximate linear model explanation,We showed that unlike saliency map, both GBP and DeconvNet are essentially doing (partial) image recovery, which verified their class-insensitive properties. We revealed that it is the backward ReLU, used by both GBP and DeconvNet, along with the local connections in CNNs that is responsible for human-interpretable visualizations. We also explained how DeconvNet also relies on the max-pooling to recover the input. Our analysis was supported by extensive experiments. Finally, we hope our analysis can provide useful insights into developing better visualization methods for deep neural networks. A future direction is to understand how the GBP visualizations in the trained CNNs filter out image patches layer by layer.% In this paper, we gave a theoretical explanation for backpropagation-based visualizations in deep neural networks. We revealed that it is the local connections in the CNNs that result in human interpretable visualizations no matter the network has been trained or not. Our results suggested that backpropagation-based visualization methods convey little information about the value of weights and the importance of pixels to a specific class. Finally, our experiments verified theoretical analysis.% In the unusual situation where you want a paper to appear in the% references without citing it in the main text, use \nocite% \nocite{langley00}\section*{Acknowledgements}Thanks to the anonymous reviewers for useful comments. WN, YZ and AB were supported by IARPA via DoI/IBC contract D16PC00003. Also, we thank Leon Sixt for pointing out an error in the proof of Theorem 1. \bibliography{GBP_draft}\bibliographystyle{icml2018}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DELETE THIS PART. DO NOT PLACE CONTENT AFTER THE REFERENCES!%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\newpage\section*{\Large Appendix}\vspace{3mm}\appendix % \renewcommand\thesection{\Alph{section}}% \def\thesection{\Alph{section}}\vspace{-2mm}\section{Proof of Lemma 1}\emph{Proof:} Saliency map includes only forward ReLUs without backward ReLUs, whereas DeconvNet includes only backward ReLUs without forward ReLUs. GBP has both types of ReLUs. Also, the norm of all the visualization results will be normalized to be in the range of $[0,1]$.Thus, by taking the (modified) derivative of $f_k(x)$ in Eq. (3) with respect to $x$ and applying the proper normalization, these backpropagation-based visualizations for the $k$-th logit can be unified as\begin{align} \label{der_sk}\begin{split}& s_k(x) \mathop  = \limits^{\left( a \right)} \frac{1}{Z_k} \sum_{i=1}^{N}\sum_{j=1}^{J}{h({V_{q_{ij},k}})\frac{\partial}{\partial x}{g({w^{(i)T}} y^{(j)})}} \\	&\mathop  = \limits^{\left( b \right)} \frac{1}{Z_k} \sum_{j=1}^{J} {D_j}^T \sum_{i=1}^{N} {h({V_{q_{ij},k}}) \frac{\partial}{\partial y^{(j)}} g({w^{(i)T}} y^{(j)})} \\	&\mathop = \limits^{(c)} \frac{1}{Z_k} \sum_{j=1}^{J} {D_j}^T \sum_{i=1}^{N} {h({V_{q_{ij},k}}) \tilde{w}^{(i,j)}}\end{split}\end{align}where $Z_k$ is the normalization coefficient to ensure $\|s_k(x)\| \in [0,1]$, $(a)$ follows from the formal definitions of backpropagation-based visualization for a ReLU activation in Eq. (1) with $h(\cdot), g(\cdot)$ being given by Eq. (2), $(b)$ is from applying $y^{(j)} = D_j x$ and swapping the two sums, and $(c)$ is from taking the derivative of $g(\cdot)$ in the three cases with\begin{align*}     \tilde{w}^{(i,j)} = \begin{cases}    w^{(i)} & \text{for DeconvNet}\\    w^{(i)}\mathbb{I}\left({w^{(i)T}} y^{(j)}\right) & \text{for saliency map and GBP} \end{cases}\end{align*}as required.% For a random neural network where every entry of both $V$ and $W$ is assumed to be independently Gaussian distributed with zero mean and variance $c^2$, i.e. % $V_{q_{ij},k}, W_{t,i} \sim \mathcal{N}(0, c^2) \text{ }\forall i \in [N], j \in [J], t \in [p]$. Assuming the number of filters $N$ is sufficiently large (e.g. VGG-16 net usually has $N=256$), then we have % \begin{align*} %\label{estmate_sk}% \begin{split}% 	s_k(x) & \mathop  \approx \limits^{\left( a \right)} \frac{1}{Z_k} \sum_{j=1}^{J} {D_j}^T \mathbb{E}\left[ {h({V_{q_{ij},k}}) \tilde{w}^{(i,j)}} \right] \\% 	& \mathop  = \limits^{\left( b \right)} \frac{1}{Z_k} \sum_{j=1}^{J} {D_j}^T \mathbb{E}\left[ h({V_{q_{ij},k}}) \right] \mathbb{E} \left[ { \tilde{w}^{(i,j)}} \right]% \end{split}% \end{align*}% where $(a)$ follows from the asymptotic approximation of sample mean to the expectation and $(b)$ follows from the fact that $V_{q_{ij},k}$ and $w^{(i)}$ are independent. \hfill $\square$\vspace{-2mm}\section{Proof of Theorem 1}\emph{Proof:}In a random neural network where every entry of both $V$ and $W$ is assumed to be independently Gaussian distributed with a zero mean and variance $c^2$, we have $V_{q_{ij},k} \sim \mathcal{N}(0, c^2)$ and $w^{(i)} \sim \mathcal{N}(0, c^2 I)$ $\forall i \in \{1, \cdots, N\}, j \in \{1,\cdots,J\}$. For GBP, in order to ensure $\|s_k(x)\| \in [0,1]$ we first set $Z_k = \tilde{Z}_k N$.Assuming the number of filters $N$ is sufficiently large (e.g. VGG-16 net usually has $N=256$), then from Eq. (\ref{der_sk}) we have \begin{align*} %\label{estmate_sk}\begin{split}	s_k(x) & = \frac{1}{\tilde{Z}_k} \sum_{j=1}^{J} {D_j}^T \frac{1}{N} \sum_{i=1}^{N} {h({V_{q_{ij},k}}) \tilde{w}^{(i,j)}} \\	& \mathop  \approx \limits^{\left( a \right)} \frac{1}{\tilde{Z}_k} \sum_{j=1}^{J} {D_j}^T \mathbb{E}\left[ {h({V_{q_{ij},k}}) \tilde{w}^{(i,j)}} \right] \\	& \mathop  = \limits^{\left( b \right)} \frac{1}{\tilde{Z}_k} \sum_{j=1}^{J} {D_j}^T \mathbb{E}\left[ h({V_{q_{ij},k}}) \right] \mathbb{E} \left[ { \tilde{w}^{(i,j)}} \right]\end{split}\end{align*}where $(a)$ follows from the asymptotic approximation of sample mean to the expectation and $(b)$ follows from the fact that $V_{q_{ij},k}$ and $w^{(i)}$ are independent. For GBP, we have $h({V_{q_{ij},k}}) = \sigma({V_{q_{ij},k}})$. Since we know ${V_{q_{ij},k}} \sim \mathcal{N} (0, c^2)$, then $h({V_{q_{ij},k}})$ follows one-dimensional rectified Gaussian distribution, and by its definition we can easily get $\mathbb{E}\left[ h({V_{q_{ij},k}}) \right] = \sqrt{\frac{1}{2\pi}}c$. Also, from the definition of $\tilde{w}^{(i,j)}$ for GBP, we know $\tilde{w}^{(i,j)}$ follows a $p$-dimensional rectified Gaussian distribution and its p.d.f. is % \begin{align} \label{w_pdf}%     p(w) = \begin{cases}%     \frac{1}{{(2\pi c^2)}^{\frac{p}{2}}} e^{-\frac{w^T w}{2c^2}} + \frac{1}{2} \delta({y^{(j)T}} w), & \text{if} \;\; {y^{(j)T}} w \geq 0 \\%     0, & \text{otherwise}%     \end{cases}% \end{align}\begin{align} \label{w_pdf}   p(w) = \frac{1}{{(2\pi c^2)}^{\frac{p}{2}}} e^{-\frac{w^T w}{2c^2}} u({y^{(j)T}} w) + \frac{1}{2} p(w_A) \delta_A(w)\end{align}where the manifold $A \triangleq \{ w | {y^{(j)T}} w = 0 \}$, $p(w_A)$ is a $(p-1)$-dimensional Gaussian distribution projected from the $p$-dimensional Gaussian distribution onto the manifold $A$, with $w_A \in \mathbb{R}^{p-1}$ being the corresponding projected vector of $w$, and $u(t)$ and $\delta_A(w)$ are the unit step function and dirac delta function, respectively, i.e., \begin{align*}    u(t) = \begin{cases} 1, & t > 0 \\ 0, & t \leq 0 \end{cases} \quad \text{and} \quad     \delta_A(w) = \begin{cases} +\infty, & w \in A \\ 0, & w \notin A \end{cases}\end{align*}By definition, we have \begin{align*}    \int p(w_A) \delta_A(w) dw \triangleq \int p(w_A) dw_A = 1\end{align*}such that it satisfies $\int p(w) dw = 1$.Accordingly, its expectation is given by\begin{align} \label{w_exp}\begin{split}& \mathbb{E} \left[ { \tilde{w}^{(i,j)}} \right] \\&= \int_{{y^{(j)T}} w > 0} \frac{w}{{(2\pi c^2)}^{\frac{p}{2}}} e^{-\frac{w^T w}{2c^2}} dw  + \int \frac{w}{2} p(w_A) \delta_A(w) dw \\& \mathop = \limits^{(a)}  \int_{\phi_p > 0} U \phi \cdot \frac{1}{{(2\pi c^2)}^{\frac{p}{2}}} e^{-\frac{\phi^T \phi}{2c^2}} |U| d \phi \\& \qquad\qquad + \int \frac{1}{2} U\phi p(\phi_{A_p}) \delta_{A_p}(\phi) |U| d \phi\\& \mathop = \limits^{(b)}  U \int_{\phi_p > 0} \phi \cdot \frac{1}{{(2\pi c^2)}^{\frac{p}{2}}} e^{-\frac{\phi^T \phi}{2c^2}} d \phi \\& \qquad\qquad + \frac{1}{2} U \int \phi p(\phi_{A_p}) \delta_{A_p}(\phi) d \phi \\% & \mathop = \limits^{(b)} %\sqrt{\frac{2}{\pi}}c \cdot U^T e_n \\%& \mathop = \limits^{(c)} % \sqrt{\frac{2}{\pi}}c \cdot \frac{y^{(j)}}{\| y^{(j)}\|_2}\end{split}\end{align}where $(a)$ follows from the change of variables $w= U \phi$ and $U$ is an unitary matrix satisfying the condition that $U^T \cdot \frac{y^{(j)}}{\| y^{(j)}\|_2} = e^{(p)}$ and $e^{(p)}$ is an unit vector with only the $p$-th entry being 1. That is, $\frac{y^{(j)}}{\| y^{(j)}\|_2}$ is the $p$-th column of $U$. Thus, ${y^{(j)T}} w = {y^{(j)T}} U \phi = e^{(p)T} \phi {\| y^{(j)}\|_2} = \phi_p {\| y^{(j)}\|_2}$ with $\phi_p$ being the $p$-th entry of $\phi$, which means ${y^{(j)T}} w > 0$ is equivalent to $\phi_p > 0$. Also, by the change of variables in the integral, we have $dw = |U| d \phi$ where $|\cdot|$ denotes the determinant of a matrix. Accordingly, we define a new manifold $A_p = \{\phi | \phi_p = 0\}$.$(b)$ follows from $|U| = 1$ by the definition of an unitary matrix, and the swap between matrix multiplication and the integral. % Also, the second term with the dirac delta function vanishes as As $\phi$ is a $p$-dimensional vector, the first integral above can be evaluated at each entry, denoted by $\phi_m$, of $\phi$ separately. For $m \neq p$, we have\begin{align*}    \begin{split}        & \int_{\phi_p > 0} \phi_m \cdot \frac{1}{{(2\pi c^2)}^{\frac{p}{2}}} e^{-\frac{\phi^T \phi}{2c^2}} d \phi \\        & \mathop = \limits^{(a)} \underbrace{\int_{-\infty}^{\infty} \frac{\phi_m}{{(2\pi c^2)}^{\frac{1}{2}}} e^{-\frac{\phi_m^2}{2c^2}} d \phi_m}_{0}  \cdot \int_{0}^{\infty}  \frac{1}{{(2\pi c^2)}^{\frac{1}{2}}} e^{-\frac{\phi_p^2}{2c^2}} d \phi_p \\        &= 0    \end{split}\end{align*}where $(a)$ follows from the expansion of the multiple integral, and all of the other $p-2$ integrals over $\phi_k$ for $k \notin \{p,m\}$ are 1. For $m=p$, we have\begin{align*}    \begin{split}
