# [Studying Large Language Model Generalization with Influence Functions](https://arxiv.org/abs/2308.03296)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question it addresses is:How does the scale of language models impact the types of training data that influence model predictions?The authors investigate how model scale impacts which training examples are most influential on a model's predictions. They examine two large language models with different scales - an 810 million parameter model and a 52 billion parameter model. Their main hypothesis is that as models become larger, the training examples that are most influential on model predictions become less focused on surface pattern matching and more focused on abstract, conceptual relationships. In other words, they hypothesize that larger models rely more on training examples that are semantically aligned with the query, rather than simply containing overlapping tokens.To test this, they implement influence measurement techniques and analyze the most influential training sequences for various queries. They find that the smaller 810M parameter model tends to be influenced by sequences with token overlap, while the larger 52B parameter model is more influenced by conceptually relevant sequences.In summary, the central research question is examining how model scale affects what types of training data are most influential, with the hypothesis that larger models are influenced more by conceptual relevance than surface token matches. The paper aims to demonstrate this through empirical analysis of influential training sequences.
