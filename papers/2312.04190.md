# [Receding Horizon Re-ordering of Multi-Agent Execution Schedules](https://arxiv.org/abs/2312.04190)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes an optimization-based receding horizon feedback control scheme to dynamically re-order fleets of autonomous guided vehicles (AGVs) executing multi-agent path finding (MAPF) plans in environments with unpredictable delays, such as warehouses with human workers or other dynamic obstacles. The key innovation is the introduction of the Switchable Action Dependency Graph (SADG), which extends prior work on Action Dependency Graphs (ADGs) by modeling allowed reorderings of AGVs at roadmap intersections while maintaining collision avoidance and deadlock avoidance guarantees. Based on the SADG, the authors formulate a mixed-integer linear program to find optimal reorderings in real-time that minimize the cumulative completion time of all AGVs' routes. This approach is evaluated in simulation across a variety of roadmaps, AGV fleet sizes, and delay conditions, reducing completion times by 8-25% compared to a baseline ADG method and state of the art robust MAPF solver. The method guarantees persistent collision and deadlock avoidance for AGVs during execution and can utilize any existing MAPF solver during initial planning. Overall, it enables more efficient coordination of AGV fleets experiencing frequent delays in unpredictable environments.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper proposes an optimization-based receding horizon feedback control scheme to re-order autonomous guided vehicles subjected to delays when executing multi-agent path finding plans in order to reduce cumulative route completion times while maintaining collision- and deadlock-free execution guarantees.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing an optimization-based receding horizon feedback control scheme to re-order AGVs (automated guided vehicles) subject to delays when executing MAPF (multi-agent path finding) plans. Specifically, the paper:

1) Introduces the SADG (switchable action dependency graph), a novel data structure that extends the ADG (action dependency graph) to enable re-ordering of AGVs while maintaining collision avoidance and deadlock-free guarantees. 

2) Formulates an optimal control problem (OCP) based on the SADG to minimize the cumulative route completion time of AGVs by optimally re-ordering them based on delays.

3) Approximates the solution to the OCP using a mixed integer linear programming (MILP) formulation that can be solved efficiently in real-time in a receding horizon fashion.

4) Integrates the MILP-based optimizer into a feedback control scheme that recursively re-plans the ordering of AGVs to improve efficiency.

5) Validates the approach through extensive simulations, showing significant reductions in cumulative route completion times compared to using the baseline ADG method or state-of-the-art robust MAPF solvers.

In summary, the main contribution is an optimization-based, delay-aware feedback control scheme for re-ordering AGVs in MAPF that provides formal guarantees on collision avoidance and deadlock prevention.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this paper include:

- Multi-Agent Path Finding (MAPF)
- Action Dependency Graph (ADG) 
- Spatially Exclusive Action Dependency Graph (SE-ADG)
- Switchable Action Dependency Graph (SADG) 
- Mixed Integer Linear Program (MILP)
- Optimal Control Problem (OCP)
- Shrinking Horizon Control (SHC)
- Receding Horizon Control (RHC)
- Recursive feasibility
- Deadlock avoidance
- Collision avoidance
- Ordering constraints
- Binary decision variables
- Optimization-based feedback control
- Delay handling
- Rescheduling

The paper introduces new concepts like the SADG to enable the rescheduling and reordering of multi-agent robot trajectories to handle delays, while providing formal guarantees on collision and deadlock avoidance. Key methods include formulating an OCP solved using a MILP and integrated into a receding horizon control scheme. The overall goal is to minimize the cumulative route completion times for teams of robots executing MAPF plans in dynamic environments.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper introduces the concept of a "switched dependency" to enable reordering of AGVs while maintaining collision avoidance guarantees. Can you explain in more detail, using a concrete example, how a switched dependency works? 

2. Algorithm 2 shows how to construct a Switchable Action Dependency Graph (SADG) from a valid MAPF solution. Walk through the key steps of this algorithm and explain the intuition behind identifying switchable dependency pairs to enable AGV reordering.  

3. The paper formulates an optimal control problem (OCP) to find an optimal reordering of AGVs based on delays, while ensuring deadlock avoidance. Explain the cost function and key constraints that encode this OCP.

4. The OCP is converted to a Mixed Integer Linear Program (MILP) formulation. What is the purpose of the "big-M" formulation used in constraints (15) and (16)? Explain how this encodes the AGV reordering decision.  

5. The concept of a finite horizon SADG subset is introduced to enable a receding horizon control scheme. Using a diagram, explain the intuition behind extracting a valid finite horizon subset that maintains guarantees on the overall SADG acyclicity.  

6. Compare and contrast the Shrinking Horizon Control (SHC) method versus the Receding Horizon Control (RHC) method proposed. What are the tradeoffs, and why is RHC preferred?

7. The paper evaluates the proposed method in three different simulation settings. Summarize the results. What new insights do you gain about the strengths and limitations of the approach?

8. How does the proposed receding horizon AGV reordering method compare with existing robust MAPF solvers like K-CBS-CH? Under what conditions does each perform better?

9. The method requires periodically solving an MILP to reorder AGVs online. Discuss potential ways the computation time could be reduced to enable real-time performance.  

10. The paper claims guaranteed collision avoidance and deadlock avoidance properties. Clearly explain how these properties are formally ensured by the proposed approach.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
This paper addresses the problem of efficiently executing multi-agent path finding (MAPF) plans for teams of automated guided vehicles (AGVs) in dynamic environments where delays are common. While optimal MAPF solutions ensure collision-free paths to goals, delays can cause loss of efficiency and deadlocks during execution. Existing robust MAPF methods account for minor delays but perform poorly with large, unpredictable delays. Local path repair methods improve individual AGV paths but lack a system-wide perspective.

Proposed Solution:
The paper proposes an optimization-based receding horizon control scheme to reorder AGVs online based on delays while guaranteeing persistent deadlock and collision avoidance. The scheme leverages a new "switchable" action dependency graph (SADG) data structure that extends the existing ADG formulation. The SADG compactly encodes allowable reordering actions at intersections that maintain safety. By solving a mixed integer linear program (MILP) over the SADG in a receding horizon fashion, the method dynamically adjusts ordering to reduce fleet-wide route completion times.

Key Contributions:

1) The SADG, a novel compact graphical model that encodes allowable reordering actions for persistent deadlock-free multi-agent plan execution

2) An online optimization-based control scheme that uses SADG-encoded reorderings to minimize cumulative completion times, proven recursively feasible

3) Shrinking and receding horizon variants of the control scheme for efficiency  

4) Extensive simulations showing significant completion time reductions compared to robust MAPF methods, especially with large delays

5) Validation in a high-fidelity Gazebo simulator environment with natural delays

The method contributes an efficient way to make pre-computed multi-agent plans robust to unpredictable delays at execution while providing formal guarantees on safety. By reasoning globally about allowable reorderings, it outperforms local path repair techniques. The online optimization leverages fast off-the-shelf solvers for real-time performance.
