# [Executable Code Actions Elicit Better LLM Agents](https://arxiv.org/abs/2402.01030)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Large language models (LLMs) have shown promise as autonomous agents that can perform actions like invoking tools and controlling robots. However, existing approaches for expanding LLMs' action space have limitations:
    - Using text or JSON actions restricts the scope of possible actions and flexibility (e.g. inability to compose tools).
    - Approaches relying on code generation cannot dynamically adjust actions based on environment observations and feedback.

Proposed Solution: 
- The paper proposes "CodeAct", a framework where LLM agents use executable Python code to consolidate actions. 
- Integrated with a Python interpreter, CodeAct allows:
    - Execution of code actions and dynamic adjustment of prior actions based on new observations through multi-turn interactions.
    - Use of existing software packages to expand action space instead of hand-crafted tools.
    - Leveraging automated feedback (e.g. error messages) for self-debugging and improving actions.

Main Contributions:
- Extensive experiments showing CodeAct outperforms text/JSON actions by up to 20% higher success rate on complex tasks while requiring 30% fewer actions.
- Introduction of "CodeActInstruct", an instruction tuning dataset of 7k high-quality multi-turn LLM-environment interactions using CodeAct.
- "CodeActAgent", an open-source LLM agent finetuned on CodeActInstruct+conversation data, uniquely tailored to leverage Python packages and self-debug through code execution.

In summary, the paper demonstrates the effectiveness of using executable code to expand LLM agents' action space, supported by a new dataset and model specialized for code-based interaction. The framework, data and model are open-sourced for community use.
