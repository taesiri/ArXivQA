# [Dissecting In-Context Learning of Translations in GPTs](https://arxiv.org/abs/2310.15987)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

What is the relative importance of different demonstration attributes (input text, output text, input-output mapping) for in-context learning of translations in large language models?

The key hypothesis seems to be that the output text distribution provides the most important learning signal during few-shot in-context learning of translations in LLMs.

In summary, the paper investigates the role of different demonstration attributes by perturbing high-quality translation examples used for few-shot prompting of LLMs. It hypothesizes and shows through experiments that the target text distribution matters most, while the source text distribution provides little signal. Based on this finding, the authors propose a method to improve zero-shot translation performance by automatically providing the target text distribution signal.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. The authors explored the role of demonstration attributes in in-context learning of translations in LLMs like GPT-3 by perturbing the input-output mappings in the examples used for few-shot prompting. 

2. They showed through experiments that perturbing the target side has a much bigger impact on translation quality compared to perturbing the source side. This suggests that the output text distribution provides the most important learning signal, while the input text distribution is less important.

3. Based on this finding, the authors proposed a method called Zero-Shot-Context that tries to automatically provide the target text distribution signal during zero-shot prompting. This improved GPT-3's zero-shot translation performance significantly.

In summary, the key contribution is an analysis of the role of different demonstration attributes in few-shot learning of translations in LLMs, which showed that the target text distribution is the most important. The authors leveraged this finding to improve zero-shot translation performance.
