# [Extracting Self-Consistent Causal Insights from Users Feedback with LLMs   and In-context Learning](https://arxiv.org/abs/2312.06820)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Microsoft's Windows Feedback Hub receives a large volume of user feedback on Windows issues, making it challenging to diagnose root causes. There is a need to better understand and triage user-reported issues.  
- A key challenge is that causal analysis requires domain knowledge to build the causal graph. This knowledge is not always available.

Proposed Solution:
- Use large language models (LLMs) and in-context learning to extract causal variables (treatments, outcomes, confounders) and sequences of events from user feedback. 
- Generate a prior causal model to aid in the causal inference pipeline when domain knowledge is lacking.
- Design causal heuristics using the extracted insights to score feedback informativeness.

Main Contributions:
- A modified self-consistency approach using LLM prompt ensembles to reduce hallucination risk.
- Demonstration of using reasoning abilities of LLMs and in-context learning to extract causal insights from real user feedback data.
- Two causal heuristics for scoring feedback actionability based on number of extracted variables and causal chain length.
- Show 19% of extracted issues are new and undiscovered bugs based on real user data evaluation.
- Minimize out-of-domain responses to 0% through the proposed techniques.

In summary, the paper presents a novel way to leverage large language models to extract reliable and previously unknown causal insights from user feedback, to aid in diagnosing issues and prioritizing bug fixing efforts. The proposed causal scoring also helps filter uninformative feedback.
