# [CUDA: Convolution-based Unlearnable Datasets](https://arxiv.org/abs/2303.04278)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question/hypothesis of this paper is: Can we generate unlearnable datasets that are robust to adversarial training by using controlled class-wise convolutions instead of additive noises?The key points are:- Existing methods for generating unlearnable datasets use small additive noises, making them vulnerable to adversarial training which is designed to be robust against such noises. - This paper proposes a new method called Convolution-based Unlearnable Dataset (CUDA) that instead uses controlled class-wise convolutions to generate the unlearnable data.- The convolutions are performed using randomly generated filters per class based on a private key. This encourages models to learn the relation between filters and labels rather than useful features.- CUDA is designed to be robust against adversarial training since it introduces multiplicative noise in the Fourier domain rather than small additive noises.- Experiments show CUDA is effective across datasets and architectures, and robust to various training techniques like adversarial training, augmentations, regularization etc.So in summary, the central hypothesis is that using class-wise controlled convolutions can generate unlearnable datasets that are more robust compared to prior additive noise-based techniques. The effectiveness of CUDA is demonstrated empirically.
