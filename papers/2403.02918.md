# [Single-Channel Robot Ego-Speech Filtering during Human-Robot Interaction](https://arxiv.org/abs/2403.02918)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Social robots currently lack the ability to selectively focus their auditory attention and separate overlapping human speech from their own ego noise and speech. This limits natural turn-taking during human-robot interactions.

- Existing solutions rely on unnatural interaction schemes like push-to-talk or separate microphones. More natural duplex interaction requires the robot to filter out its own ego noise and speech to extract the human speech.

- Challenges: differences between played and recorded robot speech due to microphone response, low signal-to-power ratio of human speech, computational efficiency for real-time interaction.

Proposed Solution: 
- Develop and evaluate two architectures - signal processing pipeline based on spectral subtraction, and a convolutional recurrent neural network (CRNN).

- Signal processing pipeline utilizes robot's ability to access its own planned speech. Calculates speaker-microphone frequency response to generate speech masks and performs spectral subtraction. Optional post-filtering with pre-trained model.

- CRNN model takes noisy input, clean target speech and reference robot speech as inputs. Attempts to learn to generate soft masks to filter robot speech.

Contributions:
- Demonstrate the feasibility of ego noise/speech filtering on manufactured datasets mixing real recorded robot and human speech

- Signal processing pipeline is very efficient and works well when room reverberation is low. Performance drops in highly reverberant environments.

- CRNN model more robust to reverberation but overall speech separation still not sufficient for comprehension.

- Weak/low pitched human speech and batch normalization layer pose challenges. More data and joint modeling with ASR system could help.

In summary, the paper explores a novel and relevant problem for human-robot interaction, proposes two solutions to enable more natural interaction, provides empirical analysis on manufactured datasets, and discusses limitations and future work.
