# [Multi-Agent, Human-Agent and Beyond: A Survey on Cooperation in Social   Dilemmas](https://arxiv.org/abs/2402.17270)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
This paper provides a comprehensive review on the study of cooperation in social dilemmas (SDs), which involve a conflict between individual and collective interests, across three key areas - multi-agent systems, human-agent systems, and using AI to facilitate human-human cooperation. It discusses the challenges in achieving mutual cooperation among self-interested agents in sequential SDs, designing algorithms for human-agent cooperation comparable to human cooperation, understanding human biases towards AI agents, and potential ways AI could enhance cooperation among humans.  

Solutions for Multi-Agent Cooperation:
- Shape intrinsic motivations like inequality aversion and social value orientation into agent rewards to promote cooperative behaviors 
- Provide external motivations through peer rewarding and formal agreements to incentivize cooperation
- Employ adaptive policy selection to choose cooperative or defective policies based on opponents, or use opponent shaping to influence opponents' future policies

Solutions for Human-Agent Cooperation:
- Algorithms like S++ and S# that combine experts and communication for swift and effective human cooperation
- Generous strategies prove better than extortion in avoiding human retaliation and establishing cooperation
- Reveal and mitigate biases where humans cooperate less with agents, through cultural cues and emotional expressions in agents

Inspirations for Human-Human Cooperation:  
- AI agents reshaping interaction networks among humans lead to increased cooperation
- Minority presence of AI agents boosts human cooperation; fully agent populations risk human cooperation collapse  
- Humans more cooperative when decisions delegated to agents due to long-term considerations

Future Directions:
- Employ large language models for advanced reasoning in designing cooperative agents
- Establish theoretical guarantees for cooperation solutions, distinct for multi-agent and human-agent systems   
- Apply to real-world scenarios like autonomous vehicles interacting with human drivers
- Connect the study of human-agent cooperation with sequential social dilemmas
- Re-examine existing theories of human cooperation in light of human-agent systems

In summary, this paper provides a unique perspective that connects the role of AI in fostering cooperation across multi-agent, human-agent and human-human systems, reviews current progress, and points out open challenges for future investigation. The insights not only advance the fundamental theories but also inform the design of cooperative algorithms for practical applications.
