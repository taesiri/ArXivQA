# [Mask-Free Video Instance Segmentation](https://arxiv.org/abs/2303.15904)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to perform high-quality video instance segmentation without using any mask annotations during training. The key hypothesis is that strong video instance segmentation can be learned even without mask supervision by leveraging temporal consistency cues in videos.Specifically, the paper proposes a new method called MaskFreeVIS that achieves competitive performance on video instance segmentation benchmarks while only using bounding box annotations during training, without any mask labels. The main idea is to leverage the rich temporal mask consistency constraints in videos through a new loss function called the Temporal KNN-patch Loss (TK-Loss). This loss enforces mask consistency between patch correspondences found across frames, providing strong mask supervision without any human labeling.The key hypothesis is that the rich information present in video sequences, such as object motion and temporal coherence, can be exploited through the TK-Loss to provide sufficient supervision for mask prediction. By replacing conventional mask losses with the proposed TK-Loss, the authors show MaskFreeVIS can attain over 90% of the performance of fully supervised methods on datasets like YouTube-VIS, drastically reducing the gap between weakly and fully supervised video instance segmentation. Overall, the main research question is how to achieve high-quality video instance segmentation without mask annotations, with the core hypothesis being that temporal consistency cues can provide sufficient supervision.
