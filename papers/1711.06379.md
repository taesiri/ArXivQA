# [Improvements to context based self-supervised learning](https://arxiv.org/abs/1711.06379)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we improve upon existing self-supervised learning methods that use image context as a supervisory signal? The authors aim to develop techniques to enhance context-based self-supervised learning, with the goal of improving performance on common benchmark tasks like image classification, object detection and segmentation. Their core hypothesis seems to be that by addressing certain limitations of existing methods, such as reliance on chromatic aberration cues and neglect of mid-level network features, they can achieve state-of-the-art results.The key research contributions appear to include:- New techniques like chroma blurring, yoked jitter, extra patches/configurations, random aperture, and rotation with classification to improve context-based self-supervised learning.- Using alternative datasets like CUB birds and CompCars during development to avoid overfitting to common benchmarks. - Demonstrating performance on multiple network architectures to show generalization.The paper seems focused on developing a "toolbox" of techniques to enhance self-supervised learning, with the goal of pushing the state-of-the-art on standard benchmarks, rather than testing a specific hypothesis. But the central research question seems to be how to improve context-based self-supervised learning through their proposed techniques.


## What is the main contribution of this paper?

The main contribution of this paper is developing a set of methods to improve self-supervised learning using context. The authors start with a baseline patch-based context learning approach and propose several techniques to address issues like chromatic aberration, spatial skew, and neglect of mid-level features. The key techniques include:- Chroma blurring to remove color cues from chromatic aberration while preserving some color information. - Yoked jitter of patches to prevent spatial distortion.- Adding extra patches and configurations to cover more of the image and create more unique patterns.- Aperture on patches to potentially bias towards learning mid-level features. - Patch rotation with classification to allow understanding parts at different orientations.The authors show these techniques yield state-of-the-art results on standard self-supervised benchmarks like PASCAL VOC classification/detection/segmentation and linear tests on ImageNet and Places. They demonstrate the generalizability of the techniques by testing on different datasets and network architectures. The overall contribution is advancing self-supervised learning through this "toolbox" of methods that could potentially transfer to other self-supervised approaches.
