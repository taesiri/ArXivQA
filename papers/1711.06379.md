# [Improvements to context based self-supervised learning](https://arxiv.org/abs/1711.06379)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we improve upon existing self-supervised learning methods that use image context as a supervisory signal? The authors aim to develop techniques to enhance context-based self-supervised learning, with the goal of improving performance on common benchmark tasks like image classification, object detection and segmentation. Their core hypothesis seems to be that by addressing certain limitations of existing methods, such as reliance on chromatic aberration cues and neglect of mid-level network features, they can achieve state-of-the-art results.The key research contributions appear to include:- New techniques like chroma blurring, yoked jitter, extra patches/configurations, random aperture, and rotation with classification to improve context-based self-supervised learning.- Using alternative datasets like CUB birds and CompCars during development to avoid overfitting to common benchmarks. - Demonstrating performance on multiple network architectures to show generalization.The paper seems focused on developing a "toolbox" of techniques to enhance self-supervised learning, with the goal of pushing the state-of-the-art on standard benchmarks, rather than testing a specific hypothesis. But the central research question seems to be how to improve context-based self-supervised learning through their proposed techniques.
