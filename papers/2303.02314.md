# [Virtual Sparse Convolution for Multimodal 3D Object Detection](https://arxiv.org/abs/2303.02314)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper tries to address is: 

How to effectively fuse RGB images and LiDAR data via virtual/pseudo points for accurate and efficient 3D object detection?

Specifically, the paper identifies two key issues with using dense virtual points generated from images for 3D detection:

1) Density problem: The huge number of virtual points creates redundant computation and decreases detection speed. 

2) Noise problem: Inaccurate depth completion leads to noise in the virtual points which degrades detection accuracy.

To tackle these issues, the paper proposes a new operator called VirConv, which consists of:

1) StVD (Stochastic Voxel Discard): Discards redundant nearby voxels to alleviate computation while retaining useful faraway voxels.

2) NRConv (Noise-Resistant Submanifold Convolution): Encodes voxel features in both 3D and 2D image space to reduce the impact of noise without losing shape cues.

Based on VirConv, the paper presents 3 multimodal detectors:

- VirConv-L: A lightweight and efficient detector
- VirConv-T: A high-precision detector 
- VirConv-S: A semi-supervised detector

Through experiments on KITTI and nuScenes datasets, the paper demonstrates the effectiveness of VirConv in addressing the density and noise issues for accurate and efficient multimodal 3D detection.

In summary, the central hypothesis is that the proposed VirConv operator can effectively fuse image and LiDAR data via virtual points for fast, accurate and robust 3D detection. The experimental results validate this hypothesis.
