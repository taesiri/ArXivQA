# [Depth Estimation fusing Image and Radar Measurements with Uncertain   Directions](https://arxiv.org/abs/2403.15787)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- General automotive radars have uncertain vertical measurement directions, making it difficult to accurately align the radar points onto an image for tasks like depth estimation. 
- Prior works that fuse radar and image data via early convolution suffer from spreading this radar uncertainty across the image.

Proposed Solution:
- Extract image features using only the RGB image, without injecting uncertain radar data.
- In training, use LiDAR to identify possibly correct radar directions. Create positive training pairs between image features and matching radar depths.
- Fuse image features and radar depths late, after feature extraction, in a pixel-wise manner to avoid spreading uncertainty.
- Train a network to evaluate image-depth consistency using the positive pairs and incorrect pairs as negative samples.

Key Contributions:
- Avoid contaminating image features with uncertain radar data by fusing late instead of early.
- Utilize LiDAR in training to determine possibly correct radar directions despite having no LiDAR at test time.
- Pixel-wise late fusion and image-depth consistency network allows accurately estimating depth only where radar is reliable.

The method improves upon prior image-radar fusion approaches by avoiding spreading the inherent radar uncertainty across the image during feature extraction. Late fusion and identification of possibly correct directions via LiDAR supervision are key to pixel-wise reliable depth estimation.
