# [Diversity is All You Need: Learning Skills without a Reward Function](https://arxiv.org/abs/1802.06070)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:Can reinforcement learning agents autonomously discover useful skills without any rewards or supervision?The key hypothesis is that by training skills to be distinguishable from each other and maximally random (maximum entropy), the skills will be incentivized to explore large parts of the state space in diverse ways. This diversity of skills can then serve as a building block for downstream tasks like hierarchical RL and imitation learning.In other words, the paper hypothesizes that an information-theoretic objective based on mutual information between skills and states is sufficient for unsupervised discovery of diverse and useful skills. The skills can then be leveraged for hierarchical RL, policy initialization, and imitation learning without needing any reward during the unsupervised skill discovery phase.The paper aims to demonstrate through experiments on simulated robotic tasks that their proposed method called "Diversity is All You Need" (DIAYN) can effectively learn useful locomotion and control skills in the absence of any rewards. It also aims to show how the learned skills can be utilized for downstream tasks, outperforming alternative approaches that do use rewards or manually shaped rewards.In summary, the key research question is whether reward/supervision is necessary for discovering useful skills, or if a mutual-information based diversity objective alone is sufficient. The paper hypothesizes the latter and provides experimental evidence to support it.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method called "Diversity is All You Need" (DIAYN) for learning diverse and useful skills in reinforcement learning without requiring any reward function. The key ideas are:- Maximizing mutual information between skills and states encourages skills to visit distinct states. This makes skills more easily distinguishable.- Maximizing entropy of the skills encourages them to explore more randomly and diversely. This pushes skills further apart to remain distinguishable.- Using a discriminator predicts the skill from states provides a learning signal, despite no reward.The method is evaluated on several simulated robotic tasks. The main results are:- DIAYN is able to learn diverse locomotion skills like running, walking, jumping without any rewards specified.- The learned skills can be used for hierarchical RL, enabling solutions for challenging exploration tasks. - The skills can be quickly adapted to new tasks, providing better initialization than random, accelerating learning.- Skills can be used for imitation learning, matching expert state distributions.In summary, the key contribution is an unsupervised reinforcement learning method that can discover useful and distinguishable skills without rewards. This provides a building block for exploration, hierarchical RL, and imitation learning.
