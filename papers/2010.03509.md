# [Automatic Backward Filtering Forward Guiding for Markov processes and   graphical models](https://arxiv.org/abs/2010.03509)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the abstract and introduction, this paper develops a framework called automatic Backward Filtering Forward Guiding (BFFG) for efficient inference on latent states and model parameters in probabilistic graphical models that contain Markov processes as building blocks. The key ideas are:- Start with a generative probabilistic model defined by a directed acyclic graph (DAG) containing both latent and observed variables. The transitions between variables are described by Markov kernels. - Transform the generative model into a "guided" model that approximates the conditional distribution given observations, by using backward filtering and forward guiding operations.- The backward filtering step propagates information from the observed variables towards the latent variables to construct an approximate conditional distribution. - The forward guiding step then transforms the generative model into a guided model using this backward filtered information, in a way that preserves the original graphical structure.- This guided model can then be used for efficient inference on the latent states and parameters, using sampling or optimization based techniques.- The framework is general, applying to both discrete and continuous time Markov processes on trees or DAGs. It is also compositional, allowing inference modules to be built up from simpler components.So in summary, the key hypothesis is that automatic BFFG provides an efficient and flexible way to perform inference in probabilistic graphical models containing latent Markov processes, while preserving the original graphical structure. The paper aims to demonstrate the applicability of this approach across a range of models and inference techniques.
