# [Anticipatory Music Transformer](https://arxiv.org/abs/2306.08620)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is:How can we construct generative models of music that can be controlled by conditioning on an asynchronous correlated process (such as a melody line)?Specifically, the paper focuses on the problem of "infilling" - generating a complete sequence of musical events conditioned on a subset of user-specified events. The authors motivate this as an important capability for building controllable generative models that can support human creativity and music co-creation. To address this question, the paper introduces a method called "anticipation" for interleaving the conditioning control sequence with the generated event sequence in an autoregressive model. This allows the model to anticipate upcoming control events and account for them when generating new events.The authors apply anticipation to train "anticipatory infilling models" on a large dataset of MIDI music, and demonstrate that these models can perform infilling tasks like generating accompaniments conditioned on a melody line. The anticipatory models match unconditional generation performance of autoregressive baselines, while unlocking new conditioned generation capabilities.So in summary, the central hypothesis is that by structuring conditional generation using anticipation, the paper's proposed models can unlock new control capabilities for symbolic music generation without sacrificing quality or flexibility of the underlying generative model.
