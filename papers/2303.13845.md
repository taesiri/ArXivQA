# [Anomaly Detection under Distribution Shift](https://arxiv.org/abs/2303.13845)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the key research question seems to be: 

How to improve anomaly detection models to be robust to distribution shift between the training data and test data?

The paper points out that most existing anomaly detection methods assume the training and test data come from the same distribution. However, in many real-world applications, the test data may exhibit a distribution shift from the training data due to changes in environmental conditions, image acquisition process, etc. This distribution shift can significantly degrade the performance of anomaly detection models. 

To address this problem, the paper proposes a new approach called "generalized normality learning" (GNL) that improves anomaly detection under distribution shift. The key ideas are:

1) Learn distribution-invariant normality representations during training by minimizing the distribution gap between normal samples from the training (in-distribution) and simulated out-of-distribution datasets. 

2) Perform test-time data augmentation through feature distribution matching to reduce the distribution discrepancy between training and test data during inference.

The central hypothesis is that by reducing the distribution gap between in-distribution and out-of-distribution normal data in both training and inference, the model can learn robust features that capture the generalized notion of normality, enabling accurate anomaly detection even under distribution shifts. 

Through extensive experiments on benchmark datasets with various simulated distribution shifts, the paper shows that their proposed GNL approach substantially outperforms existing state-of-the-art anomaly detection and out-of-distribution generalization methods by a large margin. This provides strong empirical evidence for the efficacy of their approach in tackling the key research problem.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. The authors present an extensive study of the problem of anomaly detection under distribution shift, using three widely-used datasets adapted from anomaly detection and out-of-distribution generalization tasks. The results reveal that existing state-of-the-art anomaly detection and OOD generalization methods fail to work effectively for identifying anomalies when there is a distribution shift between training and test data.

2. The paper proposes a new robust anomaly detection approach called "generalized normality learning" (GNL) to address the distribution shift issue. GNL minimizes the distribution gap between in-distribution and out-of-distribution normal samples in both training and inference stages in an unsupervised manner. It uses a normality-preserved loss function to learn distribution-invariant normality representations during training. It also utilizes a test time augmentation method based on feature distribution matching to reduce the distribution gap during inference.

3. Through extensive experiments on the three datasets, the paper demonstrates that GNL substantially outperforms existing state-of-the-art methods in detecting anomalies under various types of distribution shifts, while maintaining accuracy on in-distribution test data. For example, GNL improves over the best methods by over 10% in AUCROC on data with distribution shifts.

In summary, the key contribution is a new anomaly detection approach that can effectively handle the practical and challenging problem of distribution shift between training and test data, through novel techniques introduced in both the training and inference stages. The extensive benchmarks and superior results demonstrate its effectiveness over existing methods.
