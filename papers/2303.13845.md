# [Anomaly Detection under Distribution Shift](https://arxiv.org/abs/2303.13845)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the key research question seems to be: How to improve anomaly detection models to be robust to distribution shift between the training data and test data?The paper points out that most existing anomaly detection methods assume the training and test data come from the same distribution. However, in many real-world applications, the test data may exhibit a distribution shift from the training data due to changes in environmental conditions, image acquisition process, etc. This distribution shift can significantly degrade the performance of anomaly detection models. To address this problem, the paper proposes a new approach called "generalized normality learning" (GNL) that improves anomaly detection under distribution shift. The key ideas are:1) Learn distribution-invariant normality representations during training by minimizing the distribution gap between normal samples from the training (in-distribution) and simulated out-of-distribution datasets. 2) Perform test-time data augmentation through feature distribution matching to reduce the distribution discrepancy between training and test data during inference.The central hypothesis is that by reducing the distribution gap between in-distribution and out-of-distribution normal data in both training and inference, the model can learn robust features that capture the generalized notion of normality, enabling accurate anomaly detection even under distribution shifts. Through extensive experiments on benchmark datasets with various simulated distribution shifts, the paper shows that their proposed GNL approach substantially outperforms existing state-of-the-art anomaly detection and out-of-distribution generalization methods by a large margin. This provides strong empirical evidence for the efficacy of their approach in tackling the key research problem.
