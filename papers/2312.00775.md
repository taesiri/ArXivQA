# [Towards Generalizable Zero-Shot Manipulation via Translating Human   Interaction Plans](https://arxiv.org/abs/2312.00775)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper presents a framework called HOPMan for learning generalizable zero-shot robotic manipulation skills from internet videos of everyday human interactions combined with limited in-domain robot demonstrations. Specifically, they develop a factorized approach with two modules - a human-interaction-plan predictor that hallucinates future plausible motions of hands and objects from videos, and a translation model that maps these predicted plans to robot actions executable on a real physical platform. By leveraging easily available large-scale passive video datasets to learn hand-object interaction patterns that can generalize to unseen scenarios, their key insight is that the robot policy only needs a small amount of in-domain robot data for learning the mapping to its own embodiment. Through real-robot experiments encompassing 16 diverse manipulation skills with 100 tasks across 40 objects, they demonstrate that their framework can accomplish zero-shot table-top and in-the-wild manipulation in unseen environments not represented in the robot demonstrations. Comparisons to prior approaches and ablations validate that their factorization enables harnessing non-robot data at scale for manipulation. The framework represents an important step towards overcoming data constraints in robot learning by synergizing easily collectable human data with limited real-world robot interactions.
