# [CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via   Adversarial Latent Search](https://arxiv.org/abs/2306.10008)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How to protect facial privacy against unauthorized/black-box face recognition systems in a natural way that preserves user experience?The key hypothesis appears to be:By searching for adversarial latent codes in the low-dimensional manifold of a generative model trained on human faces, it is possible to generate protected face images that fool black-box face recognition systems while looking natural and preserving identity as perceived by humans. The paper proposes a framework to find such adversarial latent codes guided by user-defined makeup text prompts. The main contributions seem to be:1) A two-step facial privacy protection approach using adversarial latent code search in generative models.2) Leveraging textual makeup prompts for more flexible and natural adversarial transformations. 3) An identity-preserving regularization technique to maintain human-perceived identity.In summary, the core research focus is on developing a facial privacy protection method that strikes a balance between deceiving unauthorized face recognition systems (privacy) and preserving natural appearance and identity based on human perception (user experience). The key hypothesis is that optimizing over the latent space of generative models guided by textual prompts can achieve this goal.


## What is the main contribution of this paper?

The main contribution of this paper is developing a facial privacy protection method using text-guided adversarial latent search. Specifically, the key contributions are:1. Proposing a framework to search for adversarial latent codes in the latent space of a pretrained generative model (StyleGAN) to generate natural looking and identity preserving adversarial faces. 2. Leveraging user-defined textual makeup prompts and cross-modal vision-language model (CLIP) to guide the adversarial latent code search. This provides flexibility compared to using reference makeup images.3. Introducing an identity preserving regularization to optimize only over identity-related latent codes. This maintains the visual identity while fooling face recognition systems.4. Demonstrating the effectiveness of the approach under both face verification and identification settings for dodging and impersonation attacks. The method achieves higher protection success rates compared to prior arts like AMT-GAN and TIP-IM.5. Validating the practical applicability by attacking real-world commercial face recognition APIs like Face++ and Tencent.In summary, the key novelty is performing adversarial latent code search guided by user-defined text prompts to generate inconspicuous adversarial faces that protect facial privacy without compromising user experience. The identity preserving regularization and effectiveness against black-box APIs are other notable contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the main contributions of this paper:This paper proposes a new facial privacy protection approach that searches for adversarial latent codes in the low-dimensional manifold of a pretrained generative model, guided by user-defined makeup text prompts and an identity-preserving regularization, to generate natural-looking adversarial faces that can fool black-box face recognition systems.
