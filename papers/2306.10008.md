# [CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via   Adversarial Latent Search](https://arxiv.org/abs/2306.10008)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How to protect facial privacy against unauthorized/black-box face recognition systems in a natural way that preserves user experience?The key hypothesis appears to be:By searching for adversarial latent codes in the low-dimensional manifold of a generative model trained on human faces, it is possible to generate protected face images that fool black-box face recognition systems while looking natural and preserving identity as perceived by humans. The paper proposes a framework to find such adversarial latent codes guided by user-defined makeup text prompts. The main contributions seem to be:1) A two-step facial privacy protection approach using adversarial latent code search in generative models.2) Leveraging textual makeup prompts for more flexible and natural adversarial transformations. 3) An identity-preserving regularization technique to maintain human-perceived identity.In summary, the core research focus is on developing a facial privacy protection method that strikes a balance between deceiving unauthorized face recognition systems (privacy) and preserving natural appearance and identity based on human perception (user experience). The key hypothesis is that optimizing over the latent space of generative models guided by textual prompts can achieve this goal.
