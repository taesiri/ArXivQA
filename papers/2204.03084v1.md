# [Knowledge Infused Decoding](https://arxiv.org/abs/2204.03084v1)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question it aims to address is:

How can we infuse knowledge into language model decoding to improve performance on knowledge-intensive natural language generation tasks?

The key hypothesis is that dynamically retrieving relevant knowledge during each step of the language model's decoding process and using that knowledge to guide token generation will lead to improved performance compared to standard decoding algorithms like beam search and sampling. 

The paper proposes a novel decoding algorithm called Knowledge Infused Decoding (KID) that maintains a local knowledge memory based on the current context, interacts that with a dynamically created knowledge trie, and continuously updates the local memory to guide decoding via reinforcement learning.

The central hypothesis is that shaping the token probability distribution at each decoding step based on relevant entities extracted from the knowledge trie will make the language model generation more knowledge-aware, relevant, and factual compared to just using the model's parameters alone.

The paper aims to demonstrate through experiments on various knowledge-intensive NLG datasets that this knowledge-infused decoding approach can significantly improve over standard decoding algorithms as well as other knowledge-infusion techniques that require extra training or model architecture changes. The goal is to show the potential of better utilizing knowledge at inference time through decoding optimizations.
