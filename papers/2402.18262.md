# [Hierarchical Multimodal Pre-training for Visually Rich Webpage   Understanding](https://arxiv.org/abs/2402.18262)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Visually rich documents like webpages contain multiple modalities - text, images, layout, structure etc. which facilitate human understanding. However, modeling the interconnected nature of these modalities presents challenges for neural networks. 
- Existing methods for webpage understanding use only HTML text and structure, lacking rendered webpage screenshots. But HTML alone cannot fully represent real webpages.
- Current multimodal document pre-training methods treat images as natural images, ignoring the hierarchical document structure. They lack multi-granularity visual features and relationships between them.

Proposed Solution - WebLM:
- Collects large-scale multimodal webpage dataset with HTML, screenshots and metadata.
- Proposes a unified Transformer framework that concurrently models text, structure and image modalities of webpages. 
- Incorporates hierarchical structure of webpages into visual feature extraction using HTML structure and visual alignment in metadata. Extracts features across various levels - pages, sections, regions, elements.
- Models relationships between visual features using HTML structure.
- Proposes two novel pre-training tasks - Tree Structure Prediction (TSP) to predict tree relationships between HTML nodes, and Visual Misalignment Detection (VMD) to make model robust to visual noise.

Main Contributions:
- Collected multimodal dataset of 6 million webpages from 60,000 domains for pre-training.
- Proposed WebLM framework to effectively model text, structure and image modalities for webpage understanding.
- Incorporated hierarchical document structure into visual feature extraction.
- Proposed TSP and VMD pre-training tasks to model semantic relationships and enhance visual robustness.
- WebLM outperforms previous SOTA models on webpage QA and information extraction tasks, demonstrating effectiveness.
