# [Audio Dialogues: Dialogues dataset for audio and music understanding](https://arxiv.org/abs/2404.07616)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing datasets for audio understanding focus primarily on single-turn interactions like audio captioning or question answering, limiting more complex and interactive dialogues about audio content. There is a lack of multi-turn, conversational datasets tailored for training and evaluating audio-based models. 

Proposed Solution:
The paper introduces "Audio Dialogues", a multi-turn dialogue dataset for general audio sounds and music, containing 163.8k samples. It uses a prompting-based approach leveraging existing caption annotations (from AudioSet and MusicCaps datasets) to generate dialogues with GPT-4. The dataset has multiple subsets: AudioSet dialogues, Music dialogues, and AudioSet comparison questions. A data filtration strategy is used to retain high-quality dialogues.  

Main Contributions:
1) Multi-turn dialogue dataset covering sounds and music with training/evaluation splits 
2) Detailed data generation pipeline using prompts and filtration
3) Evaluation of audio models (LTU, Qwen-Audio, Audio Flamingo) on the dataset, showing benefit of fine-tuning on Audio Dialogues

The proposed Audio Dialogues dataset enables more complex audio understanding through multi-turn dialogues. Fine-tuning audio models on this dataset significantly improves performance over zero-shot, better equipping models to engage in nuanced interactions regarding audio content.
