# [Text-Guided Face Recognition using Multi-Granularity Cross-Modal   Contrastive Learning](https://arxiv.org/abs/2312.09367)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- State-of-the-art face recognition (FR) models struggle to achieve high performance when dealing with low-quality facial images from surveillance scenarios. Issues like noise, occlusion, lighting variation severely degrade performance. 
- Integrating textual descriptions of facial attributes can help improve FR performance by providing additional contextual information. However, aligning textual and visual features is challenging due to heterogeneity between modalities.

Proposed Solution:
- Propose a Text-Guided Face Recognition (TGFR) framework to integrate natural language facial descriptions to boost FR model performance.
- Uses a frozen state-of-the-art FR model as an image encoder and a Contrastive Language-Image Pretraining (CLIP)-like foundation model as the text encoder.
- Introduces a Face-Caption Alignment Module (FCAM) to map local and global features into a shared space using multiple cross-modal contrastive losses. Aligns captions with images globally and textual words with visual regions locally.
- Employs a Face-Caption Fusion Module (FCFM) to implement fine-grained interactions between regional visual features and word embeddings.

Main Contributions:
- Boosts performance of state-of-the-art FR models by effective cross-modal and intra-modal contrastive learning.
- FCAM aligns global & local features between modalities using caption-image (CICL) and word-region (WRCL) contrastive losses. Also uses intra-modal contrastive loss. 
- FCFM explores fine-grained cross-modal interactions and coarse-grained associations for improved fusion.
- Experiments on 3 datasets show significant verification rate and rank-1 identification accuracy improvements over baseline methods. Greater gains in low-quality images.

In summary, the paper presents an effective framework to integrate facial descriptions to boost face recognition performance by alignment of multimodal features using contrastive learning.
