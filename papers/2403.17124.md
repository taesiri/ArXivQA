# [Grounding Language Plans in Demonstrations Through Counterfactual   Perturbations](https://arxiv.org/abs/2403.17124)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Grounding the knowledge captured in large language models (LLMs) like GPT-3 into physical domains to enable robots to solve multi-step tasks remains an open challenge. Prior works have focused on using LLMs to generate symbolic plans but require predefined skills and additional tools to assess feasibility. This lacks interpretability and robustness when executing the plans on real robots.  

Proposed Solution:
The key idea is to leverage the concept of "mode families" from manipulation planning literature, which refer to manifolds in configuration spaces that encode specific motion constraints. The paper proposes GLiDE, a framework to ground language plans as sequences of mode transitions that implicitly satisfy preconditions and constraints needed for task success. 

Given a few human demonstrations, GLiDE perturbs the trajectories to generate additional counterfactual executions that fail the task. The overall binary task success labels then allow learning neural classifiers that map low-level states to high-level mode abstractions without needing exhaustive human annotation. GLiDE also prompts LLMs to describe the modal structure of a task, which helps constrain the classifier learning. The end result is improved interpretability of failures and more robust policies by sequencing mode-specific controllers.

Main Contributions:
- Introduces mode families as an intermediate representation connecting high-level language plans and low-level configuration spaces
- Learns mode classifiers without dense supervision via an explanation-based learning paradigm using limited perturbations
- Enables leveraging LLM plans for failure interpretation and replanning with the learned grounding operators
- Demonstrates improved robustness of mode-based policies on 2D navigation, Robosuite sim tasks, and two real robot tasks

The key advantage is the improved interpretability and reactiveness for robot learning without needing extensive engineering of perception pipelines or low-level controllers. By recovering mode constraints from demonstrations, the system can detect infeasible transitions and query LLMs for replanning.
