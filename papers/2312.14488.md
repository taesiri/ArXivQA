# [Language Model is a Branch Predictor for Simultaneous Machine   Translation](https://arxiv.org/abs/2312.14488)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Simultaneous machine translation (SiMT) aims to minimize translation latency while preserving quality. Existing methods adopt a prefix-to-prefix architecture which struggles to determine the optimal alignment between source and target prefixes. This results in either excessive delay or insufficient context for accurate translation.

Proposed Solution: 
The paper draws inspiration from CPU branch prediction and proposes incorporating similar techniques into SiMT. Specifically, a language model is utilized as a branch predictor to predict future source words. The predicted words are used to decode target words in advance. If the actual source word deviates from the prediction, the predicted output is withdrawn and re-decoded using the real source word. This prediction process runs in parallel to mitigate computational costs.

Key Ideas:
- Language model predicts next source words like a CPU branch predictor forecasts instruction flow  
- Predicted source words used to preemptively decode target output
- Mispredicted output withdrawn and re-decoded with actual source 
- Prediction layer runs in parallel so adds minimal computational cost
- Compatible with any existing SiMT model

Main Contributions:
- Proposes novel concept of using language models as branch predictors for SiMT
- Achieves lower latency while maintaining/improving translation quality
- Applicable across various SiMT methods and modalities (speech, vision, etc.)
- Introduces pre-trained language models shared as encoder and predictor which significantly boosts performance
- Analyzes impact of factors like language model size, fine-tuning, prediction threshold etc.

In summary, the paper puts forth an efficient and universal technique to enhance SiMT by adapting concepts from CPU branch prediction. Experiments confirm reduced latency and competitive quality across translation tasks.
