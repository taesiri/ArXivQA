# [CogCoM: Train Large Vision-Language Models Diving into Details through   Chain of Manipulations](https://arxiv.org/abs/2402.04236)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing vision-language models (VLMs) are trained to simply align visual inputs to linguistic answers, which leads them to ignore critical visual reasoning steps. This results in failures on meticulous visual problems, unfaithful responses, and even hallucinations.

Proposed Solution: 
- The paper proposes "Chain of Manipulations" (CoM), a mechanism that enables VLMs to solve problems through a series of manipulations on the visual inputs. Each manipulation refers to an operation that acquires different types of visual contents (e.g. zooming in on a region).

- An automatic data production framework is introduced to generate training data of reasoning chains from existing QA pairs. It involves a linguistic annotator (GPT-4) to provide solving steps and visual annotators to supply manipulation returns.

- A 17B VLM called CogCoM is trained with a memory-based architecture compatible for multi-turn reasoning. It performs evidential reasoning by actively adopting manipulations at each step.

Main Contributions:
- Proposes CoM, a general reasoning mechanism for VLMs to perform step-by-step visual reasoning with manipulations.

- Introduces an efficient data framework to automatically synthesize reasoning chains as training data.

- Develops CogCoM, a 17B VLM trained with compatible architecture and mixture of reasoning chains, which achieves SOTA across 8 benchmarks.

- Provides qualitative analysis to demonstrate CogCoM's detailed reasoning capabilities.

In summary, the key innovation is enabling VLMs to actively manipulate visual inputs for evidential reasoning, instead of passive end-to-end mapping. The data production framework and compatible model training approach contribute to an effective realization.
