# [Hard Negatives or False Negatives: Correcting Pooling Bias in Training   Neural Ranking Models](https://arxiv.org/abs/2209.05072)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to correct the pooling bias in labeled datasets for training neural ranking models (NRMs). The key points are:- Existing NRMs training relies on negative sampling over unlabeled data. Hard negative sampling from strong retrievers is shown beneficial for model generalization. However, it may introduce more false negatives (unlabeled positives) and hurt NRMs training.- The root cause of the false negative issue is the pooling bias during dataset construction, where only documents retrieved by some basic systems are labeled. This leads to potential existence of unlabeled positives.- The paper formulates the false negative problem as learning from biased labeled datasets. It proposes a Coupled Estimation Technique (CET) to jointly learn a relevance model and a selection model to estimate relevance scores and selection propensities for correcting the pooling bias.- Experiments on three benchmarks demonstrate NRMs learned with CET achieve significant gains against state-of-the-art methods in addressing false negatives during training.In summary, the key hypothesis is that by explicitly modeling and correcting the pooling bias in labeled datasets, NRMs can better distinguish false negatives from hard negatives and achieve more effective training. The proposed CET approach is shown empirically to support this hypothesis.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a Coupled Estimation Technique (CET) to address the false negative issue in training neural ranking models (NRMs) on labeled datasets with pooling bias. Specifically:- The paper formulates the false negative problem in training NRMs as learning from labeled datasets with pooling bias, where unlabeled positives are mistakenly sampled as negatives.- To solve this problem, the authors propose CET which jointly trains a relevance model to estimate documents' relevance and a selection model to estimate documents' selection propensity. The two models promote each other in a coupled learning manner.- Based on the estimated propensities, CET derives sample weights to relax the effect of false negatives and achieve bias correction learning for the relevance model.- Experiments on three retrieval benchmarks demonstrate that NRMs learned with CET significantly outperform baseline methods in ranking effectiveness.In summary, the key contribution is identifying the root cause of false negatives as pooling bias, and proposing the coupled estimation technique to address it by joint learning of relevance and selection models. This allows NRMs to benefit from hard negatives during training.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a Coupled Estimation Technique (CET) to address the pooling bias problem in training neural ranking models on labeled datasets, where CET jointly learns a relevance model and a selection model in a coupled manner to identify and correct for false negatives caused by the bias.


## How does this paper compare to other research in the same field?

This paper makes an important contribution to the field of neural ranking model training for information retrieval. Here is a summary of how it compares to related work:- Problem formulation: The paper provides a novel formulation of the false negative issue that arises when training neural ranking models as a problem of learning from datasets with pooling bias. This provides a principled perspective compared to prior work that viewed it mainly as a data noise issue.  - Proposed method: The Coupled Estimation Technique (CET) method is unique compared to prior techniques. It jointly learns a relevance model and selection model to adaptively identify false negatives caused by pooling bias. This is more advanced than heuristic filtering rules used before.- Empirical evaluation: The paper conducts extensive experiments on multiple datasets to validate the effectiveness of CET. Comparisons to several state-of-the-art baselines demonstrate clear improvements in ranking accuracy. The analysis provides insights into how CET helps address pooling bias.- Robustness: An important finding is that CET is robust and works for different neural ranking architectures trained with various retrievers. It also shows lower sensitivity to hyperparameters compared to prior methods. This indicates it is more widely applicable.Overall, the framing of the problem and the proposed CET method are novel contributions compared to related literature. The solid empirical evidence demonstrates its capabilities in improving neural ranking model training by handling pooling bias. The work highlights the importance of accounting for biases in training data.


## What future research directions do the authors suggest?

The authors suggest several potential future research directions at the end of the paper:1. Extend the proposed method to the listwise setting, where multiple negative samples are considered simultaneously to estimate the bias weights. This could further improve the estimation of bias weights.2. Apply the proposed method in the first-stage retrieval to address the pooling bias problem. The authors focused on solving the pooling bias issue for training the neural ranker in this work. But the bias also exists in the training data for neural retriever models. Applying the method to debias the retriever training could be an interesting direction.3. Investigate other potential applications of the proposed Coupled Estimation Technique (CET). The authors mention that CET could be potentially used in other scenarios with biased training data besides information retrieval. Exploring other applications of CET could be an important future work. 4. Study the effect of different model architectures in the CET framework. As discussed in the paper, the performance gain of CET varies for different neural ranking models. Analyzing the impact of model architecture design choices could provide useful insights.5. Extend CET to address other types of bias in IR training data beyond pooling bias, such as position bias and trust bias. The authors focused on pooling bias in this work, but other biases also widely exist in IR datasets. Expanding the technique to handle other biases could make it more generally applicable.In summary, the main future directions are: applying CET in more scenarios like first-stage retrieval and other tasks; investigating the effect of techniques like listwise learning and model architecture design; and generalizing it to address other types of bias in IR training data.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the key points from the paper:The paper focuses on addressing the false negative issue when training neural ranking models (NRMs) on labeled datasets with pooling bias. The pooling bias occurs because annotators only label documents selected by basic retrievers, causing unlabeled positives (false negatives) in the data. Hard negative sampling from stronger retrievers increases false negatives, hurting NRM training. To solve this, the authors propose a Coupled Estimation Technique (CET) to jointly learn a relevance model and selection model on the biased data. The selection model estimates the propensity of a document being selected, which helps train the relevance model by downweighting false negatives. Experiments on three datasets show CET significantly improves ranking performance over methods like denoising and propensity weighting. Overall, CET provides an effective approach to correct pooling bias and train high quality NRMs from labeled IR datasets.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:This paper addresses the issue of false negatives hurting the performance of neural ranking models (NRMs) when trained on datasets with pooling bias. Many large-scale IR datasets are constructed by having human annotators label the relevance of documents retrieved by some initial system. This leads to a pooling bias, where there may be many unjudged yet relevant documents (false negatives).  When training NRMs on such datasets and using top ranked results of a stronger retriever for hard negative sampling, performance degrades due to more false negatives. The authors propose a Coupled Estimation Technique (CET) to jointly learn a relevance model and selection model to correct for the pooling bias. The relevance model estimates document relevance while the selection model estimates the likelihood of a document being selected for annotation. These two models are trained together, with the selection model providing weights to reduce the impact of likely false negatives. Experiments on MS MARCO, TREC DL, and DuReader datasets show CET can significantly improve ranking performance over methods that heuristically identify false negatives. CET also works well across different rankers and retrievers.
