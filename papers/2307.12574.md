# [A Good Student is Cooperative and Reliable: CNN-Transformer   Collaborative Learning for Semantic Segmentation](https://arxiv.org/abs/2307.12574)

## What is the central research question or hypothesis that this paper addresses?

From my understanding, the central research question this paper seeks to address is:How to collaboratively learn compact yet effective CNN-based and ViT-based models for semantic segmentation by selecting and exchanging reliable knowledge between them? Specifically, the authors propose a novel online knowledge distillation framework that enables a CNN-based student model and a ViT-based student model to teach each other and learn collaboratively. The key research questions/goals are:1) How to enable the CNN student and ViT student to learn complementary heterogeneous features from each other, to compensate for their individual limitations? 2) How to transfer reliable knowledge between the CNN and ViT students selectively in both the feature space and prediction space?3) How to simultaneously optimize compact yet effective CNN and ViT models that surpass training them individually, through collaborative online distillation?The main hypothesis is that by exchanging knowledge bidirectionally between CNN and ViT students in a selective manner guided by ground truth labels, the two heterogeneous models can learn collaboratively and achieve improved performance over training individually. The proposed methods of heterogeneous feature distillation and bidirectional selective distillation are designed to address these challenges. Experiments on semantic segmentation datasets demonstrate the effectiveness of the proposed collaborative learning framework.In summary, the key research question is how to synergistically optimize and transfer knowledge between CNNs and ViTs for semantic segmentation in an online distillation manner, which is addressed through the proposed techniques in this paper.


## What is the main contribution of this paper?

Based on my understanding, the main contributions of this paper are:1. It proposes the first online knowledge distillation (KD) strategy to collaboratively learn compact yet effective CNN-based and ViT-based models for semantic segmentation. 2. It introduces two key technical innovations:- Heterogeneous feature distillation (HFD) to improve students' consistency in low-layer feature space by mimicking heterogeneous features between CNNs and ViT.- Bidirectional selective distillation (BSD) to transfer selective knowledge bidirectionally between CNNs and ViT in both feature space and logit space. This includes region-wise BSD to determine knowledge transfer directions between regions, and pixel-wise BSD to discern which prediction knowledge to transfer.3. Extensive experiments show the proposed method outperforms state-of-the-art online distillation methods by a large margin on semantic segmentation benchmarks like PASCAL VOC, Cityscapes and CamVid. The results demonstrate the efficacy of the proposed collaborative learning between CNN-based and ViT-based models.In summary, the key contribution is proposing the first online knowledge distillation strategy to enable effective collaborative learning between CNN-based and ViT-based models for semantic segmentation, with two novel techniques HFD and BSD. Experiments validate its superiority over existing approaches.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper proposes an online knowledge distillation framework that enables compact CNN-based and ViT-based models to collaboratively learn from each other for semantic segmentation by exchanging reliable knowledge bidirectionally between them in the feature and logit spaces.
