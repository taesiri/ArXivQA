# [On the Benefits of Fine-Grained Loss Truncation: A Case Study on   Factuality in Summarization](https://arxiv.org/abs/2403.05788)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Text summarization and simplification models suffer from generating inaccurate or unsupported information (hallucinations). This stems from training on misaligned data, where ground truth targets contain information not supported by the input. Prior work has tried to address this via training procedures or post-processing, but the root issue of noisy training data remains. 

Methodology: 
The paper studies Loss Truncation (LT), an efficient method that adaptively removes noisy examples during training by truncating losses above a threshold. Although LT reduces hallucinations, models still produce substantial fabricated content. 

To understand this, the authors analyze LT's assumption that noisy targets have higher loss. They find minimal loss difference between clean and noisy examples, limiting LT's performance. However, loss on entity tokens shows a clearer distinction. 

Key Insights:
1) Noisy examples don't necessarily have higher loss, violating LT's assumption. 
2) Entity token losses better indicate noise over sentence losses.
3) Web-scraped datasets are much noisier than human-annotated ones.

Contributions:
1) Demonstrate LT's limited performance when its assumption isn't met. 
2) Propose "fine-grained LT" using entity token losses, reducing hallucinations on some datasets.
3) Develop heuristic data cleaning strategies tailored to dataset noise, further lowering hallucinations.

The analysis offers new perspectives on LT's underlying dynamics, while the proposed methods showcase the potential of fine-grained loss truncation and data cleaning for improving factuality in summarization. Limitations include restricted evaluation to entity hallucinations and varying performance over datasets.
