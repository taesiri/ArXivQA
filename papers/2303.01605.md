# [Hierarchical discriminative learning improves visual representations of   biomedical microscopy](https://arxiv.org/abs/2303.01605)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: Can leveraging the inherent patient-slide-patch hierarchy of clinical biomedical microscopy data improve self-supervised visual representation learning compared to existing methods that do not account for this hierarchy? 

The key hypothesis is that by combining patch, slide, and patient level discrimination into a unified hierarchical self-supervised learning objective (HiDisc), they can learn better visual representations without needing additional annotations. The hierarchical discrimination tasks provide increased diversity between positive image pairs compared to standard patch-level instance discrimination. This allows the model to learn features related to the underlying diagnosis rather than just individual patches.

In summary, the central hypothesis is that accounting for the hierarchical structure of clinical microscopy data in a self-supervised framework like HiDisc will lead to improved visual representations compared to prior self-supervised methods that do not leverage this hierarchical information. The paper aims to demonstrate this through quantitative and qualitative benchmarking experiments on two different biomedical image analysis tasks.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a new self-supervised learning method called HiDisc that leverages the inherent patient-slide-patch hierarchy of clinical microscopy images. 

2. HiDisc defines hierarchical discrimination tasks at the patch, slide, and patient levels to learn visual representations without the need for labels.

3. It shows that HiDisc outperforms previous self-supervised methods like SimCLR, BYOL, and VICReg on two biomedical image classification tasks, demonstrating improved representation learning.

4. The method does not require strong data augmentations like prior instance discrimination methods and can work well with just basic augmentations.

5. It provides both quantitative evaluation as well as qualitative visualization of the learned representations to demonstrate the benefits of HiDisc. 

In summary, the key novelty is utilizing the hierarchical structure of microscopy data to define a new self-supervised pretext task for representation learning, outperforming prior arts and showing the potential of hierarchical discrimination for biomedical images. The method also reduces reliance on strong augmentations.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper introduces HiDisc, a self-supervised learning method that leverages the inherent patient-slide-patch hierarchy of clinical microscopy data to define hierarchical discrimination tasks for learning high-quality visual representations without the need for strong data augmentations.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other research on self-supervised learning for biomedical image analysis:

- The key novelty of this paper is using the inherent hierarchical structure of clinical whole slide images (patient -> slides -> patches) to define the pretext task for self-supervised learning. Most prior work has focused just on patch-level instance discrimination, without considering the relationships between patches.  

- This hierarchical approach allows them to create more diverse positive pairs during contrastive learning, without needing to rely as heavily on data augmentations. Other recent methods like BYOL and SimSiam also aim to reduce the need for augmentations, but not by using hierarchical information.

- For biomedical images specifically, there has been some prior work using self-supervised learning, but it has mostly applied standard SSL approaches like SimCLR directly to patches. This paper shows that designing the pretext task around the data structure can lead to better representations.

- They demonstrate strong results on two distinct biomedical image datasets/tasks - multiclass cancer diagnosis on microscopy, and predicting genetic mutations from histopathology slides. Showing consistent improvements over multiple datasets is important.

- The hierarchical discriminative learning idea seems quite generalizable, so it will be interesting to see if it could extend to other medical imaging data like radiology scans that also have a nested data structure.

- One limitation is that they only evaluate representations using a nearest neighbor classifier. Fine-tuning evaluation could give more insight into downstream performance. But the gains with kNN Evaluation are fairly convincing.

Overall, this paper makes a nice contribution in tailoring self-supervised learning specifically to leverage hierarchical structure in biomedical images. The core idea seems applicable to other domains as well.
