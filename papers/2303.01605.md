# [Hierarchical discriminative learning improves visual representations of   biomedical microscopy](https://arxiv.org/abs/2303.01605)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: Can leveraging the inherent patient-slide-patch hierarchy of clinical biomedical microscopy data improve self-supervised visual representation learning compared to existing methods that do not account for this hierarchy? 

The key hypothesis is that by combining patch, slide, and patient level discrimination into a unified hierarchical self-supervised learning objective (HiDisc), they can learn better visual representations without needing additional annotations. The hierarchical discrimination tasks provide increased diversity between positive image pairs compared to standard patch-level instance discrimination. This allows the model to learn features related to the underlying diagnosis rather than just individual patches.

In summary, the central hypothesis is that accounting for the hierarchical structure of clinical microscopy data in a self-supervised framework like HiDisc will lead to improved visual representations compared to prior self-supervised methods that do not leverage this hierarchical information. The paper aims to demonstrate this through quantitative and qualitative benchmarking experiments on two different biomedical image analysis tasks.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a new self-supervised learning method called HiDisc that leverages the inherent patient-slide-patch hierarchy of clinical microscopy images. 

2. HiDisc defines hierarchical discrimination tasks at the patch, slide, and patient levels to learn visual representations without the need for labels.

3. It shows that HiDisc outperforms previous self-supervised methods like SimCLR, BYOL, and VICReg on two biomedical image classification tasks, demonstrating improved representation learning.

4. The method does not require strong data augmentations like prior instance discrimination methods and can work well with just basic augmentations.

5. It provides both quantitative evaluation as well as qualitative visualization of the learned representations to demonstrate the benefits of HiDisc. 

In summary, the key novelty is utilizing the hierarchical structure of microscopy data to define a new self-supervised pretext task for representation learning, outperforming prior arts and showing the potential of hierarchical discrimination for biomedical images. The method also reduces reliance on strong augmentations.
