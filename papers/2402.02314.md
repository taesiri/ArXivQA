# [Selecting Large Language Model to Fine-tune via Rectified Scaling Law](https://arxiv.org/abs/2402.02314)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is a growing ecosystem of large language models (LLMs), posing the challenge of selecting the most appropriate pre-trained model to fine-tune. 
- Given limited resources like time, computation, and storage, it is infeasible to fine-tune all candidate models and compare. Intuitive selection methods also fail.
- The difficulty in predicting full fine-tuning performance given limited resources connects to understanding scaling laws in fine-tuning.

Key Observations:
- Unlike pre-training, the fine-tuning scaling curve shows a "phase transition" - a pre-power phase where slope decreases, followed by the power phase where loss and data size are linearly correlated in log-log scale.
- Existing scaling laws fail to capture this transition both theoretically and empirically.

Proposed Solution: 
- Introduce a "pre-learned data size" term into the scaling law, indicating data size pre-learned from pre-training relevant for the downstream task.
- This overcomes limitations of previous laws and fits experimental results much better.

Main Contributions:
- Establish rectified scaling law of LLM fine-tuning incorporating pre-learned data size, which fits phase transition behavior.
- Propose LLM selection algorithm "Accept then Stop" that leverages the law - distinguishes phases in scaling curve and extrapolates full performance.
- Demonstrate superior and consistent performance over baselines, selecting near optimal models with hundreds of times less resources.

The summary covers the key aspects of the paper including the problem definition, limitations of existing work, proposed solutions, and highlights the main contributions around the rectified scaling law and LLM selection algorithm.
