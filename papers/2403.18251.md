# [Since the Scientific Literature Is Multilingual, Our Models Should Be   Too](https://arxiv.org/abs/2403.18251)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- English is assumed to be the dominant language for scientific literature and research. Many NLP models and datasets for scientific document representation only support English. 
- The paper quantitatively shows that the scientific literature is highly multilingual - around 15% is written in non-English languages like French, Spanish, Chinese etc.

Analysis & Results:
- English-only models have very high unknown token rates (>60%) when processing abstracts of papers in non-Latin scripts like Chinese, Korean, Japanese etc. This leads to poor representations.
- Even for languages using Latin scripts, English-only models show much higher perplexity compared to multilingual models like XLM-R, indicating deteriorating performance.  
- Real-world models used by Semantic Scholar also display nonsensical outputs for non-English papers.

Main Contributions:
- Quantitative analysis showing the diversity of languages in scientific literature based on a sample of over 28 million papers.
- Evaluation of English-only models on non-English papers demonstrating failures in representation.
- Examples of negative real-world impacts when using English-only models for a multilingual domain.
- Suggestions for improvements like multilingual models, better evaluation benchmarks covering more languages, using machine translation etc.

Key Message:
- Since scientific literature is multilingual, NLP methods involving scientific documents should have proper multilingual support to ensure fair and accurate representation across different languages.
