# Improving Generative Visual Dialog by Answering Diverse Questions

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can generative visual dialog models be improved by incentivizing the questioner agent (\Qbot) to ask more diverse questions during training?The key hypothesis is that encouraging \Qbot to ask more varied questions will reduce repetition in the \Qbot-\Abot dialog during reinforcement learning-based "self-talk" training. This will enable \Abot to explore a larger state space and be exposed to more visual concepts and varied questions. Overall, this should lead to better dialog quality in terms of diversity, consistency, fluency, and detail.The authors evaluate this hypothesis by introducing a smooth L1 penalty during RL training that penalizes successive dialog states from being too similar. This encourages \Qbot to drive the dialog in more varied directions. The resulting \Qbot-\Abot dialog is evaluated extensively, showing reductions in repetition and improvements in dialog quality while maintaining image relevance.In summary, the central research question is how to improve generative visual dialog via more diverse questioning, with the key hypothesis being that this will enable reinforcement learning to produce better quality dialog overall. The paper presents evidence to support this hypothesis through empirical results.


## What is the main contribution of this paper?

The main contribution of this paper is proposing an approach to improve generative visual dialog models trained with reinforcement learning (RL). Specifically:- The paper analyzes a prior RL-based approach for visual dialog called VisDial-RL, which trains a questioner bot (Q-bot) and answerer bot (A-bot) to play an image guessing game. - It identifies issues with VisDial-RL, including repetitive dialog and diminishing returns on the image guessing game after a few rounds.- To address these issues, the authors propose an auxiliary objective to encourage Q-bot to ask more diverse questions. This involves penalizing similarity between Q-bot's successive dialog states during training to reduce repetition.- Extensive experiments show that their approach leads to more diverse and informative dialog between Q-bot and A-bot, without reducing image relevance. Results also demonstrate improved consistency, fluency and detail compared to VisDial-RL baselines based on automatic metrics and human studies.In summary, the key contribution is an auxiliary diversity-promoting objective for RL-based visual dialog that yields better dialog agents through reduced repetition and more exploration. The overall approach helps address core challenges in training generative dialog models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a method to improve generative visual dialog models by incentivizing the questioner agent to ask more diverse questions during training, which reduces repetitive dialog and enables the answering agent to explore a larger state space.
