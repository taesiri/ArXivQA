# [TimeDRL: Disentangled Representation Learning for Multivariate   Time-Series](https://arxiv.org/abs/2312.04142)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes TimeDRL, a novel framework for self-supervised representation learning on multivariate time-series data. The key innovation is the disentanglement of timestamp-level embeddings, which capture granular information at each timestep, and instance-level embeddings that summarize the entire time-series instance. This is achieved by using a dedicated [CLS] token strategy on patched time-series data to extract the instance embedding directly while avoiding the anisotropy problem faced by prior works. TimeDRL employs two pretext tasks for representation learning - a timestamp-predictive task with reconstruction loss to optimize the timestamp embeddings, and an instance-contrastive task leveraging dropout randomness to optimize the instance embedding without needing external data augmentations. By avoiding augmentations altogether, TimeDRL mitigates inductive bias. Experiments on forecasting and classification tasks demonstrate state-of-the-art performance, with average improvements of 57.98% in MSE for forecasting and 1.25% in accuracy for classification over baselines. Ablation studies validate the relative contributions of TimeDRLâ€™s components. The disentangled dual representation makes TimeDRL universally applicable across various time-series applications.
