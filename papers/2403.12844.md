# [MELTing point: Mobile Evaluation of Language Transformers](https://arxiv.org/abs/2403.12844)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like chatbots have huge computational requirements, making deployment on mobile devices challenging. This limits their use for private, on-device applications. 
- There is a need to quantify LLM performance on mobile devices to identify bottlenecks and guide future research for efficient on-device deployment.

Methodology:
- The authors developed an automation infrastructure called MELT to benchmark LLM performance on mobile (Android, iOS) and edge devices.
- MELT supports automated model conversion, deployment, interaction and tracing of metrics like throughput, power, energy, and temperature during inference.
- Various popular open-source LLMs (1-13B parameters) were evaluated using MELT through conversational chat prompts. Quantization was used to reduce model size.

Key Contributions:
- First systematic study quantifying on-device computational, memory, energy, and thermal characteristics of LLMs during conversational inference.
- Highlight current limiting factors for deployment: memory bandwidth, sustained performance, thermals. Quantization helps but reduces accuracy.  
- Analysis of operator timing shows majority time spent in memory bound de-quantize and matrix multiply operations.
- Results showcase feasible but constrained on-device execution. Better hardware accelerators and offloading to capable ambient edge devices more promising currently.
- MELT automation infrastructure enables standardized benchmarking of diverse models across platforms. Can facilitate future mobile LLM research.

In summary, the paper provides unique benchmarking results that give important insights into the challenges, tradeoffs and potential solutions for enabling private and efficient deployment of conversational LLMs on future mobile systems.
