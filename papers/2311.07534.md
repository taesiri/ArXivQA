# [Unsupervised Musical Object Discovery from Audio](https://arxiv.org/abs/2311.07534)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes MusicSlots, a novel approach that adapts the SlotAttention architecture from the visual domain to achieve unsupervised decomposition of music spectrograms into constituent note spectrograms. Since concepts like occlusion do not apply in the auditory domain, the softmax normalization of alpha masks used in visual SlotAttention is not suitable for music. MusicSlots overcomes this by using sigmoid normalization or no alpha masking in the decoder. The authors introduce new multi-object music datasets based on Bach chorales and JazzNet to evaluate object-centric learning on music. On these datasets, MusicSlots shows strong performance on unsupervised note discovery and outperforms baselines like VAEs on supervised note property prediction tasks. It also generalizes better to unseen combinations and numbers of notes. The learned representations could be useful for applications like music transcription. Through both algorithmic innovations and new datasets, this work represents an important step in extending object-centric learning to the music domain.


## Summarize the paper in one sentence.

 The paper proposes MusicSlots, an object-centric autoencoder model that decomposes musical chord spectrograms into constituent note spectrograms in an unsupervised manner and shows it achieves good performance on downstream note property prediction compared to baselines.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the key points in this paper:

This paper proposes MusicSlots, a novel unsupervised object-centric learning method that extends the SlotAttention architecture from computer vision to the musical domain. The goal is to decompose a chord spectrogram into its constituent note spectrograms in a fully unsupervised manner. A key contribution is adapting SlotAttention to handle properties unique to the auditory domain, where concepts like occlusion and opacity are invalid. The authors introduce alternatives to softmax normalization of alpha masks to allow multiple notes to contribute to the power at a spectrogram location. They also introduce a new multi-object music dataset with chord and note-level spectrograms to evaluate object-centric learning on music. Experiments show MusicSlots successfully discovers notes in an unsupervised way and outperforms VAEs and supervised CNNs on downstream note property prediction tasks. Representations learned by MusicSlots could be useful for music transcription, generation and building more human-like models of audio perception.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes MusicSlots, an unsupervised object-centric model adapted from SlotAttention that can decompose musical chords in spectrogram representation into constituent note spectrograms without relying on annotated supervision.


## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is whether object-centric learning models that have been successful for visual scene decomposition can be adapted to achieve unsupervised music decomposition. Specifically, the authors investigate if the SlotAttention model can be modified to decompose a musical chord spectrogram into its constituent note spectrograms in a completely unsupervised manner.

The key hypothesis is that by making certain modifications to the SlotAttention architecture like removing the softmax normalization of the masks, and using a spectrogram-based multi-object music dataset for training and evaluation, their proposed MusicSlots model will be able to discover musical objects (notes) from chords without any supervision.

So in summary, the central research question is: Can object-centric learning approaches like SlotAttention be adapted to do unsupervised music decomposition by discovering notes in chords? And the key hypothesis is that with certain modifications, a SlotAttention-based model called MusicSlots can achieve this.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing MusicSlots, an object-centric autoencoder model adapted from visual SlotAttention to achieve unsupervised music decomposition. MusicSlots decomposes a chord spectrogram input into constituent note spectrograms.

2. Introducing modifications to SlotAttention such as removing softmax normalization of alpha masks in the decoder to make it suitable for the audio domain where concepts of opacity and occlusion do not apply.

3. Introducing a multi-object music dataset based on Bach chorales and JazzNet specifically for evaluating object-centric learning on music. The dataset provides chord spectrograms, constituent note spectrograms and ground truth binary masks.

4. Demonstrating MusicSlots' performance on unsupervised note discovery and comparing it against VAE and autoencoder baselines on supervised note property prediction tasks. MusicSlots achieves good note discovery and outperforms the baselines on note property prediction.

In summary, the main contribution is proposing an object-centric model for unsupervised music decomposition and introducing a suitable dataset to evaluate such models. The results demonstrate the promise of object-centric learning for music analysis tasks.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other research in unsupervised music decomposition and object-centric learning:

- This is the first work to apply object-centric learning models like SlotAttention to the problem of unsupervised music decomposition. Prior object-centric models have focused on vision tasks. 

- The paper introduces a new multi-object music dataset based on Bach chorales and JazzNet specifically for evaluating object-centric models on music. Other datasets in this area have not been tailored for object-centric approaches.

- The MusicSlots model outperforms common unsupervised baselines like autoencoders and VAEs on downstream note prediction tasks. This shows its learned representations are more useful. 

- Removing alpha masks and using sigmoid normalization instead of softmax leads to better music decomposition results with MusicSlots. This is different from prior object-centric models in vision that rely on softmax masks.

- MusicSlots generalizes better to unseen combinations of notes and different numbers of notes compared to supervised approaches. This demonstrates the benefits of unsupervised learning.

- While there has been related work on learning representations from audio and music, MusicSlots takes an object-centric approach focused on decomposing music into constituent objects.

So in summary, this paper uniquely applies object-centric learning to music, requires adapting models like SlotAttention to the audio domain, and shows strong results on unsupervised music decomposition compared to other models. The dataset and analyses of what modifications work best for music are also novel contributions.


## What future research directions do the authors suggest?

 Based on my review of the paper, some future research directions suggested by the authors are:

- Exploring extensions of MusicSlots to more complex musical structures beyond notes and chords, such as melodies, phrases, and full compositions. The authors mention that western tonal music has rich generative grammars at multiple levels of hierarchy.

- Applying MusicSlots to real-world music data beyond the synthetic datasets used in this work. The authors state that the representations learned by MusicSlots could be useful for practical applications like music transcription, generation, and building more human-like models of music perception.

- Investigating other choices for the normalization function of the alpha masks in MusicSlots' decoder, beyond sigmoid and no masking. The paper shows these perform much better than softmax for music, but there may be even better alternatives.

- Extending object-centric learning models like MusicSlots to other auditory domains beyond music, such as speech or environmental sounds. The authors suggest the concepts explored here could generalize.

- Combining the strengths of MusicSlots' unsupervised representations with supervised training for end tasks like transcription. The paper shows MusicSlots can outperform supervised baselines, suggesting benefits from pre-training.

In summary, the main future directions are exploring MusicSlots for more complex music structures, applying it to real audio data, improving the alpha masking, generalizing it to other audio domains, and combining unsupervised pre-training with supervised fine-tuning.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, here are some of the key terms and keywords associated with it:

- Object-centric learning
- Unsupervised learning
- SlotAttention 
- Music decomposition
- Note discovery
- Spectrogram
- Autoencoder
- Bach chorales
- JazzNet
- Alpha masks
- Occlusion
- Opacity
- Hungarian matching
- Mean squared error (MSE) 
- Mean intersection over union (mIoU)

The paper proposes MusicSlots, an unsupervised object-centric model that extends SlotAttention architecture from computer vision to decompose music spectrograms into constituent note spectrograms. It introduces modifications like removing softmax normalization of alpha masks to adapt SlotAttention from visual domain to music. The model is evaluated on new multi-object music datasets based on Bach chorales and JazzNet. Key results show MusicSlots achieves good unsupervised note discovery and outperforms baselines on supervised note property prediction tasks.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the methods proposed in this paper:

1. The paper proposes MusicSlots, an adaptation of the SlotAttention architecture for unsupervised music decomposition. How does MusicSlots differ from the original SlotAttention model for images? What modifications were made to adapt it to the audio domain?

2. The softmax normalization of alpha masks in SlotAttention's decoder is argued to be unsuitable for decomposing audio objects. Why is this the case? How do the concepts of opacity and occlusion differ between the visual and auditory domains?

3. The paper introduces alternatives to softmax normalization of alpha masks, such as sigmoid normalization and not using masks. How do these alternatives compare in quantitative performance on note discovery? What are the trade-offs?

4. What novel multi-object music dataset is introduced in this work? How is it generated and what statistics are provided about the dataset splits? How is it tailored to evaluate object-centric learning on music?

5. For the note discovery task, Hungarian matching is used to find the optimal assignment between predicted and ground-truth notes before calculating metrics like MSE and mIoU. Why is this matching necessary?

6. How does MusicSlots compare to various baselines like Autoencoders, VAEs, and CNNs on the supervised note property prediction task? Why might it outperform even the supervised baselines?

7. What ablations were performed to arrive at the final MusicSlots architecture? How impactful were modifications like stride length, removing softmax masks, and implicit differentiation?

8. The paper argues that training on multi-instrument datasets is beneficial for decomposition quality. Why might this be the case? How do the single vs multi-instrument results compare?

9. What value of beta worked best for the VAE baseline? How did reconstruction quality and downstream task performance change with higher beta values?

10. What are some of the common failure cases shown qualitatively for MusicSlots? What future work could be done to address these issues?
