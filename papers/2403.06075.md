# [Multisize Dataset Condensation](https://arxiv.org/abs/2403.06075)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Dataset condensation is useful to create small, representative datasets that enable efficient training. However, existing methods have limitations when applied to on-device scenarios with fluctuating compute resources.  
- Specifically, taking a subset from a condensed dataset leads to worse accuracy compared to directly condensing to that smaller size ("subset degradation problem"). But repeatedly condensing to multiple sizes requires extensive compute.

Proposed Solution - Multisize Dataset Condensation (MDC):
- Compresses multiple condensation processes into a single process to obtain condensed datasets of varying sizes after just one condensation. 
- Introduces an "adaptive subset loss" on top of the basic condensation loss to mitigate "subset degradation". Loss helps enhance learning for subsets.
- Adaptively selects a Most Learnable Subset (MLS) in each iteration to compute subset loss. MLS has steepest rate of change in its representation of original data.
- Freezes preceding MLS when its size is smaller than current MLS. Prevents overriding already learned info.

Key Contributions:
- First work to condense multiple condensation processes into one. Reduces compute and storage.
- Identifies and addresses "subset degradation problem" via adaptive subset loss. Enables flexible subset sizes.
- Extensive validation over networks (ConvNet, ResNet, DenseNet) and datasets (SVHN, CIFAR, ImageNet). E.g. 6.4% avg accuracy gains on CIFAR-10.
- 94.8% less training time needed to match baseline accuracy. New loss provides helpful supervision.

In summary, the paper introduces an efficient single-pass solution to multisize dataset condensation for on-device usage by adaptively enhancing subset quality over the process.
