# [Improving Adversarial Robust Fairness via Anti-Bias Soft Label   Distillation](https://arxiv.org/abs/2312.05508)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Deep neural networks (DNNs) suffer from adversarial attacks, where small perturbations to inputs can cause misclassification. Adversarial training (AT) is effective for improving robustness, but encounters a robust fairness problem - the model exhibits strong robustness on some classes (easy classes) but weak robustness on other classes (hard classes). This class-wise vulnerability raises security risks.

- Existing methods to improve robust fairness focus on re-weighting sample importance. However, the effect of labels that guide model training is ignored. 

Key Idea:
- The paper first empirically observes and theoretically analyzes that the smoothness degree of soft labels for different classes affects robust fairness. Using sharper soft labels for hard classes and smoother soft labels for easy classes can improve fairness. 

- Based on this finding, the paper proposes Anti-Bias Soft Label Distillation (ABSLD) within the knowledge distillation framework to pursue fairness by adjusting class-wise smoothness of soft labels. It assigns different temperatures when distilling soft labels for different classes based on the student's class-wise error risk.

Key Contributions:
- First work exploring effect of class-wise label smoothness on robust fairness. Found connection between label smoothness and model fairness.

- Proposed ABSLD method that adapts soft label smoothness in distillation process to mitigate fairness problem and boost worst-class robustness.

- Extensive experiments show ABSLD outperforms state-of-the-art methods on CIFAR datasets. Effectively improves model's overall robustness and fairness.

In summary, the key novelty is providing both empirical and theoretical justification that adjusting class-wise smoothness of soft labels can improve model robustness fairness, and using this idea to design the ABSLD distillation procedure. Experiments demonstrate clear improvement over prior arts.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes an Anti-Bias Soft Label Distillation (ABSLD) method that adjusts the smoothness degrees of teachers' soft labels for different classes to enhance adversarial robustness fairness in student models.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. The authors explore the effects of labels, specifically the class-wise smoothness degree of soft labels, on the adversarial robust fairness of deep neural networks (DNNs). They find both empirically and theoretically that adjusting the smoothness degrees can help improve robust fairness. 

2. The authors propose a method called Anti-Bias Soft Label Distillation (ABSLD) to address the robust fairness problem within the knowledge distillation framework. ABSLD adjusts the teacher's soft label smoothness for different classes by assigning them different temperatures based on the student's class-wise error risk. This reduces the error risk gap between different classes.

3. Through extensive experiments, the authors demonstrate that ABSLD outperforms state-of-the-art methods in terms of the overall robustness and fairness performance against different attacks on CIFAR-10 and CIFAR-100 datasets.

In summary, the main contribution is proposing and evaluating a method to improve adversarial robust fairness by adjusting the class-wise smoothness degree of soft labels used to guide model training.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, here are some of the key terms and concepts:

- Adversarial training (AT) - Training neural networks on adversarial examples to improve robustness against adversarial attacks. 

- Adversarial robustness distillation (ARD) - Using knowledge distillation to transfer robustness from a large teacher model to a smaller student model.

- Robust fairness - The notion that robust models should exhibit equal robustness across all classes, rather than just improving overall robustness. 

- Anti-bias soft label distillation (ABSLD) - The proposed method to improve adversarial robust fairness by adjusting the smoothness of soft labels on a per-class basis during distillation.

- Smoothness degree of soft labels - The paper argues both empirically and theoretically that the smoothness of soft labels impacts model fairness during training. Smoother labels for easy classes and sharper labels for hard classes can improve fairness.

- Re-temperating soft labels - Adjusting the temperature parameter on a per-class basis when creating soft labels to control their smoothness. Higher temperature makes labels smoother.

- Knowledge distillation - Using the soft labels from a teacher model to supervise training of a smaller student model.

In summary, the key focus is on improving the robustness fairness of distilled student models by adjusting the smoothness of soft labels for each class separately during training.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. What is the motivation behind exploring the effect of label smoothness on robust fairness? Why did the authors hypothesize that label smoothness could impact model fairness?

2. How does adjusting the smoothness of labels for different classes lead to more robust fairness? Explain the intuition behind why sharper labels for hard classes and smoother labels for easy classes improves fairness.  

3. Discuss the differences between existing sample re-weighting based fairness methods and the proposed label smoothness based method. What are the relative advantages and disadvantages?

4. Explain how the class-conditional label temperatures are adjusted in the Anti-Bias Soft Label Distillation (ABSLD) method. How does this reduce the optimization error risk gap between classes?

5. What threats to validity should be considered when evaluating the robust fairness results? Could the improvements be an artifact of the evaluation protocol or metrics?

6. How was the worst-case or hardest class determined for the CIFAR datasets? What are other potential ways to define class difficulty that could have been used?

7. What hyperparameter tuning was performed for the ABSLD method? Was a sensitivity analysis conducted with regards to key hyperparameters? 

8. Does the ABSLD method improve standard accuracy in addition to robust accuracy and fairness? If not, does this reveal any tradeoffs?

9. How well does the method generalize to more complex datasets like ImageNet? What architecture modifications might be needed to scale it up?

10. Can insights from the label smoothness analysis be combined with sample re-weighting to achieve further fairness gains? What other extensions seem promising to build on this work?
