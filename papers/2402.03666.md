# [QuEST: Low-bit Diffusion Model Quantization via Efficient Selective   Finetuning](https://arxiv.org/abs/2402.03666)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Diffusion models have achieved great success in image generation tasks recently. However, their practical deployment is limited by the high memory consumption and computational time during inference. Quantizing diffusion models to lower bit-widths can simultaneously accelerate inference speed and reduce memory usage. However, existing quantization methods fail to work properly under low-bit settings (e.g. 4-bit weight and 4-bit activation) due to overlooking three unique properties of quantized diffusion models:

1) Imbalanced activation distributions, where most values are small but some are sporadically large. Neither quantizing for small or large values works.  

2) Precise temporal information across the many time steps is important, but cannot be well-preserved using limited bits.

3) Different model components have varying sensitivity to quantization perturbations. Uniformly quantizing all layers is suboptimal.

Proposed Solution - QuEST:
The authors propose a quantization method called QuEST that addresses the above issues via efficient selective finetuning. The key ideas are:

1) Finetune model weights instead of finding optimal quantization parameters. This enhances model robustness to activation perturbations from quantization.

2) Identify time embeddings and attention layers as most vulnerable. Finetune them selectively and progressively using the full-precision model's outputs as supervision.

3) Introduce a Time-aware Activation Quantizer that uses separate quantization parameters for different time steps.

Main Contributions:

- Identify and validate three unique properties of quantized diffusion models that compromise performance.

- Propose the idea of using efficient selective weight finetuning to obtain low-bit quantization capability. 

- Achieve state-of-the-art image generation performance under 4-8 bit settings over multiple models and tasks. 

- Enable the first ever full 4-bit quantization of Stable Diffusion with reasonable image quality.

The method is time and memory efficient by being data-free and only finetuning a very small subset of weights.
