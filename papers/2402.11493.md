# [Benchmarking Knowledge Boundary for Large Language Model: A Different   Perspective on Model Evaluation](https://arxiv.org/abs/2402.11493)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Existing methods for evaluating large language models (LLMs) use fixed prompts/questions, which is unreliable due to the sensitivity of LLMs to prompts.
- Evaluating LLMs using a small set of prompts does not provide a comprehensive assessment of their knowledge capabilities. 

Proposed Solution:
- Introduce a new concept of "knowledge boundary" to evaluate LLMs more robustly. This encompasses both prompt-agnostic knowledge and prompt-sensitive knowledge within the model. 
- Formulate the problem of finding optimal prompts to reveal knowledge boundaries as a discrete optimization task.
- Propose a novel algorithm called Projected Gradient Descent with Constraints (PGDC) to search over semantic space to find optimal prompts.

Key Contributions:
- New paradigm for benchmarking knowledge boundaries of LLMs to provide more reliable evaluation.
- Design a prompt optimization method PGDC that outperforms baselines in detecting knowledge while preserving semantics.
- Evaluate 5 LLMs using PGDC, analyze their domain knowledge capabilities and limitations. 
- Findings provide guidance for appropriate LLM selection and design for downstream tasks.
- Open up a new direction in semantic-preserving prompt optimization for model evaluation.

In summary, this paper addresses the unreliability in existing LLM evaluation approaches due to prompt sensitivity issues. It proposes a novel prompt optimization algorithm to find optimal prompts that can reveal comprehensive knowledge boundaries of models for more robust assessment. Both quantitative experiments and human evaluations demonstrate the effectiveness of this new evaluation paradigm and algorithm.
