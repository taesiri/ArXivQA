# [DVAE++: Discrete Variational Autoencoders with Overlapping   Transformations](https://arxiv.org/abs/1802.04920)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes a new method for training generative models with discrete latent variables. The key ideas are:

1. A new class of "overlapping transformations" is introduced to smooth discrete variables. These transformations rely on mixtures of overlapping distributions that converge to discrete distributions.

2. The transformations enable training of models with directed priors (like VAEs) as well as undirected priors (like Boltzmann machines). New variational bounds are derived for training with Boltzmann machine priors. 

3. The transformations allow gradients to be estimated without special handling, enabling the use of automatic differentiation libraries.

4. A new VAE architecture called DVAE++ is developed that combines global discrete variables (to capture discontinuous properties) and hierarchical continuous variables (to capture local dependencies). The global variables have a Boltzmann machine prior.

5. Experiments show DVAE++ generates high quality samples and outperforms previous techniques for training discrete latent variable models, achieving state-of-the-art results on several benchmarks.

So in summary, the central hypothesis is that overlapping transformations can be used to effectively train deep generative models with discrete latent variables, capturing both global discrete properties and local dependencies. The effectiveness of this approach is demonstrated through the DVAE++ model and experiments.


## What is the main contribution of this paper?

 The paper proposes a new class of smoothing transformations for training discrete latent variable models. The key contributions are:

1. It introduces overlapping transformations that use a mixture of two overlapping distributions to relax discrete variables. This allows gradients to flow through discrete nodes during training.

2. It shows how overlapping transformations can be applied to train both directed and undirected (Boltzmann machine) priors over discrete latent variables. 

3. For undirected priors, it derives a new variational lower bound that enables end-to-end training without any special manual handling of gradients.

4. It develops DVAE++, a new deep generative model architecture with discrete global variables and convolutional local variables. DVAE++ incorporates overlapping transformations and achieves state-of-the-art performance on several image datasets.

5. Experiments demonstrate that overlapping transformations outperform previous continuous relaxations like Gumbel-Softmax and the original smoothing method used in discrete variational autoencoders. 

In summary, the main contribution is proposing overlapping transformations as a new way to incorporate discrete variables in variational autoencoders and showing this enables training highly expressive models like DVAE++. The theoretical derivation of the bounds and demonstration of strong empirical performance are also key results.


## How does this paper compare to other research in the same field?

 Here are some ways this paper compares to other research in discrete variational autoencoders and generative modeling:

- It proposes a new class of smoothing transformations for binary latent variables based on overlapping distributions. This is a novel approach compared to previous smoothing methods like the Gumbel-Softmax trick or spike-and-exponential distributions. 

- It shows these overlapping transformations can be used to train both directed and undirected (Boltzmann machine) priors over discrete latent variables. Prior work like Concrete/Gumbel-Softmax focused only on directed graphical models, while DVAE used spike-and-exponential for undirected priors. 

- The paper presents a new bound for training VAEs with Boltzmann machine priors that avoids manually coding gradients. This is an improvement over the original DVAE which required modifying gradients during training.

- DVAE++ integrates discrete latent variables with a hierarchy of convolutional continuous variables. This architecture builds upon recent advances in convolutional VAEs, adding discrete variables to capture global structure.

- Experiments show DVAE++ achieves state-of-the-art or comparable results to other VAEs on benchmark image datasets. The discrete variables are shown to capture meaningful semantic factors.

- The approach is compared extensively to other methods for training discrete variable models like Gumbel-Softmax, DVAE, NVIL, MuProp, etc. This provides insight into the relative merits of overlapping transformations.

Overall, this paper makes significant contributions in combining discrete and continuous latent variables in VAEs, proposing a novel smoothing method with theoretical justification, and achieving strong empirical performance on generative modeling tasks. It advances the state-of-the-art in variational autoencoders with discrete variables.
