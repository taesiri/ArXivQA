# [ARTIC3D: Learning Robust Articulated 3D Shapes from Noisy Web Image   Collections](https://arxiv.org/abs/2306.04619)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we reconstruct high-quality 3D articulated animal shapes and textures from sparse and noisy web image collections, without relying on any 3D shape templates or per-image annotations like keypoints or camera viewpoints?The key ideas and contributions are:- Proposing ARTIC3D, a novel diffusion-guided optimization framework to estimate 3D articulated shape and texture from sparse in-the-wild images.- Using a skeleton-based surface representation that enables explicit part manipulation and realistic animation.- Designing a Decoder-based Accumulative Score Sampling (DASS) module to efficiently incorporate 2D diffusion priors into the 3D optimization process.- Preprocessing noisy input images via diffusion models to obtain cleaner silhouettes and features.- Jointly optimizing camera, pose, shape, and texture to reconstruct details faithful to input images. - Introducing animation fine-tuning strategies to improve shape and texture coherence across frames.- Evaluating on PASCAL-Part, LASSIE, and a new extended LASSIE dataset with occluded images to demonstrate ARTIC3D can produce more robust and higher-quality 3D outputs compared to prior arts.In summary, the key hypothesis is that leveraging 2D diffusion priors can enable reconstructing high-fidelity 3D articulated shapes from sparse noisy image collections, without relying on 3D supervision or per-image annotations. The experiments seem to validate this hypothesis.


## What is the main contribution of this paper?

This paper presents ARTIC3D, a framework for reconstructing articulated 3D animal shapes and textures from sparse and noisy image collections without 3D supervision. The main contributions are:- Proposes a novel Decoder-based Accumulative Score Sampling (DASS) module to efficiently incorporate 2D diffusion priors into 3D surface optimization. DASS provides cleaner gradients compared to backpropagating through the latent encoder. - Uses DASS for input image preprocessing to deal with occlusions/truncation, shape/texture optimization, and animation fine-tuning for temporal consistency.- Achieves robust 3D reconstruction on a new E-LASSIE dataset with occluded web images, producing shapes and textures that are more detailed and faithful to the inputs compared to prior works.  - Enables applications like high-quality 3D animation and texture transfer by representing the 3D surface with articulated parts.Overall, the key insight is to leverage recent advances in 2D generative diffusion models to supervise the 3D optimization process for articulated animal shapes from challenging sparse image collections. The proposed strategies help produce shapes that are robust, detailed, realistic, and animatable.
