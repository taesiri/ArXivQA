# [Zero-shot Pose Transfer for Unrigged Stylized 3D Characters](https://arxiv.org/abs/2306.00200)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper tries to address is how to transfer poses from a reference avatar (e.g. a human or animal) to stylized 3D characters with significantly different shapes, without requiring tedious manual rigging or paired training data of the stylized characters. 

The key hypothesis is that by disentangling shape and pose using a correspondence-aware shape module and implicit pose deformation module, and using efficient test-time tuning, their method can achieve realistic and accurate pose transfer to stylized characters in a zero-shot manner, using only readily available data such as posed human meshes for training.

In summary, the paper aims to develop an automated approach for pose transfer to stylized characters that does not rely on manual rigging or paired training data, which are big limitations of prior methods. The key ideas are shape/pose disentanglement and zero-shot generalization using proposed modules like correspondence-aware shape encoding and implicit pose deformation.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a solution for deforming stylized 3D characters to match poses of reference avatars, using only easily accessible posed human/animal meshes for training. This avoids the need for tedious rigging or collection of paired stylized character data.

2. It develops a correspondence-aware shape understanding module and an implicit pose deformation module to enable generalization to unseen stylized characters and arbitrary poses in a zero-shot manner.

3. It introduces an efficient volume-based test-time training procedure to encourage realistic and accurate deformation of stylized characters. 

4. It demonstrates the effectiveness of the proposed method on both human and quadruped characters, producing more visually pleasing and accurate results compared to baselines trained with comparable or more supervision.

5. The minimal supervision requirement allows the method to be applied to categories like stylized quadrupeds where rigging/paired data is even more scarce.

In summary, the main contribution is a model that can deform unrigged stylized 3D characters guided by reference avatar poses, which requires little supervision, generalizes in a zero-shot manner, and produces high quality results. The technical novelty lies in the proposed modules and test-time tuning procedure.
