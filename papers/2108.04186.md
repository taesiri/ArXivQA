# [Pose is all you need: The pose only group activity recognition system   (POGARS)](https://arxiv.org/abs/2108.04186)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research questions and hypotheses addressed in this paper are:- Can group activity recognition be performed accurately using only tracked human poses as input, without relying on raw RGB video frames? - Will a model trained on pose data generalize better to new test data compared to models trained on RGB video frames?- Can 1D CNNs more effectively model the temporal dynamics of human poses for group activity recognition compared to RNN/LSTM models used in prior work?- Do spatial and temporal attention mechanisms help improve group activity recognition accuracy by identifying key people and video frames?- Does multi-task learning to jointly predict group and individual actions boost performance on the primary task of group activity recognition?The central hypothesis seems to be that a model using only tracked human poses as input can match or exceed the accuracy of state-of-the-art methods that use RGB frames and/or optical flow as input for group activity recognition. The authors design the POGARS model architecture to test this hypothesis. The other questions explore the benefits of different architectural choices like 1D CNNs versus RNNs and the usefulness of attention. The experiments aim to validate these hypotheses and design decisions empirically.In summary, the key focus is on developing an accurate and robust pose-based model for group activity recognition that generalizes better than methods relying on raw pixel input. The paper explores architectural innovations to achieve this goal.


## What is the main contribution of this paper?

The main contribution of this paper is the proposal of POGARS, a novel deep learning-based approach for group activity recognition that uses only tracked human poses as input. The key highlights of POGARS are:- It is the first group activity recognition system that uses only tracked human poses, without relying on pixel data like RGB images or optical flow.- It uses 1D CNNs instead of RNNs like LSTM to model the temporal dynamics of human poses. The 1D CNNs are found to be more effective.- It employs both spatial and temporal self-attention mechanisms to identify the most relevant people and time frames for recognizing the group activity. - It utilizes multi-task learning to simultaneously predict group activity labels and individual person actions, which is shown to improve performance.- Experiments on a standard volleyball dataset show POGARS achieves highly competitive accuracy compared to state-of-the-art methods, despite using only pose as input.- A key advantage is POGARS generalizes much better than RGB-based methods when tested on matches from new venues not seen in training. This is because pose representations exclude factors like background, clothing colors etc.In summary, the paper demonstrates pose alone contains enough information for accurate group activity recognition, and presents an effective deep learning architecture for this task that generalizes very well to new test data.
