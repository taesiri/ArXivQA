# [DeAL: Decoding-time Alignment for Large Language Models](https://arxiv.org/abs/2402.06147)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Large language models (LLMs) like GPT, PaLM, and LLama are capable of a wide range of natural language tasks, but aligning their generations to user preferences remains challenging. 
- Current methods focus on alignment during model training via reinforcement learning from human feedback (RLHF) or modifying the training loss. However, these have limitations:
  - Restricting models to predefined principles limits downstream applications
  - Requires maintaining custom fine-tuned models for each new alignment objective
  - Fine-tuning on private alignment data may not be possible 
  - Learned principles during training are not guaranteed to be respected during generation

Proposed Solution: \deal 
- A framework to impose custom alignment objectives at decoding time
- Views text generation as a heuristic search problem, with LLMs providing transition probabilities
- Lets users define arbitrary alignment objectives (programmatic like length, or abstract like harmless/helpfulness)  
- Objectives imposed via lookahead heuristics to guide search and find high reward sequences
- Can flexibly combine multiple objectives like helpfulness and harmlessness

Main Contributions:
- Formalizes decoding as a prompted search problem, discussing implications 
- Experiments with various constraints (keyword, length) and abstract objectives (harmlessness)
- Shows improved alignment over training-time methods like RLHF
- Allows customizing and combining objectives flexibly per use case
- Complementary to training methods, but more reliable for security use cases

Limitations:
- Inference efficiency reduced due to search over alignment objectives
- Future work is optimization for practical applications
