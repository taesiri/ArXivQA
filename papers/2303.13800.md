# [Aligning Step-by-Step Instructional Diagrams to Video Demonstrations](https://arxiv.org/abs/2303.13800)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How can we align in-the-wild web videos of furniture assembly with the respective diagrams in the instruction manuals?

Specifically, the paper introduces a new multimodal alignment task between:

(i) Instruction steps depicted as assembly diagrams in instruction manuals 

(ii) Video segments from real-world videos demonstrating the assembly process

The key challenges highlighted are:

- Instructional diagrams can be highly abstract compared to text/audio 

- Subtle differences between instruction steps 

- Assembly actions depicted may be unclear to machines

- No standard visual language followed in manuals

To address these challenges, the paper proposes a novel contrastive learning framework to align videos and diagrams using specialized losses. The effectiveness of the approach is evaluated on two tasks:

1) Nearest neighbor retrieval between video clips and diagrams

2) Aligning the instruction steps to video segments

The core hypothesis seems to be that the proposed losses will enable more effective video-diagram alignment on these tasks compared to alternatives. The paper introduces a new dataset called IAW to study this problem in a realistic setting.


## What is the main contribution of this paper?

 The main contribution of this paper is the introduction of a novel method for aligning step-by-step instructional diagrams with in-the-wild web videos of furniture assembly. Specifically:

- They propose a supervised contrastive learning approach with three novel losses designed for the task of aligning abstract instructional diagrams with real-world videos. 

- They introduce a new dataset called Ikea Assembly in the Wild (IAW) containing 183 hours of assembly videos crawled from YouTube and nearly 8,300 instructional diagrams scraped from Ikea manuals. The videos and diagrams are annotated with ground truth alignments.

- They define two tasks on this dataset - nearest neighbor retrieval between videos and diagrams, and full alignment of diagrams to video clips.

- They demonstrate through experiments that their method outperforms compelling alternatives like CLIP on both retrieval and alignment on this challenging new dataset.

So in summary, the main contribution is a novel supervised contrastive learning method tailored for aligning abstract instructional diagrams with real videos, evaluated on a new challenging dataset collected specifically for this purpose. The introduced dataset itself to study this problem is also a contribution.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper introduces a new method and dataset for aligning real-world instructional videos of furniture assembly with diagrams from instruction manuals using contrastive learning and novel loss functions.
