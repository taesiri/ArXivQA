# [TARGET: Federated Class-Continual Learning via Exemplar-Free   Distillation](https://arxiv.org/abs/2303.06937)

## What is the central research question or hypothesis that this paper addresses?

 From my reading, the key research focus of this paper is federated class-continual learning, which aims to enable continually learning new classes in a federated learning setting while mitigating catastrophic forgetting of old classes. 

Specifically, the paper proposes a new method called TARGET (federatTed clAss-continual leaRninG via Exemplar-free disTillation) to address the catastrophic forgetting problem in federated class-continual learning scenarios. The central hypothesis is that leveraging global information from the federated learning process can help alleviate catastrophic forgetting without requiring storing additional datasets or previous task data.

To test this hypothesis, the paper first analyzes the impact of non-IID (non-independent and identically distributed) data on exacerbating catastrophic forgetting in federated learning. It then proposes the TARGET framework which utilizes knowledge distillation from the global model trained on previous tasks to transfer knowledge to the model for the current task, along with training a generator to produce synthetic data capturing the global data distribution. This allows leveraging global information to mitigate catastrophic forgetting without violating privacy by storing real data.

Through extensive experiments on benchmark datasets, the paper demonstrates that TARGET outperforms existing federated class-continual learning methods by achieving higher average accuracy across tasks and lower forgetting of previous tasks. The results validate their hypothesis that using global information can effectively alleviate catastrophic forgetting in this setting.

In summary, the central research contribution is proposing and evaluating the TARGET framework to enable privacy-preserving federated class-continual learning by mitigating catastrophic forgetting through utilizing global model knowledge and synthesized global data.
