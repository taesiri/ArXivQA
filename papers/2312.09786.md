# [Drones Guiding Drones: Cooperative Navigation of a Less-Equipped Micro   Aerial Vehicle in Cluttered Environments](https://arxiv.org/abs/2312.09786)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem Statement:
The paper investigates the problem of enabling reliable navigation of micro aerial vehicles with limited sensing and computation capabilities in cluttered unknown environments. These less-capable UAVs do not have the payload capacity to carry heavy and expensive sensors like 3D lidars which are required for robust obstacle avoidance. The goal is to offload the necessity of these sensors to a more capable "primary" UAV while still providing obstacle avoidance capabilities to the less-equipped "secondary" UAV.

Proposed Solution:
The paper proposes a cooperative guidance framework where the primary UAV is equipped with a 3D lidar and builds a dense occupancy map of the surroundings. It also performs relative localization of the secondary UAV using lidar detections and visual-inertial odometry (VIO) data received from the secondary UAV over wireless network. Using this map and localization information, the primary UAV plans collision-free paths for both UAVs - guiding path for secondary UAV to reach specified goals and viewpoints for itself to track the secondary UAV. It then guides the secondary UAV by periodically sending waypoints from its planned path transformed to the secondary UAV's body frame.

Key Contributions:
- Novel cooperative framework to enable navigation of less-capable UAVs by offloading heavy sensing to a primary UAV
- Primary UAV builds map, localizes secondary UAV, plans paths for both UAVs and guides secondary UAV
- Precise relative localization by fusing lidar detections and VIO data 
- Viewpoint selection algorithm for primary UAV to maximize visibility of secondary UAV path 
- Real-world demonstration of the approach with two heterogeneous UAVs and all computation running fully onboard

The key idea is that by leveraging cooperation, the capabilities and sensors of robotic teams can be distributed efficiently to enable reliable and robust operation even for less-capable individual robots. The proposed framework demonstrates a successful implementation of this concept.


## Summarize the paper in one sentence.

 This paper proposes a novel cooperative guidance framework that enables offloading heavy and expensive obstacle sensors from a small UAV to a more capable UAV teammate, while preserving the obstacle avoidance capabilities of the small UAV.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel cooperative guidance framework that enables offloading the need to carry heavy and expensive obstacle-sensing sensors from a less-capable micro aerial vehicle (MAV) to a more-capable MAV in a heterogeneous multi-UAV team. Specifically:

- A primary UAV (pUAV) equipped with a 3D lidar builds a dense occupancy map of the unknown environment, performs precise relative localization of a secondary UAV (sUAV) using lidar detections, plans collision-free paths for both UAVs, and guides the sUAV along its planned path.

- The framework offloads the requirements for accurate mapping and planning from the size, weight and computationally constrained sUAV to the more capable pUAV, allowing the use of a miniature UAV with basic sensors as the sUAV.

- The approach is verified in real-world experiments with a lidar-equipped pUAV guiding a camera-equipped sUAV through cluttered environments, with all computation running fully onboard the UAVs.

So in summary, the key contribution is a cooperative guidance approach that leverages UAV heterogeneity to preserve obstacle avoidance for a size/weight constrained UAV by offloading key capabilities to a team member. The feasibility of guiding UAVs in this manner is demonstrated with real experiments.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Heterogeneous UAV teams - Using UAVs with different capabilities working cooperatively
- Guiding UAVs - One UAV guiding another less-capable UAV
- Offloading requirements - Moving computationally heavy tasks from a less capable UAV to a more capable one  
- Obstacle avoidance - Enabling a UAV to avoid collisions without heavy onboard sensors
- Occupancy mapping - Mapping obstacles in the environment 
- Path planning - Planning collision-free trajectories
- Relative localization - Precisely localizing one UAV relative to another
- Lidar detection - Detecting another UAV using lidar
- Vision-based navigation - Using cameras for state estimation
- Onboard computation - Running all algorithms fully on the UAVs themselves
- GNSS-denied environments - GPS-unavailable environments like forests or warehouses
- Micro UAVs - Small, lightweight UAV platforms

The key focus seems to be using a heterogeneous team to offload requirements from a micro UAV to a more capable UAV, specifically for mapping, path planning and precise relative localization to enable obstacle avoidance and navigation without heavy onboard sensors. The approaches are demonstrated in real-world experiments in cluttered environments without relying on external navigation systems.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions using reflective markers on the secondary UAV's legs to aid the lidar-based detection approach. What considerations need to be made in terms of the shape, size, orientation, and placement of these markers to maximize detection performance? How was this optimized in the experiments?

2. In the guiding viewpoint selection algorithm, what trade-offs need to be considered when selecting the parameters like raycasting sample count, raycasting maximum length, and minimum safe distance from the secondary UAV path? How were these parameters optimized for the forest experiments? 

3. The paper uses an A* planning algorithm for path planning. What modifications or constraints were made to the standard A* algorithm to make it suitable for multi-UAV planning in cluttered environments? Were heuristics used to improve performance?

4. What factors contribute to the total end-to-end latency in transmitting a planned path from the primary UAV to the secondary UAV? How does this latency impact overall system performance?

5. The primary UAV constructs a local occupancy map centered around itself. What considerations need to be made regarding the size of this map to balance real-time performance and completeness of obstacle information?

6. How robust is the proposed approach to temporary line-of-sight occlusions or lost detections between the UAVs? What recovery strategies are employed? How could they be improved?

7. What additional sensors could be integrated with the lidar-based relative localization to improve robustness? What modifications would need to be made to support sensor fusion?

8. How well would the proposed approach scale to guiding multiple secondary UAVs by a single primary UAV? What limits the number of secondary UAVs supported?

9. The experiments were all conducted with static environments. How well would the approach work in dynamic environments with moving obstacles? What changes are needed to enable reactive planning?

10. What effect does synchronization between the UAVs have on overall system performance? How accurate does the synchronization need to be? Could asynchronous operation work?
