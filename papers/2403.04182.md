# [Metric-aware LLM inference](https://arxiv.org/abs/2403.04182)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) show strong performance on NLP tasks when evaluated on the exact match (EM) metric. 
- However, many tasks use different evaluation metrics like squared error, F1 score etc.
- Current LLM inference via sampling the most likely target works well for EM but is suboptimal for other metrics.

Proposed Solution: 
- Propose metric-aware LLM inference (MALI) to optimize a custom metric at inference time.  
- Formulate the inference as a decision theoretic problem to maximize expected score.
- Derive optimal rules for common metrics like squared error, F1 etc.
- Approximate the expectation over LLM predictions via sampling. 

Main Contributions:
- Show across datasets that sampling just the top prediction is suboptimal for metrics like RMSE. Taking the mean/median of samples works better.
- For text metrics like F1, optimize over candidates derived from the samples.
- Analyze tradeoffs wrt number of samples, temperature scaling etc.
- Show gains from MALI over strong baselines like greedy decoding across models, metrics and datasets in a zero-shot setting.
- Point out that calibration of LLM distributions is crucial for effective application of MALI.

In summary, the paper proposes a principled technique to adapt LLM inference to the evaluation metric of interest that gives noticeable gains over current approaches. The decision theoretic view provides a valuable framework for metric-aware decoding.


## Summarize the paper in one sentence.

 This paper proposes metric-aware language model inference, a decision theoretic approach to optimize for custom evaluation metrics at inference time.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a metric-aware LLM inference approach called MALI. Specifically:

- It proposes using decision theoretic inference to optimize for custom evaluation metrics at test time, instead of just maximizing likelihood. 

- It shows across datasets and models that this approach can substantially improve performance over standard sampling or greedy decoding, especially when the evaluation metric is not exact match.

- It provides a general framework for metric-aware inference that can handle metrics like squared error, absolute error, F1 score, etc. by optimizing an expected utility objective.

In summary, the key insight is that typical LLM inference focuses on likelihood, which inherently optimizes for exact match, but many tasks use different metrics. So directly optimizing for those metrics with MALI gives better performance.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and keywords associated with this paper are:

- Large language models (LLMs)
- Metric-aware inference
- Decision theoretic approach 
- Custom metrics
- Academic benchmarks
- Exact match (EM) metric
- Zero-shot abilities
- Sampling temperature
- Bayes-optimal inference
- Model output distribution
- Evaluation metrics (squared error, absolute error, F1 score, etc.)

The paper proposes a metric-aware LLM inference approach to optimize for custom metrics at inference time rather than just using autoregressive sampling. It shows improvements on academic benchmarks by adapting the inference procedure to the evaluation metric. Key terms cover the proposed approach, metrics, experiments, and areas for future work.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. How does the proposed metric-aware LLM inference method differ from standard autoregressive decodingstrategies for LLMs? What problem does it aim to address? 

2. What is the key intuition behind formulating metric-aware LLM inference as a decision-theoretic approach? Explain the expected utility objective that is optimized.

3. Explain how the proposed method approximates the Bayes-optimal inference strategy. What two main approximations are made and why?

4. What is the benefit of using weighted likelihood estimates in the objective function optimized by the proposed method? How does it relate to temperature scaling?

5. How does the proposed method handle different evaluation metrics like squared error, F1 score etc? What solution strategies are adopted for metrics with and without closed-form solutions?

6. Explain the efficiency considerations when using sampling versus scoring for estimating the MALI objective. In which cases would sampling be preferred?

7. How is the method adapted for non-decomposable ranking metrics like AUC? What is the optimal decision rule used? 

8. What are some ways the candidate set C can be constructed when optimizing over text metrics like F1? How can samples be transformed to improve search?

9. How sensitive is the performance of the proposed approach to hyperparameters like number of samples K and sampling temperature T? Should they be tuned?

10. What are some promising future directions for improving upon metric-aware LLM inference proposed in the paper? Can the approach be extended to conditional generation tasks?
