# [FedX: Unsupervised Federated Learning with Cross Knowledge Distillation](https://arxiv.org/abs/2207.09158)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper abstract, the central research question seems to be: How can we develop an unsupervised federated learning framework that learns unbiased representations from decentralized, heterogeneous local data while preserving privacy between clients?The key points about the research question are:- It focuses on unsupervised federated learning, which is an emerging research area. Many existing federated learning methods rely on supervised learning with labeled data.- The goal is to learn good representations from non-IID (non-identically distributed) local data in a decentralized network. This setting poses challenges due to the heterogeneity and lack of global data distribution knowledge at individual clients.- Privacy preservation between clients is a key consideration. The method should avoid directly sharing or exposing local data.- The aim is to develop a novel framework that addresses these challenges in unsupervised federated learning and learns unbiased representations despite the decentralized heterogeneous data.So in summary, the core research question is around developing a new privacy-preserving unsupervised federated learning approach for learning from decentralized non-IID data. The paper seems to propose a solution called FedX that employs two-sided knowledge distillation to achieve this goal.


## What is the main contribution of this paper?

According to the abstract and introduction, the main contributions of this paper are:1. It proposes an unsupervised federated learning framework called FedX that learns data representations via two-sided knowledge distillation at the local and global levels. 2. The two-sided knowledge distillation helps discover meaningful representations from local data while eliminating bias by using global knowledge. 3. FedX can be applied to existing unsupervised algorithms to improve performance significantly (1.58-5.52 pp) in top-1 accuracy and enhance training speed.4. Unlike other unsupervised federated learning approaches, FedX preserves privacy between clients and does not share data directly. It is lightweight and does not require complex communication for sending data features.5. The authors have open-sourced FedX to share their technique and implementation details for tackling problems with decentralized data.In summary, the main contribution is proposing the FedX framework for privacy-preserving and efficient unsupervised federated learning via a unique two-sided knowledge distillation approach. The experiments demonstrate FedX's versatility in improving various existing algorithms and robustness across datasets and settings.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper presents FedX, an unsupervised federated learning framework that learns semantic representations from decentralized client data through a two-sided knowledge distillation strategy at the local and global levels without requiring direct data sharing between clients.
