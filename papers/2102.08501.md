# [DEUP: Direct Epistemic Uncertainty Prediction](https://arxiv.org/abs/2102.08501)

## What is the central research question or hypothesis that this paper addresses?

The central hypothesis of this paper is that model uncertainty/bias should be accounted for when estimating epistemic uncertainty, in addition to approximation uncertainty. The key claims made are:1) Discrepancy-based measures of epistemic uncertainty (e.g. variance of the Bayesian posterior predictive) only capture approximation uncertainty and miss model uncertainty/bias. This can lead to poor uncertainty estimates and decisions when the model is misspecified.2) The excess risk, defined as the gap between the generalization error and the Bayes error, captures both approximation and model uncertainty. It is proposed as a more robust measure of epistemic uncertainty.3) A framework called DEUP is proposed to directly estimate the excess risk by training a separate model to predict the generalization error and subtracting an estimate of aleatoric uncertainty.4) DEUP can improve optimization and exploration in interactive learning settings like sequential model optimization and RL compared to variance-based uncertainty measures.5) The error predictor in DEUP can generalize its uncertainty estimates to out-of-distribution data by using additional "stationarizing" features related to density and model variance.So in summary, the central hypothesis is that epistemic uncertainty estimates should account for model uncertainty/bias and not just approximation uncertainty. DEUP is proposed as a way to achieve this.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It provides a theoretical analysis of the sources of epistemic uncertainty and argues that model bias/misspecification should be accounted for, in addition to approximation uncertainty captured by variance. 2. It proposes the DEUP framework which trains an error predictor to estimate the generalization error (excess risk) directly. Subtracting an estimate of aleatoric uncertainty gives an estimate of epistemic uncertainty.3. It describes how DEUP can be adapted for interactive learning settings like active learning, sequential model optimization, and reinforcement learning. It proposes using stationarizing features like density, variance estimates, and an in-sample bit as inputs to the error predictor to make it robust to non-stationarities.4. It provides experimental validation that DEUP's uncertainty estimates lead to improved performance on downstream tasks like SMO, exploration in RL, and OOD detection compared to variance-based Bayesian approaches. It also shows DEUP can estimate uncertainty well in a real-world drug synergy prediction task.In summary, the key idea is to directly predict the generalization error using out-of-sample errors to get an estimate of epistemic uncertainty that captures model bias, unlike just using variance. The method is model-agnostic and shown to be useful across different interactive learning settings.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the main points from the paper:The paper analyzes sources of lack of knowledge (uncertainty) in machine learning models, argues that common Bayesian approaches largely ignore model uncertainty (bias), and proposes a framework called Direct Epistemic Uncertainty Prediction (DEUP) which trains an error predictor to directly estimate a model's generalization error and epistemic uncertainty.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other related work on epistemic uncertainty estimation:- It provides a theoretical analysis of the sources of lack of knowledge/epistemic uncertainty, arguing that model bias should be accounted for in addition to approximation uncertainty (variance). This is an important distinction from most existing work that focuses only on variance as a measure of epistemic uncertainty. - It proposes a principled framework (DEUP) for directly estimating epistemic uncertainty by predicting the generalization error. This is different from common Bayesian approaches that rely on the posterior variance, or ensemble methods that measure disagreement. It is more similar to recent work on predicting the loss directly.- For interactive learning settings, it proposes using "stationarizing" features like density and variance estimates to make the error prediction more robust to distribution shifts during learning. This idea of conditioning on properties of the dataset seems quite novel.- It aims to be model-agnostic, in that DEUP can be applied to any learner, Bayesian or not. Most existing approaches are tailored to specific model families like neural networks or Gaussian processes.- The experimental validation is quite extensive, spanning areas like SMO, RL, drug discovery etc. Most papers focus evaluation on 1-2 domains. The results suggest DEUP uncertainty is useful across a diverse set of applications.In summary, the key distinguishing aspects seem to be: 1) explicitly accounting for model bias in the theory of epistemic uncertainty 2) the DEUP framework to directly predict errors 3) the use of stationarizing features for handling distribution shifts and 4) model-agnostic formulation and extensive experimental validation. The paper makes both theoretical and practical contributions to improving epistemic uncertainty estimation.


## What future research directions do the authors suggest?

The paper suggests several promising directions for future research:- Investigating ways to improve the computational efficiency of DEUP. This could include exploring different choices of stationarizing features or alternate ways of incorporating the dataset as input to the secondary predictor.- Developing methods to estimate aleatoric uncertainty when no estimator is readily available and one cannot simply query an oracle multiple times on the same input x. This would allow DEUP to estimate epistemic uncertainty in a wider range of settings.- Theoretically studying the properties of DEUP under model misspecification. Understanding how misspecification impacts the error predictor and derived uncertainty estimates would be an important theoretical contribution.- Applying DEUP to additional interactive learning settings like active learning and exploration in reinforcement learning. Scalability to more complex environments is also an important direction.- Considering alternate loss functions beyond squared error for training the error predictor, which may capture epistemic uncertainty more effectively for certain tasks.- Exploring the use of different stationarizing features beyond density, variance, and in/out of sample indicators. Other statistical properties of the training set may further improve uncertainty estimates.- Leveraging alternate training strategies like meta-learning to make the error predictor generalize more effectively across main predictors and datasets.So in summary, the main suggested directions are: improving computational efficiency, handling aleatoric uncertainty, theoretical analysis, expanded applications, exploring additional features and training techniques, and using alternate loss functions. Overall the paper points to many interesting ways DEUP could be extended and improved in future work.


## Summarize the paper in one paragraph.

The paper presents a framework called DEUP (Direct Epistemic Uncertainty Prediction) for estimating epistemic uncertainty in machine learning models. The key ideas are:- Standard measures of epistemic uncertainty like variance of the Bayesian posterior capture approximation uncertainty but miss out on model uncertainty induced by misspecification/bias. - The excess risk, defined as the gap between the generalization error and Bayes error, captures both approximation and model uncertainty. So estimating excess risk is a sound way to measure epistemic uncertainty.- DEUP trains a secondary model called the error predictor to estimate the generalization error (risk) of the main predictor. Subtracting an estimate of aleatoric uncertainty gives the epistemic uncertainty.- For interactive learning settings, the error predictor takes stationarizing features like density, variance as input along with the data point. This helps handle the non-stationarity induced by retraining the main model.- Experiments show DEUP uncertainty estimates improve sequential model optimization and exploration in RL compared to baselines. DEUP also produces well-calibrated uncertainty estimates for classification and drug synergy prediction tasks.In summary, the paper proposes a principled and flexible framework DEUP for estimating epistemic uncertainty by directly predicting generalization error, which captures both approximation and model uncertainty. The method is evaluated extensively across different settings like active learning, showing improved performance over standard Bayesian approaches.
