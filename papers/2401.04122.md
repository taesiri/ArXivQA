# [From Prompt Engineering to Prompt Science With Human in the Loop](https://arxiv.org/abs/2401.04122)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Using large language models (LLMs) for scientific research via prompt engineering can introduce issues like bias, lack of transparency, and inability to replicate findings. 
- Prompt engineering involves iteratively tweaking a prompt to get desired LLM responses, but this process is ad-hoc and subjective.

Proposed Solution:
- Transform prompt engineering into "prompt science" with more rigor and transparency. 
- Take inspiration from qualitative research methods like codebook development that use multiple human coders to remove subjectivity.  
- Propose a 4-phase methodology involving multiple researchers to systematically construct and validate prompts and criteria for evaluating LLM responses.

Key Details:
- Phase 1: Set up initial LLM pipeline 
- Phase 2: Researchers iteratively develop codebook (criteria) for evaluating LLM responses
- Phase 3: Researchers iteratively develop prompt to meet response criteria 
- Phase 4: Validate overall pipeline with new researchers/data

Main Contributions:
- Outlines problems with using prompt engineering for scientific research
- Provides a systematic, transparent methodology for constructing LLM prompts inspired by qualitative research
- Emphasizes use of multiple researchers and test sets to remove subjectivity 
- Demonstrates methodology by developing a prompt to generate questions for auditing LLMs


## Summarize the paper in one sentence.

 The paper proposes a rigorous multi-phase methodology with human verification to systematically construct prompts for large language models to enable more reliable, objective, and replicable usage of LLMs for analyzing data in research.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a new methodology for systematically and scientifically constructing prompts to be used with large language models (LLMs). The key ideas are:

1) Turning ad-hoc prompt engineering into a more rigorous process of prompt science by introducing multiple phases of response and prompt validation with humans in the loop. 

2) Using a process inspired by qualitative coding and codebook development from social sciences to remove individual biases and subjectivity and enhance transparency and replicability. 

3) Providing a way to not just reliably generate desired LLM responses but also improve collective understanding of the task, evaluation criteria, and data through researcher deliberations.

4) Demonstrating the feasibility of this methodology through a case study of developing prompts to generate different versions of questions for auditing LLMs.

In summary, the paper offers a novel framework to construct LLM prompts more systematically, objectively and scientifically for use in research applications.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the main keywords or key terms associated with it are:

- Large Language Models (LLMs)
- Prompt engineering
- Qualitative coding  
- Verification
- Replicability
- Transparency
- Objectivity
- Scientific rigor
- Human-in-the-loop
- Codebook development

The paper discusses issues with using prompt engineering to get desired outputs from LLMs for research purposes, as this process often lacks transparency, replicability, and objectivity. To address this, the authors propose turning prompt engineering into "prompt science" by using a rigorous multi-phase methodology inspired by qualitative coding and codebook development. Central to this is having humans-in-the-loop to systematically construct and verify prompts to remove subjectivity and ensure reliable, validated outputs that can be trusted for downstream scientific applications.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes a 4-phase process for developing prompts in a rigorous scientific manner. Can you walk through each phase in detail and explain the key goals and outcomes of each one? 

2. A core aspect of the methodology is the involvement of human assessors in an iterative process to evaluate model outputs and refine prompts. Why is the human-in-the-loop critical for ensuring scientific rigor according to the authors?

3. The method draws inspiration from qualitative coding techniques used in social sciences research. What specific qualities and best practices from qualitative coding are integrated into the prompt development process?  

4. One claimed benefit of the methodology is the removal of individual researcher biases and subjectivity. What mechanisms in the design specifically aim to achieve this? How might you further reduce bias?

5. The paper argues this methodology leads to increased costs compared to ad hoc prompt engineering. Do you think the added rigor justifies the increased resource requirements? How might the costs be reduced while preserving scientific standards?  

6. How exactly does the verification of evaluation criteria before focusing on the prompt itself help avoid issues like self-fulfilling prophecies? Explain the logical connection.  

7. The authors claim the methodology provides "a systematic and scientifically verifiable way of producing prompt templates." Unpack what makes it systematic and scientifically verifiable in your view. What standards of scientific rigor are met?

8. One desired outcome is improved generalizability of prompts across contexts. How might the documentation and deliberation process contribute to more generalizable prompts? What else could be done?  

9. The methodology yields both reliable prompt templates and increased researcher understanding. Discuss how heightened understanding contributes to the goals of transparency, rigor and trust in the process.

10. While demonstrated for an auditing application, discuss how this methodology could be adapted to ensure more scientifically rigorous use of LLMs for applications like literature reviews, proposal writing, drug discovery etc. What modifications might be required?
