# [U-ARE-ME: Uncertainty-Aware Rotation Estimation in Manhattan   Environments](https://arxiv.org/abs/2403.15583)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Accurate estimation of camera rotation from monocular image sequences is important for many computer vision applications like visual odometry, image stabilization, and augmented reality. Existing methods have limitations:
- RGB-based methods relying on sparse features/vanishing points are not robust to image noise and degradation. 
- RGB-D methods require depth data.
- Learning-based methods overfit and drift over long sequences.
- SLAM systems need calibrated cameras.

Proposed Solution:
The paper proposes U-ARE-ME, an uncertainty-aware rotation estimation method for Manhattan world scenes from monocular RGB images. It has two key steps:

1. Single-Image Optimization: Leverages recent advances in neural network-based surface normal prediction. Defines an uncertainty-weighted cost function that aligns the predicted normals to Manhattan frame axes. Performs optimization on SO(3) to get the rotation + uncertainty.

2. Multi-Frame Optimization: Uses the single-frame uncertainty to reject outliers and enforce temporal consistency across a window of frames via factor graph optimization. Handles frames with limited Manhattan directions.

Main Contributions:
- Introduces uncertainty modeling in surface normal-based rotation estimation to improve robustness.
- Provides a complete pipeline for globally consistent rotation estimation from monocular videos without needing depth or intrinsics.
- Demonstrates state-of-the-art performance on standard datasets and shows applications like horizon estimation, up-vector prediction and ground segmentation.
- Analysis shows the approach is more robust to image noise and uninsured camera intrinsics than SLAM methods.

In summary, the paper presents a novel formulation and pipeline for robust and accurate camera rotation estimation from monocular videos leveraging recent advances in single-image surface normal predictions.
