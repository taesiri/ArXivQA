# [ConceptMath: A Bilingual Concept-wise Benchmark for Measuring   Mathematical Reasoning of Large Language Models](https://arxiv.org/abs/2402.14660)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing benchmarks for evaluating mathematical reasoning of large language models (LLMs) only measure overall average accuracy. They lack the ability to assess performance on specific math concepts and identify model weaknesses.  
- Mathematical reasoning capabilities are acquired concept-by-concept through a curriculum. A fine-grained evaluation is needed.

Proposed Solution:  
- Introduce ConceptMath, the first bilingual (English and Chinese), concept-wise benchmark to evaluate LLMs' math reasoning abilities.
- Organize over 4000 math word problems hierarchically into 4 concept systems based on mainstream education curriculums. Each system covers around 50 concepts with 20 problems per concept.
- Assess LLMs in zero-shot, chain-of-thought and few-shot settings based on concept-wise accuracies.

Key Findings:
- LLMs exhibit significant variability and weaknesses across concepts, despite high average accuracy on existing benchmarks.
- An efficient fine-tuning method is proposed to enhance LLMs' capabilities on underperforming concepts.
- Concept-wise analysis provides direction for improving mathematical reasoning of LLMs.

Main Contributions:
- First fine-grained, concept-wise benchmark for mathematical reasoning evaluation
- Extensive experiments on 19 LLMs to reveal concept-specific weaknesses  
- Bilingual problems in both English and Chinese
- Efficient fine-tuning strategy to boost capabilities on weak concepts
- ConceptMath drives targeted advancement of LLMs' mathematical reasoning

The paper introduces ConceptMath to enable fine-grained, concept-wise evaluation of LLMs' mathematical reasoning, revealing performance variability across concepts. An efficient fine-tuning strategy is also proposed to boost capabilities on underperforming concepts. ConceptMath provides specific direction for advancing LLMs' math reasoning abilities.
