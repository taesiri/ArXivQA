# [Occ$^2$Net: Robust Image Matching Based on 3D Occupancy Estimation for   Occluded Regions](https://arxiv.org/abs/2308.16160)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to perform robust image matching for occlusion scenarios where parts of the scene are visible in one image but occluded in the other. 

Specifically, the paper proposes a novel occlusion-aware image matching method called Occ^2Net that can match not only visible points between two images, but also between visible points and occluded points. This allows it to establish correspondences even when there is significant occlusion.

The key hypothesis is that by modeling the 3D occupancy of the scene and the occlusion relationships between objects, the network can infer the matching location of points in occluded regions that are not directly visible.

So in summary, the paper focuses on the problem of occlusion in image matching, and hypothesizes that occlusion relations can be modeled via 3D occupancy estimation to enable matching of visible to occluded points.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- It proposes Occ^2Net, a novel occlusion-aware image matching algorithm that uses 3D occupancy to model the occlusion relations between objects and infer the location of matching points in occluded regions. 

- It combines an Occupancy Estimation (OE) module with an Occlusion-Aware (OA) module to enable visible-occluded matching using a coarse-to-fine structure with occupancy estimation.

- It demonstrates state-of-the-art pose estimation accuracy on both the real-world dataset ScanNet and the simulated dataset TartanAir, showing the effectiveness of matching occluded points.

In summary, the key innovation is using 3D occupancy modeling and estimation to achieve robust image matching performance in the presence of occlusions, which is a common challenge in many vision applications like SLAM. By matching occluded points in addition to visible points, the method improves accuracy over previous approaches.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from this paper:

The paper proposes Occ^2Net, a novel image matching method that uses 3D occupancy estimation to model occlusion relations between objects and infer matches in occluded regions to achieve robust pose estimation, outperforming state-of-the-art methods on real and simulated indoor/outdoor datasets.
