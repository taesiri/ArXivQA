# [Deep Geometrized Cartoon Line Inbetweening](https://arxiv.org/abs/2309.16643)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key points of this paper are:

- The paper addresses the problem of inbetweening cartoon line drawings, which involves generating intermediate frames between two input line drawing keyframes. This is an important but understudied problem in 2D animation production.

- Existing frame interpolation methods that work on raster images are not suitable for line inbetweening, as they can introduce artifacts like blurring and loss of detail in the sparse line drawings. 

- The paper proposes a new deep learning framework called AnimeInbet to perform line inbetweening in a geometrized vector format instead of raster images. This preserves the detail and structure of lines better.

- The core of AnimeInbet is to match and fuse vertices between input line drawing graphs and reposition them to synthesize an intermediate graph. This involves modules for vertex embedding, matching, repositioning, and visibility handling.

- To facilitate learning and evaluation, the paper introduces a new dataset MixamoLine240 containing vectorized line drawings with ground truth correspondence labels.

- Experiments show AnimeInbet produces higher quality inbetweening results compared to existing interpolation methods, especially for cases with large motions.

In summary, the central hypothesis is that formulating line inbetweening as a geometrized graph fusion problem and learning vertex-level correspondences can better preserve line details compared to raster-based approaches. The AnimeInbet framework and MixamoLine240 dataset are proposed to demonstrate this.


## What is the main contribution of this paper?

 This paper makes three main contributions:

1. It introduces a new task: inbetweening of cartoon line drawings. This involves generating intermediate frames between two input line drawings, which could help automate and speed up 2D animation production.

2. It proposes a new method called AnimeInbet to address this task. AnimeInbet converts the line drawings into graphs and formulates inbetweening as a graph fusion problem with vertex repositioning. It consists of modules for vertex embedding, matching, repositioning, and visibility prediction.

3. It provides a new dataset called MixamoLine240 to facilitate training and evaluation. This is the first dataset with ground truth vectorization and accurate vertex matching labels for line drawing sequences. It contains 240 sequences with over 47k frames.

In summary, the paper proposes a new challenging task of line inbetweening, a novel deep learning-based method that outperforms existing solutions, and a labeled dataset to support comprehensive training and benchmarking. This could help advance research in automating 2D animation production.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a deep learning framework called AnimeInbet for generating intermediate frames (inbetweening) between two input line drawings by representing them as graphs, matching vertices across graphs, propagating vertex shifts, and predicting vertex visibility, introducing a new line drawing dataset MixamoLine240 for training and evaluation.


## How does this paper compare to other research in the same field?

 Here are a few key points comparing this paper to other related research:

- This paper introduces a new task - inbetweening of cartoon line drawings. Inbetweening is an important part of 2D animation production but has received little attention in AI research so far. Most prior work has focused on frame interpolation for full-color videos. This paper proposes one of the first learning-based methods tailored for line inbetweening.

- The paper frames line inbetweening as a graph fusion problem rather than a raster image interpolation task. It converts line drawings into graphs and matches vertices across frames. This allows better handling of the sparse line drawings compared to pixel-based approaches. 

- To train and evaluate models, the paper introduces a new dataset MixamoLine240. Prior datasets like AnimeInterp only provide raw images without vectorization or correspondence labels. MixamoLine240 has ground truth geometrization and accurate vertex correspondences derived from 3D models.

- For the method, the paper designs a pipeline with four main components: vertex embedding, correspondence transformer, repositioning propagation, and visibility prediction+fusion. This combines ideas like transformer matching, attention propagation, which are often used for establishing correspondences between images/graphs.

- Experiments compare to recent image-based interpolation methods. The proposed AnimeInbet outperforms on both quantitative metrics and subjective comparisons. The gains are especially significant for cases with large motions. Ablations validate the design choices.

In summary, this paper explores a new problem setup for line inbetweening and provides strong baseline solutions, outperforming adaptations of image-based interpolation methods. The graph-based formulation and new dataset are valuable contributions. This could open up future research avenues in this direction.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the future research directions suggested by the authors include:

- Developing more advanced geometrization methods for converting raster line drawings to vector format. The authors note that using a more accurate geometrizer for raster images would enable higher quality inbetweening results.

- Exploring unsupervised or semi-supervised learning approaches. The current method requires ground truth data for training, but unlabeled line drawing data is far more abundant. Developing techniques to leverage unlabeled data could be valuable.

- Extending the approach to color line drawings. The current method focuses on black-and-white line art, but extending it to handle color would increase its applicability.

- Applying the method to video frame interpolation. The current work performs interpolation on just two frames, but extending it to video could be useful for applications like increasing frame rate.

- Developing interactive tools built upon the method. The authors suggest that their method could produce results sufficient for finishing with just minor manual effort. Developing smarter interactive tools could further reduce manual touch-up.

- Exploring the method on other types of sparse drawings beyond anime-style, such as architectural drawings or sketches.

- Improving the robustness and flexibility, for example by handling incomplete or erroneous vectorization input.

In summary, the authors point to several promising directions such as leveraging unlabeled data, extending to color and video, developing interactive tools, and broadening the applicability beyond anime line art. Advances in these areas could help make automated inbetweening even more useful for practical applications.


## Summarize the paper in one paragraph.

 The paper presents a new approach for inbetweening cartoon line drawings, which is the process of generating intermediate frames between two input line drawings. The key ideas are:

1. The authors reformulate line inbetweening as a graph fusion problem, by converting the input line drawings into graphs with vertices and edges. This allows preserving the structure better compared to operating on raster images directly. 

2. They propose a learning framework called AnimeInbet which consists of four main components: (a) a CNN to embed geometric features of each vertex, (b) a Transformer module to establish vertex correspondences, (c) an attention module to propagate vertex shifts, and (d) a visibility predictor to handle occlusions.

3. They introduce a new dataset MixamoLine240 containing ground truth vectorizations and vertex matchings to train models for this task. 

4. Experiments show their method generates cleaner and more complete inbetween frames compared to existing interpolation methods like RIFE and EISAI. The graph-based formulation and learning framework are better suited for line drawings.

In summary, the paper addresses the under-studied problem of automating inbetweening of line drawings by reformulating it as graph fusion and proposing a learning-based solution with a new dataset. This could significantly improve productivity in 2D animation.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper presents a new deep learning framework called AnimeInbet for inbetweening line drawings in anime production. Unlike existing frame interpolation methods that operate on raster images, AnimeInbet treats line drawings as sparse vector graphs and formulates inbetweening as a graph fusion problem. The framework consists of four main components: (1) A CNN-based vertex embedding module that encodes both contextual and geometric information. (2) A Transformer module that matches vertices between the two input line drawings. (3) A repositioning propagation module that shifts unmatched vertices based on an attention mechanism. (4) A visibility predictor that masks occluded lines. The framework is trained end-to-end on MixamoLine240, a new dataset introduced in the paper. It contains 240 sequences of line drawings with ground truth vectorization and vertex correspondence labels derived from 3D models. Experiments demonstrate that AnimeInbet generates significantly cleaner and more complete inbetweens compared to state-of-the-art frame interpolation methods, especially for large motions.

In summary, this paper makes two key contributions - (1) AnimeInbet, a novel deep learning framework for inbetweening line drawings by treating them as geometrized graphs rather than raster images. (2) MixamoLine240, a large-scale dataset to support the learning and evaluation of line drawing inbetweening. The method and dataset could help automate the tedious frame-by-frame drawing process in 2D animation production.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes a graph fusion-based framework called AnimeInbet for inbetweening line drawings of cartoon characters. It takes as input two vectorized line drawings and outputs an intermediate frame represented as a vector graph. The key steps are: 1) Encoding vertex features using a CNN to embed image context, position, and topology information. 2) Matching vertices between the two input graphs using a Transformer architecture with self- and cross-attention blocks. 3) Propagating the shifts of matched vertices to unmatched ones using attention pooling to obtain repositioning vectors. 4) Predicting visibility masks to handle occlusions. 5) Fusing the two graphs based on the predicted correspondence and visibility to generate the intermediate graph. The framework is trained in a supervised manner using a newly introduced dataset MixamoLine240, which provides ground truth data for geometrization, vertex correspondence, and visibility. The method aims to preserve line structure details during inbetweening by operating on vector graphs rather than raster images. Experiments show it outperforms existing frame interpolation methods, especially for large motions.
