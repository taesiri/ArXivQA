# [MMVC: Learned Multi-Mode Video Compression with Block-based Prediction   Mode Selection and Density-Adaptive Entropy Coding](https://arxiv.org/abs/2304.02273)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question/hypothesis appears to be:

How can we develop an efficient video compression method that can adaptively select optimal prediction modes and entropy coding strategies on a block-level basis to improve compression performance across diverse video content? 

The key ideas and contributions seem to be:

- Proposing a multi-mode video compression framework (MMVC) that selects among different prediction modes (convLSTM-based, optical flow-based, feature propagation) at the block level based on which yields the sparsest residual and shortest code length.

- Developing a density-adaptive entropy coding scheme that switches between dense and sparse coding paths for each block based on the residual density, using run-length coding for sparse blocks.

- Introducing a block-wise channel pruning method to remove less important channels from the residuals to improve sparsity without much quality loss.

- Demonstrating competitive or superior RD performance compared to state-of-the-art learned video compression methods and standard codecs like HEVC and VVC.

In essence, the central hypothesis appears to be that adaptively selecting prediction modes and entropy coding strategies tailored to each block's specific content can improve compression efficiency compared to using a single universal approach. The results seem to validate this hypothesis.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing a multi-mode video compression framework (MMVC) that adaptively selects between different prediction modes on a block-level basis to address different motion patterns. The prediction modes include:

- Skip mode for static regions
- Optical flow conditioned feature prediction for regions with smooth motion 
- Feature propagation for changed regions with no better alternative
- Feature prediction with ConvLSTM for generic cases

2. Introducing a block-wise channel removal technique to remove unimportant residual channels and improve compression.

3. Using a density-adaptive entropy coding scheme with optional run-length coding for sparse residual blocks, guided by a binary density map. This provides significant bitrate savings compared to dense entropy coding of all blocks.

4. Demonstrating through experiments that MMVC achieves superior rate-distortion performance compared to prior learned video compression methods and standard video codecs like HEVC and AVC.

In summary, the key ideas are block-level mode selection for motion-adaptive prediction, channel removal and density-adaptive entropy coding for improved compression, and extensive experiments showing state-of-the-art performance. The adaptivity to different motion patterns and efficient handling of residuals are the main strengths of this approach.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a deep learning based video compression method called MMVC that adaptively selects between different inter-frame prediction modes on a per-block basis and uses a density-adaptive entropy coder to further compress the prediction residuals.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this paper compares to other research in the field of learned video compression:

- The key innovation is the multi-mode prediction framework that adapts prediction strategies on a per-block basis. Other methods typically use a single prediction model applied uniformly across the frame. Enabling multiple prediction modes customized for each block's content is a novel idea. 

- The proposed multi-mode prediction allows handling a wide variety of motion types, from static scenes to complex dynamic motions. Many other learned video compression works focus on a certain type of motion, but have limitations generalizing to diverse contents.

- Using block-based processing for mode selection and channel removal is also an impactful contribution. Prior arts apply operations uniformly across the entire frame. The block-based approach allows better adaptation and customization leading to gains in compression efficiency.

- The dual-mode entropy coding conditioned on residual density is another major contribution not explored before. It effectively converts sparser residuals from the multi-mode prediction to substantial bitrate reductions.

- Overall compression performance is competitive or better than recent state-of-the-art learned video codecs like DVC, DCVC, VCT, etc. as well as standard codecs like HEVC and VVC. 

- The ablation studies provide useful insights into when and why each mode is more effective depending on motion characteristics. This analysis helps understand the complementarity of different prediction modes.

In summary, the block-based multi-mode prediction framework combined with the density-adaptive entropy coding provides novel contributions over prior arts. The gains in rate-distortion performance are clearly demonstrated through comparisons and ablation studies. The ideas proposed have strong potential for practical impact in video compression.
