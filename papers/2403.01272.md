# [Can a Confident Prior Replace a Cold Posterior?](https://arxiv.org/abs/2403.01272)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Bayesian neural networks (BNNs) tend to underfit on clean image classification datasets like CIFAR-10 when using standard priors and likelihoods. This results in poor accuracy and overestimated aleatoric uncertainty. 
- A common solution is to use a "cold posterior" which improves fit to the data but deviates from a valid Bayesian posterior. Cold posteriors correspond to likelihoods that are not valid probability distributions over classes.

Proposed Solutions:
1. Introduce a "DirClip" prior, which is a clipped version of the Dirichlet prior. This fixes instability issues with the Dirichlet and allows controlling the BNN's aleatoric uncertainty. DirClip reaches 94% test accuracy on CIFAR-10, almost matching a cold posterior.

2. Introduce a "confidence prior" which directly encodes a preference for high-confidence predictions. As temperature decreases, the confidence prior combined with categorical likelihood provably converges to a cold likelihood. However, the confidence prior has many local optima, making sampling difficult.

Key Insights:
- Cold posteriors can be seen as approximating the confidence prior in the limit of decreasing temperature. So cold posteriors arise from a valid Bayesian model.

- When using the Dirichlet or DirClip prior, the gradient can point away from the true class during optimization. This causes training instability that can be mitigated through proper initialization.

Main Contributions:
- DirClip prior that controls aleatoric uncertainty through the concentration parameter Î±
- Confidence prior that theoretic justifies cold posteriors as approximating high-confidence predictions
- Analysis of when Dirichlet-based priors become unstable during training and how to mitigate this

The paper provides both practical and theoretical justifications for commonly-used techniques in Bayesian deep learning. The proposed DirClip prior could be widely adopted as an alternative to posterior tempering.
