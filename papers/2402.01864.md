# [(A)I Am Not a Lawyer, But...: Engaging Legal Experts towards Responsible   LLM Policies for Legal Advice](https://arxiv.org/abs/2402.01864)

## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1) The paper demonstrates an effective method for translating domain expertise into actionable AI deployment guidance, through case-based expert deliberation workshops. Specifically, by presenting legal professionals with realistic legal query "cases" and sample AI responses, the authors were able to elicit rich considerations around appropriate AI behavior when generating legal advice. 

2) The paper produces a concrete 4-dimension framework spanning 25 key factors that experts consider when evaluating AI responses, covering user attributes/behaviors, query characteristics, AI capabilities, and impacts. This framework provides an analytical foundation for further research into responsible AI assistance in the legal and other professional domains.

3) The paper reveals novel legal and ethical issues overlooked in prior LLM literature, including unauthorized practice of law, confidentiality, liability, and accountability deficits compared to human attorney advice. It argues that responsible AI legal advice requires cross-disciplinary understanding across law, technology, and ethics.

4) While experts disagreed on the appropriate level of AI involvement, the paper shares recommendations around providing factual legal information versus opinions, as well as the potential for multi-turn interactions to help users clarify questions and identify applicable laws. Additional guiding principles are also suggested, like transparency and avoiding harm.

In summary, the main contribution is demonstrating and evaluating a participatory method for translating professional knowledge into an actionable AI policy framework, using the legal domain as an example.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper's content, some of the main keywords and key terms associated with this paper include:

- Large language models (LLMs)
- Legal advice 
- AI ethics
- Unauthorized practice of law (UPL)
- Case-based reasoning  
- Expert deliberation
- Appropriate AI responses
- Information vs opinion
- Confidentiality 
- Accountability
- Impact dimensions
- User dimensions 
- Query dimensions
- AI capability dimensions

The paper discusses using a case-based reasoning approach to convene workshops with legal experts in order to determine appropriate AI responses to legal queries from lay users. It identifies key dimensions experts consider across categories of user attributes/behaviors, query characteristics, AI capabilities, and impacts. The paper also highlights novel legal issues around confidentiality, accountability, and unauthorized practice of law that have been overlooked in existing LLM literature. Overall, it aims to translate professional knowledge into concrete AI policy considerations.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes a case-based reasoning approach to translate professional knowledge into AI policy guidelines. How might this approach generalize to other high-stakes domains beyond law, such as medicine or finance? What adaptations would need to be made?  

2. The paper highlights the benefits of case deliberation for eliciting nuanced considerations from experts. However, are there any potential downsides or limitations to this approach compared to surveys or focus groups? How might those be mitigated?

3. The paper distinguishes between legal "information" and legal "opinion" when determining appropriate AI responses. Is this distinction clear and comprehensive enough to apply in practice? What examples blur this line or reveal gaps?  

4. The 4-dimension framework provides useful scaffolding but remains abstract. What specific mechanisms or processes would be required to translate each dimension into concrete system requirements or design choices?  

5. The paper reveals accountability gaps between attorney standards and AI systems. How might we envision better accountability mechanisms appropriate for AI assistance models in professional domains? What analogies exist?

6. The paper argues AI assistance could aid question refinement through multi-turn interactions. However, where exactly should systems stop probing to avoid eliciting too much personal information or crossing into legal advice? 

7. The guiding principles seem generally agreeable. Do any pose implementation challenges or unintended consequences overlooked by the experts? Are additional principles needed?

8. Case-based reasoning emphasizes highly context-dependent judgments. However, what overarching lessons or more generalizable guidelines does this research reveal about AI ethics/policy beyond the specifics of legal advice?

9. The paper focuses on the US and common law. How might considerations differ under the legal and cultural norms of other nations regarding appropriate AI assistance?  

10. The proposed methods center legal experts, but should client experiences and perceptions be given equal or greater weight in determining policies for public-facing AI systems? What complementary methods could capture user voices?
