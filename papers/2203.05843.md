# An Interpretable Neuro-Symbolic Reasoning Framework for Task-Oriented   Dialogue Generation

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we develop an interpretable knowledge base reasoning framework for task-oriented dialogue systems? The key points are:- Most neural dialogue systems have an implicit reasoning strategy that makes model predictions uninterpretable to humans. - The authors aim to tackle this by introducing a neuro-symbolic framework to perform explicit reasoning via reasoning chains. This makes the reasoning process more transparent and interpretable.- Existing neuro-symbolic approaches face challenges with error propagation when doing multi-hop reasoning on large knowledge bases (KB). - To address this, the authors propose a two-phase "generating and verifying" approach with a hypothesis generator and reasoner module. - Multiple hypotheses are first generated and then verified via reasoning chains constructed from the KB, helping mitigate error propagation.- The framework is trained end-to-end without reasoning chain annotations by using dialogue response supervision. So in summary, the key research question is developing an interpretable KB reasoning framework for task-oriented dialogues by introducing explicit reasoning chains generated and verified in a two-phase approach. This aims to improve interpretability while handling challenges like error propagation.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel neuro-symbolic framework for interpretable knowledge base reasoning in task-oriented dialogue systems. Specifically, the key contributions are:1. Introducing a two-phase "generating-and-verifying" approach that consists of a hypothesis generator and a reasoner. The hypothesis generator proposes multiple hypotheses (potential operations to achieve the task). The reasoner then verifies the hypotheses via explicit reasoning chains to mitigate error propagation.2. The whole framework is trained end-to-end without any reasoning chain annotations by exploiting raw textual dialogues and formulating reasoning chain optimization into hypotheses likelihood maximization. 3. Extensive experiments on two benchmark datasets demonstrate the effectiveness of the proposed model. The generated hypotheses and verification procedures also showcase the interpretability of the framework.In summary, the paper makes a significant contribution towards interpretable and explainable KB reasoning for task-oriented dialogues by developing a novel neuro-symbolic approach. The two-phase generating-and-verifying design combined with the end-to-end learning paradigm helps improve both accuracy and transparency of the reasoning process.
