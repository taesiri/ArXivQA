# ["Help Me Help the AI": Understanding How Explainability Can Support   Human-AI Interaction](https://arxiv.org/abs/2210.03735)

## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution is an empirical study examining end-users' explainability needs, uses, and perceptions around explainable AI (XAI) methods in a real-world context. Specifically, the authors conducted a mixed-methods study with 20 end-users of the Merlin bird identification mobile app to understand their needs, intended uses, and perceptions of different XAI approaches. The key findings and contributions are:- Identifying that end-users desire practically useful XAI information to improve their collaboration and outcomes with the AI system, beyond just technical details about the system.- Finding that end-users intend to use XAI explanations for various purposes like determining trust, improving their own skills, supplying better inputs to the AI, and providing feedback to developers. This highlights a broader range of XAI uses compared to solely understanding the AI's outputs.- Getting direct feedback on representative XAI methods from end-users of a real-world AI application. The feedback revealed end-users prefer explanations that resemble human reasoning, and uncovered a creator-consumer gap in current XAI research.- Providing design recommendations for XAI based on end-users' needs and feedback, emphasizing the importance of participatory approaches that involve end-users in the XAI design process.In summary, the main contribution is an in-depth empirical study focused on end-users' perspectives on XAI explanations in a real-world context. The findings surface insights to guide the design of human-centered XAI methods.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on my reading of the paper, here is a one sentence summary:The paper describes a mixed-methods study of 20 end-users of the Merlin bird identification app, finding that they desire practically useful XAI explanations that can help them collaborate with and provide feedback to improve the AI system, and they prefer part-based explanations resembling human reasoning over other forms like heatmaps.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in human-centered explainable AI (XAI):- The focus on studying end-users' XAI needs, uses, and perceptions in a real-world context is relatively unique. Much XAI research relies on hypothetical scenarios or lab studies with prototype systems. Studying an actively used, deployed system provides valuable ecological validity.- Connecting end-users directly to the XAI methods literature, by presenting mock-ups of different XAI approaches, is an innovative way to elicit concrete feedback. This helps bridge the gap between the technical XAI community and real-world needs.- Looking at individual differences based on users' domain knowledge and AI expertise is an important contribution. Most prior work does not differentiate users. Finding that XAI needs differ based on background highlights the value of a human-centered approach.- Centering the concept of human-AI collaboration, and how XAI can support it, provides a fresh perspective. This moves beyond just explaining outputs to empowering more meaningful interactions.- The focus on an ordinary application (bird identification), rather than a high-stakes medical, legal, etc. context, diversifies the types of AI systems studied. This highlights XAI needs in everyday settings.- The sample size of 20 users is reasonably large for an interview study of this depth. Many similar studies engage fewer participants. However, larger sample sizes would increase generalizability.Overall, the paper makes excellent contributions to human-centered XAI through its real-world setting, focus on end-users, and bridging technical XAI with applications. The insights on XAI needs, uses, and design will meaningfully advance this growing research area. More studies like this in diverse contexts will be highly impactful.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the key future research directions the authors suggest are:- Conducting similar studies on XAI needs, uses, and perceptions in other application contexts beyond Merlin. The authors acknowledge their findings may have limited generalizability since they focus specifically on the Merlin app. They suggest their study design could be applied to study other types of AI applications used in different domains and contexts.- Involving more participants from underrepresented subgroups in the study sample, such as those with low domain or AI background. The authors had relatively few participants in some subgroups, so suggest including more participants from these groups in future work.- Studying needs of different stakeholder groups beyond just end-users, such as developers and deployers of AI systems. The authors note they only studied end-users but other stakeholders may have different XAI needs.- Continuing the research agenda of human-centered XAI and involving end-users directly in the XAI design process. The authors found end-users exposed blindspots in existing XAI approaches, so suggest participatory design approaches to better align XAI methods with end-user needs.- Developing XAI methods that answer "why" questions and provide causal explanations. Several participants were unsatisfied with explanations only describing "what" and wanted more causal "why" explanations. - Using multiple explanation forms/modalities tailored to end-users' needs and the application context. Participants often suggested combining XAI approaches, so the authors suggest expanding the XAI design space.- Rigorously evaluating XAI methods for both their intended goals and potential negative effects. The authors note explanations can sometimes have unintended consequences, so rigorous evaluation throughout development is important.In summary, the authors provide suggestions around studying XAI in new contexts and with new populations, involving end-users directly in XAI design, enhancing current methods to be more causal, multimodal, and tailored, and rigorous evaluation of XAI.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the key points from the paper:The paper presents a mixed-methods study examining end-users' explainability needs, uses, and perceptions around explainable AI (XAI) in the context of the Merlin bird identification mobile app. The authors interviewed 20 Merlin users with diverse domain knowledge about birds and AI expertise to understand their XAI needs (RQ1), intended uses of XAI (RQ2), and feedback on four representative XAI approaches mocked up for Merlin (RQ3). They found users wanted practical information to improve their collaboration with AI rather than technical details, intended to use XAI for purposes beyond understanding AI outputs like improving their own skills, and preferred part-based XAI explanations resembling human reasoning. Based on the findings, the authors provide recommendations for designing human-centered XAI to support users' needs and collaboration with AI systems.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:The paper presents a mixed-methods study examining end-users' explainability needs, uses, and perceptions of explainable AI (XAI) in the context of Merlin, a real-world mobile app that uses AI for bird identification. The study involved interviews with 20 Merlin users with diverse backgrounds in terms of their domain knowledge (birding expertise) and AI knowledge. The interviews explored participants' XAI needs through open-ended questions and a survey, their intended uses of XAI explanations through interactive feedback on mockups, and their perceptions of four representative XAI approaches (heatmap, example, concept, prototype-based). The key findings were: (1) Participants unanimously expressed a need for practically useful information to improve their collaboration with the AI system, rather than just technical details. (2) Participants intended to use XAI explanations not only to understand AI outputs, but also to calibrate their trust in the AI, improve their own skills, supply better inputs to the AI, and provide feedback to developers. (3) Among the XAI approaches, participants preferred concept and prototype-based explanations because of their resemblance to human reasoning and because they provide specific, actionable information. Based on the findings, the authors make recommendations for designing human-centered XAI explanations and improving XAI methods to better serve end-users' needs and support human-AI collaboration.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper:The authors conducted a mixed-methods study with 20 end-users of the Merlin bird identification mobile app to understand their explainable AI (XAI) needs, uses, and perceptions. The study involved hour-long interviews with each participant, which included both open-ended questions and a survey. The survey asked participants which aspects of the AI system they were curious about, adapted from the XAI Question Bank framework. During the interview, participants were also shown mock-ups of four different XAI approaches that could potentially be implemented in Merlin - heatmap, example, concept, and prototype-based explanations. Participants provided feedback on these mock-ups in terms of what they liked/disliked, how they would use them, and how much the explanations helped them understand the AI. The interviews were transcribed and a codebook was iteratively developed to identify themes related to XAI needs, uses, and perceptions. One author then used this codebook to analyze all transcripts. The diverse sample of participants enabled the researchers to identify differences in XAI needs and perceptions based on domain knowledge and AI expertise. Overall, the combination of surveys, mock-ups, and open-ended questions allowed the researchers to gain an in-depth understanding of end-users' perspectives on XAI explanations in a real-world AI application context.


## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research questions that this paper addresses are:1) What are end-users' XAI (explainable AI) needs in real-world AI applications? (RQ1)2) How do end-users intend to use XAI explanations? (RQ2) 3) How are existing XAI approaches perceived by end-users? (RQ3)The authors state these three research questions explicitly in the introduction section:"In this work, we set out to answer three research questions:- RQ1: What are end-users' XAI needs in real-world AI applications? - RQ2: How do end-users intend to use XAI explanations?- RQ3: How are existing XAI approaches perceived by end-users?"The rest of the paper is structured around investigating these three research questions through a mixed-methods study with end-users of a real-world AI application (the Merlin bird identification app).


## What problem or question is the paper addressing?

Based on my reading, the key points of this paper are:- The paper is addressing the lack of understanding around end-users' explainability needs and behaviors when interacting with AI systems that use explainable AI (XAI) methods. - In particular, it focuses on understanding end-users' XAI needs, how they intend to use XAI explanations, and how they perceive different types of XAI approaches.- The paper notes that much XAI research has focused on developing algorithms without fully embracing end-user needs. It argues for a "human-centered" approach to XAI.- To address these gaps, the authors conduct an empirical study with 20 end-users of a real-world AI application - the Merlin bird identification mobile app. - Through interviews and mockups of XAI explanations, the study examines end-users' XAI needs, intended uses, and perceptions. It finds that end-users want XAI to help them collaborate better with the AI system.- Based on the findings, the paper provides recommendations for designing more human-centered XAI systems that serve end-user needs.In summary, the key problem this paper tries to address is the lack of understanding of end-users' explainability needs and interactions with XAI systems in real-world contexts. The paper takes an empirical, human-centered approach to gain insights into this problem.
