# "Help Me Help the AI": Understanding How Explainability Can Support   Human-AI Interaction

## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution is an empirical study examining end-users' explainability needs, uses, and perceptions around explainable AI (XAI) methods in a real-world context. Specifically, the authors conducted a mixed-methods study with 20 end-users of the Merlin bird identification mobile app to understand their needs, intended uses, and perceptions of different XAI approaches. The key findings and contributions are:- Identifying that end-users desire practically useful XAI information to improve their collaboration and outcomes with the AI system, beyond just technical details about the system.- Finding that end-users intend to use XAI explanations for various purposes like determining trust, improving their own skills, supplying better inputs to the AI, and providing feedback to developers. This highlights a broader range of XAI uses compared to solely understanding the AI's outputs.- Getting direct feedback on representative XAI methods from end-users of a real-world AI application. The feedback revealed end-users prefer explanations that resemble human reasoning, and uncovered a creator-consumer gap in current XAI research.- Providing design recommendations for XAI based on end-users' needs and feedback, emphasizing the importance of participatory approaches that involve end-users in the XAI design process.In summary, the main contribution is an in-depth empirical study focused on end-users' perspectives on XAI explanations in a real-world context. The findings surface insights to guide the design of human-centered XAI methods.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on my reading of the paper, here is a one sentence summary:The paper describes a mixed-methods study of 20 end-users of the Merlin bird identification app, finding that they desire practically useful XAI explanations that can help them collaborate with and provide feedback to improve the AI system, and they prefer part-based explanations resembling human reasoning over other forms like heatmaps.
