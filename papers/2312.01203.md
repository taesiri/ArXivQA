# [Harnessing Discrete Representations For Continual Reinforcement Learning](https://arxiv.org/abs/2312.01203)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Reinforcement learning (RL) agents rely heavily on representations of observations to make decisions, yet there is little understanding of the advantages of using discrete (categorical) representations versus continuous ones.

- Prior works have shown success with learned discrete representations in RL, but provide limited analysis and typically compare to end-to-end baselines rather than explicit representation learning methods. 

Methods:
- The paper systematically compares discrete representations from VQ-VAEs to continuous representations from vanilla autoencoders and sparse representations from FTA autoencoders.

- Evaluations are done in world model learning, model-free RL, and continual RL settings using Minigrid environments of varying complexity.

Key Findings:
- Discrete representations enable more accurate world models, especially for modeling rare transitions, with less model capacity. This is attributed to better generalization.

- In model-free RL, discrete and sparse representations yield faster policy learning with less environment samples. This is shown to lead to faster adaptation in continual RL settings.

- The benefits are linked to the one-hot encoding rather than discreteness itself. Quantized discrete latents perform worse than one-hot encoded indices pointing to embeddings.

- There are optimal levels of sparsity, with too little or too much hurting continual RL performance.

Main Contributions:  
- Demonstrates multiple advantages of learned discrete representations in RL - more accurate world models, faster policy learning, quicker adaptation.

- Shows one-hot encoding rather than discreteness leads to the benefits, suggesting sparsity and orthogonality are key factors.

- Identifies and demonstrates usefulness of discrete/sparse representations for continual RL where fast adaptation is critical.
