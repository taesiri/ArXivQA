# [Bidirectionally Deformable Motion Modulation For Video-based Human Pose   Transfer](https://arxiv.org/abs/2307.07754)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research goal is to develop an improved method for video-based human pose transfer. Specifically, the authors aim to address two key challenges in this task:

1) Spatial misalignment of complex structural patterns when transferring poses between a source image and target poses. For example, accurately transferring intricate textures on clothing. 

2) Temporal inconsistency when generating video sequences, especially when conditioned on noisy/inaccurate pose sequences extracted by third-party pose detectors. 

To tackle these issues, the central hypothesis seems to be:

A model incorporating a novel "Deformable Motion Modulation" mechanism and bidirectional propagation can better handle spatial misalignment and temporal inconsistency in video-based human pose transfer.

The Deformable Motion Modulation module uses geometric kernel offsets and adaptive weight modulation to perform feature alignment and style transfer simultaneously. The bidirectional propagation helps strengthen temporal coherence by extracting motion information from both forward and backward passes through the sequence.

So in summary, the key research question is how to improve spatial alignment and temporal consistency in video-based pose transfer. The central hypothesis is that the proposed Deformable Motion Modulation and bidirectional propagation mechanisms can achieve these aims. The experiments then aim to demonstrate the effectiveness of the proposed approach.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- Proposing a novel Deformable Motion Modulation (DMM) module that utilizes geometric kernel offsets with adaptive weight modulation to perform spatio-temporal alignment and style transfer simultaneously. 

- Using bidirectional propagation on coarsely warped images to capture long-range temporal correspondence and handle noisy/discontinuous poses. 

- Achieving state-of-the-art performance on video-based human pose transfer, generating high-fidelity and temporally coherent results on challenging benchmarks.

Specifically, the DMM module aligns features and transfers source image style by modulating offsets and weights based on propagated features and source style codes. The bidirectional propagation expands the receptive field across the sequence to robustly handle noisy poses. Together, DMM and bidirectional propagation enable generating visually appealing and smooth video results despite challenges like complex textures and occlusion. Experiments show the method outperforms prior arts quantitatively and qualitatively.

In summary, the key innovation is the deformable motion modulation approach for feature alignment and style transfer in video pose transfer, enabled by bidirectional propagation over the sequence. This achieves new state-of-the-art in this challenging conditional video generation task.
