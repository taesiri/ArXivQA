# [Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over   Structured Environments](https://arxiv.org/abs/2403.08593)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Large language models (LLMs) have shown promise in reasoning over structured environments like knowledge graphs and tables. However, existing methods either require tedious step-by-step interaction between the LLM and environment, or rely on large amounts of labeled data for fine-tuning, both of which have significant limitations. 

Proposed Solution:
The paper proposes RePEdi, a novel framework where the LLM first generates an entire reasoning path given a question, which is then instantiated on the structured environment. If the instantiation gets stuck at any point, error messages are collected and the LLM is called to edit the reasoning path. This allows the LLM to reason efficiently, with fewer calls compared to step-by-step methods, and faithfully since the path is grounded on the environment.

Key Contributions:
- Introduces a new paradigm for LLM reasoning that fully leverages their intrinsic planning abilities by generating then refining reasoning paths.
- Achieves state-of-the-art results on 5 QA datasets, significantly outperforming existing LLM methods and comparable to fine-tuned models without requiring annotations.  
- Demonstrates high efficiency, with 40-60% of initial paths directly instantiable and only 1.55 editing calls on average. Analysis shows the path generation and editing resemble human-like reasoning.
- Establishes both efficiency and faithfulness in LLM reasoning over structured environments, advancing their applicability for complex real-world scenarios.

In summary, the paper proposes RePEdi as an effective approach for faithful and efficient LLM reasoning over knowledge graphs, tables, and other structured data by generating then refining reasoning paths when needed. The strong empirical results highlight the potential of harnessing LLMs' planning abilities for structured reasoning.


## Summarize the paper in one sentence.

 This paper proposes ReaPathEd, a novel framework where large language models can efficiently and faithfully reason over structured environments by initially generating a reasoning path and then editing it only when necessary during instantiation.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Proposing a novel framework called Reasoning-Path-Editing (READI) where large language models (LLMs) can reason efficiently and faithfully over large-scale structured environments like knowledge graphs and tables. 

2. In READI, LLMs initially generate a reasoning path which is then instantiated on the environments. Path editing is triggered only when necessary, which reduces the number of LLM calls required.

3. Comprehensive experiments across five multi-hop reasoning tasks in knowledge graph QA and table QA demonstrate the effectiveness of READI. It outperforms other LLM-based solutions and is comparable or better than most fine-tuned methods.

4. Detailed analysis highlights the performance of READI's reasoning path generation and editing modules. Experiments show READI requires much fewer LLM calls on average compared to step-by-step interaction paradigms. The reasoning log also reveals READI exhibits characteristics similar to human thought processes.

In summary, the main contribution is proposing the READI framework to enable efficient and faithful reasoning over structured environments by large language models.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and concepts associated with it include:

- Large Language Models (LLMs)
- Reasoning over structured environments 
- Knowledge graphs
- Tables
- Multi-hop reasoning
- Reasoning path generation
- Reasoning path instantiation
- Reasoning path editing
- Efficient reasoning
- Faithful reasoning
- Question Answering over Knowledge Graphs (KGQA)
- Table Question Answering (TableQA)
- Information retrieval 
- Plan-and-refine

The paper proposes a novel framework called Reasoning-Path-Editing (READI) that enables LLMs to efficiently and faithfully reason over structured environments like knowledge graphs and tables. It allows LLMs to initially generate a reasoning path, instantiate it over the environment, and edit the path only when necessary. Experiments on KGQA and TableQA tasks demonstrate the effectiveness of READI in improving reasoning efficiency and accuracy over prior methods.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. How does the proposed method leverage the intrinsic planning ability of large language models (LLMs) for reasoning over structured environments? What are the key components that enable this?

2. The paper claims the proposed method is more efficient than previous step-by-step interaction paradigms. What specifically makes it more efficient and approximately how many fewer LLM calls does it require?

3. How does the reasoning path instantiation process work? Explain relation binding and path connecting. What algorithms or techniques are used?

4. When reasoning path instantiation gets stuck, what key information is collected in the error messages to guide reasoning path editing? Why is this information useful? 

5. How exactly does the reasoning path editing module work? Explain the summarization and preparation steps. What prompts are provided to the LLM?

6. What metrics are used to evaluate the quality of the generated reasoning paths? How do the initial paths compare to state-of-the-art methods?

7. What is the distribution of the number of LLM calls required for reasoning path editing? What does this suggest about the efficiency of the approach?

8. What limitations still exist with the proposed approach? What could be improved in future work?

9. How is the method adapted for table question answering? What changes are made for reasoning path generation and editing?

10. The paper claims "characteristics akin to human thought process" for the reasoning path. Elaborate on what this means and what evidence supports it.
