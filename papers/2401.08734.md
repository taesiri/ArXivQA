# [Bag of Tricks to Boost Adversarial Transferability](https://arxiv.org/abs/2401.08734)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Adversarial examples pose security threats to deep neural networks and have low attack transferability across models. Enhancing adversarial transferability is crucial for evaluating model vulnerabilities in real-world applications. However, existing attacks follow default hyperparameter settings and overlook factors impacting transferability.   

Methods:
The paper first conducts a hyperparameter study on iterative adversarial attacks and shows the impact of hyperparameters like number of iterations, step size, and momentum decay on transferability. Then it proposes a bag of tricks to enhance transferability:

1) Gradient-based attacks: 
- Random global momentum initialization explores neighborhood to capture better initialization.
- Scheduled step size assigns larger step sizes initially for better transferability. 
- Dual example focuses gradients near benign samples for transferability.

2) Input transformation attacks:  
- High frequency transformations augment high frequency components.
- Spectral augmentations apply transformations in frequency domain.

3) Ensemble attacks:
- Gradient alignment orthogonalizes conflicting gradients.  
- Asynchronous input transformation applies different transforms to each model.
- Model shuffle randomly shuffles model order across iterations.

Results: 
Extensive experiments on ImageNet validate the efficacy of tricks like scheduled step size (4.4% improvement), dual example (12.4% improvement), spectral augmentation (5.4% improvement) in boosting transferability of attacks. Combining tricks further enhances performance, achieving 100% attack success on Google Vision API compared to only 23.6% for vanilla attacks.  

Conclusion:
The paper provides useful insights into overlooked factors impacting transferability and proposes a bag of simple yet effective tricks that can be flexibly combined to significantly boost attack transferability in real-world applications.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from this paper:

The paper proposes a comprehensive set of tricks to enhance the transferability of adversarial attacks across models, including techniques like random momentum initialization, scheduled step sizes, dual examples, high-frequency input transformations, and ensemble strategies like gradient alignment and asynchronous transformations.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a comprehensive set of tricks to boost the transferability of adversarial examples across different models. Specifically, the key contributions include:

1) Conducting careful studies on the impact of key hyper-parameters (number of iterations, step size, momentum decay factor) on the transferability of various adversarial attacks. The results reveal that adversarial transferability is much more sensitive to some basic settings than commonly thought. 

2) Proposing several effective tricks to enhance adversarial transferability for different types of attacks:
- Gradient-based attacks: Random global momentum initialization, scheduled step size, dual example 
- Input transformation attacks: High-frequency transformation, spectral-based augmentations
- Ensemble attacks: Gradient alignment, asynchronous input transformation, model shuffle

3) Extensive experiments validate the efficacy of the proposed tricks and show combining them can further improve transferability against defense models and on Google Cloud Vision. For example, integrating all tricks boosts the attack success rate by 19.9% against the certified defense of random smoothing.

4) The proposed bag of tricks offers practical guidance and techniques to enhance adversarial transferability. It also reveals limitations of current defense methods and the necessity of better understanding factors influencing transferability.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Adversarial examples - Examples crafted to fool machine learning models by adding imperceptible perturbations. The paper focuses on improving the transferability of adversarial examples across different models.

- Adversarial transferability - The ability of adversarial examples crafted on one model (surrogate model) to fool other models (victim models). Improving transferability is a key focus of the paper.  

- Gradient-based attacks - Attacks like I-FGSM, MI-FGSM that use gradient information to craft adversarial examples. The paper examines hyperparameters like number of iterations and step size for these attacks.

- Input transformation attacks - Attacks like DIM, SIM, Admix that transform inputs before computing gradients. The paper proposes spectral transformations.  

- Ensemble attacks - Attacks that use multiple models either in parallel or sequence. The paper analyzes different ensemble strategies.

- Defense methods - Methods like adversarial training, denoising, random smoothing etc. to make models more robust. The paper evaluates attack performance against defenses.  

- Tricks - Simple but effective techniques proposed like random momentum initialization, scheduled step size, dual examples etc. to boost attack transferability.

In summary, the key focus is on improving adversarial transferability across models using gradient-based attacks, input transformations, ensemble strategies and other tricks. Defense methods are used for evaluation.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the methods proposed in this paper:

1. The paper proposes several tricks to enhance adversarial transferability, including momentum initialization, scheduled step size, dual example, input transformations, and ensemble strategies. How do you think each trick contributes to improving transferability? What is the underlying intuition behind them?

2. For momentum initialization, the paper argues that proper initialization requires exploring the entire neighborhood around the input. How does the proposed random global momentum initialization technique achieve this goal? What are the tradeoffs between computational overhead and performance gains? 

3. The dual example method aims to balance using gradients near the benign sample and efficient updates later on. How does the proposed technique strike this balance? What is the effect of using an ensemble of dual examples?

4. What is the motivation behind using a scheduled step size? How do the different decay rates for the proposed sequences impact the importance assigned to each iteration's gradient?

5. For input transformations, the paper argues for a focus on high-frequency components. What is the intuition behind this? How does the proposed SSA+ method build upon this idea to further improve performance?

6. The paper categorizes ensemble strategies into lateral and longitudinal ones. What are the differences? Why does the longitudinal strategy outperform lateral ones?

7. What causes gradient conflicts in ensemble attacks? How does the proposed gradient alignment technique detect and mitigate such conflicts? What effect does it have?

8. Asynchronous input transformations are used to increase diversity for ensemble attacks. How does this build upon existing input transformation strategies? What transformations can be used?

9. Model shuffle is proposed to reduce bias towards specific models in longitudinal ensemble attacks. How does shuffling model order achieve this? What are the expected benefits?

10. The paper combines multiple tricks into an ensemble framework and evaluates defense methods. What performance gains are achieved over baselines without tricks? How do the tricks complement each other?
