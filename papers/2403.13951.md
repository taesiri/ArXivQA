# [ACDG-VTON: Accurate and Contained Diffusion Generation for Virtual   Try-On](https://arxiv.org/abs/2403.13951)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Virtual try-on (VTON) aims to generate realistic images of a person wearing desired clothes. Diffusion models can generate high-quality VTON images but often alter or hallucinate details of clothes like logos, textures, prints etc, reducing accuracy. 
- Most diffusion methods use a variational autoencoder (VAE) for efficiency which can distort image details because of the limited size of the VAE dictionary.

Proposed Solution:
- Propose a warp-then-diffuse pipeline called ACDG-VTON that accurately preserves clothes details and allows features like layering multiple clothes, styling options, and shoe try-on.

- Key idea is to carefully choose the control images used during diffusion model training to limit the scope for hallucination, improving accuracy. Rather than using warped clothes images as control, craft a simulated incomplete image where clothes features are precisely aligned with target image.

- The simulated image removes details like shadows, wrinkles etc from ground truth image to mimic a warped clothes distribution while aligning essential features. This prevents the diffusion model from learning to hallucinate during training.

- At inference, warp clothes onto person image to create an incomplete image for diffusion. Use this image as control and starting point for diffusion to generate final output.

- Can generate high-res zoomed regions without training on higher resolutions by cropping and upsampling regions from incomplete image before diffusion. Helps overcome VAE limitations.


Main Contributions:

- Identify issues with standard diffusion training leading to inaccuracy - tendency to hallucinate details and eliminating high-freq details due to VAE limitations

- Propose simulated incomplete image training scheme with precise alignment to ground truth image, preventing hallucination

- Show method faithfully preserves clothes details like logos, prints, textures better than previous diffusion VTON techniques  

- Enable high-quality zoom generations to overcome VAE distortions without higher-res training

- Provide controllable pipeline allowing multi-clothes layering, styling options, shoe try-on in single diffusion inference pass
