# [OST: Refining Text Knowledge with Optimal Spatio-Temporal Descriptor for   General Video Recognition](https://arxiv.org/abs/2312.00096)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Current methods for adapting image-text models (e.g. CLIP) to video rely on adding temporal modeling components but do not address the semantic discrepancy between the descriptive narratives seen during image-text pretraining and the more concise category names used to label video datasets. This results in a less separable latent space that can hinder video recognition performance.

Proposed Solution: 
The authors propose a new method called Optimal Spatio-Temporal Descriptor (OST) that has two main components:

1) Spatio-Temporal Descriptors: Prompt a large language model to generate detailed textual descriptors that disentangle a category name into a spatial descriptor capturing static visual elements, and a temporal descriptor detailing the step-by-step evolution of the action over time. This enhances the semantic distinction compared to just using the category names.

2) Optimal Descriptor Solver: Formulate the video recognition problem as an optimal transport problem to obtain the best matching between frame-level visual features and the descriptor embeddings on a per-video basis. This addresses variability in relevance of descriptors across videos of the same class.

Main Contributions:
- Provide new insight on semantic discrepancy limiting performance when adapting image-text models to video
- Propose Spatio-Temporal descriptors to enhance semantic distinction and provide external knowledge 
- Introduce Optimal Descriptor Solver to adaptively assign optimal descriptors to each video via optimal transport
- Achieve new state-of-the-art results on multiple datasets for zero-shot, few-shot and fully supervised video recognition

In summary, the key innovation is enhancing video recognition by prioritizing refinement of the textual representations via descriptive narratives tailored on a per-video basis, rather than solely addressing visual discrepancies.
