# [Navigating the Post-API Dilemma Search Engine Results Pages Present a   Biased View of Social Media Data](https://arxiv.org/abs/2401.15479)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Recent decisions by Twitter/X and Reddit to discontinue free API access is severely limiting internet research and the field of computational social science. This is called the "Post-API Dilemma". 
- One potential solution is to use search engine result pages (SERPs) to gather indirect social media data. However, it's unclear if SERP provides an unbiased and complete sample of social media data.

Research Questions:
- Does SERP provide a complete and unbiased sample of social media data? 
- Is SERP a viable alternative to direct API access for researchers?

Methodology:
- Compared SERP results from Google for Reddit posts and COVID-19 related tweets to near-complete baseline datasets from Reddit and Twitter/X.
- Analyzed differences along 4 dimensions: popularity, token usage, sentiment, and topical coverage.

Key Findings:
- SERP results skewed towards more popular Twitter/X users and higher scoring Reddit posts.
- Token analysis showed substantive differences - SERP filters out political, pornographic, vulgar content. 
- Sentiment analysis revealed SERP results are more positive than baseline social media data.
- Topical analysis exposed gaps in coverage - lacks spam, political posts, pornography.

Conclusions:
- SERP introduces significant biases and is not a viable replacement for direct API access.
- Future research using only SERP data risks making unsupported conclusions.
- Provides guidance for carefully using SERP data in special cases like search engine analysis.

In summary, the paper conducts a rigorous comparative analysis to demonstrate that search engine result pages are highly biased and incomplete representations of underlying social media data. The authors recommend against using SERP as an alternative data source in most research applications.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper investigates whether search engine result pages provide an unbiased view of social media data to replace discontinued API access and finds that SERP results are highly biased towards more popular, less political, less vulgar, more positive posts, with significant topical gaps compared to the underlying social media data.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is:

The paper performs a comparative analysis between social media data obtained from search engine result pages (SERPs) and more complete, non-sampled social media data from Reddit and Twitter. The goal is to determine if SERPs provide an unbiased sample of social media data that could serve as a replacement for direct API access to platforms like Reddit and Twitter. 

Through popularity, token-level, sentiment, and topical analyses, the paper finds that SERP data is highly biased compared to the non-sampled data. SERP results favor more popular posts, lack certain types of content like political and vulgar posts, have more positive sentiment, and have gaps in topical coverage. 

The main conclusion is that SERP data is not a viable alternative or replacement for direct API access to social media platforms. The biases identified mean that research relying solely on SERP data would not have an unbiased sample of the underlying social media discourse.

In summary, the key contribution is demonstrating and characterizing biases in SERP social media data through comparison to more complete baseline datasets. This better informs future research about the limitations of using SERP data instead of direct platform access.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it are:

- Post-API dilemma
- Search engine results pages (SERP)
- API access
- Bias analysis
- Sample bias
- Popularity analysis
- Token-level analysis
- Sentiment analysis  
- Topic analysis
- Rank turbulence divergence (RTD)
- UMAP projections
- Topical gaps
- Threats to validity

The paper examines whether search engine results pages (SERP) can serve as an unbiased alternative source of social media data now that platforms like Twitter/X and Reddit have restricted API access. It conducts a comparative analysis between SERP results and non-sampled social media data along dimensions like popularity, text content, sentiment, and topics. Some key terms and techniques used in this analysis include rank turbulence divergence, UMAP projections to visualize topical gaps, sentiment analysis tools, and measures to assess threats to validity of using SERP as a data source. The paper concludes that SERP introduces significant biases and is likely not a viable replacement for direct API access.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper compares SERP results to "nonsampled" social media data from Reddit and Twitter. What are some potential issues with assuming the nonsampled data represents ground truth? Could there be biases or gaps in coverage?

2. The paper uses a COVID-19 Twitter dataset collected using specific hashtags. In what ways could this impact the generalizability of the Twitter/SERP comparison results? Would results likely differ for other topics?

3. For the Reddit popularity analysis, what other metrics besides score could have been used to assess popularity? How might choices in popularity metrics impact findings of popularity bias in SERP? 

4. The paper computes Rank Turbulence Divergence (RTD) between keywords in the SERP results and nonsampled data. How robust is this measure to changes in the sampling distribution used to select keywords? Could the choice of sampling scheme substantially alter findings?

5. Could the topical gaps observed between SERP results and nonsampled data be partially explained by randomness in search engine crawling rather than intentional bias? How might the authors strengthen the case that gaps represent bias?

6. The sentiment analysis relies on a model fine-tuned on Twitter data. What issues could arise from directly applying this model to Reddit data? How could the authors validate performance?

7. The paper hypothesizes that stricter content moderation could explain observed gaps for COVID-related Twitter data. How might the authors directly test whether moderation explains gaps rather than search engine bias? 

8. How consistent are the observed biases and gaps likely to be across search engines besides Google? What experiments could explore consistency across engines?

9. The paper analyzes snapshots of data from specific time periods. How might temporal effects impact the generalizability of the findings over longer time scales?  

10. The cost analysis computes the expense of recreating the nonsampled datasets via APIs. What other factors beyond financial cost should influence researchers weighing scrape vs API data collection?
