# [SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context   Misinformation Detection](https://arxiv.org/abs/2403.03170)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Out-of-context (OOC) misinformation is a prevalent issue where authentic images are reused with false or misleading text to deceive audiences. Detecting such misinformation is challenging as the images are real while the deception stems from the contextual manipulation.  
- Existing methods focus on image-text consistency but lack convincing explanations for their judgments. Multimodal large language models (MLLMs) have potential for this task but may fail to follow instructions, misunderstand user intent, and hallucinate due to differences from their training data.

Proposed Solution:
- The paper proposes Sniffer, an MLLM specifically engineered for OOC misinformation detection and explanation through two-stage instruction tuning.  
- Stage 1 tunes the model to align concepts between images and fine-grained news entities. 
- Stage 2 leverages GPT-4 generated instruction data covering judgments and explanations to adapt the model to the OOC task.  
- Sniffer conducts internal checking for image-text consistency and external checking between text and retrieved evidence, integrated through the LLM module for a unified output.

Main Contributions:
- A data reformation pipeline to convert OOC samples into judgment and explanation instruction format using GPT-4 
- A practical tuning approach to adapt general MLLMs to the OOC detection task  
- Sniffer architecture conducting both internal and external verification for comprehensive reasoning 
- Extensive experiments showing Sniffer exceeds SOTA methods in both detection accuracy and explainability

In summary, the paper addresses key limitations of existing works through an innovatively engineered MLLM solution that sets the new state-of-the-art for out-of-context misinformation detection and explanation.
