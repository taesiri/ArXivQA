# [DialogGen: Multi-modal Interactive Dialogue System for Multi-turn   Text-to-Image Generation](https://arxiv.org/abs/2403.08857)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Text-to-image (T2I) models have advanced significantly, but interacting with them is difficult for average users due to the need for prompt engineering expertise and inability to perform multi-turn image generation. 
- Recent works have combined multi-modal large language models (MLLMs) with T2I models to bring natural language instructions into reality. However, identifying correct output modalities and generating coherent images across turns remains challenging as conversations become more complex.

Proposed Solution: 
- The authors propose DialogGen, an effective pipeline to align off-the-shelf MLLMs and T2I models to build a multi-modal interactive dialogue system (MIDS) for multi-turn text-to-image generation.

Key Components of DialogGen:
- Drawing Prompt Alignment: Retrain T2I model using re-captioned images from MLLM to align distributions.  
- Training Data Curation: Add object consistency guarantee, carefully curate instruction tuning data, and use bilingual training data.
- Error Correction: Learn from mistakes by having stronger teacher LLM provide corrections.

Proposed Benchmark (DialogBen):
- Comprehensive bilingual benchmark with 9957 three-turn conversations covering 7 editing types and 13 topics.
- Assesses modality switching accuracy and generation coherence using VQA.

Main Contributions:   
- Propose DialogGen pipeline to effectively combine MLLMs and T2I for multi-turn text-to-image generation.
- Introduce DialogBen benchmark to evaluate emerging multi-modal dialogue systems.
- Achieve state-of-the-art performance on DialogBen over other models.
