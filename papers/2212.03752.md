# [GLeaD: Improving GANs with A Generator-Leading Task](https://arxiv.org/abs/2212.03752)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we improve GAN training by establishing a fairer competition between the generator and discriminator? 

The key hypothesis is that assigning the discriminator an additional "generator-leading" task, where it must reconstruct images using features that align with the generator's view, will force the discriminator to learn more useful representations instead of freely discriminating. This in turn will alleviate the unfairness between the generator and discriminator in standard GAN training.

In summary, the paper proposes a new adversarial training paradigm that gives the generator more influence over the discriminator by having it assign an image reconstruction task. This is hypothesized to make GAN training more equitable and improve synthesis performance.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a new adversarial training paradigm for GANs called GLeaD (Generator-Leading Discriminator). The key ideas are:

- Assigning the discriminator (D) an additional task of reconstructing the input images (both real and fake) using features extracted by D and a frozen generator (G). 

- This forces D to extract more representative features aligned with G's view, instead of learning freely for domain classification. 

- As a result, the unfairness between G and D is reduced, leading to improved GAN training and better synthesis quality.

In summary, the core novelty is introducing a generator-leading task for the discriminator, which helps establish a fairer game between G and D. Extensive experiments demonstrate the effectiveness of GLeaD in improving GAN performance across multiple datasets. The new adversarial training paradigm provides a promising direction for better balancing G and D.
