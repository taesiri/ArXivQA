# [Expediting In-Network Federated Learning by Voting-Based Consensus Model   Compression](https://arxiv.org/abs/2402.03815)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Federated learning (FL) trains machine learning models across decentralized clients without accessing raw private data. This helps preserve data privacy.
- To accelerate FL, recent works explore deploying programmable switches (PS) to conduct in-network aggregation of model updates from clients. This is much faster than using a server.  
- However, PSes have very limited memory, e.g. 1 MB, which restricts the efficiency of in-network FL aggregation algorithms like FedAvg. With 1 MB memory, a PS can only process 2.5x10^5 integer numbers per aggregation. This is insufficient for large models.

Proposed Solution: 
- The paper proposes FediAC, a two-phase algorithm for efficient in-network FL aggregation under limited PS memory.
- Phase 1 - Client Voting: Each client uploads a bit array to PS, with 1/0 indicating significant/insignificant local model updates based on magnitudes. PS aggregates bit arrays to deduce consensus global significant updates.
- Phase 2 - Model Uploading/Aggregation: Clients upload quantized values of only the significant updates from Phase 1. PS aggregates them.

Main Contributions:
- FediAC identifies globally significant model updates through lightweight client voting in Phase 1. This allows efficient aggregation in Phase 2.
- FediAC consumes much less memory and communication traffic than prior arts. 
- Theoretically proves convergence of FediAC and provides guidance on tuning compression rate.
- Extensive experiments on CIFAR and FEMNIST datasets show FediAC improves model accuracy by 1.15-7.71% or reduces communication traffic by 41-70% over state-of-the-art solutions.

In summary, FediAC achieves communication-efficient in-network FL aggregation under stringent PS memory constraints via a two-phase significance voting and model aggregation design.
