# [Bayesian Active Learning for Censored Regression](https://arxiv.org/abs/2402.11973)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Bayesian active learning aims to actively select the most useful data points to acquire labels for and improve the model's predictive performance. However, existing Bayesian active learning methods like BALD fail for censored regression problems, where the response/target variables are only partially observed.
- Specifically in censored regression, we observe clipped/censored values of the true response variable instead of the actual values. Since censored observations do not contain full information about the true values, it is challenging to determine how much information acquiring their labels would provide for improving the model.

Proposed Solution:
- Derive the entropy and mutual information equations for censored distributions to quantify the amount of information in censored observations. This accounts for the fact that censored observations contain less information than uncensored ones.

- Propose a novel C-BALD acquisition function for active learning in censored regression, based on the mutual information between model parameters and censored observations. This measures the expected information gain from acquiring censored observations.

- Since C-BALD relies on the unknown censorship status and thresholds of new unlabeled data points, explicitly model these variables to estimate C-BALD on new data points.

Main Contributions:

1. Formulation and derivation of entropy and mutual information for censored distributions, to quantify information in censored observations.

2. A C-BALD acquisition function for Bayesian active learning tailored to censored regression problems, using the derived information theoretic quantities. 

3. A modeling approach to estimate the censorship probabilities and thresholds for new unlabeled data points, in order to estimate C-BALD values for active learning of censored data.

4. Empirical evaluation showing C-BALD outperforms BALD and other baselines on both synthetic and multiple real-world censored regression datasets.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper derives a Bayesian active learning acquisition function for censored regression that accounts for the varying informative value of censored versus uncensored observations by modelling the censorship distribution and censoring thresholds.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Formulation and derivation of the mutual information between observations and model parameters when the observations are subject to censoring. 

2. A novel acquisition function for active learning using the derived mutual information and the entropy of censored distributions, as well as a novel modelling approach to estimate the entropy.

3. Evaluation of the proposed acquisition function (called C-BALD) on synthetic and real-world datasets compared to other Bayesian active learning methods, demonstrating that C-BALD outperforms them in censored regression problems.

In summary, the main contribution is the proposal of a new acquisition function called C-BALD that extends Bayesian active learning to handle censored regression problems by properly accounting for censorship when estimating the mutual information. This allows more effective active learning in problems where the targets are subject to censoring.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts include:

- Censored regression - The paper focuses on regression problems where the target variable is subject to censoring, meaning only clipped/partial values are observed.

- Bayesian active learning - The paper studies how to actively select the most useful data points to label in the context of Bayesian models and censored regression problems.

- BALD (Bayesian Active Learning by Disagreement) - A popular acquisition function for active learning that measures the mutual information between model parameters and potential labels. The paper extends this to the censored case.

- Mutual information - A key concept for quantifying the expected information gain from acquiring a new labelled data point. The paper derives formulations of mutual information for censored data.

- Entropy - The paper derives entropy calculations for censored distributions, which feed into the mutual information computations.

- Acquisition functions - Functions used in active learning to score and select the most useful data points to acquire labels for. The paper proposes a novel acquisition function called C-BALD.

- Tobit model - A standard model for censored regression that assumes the latent uncensored values follow a Gaussian distribution.

So in summary, the key focus is on Bayesian active learning and information-theoretic acquisition functions for censored regression problems.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a novel modeling approach to estimate the $\mathcal{C}$-BALD objective by explicitly modeling the censoring indicator $\ell_i$ and the censoring threshold $z_i$. What is the intuition behind modeling these variables to compute the mutual information for censored data? What assumptions need to hold for this approach to be valid?

2. Why can't we directly apply the standard BALD acquisition function for uncensored data to the censored regression setting? What specifically breaks down when trying to estimate BALD with censored observations? 

3. The paper derives the entropy and mutual information equations for censored data distributions. Walk through the key steps in these derivations. What is the interpretation of the final entropy equation proposed? 

4. What are the limitations of only modeling the observed $y_i$ distribution compared to jointly modeling the true $y_i^*$ and observed $y_i$ distributions? What extra information does modeling $y_i^*$ provide?

5. The proposed method uses Gaussian distributions for $y_i^*$ and $y_i$. What is the resulting model if these assumptions hold? How does this compare to other standard censored regression models?

6. Walk through how the $\mathcal{C}$-BALD acquisition function is estimated in practice using the proposed modeling approach. What are the outputs of the Bayesian neural network? 

7. The method is evaluated on synthetic and real-world censored datasets. What metrics are used to quantify the performance of the acquisition function? Why are these suitable for this setting?

8. How sensitive is the performance of the proposed acquisition function to choices like model architecture and uncertainty quantification method? What experiments shed light on this?

9. The method outperforms baselines like BALD and random acquisitions. What is the key reason it is better suited to the censored setting? How does explicitly accounting for censorship help guide acquisitions?

10. What are some promising directions for future work building on this method? For example, what other censoring schemes or models could this approach be extended to?
