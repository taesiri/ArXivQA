# [Physics-based Motion Retargeting from Sparse Inputs](https://arxiv.org/abs/2307.01938)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we retarget motions from sparse human sensor data to characters of different morphologies in real-time? Specifically, the paper aims to address two key challenges:1. AR/VR systems only provide sparse sensory data about the user's pose from a headset and controllers, lacking lower body information. 2. The target avatar may have a very different skeleton structure and proportions compared to a human. The central hypothesis is that physics-based simulation and deep reinforcement learning can be used to learn control policies that can retarget motions from sparse human input to characters of various morphologies in real-time. The policies can take the sparse data and generate full-body poses and physically valid motions for non-human characters, while respecting differences in proportions and physical properties.The key innovations are:- Using asymmetric actor-critic observations to provide more state information during training while still relying only on sparse data at test time.- A flexible reward function that allows tuning the degree of imitation versus physical realism.- Demonstrating real-time retargeting from real sparse data to physically simulated characters.So in summary, the main research question is how to perform real-time motion retargeting from sparse human input to non-human characters using physics-based simulation and deep reinforcement learning. The central hypothesis is that this approach can overcome the challenges of sparse input data and differing morphologies.


## What is the main contribution of this paper?

The main contribution of this paper is developing a method for real-time motion retargeting from sparse human sensor data to control physics-simulated characters of different morphologies. Specifically, the key contributions are:- Proposing an imitation-based reinforcement learning approach to learn policies that can drive physics-simulated characters while tracking sparse real-time user input from AR/VR devices.- Introducing a flexible reward formulation that allows controlling the degree of imitation versus reliance on physics, enabling retargeting between differently shaped characters.- Demonstrating results on three characters: a mouse, dinosaur, and human, using sparse headset and controller inputs. The method generates high-quality and physical motions.- Performing ablations to validate the design choices, including the impact of the reward terms, observation asymmetry, and amount of training data.- Showing the capability to track real motions from unseen users and from only headset input, which is an extremely challenging one-point tracking problem.In summary, the key contribution is enabling real-time retargeting from sparse user input to characters of varying morphologies through a physics-based reinforcement learning approach. The method removes the need for target-specific motion data.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a method to retarget motion from sparse human sensor data to simulated characters of different morphologies in real-time using reinforcement learning to train policies that control the characters in a physics simulator, enabling avatar control and self-expression in VR/AR while respecting physical constraints.


## How does this paper compare to other research in the same field?

This paper presents a novel method for motion retargeting from sparse user inputs to non-human characters using physics-based simulation and reinforcement learning. Here are some key comparisons to other work in this field:- Most prior work on motion retargeting focuses on kinematic methods to map motions between humanoids or characters with similar morphology. This paper tackles the more challenging problem of retargeting to very different character morphologies by using physics-based simulation.- Other physics-based character animation methods focus on tracking reference motions, but don't address the problem of retargeting from live sparse user input. This paper shows results driven by real headset and controller data.- Unlike some prior physics-based retargeting work that requires artist-generated reference animations for each new character, this method only relies on easy-to-obtain human mocap data and simple kinematic retargeting to provide training signal.- Compared to the concurrent QuestSim work, this method demonstrates retargeting to non-human characters and enables real-time control, whereas QuestSim targets human avatars and is not real-time.- The Neural3Points method also uses RL to drive characters from sparse input, but requires a full-body pose predictor and is user-specific. This method is more direct and generalizable.- The technique of using asymmetric actor-critic observations is novel in this domain and shown to be critical for learning from sparse inputs.Overall, this paper pushes the boundaries of physics-based retargeting to very different morphologies from live sparse input data. The main limitations are the reliance on bipedal morphology and challenges with highly dynamic motions. But within its scope, it demonstrates an important advancement for immersive character control.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the key future research directions suggested by the authors include:- Developing methods to handle more challenging motion sequences with fast and dynamic movements or uncorrelated upper/lower body motions. The authors note their physics-based controller can sometimes fail on such complex motions, while a kinematic controller may be able to better handle teleporting between poses. They suggest a hybrid approach could help combine the benefits of both methods.- Increasing the complexity of characters handled beyond just bipedal characters. The authors mention providing the policy with skeleton information, using graph neural networks, or training an auxiliary network to find mappings between different skeletons as ways to potentially control more complex characters. - Improving the quality of retargeting by supplying additional information to the policy beyond just the sparse headset and controller data, such as information about the user's environment captured through sensors.- Exploring other forms of stylization and control over the motion by modifying the reward function or training multiple policies to represent different styles that could be smoothly blended.- Developing more advanced methods for handling situations where multiple characters need to coordinate and interact, rather than just focusing on a single isolated character.- Testing the approach on a greater diversity of motions and characters to better understand the limitations and how well it generalizes.In summary, the main suggestions are around enhancing the complexity of motions and characters handled, providing more control over style and coordination, and improving the quality and robustness of the method through hybrid techniques and additional sensory information.
