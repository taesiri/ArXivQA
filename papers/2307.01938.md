# [Physics-based Motion Retargeting from Sparse Inputs](https://arxiv.org/abs/2307.01938)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we retarget motions from sparse human sensor data to characters of different morphologies in real-time? Specifically, the paper aims to address two key challenges:1. AR/VR systems only provide sparse sensory data about the user's pose from a headset and controllers, lacking lower body information. 2. The target avatar may have a very different skeleton structure and proportions compared to a human. The central hypothesis is that physics-based simulation and deep reinforcement learning can be used to learn control policies that can retarget motions from sparse human input to characters of various morphologies in real-time. The policies can take the sparse data and generate full-body poses and physically valid motions for non-human characters, while respecting differences in proportions and physical properties.The key innovations are:- Using asymmetric actor-critic observations to provide more state information during training while still relying only on sparse data at test time.- A flexible reward function that allows tuning the degree of imitation versus physical realism.- Demonstrating real-time retargeting from real sparse data to physically simulated characters.So in summary, the main research question is how to perform real-time motion retargeting from sparse human input to non-human characters using physics-based simulation and deep reinforcement learning. The central hypothesis is that this approach can overcome the challenges of sparse input data and differing morphologies.


## What is the main contribution of this paper?

The main contribution of this paper is developing a method for real-time motion retargeting from sparse human sensor data to control physics-simulated characters of different morphologies. Specifically, the key contributions are:- Proposing an imitation-based reinforcement learning approach to learn policies that can drive physics-simulated characters while tracking sparse real-time user input from AR/VR devices.- Introducing a flexible reward formulation that allows controlling the degree of imitation versus reliance on physics, enabling retargeting between differently shaped characters.- Demonstrating results on three characters: a mouse, dinosaur, and human, using sparse headset and controller inputs. The method generates high-quality and physical motions.- Performing ablations to validate the design choices, including the impact of the reward terms, observation asymmetry, and amount of training data.- Showing the capability to track real motions from unseen users and from only headset input, which is an extremely challenging one-point tracking problem.In summary, the key contribution is enabling real-time retargeting from sparse user input to characters of varying morphologies through a physics-based reinforcement learning approach. The method removes the need for target-specific motion data.
