# [Decoupling Meta-Reinforcement Learning with Gaussian Task Contexts and   Skills](https://arxiv.org/abs/2312.06518)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel framework called Decoupled Meta-Reinforcement Learning (DCMRL) for adapting to unseen target tasks more effectively in the meta-testing phase by acquiring more generalizable prior experience from meta-training tasks. Specifically, DCMRL utilizes both task contexts and skills as prior experience and represents them as Gaussian distributions. It applies a proposed Gaussian Quantization Variational Autoencoder (GQ-VAE) module to cluster the Gaussian distributions of task contexts and skills into representative discrete codes stored in codebooks, thereby decoupling exploration and learning. Furthermore, it contrastively restricts task contexts to distinguish tasks and handles similarity within tasks. Experiments in long-horizon, sparse-reward continuous control environments for navigation and manipulation demonstrate that DCMRL outperforms previous meta-RL methods by achieving faster adaptation, higher sample efficiency, and better final performance on unseen target tasks. The key innovations are the GQ-VAE for decoupled exploration and learning and the contrastive restriction of task contexts.
