# [Talking Head Generation with Probabilistic Audio-to-Visual Diffusion   Priors](https://arxiv.org/abs/2212.04248)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research questions and hypotheses addressed in this paper are:1. How can we holistically infer all non-lip related facial attributes (e.g. pose, expression, blink, gaze) from audio input only, while maintaining accurate lip synchronization? The authors hypothesize that this can be achieved through two key steps:(a) Learning disentangled lip and non-lip representations from pre-trained facial motion encodings. (b) Modeling the mapping from audio to non-lip representations using a novel audio-to-visual diffusion prior.2. Can a diffusion prior effectively model the one-to-many mapping from audio to reasonable non-lip facial motions?The authors hypothesize that a diffusion prior can capture the intrinsic uncertainty and diversity in mapping from audio to facial motions, allowing sampling of varied but realistic non-lip motions given the same audio input.3. Can their proposed framework produce natural looking and diverse facial motions from audio alone, without requiring additional pose/expression videos as input?The authors hypothesize that by combining lip/non-lip disentanglement and the audio-to-visual diffusion prior, their framework can generate plausible talking heads with accurate lip sync, natural head movements and facial expressions using only a reference image and audio clip.4. How can the quality of synthesized talking heads be effectively evaluated, especially the naturalness and richness of non-lip facial motions? The authors propose new quantitative metrics like FID scores on pose/expression features and sequence naturalness distance to measure the realism and diversity of generated motions.In summary, the core research questions address how to perform audio-only driven talking head generation through disentangled representation learning and probabilistic modeling of audio-to-visual mappings using diffusion priors. The hypotheses focus on the capabilities of this framework to produce synchronized, diverse and natural talking heads.
