# [Building a Winning Team: Selecting Source Model Ensembles using a   Submodular Transferability Estimation Approach](https://arxiv.org/abs/2309.02429)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question it addresses is: How can we effectively estimate the transferability of an ensemble of pre-trained deep learning models to a new target task, in order to select a well-performing ensemble without having to fine-tune all possible combinations?The key hypothesis is that considering three factors - domain difference, task difference, and inter-model cohesion - can lead to a better transferability estimate for model ensembles compared to prior approaches.In summary, the paper proposes a new transferability metric called OSBORN that accounts for these three factors when estimating how well an ensemble of pre-trained models will transfer to a new task. It aims to reliably estimate ensemble performance so that a small well-performing subset can be selected from a large pool of candidate models without exhaustive fine-tuning.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing a new transferability estimation metric called OSBORN (Optimal Transport-based Submodular Transferability metric) for selecting source model ensembles for a target task. - OSBORN considers three key factors in estimating ensemble transferability - domain difference, task difference, and inter-model cohesion. It uses optimal transport to measure domain difference, conditional entropy for task difference, and a novel cohesion term to capture relationships between models in the ensemble.- Showing that OSBORN can be posed as a submodular optimization problem, allowing efficient greedy maximization for selecting good model ensembles.- Evaluating OSBORN extensively on image classification and segmentation tasks using multiple datasets, model architectures, and pre-training methods. It outperforms prior state-of-the-art methods like MS-LEEP and E-LEEP across different correlation measures.- Conducting additional analysis and ablation studies to demonstrate the contribution of each component of OSBORN and providing insights into transferability estimation for ensembles.In summary, the key novelty of this work seems to be the proposal of OSBORN, which is the first ensemble transferability estimation metric that holistically accounts for domain difference, task difference and model relationships in a principled manner. The submodularity view also allows efficient optimization. The comprehensive experiments highlight the effectiveness of OSBORN over strong baselines.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper proposes a new transfer learning method called OSBORN that selects an optimal ensemble of source models for a target task by considering domain difference, task difference, and model cohesiveness between the source models.
