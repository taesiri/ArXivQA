# [Building a Winning Team: Selecting Source Model Ensembles using a   Submodular Transferability Estimation Approach](https://arxiv.org/abs/2309.02429)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question it addresses is: How can we effectively estimate the transferability of an ensemble of pre-trained deep learning models to a new target task, in order to select a well-performing ensemble without having to fine-tune all possible combinations?The key hypothesis is that considering three factors - domain difference, task difference, and inter-model cohesion - can lead to a better transferability estimate for model ensembles compared to prior approaches.In summary, the paper proposes a new transferability metric called OSBORN that accounts for these three factors when estimating how well an ensemble of pre-trained models will transfer to a new task. It aims to reliably estimate ensemble performance so that a small well-performing subset can be selected from a large pool of candidate models without exhaustive fine-tuning.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing a new transferability estimation metric called OSBORN (Optimal Transport-based Submodular Transferability metric) for selecting source model ensembles for a target task. - OSBORN considers three key factors in estimating ensemble transferability - domain difference, task difference, and inter-model cohesion. It uses optimal transport to measure domain difference, conditional entropy for task difference, and a novel cohesion term to capture relationships between models in the ensemble.- Showing that OSBORN can be posed as a submodular optimization problem, allowing efficient greedy maximization for selecting good model ensembles.- Evaluating OSBORN extensively on image classification and segmentation tasks using multiple datasets, model architectures, and pre-training methods. It outperforms prior state-of-the-art methods like MS-LEEP and E-LEEP across different correlation measures.- Conducting additional analysis and ablation studies to demonstrate the contribution of each component of OSBORN and providing insights into transferability estimation for ensembles.In summary, the key novelty of this work seems to be the proposal of OSBORN, which is the first ensemble transferability estimation metric that holistically accounts for domain difference, task difference and model relationships in a principled manner. The submodularity view also allows efficient optimization. The comprehensive experiments highlight the effectiveness of OSBORN over strong baselines.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper proposes a new transfer learning method called OSBORN that selects an optimal ensemble of source models for a target task by considering domain difference, task difference, and model cohesiveness between the source models.


## How does this paper compare to other research in the same field?

Based on my understanding, here is a brief comparison of this paper to other related work in transfer learning and transferability estimation:- This paper focuses specifically on transferability estimation for model ensembles, whereas much prior work has focused only on single source model selection. The most relevant prior work is MS-LEEP and E-LEEP, which also look at ensemble transferability, but this paper argues those methods are limited because they only consider model outputs and not other factors like feature space mismatch.- Compared to single source transferability papers like LEEP, LogME, and OTCE, this paper incorporates additional considerations like model cohesiveness and poses the problem as a submodular optimization. It also evaluates on a wider range of tasks like segmentation and domain adaptation.- Most prior transferability estimation papers focus only on fully supervised pre-training. This paper considers both fully supervised and self-supervised pre-training strategies.- The inclusion of optimal transport for measuring domain mismatch builds on OTCE, but adapts it for the ensemble setting. The cohesiveness term and submodular optimization formulation are novel contributions not considered in prior work.- The experimental evaluation is quite comprehensive compared to prior work, spanning multiple datasets, tasks, and pre-training schemes. The only other paper that compares on such a breadth is MS-LEEP.- Overall, this paper pushes transferability estimation forward into the ensemble domain while properly accounting for factors overlooked by prior work like feature space mismatch and model relationships. The submodularity framing and cohesiveness term are unique contributions that yield improved results.In summary, this paper advances the state-of-the-art in transferability estimation, especially for model ensembles, through several novel considerations and extensive experimentation. It addresses limitations of prior single source methods and ensemble methods by taking a more holistic approach.
