# Generative Image Inpainting with Contextual Attention

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we improve image inpainting using deep learning to synthesize more realistic and coherent image content in missing regions, especially for challenging cases with large holes or complex structures?The paper proposes a new deep generative network with a novel contextual attention module to address the limitations of previous CNN-based inpainting methods. The key ideas and contributions are:- Proposing a contextual attention module to explicitly attend on relevant background image features at distant locations and copy them to missing regions. This helps improve coherence.- Introducing techniques like improved GAN loss, coarse-to-fine network, and spatially discounted reconstruction loss to enhance training stability and image quality.- Demonstrating a unified feed-forward inpainting model that combines the contextual attention pathway and a separate pathway for hallucinating novel content.- Evaluating the method on challenging datasets and showing it generates higher-quality inpainting results than previous state-of-the-art methods.So in summary, the main research contribution is using attention and copying features from background to foreground in a learnable way along with other training improvements, to advance image inpainting quality and coherence for complex cases.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:- Proposing a novel contextual attention layer to explicitly attend on related feature patches at distant spatial locations in a deep generative network for image inpainting.- Introducing several techniques including inpainting network enhancements, global and local WGANs, and spatially discounted reconstruction loss to improve training stability and speed. This allows them to train the network much faster than prior work.- Achieving high-quality inpainting results on challenging datasets including faces, textures and natural images using a unified feedforward generative network with the proposed contextual attention module.In summary, the key contribution is the contextual attention layer and associated training techniques that enable efficient and effective borrowing of contextual information from background to fill in missing regions in images. The contextual attention allows matching and reconstructing missing patches using relevant patches from the surroundings.
