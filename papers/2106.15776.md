# [Local Reweighting for Adversarial Training](https://arxiv.org/abs/2106.15776)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is: Can a robust neural network model be trained to defend against various adversarial attacks, not just a specific attack used during training?The key hypotheses appear to be:1) The relative vulnerability of instances to adversarial attacks is inconsistent across different attacks. Instances that are robust to one type of attack may be vulnerable to another.2) Existing adversarial training methods that assign instance-specific weights, like IRAT, can overfit to the particular attack used during training. This leads to reduced robustness on unseen attacks. 3) A training approach called Locally Reweighted Adversarial Training (LRAT) that performs local reweighting within instance-attack pairs, while avoiding global reweighting across instances, can improve robustness on diverse attacks.So in summary, the central research question is how to train models robust to diverse adversarial attacks, not just a single attack. The key hypothesis is that LRAT, through local reweighting, can achieve improved robustness compared to methods like IRAT that assign global instance weights. The experiments aim to demonstrate this improved generalized robustness of LRAT across different attacks.


## What is the main contribution of this paper?

The main contribution of this paper seems to be proposing a new adversarial training method called Locally Reweighted Adversarial Training (LRAT). The key ideas of LRAT are:- It pairs each instance with its adversarial variants and performs local reweighting inside each pair, rather than doing global reweighting across all instances like prior work on instance reweighting.- The rationale is to fit the instance itself if it is immune to a given attack, but still keep the pair to passively defend against different attacks, rather than skip or downweight the pair like global reweighting methods.- It uses a general vulnerability-based reweighting strategy that can work with different attacks, rather than a heuristic based on PGD steps.- It assigns some minimum weight to the natural data term to avoid overly downweighting instances, to defend against unseen attacks.The authors argue that global reweighting methods like prior work can overly downweight instances, harming generalization to unseen attacks. The local reweighting of LRAT is shown to improve robustness compared to no reweighting, global reweighting, and their combination.So in summary, the main contribution seems to be proposing this new locally reweighted adversarial training approach to improve robustness to diverse adversarial attacks.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other related research:- This paper focuses specifically on adversarial training methods for deep neural networks. Adversarial training is a hot topic in ML security and robustness. Many recent papers have looked at novel adversarial training procedures or modifications to improve robustness. This paper builds off that line of work.- The key contribution here is proposing a new locally reweighted adversarial training (LRAT) method to address limitations of prior work on instances-reweighted adversarial training (IRAT). So it is extending IRAT and analyzing/fixing some of its shortcomings. - The authors motivate the need for LRAT by providing empirical analysis on the inconsistent vulnerability of instances to different attacks. This highlights an overlooked issue with previous methods. Other papers have not directly analyzed this phenomenon in detail.- Most prior adversarial training methods either do no reweighting (standard AT) or global reweighting (IRAT). By proposing a local reweighting scheme, this represents a new approach in between those extremes.- The paper includes thorough experiments on CIFAR-10 and SVHN comparing LRAT to standard AT and IRAT. The results support the benefits of their proposed local reweighting strategy. Other papers have not directly tested this type of approach.- The authors also design LRAT versions for existing methods like TRADES. Showing the approach can be integrated into the state-of-the-art. This demonstrates the general applicability of the local reweighting idea.- Overall, this paper makes an important empirical contribution in analyzing limitations of prior work, and proposes a novel local reweighting adversarial training method to address them. The approach appears to outperform previous global reweighting and no reweighting strategies.
