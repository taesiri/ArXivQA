# [What Sketch Explainability Really Means for Downstream Tasks](https://arxiv.org/abs/2403.09480)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Sketches have inherent meaning in the strokes drawn by humans, unlike pixels in images. However, most sketch applications and networks operate on rasterized sketches which lose this stroke-level information. 
- Existing sketch explainability methods require retraining networks, limiting their applicability. They also focus more on visualization rather than implications for downstream tasks.

Proposed Solution:
- Lightweight attribution algorithms that can be plugged into any pre-trained sketch network without retraining. 
- Provides explanations at both coarse stroke-level (SLA) and fine partial stroke-level (P-SLA).
- Addresses non-differentiability of rasterization to enable backpropagation to strokes.

Key Contributions:
- Emphasizes role of strokes for explainability in human sketches.
- Showcases profound impact of explainability via four applications: sketch-based retrieval, sketch-to-image generation, assisted drawing, and adversarial attacks.
- SLA aggregates gradients over strokes by differentiably composing stroke images. P-SLA computes distance transform and thresholds to differentiably rasterize.  
- Evaluates new applications like filtering noisy strokes for assisted drawing and removing tiny strokes for adversarial attacks.
- Validates through quantitative experiments and human studies that explanations aid transparency, fairness and trust.

In summary, this paper provides a lightweight sketch attribution technique, adaptable to multiple downstream applications. By backpropagating to strokes, it generates meaningful explanations that capture the sketching process, giving insights into model behavior. Human studies demonstrate the utility of such fine-grained explanations for end users.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes lightweight and adaptable stroke-level attribution algorithms to explain sketch recognition models, demonstrating applications in diverse downstream tasks like retrieval, generation, assisted drawing, and adversarial attacks.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

(i) The paper explores sketch explainability, emphasising the importance of strokes in human-drawn sketches. 

(ii) It highlights the profound impact of explainability on various sketch-related domains, presenting applications in retrieval, generation, assisted drawing, and adversarial attacks.

(iii) It solves for the non-differentiability problem of rasterisation, and provides both stroke-level and partial-stroke level attribution to explain model predictions.

In summary, the main contribution is proposing a lightweight and adaptable explainability solution that attributes explanations to individual strokes and their parts in human-drawn sketches. This is shown to provide insights for diverse downstream sketch tasks compared to typical pixel-based explanations.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts include:

- Sketch explainability - Explaining and interpreting sketch recognition models, with a focus on attributing predictions to individual strokes.

- Stroke-level attribution (SLA) - Coarse attribution map that assigns importance scores to entire strokes in a sketch. Helps identify important strokes.

- Partial stroke-level attribution (P-SLA) - Fine-grained attribution that assigns importance to parts of strokes by backpropagating to stroke coordinate points. 

- Non-differentiable rasterization - Challenge of backpropagating gradients from raster sketch images to vector stroke representations due to discrete, non-differentiable conversion.

- Downstream sketch tasks - Various applications explored including sketch-based image retrieval, assisted drawing, sketch-to-image generation, and adversarial attacks.

- Lightweight and portable - Proposed solution integrates seamlessly with pre-trained models without retraining.

- Human studies - Evaluating model interpretability and trustworthiness by user studies instead of just accuracy metrics.

In summary, the key focus is on stroke-level explainability methods for sketch recognition models and demonstrating their utility on diverse downstream applications.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper introduces two novel methods for backpropagating gradients to strokes - Stroke-Level Attribution (SLA) and Partial Stroke-Level Attribution (P-SLA). What are the key differences between SLA and P-SLA in terms of granularity of attribution and handling the non-differentiability of rasterization?

2. Explain in detail the process used in SLA to calculate attribution scores for individual strokes. How does it avoid the problem of degenerate solutions where all strokes get the same attribution? 

3. The P-SLA method calculates the distance transform to differentiably rasterize the vector sketch points. Walk through the key steps involved in computing the distance transform and converting it to a rasterized sketch image. 

4. The paper demonstrates four novel applications enabled by SLA and P-SLA - sketch retrieval, assisted drawing, sketch-to-image generation, and adversarial attacks. Pick one application and explain how sketch attribution helped improve or provide new capabilities.

5. For the application of robust sketch-based image retrieval, the paper proposes using attribution to predict stroke order and compare it to human drawn order. Why is this a reliable way to evaluate model predictions? What results did the paper show?

6. In the assisted drawing application, noisy strokes are removed using attribution scores. Compare the quantitative results achieved by SLA/P-SLA filtering to the state-of-the-art method. Why is there a performance gap?

7. For interactive sketch-to-image generation, attribution scores are used to provide feedback to the user on strokes being ignored. Walk through the full pipeline and how attribution helps in faithfully generating the output image.

8. The paper presents the first study on adversarial attacks for human sketches using SLA and P-SLA. Explain the key differences compared to conventional adversarial attacks on images.

9. Discuss the human study evaluation conducted to assess transparency, fairness and trustworthiness of the attribution methods. What metrics were used and what were the main findings?

10. The paper focused only on gradient-based attribution for simplicity. What are some limitations of this approach? What are some potential future research directions discussed to address these limitations?
