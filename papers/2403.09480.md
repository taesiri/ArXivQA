# [What Sketch Explainability Really Means for Downstream Tasks](https://arxiv.org/abs/2403.09480)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Sketches have inherent meaning in the strokes drawn by humans, unlike pixels in images. However, most sketch applications and networks operate on rasterized sketches which lose this stroke-level information. 
- Existing sketch explainability methods require retraining networks, limiting their applicability. They also focus more on visualization rather than implications for downstream tasks.

Proposed Solution:
- Lightweight attribution algorithms that can be plugged into any pre-trained sketch network without retraining. 
- Provides explanations at both coarse stroke-level (SLA) and fine partial stroke-level (P-SLA).
- Addresses non-differentiability of rasterization to enable backpropagation to strokes.

Key Contributions:
- Emphasizes role of strokes for explainability in human sketches.
- Showcases profound impact of explainability via four applications: sketch-based retrieval, sketch-to-image generation, assisted drawing, and adversarial attacks.
- SLA aggregates gradients over strokes by differentiably composing stroke images. P-SLA computes distance transform and thresholds to differentiably rasterize.  
- Evaluates new applications like filtering noisy strokes for assisted drawing and removing tiny strokes for adversarial attacks.
- Validates through quantitative experiments and human studies that explanations aid transparency, fairness and trust.

In summary, this paper provides a lightweight sketch attribution technique, adaptable to multiple downstream applications. By backpropagating to strokes, it generates meaningful explanations that capture the sketching process, giving insights into model behavior. Human studies demonstrate the utility of such fine-grained explanations for end users.
