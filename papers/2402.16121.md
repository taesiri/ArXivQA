# [Towards Accurate Post-training Quantization for Reparameterized Models](https://arxiv.org/abs/2402.16121)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Quantizing reparameterized models like RepVGG and MobileOne to 8 bits often leads to significant loss in accuracy. This is primarily due to the presence of channel-specific and sample-specific outliers caused by BatchNorm layers.
- Existing quantization methods rely on minimizing Mean Squared Error (MSE) which gets disproportionately affected by these outliers, leading to suboptimal selection of quantization parameters.

Proposed Solution:
- Introduce a quantization framework called RepAPQ tailored for reparameterized models consisting of two key components:
  1) Quantization Protecting Reparameterization (QPRep):
     - Inserts an affine layer after reparameterized convolutions to amplify features and better accommodate samples with outliers.
     - Allows adaptive adjustment of output to be closer to real output and accelerate convergence.
  2) Across Block Calibration (ABC):  
     - Employs Mean Absolute Error (MAE) instead of MSE to mitigate impact of outliers.
     - Uses stage output as supervision signal to enhance interlayer correlations and address gradient issues with MAE.

Main Contributions:
- Comprehensive analysis of factors causing accuracy loss during quantization of reparameterized models, highlighting outlier issue 
- Proposal of tailored quantization techniques QPRep and ABC to address sample/channel-specific outliers and improve accuracy
- Achieves state-of-the-art results, outperforming previous methods by ~1% for 8-bit and ~2% for 6-bit quantization on various models
- Pushes limits of quantization for reparameterized models by obtaining accurate 6-bit quantized models, approaching FP32 performance
- Demonstrates broad applicability across range of models like RepVGG, MobileOne for image classification and YoloV6 for detection

In summary, the paper provides an in-depth analysis of challenges in quantizing reparameterized models and proposes innovative solutions to achieve accurate and efficient low-bit quantized models for these architectures. The techniques substantively advance state-of-the-art.
