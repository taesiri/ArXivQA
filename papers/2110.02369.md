# [EntQA: Entity Linking as Question Answering](https://arxiv.org/abs/2110.02369)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can entity linking be formulated as a question answering task to avoid the limitation of conventional approaches that require detecting mentions without knowing the entities?The key hypotheses are:1) It is easier to find relevant entities in a document without knowing the specific mentions, compared to finding mentions without knowing the entities.2) Entity linking can be effectively decomposed into two subtasks: entity retrieval followed by reading comprehension to identify mentions.3) Recent advances in dense entity retrieval and reading comprehension models can be leveraged for the two subtasks to develop an accurate entity linking system without relying on mention candidate dictionaries or large weakly supervised pretraining.In summary, the paper proposes and evaluates the EntQA model which formulates entity linking as a question answering task by first retrieving candidate entities and then using a reader model to find mentions of each entity. This inverts the traditional pipeline and avoids the difficulty of detecting mentions without entity knowledge.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. Proposing a new model for entity linking called EntQA (Entity Linking as Question Answering) that flips the traditional order of mention detection and entity disambiguation. EntQA first retrieves candidate entities that may be mentioned in a document, and then finds mentions of each candidate entity using a reading comprehension model. 2. Formulating entity linking as an "inverted" open domain question answering problem, where candidate entities act as "questions" and mentions of those entities act as "answer spans". This allows EntQA to leverage recent progress in dense entity retrieval and reading comprehension models.3. Demonstrating strong results with EntQA on the GERBIL benchmark, including state-of-the-art performance on the in-domain AIDA dataset. The model achieves these results without relying on mention-candidate dictionaries or large scale weak supervision during training.4. Providing ablation studies and error analysis showing the effectiveness of the retriever and reader modules, and analyzing the types of errors made by EntQA. The analysis shows extremely high retrieval recall and finds that many reader errors are reasonable, like predicting missing hyperlinks or linking mentions to more specific entities than the gold labels.In summary, the key innovation is the inverted QA formulation for entity linking, which allows more accurate retrieval of relevant entities before mention finding and enables leveraging recent QA models. This removes the limitation of prior work that requires detecting mentions without knowing the entities.
