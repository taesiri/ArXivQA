# [EntQA: Entity Linking as Question Answering](https://arxiv.org/abs/2110.02369)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can entity linking be formulated as a question answering task to avoid the limitation of conventional approaches that require detecting mentions without knowing the entities?The key hypotheses are:1) It is easier to find relevant entities in a document without knowing the specific mentions, compared to finding mentions without knowing the entities.2) Entity linking can be effectively decomposed into two subtasks: entity retrieval followed by reading comprehension to identify mentions.3) Recent advances in dense entity retrieval and reading comprehension models can be leveraged for the two subtasks to develop an accurate entity linking system without relying on mention candidate dictionaries or large weakly supervised pretraining.In summary, the paper proposes and evaluates the EntQA model which formulates entity linking as a question answering task by first retrieving candidate entities and then using a reader model to find mentions of each entity. This inverts the traditional pipeline and avoids the difficulty of detecting mentions without entity knowledge.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. Proposing a new model for entity linking called EntQA (Entity Linking as Question Answering) that flips the traditional order of mention detection and entity disambiguation. EntQA first retrieves candidate entities that may be mentioned in a document, and then finds mentions of each candidate entity using a reading comprehension model. 2. Formulating entity linking as an "inverted" open domain question answering problem, where candidate entities act as "questions" and mentions of those entities act as "answer spans". This allows EntQA to leverage recent progress in dense entity retrieval and reading comprehension models.3. Demonstrating strong results with EntQA on the GERBIL benchmark, including state-of-the-art performance on the in-domain AIDA dataset. The model achieves these results without relying on mention-candidate dictionaries or large scale weak supervision during training.4. Providing ablation studies and error analysis showing the effectiveness of the retriever and reader modules, and analyzing the types of errors made by EntQA. The analysis shows extremely high retrieval recall and finds that many reader errors are reasonable, like predicting missing hyperlinks or linking mentions to more specific entities than the gold labels.In summary, the key innovation is the inverted QA formulation for entity linking, which allows more accurate retrieval of relevant entities before mention finding and enables leveraging recent QA models. This removes the limitation of prior work that requires detecting mentions without knowing the entities.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on my understanding of the paper, here is a one sentence summary:The paper proposes EntQA, a new end-to-end entity linking model that first retrieves candidate entities using dense retrieval and then identifies mentions of each candidate in the document via reading comprehension, without relying on mention detection or a mention-candidates dictionary.


## How does this paper compare to other research in the same field?

Here are some thoughts on how this paper compares to other research in the same field:- This paper tackles the task of entity linking by formulating it as a question answering problem. This is a novel approach compared to prior work, which typically separates mention detection and entity disambiguation into pipeline stages. Casting it as QA allows the model to leverage recent advances in retriever-reader architectures.- Most prior entity linking methods rely heavily on mention candidate dictionaries to constrain the output space. This paper does not use any dictionary, making the approach potentially more generalizable to new knowledge bases without such resources.- The paper shows competitive or state-of-the-art results on benchmark datasets compared to prior published methods. The results are especially strong on out-of-domain datasets, demonstrating robustness.- Compared to the recent autoregressive model GENRE, this model trades off not having expensive pretraining while still surpassing its performance. It also allows more direct interpretability and control via the separate retrieval and reading modules.- One downside is that incorporating coreference information seems difficult in the proposed framework, whereas pipeline models and autoregressive models may have an easier time with pronouns or nominal mentions.- Overall, the question answering formulation, lack of reliance on dictionaries, competitive performance, and modular interpretability offer notable advantages over related prior work in entity linking. The novelty of the approach is a key contribution. One direction for future work is extending it to nested or coreferential entities.In summary, the paper introduces a novel QA-based formulation for entity linking that avoids pitfalls like error propagation in pipelines and constrained search spaces of prior work. The retrieval-reader architecture leverages recent NLP advances to achieve strong performance without extensive pretraining. The approach represents a conceptual shift in entity linking that highlights the flexibility of casting NLP problems as question answering.


## What future research directions do the authors suggest?

Based on my reading of the paper, here are some of the main future research directions the authors suggest:- Exploring different architectural choices and objective functions for the retriever and reader modules in EntQA. The authors suggest this could lead to further improvements in performance.- Developing more sophisticated mention selection methods beyond just thresholding mention probabilities. This could help address cases of over- and under-prediction of mentions.- Handling nested entity mentions. The threshold-based inference approach of EntQA can naturally be extended to handle nested mentions, which the authors suggest as an interesting direction. - Combining the strengths of the dense retrieval approach of EntQA with the autoregressive approach like GENRE. The authors suggest this hybrid approach could yield further gains.- Adapting EntQA to handle coreference cases with pronouns and common nouns, which it currently does not handle. The authors note EntQA's weaker performance on datasets with such annotations.- Applying EntQA to small domain-specific knowledge bases that lack resources like annotated corpora to construct mention-candidate dictionaries. The authors highlight EntQA's potential for zero-shot application to new KBs.- Reducing the memory footprint of dense retrieval, for instance by approximating retrieved embeddings to enable scaling to even larger candidate sets.In summary, the main suggestions are around architectural variants of EntQA, improving mention selection, handling nested entities, combining with autoregressive models, adapting to coreference, applying to new KBs in a zero-shot manner, and reducing memory requirements.


## Summarize the paper in one paragraph.

The paper proposes EntQA, a new model for entity linking that reformulates the task as question answering. Unlike traditional entity linking methods that first detect mentions and then link them to entities, EntQA first retrieves candidate entities likely to be mentioned in the document using dense retrieval, and then finds textual mentions of each candidate entity using a reading comprehension model. This inverted question answering approach avoids the limitation of traditional methods that must detect mentions without knowing the target entities. EntQA combines recent advances in dense entity retrieval and reading comprehension to achieve state-of-the-art performance on the GERBIL benchmark without relying on mention-candidate dictionaries or large weakly supervised pretraining. The key ideas are retrieving candidate entities first to convert entity linking to QA, using dense retrieval and reading comprehension models from QA research, and simple yet effective mention finding and reranking during inference. Overall, EntQA demonstrates the effectiveness of reformulating entity linking as inverted question answering.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:The paper presents EntQA, a new model for entity linking that avoids a key limitation of prior approaches. Existing methods detect mention spans first, then try to link mentions to knowledge base entities. This is problematic because finding mentions without knowing entities is unnatural and difficult. EntQA flips the traditional pipeline by first retrieving candidate entities using a fast retriever module, then identifying mentions for each candidate using a powerful reader module. This framing as "inverted" question answering allows EntQA to leverage progress in dense retrieval and reading comprehension. EntQA achieves strong results on the GERBIL benchmark, outperforming prior methods. A key advantage is not relying on a mention-candidates dictionary, making it applicable to new knowledge bases. EntQA is also efficient to train compared to recent end-to-end approaches. The paper demonstrates the effectiveness of reformulating entity linking as inverted question answering.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper:The paper proposes a novel approach to entity linking called EntQA that reformulates the task as question answering. Instead of the traditional pipeline of mention detection followed by entity disambiguation, EntQA first retrieves candidate entities that may be mentioned in the document using a retriever module. It then applies a reader module to extract mentions of each candidate entity in the document, rejecting candidates for which no mention is found. Specifically, the retriever encodes the document passages and entity descriptions into dense embeddings which are compared for retrieval. The reader performs reading comprehension on the document passage and candidate entity descriptions to predict start and end tokens of mention spans. At inference time, mention spans are extracted for each candidate entity with probability above a threshold and globally reranked. This inverted question answering approach allows EntQA to leverage recent advances in dense retrieval and reading comprehension models, avoiding reliance on mention dictionaries and large weakly labeled training data.
