# [All Language Models Large and Small](https://arxiv.org/abs/2402.12061)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Large language models (LLMs) require massive computational resources for training and execution, making their deployment challenging in edge devices with limited compute capabilities. Smaller LMs are more efficient but have degraded performance. The paper aims to address this tradeoff between performance and computational efficiency.  

Proposed Solution: 
The paper proposes LONDI, a novel framework for selectively activating an LLM (called DEEPTHINK) to cooperate with a smaller LM (called QUICK) in order to solve tasks efficiently. LONDI introduces an adaptive reinforcement learning agent called Switcher that controls activations of DEEPTHINK. Switcher is based on a dual process theory inspired "fast and slow thinking" mechanism, where QUICK provides fast reflexive responses and DEEPTHINK deliberate reasoning where needed.

Main Components:
- QUICK: Smaller, computationally cheaper LM  
- DEEPTHINK: Larger, powerful but expensive LLM
- Switcher: Uses a reinforcement learning policy with switching controls to select states where DEEPTHINK should be activated, keeping it off elsewhere to use QUICK

Key Results:
- Theoretical convergence guarantees for LONDI within the MDP formulation
- LONDI-B variant that allows specifying budget constraints on DEEPTHINK activations  
- Experiments showing LONDI solves complex tasks in ScienceWorld and BabyAI using upto 30% less GPU resources than just using DEEPTHINK
- LONDI is robust, consistent across tasks and can incorporate different LMs/LLMs

Main Contributions:
- Novel selective activation framework to combine strengths of small and large LMs in a resource efficient way
- Introduction of an adaptive "switcher" agent that automates efficient delegations between the LMs  
- Budget-aware extension (LONDI-B) to control LLM usage
- Theoretical proofs of optimality and convergence for LONDI
- Demonstration of improved efficiency and performance across planning tasks

In summary, LONDI offers a systematic way to augment limited LMs to solve complex tasks by selective incorporation of more capable but expensive LLM reasoning only where beneficial, making model deployment more practical.
