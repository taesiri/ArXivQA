# [DreamHuman: Animatable 3D Avatars from Text](https://arxiv.org/abs/2306.09329)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we generate realistic, animatable 3D human avatars from just textual descriptions, without any paired text-to-3D training data?The key points are:- The paper presents a method called DreamHuman to generate 3D human avatars from text prompts. - The goal is to create animated 3D models that match the textual description, with realistic appearance, clothing, and body shape.- The key innovation is doing this without any supervised text-to-3D training data. - The method combines text-to-image diffusion models, neural radiance fields, and 3D statistical human body models.- The human body model acts as a strong prior to regularize the avatar structure and appearance during optimization.- This allows generating animatable avatars that can be reposited in new poses.So in summary, the main research question is how to leverage recent advances in generative models to create controllable, animatable 3D human avatars from text alone, without paired text-to-3D supervision. The paper presents a novel approach and demonstrates high quality 3D human generation.
