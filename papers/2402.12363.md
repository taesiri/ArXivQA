# [Emergent Word Order Universals from Cognitively-Motivated Language   Models](https://arxiv.org/abs/2402.12363)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Explaining the source of word order biases (so-called "universals") in human languages is a key challenge in linguistics. For example, why do SOV languages often have postpositions while SVO languages typically have prepositions?
- Simply correlating properties of existing languages has limitations in elucidating the underlying mechanisms behind these biases. 

Proposed Solution and Contributions:
- The authors computationally simulate word order universals via language models (LMs) to study their emergence through cognitive biases.
- They compare multiple cognitively-motivated LMs against standard LMs on their ability to replicate typological markedness in their word order preferences on controlled artificial languages.
- Their experiments show LMs with syntactic biases, left-corner parsing strategies, and memory limitations better simulate the frequency distribution of attested word order configurations.
- This suggests the interplay of these cognitive factors and predictability (perplexity) can explain many word order universals, providing computational evidence of their cognitive underpinnings.
- Results demonstrate the advantage of cognitively-motivated LMs in not just modeling sentence processing but also simulating typological biases, further validating their usefulness in cognitive modeling.

In summary, this work leverages cognitively-plausible language models to provide a computationally-grounded explanation of the source of many linguistic word order universals based on human cognitive biases related to efficient sentence processing and prediction.
