# [Taming the Tail in Class-Conditional GANs: Knowledge Sharing via   Unconditional Training at Lower Resolutions](https://arxiv.org/abs/2402.17065)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Generating high-quality and diverse images from generative adversarial networks (GANs) trained on long-tailed data remains challenging. Long-tailed data refers to highly imbalanced multi-class data where a few head classes dominate the distribution while tail classes have very limited samples. Standard GANs struggle to effectively model the diversity in tail classes, often exhibiting mode collapse. This work aims to improve class-conditional GANs for long-tailed data.

Method: 
The key idea is to promote knowledge sharing from data-rich head classes to data-poor tail classes. The authors make an observation that head and tail classes share more similarities at lower resolutions where the differences are less apparent. Hence, they propose Unconditional Training at LOwer resolutions (UTLO) where the lower layers of the generator are trained to reconstruct low-resolution unconditional images while the top layers receive class embeddings and output high-resolution class-conditional images. The unconditional path acts as a means to share common low-resolution patterns from head to tail.

Contributions:
- Propose UTLO, a novel conditional GAN framework tailored for long-tailed data. It features a generator with partially unconditional lower layers and conditional top layers to enable knowledge transfer.

- Introduce adapted GAN metrics called FID-FS and KID-FS specifically for evaluating performance on few-shot tail classes. 

- Experiments across several long-tailed datasets and GAN models demonstrate UTLO consistently improves tail image quality and diversity, outperforming recent methods. The framework is model-agnostic and brings more pronounced gains as imbalance increases.

In summary, this work presents a simple yet effective technique to share knowledge in conditional GANs for improved long-tailed image modeling, backed by strong empirical validation. The partial unconditional training scheme is a distinguishing feature not explored in prior GAN literature.
