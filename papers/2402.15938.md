# [Generalization or Memorization: Data Contamination and Trustworthy   Evaluation for Large Language Models](https://arxiv.org/abs/2402.15938)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like ChatGPT are susceptible to data contamination, where the test data is included in the training data. This leads to inflated performance estimates and hides model flaws.  
- Detecting contamination is challenging due to opaque training data, black-box access to models, and proliferation of synthetic training data containing variants of test data.
- There is a need for contamination detection and mitigating impact on evaluation without access to model internals.

Proposed Solution: 
- A new approach called CDD that detects contamination by identifying peakedness in the output distribution obtained by sampling text from the LLM given a test input. More peakedness indicates higher likelihood of contamination.
- A new approach called TED that mitigates the impact of contamination on evaluation by excluding the peakedness and removing duplicate samples from the LLM's output distribution.
- Constructed two new datasets - DetCon and ComiEval - for contamination detection and mitigation tasks.

Main Contributions:
- Propose CDD and TED, two novel approaches leveraging only sampled text for contamination detection and mitigation without requiring model probabilities or parameters. 
- CDD outperforms prior works by 21.8%-30.2% and handles variant contamination.
- TED successfully reduces inflated performance by up to 66.9% across different contamination settings.  
- Provide evidence of potential ChatGPT contamination on HumanEval via CDD detection and TED mitigation.
- Release two new benchmarks to facilitate research into contamination issues with LLMs.

In summary, the paper tackles key challenges in identifying and accounting for contamination during evaluation of opaque LLMs using simple but effective techniques based on output distribution analysis.
