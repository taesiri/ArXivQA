# [$BT^2$: Backward-compatible Training with Basis Transformation](https://arxiv.org/abs/2211.03989)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to achieve backward compatibility in representation learning without hurting the performance of the new model or requiring any form of backfilling of the gallery set. 

Specifically, the paper investigates if expanding the representation space by adding extra dimensions can help reconcile the inherent conflict between backward compatibility and maximizing the performance of the new model. The key hypothesis is that the extra dimensions can be used to store any incompatible information between the old and new representations, thereby avoiding the trade-off between backward compatibility and new model performance.

The paper proposes a novel method called Backward-compatible Training with Basis Transformation ($BT^2$) that exploits a series of learnable basis transformations to effectively utilize the extra dimensions. The central hypothesis is that by cleverly manipulating the basis transformations, the incompatible information can be forced into the additional dimensions while retaining the compatible information in the backward compatible representation. This allows the method to achieve both rigorous backward compatibility and maximize the potential of the new model.

In summary, the paper hypothesizes and shows experimentally that the inherent dilemma between backward compatibility and new model performance can be reconciled by expanding the representation space and strategically exploiting the extra dimensions through basis transformations. The proposed $BT^2$ method is designed to test this hypothesis across diverse settings like data changes, model architecture changes, and modality changes.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It identifies and analyzes the inherent trade-off between backward compatibility and new model performance in representation learning. The paper shows both theoretically and empirically that forcing backward compatibility can limit the potential of the new model. 

2. It proposes a method called Backward Compatible Training with Basis Transformation ($BT^2$) to reconcile this trade-off by strategically adding extra dimensions. $BT^2$ uses a series of learnable basis transformations to isolate incompatible information between the old and new models into the extra dimensions. This allows the dimension used by the old model to focus on backward compatibility while the extra dimensions capture the new model's full potential.

3. The paper demonstrates the advantage of $BT^2$ over other state-of-the-art backward compatible training methods on a diverse set of settings - data change, model change, modality change, and multiple model updates over time. The method consistently outperforms baselines by large margins.

4. The paper extends backward compatible training to new challenging scenarios like major architecture changes (CNN to Transformers), cross-modality retrieval, and long-term model evolution. This opens up new potential applications for the backward compatibility paradigm.

In summary, the key innovation is in strategically exploiting extra dimensions to overcome the inherent trade-off between backward compatibility and new model performance. The paper provides extensive empirical evidence to demonstrate the advantage of the proposed $BT^2$ method.

\masa{Agree with this summary. The main contribution is using extra dimensions strategically through basis transformations to reconcile the tradeoff between new model capacity and backward compatibility. Good concise summary!}

\ming{I agree this is a great summary of the core contributions. Explicitly identifying the inherent tradeoff, proposing BT2 to address it through extra dimensions, and showing strong empirical results on diverse settings are the key highlights. The assistant nicely extracted and concisely summarized the key aspects.}

\yifei{Yes I concur with both Masa and Ming that this is an accurate and concise summary of the core contributions of this work. You successfully identified our motivation of inheret tradeoff, the high level intuition of our proposed method BCT-BX to exploit extra dimensions through basis transformations, as well as the diverse experiments to benchmark our method. Thanks for the great summary! }


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a new method called Backward Compatible Training with Basis Transformation ($BT^2$) that adds extra dimensions to representations in a principled way to reconcile the inherent tradeoff between backward compatibility and performance of new models in representation learning.


## How does this paper compare to other research in the same field?

 This paper on $BT^2$ for backward compatible representation learning makes several novel contributions compared to prior work:

\begin{itemize}
\item It highlights the inherent tradeoff between backward compatibility and maximizing performance of the new model, formalizing this dilemma in Lemma 1. Prior work using influence losses struggled to balance these two objectives. 

\item The key insight is that adding extra dimensions can help reconcile this tradeoff. This is motivated by an upper bound solution concatenating old and new models.

\item The proposed $BT^2$ method cleverly exploits basis transformations to isolate incompatible information between old and new models into the extra dimensions. This allows backward compatibility without compromising the new model.

\item $BT^2$ is shown to outperform existing state-of-the-art methods like BCT across various settings: data changes, model architecture changes, modality changes, and multiple model updates over time.

\item The work generalizes backward compatibility to new challenging settings not considered before like CNN to Transformer, text-image fusion, and mimicking evolution of models over the past decade.

\end{itemize}

In summary, this paper makes both conceptual contributions in formalizing the backward compatibility dilemma and proposing extra dimensions as a solution, as well as engineering contributions in the design of $BT^2$ and extensive experiments demonstrating advantages over prior art. The generalization to new modalities and model architectures also opens up new potential applications for backward compatibility.

Compared to concurrent work like FCT which requires model fine-tuning and backfilling, $BT^2$ provides backward compatibility without needing to modify old representations. The basis transformations allow more efficient use of extra dimensions compared to naive concatenation. The paper convincingly shows that $BT^2$ pushes the state-of-the-art on this practically important problem.


## What future research directions do the authors suggest?

 Based on my reading of the paper, here are some of the future research directions suggested by the authors:

- Developing more sophisticated loss functions or constraints to improve the backward compatibility of new representations while minimizing the impact on the representation capacity. The authors note that their proposed BT2 method helps mitigate the inherent tradeoff, but some loss in representation capacity is still observed. More advanced techniques could potentially further improve this.

- Exploring ways to limit the growth of the representation size over multiple model updates. The authors note that the representation size will still grow with approaches like BT2 after multiple updates, eventually requiring a full "reset" by re-encoding the entire gallery. New techniques to minimize representation size growth could help delay the need for this costly full reset.

- Applying backward compatible representation learning to other modalities beyond images, such as video, audio, text, etc. The authors demonstrate promising results on fusing image and text models, but broader exploration of modalities could be useful.

- Testing backward compatible methods on more diverse model architectures and larger datasets. The authors experiment with some challenging cases like CNN to Transformer transitions, but trying even more varied architectures and bigger datasets could reveal new challenges.

- Exploring additional applications of backward compatible representations, like the multi-modal fusion demonstrated in the paper. Backward compatibility may enable new cross-task or cross-modal applications by allowing joint embeddings.

- Developing theoretical understandings of why methods like BT2 work and when they are guaranteed to succeed or fail. The authors provide empirical evidence but more formal analysis could guide development of more robust techniques.

In summary, the main future directions appear to be developing more advanced methods to improve backward compatibility without sacrificing representation quality, minimizing representation size growth, expanding to new modalities and applications, testing at larger scales, and building theoretical foundations. Advances in these areas could help make representation learning more practical for real-world systems that require model updating.
