# [Conditional Normalizing Flows for Active Learning of Coarse-Grained   Molecular Representations](https://arxiv.org/abs/2402.01195)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Efficiently sampling the configurational space of molecular systems to obtain the Boltzmann distribution is challenging. Methods like molecular dynamics (MD) struggle to cover rare transition regions. Recently, normalizing flows trained without samples to match the Boltzmann distribution have been used, but suffer from mode collapse. 

Proposed Solution:
The authors separate the problem into a coarse-grained (CG) and a fine-grained (FG) level. A normalizing flow is trained to generate the FG conditioned on the CG space. This avoids mode collapse since the CG encapsulates the main modes. Active learning (AL) explores the CG space to find high-error regions and refine the flow. 

Main Contributions:
- Novel conditional normalizing flow to generate the FG conditioned on the CG 
- AL workflow with CG sampling to explore configuration space and refine flow
- Method to extract CG potential of mean force (PMF) from trained conditional flow
- Demonstration on alanine dipeptide: 
  - Higher accuracy PMF using 10x less evaluations than state-of-the-art by Midgley et al. 
  - More complete PMF map than MD with 100x less evaluations
  - Speedup over MD between 15.9x to 216x vs 4.5x for Midgley et al.

Overall, the paper introduces an AL workflow using conditional normalizing flows that enables efficient exploration of molecular configuration spaces. By conditioning flows on a CG space, mode collapse is avoided. Experiments on alanine dipeptide demonstrate substantially improved computational efficiency over previous approaches.
