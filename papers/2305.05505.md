# [Recursions Are All You Need: Towards Efficient Deep Unfolding Networks](https://arxiv.org/abs/2305.05505)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to enhance the efficiency of deep unfolding networks for compressive sensing through the use of recursions. The key hypotheses are:1) Using recursions can effectively eliminate redundancies in deep unfolding networks, reducing the number of parameters and training time.2) Randomizing the number of recursions during training can further decrease training time. 3) Modulating features based on the number of recursions (using a learnable unit) allows the model to more efficiently utilize the power of recursions.The overall goal is to show that a recursion-based framework can improve the efficiency of deep unfolding models like ISTA-Net+ and COAST in terms of number of parameters, training time, and resilience to overfitting when training data is limited. The use of recursions is proposed as a way to achieve this increased efficiency while maintaining competitive performance.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Proposing a novel recursive framework to enhance the efficiency of deep unfolding networks for compressive sensing. The key ideas are:- Using recursions to reduce redundancies in the iterative blocks of deep unfolding networks. This allows each layer to be utilized more efficiently before moving to the next layer.- Randomizing the number of recursions during training to reduce training time. - Introducing a learnable unit (RFMU) to modulate features based on recursion statistics, which further improves efficiency.2. Applying the proposed framework to two deep unfolding networks - ISTA-Net+ and COAST. Results show:- Up to 75% reduction in parameters and 21-42% less training time while maintaining similar performance.- When training data is limited, recursive models match or outperform non-recursive baselines due to resilience against overfitting.3. Ablation studies validating the benefits of the proposed RFMU unit and determining ideal number of recursions before diminishing returns.In summary, the key contribution is a novel recursive framework that makes deep unfolding networks much more efficient by reducing redundancies, without significantly sacrificing performance. This could make such models more practical for real-world deployment.
