# [Conditions for Length Generalization in Learning Reasoning Skills](https://arxiv.org/abs/2311.16173)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Recent large language models (LLMs) like GPT-3 show promising reasoning capabilities when trained with chain of thought (CoT) prompting. However, there is a lack of theoretical understanding of the reasoning limitations of LLMs. 

- This paper formally characterizes the reasoning limitations of LLMs by proposing reasoning complexity measures and theoretically proving bounds on the complexity LLMs can achieve.

Proposed Solution: 
- The paper introduces two complexity measures - dynamic complexity $C_d$ and causal complexity $C_c$ to characterize the reasoning complexity in dynamic processes and causal graphs respectively.

- It formally proves that given finite training data, LLMs can only learn reasoning procedures with bounded dynamic complexity $C_d$ and causal complexity $C_c$. Increasing model scale does not help in overcoming these inherent limitations.

- For common reasoning tasks, the paper shows $C_d$ and $C_c$ are small, implying even large LLMs may fail to solve these tasks. This explains some of the reasoning limitations observed empirically.

Key Contributions:
- First complexity measure for reasoning procedures and complexity bounds for LLMs.

- Concrete characterization of reasoning limitations of LLMs - model scale up cannot overcome without changes in training methodology. 

- Theoretical explanations for limitations observed empirically in tasks like mathematical reasoning, logical puzzles etc.

- Proof that details of intermediate reasoning steps are critical for learning - answering only the question and final answer is insufficient.

- Analysis also points to potential directions for overcoming limitations by developing better training methods.

In summary, this paper makes important theoretical contributions towards demystifying and explaining the reasoning capacities and bottlenecks of large language models. The analysis and insights pave way for developing improved training to enhance reasoning abilities.
