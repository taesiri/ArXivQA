# [NoMIRACL: Knowing When You Don't Know for Robust Multilingual   Retrieval-Augmented Generation](https://arxiv.org/abs/2312.11361)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Retrieval-augmented generation (RAG) uses a retrieval system to ground an LLM's output in factual knowledge and reduce hallucinations. However, errors from the retrieval stage can mislead the LLM.
- Prior work lacks comprehensive LLM robustness evaluation across diverse languages when provided noisy retrieved passages.

Proposed Solution:  
- Introduce NoMIRACL, a dataset for evaluating LLM robustness across 18 typologically diverse languages when provided noisy retrieved Wikipedia passages.
- NoMIRACL contains a non-relevant subset (all passages manually labeled as non-relevant) and a relevant subset (at least one passage manually labeled as relevant).

Metrics:
- Hallucination rate - measures tendency to hallucinate an answer using non-relevant passages. 
- Error rate - measures failure to identify a relevant, answerable passage.

Contributions:
- Establish multilingual NoMIRACL dataset with non-relevant and relevant subsets.
- Provide GPT-4 baseline trained on NoMIRACL. GPT-4 struggles with high 33.2% hallucination rate on non-relevant subset.
- Observe positive correlation between hallucination rate and language resource size.
- Enable future research towards improving LLM robustness against noisy retrieved passages across languages.

In summary, the paper introduces NoMIRACL to evaluate and improve LLM robustness in handling errors from the retrieval stage across diverse languages. The analysis using GPT-4 reveals challenges for LLMs in reliably detecting non-relevant passages.
