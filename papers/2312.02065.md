# [Know Your Audience: Do LLMs Adapt to Different Age and Education Levels?](https://arxiv.org/abs/2312.02065)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper evaluates how well four large language models (LLMs) - two commercial (ChatGPT, GPT-3) and two open-source (BigScience, Flan-T5) - adapt their generated responses to science questions when prompted for different age groups and education levels. It assesses the readability of the LLM responses using standard metrics like Flesch-Kincaid. The authors find that while models like GPT-3 and Flan-T5 exhibit some expected trends in readability scores for certain education levels, overall the models do not reliably adapt their outputs to target age groups or difficulty levels, even when explicitly prompted. On average only 15% of responses fell into the recommended readability range. An additional classification test showed no significant measurable differences in the texts. The results indicate current LLMs have limited ability to tailor responses to suit different audiences, making them poorly suited for educational purposes where age-appropriate explanations are critical. The authors argue this demonstrates the need to enhance model adaptability, particularly for uses in education.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
The paper investigates how well large language models (LLMs) like ChatGPT can adapt their generated text to be appropriate for readers of different age groups and education levels when explicitly prompted to do so. This is an important capability for using LLMs in educational settings. 

Methodology:
The authors prompt 4 LLMs (ChatGPT, GPT-3, BigScience, Flan-T5) to answer 100 science questions for different target age groups (11 to 23 years old) and education levels (5th grade to college graduate). They collect and analyze 33,600 prompt-response pairs. Using Flesch-Kincaid readability metrics, they assess whether each LLM adapts the reading difficulty of its responses to match the reading comprehension level expected for the age/education level specified in the prompt.

Key Findings:  
- LLMs do not reliably adapt their responses to target different age groups and education levels, even when explicitly prompted.  
- Each LLM tends to produce responses in a narrow band of reading difficulty, regardless of prompts.
- The probability of an LLM generating a response with reading level appropriate for the prompted age/education is only ~15%. 

Main Contributions:
- Evidence that current LLMs have limited ability to adapt output reading level for different audiences 
- Demonstrates need to enhance LLM adaptability for education purposes
- Provides methodology and dataset for further research into LLM adaptation capabilities

In summary, the study reveals difficulties faced by current LLMs in adapting text for readers of different ages and education levels - an important capability for using LLMs effectively in education. The authors provide empirical evidence of this limitation and contribute a methodology and dataset to further advance research on improving LLM adaptability.
