# [PROC2PDDL: Open-Domain Planning Representations from Texts](https://arxiv.org/abs/2403.00092)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Planning in text-based environments is a major challenge for AI systems. Recent approaches have used language models (LMs) to generate plans, but this has limitations in performance and interpretability. 
- An alternative is to use LMs to translate natural language descriptions into planning domain definition language (PDDL). PDDL can then be solved by a planner.  
- However, all previous work has only evaluated such neurosymbolic methods in closed-domain simulated environments like a household or object placement. There is no evaluation in open-domain planning from texts.

Proposed Solution:
- The paper introduces Proc2Pddl, the first open-domain dataset containing procedural texts paired with expert-annotated PDDL representations. 
- It focuses on the task of action modeling - predicting the preconditions and effects of actions in PDDL, given some natural language texts and the header of the domain file that specifies types, predicates and action names.
- State-of-the-art LMs like GPT-3.5 and GPT-4 are evaluated on this action modeling task. A pipeline is introduced to modularly generate PDDL.

Main Contributions:
- First open-domain dataset linking procedural texts to PDDL to evaluate text-based planning
- Formulation and benchmark of the action modeling task - predicting PDDL action definitions 
- Experiments showing GPT-3.5 failing on this task while GPT-4 has 35% success rate
- Analysis of syntactic errors in generating PDDL and semantic errors in reasoning about events
- A dataset and benchmark to promote progress at integrating language models and formal planning

In summary, the paper introduces a new challenging open-domain planning dataset and task to address limitations of prior work, evaluates state-of-the-art LMs, provides an analysis of errors, and lays groundwork to combine strengths of LMs and planning.


## Summarize the paper in one sentence.

 This paper presents a new dataset called Proc2Pddl for evaluating models on translating open-domain procedural texts to PDDL representations, studies the challenging task of predicting action definitions in PDDL based on texts, and shows that large language models still struggle at this task, making both syntactic errors in generating PDDL and semantic errors in reasoning about actions.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1) It presents Proc2Pddl, the first open-domain dataset that contains pairs of natural language procedural texts and expert-annotated PDDL representations. This allows evaluating models on translating open-domain text to PDDL, going beyond existing closed-domain benchmarks.

2) It formulates the task of action modeling as predicting the parameters, preconditions, and effects of actions in a PDDL domain file, given the text, types, predicates, and action names. 

3) It shows through experiments that this task is very challenging for state-of-the-art language models like GPT-3.5 and GPT-4, with success rates close to 0% and around 35% respectively. Both syntactic and semantic errors are analyzed.

4) It provides some first attempts at this task, including zero-shot prompting, chain-of-thought prompting to improve modularization, and calculations of action equivalence. The analysis and dataset are intended to facilitate future progress.

In summary, the main contribution is the proposal and analysis of a new challenging NLP task situated at the intersection of language and planning, along with a novel open-domain dataset and preliminary modeling attempts.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper abstract and introduction, some of the key terms and concepts associated with this paper include:

- Planning domain definition language (PDDL) - A language used to represent planning domains and problems symbolically. The paper focuses on translating natural language descriptions to PDDL.

- Open-domain planning - Planning tasks not restricted to a narrow domain, but applicable more broadly. The paper introduces a new open-domain dataset. 

- Action modeling - Defining the preconditions and effects of actions in a planning domain. This is formulated in the paper as translating text to PDDL action definitions.

- Language models (LMs) - Neural network models trained on large amounts of text data that are able to generate text. The paper experiments with using LMs to translate text to PDDL.

- Zero-shot prompting - Using an LM to generate text for a novel task by providing a natural language description of the task without any training examples.

- Chain-of-thought prompting - Explicitly decomposing a complex task for an LM into simpler sub-tasks to improve performance.

- Domain file (DF) and Problem file (PF) - The components of a PDDL representation that define the planning domain and a specific problem instance respectively.

So in summary, the key topics are open-domain planning, translating natural language to symbolic PDDL representations, using large language models, and analyzing their ability to define executable planning actions.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper introduces a new dataset called Proc2Pddl for evaluating models' ability to generate PDDL representations from natural language texts. How does this dataset compare to existing datasets used in prior work on translating texts to PDDL? What are some key differences that make Proc2Pddl more challenging?

2. The paper formulates the problem as predicting action definitions (parameters, preconditions, effects) in the PDDL domain file given the domain header and procedural texts. What is the rationale behind assuming the availability of the domain header? How does this formulation compare to directly predicting the full domain file?

3. The paper experiments with zero-shot prompting of large language models like GPT-3.5 and GPT-4. What are some potential issues with few-shot prompting for this task that make zero-shot prompting more suitable? How could the zero-shot prompting approach be further improved?  

4. The paper introduces a chain-of-thought prompting technique to improve performance. What are the key ideas behind this technique and how does it lead to better translation from texts to PDDL actions? What are some limitations of this approach?

5. The quantitative evaluation involves both intrinsic evaluation of predicted action accuracy and extrinsic evaluation of solving problem files. What are the merits and demerits of each evaluation approach? How could the extrinsic evaluation be further strengthened?

6. What are some of the key error types observed in the analysis? Do these errors primarily indicate deficiencies in language generation, logical reasoning or domain-specific knowledge? How can these deficiencies be addressed?

7. How suitable do you think PDDL is as a representation for modeling real-world procedural knowledge compared to less formal planning languages? What enhancements could make PDDL more realistic and applicable? 

8. The paper focuses on predicting action definitions in PDDL domain files. How could the approach be extended to also predict other components like objects, initial states and goals in PDDL problem files?

9. Do you think the annotate-then-predict formulation could scale to much larger datasets required for real-world applications? What are some data augmentation techniques that could generate additional annotated data?

10. The paper conducts experiments exclusively with large pretrained language models. What are some potential benefits of using specialized neuro-symbolic models compared to general-purpose LMs for this task?
