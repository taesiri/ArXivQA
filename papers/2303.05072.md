# [Identification of Systematic Errors of Image Classifiers on Rare   Subgroups](https://arxiv.org/abs/2303.05072)

## What is the central research question or hypothesis that this paper addresses?

 The central research question addressed in this paper is: How can we systematically identify cases where image classifiers make errors on rare or underrepresented subgroups, when we do not have labeled examples from those subgroups?

The key ideas and contributions are:

- Leveraging recent advances in text-to-image models like Stable Diffusion to synthesize examples of rare subgroups specified through text prompts. This allows probing classifier performance on subgroups even if real examples are not available.

- A procedure called PromptAttack that explores a large space of subgroup prompts in a principled way using combinatorial testing. This allows identifying subgroups where classifiers show systematically worse performance.

- Demonstrating PromptAttack can uncover known issues like classifying certain images of people as apes. It also finds new subgroups for ImageNet classifiers where performance drops, requiring a conjunction of factors like color, pose, weather etc.

- Proposing a benchmark for evaluating systematic error identification methods, based on intentionally injecting errors on subgroups into zero-shot classifiers.

Overall, the key insight is that text-to-image synthesis can help probe classifier performance on rare subgroups beyond the available training/test data. The paper shows this can uncover known and previously unknown systematic errors, which is useful for improving model robustness, reliability and fairness.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing PromptAttack, a new procedure for identifying systematic errors of image classifiers based on synthetically generated images from text-to-image models conditioned on prompts encoding subgroup information. 

2. Using combinatorial testing to explore a large subset of subgroups from an operational design domain, achieving near-equable coverage of the subgroups.

3. Introducing a benchmark for evaluating systematic error identification methods based on zero-shot classifiers constructed from CLIP.

4. Applying PromptAttack to ImageNet classifiers and identifying novel systematic errors on rare subgroups, including fairness issues related to misclassifying people.

In summary, the paper introduces a novel method leveraging advances in text-to-image models to systematically test image classifiers on rare subgroups defined by combinations of semantic attributes. The quantitative and qualitative results demonstrate PromptAttack can effectively identify systematic errors missed by prior work. The main innovations are the conditional image synthesis for subgroup exploration and the use of combinatorial testing for coverage.
