# [Identification of Systematic Errors of Image Classifiers on Rare   Subgroups](https://arxiv.org/abs/2303.05072)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is: How can we systematically identify cases where image classifiers make errors on rare or underrepresented subgroups, when we do not have labeled examples from those subgroups?The key ideas and contributions are:- Leveraging recent advances in text-to-image models like Stable Diffusion to synthesize examples of rare subgroups specified through text prompts. This allows probing classifier performance on subgroups even if real examples are not available.- A procedure called PromptAttack that explores a large space of subgroup prompts in a principled way using combinatorial testing. This allows identifying subgroups where classifiers show systematically worse performance.- Demonstrating PromptAttack can uncover known issues like classifying certain images of people as apes. It also finds new subgroups for ImageNet classifiers where performance drops, requiring a conjunction of factors like color, pose, weather etc.- Proposing a benchmark for evaluating systematic error identification methods, based on intentionally injecting errors on subgroups into zero-shot classifiers.Overall, the key insight is that text-to-image synthesis can help probe classifier performance on rare subgroups beyond the available training/test data. The paper shows this can uncover known and previously unknown systematic errors, which is useful for improving model robustness, reliability and fairness.
