# [Learning Safety Constraints From Demonstration Using One-Class Decision   Trees](https://arxiv.org/abs/2312.08837)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper introduces a novel approach for learning safety constraints from expert demonstrations using one-class decision trees. The key idea is to model the safe expert behavior as a convex set in a feature space. This is achieved by training a one-class decision tree on state-action tuples from the expert trajectories mapped to the feature space. The tree represents the safe set through a union of hyper-rectangles. Subsequently, a logical formula in disjunctive normal form defining the constraints is extracted from the tree. This formula is used within a constrained reinforcement learning framework as a cost function to train policies adhering to the learned constraints. A key advantage of this approach is the interpretability of both the safe set and constraints. Additionally, the method requires no knowledge about environment dynamics or reward functions. The authors evaluate their technique in several synthetic environments from a standardized safety gym benchmark and in a realistic highway driving simulator. Results demonstrate improved safety and performance over baseline reinforcement learning methods, showcasing the promise of this approach for learning interpretable safety constraints from demonstrations.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Reinforcement learning (RL) agents can behave unsafely when deployed in physical environments. Defining reward and cost functions to ensure safety is complex and error-prone.
- Existing constrained RL methods assume availability of well-defined constraints, but specifying correct and complete constraints is challenging.

Proposed Solution:
- Learn safety constraints from expert demonstrations using one-class decision trees. 
- Decision trees provide logical formula in disjunctive normal form representing constraints.
- Use learned constraints within oracle constrained RL framework to obtain safe policy.

Key Contributions:
- Novel approach to learn interpretible constraints from demonstrations using one-class decision trees.
- Extract logical formula from tree to define constraints in disjunctive normal form.
- Employ constraints within PPO-Lagrangian constrained RL method.
- Propose post-training pruning to refine constraints and improve interpretability.
- Constraints can be transferred across agents and tasks once learned.
- Evaluate proposed method in synthetic safety gym benchmarks and real-world driving environment.
- Show improved safety and performance over RL without constraints and RL with hand-engineered rewards.

In summary, this paper introduces an interpretable approach to learn safety constraints from expert demonstrations using decision trees. The acquired logical formula representing constraints is then utilized by a constrained RL method to obtain policies that are safe and high-performing. A key advantage is the ability to transfer learned constraints across agents and tasks. Experiments validate the effectiveness for improving safety in synthetic and realistic environments.
