# [Unsupervised Semantic Correspondence Using Stable Diffusion](https://arxiv.org/abs/2305.15581)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be whether one can leverage the semantic knowledge within text-to-image diffusion models like Stable Diffusion to find semantic correspondences between images, without any training specific to semantic correspondence tasks. The key hypothesis is that since diffusion models are capable of generating realistic images from just text prompts, they must have built-in knowledge about semantics and correspondences between visual concepts. By optimizing the prompt embeddings to activate attention on regions of interest in one image, the correspondences can be transferred to new images by reusing the prompt embeddings.In summary, the paper is exploring whether the knowledge encoded in pre-trained diffusion models can be extracted and applied to semantic correspondence tasks in a zero-shot transfer manner, without task-specific training. The central hypothesis is that the semantic knowledge required for correspondence is already present in the models' parameters and attention mechanisms.
