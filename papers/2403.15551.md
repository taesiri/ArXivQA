# [Language-Based Depth Hints for Monocular Depth Estimation](https://arxiv.org/abs/2403.15551)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Monocular depth estimation (MDE) is an ill-posed problem due to inherent ambiguity. A given 2D image can result from infinite 3D scenes. 
- MDE methods must make assumptions about likely 3D scenes for a given input image. These can be explicit (hard-coded into model) or implicit (learned from data).

Proposed Solution:  
- Use natural language as an explicit source of prior about world structure. Hypothesize language encodes likely depth distribution of objects.
- First show language model encodes depth bias, and extract it using a simple learned approach. 
- Then provide the prediction as an explicit assumption to an MDE system using an off-the-shelf instance segmentation model.

Main Contributions:
1. Demonstrate existence of depth bias in BERT relating objects to likely depth values, and present method to extract this.
2. Show novel way to incorporate bias into existing MDE system in an adaptable way.
3. Achieve improved performance compared to baseline and random controls on NYUD2 dataset.

Proposed Method:
- Pipeline has RGB-to-depth model and language-to-depth (L2D) model. 
- Instance segmentation provides per-pixel labels to bridge image and L2D model.
- L2D model pretrained to extract depth bias from BERT. Two versions tested - classification and log-mean regression.
- L2D prediction combined with RGB input for main MDE model (AdaBins-B1).

Experiments/Results:
- Confirmed existence of depth bias in BERT embeddings.
- Incorporating L2D prediction improves MDE performance over baseline. Best model uses BERT-Tiny embeddings.
- Simple "inst" pretrained L2D model outperforms more complex "leave-one-out" version.

Future Work: 
- Explore nature of language model depth biases further
- Enhance L2D models to better extract depth bias from BERT
