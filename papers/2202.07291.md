# [Exploring Discontinuity for Video Frame Interpolation](https://arxiv.org/abs/2202.07291)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is how to make video frame interpolation networks robust to discontinuous motions like logos, user interfaces, subtitles, etc., which violate the assumption of continuous motion between frames. 

The key ideas proposed to address this question are:

1) A new data augmentation strategy called Figure-Text Mixing (FTM) that mixes synthetic discontinuous elements like static figures and moving text into the training data. This allows models to learn to handle discontinuous motion without needing extra training datasets.

2) A Discontinuity Map (D-map) module that predicts a 1-channel map indicating discontinuity between frames. The D-map allows switching between continuous motion interpolation and simply copying pixels from the previous frame for discontinuous areas.

3) Objective functions to provide supervision for the D-map prediction when FTM augmentation is used, since the augmented elements provide ground truth discontinuity.

The central hypothesis is that by augmenting training data and explicitly modeling discontinuity, they can make existing video frame interpolation networks perform better on videos containing discontinuous motion elements without degrading performance on regular continuous motion videos.
