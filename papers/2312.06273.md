# [Regroup Median Loss for Combating Label Noise](https://arxiv.org/abs/2312.06273)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a new method called Regroup Median Loss (RML) to combat label noise in deep learning. Label noise caused by incorrect annotations is inevitable in large datasets, harming model performance. Existing methods select clean samples based on small losses, but some noisy samples have similar losses, causing issues. RML reduces the probability of selecting noisy samples by processing losses. It then estimates robust losses for noisy samples by randomly regrouping selected samples and taking the median between subgroup mean losses and the sample's loss. This process is theoretically proven to bound the loss estimation error. RML also enables a semi-supervised approach to further utilize noisy samples. Experiments on CIFAR and real-world datasets like Clothing1M and WebVision show RML consistently improves accuracy over state-of-the-art by 1-8\%. The method also enables the best semi-supervised performance. By effectively handling label noise, RML advances the capability to train models on imperfect real-world data.
