# [Self-Supervised Video Forensics by Audio-Visual Anomaly Detection](https://arxiv.org/abs/2301.01767)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question it addresses is: Can video manipulation be detected through self-supervised anomaly detection using audio-visual synchronization features, without requiring any manipulated training examples?Specifically, the key hypothesis appears to be:Videos that have manipulated speech/faces will contain subtle inconsistencies between the visual and audio signals. By modeling the joint distribution of audio-visual synchronization features extracted from real unlabeled videos, manipulated videos can be identified as anomalies/outliers at test time.In summary, the paper proposes and evaluates an unsupervised anomaly detection approach for video forensics, using features that capture audio-visual synchronization patterns learned from real videos. The key hypothesis is that this method can identify manipulated videos as anomalies, despite being trained solely on real examples.


## What is the main contribution of this paper?

The main contributions of this paper are:- Proposing a video forensics method based on anomaly detection that can be trained solely on real, unlabeled videos. The key idea is to detect subtle inconsistencies between visual and audio signals that may indicate manipulation.- Introducing the concept of "synchronization features", which are audio-visual features designed to convey temporal alignment between vision and sound streams in a video. The paper evaluates different options for synchronization features.- Showing that an autoregressive model can be trained on sequences of synchronization features extracted from real videos, and then used to detect anomalies at test time by assigning low probability to manipulated videos.- Demonstrating strong performance on detecting manipulated speech videos by evaluating on the FakeAVCeleb and KoDF datasets. The method generalizes well despite being trained only on real videos from other datasets.- Analyzing the robustness of the method to various perturbations like compression, blurring, etc. as well as showing generalization to unseen languages.Overall, the key contribution is developing a self-supervised anomaly detection approach for video forensics that relies only on unlabeled real training data. This is enabled by using synchronization features that capture consistency between modalities.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:This paper proposes a self-supervised video forensics method that detects manipulated videos by modeling the distribution of audio-visual synchronization features extracted from real videos and identifying test videos with anomalous feature sequences as potential fakes.


## How does this paper compare to other research in the same field?

This paper makes several key contributions to the field of audio-visual video forensics:- It proposes a new self-supervised approach for detecting manipulated videos by training only on real, unlabeled videos. Most prior work has relied on supervised training with fake examples labeled. The self-supervised approach allows the method to detect new types of fakes it has not seen during training.- It introduces the idea of using audio-visual "synchronization features" for anomaly detection. These capture subtle temporal relationships between visual frames and audio that may reveal manipulations. Prior work has not explicitly used such synchronization feature sets.- It shows strong results on standard forensics benchmarks like FakeAVCeleb and KoDF using the proposed self-supervised approach with synchronization features. The method achieves accuracy rivaling supervised techniques despite no fake data during training.- It demonstrates generalization to unseen perturbations like blurring/compression and unseen languages during inference without retraining. This helps address common issues in forensics methods overfitting to seen data.- It provides ablation studies analyzing the impact of different synchronization feature sets. This sheds light on what specific types of audio-visual relationships are most indicative of manipulations.Overall, the key novelty is the idea of self-supervised anomaly detection using audio-visual synchronization. This allows manipulating unseen fake data and generalizes better than supervised alternatives. The synchronization features are tailored for finding audio-visual mismatches indicative of manipulations. The results demonstrate the viability of this approach and that temporal audio-visual relationships contain important manipulation cues.
