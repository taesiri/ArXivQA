# [Random Sub-Samples Generation for Self-Supervised Real Image Denoising](https://arxiv.org/abs/2307.16825)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: How can we develop an effective self-supervised learning method for real image denoising that does not require paired noisy/clean training data? 

The key points are:

- Supervised deep learning methods require paired noisy/clean images for training, which are difficult to obtain for real-world images. 

- Existing self-supervised methods like Noise2Void make assumptions (e.g. pixel-wise independent noise) that are not valid for real images.

- The authors propose a new self-supervised framework called SDAP that uses random sub-samples generation and a cyclic sampling difference loss to achieve state-of-the-art results in real image denoising without needing paired training data.

So in summary, the main research question is how to do effective self-supervised real image denoising without paired training data, which SDAP aims to address through its proposed methods.


## What is the main contribution of this paper?

 Here are the main contributions of this paper:

- The paper proposes a new self-supervised real image denoising framework called Sampling Difference As Perturbation (SDAP) based on Random Sub-samples Generation (RSG) with a cyclic sample difference loss. 

- It provides a new perspective that adding appropriate perturbations to the training data can improve the performance of Blind-Spot Network (BSN) for self-supervised denoising. The paper suggests using the difference between sub-samples generated by sampling as a type of perturbation.

- It proposes the random sub-samples generation (RSG) strategy to obtain more diverse sub-samples and make the sampling difference closer to random perturbation compared to pixel-shuffle downsampling (PD).

- A new cyclic sampling difference BSN loss is proposed to make full use of the sub-samples generated by RSG.

- Extensive experiments show the proposed method outperforms state-of-the-art self-supervised denoising methods on real-world datasets like SIDD and DND.

In summary, the key novelty is proposing the idea of using sampling difference as perturbation for self-supervised real image denoising, as well as the associated techniques like RSG and the new cyclic loss function. The proposed SDAP framework achieves new state-of-the-art results on benchmark datasets.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a new self-supervised real image denoising framework called Sampling Difference As Perturbation (SDAP) based on Random Sub-samples Generation (RSG) and a cyclic sample difference loss, which outperforms state-of-the-art self-supervised denoising methods on real-world datasets without requiring paired training data.


## How does this paper compare to other research in the same field?

 Here are a few key points comparing this paper to other research in self-supervised image denoising:

- This paper focuses on real image denoising, which is more challenging than denoising synthetic noisy images. Many previous self-supervised methods like Noise2Void are designed for synthetic noise and don't work as well on real images. 

- The paper points out limitations of prior self-supervised methods like AP-BSN that make assumptions about independent pixel noise. Real noise is spatially correlated so these methods don't translate well. This paper adapts the blind spot network idea to handle real image characteristics better.

- The proposed Sampling Difference as Perturbation (SDAP) method introduces novel components like random sub-sample generation and a cyclic sampling difference loss. These provide more varied training data and help the network generalize better to real images.

- Experiments show SDAP outperforms recent state-of-the-art self-supervised denoising methods on standard real image datasets like SIDD and DND. The gains over methods like AP-BSN and CVF-SID are significant.

- SDAP achieves results competitive with some supervised methods that require paired noisy/clean training data which is difficult to obtain for real images. This demonstrates the promise of self-supervised techniques.

Overall, this paper pushes self-supervised denoising capabilities forward, especially for real images. The sampling strategies and cyclic loss provide useful insights that could benefit other self-supervised approaches as well. The results demonstrate self-supervised methods can reach performance levels comparable to supervised techniques for this task.


## What future research directions do the authors suggest?

 The authors suggest a few promising future research directions:

1. Reviving more traditional self-supervised objectives in the deep learning era: The authors argue that many traditional self-supervised objectives like context prediction and solving jigsaw puzzles could be revisited and may achieve compelling performance with modern deep architectures. Exploring how to adapt these ideas to deep networks could lead to advances.

2. Scaling self-supervision to more data and larger models: Self-supervision has made good progress but has not yet matched the performance of supervised learning on large benchmark datasets and models. Scaling up self-supervised techniques to work well with more data and larger models is an important direction.

3. Combining self-supervised learning with semi-supervised learning: The authors argue that semi-supervised techniques that make use of limited labeled data together with unlabeled data are complementary to self-supervision. Finding optimal ways to combine these approaches is a promising direction.

4. Utilizing recent contrastive learning insights: Contrastive self-supervised methods have shown marked improvements, suggesting value in better understanding and extending contrastive techniques. For example, exploring multi-view contrasting beyond image transforms.

5. Improving transfer learning from self-supervised representations: While some methods show promising transfer results, transfer is less well understood for self-supervised techniques. Advancing transferability is key for widespread practical use.

6. Combining self-supervision with different supervision types: Beyond combinations with standard supervised learning, exploring integrations with weak supervision forms like image tags or video narration could be fruitful.

So in summary, some key future directions involve revisiting traditional pretext tasks, scaling up self-supervision, combining it with semi-supervised and transfer learning, utilizing contrastive techniques, and integrating it with varied supervision signals. Advances in these areas could help progress self-supervised learning.


## Summarize the paper in one paragraph.

 The paper proposes a novel self-supervised real image denoising framework called Sampling Difference As Perturbation (SDAP) based on Random Sub-samples Generation (RSG) with a cyclic sample difference loss. It first analyzes the limitations of the blind spot network (BSN) when applied to real-world denoising and finds that adding appropriate perturbations to the training data can improve BSN's performance. The paper suggests using the difference between sub-samples generated by sampling as a type of perturbation. To obtain more random perturbations and sub-samples, it proposes an RSG strategy. Based on this, it introduces a new cyclic sampling difference loss for training BSN and proposes a new BSN framework combined with RSG. Experiments on real-world datasets like SIDD and DND show the proposed method significantly outperforms other state-of-the-art self-supervised denoising methods.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points from the paper:

This paper proposes a new self-supervised framework called Sampling Difference As Perturbation (SDAP) for real image denoising based on blind-spot networks (BSNs). The key idea is to use the difference between random sub-samples of an image as a form of perturbation to improve BSN training. The authors first analyze why BSN performance is limited for real image denoising, showing that adding appropriate perturbations to the training data can enhance results. They suggest using the difference between sub-samples from techniques like pixel-shuffle downsampling as a suitable perturbation. To generate more diverse sub-samples, they propose a random sub-sample generation (RSG) strategy. RSG divides the image into patches, randomly shuffles pixels within each patch, then reassembles to create multiple similar but different sub-images. The cyclic sampling difference loss function makes use of all sub-samples.

For training, noisy images are sampled into sub-images with RSG, denoised by BSN, and optimized based on the difference between original and denoised sub-images. For testing, pixel-shuffle downsampling is used for stability. The denoised sub-images are stitched together and further denoised to reduce artifacts. Experiments on real image datasets SIDD and DND show SDAP outperforms state-of-the-art self-supervised methods. The key contributions are the idea of using sampling difference as perturbation for BSN training and the proposed RSG strategy and cyclic loss to enable effective self-supervised real image denoising.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes a new self-supervised real image denoising framework called Sampling Difference As Perturbation (SDAP) based on Random Sub-samples Generation (RSG) with a cyclic sample difference loss. 

The key ideas are:

- Blind spot networks (BSN) like Noise2Void assume pixel-wise independent noise and perform poorly on real images with spatially correlated noise. 

- Adding appropriate perturbations to the training images can help improve BSN's performance. The difference between sub-samples acts as a natural perturbation.

- They propose random sub-sample generation (RSG) to obtain more varied random sub-samples compared to fixed pixel downsampling. The differences between sub-samples act as perturbations.

- They use a cyclic sampling difference loss to make full use of the random sub-samples during training. 

- For testing, they use pixel downsampling which is more stable than RSG. They further refine the results by denoising again to reduce artifacts.

- Experiments show the proposed SDAP framework with RSG and cyclic loss outperforms state-of-the-art self-supervised denoising methods on real-world datasets like SIDD and DND.


## What problem or question is the paper addressing?

 Based on my reading, the key points about the problem addressed in this paper are:

- Supervised deep learning methods have shown great performance for image denoising when there are sufficient paired training images. However, it is challenging to obtain such paired real noisy and clean images. 

- Existing self-supervised denoising methods have limitations when applied to real-world images, as they make strict assumptions like the noise being pixel-wise independent. This does not hold for real image noise.

- The original blind spot network (BSN) method assumes pixel-wise independent noise and performs well on synthetic data. But it has limited performance on real images due to lack of training data and violation of its noise assumption.

- The authors aim to develop an effective self-supervised framework for real image denoising that does not require paired training data, relaxes the restrictive assumptions of prior methods, and outperforms state-of-the-art techniques.

In summary, this paper proposes a new self-supervised framework for real image denoising to overcome the need for paired training data and limitations of assumptions in previous self-supervised methods. The key goal is developing a practical denoising approach that works well on real-world image datasets.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Self-supervised learning - The paper proposes a self-supervised framework for real image denoising that does not require paired noisy-clean images for training.

- Real image denoising - The paper focuses on removing noise from real-world images, as opposed to synthetically generated noise.

- Blind spot network (BSN) - A type of deep network proposed in Noise2Void that can be trained in a self-supervised manner by masking portions of the input image. The paper proposes improvements to BSN for real image denoising.

- Sampling difference - The paper views the difference between sub-images generated through sampling strategies like pixel shuffle as a form of perturbation for training BSN.

- Random sub-samples generation (RSG) - A proposed sampling strategy to generate multiple augmented views of an image to create training pairs for BSN.

- Cyclic sampling difference loss - A proposed training loss function that uses pairs of sub-images generated through RSG in a cyclic manner to train BSN.

- Real-world noise characteristics - The paper considers issues like spatially correlated noise and noise introduced by image processing pipelines, which differ from simplified synthetic noise models.

- Performance on real datasets - The method is evaluated on real-world denoising datasets like SIDD and DND and shown to outperform prior self-supervised techniques.

In summary, the key focus is using techniques like RSG and cyclic loss functions to train BSN in a self-supervised manner tailored for real image denoising, without relying on paired training data.
