# [Don't be a Fool: Pooling Strategies in Offensive Language Detection from   User-Intended Adversarial Attacks](https://arxiv.org/abs/2403.15467)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Offensive language online is a growing issue, but malicious users find ways to evade filtering systems by adding typographical errors or character substitutions.  
- There has been limited exploration of such evasions in Korean language specifically, which has distinct features like characters being further subdivided.
- The paper terms such evasive tactics as "user-intended adversarial attacks" and categorizes them into: (1) Inserting meaningless strings/spaces/symbols (2) Copying the initial/middle/final sound of one Korean character to another (3) Decomposing a character into its constituent sounds.

Proposed Solution: 
- Instead of relying only on the final encoder layer's output, the paper utilizes "layer-wise pooling strategies" to selectively aggregate useful features from all layers.  
- Strategies introduced: Mean pooling, max pooling, weighted pooling, first-last pooling.
- These strategies leverage preceding layers' outputs too which focus more on token embeddings.
- Allows capturing both offensiveness (from later layers) and degree of textual attacks (from earlier layers).

Main Contributions:
- Proposes the evasive tactics as adversarial attacks grounded in real malicious behavior online.
- Introduces simple yet effective layer-wise pooling strategies to defend against these attacks without directly training them.
- Shows pooling strategies are robust even when attack rate is increased, achieving comparable performance to models trained on noisy texts.  
- Demonstrates importance of leveraging first and last layers rather than middle layers for detecting attacked offensive language.
- Establishes flexibility of pooling strategies - improves performance of both clean text models and noisy text models.
