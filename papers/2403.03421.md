# [LEAD: Learning Decomposition for Source-free Universal Domain Adaptation](https://arxiv.org/abs/2403.03421)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper focuses on the problem of universal domain adaptation (UniDA), where there are shifts in both the data distributions (covariate shift) as well as the label spaces (label shift) across domains. Specifically, it tackles the more challenging source-free UniDA (SF-UniDA) setting, where labeled source data are unavailable during adaptation. The key challenge lies in distinguishing target samples belonging to common label spaces versus those from target-private "unknown" categories, without any prior knowledge about the label shifts. Existing SF-UniDA methods address this either through hand-crafted thresholding on predictions or by developing iterative clustering strategies, both of which have limitations.

Proposed Solution: 
The paper proposes a new Learning Decomposition (LEAD) framework that decomposes features into source-known and source-unknown parts to identify target-private data. The key idea is that target-private data likely contain more components from the source-unknown space even under covariate shifts. Specifically, LEAD:

1) Performs orthogonal decomposition using SVD to decompose features into source-known and source-unknown subspaces. 

2) Models the distribution of source-unknown feature magnitudes via a 2-component GMM to estimate modes of common and private data.

3) Defines a "common score" metric that accounts for distances to both target prototypes and source anchors to derive instance-level decision boundaries for identifying target-private data.

Main Contributions:
- Proposes the new LEAD framework for SF-UniDA that provides an elegant solution for target-private data identification without tedious threshold tuning or reliance on iterative unstable clustering.

- Achieves state-of-the-art performance across various SF-UniDA scenarios (PDA, OSDA, OPDA) on datasets like Office-Home, Office-31, VisDA and DomainNet.

- Demonstrates the complementarity of LEAD by integrating it with prior SF-UniDA methods like UMAD and GLC to obtain further performance gains. For instance, improves UMAD's OPDA H-score on Office-Home from 70.1% to 78.0%.

- Reduces the compute time for deriving decision boundaries by over 75% compared to clustering-based methods like GLC that scale poorly with data size.
