# [Explanatory Learning: Beyond Empiricism in Neural Networks](https://arxiv.org/abs/2201.10222v1)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can machines be enabled to learn how to interpret symbolic knowledge (explanations, rules, etc.) on their own, without relying solely on hard-coded logic provided by humans?

The key ideas and contributions towards addressing this question appear to be:

1) Introducing the Explanatory Learning (EL) framework, which formalizes the problem of learning to interpret symbolic knowledge from examples of (explanation, observations) pairs. 

2) Presenting Odeen, a simulated environment for testing EL approaches, which is inspired by games like Zendo.

3) Proposing Critical Rationalist Networks (CRNs), a model architecture designed according to rationalist epistemology, which learns a separate interpreter and conjecture generator from data.

4) Demonstrating through experiments on Odeen that CRNs can discover explanations for new phenomena more effectively than end-to-end empirical neural network models.

So in summary, the central hypothesis seems to be that rationalist-inspired models like CRNs will be better at interpreting and learning from symbolic knowledge than pure empiricist neural networks. The Odeen environment and EL framework provide a way to test this hypothesis.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It introduces the Explanatory Learning (EL) framework, which formulates the problem of learning to interpret symbolic explanations paired with observations as a machine learning task. This provides a unified perspective on related problems like learning regular languages or captioned image datasets.

2. It presents Odeen, a new dataset and environment for studying EL. Odeen simulates a scientist discovering rules in a simple "flatland" universe, providing a testbed for EL algorithms.

3. It proposes Critical Rationalist Networks (CRNs), a model designed according to rationalist epistemology, as a solution to EL problems. CRNs have an explicit separation between symbolic conjectures and an interpreter learned from data.

4. It shows experimentally that CRNs can successfully discover symbolic explanations on the Odeen dataset, outperforming end-to-end neural models. The paper argues CRNs are more interpretable, adjustable, and confident compared to these neural baselines.

In summary, the main contribution seems to be proposing the EL framework and CRN model as a rationalist approach to learning structured knowledge, supported by the Odeen dataset/environment and experimental results. The key ideas are learning to interpret explanations rather than just predict, and separating conjecture generation from learned interpretation.
