# [TTT-KD: Test-Time Training for 3D Semantic Segmentation through   Knowledge Distillation from Foundation Models](https://arxiv.org/abs/2403.11691)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Generalizing 3D semantic segmentation models to different datasets is challenging due to domain shifts such as different sensors, noise levels, scene compositions, etc. While unsupervised domain adaptation (UDA) methods have been proposed, they require access to unlabeled target data and work when the target domain is known in advance. The authors propose a test-time training (TTT) approach that can adapt networks on-the-fly when they encounter unseen distributions without needing target data.

Method:
The authors propose TTT-KD, the first TTT method for 3D semantic segmentation. It uses knowledge distillation (KD) from 2D foundation models (e.g. DINOv2) as a self-supervised objective to adapt weights at test-time. 

During training, TTT-KD jointly optimizes a 3D backbone for semantic segmentation using pointcloud labels and for 2Dâ†’3D KD using images. Two projectors predict semantics and distill knowledge respectively from the 3D backbone's features.

At test-time, for each sample, TTT-KD performs gradient descent on the KD loss to update network weights before freezing the network and making the final semantic prediction. By improving on KD, it adapts the weights to the particular sample distribution.

Contributions:

- First TTT approach for 3D semantic segmentation that can adapt to distribution shifts for each test scene without needing target data

- Uses KD from 2D foundation models as a self-supervised objective for test-time fine-tuning 

- Agnostic to choice of 3D backbone and 2D teacher model

- Shows significant gains both for in-distribution (up to +8.5 mIoU) and out-of-distribution (up to +45 mIoU) test scenes across multiple benchmarks

- Computationally inexpensive compared to other TTA methods with an online version requiring only 1 extra backprop per scene
