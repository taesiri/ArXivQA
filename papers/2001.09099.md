# [TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval](https://arxiv.org/abs/2001.09099)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research focus is on developing a new dataset (TVR) and model (XML) for the task of multimodal video moment retrieval, where the goal is to retrieve specific moments from a video corpus using natural language queries. The key ideas and contributions appear to be:- Introducing the TVR dataset, which contains over 100K annotated queries for retrieving moments in videos paired with subtitles. This supports the multimodal moment retrieval task using both video and text. - Proposing the XML model for efficiently retrieving moments from a large video corpus using late fusion of video and text features along with a novel Convolutional Start-End module.- Analyzing XML and showing it outperforms previous methods on the multimodal moment retrieval task while being more computationally efficient.So in summary, the central hypothesis seems to be that leveraging both video and associated text (subtitles) is important for the video moment retrieval task, and the XML model provides an effective and scalable approach to do this retrieval from a large video corpus. The TVR dataset enables research on this multimodal task.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions seem to be:1. Introduction of a new dataset called TVR for multimodal video-subtitle moment retrieval. TVR contains over 100K queries on 21K videos from 6 TV shows. It requires using both video and associated subtitles for retrieval. TVR is analyzed to be more diverse and challenging than previous datasets.2. Proposal of a Cross-Modal Moment Localization (XML) model for efficient and accurate retrieval on the corpus-level VCMR task. The key component is a novel Convolutional Start-End detector (ConvSE) that learns to detect start and end positions from similarity signals. Experiments show XML with ConvSE outperforms previous methods.3. Collection of additional descriptions for TVR moments to form a new multimodal video captioning dataset called TVC with over 260K captions. Baselines are provided for the dataset.In summary, the main contributions appear to be: 1) the introduction of two new large-scale multimodal datasets TVR and TVC, and 2) the proposal of the XML model with ConvSE for efficient and accurate video-subtitle moment retrieval on these datasets. The paper provides comprehensive analyses and experiments demonstrating the value of the datasets and proposed method.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other research in video moment retrieval:- It introduces a new multimodal dataset (TVR) that requires using both video and associated text (subtitles) for retrieval. Other popular datasets like DiDeMo, Charades-STA, etc. focus only on visual retrieval. So TVR introduces a more realistic and challenging setting.- It proposes a new model (XML) that uses a late fusion approach to integrate visual and text features. Many prior works use early fusion which can be computationally expensive. Late fusion allows precomputing visual features, thereby improving efficiency. - The paper presents a novel Convolutional Start-End detector module that learns to identify start and end timestamps from similarity scores. Other methods rely more on handcrafted rules or sliding windows for locating moments.- Experiments show the proposed XML model outperforms previous methods by a good margin on the new TVR dataset. The results highlight the benefits of the late fusion design and the ConvSE detector.- The paper also collects additional captions on the TVR dataset to form a new large-scale multimodal video captioning dataset TVC. This extends the scope and potential impact of the paper.Overall, this paper pushes multimodal video retrieval research forward through the introduction of new datasets, models, and analyses. The late fusion design and ConvSE detector seem like useful advancements over prior art.
