# [Semantic Scene Completion with Cleaner Self](https://arxiv.org/abs/2303.09977)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research focus of this paper is how to handle the inherent noise in depth values when predicting semantic 3D scene completion from an RGB image and depth input. The depth noise leads to two main problems:

1) Incomplete surface reconstruction due to zero noise where the depth sensor cannot estimate depth in some regions. This leads to incomplete 3D predictions. 

2) Confused semantic labels due to delta noise where the depth value deviates from the ground truth. This results in voxels getting wrong semantic labels.

The main hypothesis is that training with ground truth noise-free depth values can provide cleaner knowledge that can be transferred to a model that takes real noisy depth as input at test time. The key research questions are:

- Can a teacher model trained on perfect depth provide useful knowledge to guide a student model trained on noisy depth to handle the two noise issues?

- What distillation strategies are most effective for transferring the cleaner knowledge - feature-based, logit-based, or both?

- Does this knowledge transfer lead to improved scene completion and semantic scene completion compared to models trained only on noisy depth data?

So in summary, the core research focus is on leveraging knowledge distillation to mitigate the effects of inherent depth noise during training for improving semantic 3D scene completion at test time when only noisy depth is available.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a novel Cleaner Self (CleanerS) framework for Semantic Scene Completion (SSC) that can mitigate the negative effects of noisy depth values during training. 

2. It identifies two common types of noise in depth values - zero noise and delta noise - and analyzes their impacts on SSC performance.

3. It trains a teacher network on noise-free depth values rendered from 3D voxel ground truth to learn "cleaner" knowledge. This is then transferred to a student network with noisy depth values via knowledge distillation.

4. Specifically, it uses feature-based and logit-based distillation strategies to transfer occupancy and semantic knowledge from the teacher to student network. 

5. Extensive experiments show the proposed CleanerS framework improves performance over noisy counterparts by 3.1% in scene completion IoU and 2.2% in SSC mIoU.

6. It achieves new state-of-the-art results on the challenging NYU dataset for SSC using noisy depth values as input.

In summary, the key contribution is a novel training framework called CleanerS that can learn from noise-free data to improve a model that takes noisy data as input for the SSC task. This is done through specific feature and logit based knowledge distillation strategies.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points in the paper:

The paper proposes a Cleaner Self framework for Semantic Scene Completion that uses knowledge distillation from a teacher network trained on noise-free data to help improve a student network trained on noisy data, achieving state-of-the-art results on the NYU dataset without needing ground truth at inference time.


## How does this paper compare to other research in the same field?

 This paper presents a new approach for semantic scene completion (SSC) that addresses key limitations of prior work, particularly in handling noise in the input depth data. Here is a high-level comparison to related work:

- Most prior SSC methods take noisy depth data as input, which leads to problems like incomplete predictions and confused semantics. This paper is the first to focus on mitigating the negative effects of noisy depth inputs.

- Some recent works use ground truth depth data for training SSC models. However, they still require clean depth at test time, which is impractical. This paper transfers knowledge from clean data to the noisy pipeline only during training. 

- For handling noise, common approaches are data denoising or learning robust features. This paper proposes a novel "cleaner self" framework of distilling knowledge from a teacher (trained on clean data) to student (trained on noisy data).

- State-of-the-art SSC methods are based on TSDF, points, or RGB-D fusion. This paper also adopts a hybrid approach of RGB image + TSDF volumes, but contributes new distillation objectives tailored for SSC.

- Both feature-level and output-level distillation are explored, finding global semantic distillation more effective than local voxel distillation due to input differences.

- Experiments demonstrate state-of-the-art results on the challenging NYU dataset. The framework improves noisy counterparts, achieving gains of 3.1% in scene completion and 2.2% in semantic completion.

In summary, this paper makes key contributions in analyzing and addressing the impact of depth noise on SSC, via a novel knowledge distillation approach that does not require ground truth depth at test time. The gains over prior art validate it as a new state-of-the-art technique.
