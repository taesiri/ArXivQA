# [Semantic Scene Completion with Cleaner Self](https://arxiv.org/abs/2303.09977)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research focus of this paper is how to handle the inherent noise in depth values when predicting semantic 3D scene completion from an RGB image and depth input. The depth noise leads to two main problems:

1) Incomplete surface reconstruction due to zero noise where the depth sensor cannot estimate depth in some regions. This leads to incomplete 3D predictions. 

2) Confused semantic labels due to delta noise where the depth value deviates from the ground truth. This results in voxels getting wrong semantic labels.

The main hypothesis is that training with ground truth noise-free depth values can provide cleaner knowledge that can be transferred to a model that takes real noisy depth as input at test time. The key research questions are:

- Can a teacher model trained on perfect depth provide useful knowledge to guide a student model trained on noisy depth to handle the two noise issues?

- What distillation strategies are most effective for transferring the cleaner knowledge - feature-based, logit-based, or both?

- Does this knowledge transfer lead to improved scene completion and semantic scene completion compared to models trained only on noisy depth data?

So in summary, the core research focus is on leveraging knowledge distillation to mitigate the effects of inherent depth noise during training for improving semantic 3D scene completion at test time when only noisy depth is available.
