# [On the Diversity and Realism of Distilled Dataset: An Efficient Dataset   Distillation Paradigm](https://arxiv.org/abs/2312.03526)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a new dataset distillation method called RDED that aims to address the key challenges of efficiency, realism, and diversity when condensing large-scale, high-resolution datasets like ImageNet. The authors introduce two novel metrics - the compression rate of information and a realism score - to help balance diversity and realism during the distillation process. The core idea is to first extract the most realistic patches from the full dataset based on the observer model's predictions and scores. These patches are then reconstructed into new distilled images paired with soft region-level labels to maximize information. Extensive experiments demonstrate RDED's superiority - it can distill ImageNet-1K with just 10 images per class down to 7 minutes with improved cross-architecture generalization. For example, RDED achieves 42\% top-1 validation accuracy on ResNet-18, significantly higher than prior state-of-the-art. The optimization-free nature also leads to massive efficiency gains. Overall, RDED offers an effective paradigm to distill more realistic and diverse datasets for large-scale machine learning.
