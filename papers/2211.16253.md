# [Advancing Deep Metric Learning Through Multiple Batch Norms And   Multi-Targeted Adversarial Examples](https://arxiv.org/abs/2211.16253)

## What is the central research question or hypothesis that this paper addresses?

 The central research question addressed in this paper is how to improve the accuracy and robustness of deep metric learning (DML) models using multi-targeted adversarial examples (MTAXs) and multiple batch normalization layers. 

Specifically, the paper proposes a framework called MDProp that aims to:

1) Improve the performance of DML models on clean, unperturbed data.

2) Increase the robustness of DML models against adversarial examples that follow different distributions than the clean data. 

The key hypotheses are:

- Using MTAXs and single-targeted adversarial examples (STAXs) during training will regularize the feature space of DML models, reducing problematic overlapping regions and improving generalization.

- Leveraging disentangled learning through multiple batch normalization layers will allow the model to handle the distribution shifts caused by using multi-distribution training data like MTAXs and STAXs.

The central goal is to develop a training approach that uses these two techniques - multi-targeted attacks and disentangled learning with multiple batch norms - to get better DML models that perform well on both clean data and data from different distributions.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes MDProp, a novel framework to improve the image retrieval performance of deep metric learning (DML) models on both clean data and adversarial inputs. 

2. It introduces the use of multi-targeted adversarial examples (MTAXs) during training along with single-targeted adversarial examples (STAXs) to improve accuracy and robustness. MTAXs are designed to target overlapping regions in the embedding space to improve generalization. 

3. It extends the concept of AdvProp from image classification to DML by proposing AdvProp-D. AdvProp uses separate batch normalization layers for clean and adversarial data during training.

4. It demonstrates state-of-the-art performance on standard DML benchmarks using multiple architectures and loss functions. MDProp improves clean data performance by up to 2.95% in R@1 scores while also improving adversarial robustness by up to 39.09% in R@1.

5. It provides the first comprehensive analysis of using multi-distribution data and disentangled learning through separate batch norm layers to simultaneously improve accuracy and robustness of DML models.

In summary, the key novelty is the introduction of MDProp framework that leverages multi-targeted adversarial examples and disentangled learning to advance the state-of-the-art in deep metric learning.
