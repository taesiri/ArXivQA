# [Advancing Deep Metric Learning Through Multiple Batch Norms And   Multi-Targeted Adversarial Examples](https://arxiv.org/abs/2211.16253)

## What is the central research question or hypothesis that this paper addresses?

 The central research question addressed in this paper is how to improve the accuracy and robustness of deep metric learning (DML) models using multi-targeted adversarial examples (MTAXs) and multiple batch normalization layers. 

Specifically, the paper proposes a framework called MDProp that aims to:

1) Improve the performance of DML models on clean, unperturbed data.

2) Increase the robustness of DML models against adversarial examples that follow different distributions than the clean data. 

The key hypotheses are:

- Using MTAXs and single-targeted adversarial examples (STAXs) during training will regularize the feature space of DML models, reducing problematic overlapping regions and improving generalization.

- Leveraging disentangled learning through multiple batch normalization layers will allow the model to handle the distribution shifts caused by using multi-distribution training data like MTAXs and STAXs.

The central goal is to develop a training approach that uses these two techniques - multi-targeted attacks and disentangled learning with multiple batch norms - to get better DML models that perform well on both clean data and data from different distributions.
