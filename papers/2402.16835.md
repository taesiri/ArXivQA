# [Eight Methods to Evaluate Robust Unlearning in LLMs](https://arxiv.org/abs/2402.16835)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) retain undesirable knowledge from their training data and can exhibit harmful behaviors if prompted in malicious ways. This motivates developing techniques for "unlearning" specific knowledge.  
- However, there is a lack of standardized evaluation methods to rigorously assess if unlearning techniques actually robustly remove targeted knowledge. Many works rely on limited or ad-hoc evaluations.

Method: 
- The paper comprehensively evaluates the "Who's Harry Potter" (WHP) unlearning method from Eldan and Russinovich (2023) which aims to remove an LLM's knowledge of Harry Potter by fine-tuning on modified text.
- They test the generalization, robustness and competitiveness of WHP unlearning using 8 evaluation strategies:
   1. Testing other languages 
   2. Using adversarial "jailbreaking" prompts
   3. Providing related context to re-surface knowledge  
   4. Fine-tuning on small Harry Potter excerpts
   5. Harry Potter question answering tasks
   6. Probing latent representations
   7. Comparing to a basic prompting baseline 
   8. Testing "side effects" on related domains

Key Findings:
- The WHP unlearning generalizes well when using the "Familiarity" metric from the original paper.
- However, other tests can reliably extract more knowledge than baseline amounts. The model also performs similarly to the original on downstream QA.
- Latent knowledge in WHP can be extracted comparably to the original model.
- There are side effects resulting in drops in performance on some related domains.

Implications:
- Thorough, standardized evaluations are critical for assessing progress in LLM unlearning. Ad-hoc metrics can be misleading. 
- The limitations found even for WHP's generalized unlearning highlight the need to develop more robust techniques that deeply remove capabilities and knowledge.
