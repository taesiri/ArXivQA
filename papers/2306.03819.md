# [LEACE: Perfect linear concept erasure in closed form](https://arxiv.org/abs/2306.03819)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we optimally edit a representation X to remove linearly encoded information about a protected attribute Z, while minimizing collateral damage to other useful information in X?The key contributions and hypotheses appear to be:1) A set of theoretical results showing the equivalence between several conditions related to linearly guarding Z in X, including:- X linearly guards Z - The trivial constant predictor achieves optimal loss for all convex losses- The classconditional means of X given Z are all equal - The cross-covariance between X and Z is zero2) A closed-form solution called LEACE which provably finds the optimal affine edit to X that removes linear correlations with Z while minimizing mean squared error under any seminorm. 3) A method called "concept scrubbing" which applies LEACE sequentially to all layers of a neural network to remove target concepts.The central hypothesis seems to be that LEACE will allow more surgical removal of concepts from neural networks compared to prior work like INLP, better preserving useful information while still effectively guarding concepts of interest. The paper aims to demonstrate this via experiments on debiasing and amnesic probing.Does this seem like an accurate high-level summary of the core research question and contributions? Let me know if you need any clarification or have additional thoughts!
