# LS-Tree: Model Interpretation When the Data Are Linguistic

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to interpret trained classification models for linguistic data in a way that leverages the syntactic structure and compositionality of language. The key hypotheses are:1) Syntactic constituency structure, as represented by parse trees, can be used to assign importance scores to words that capture their contribution to a model's predictions.2) These importance scores can be used to detect and quantify interactions between words based on their relationships in the parse tree structure. 3) Analyzing these interactions provides insights into properties of the model, such as its nonlinearity and ability to capture linguistic phenomena like adversative relations.4) Statistics of the interaction scores can serve as diagnostics for overfitting in model training.The overall goal is to develop model-agnostic interpretation methods tailored for linguistic data that provide explanatory power beyond what current generic feature attribution techniques can offer. The parse tree-based scoring scheme and interaction detection algorithm are proposed as concrete realizations of this goal.


## What is the main contribution of this paper?

The main contributions of this paper are:- Proposing the LS-Tree value, a method to assign importance scores to words in a sentence by leveraging its syntactic structure represented as a constituency parse tree. The scores are obtained by fitting a linear model to approximate the prediction function on word subsets corresponding to the nodes of the parse tree.- Relating the LS-Tree value to the Banzhaf value from coalitional game theory. This provides an axiomatic characterization and justification for the proposed method. - Developing an algorithm based on the LS-Tree value to detect and quantify interactions between words, specifically sibling nodes in the parse tree, using Cook's distance.- Demonstrating the utility of the LS-Tree value and interaction scores for analyzing several aspects of NLP models: quantifying nonlinearity, assessing ability to capture adversative relations, and detecting overfitting.- Conducting experiments on four models (BoW, CNN, LSTM, BERT) over three sentiment analysis datasets to illustrate the usefulness of the proposed techniques.In summary, the key contribution is a novel model-agnostic method for interpreting NLP models by assigning importance scores to words in a principled way using syntactic structure, along with an algorithm to quantify interactions that can provide insights into model behavior. Theoretical connections and experimental results demonstrate the usefulness of the approach.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a method called LS-Tree to interpret trained classification models on linguistic data by assigning importance scores to words using syntactic constituency structure and relating the method to concepts in coalitional game theory; the importance scores are then used to detect interactions between words captured by the model.


## How does this paper compare to other research in the same field?

Here are a few key points in comparing this paper to other research on interpreting machine learning models for natural language processing:- The paper focuses specifically on interpreting trained classification models for linguistic data represented as parse trees. Many other interpretation methods are more general and do not leverage this syntactic structure.- The proposed LS-Tree value provides instance-wise importance scores for words that respect the constituency structure of the parse tree. This connects model interpretation to concepts like the Banzhaf value from cooperative game theory. Other methods like LIME and SHAP do not have this kind of theoretical grounding.- The paper introduces a novel algorithm for detecting interactions between words based on the LS-Tree scores. This provides a principled way to quantify compositionality that is not found in other interpretation methods. - The approach is model-agnostic and can be applied to any classification model, including neural networks like CNNs and LSTMs. Some other interpretation methods are designed for specific model classes.- The experiments demonstrate how the LS-Tree approach can analyze model properties like nonlinearity, handling of adversative relations, and overfitting. Many papers on interpretation methods do not go into this level of analysis.- The approach does rely on having a constituency parse tree as input, whereas other methods work directly from raw text. This could limit applicability in some cases.Overall, the LS-Tree method makes useful connections between compositionality in language, coalition game theory, and model interpretation. The analysis enabled by the interaction scores is a unique contribution. But the reliance on parse trees and focus on classification may limit wider adoption compared to more broadly applicable methods.
