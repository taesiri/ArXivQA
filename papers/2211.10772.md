# [DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text   Spotting](https://arxiv.org/abs/2211.10772)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to efficiently deal with the relationship between text detection and recognition in end-to-end scene text spotting. Specifically, the authors aim to develop an end-to-end framework that can effectively integrate text detection and recognition into a unified pipeline, while also achieving improved performance and training efficiency.The key hypotheses are:- Representing text instances using explicit point queries based on Bezier curves can provide an efficient joint representation to encode position, shape, and semantics for both detection and recognition. - A single Transformer decoder taking point queries as input can simultaneously handle detection and recognition well, eliminating the need for separate detection and recognition branches.- Simple prediction heads decoding the point queries are sufficient for detection and recognition, without requiring complex task-specific modules.- A text matching loss can provide more accurate supervision to improve training efficiency.In summary, the core hypothesis is that modeling text using explicit point queries and decoding them with a single Transformer can lead to an effective and simplified end-to-end scene text spotting framework. The experiments aim to validate whether the proposed DeepSolo architecture can achieve state-of-the-art performance and training efficiency compared to previous methods.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes DeepSolo, a simple DETR-like baseline for end-to-end scene text spotting. DeepSolo uses a single Transformer decoder and several simple prediction heads to simultaneously perform text detection and recognition. 2. It proposes a novel query form based on explicit points sampled from the Bezier center curve representation of text instances. Each point query encodes the position, shape, and semantics of characters. This allows simplifying the text spotting pipeline into a single decoder framework.3. It introduces a text matching criterion based on CTC loss to provide accurate supervision during training. This improves training efficiency.4. Experiments on public benchmarks including Total-Text, ICDAR 2015, and CTW1500 show that DeepSolo achieves state-of-the-art performance and training efficiency. It also shows compatibility with different levels of annotation, from polygons to just center lines.In summary, the main contribution is a simple and unified framework DeepSolo that efficiently solves text detection and recognition simultaneously using a novel point query representation and text matching loss. The succinct design sets a new state-of-the-art for end-to-end scene text spotting.
