# [Unsupervised Learning by Predicting Noise](https://arxiv.org/abs/1704.05310)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is:How can we train deep convolutional neural networks in an unsupervised manner to produce useful visual features, while avoiding common issues like feature collapse? The central hypothesis is that by mapping deep features to a set of fixed, randomly generated target representations and aligning the features to those targets, the model will learn more robust and transferable features compared to other unsupervised methods. This approach, called Noise As Targets (NAT), avoids feature collapse by fixing the target reps and diversifying the features through the alignment.The authors propose an online optimization method to efficiently train NAT at large scale, and evaluate the quality of the learned features on transfer tasks like ImageNet classification. Their goal is to show NAT can match or exceed the performance of other unsupervised and self-supervised approaches while being simpler and faster to train.
