# [Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video](https://arxiv.org/abs/1910.09430)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we learn reusable skill embeddings from unlabeled video demonstrations that can be composed to solve new tasks?In particular, the authors aim to learn a task-agnostic skill embedding space from unlabeled multi-view video demonstrations, without needing any correspondence between frames and task labels. The goal is for the learned embedding to enable training reinforcement learning agents to reuse previous skills for new tasks by using the embedding space as a reward function.To address this, the paper introduces Adversarial Skill Networks, which combines a metric learning loss that utilizes temporal video coherence with an entropy-regularized adversarial skill transfer loss. The key ideas are:- The metric learning loss learns a state representation by attracting simultaneous viewpoints of the same observations and repelling visually similar frames from temporal neighbors. - The adversarial skill transfer loss enhances re-usability of learned skill embeddings over multiple task domains by maximizing the entropy of a discriminator's outputs.- Using these losses jointly results in a versatile embedding space that represents skills in a task-independent way.- The learned embedding can then be used as a reward function to train RL agents to solve new tasks by composing and interpolating previously seen skills.So in summary, the central research question is how to learn a reusable, task-agnostic skill embedding space from unlabeled videos that allows solving new tasks by skill composition, which they address using an adversarial learning framework with specific metric and entropy losses.
