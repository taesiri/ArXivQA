# [LoSA: Long-Short-range Adapter for Scaling End-to-End Temporal Action   Localization](https://arxiv.org/abs/2404.01282)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Temporal action localization (TAL) involves localizing and classifying action snippets in untrimmed videos. 
- Recent large video foundation models like VideoMAEv2 (ViT-g) achieve state-of-the-art TAL performance using only RGB features. 
- However, adapting these large models for end-to-end TAL training is prohibitively expensive due to GPU memory constraints when processing long untrimmed videos.

Proposed Solution:
- The paper proposes LoSA, the first memory- and parameter-efficient backbone adapter tailored for end-to-end TAL.

- LoSA introduces lightweight Long-range and Short-range Adapters attached to intermediate layers of the video backbone. 
    - Short-range Adapters capture fine-grained short-term temporal context.
    - Long-range Adapters capture long-term dependencies in the untrimmed video.

- These adapters run parallel to the backbone via cross-attention, circumventing gradient backpropagation through backbone to reduce memory footprint.

- LoSA also has a Long-Short-range Fusion module to strategically combine outputs of the adapters from different backbone layers to generate TAL-enhanced features.

Main Contributions:
- LoSA enables end-to-end adaptation of billion-parameter models like VideoMAEv2 (ViT-g) for TAL by being memory- and parameter-efficient. 

- It is the first approach to go beyond traditional techniques like full backbone adaptation and head-only transfer learning for TAL.

- Experiments show LoSA significantly improves RGB-only TAL performance over state-of-the-art methods on THUMOS-14 and ActivityNet benchmarks.

- Qualitative results demonstrate LoSA's precision in localizing nuanced temporal boundaries of actions.

In summary, the paper makes an important contribution in advancing large model adaptation for TAL by designing a specialized memory-efficient adapter architecture to handle challenges unique to untrimmed video understanding.
