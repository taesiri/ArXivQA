# [Disclosure and Mitigation of Gender Bias in LLMs](https://arxiv.org/abs/2402.11190)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) can generate biased and harmful text, stemming from biases in the training data and model architecture. However, prior probing techniques rely on explicitly mentioning stereotypes or demographic groups, which is challenging to comprehensively collect.

Solution: 
- The paper proposes an indirect probing framework to induce LLMs to disclose gender bias through conditional text generation, without needing explicit gender or stereotype mentions.

- Three strategies are explored - naturally-sourced inputs from existing datasets, LLM-generated inputs using a seed prompt, and template-based inputs with predefined stereotypes.

- Explicit (Gender Attribute Score) and implicit (Gender Logits Difference, Attribute Distribution Distance) metrics are introduced to quantify gender bias.

Experiments and Results:
- Experiments on 10 LLMs demonstrate all models exhibit varying degrees of explicit and implicit bias, even on naturally-sourced or LLM-generated inputs without stereotypes.

- Larger or aligned LLMs display more bias in most cases. Template-based inputs give inconsistent results across topics.

- Three debiasing methods are explored - hyperparameter tuning, instruction guiding, and debias tuning. Debias tuning, which brings gender distributions closer while reducing gender word probabilities, is most effective.

Main Contributions:
- Proposes a new conditional generation probing approach to disclose gender bias in LLMs without needing explicit gender or stereotypes.

- Defines new metrics to quantify explicit and implicit gender bias based on conditional generation.

- Systematically benchmarks gender bias across 10 major LLMs, and explores debiasing techniques, with debias tuning proving remarkably effective.
