# [CREPE: Can Vision-Language Foundation Models Reason Compositionally?](https://arxiv.org/abs/2212.07796)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research question being addressed is: 

Can existing large-scale vision-language models demonstrate compositional reasoning abilities? Specifically, do they exhibit systematicity (the ability to recombine known components to understand novel combinations) and productivity (the ability to understand increasingly complex inputs)?

The key hypotheses seem to be:

1) Current vision-language models struggle with systematic generalization, and will perform worse when tested on novel visual concept compositions compared to seen compositions.

2) Vision-language models' ability to correctly comprehend scenes will degrade as the complexity of the textual description increases.

To evaluate these hypotheses, the authors introduce a new benchmark called CREPE that tests systematicity via seen/unseen splits of compounds, and productivity by testing on captions of increasing complexity. The experiments assess whether current models exhibit the expected deficiencies in these two aspects of compositional reasoning.

So in summary, the paper sets out to probe whether existing vision-language models actually demonstrate robust compositional abilities, or whether their strong performance on many downstream tasks may be relying more on simply recognizing familiar patterns. The introduction of CREPE provides a way to directly test models for these hypothesized limitations.
