# [Depicting Beyond Scores: Advancing Image Quality Assessment through   Multi-modal Language Models](https://arxiv.org/abs/2312.08962)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper introduces DepictQA, a novel image quality assessment (IQA) method that leverages multi-modal language models to provide descriptive, human-like evaluations of image quality. Unlike traditional IQA methods that output numerical scores, DepictQA identifies distortions in images, weighs their influence on texture damage, and provides natural language justifications for quality comparisons. The authors construct a hierarchical framework with three tasks: quality description, quality comparison, and comparison reasoning. They also collect a multi-modal IQA dataset called M-BAPPS to train the model. To address challenges with limited data and processing multiple images, the authors employ multi-source training data and specialized image tags. Experiments demonstrate that DepictQA outperforms score-based methods on the BAPPS benchmark and generates more accurate reasoning descriptions than general multi-modal models. The work shows the promise of language-based IQA to better align with human judgment, especially for complex cases like misalignment and multiple distortions. It also indicates the potential to customize IQA for individual preferences. Overall, this paper makes important strides towards descriptive, interpretable IQA through integration of natural language and reasoning capabilities.
