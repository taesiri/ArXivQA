# [SequencePAR: Understanding Pedestrian Attributes via A Sequence   Generation Paradigm](https://arxiv.org/abs/2312.01640)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

The paper proposes a new generative framework for pedestrian attribute recognition called SequencePAR. Unlike previous works that treat attribute recognition as a multi-label classification problem, SequencePAR formulates it as a sequence generation task similar to image captioning. It first extracts visual features from pedestrian images using a pre-trained CLIP model, and represents the textual attributes as embedded query tokens. A novel Transformer decoder is then used to sequentially predict attributes by attending over the image and text features using masked multi-head attention blocks. This allows modeling inter-attribute dependencies and semantic relationships. Extensive experiments on multiple pedestrian datasets demonstrate state-of-the-art performance of SequencePAR. The generative modeling approach makes the predictions more robust to imbalanced training data and label noise compared to discriminative models. The visualization also shows SequencePAR accurately predicting fine-grained details of clothing, accessories, age, gender etc. Some limitations are complex images with multiple people can degrade performance. Future work will explore adding pedestrian localization modules. Overall, SequencePAR provides a new direction for pedestrian attribute recognition through its sequence generation formulation.
