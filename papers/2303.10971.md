# [Self-Supervised Learning for Multimodal Non-Rigid 3D Shape Matching](https://arxiv.org/abs/2303.10971)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we develop an accurate and robust method for matching 3D shapes represented as either triangle meshes or point clouds in a self-supervised manner? 

The key hypotheses appear to be:

1) By combining mesh-based functional map regularization with a contrastive loss between meshes and point clouds, a feature representation can be learned that is effective for matching both modalities.

2) This multimodal self-supervised training strategy will enable accurate intramodal matching for meshes, point clouds, and partial point clouds, as well as cross-modal matching between them. 

3) The method will achieve state-of-the-art performance compared to previous supervised and unsupervised techniques, even with little training data, while also demonstrating improved robustness and generalization ability.

In summary, the central research question is how to develop an accurate and robust self-supervised approach to multimodal non-rigid 3D shape matching. The key hypotheses relate to using a combination of functional map regularization and contrastive learning to enable effective cross-modal feature learning for this task.
