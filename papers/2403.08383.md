# [RAF-GI: Towards Robust, Accurate and Fast-Convergent Gradient Inversion   Attack in Federated Learning](https://arxiv.org/abs/2403.08383)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Federated learning (FL) exposes only model gradients instead of original data for privacy. However, gradient inversion (GI) attacks can reconstruct users' private data from gradients. 
- Existing GI attacks face challenges in accuracy and efficiency:
    - Inferior attack accuracy when context is complicated (e.g. large batch size, duplicated labels).
    - Very slow attack convergence, taking hours to reconstruct one image.

Proposed Solution - RAF-GI:
- Proposes a Robust, Accurate and Fast GI attack with two components:
    1. Additional Convolution Block (ACB): 
        - Accurately restores labels from gradients, even with duplicated labels.
        - Uses convolutional layers to enhance discrimination between repeated and non-repeated labels.
    2. Total variance, Mean and Canny edge detection (TEA) regularization:
        - Reconstructs images from gradients and labels from ACB.
        - Employs regularization terms for faster convergence and higher quality.

Main Contributions:
- ACB significantly improves label accuracy by up to 20%, supporting batch sizes up to 48.
- TEA regularization enables over 94% faster attack convergence compared to prior art while achieving much higher image quality.  
- RAF-GI works on large ImageNet dataset, reconstructing 224x224 resolution images.
- With batch size 1, RAF-GI obtains 7.89 higher PSNR over state-of-the-art attack algorithms.
- RAF-GI does not make impractical assumptions of prior GI attacks, making it applicable to general attack scenarios.

In summary, the proposed RAF-GI attack enables highly accurate, robust and efficient reconstruction of private images from gradients exposed in federated learning, highlighting privacy risks. The attack advances state-of-the-art with innovative techniques for label recovery and image reconstruction.
