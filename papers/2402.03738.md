# [AoSRNet: All-in-One Scene Recovery Networks via Multi-knowledge   Integration](https://arxiv.org/abs/2402.03738)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Imaging quality is often degraded in adverse environments like haze, sandstorms, and low light. This reduces contrast, color fidelity and edge information in collected images, which limits developments in vision-based intelligent systems. Hence, methods are needed to improve visibility in such low-visibility conditions across multiple scenes.

Proposed Solution: The paper proposes AoSRNet (All-in-One Scene Recovery Network), a unified network to enhance image visibility across three low-visibility conditions - hazy scenes, sandy/dusty scenes, and low-light scenes. 

Key components of AoSRNet:

1) Detail Enhancement Module (DEM): Uses gamma correction with different gamma values to extract detail features like textures under multiple exposure conditions. Helps avoid overfitting.

2) Color Restoration Module (CRM): Employs optimized linear stretching to rescale distribution of pixel intensities for better contrast. Restores color information.  

3) Multi-Receptive Field Extraction Module: Uses parallel atrous convolutions to extract enhanced context from multiple receptive fields. Reduces loss of details from DEM and CRM.

4) Encoder-Decoder Fusion Module: Fuses the coarse features from above modules through residual learning in encoder-decoder structure for final image recovery.

Main Contributions:

- Proposes first unified all-in-one solution for image enhancement across haze, sandstorm and low light scenes via a single network AoSRNet

- Integrates traditional image processing techniques (gamma correction, linear stretching) with deep network to avoid overfitting and improve generalization 

- Comprehensive experiments verify AoSRNet outperforms state-of-the-art across multiple low visibility scenes.

The key highlight is leveraging both conventional image processing and deep learning for a robust unified solution generalizable across multiple complex visibility degradation conditions.
