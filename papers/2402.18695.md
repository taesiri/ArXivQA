# [Grounding Language Models for Visual Entity Recognition](https://arxiv.org/abs/2402.18695)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper tackles the problem of open-domain visual entity recognition (VER). In VER, given an image and a question about the image, the goal is to answer with a very specific entity from Wikipedia (e.g. a specific model of airplane like "ATR 42"). This is challenging because the label space comprises over 6 million Wikipedia entities and many entities are visually very similar. Existing solutions using classifiers or generative models struggle with this large label space and fail to leverage visual information from entity images to disambiguate between similar entities.

Proposed Solution: 
The paper proposes AutoVER, an autoregressive model for visual entity recognition. AutoVER extends a pre-trained multimodal language model by employing retrieval augmented constrained generation. Specifically:

1) It learns representations for query image-text pairs and candidate entities with a contrastive loss for query-to-entity retrieval. 

2) During inference, it retrieves the top candidate entities and builds a prefix tree (trie) from their identifiers. 

3) It then performs constrained decoding by only allowing tokens during generation that are present in the prefix tree. This ensures the generated text matches one of the retrieved entities.

4) It also incorporates hard negative mining strategies to encourage distinguishing between similar entities.

Main Contributions:
- Proposes a unified retrieval-augmented generation framework for visual entity recognition that mitigates issues with out-of-domain entities and reasoning
- Achieves state-of-the-art results on the OVEN-Wiki dataset, significantly outperforming prior methods
- Demonstrates strong generalization to out-of-domain questions on A-OKVQA
- Ablation studies validate the contribution of the proposed retrieve-generate framework and decoding constraints

Overall, the paper makes an important contribution in improving visual entity recognition using multimodal language models with a clever integration of retrieval and constrained decoding.
