# [FOCUS: Familiar Objects in Common and Uncommon Settings](https://arxiv.org/abs/2110.03804)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How do deep learning image classification models perform on images containing familiar objects in uncommon or atypical environments/settings, and can their ability to classify such images be improved?The key points are:- Standard image datasets used to train deep learning models often do not contain many examples of objects in uncommon settings (e.g. planes on water, cars in snow). - This can cause models to rely too heavily on contextual cues and have poor generalizability to uncommon settings.- The authors introduce a new dataset called FOCUS containing images of familiar objects in both common and uncommon settings.- They evaluate several popular deep learning models on FOCUS and find a significant drop in accuracy on uncommon images.- Finetuning the models on FOCUS improves their ability to classify objects in uncommon settings.So in summary, the main question is whether deep learning models can accurately classify familiar objects in uncommon settings, and if their performance on such uncommon cases can be improved via finetuning on a dataset containing more diversity. The FOCUS dataset and experiments are aimed at addressing this question.


## What is the main contribution of this paper?

The main contribution of this paper is introducing a new dataset called FOCUS (Familiar Objects in Common and Uncommon Settings) to evaluate deep learning image classifiers. The key ideas are:- Leveraging search engines to deliberately gather images with objects in both common and uncommon settings like locations, weather conditions, and time of day.- Using FOCUS to evaluate popular ImageNet classifiers and finding they perform significantly worse on uncommon images, demonstrating insufficient generalization. - Showing that finetuning on FOCUS improves models' ability to focus on the object of interest, leading to better accuracy on uncommon images.- Using FOCUS to add rich context annotations (time, weather, location) to the whole ImageNet dataset.In summary, the paper introduces FOCUS as a dataset to stress test generalization of classifiers to uncommon settings, reveals poor generalization of popular models, and shows finetuning on FOCUS improves generalization. The dataset and annotations also enable future work on improving model robustness.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper introduces FOCUS, a dataset of natural images containing common and uncommon settings to evaluate the ability of deep learning image classifiers to generalize to atypical contexts; the authors find popular classifiers have reduced performance on uncommon settings which is improved by fine-tuning on FOCUS.


## How does this paper compare to other research in the same field?

Here are some key points about how this paper compares to other related work:- The paper focuses on studying the ability of deep learning models to classify images containing common objects in uncommon contexts or settings. This is an important but understudied problem, as most existing image datasets contain biases towards objects in their typical contexts.- The paper introduces a new dataset called FOCUS specifically designed to have a balanced distribution of objects in both common and uncommon settings. Most prior work has studied model robustness using artificial image corruptions or synthetic distribution shifts. FOCUS provides more natural distribution shifts.- The paper thoroughly evaluates many recent state-of-the-art image classifiers on FOCUS and shows they have substantially reduced accuracy on uncommon images, highlighting their lack of robustness. Prior work has not systematically studied such a wide range of models.- The paper shows that finetuning on FOCUS significantly improves model accuracy on uncommon settings. This demonstrates that datasets like FOCUS can be used to improve model generalization. Most prior work has focused only on evaluating models rather than improving them.- The paper uses FOCUS to add richer contextual attribute labels to ImageNet, facilitating future large-scale studies. Expanding datasets with contextual attributes has not been explored much before.Overall, this paper makes excellent contributions in rigorously benchmarking model robustness on natural distribution shifts and demonstrating how targeted datasets can diagnose and improve model biases. The comparisons to other datasets and breadth of models evaluated also move forward the understanding in this problem space.
