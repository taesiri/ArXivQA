# [From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion](https://arxiv.org/abs/2308.02560)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we develop a high-fidelity multi-band diffusion framework to generate high quality audio (speech, music, environmental sounds etc.) from low bitrate discrete representations?The key hypotheses appear to be:1) Using a band-specific diffusion model that processes different frequency bands independently can reduce error accumulation and improve audio quality. 2) Adjusting the frequency bands to balance the energy distribution between the data distribution and Gaussian prior can improve diffusion sampling.3) Designing a power noise schedule tuned for audio data with rich harmonics can improve diffusion model training and sampling. 4) The proposed multi-band diffusion framework can outperform state-of-the-art generative models like GANs in generating high fidelity audio from low bitrate discrete representations.In summary, the central research question is how to develop an optimal diffusion-based framework for high quality audio generation from compressed representations, with the key hypotheses relating to using band-specific modeling, energy rebalancing, schedule tuning, and showing superiority over other generative models.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Proposing a novel diffusion-based model called Multi-Band Diffusion (MBD) for high-fidelity audio synthesis from low bitrate discrete representations. The key aspects of MBD are:- Using a band-specific diffusion model that processes different frequency bands independently, allowing for less accumulative entangled errors. - A frequency equalizer processor that reduces the discrepancy between the prior Gaussian distribution and the data distribution in different frequency bands.- A power noise scheduler designed for audio data with rich harmonic content.2. Demonstrating through experiments that MBD can generate high quality audio samples of various modalities (speech, music, environmental sounds) from compressed representations.3. Showing that MBD outperforms state-of-the-art generative models like GANs in terms of perceptual quality at equal bitrates through both objective metrics and human evaluation.4. Illustrating how MBD can be combined with generative language models for tasks like text-to-speech and text-to-music generation to enhance the quality.5. Providing training code, evaluation code, and audio samples to replicate the method.In summary, the key contribution is proposing a novel diffusion-based framework (MBD) for high-fidelity audio synthesis from compressed representations that outperforms previous state-of-the-art approaches. The method is demonstrated to work well across various audio modalities.
