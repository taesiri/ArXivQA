# [Federated Learning Under Attack: Exposing Vulnerabilities through Data   Poisoning Attacks in Computer Networks](https://arxiv.org/abs/2403.02983)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Federated Learning (FL) enables collaborative training of models across decentralized devices without sharing raw data. However, model updates exchanged are vulnerable to data poisoning attacks which can violate integrity and availability.  

- The paper investigates severity of data poisoning attacks in computer network domain as they are easy to execute but hard to detect. Two attack types examined - Label Flipping (LF) where benign labels flipped; Feature Poisoning (FP) where key features manipulated.

Methodology:  
- Used CIC and UNSW network traffic datasets. Developed neural network model BAU1 for binary classification. 

- White box attack scenario with server and two clients. LF and FP attacks implemented only on one client's data. LF attack involves random label flipping while FP attack tweaks values of most important features identified via Random Forest.

- Attacks executed at 1% to 25% poisoning on client's data. Server accuracy and Attack Success Rate (ASR) recorded across percentages for both datasets.

Key Results:
- LF attack fails as server accuracy drops drastically making attack evident. But FP attack succeeds in fooling server for most percentages, with negligible accuracy drop and high ASR.

- With 1% FP attack on CIC, accuracy ~0.96 and ASR ~0.96. Hard to detect attack. Most FP percentages successful except 2%, 3%.

- On UNSW, FP attack successful for all percentages except 4%. Eg - 1% poisoning causes accuracy 0.82 and ASR 0.82.  

Main Contributions:  
- First study examining data poisoning attacks in computer network FL domain, using CIC and UNSW datasets.

- Flexible framework developed to test attacks at varying percentages on clients. Quantified impact via server accuracy and ASR metrics.

- Key insight - FP attacks can surreptitiously compromise FL in this domain whereas LF clearly detectable. Establishes need for enhanced defenses like feature protection.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The paper investigates the vulnerability of federated learning models to data poisoning attacks, specifically label flipping and feature poisoning, on computer network datasets, finding that while label flipping attacks fail to fool the server due to significant drops in accuracy, feature poisoning attacks are more effective in deceiving the server while avoiding detection.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. The authors conducted training sessions for neural networks using two prominent datasets in the field of computer networks - CIC and UNSW. Their goal was to perform binary classification of network traffic, distinguishing between benign and malicious traffic. This aimed to provide insights into malicious activities detection in computer networks.

2. They implemented an experimental federated learning (FL) setup with two clients and a server. They designed and applied two data poisoning attacks - label flipping (LF) and feature poisoning (FP) - on one client in a white-box scenario, to assess the impact on the server's accuracy. Their investigation exposed vulnerabilities of FL to such targeted adversarial techniques.  

3. They delved into the efficacy of data poisoning attacks within the computer network domain by applying these attacks at varying percentages on only one client's training data. They calculated both server accuracy and Attack Success Rate (ASR) across different attack percentages. This provided a nuanced understanding of the vulnerabilities introduced by data poisoning in this context.  

4. They developed a highly flexible and generic codebase to facilitate reproducibility and adaptability of the experiments to diverse datasets and attack percentages. This codebase allows for seamless future research extensions in this problem area.

5. Through their analysis, they underscored that while LF attacks failed, FP attacks were highly effective in fooling the server. By compromising only a few important features, the FP attack caused negligible change to server accuracy but a significant increase in ASR. Thus, FP attacks pose a potent and stealthy threat.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key keywords and terms associated with this paper include:

- Federated learning
- Causative attacks 
- Adversarial machine learning
- Corrupted training sets 
- Cybersecurity
- Data poisoning
- Label flipping (LF) 
- Feature poisoning (FP)
- Attack success rate (ASR)
- CIC and UNSW datasets
- Deep learning models
- Client-server architecture
- Gradient updates
- Model poisoning attacks
- Membership inference attacks

The paper explores data poisoning attacks like label flipping and feature poisoning in the context of federated learning systems, evaluating their impact on model accuracy and attack success rate using computer network datasets like CIC and UNSW. Key goals are assessing vulnerabilities in federated learning to such causative attacks and providing insights into potential mitigation strategies.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper mentions two types of data poisoning attacks - label flipping (LF) and feature poisoning (FP). Can you explain in detail the process used to implement each of these attacks? What are some key differences between them?

2. The paper evaluates the attacks on two datasets - CIC and UNSW. Why were these specific datasets chosen and how are they particularly relevant for studying vulnerabilities in computer networks? 

3. For the feature poisoning (FP) attack, the paper determines important features using a Random Forest algorithm. Can you explain how this algorithm identifies key features? Why is identifying influential features crucial for a successful FP attack?

4. The methodology involves splitting the data into separate training and testing sets. What percentages were used for splitting the data? Why did the authors choose this specific split?

5. The network architecture called BAU1 is central to the experiments. Can you walk through the key components of this network? What architectural choices were made and why?  

6. The paper evaluates the attacks under a white-box threat model. What assumptions does this threat model make about the attacker's knowledge and capabilities? How would the results differ under a grey-box or black-box model?

7. For determining attack success, accuracy and ASR thresholds are set. Why are both metrics necessary? What do they each tell about the impact of the attack from different perspectives?   

8. The LF attack is found to be unsuccessful while the FP attack succeeds in most cases. What underlying reasons account for these differences in attack efficacy?

9. How exactly is the feature importance analysis done to identify columns most susceptible for feature poisoning? What defenses could potentially protect these sensitive columns? 

10. The methodology relies on a network with only two clients. How could the experiments be extended or modified to evaluate larger multi-client scenarios? How might the attacks behave differently?
