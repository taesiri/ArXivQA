# [REALM: Retrieval-Augmented Language Model Pre-Training](https://arxiv.org/abs/2002.08909)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central hypothesis is that augmenting language model pre-training with a learned knowledge retriever will improve performance on knowledge-intensive natural language processing tasks like open-domain question answering. Specifically, the paper proposes REALM (Retrieval-Augmented Language Model), which adds a neural retriever module that retrieves relevant documents from a corpus during pre-training and fine-tuning. The key ideas are:- The retriever is trained jointly with the language model in an unsupervised way, using the language modeling objective. This allows it to learn what documents are useful for reducing perplexity.- The model is optimized end-to-end, backpropagating through the retrieval step to learn better retrievals.- This approach allows incorporating knowledge from large textual corpora in a modular and interpretable way, compared to storing all knowledge implicitly in the model parameters.The central hypothesis is that this retrieval-augmented pre-training approach will improve performance on open-domain QA, by teaching the model to retrieve and utilize external knowledge. The paper evaluates this hypothesis by pre-training REALM models and fine-tuning them on open-domain QA datasets, where they outperform previous state-of-the-art systems.


## What is the main contribution of this paper?

 The main contribution of this paper is presenting REALM (Retrieval-Augmented Language Model), a new method for pre-training language models that incorporates latent knowledge retrieval. The key ideas are:- Augmenting a masked language model with a neural retriever module that retrieves relevant documents from a corpus to help predict masked tokens.- Pre-training the retriever and language model end-to-end by maximizing the marginal likelihood over retrieved documents. This encourages retrievals that improve perplexity.- Using maximum inner product search to enable scaling to large corpora during pre-training.- Evaluating on open-domain question answering and showing significant gains over previous state-of-the-art methods, including large pretrained language models like T5.In summary, the main contribution is presenting a new way to inject knowledge into language models by retrieving from corpora on-the-fly, and showing its effectiveness on knowledge-intensive tasks like open-domain QA. The retriever provides interpretability and modularity compared to storing all knowledge in the parameters.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:The paper proposes REALM, a new pre-training method that augments language model pre-training with a latent knowledge retriever that retrieves relevant documents from a corpus to help predict masked tokens, achieving state-of-the-art results on open-domain question answering benchmarks.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other research in open-domain question answering and knowledge-based language models:- It proposes REALM, a new model that augments language model pre-training with an explicit neural knowledge retriever. This differs from most prior work that looked at either retrieval-based QA systems with non-learned components or huge language models like T5 that store knowledge implicitly. - REALM achieves state-of-the-art results on multiple open-domain QA benchmarks, outperforming previous approaches including very large models like 11B parameter T5. This demonstrates the effectiveness of the proposed pre-training framework.- The paper provides an analysis of the model, including ablations and examples showing that the retriever learns to retrieve genuinely useful documents. This sheds light on why the approach works.- REALM is designed to be more interpretable and modular compared to gigantic black-box models. The authors argue this could lead to other benefits like easier adaptation to new knowledge.- The method of pre-training a retriever using a latent variable language model objective seems novel compared to prior work on learned retrieval for QA.- There is still limited analysis of the knowledge being captured by REALM versus in parameter weights. More inspection could reveal strengths/weaknesses of the different approaches.In summary, this paper introduces a new way of incorporating world knowledge into language models that obtains strong empirical results. It also provides some useful analysis and discussion about the benefits of explicit retrieval versus implicit parameter storage for knowledge.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors are:- Applying the REALM framework to structured knowledge sources, not just unstructured text. This could allow the model to learn when to retrieve relevant entities or facts from a knowledge graph.- Extending REALM to multi-lingual settings, where documents retrieved in a high-resource language could provide knowledge to represent text in a low-resource language. - Generalizing REALM to multi-modal settings, where images or videos could be retrieved to provide visual knowledge not easily obtained from text alone.- Exploring different architectures and training techniques for the retriever module, to further improve its ability to retrieve useful documents. - Applying REALM to other knowledge-intensive tasks beyond open-domain QA, to assess its general utility.- Developing better techniques to inject inductive bias into the retriever during pre-training, to further guide it towards meaningful retrievals.- Improving computational efficiency and scalability of the end-to-end system.So in summary, the main directions mentioned aim to generalize the REALM approach to handle more diverse knowledge sources and modalities, apply it to more tasks, and further improve the capabilities of the retriever.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:The paper proposes REALM (Retrieval-Augmented Language Model), a novel method for augmenting language model pre-training with a latent knowledge retriever. REALM jointly trains a neural knowledge retriever and a knowledge-augmented encoder by maximizing the likelihood of a retrieve-then-predict generative process. The retriever learns to select relevant knowledge documents from a corpus to help the encoder fill masked tokens. This is achieved by backpropagating through a retrieval step that considers millions of documents. REALM is pre-trained on large unlabeled corpora and then fine-tuned for open-domain question answering. Experiments show it outperforms previous state-of-the-art systems on multiple benchmarks while also providing interpretability and modularity benefits. The explicit retrieval allows adapting REALM to new knowledge by simply modifying the corpus.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:This paper proposes a new method for language model pre-training called Retrieval-Augmented Language Model pre-training (REALM). REALM augments existing masked language model pre-training methods like BERT with an explicit neural retriever module. During pre-training, the retriever learns to retrieve relevant documents from a textual knowledge corpus like Wikipedia to help the model fill in masked words and phrases. This allows the model to incorporate more external knowledge than just what is in its parameters. The authors show that REALM outperforms previous state-of-the-art methods on open-domain question answering benchmarks like Natural Questions and WebQuestions. REALM is able to achieve much higher performance than previous retrieval-augmented models like ORQA while using a smaller model size. The authors also demonstrate benefits of REALM such as interpretability and the ability to quickly adapt to new knowledge by changing the corpus. Overall, REALM presents a promising direction for injecting more world knowledge into pre-trained language models in an explicit and scalable way.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes REALM (Retrieval-Augmented Language Model), a novel pre-training method that augments standard masked language model pre-training with a latent knowledge retriever. The key idea is to add a retrieval step before predicting masked tokens, where the model retrieves potentially relevant documents from a large corpus to help predict the masked tokens. The retriever and encoder are trained end-to-end to maximize the marginal likelihood, where the gradient backpropagates through the retrieval step. This allows the retriever to learn which documents are useful for the prediction task. The authors demonstrate the benefits of REALM pre-training on open-domain question answering, where it outperforms previous state-of-the-art methods by a significant margin. The main technical novelty is jointly training the knowledge retriever in an unsupervised manner by only using the signal from the masked language modeling task.


## What problem or question is the paper addressing?

 Based on my reading of the paper, the key problems/questions it is addressing are:- How can we build language models that store world knowledge in a more interpretable and modular way, rather than implicitly in the parameters of a giant neural network?- How can we leverage large textual knowledge sources like Wikipedia to provide external knowledge to neural models, while still being able to train the whole system end-to-end?- Can such an approach where knowledge is retrieved on-the-fly improve performance on knowledge-intensive NLP tasks like open-domain question answering?Specifically, the paper proposes a novel framework called REALM (Retrieval-Augmented Language Model) which adds a learned neural retriever module to standard language model pre-training. The retriever retrieves relevant documents from a knowledge corpus like Wikipedia to provide knowledge that helps the language model make better predictions. The whole framework including the retriever is trained end-to-end using the language modeling objective. This provides a more interpretable way to incorporate knowledge compared to just training a giant LM, while also improving performance on downstream QA tasks.
