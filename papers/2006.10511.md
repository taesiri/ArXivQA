# [Contrastive learning of global and local features for medical image   segmentation with limited annotations](https://arxiv.org/abs/2006.10511)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be:How can contrastive learning frameworks for self-supervised representation learning be adapted and improved for volumetric medical image segmentation tasks with limited labeled data? More specifically, the authors propose and investigate:1) Novel contrasting strategies that leverage the structural similarity typically present across medical image volumes of the same anatomy (domain-specific cue) to better define similar and dissimilar pairs for the global contrastive loss. 2) A local version of the contrastive loss that encourages the network to learn distinctive representations of local image regions, in order to better distinguish neighboring areas, which is useful for segmentation (problem-specific cue).The central hypothesis is that incorporating these domain and problem-specific cues into contrastive self-supervised learning will yield better feature representations that improve segmentation accuracy when fine-tuned on small labeled datasets, compared to prior contrastive learning approaches.So in summary, the key question is how to adapt contrastive self-supervised learning for medical volumetric segmentation with scarce labels, with a focus on using domain and task-specific knowledge to improve the learned representations. The proposed local contrastive loss and similarity notions leveraging inter-volume structure are the main novelties.


## What is the main contribution of this paper?

This paper proposes novel contrastive learning strategies for medical image segmentation in settings with limited labeled data. The main contributions are:1. New contrasting strategies for the global contrastive loss that leverage naturally occurring similarity cues in volumetric medical images, by using corresponding slices across different volumes as similar pairs. 2. A local contrastive loss to learn distinctive representations of local regions in an image, which complements the global representations learned via the global loss.3. Evaluation of the proposed strategies on three MRI segmentation datasets shows substantial improvements compared to no pre-training, pre-training with only the global loss, and other self-supervised learning methods. 4. The proposed pre-training provides benefits complementary to data augmentation and semi-supervised learning techniques for learning with limited annotations.In summary, the key novelty is in designing contrastive learning strategies tailored for volumetric medical images and segmentation tasks by incorporating domain knowledge and problem-specific cues into the contrastive loss formulation, at both global and local levels. This allows learning useful representations from unlabeled medical volumes to significantly boost performance when only few labeled examples are available for the target segmentation task.
