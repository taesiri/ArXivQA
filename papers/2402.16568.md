# [Two-stage Generative Question Answering on Temporal Knowledge Graph   Using Large Language Models](https://arxiv.org/abs/2402.16568)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Temporal knowledge graphs (TKGs) store facts associated with valid time periods. Answering natural language questions over TKGs (temporal QA) is challenging due to the temporal constraints hidden in questions and the need to reason over dynamic facts.  
- Although large language models (LLMs) have shown reasoning ability over structured data, their application to temporal QA remains relatively unexplored. Two key challenges are identified:
	1) Retrieving the question-relevant facts from the large search space along both structure and time dimensions.
	2) Reasoning over the retrieved facts to answer complex questions that require understanding temporal order and dependencies.

Proposed Solution:
- A novel two-stage generative temporal QA framework called GenTKGQA:
	1) Subgraph Retrieval: Utilize LLM's intrinsic knowledge to mine temporal constraints and structural connections within the question. This narrows down the search space without extra training.
	2) Answer Generation: Design virtual knowledge indicators to fuse LLM text representations with graph neural network signals of the retrieved facts. This enables deeper understanding of temporal order and structure through instruction tuning.

Main Contributions:
1) First application of LLMs for generative temporal QA over dynamic KGs.
2) Novel technique to exploit LLM knowledge for efficient two-dimensional subgraph retrieval.  
3) Non-trivial fusion method to incorporate structural and temporal knowledge into LLM for complex reasoning.
4) Consistently outperforms previous state-of-the-art models, achieving 100% accuracy on simple questions.

In summary, the paper explores the temporal reasoning capability of LLMs for QA over temporal KGs, and proposes an efficient two-stage framework to address key limitations. The solution achieves new state-of-the-art performance.
