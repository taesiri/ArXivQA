# [Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass the   Censorship of Text-to-Image Generation Model](https://arxiv.org/abs/2312.07130)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Text-to-image models like DALL-E 3 offer innovative services but also raise ethical concerns around potential misuse to generate inappropriate/unethical images. 
- Most models employ safety filters to detect and block harmful content, but their robustness is still susceptible to adversarial attacks via carefully manipulated prompts.

Proposed Solution - Divide and Conquer Attack (DACA)  
- Proposes using language models (LLMs) as agents to transform sensitive prompts into adversarial ones that can bypass safety filters.  
- Applies a "divide-and-conquer" strategy - deconstructs a sensitive image into multiple visual elements, each described harmlessly. Then combines element descriptions into adversarial prompts.
- Uses specialized helper prompts to guide the LLM - e.g. to extract visual elements from original image, rephrase sensitive pieces harmlessly.

Key Contributions
- Implements DACA attack which leverages LLMs to automatically transform sensitive prompts into adversarial ones that bypass safety filters.
- Demonstrates success against state-of-the-art DALL-E 3 model across various unethical topics like violence, discrimination.
- Highlights intriguing phenomenon of using LLMs to breach LLM-powered protections in DALL-E 3. Sparks further research into attack/defense dynamics.
- Discusses potential positive applications like using attack method as a red teaming tool to rapidly uncover model vulnerabilities.

In summary, the paper introduces a novel attack that weaponizes LLMs to defeat the safety mechanisms they power in state-of-the-art text-to-image models. It demonstrates an intriguing attack phenomenon and stimulates further work into model security/safety.
