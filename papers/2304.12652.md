# [Hybrid Neural Rendering for Large-Scale Scenes with Motion Blur](https://arxiv.org/abs/2304.12652)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is: How can we synthesize high-fidelity and view-consistent novel view images of large-scale real-world scenes from images captured in the wild that contain inevitable artifacts like motion blur? 

The key points are:

- Synthesizing novel views of large-scale real-world scenes is challenging due to limitations of neural 3D representations and unavoidable artifacts in the image data.

- The paper proposes a hybrid neural rendering approach that combines the strengths of image-based rendering (for high fidelity) and neural 3D representations (for consistency).

- The paper also proposes efficient blur simulation and detection strategies to provide blur-free supervisory signals to optimize the hybrid rendering model when trained on real-world blurry data.

- Experiments on real and synthetic indoor scene datasets demonstrate the proposed method outperforms prior neural rendering techniques, especially point-based methods, for novel view synthesis.

In summary, the paper addresses the problem of rendering high-quality, consistent novel views of real-world scenes by using a hybrid neural rendering approach and handling inevitable image artifacts like blur through simulation and detection techniques.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. Proposing a hybrid neural rendering approach that combines both image-based features and 3D geometry-based neural radiance fields to synthesize novel views of large-scale scenes. The key is a neural feature fusion module that aggregates features from the two modalities.

2. Designing efficient blur simulation and detection strategies to handle motion blur artifacts in the training data. This includes simulating blur on rendered images to provide blur-free supervision, and downweighting blurry images via content-aware blur detection. 

3. Demonstrating through experiments on real and synthetic datasets that the proposed hybrid approach outperforms prior methods like Point-NeRF in generating high-quality, temporally consistent novel views of large scenes. The blur handling also improves sharpness.

In summary, the paper makes contributions in both the neural rendering model design and strategies to deal with unsatisfactory training data. The hybrid model leverages complementary strengths of image-based and geometry-based representations. The blur simulation and detection allows the model to learn from imperfect real-world data. Together these advance the state-of-the-art in novel view synthesis for large real-world scenes containing artifacts.
