# Grounded Decoding: Guiding Text Generation with Grounded Models for
  Robot Control

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, it seems the central research question is how to effectively leverage the knowledge and capabilities of large language models for embodied tasks like robot control. The key ideas explored are:- Large language models (LLMs) have a lot of semantic knowledge from pretraining on large amounts of text data, but lack grounding in real world environments. - Robot policies learned from interaction data are grounded in embodiment and environment, but may lack high-level semantic understanding.- The proposed approach, Grounded Decoding (GD), combines the strengths of LLMs and grounded policies by decoding sequences that have high probability under both the LLM and "grounding functions" that model embodied probabilities like affordances.- GD resembles probabilistic filtering, selecting tokens that are likely under the LLM and grounded models. This enables complex, long-horizon robot tasks by leveraging knowledge from both models.So in summary, the central hypothesis is that guiding LLM decoding with probabilities from grounded models can achieve strong performance on embodied tasks by combining their complementary strengths. The experiments across three robot domains seem aimed at validating this approach.
