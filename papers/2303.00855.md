# Grounded Decoding: Guiding Text Generation with Grounded Models for   Robot Control

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, it seems the central research question is how to effectively leverage the knowledge and capabilities of large language models for embodied tasks like robot control. The key ideas explored are:- Large language models (LLMs) have a lot of semantic knowledge from pretraining on large amounts of text data, but lack grounding in real world environments. - Robot policies learned from interaction data are grounded in embodiment and environment, but may lack high-level semantic understanding.- The proposed approach, Grounded Decoding (GD), combines the strengths of LLMs and grounded policies by decoding sequences that have high probability under both the LLM and "grounding functions" that model embodied probabilities like affordances.- GD resembles probabilistic filtering, selecting tokens that are likely under the LLM and grounded models. This enables complex, long-horizon robot tasks by leveraging knowledge from both models.So in summary, the central hypothesis is that guiding LLM decoding with probabilities from grounded models can achieve strong performance on embodied tasks by combining their complementary strengths. The experiments across three robot domains seem aimed at validating this approach.


## What is the main contribution of this paper?

The main contribution of this paper seems to be presenting Grounded Decoding (GD), an approach for guiding natural language generation with large language models (LLMs) in embodied domains like robotics. Specifically:- GD frames the problem as a type of probabilistic filtering, where the goal is to decode text sequences that have high probability under both the LLM and "grounding" models that represent constraints and objectives in the physical world. - By factorizing the joint probability into the LLM's text probability and probabilities from grounding models (like affordances, safety, etc.), GD allows leveraging the knowledge and semantic capabilities of LLMs while grounding their outputs in the physical world.- GD is demonstrated on three robotics domains: simulated tabletop rearrangement, a 2D maze, and a real mobile manipulator. The results show GD can solve complex, long-horizon tasks by combining the reasoning of the LLM and grounding from models trained on robot interaction data.- GD provides a general, flexible framework for guiding LLM decoding. Different grounding models like affordances, safety, preferences, or multimodal embeddings can be seamlessly incorporated based on the task.So in summary, the key contribution seems to be presenting this method for grounding LLMs in embodied domains by decoding sequences that are likely under both the LLM and grounded models, enabling leveraging LLM knowledge while adhering to real-world constraints. The generality and benefits of this approach are demonstrated across three distinct robotics domains.
