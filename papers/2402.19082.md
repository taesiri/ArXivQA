# [VideoMAC: Video Masked Autoencoders Meet ConvNets](https://arxiv.org/abs/2402.19082)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing masked video modeling (MVM) methods rely excessively on vision transformers (ViTs), which have inadequate spatial modeling capabilities for dense downstream tasks like segmentation and detection. 
- ViT-based MVM methods also consume significant computational resources.
- ConvNets have not been explored for MVM despite their built-in hierarchical structure and efficiency. Applying ConvNets to MVM is non-trivial due to the dense convolution windows resulting in mask leakage.

Proposed Solution:
- VideoMAC - a video masked autoencoder framework built using pure ConvNets by substituting dense convolution with sparse convolution to maintain mask structure.
- Employs an online encoder-decoder network optimized by gradients and a target network updated by exponential moving average (EMA) to model pairs of frames.  
- Introduces a reconstruction consistency loss between the reconstructed patches of the frame pairs to enable temporal modeling.

Main Contributions:
- Pioneering work to enable ConvNet-based hierarchical MVM using sparse convolution.
- A simple yet effective masked video modeling approach using online and target networks with EMA updates to process frame pairs.
- Introduction of reconstruction consistency loss for spatio-temporal modeling in videos.
- State-of-the-art performance on downstream tasks like video object segmentation, body part propagation and human pose tracking compared to previous ViT-based MVM methods.
- Promising image recognition results using models pre-trained on videos, comparable to ConvNet models pre-trained with masked image modeling.

In summary, VideoMAC enables the use of computation and parameter efficient ConvNets for masked video modeling via innovations like sparse convolution and reconstruction consistency loss. It shows superior performance over existing ViT-based MVM methods on various video and image tasks.
