# [Debiasing Machine Learning Models by Using Weakly Supervised Learning](https://arxiv.org/abs/2402.15477)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Machine learning models can produce biased decisions that systematically favor some groups over others based on sensitive attributes like age, financial status etc. 
- Most prior work on debiasing deals with discrete sensitive variables. This paper tackles the harder problem of continuous sensitive variables.
- The paper models the problem as a forecasting task with endogeneity i.e. correlation between independent variables (sensitive attributes) and the error term.

Proposed Solution:
- Post-process the outputs of a black-box ML model to mitigate bias, inspired by techniques from inverse problems.
- Use a neural network in a weakly supervised setting - only a small labeled dataset with true fair scores, and a distributional constraint based on Wasserstein distance.
- Two step process - initial local estimation followed by refinement using the neural network to match distribution and labeled samples.

Main Contributions:
- Handles continuous sensitive variables unlike most prior work. Setting inspired by econometrics.
- Learns notion of fairness from data distribution, does not pre-define subgroups or constraints.
- Model agnostic, black box approach applicable to any ML model.  
- Weakly supervised method reduces expert interventions. Matches distribution and few labeled samples.
- Theoretical guarantee bounding performance in terms of "specialist" models.
- Evaluation on synthetic 1D and 2D signals inspired by economics use cases. High quality estimates from 1% labeled data.
- Handles complex noise terms including product of sensitive attributes.
- Can track time-varying notions of fairness.

In summary, the paper introduces a novel weakly supervised approach to mitigate bias for continuous sensitive attributes by post-processing ML model outputs, with strong theoretical and empirical results.
