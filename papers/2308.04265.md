# [FLIRT: Feedback Loop In-context Red Teaming](https://arxiv.org/abs/2308.04265)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we automatically and efficiently test AI systems such as text-to-image and text-to-text models for vulnerabilities that could lead to generating unsafe or inappropriate content?The authors propose an automated "red teaming" framework called FLIRT (Feedback Loop In-context Red Teaming) that uses in-context learning and a feedback loop to efficiently generate adversarial prompts aimed at triggering target models into generating unsafe content. The key hypotheses appear to be:1) FLIRT will be more efficient and effective at exposing vulnerabilities in models compared to prior red teaming methods that require a lot of data generation or fine-tuning. 2) FLIRT's in-context learning approach will allow generating diverse and effective adversarial prompts by iteratively updating prompts based on model feedback.3) The proposed attack strategies in FLIRT will allow controlling different objectives like diversity and toxicity to expose a wider range of vulnerabilities.4) FLIRT will be effective at red teaming both text-to-image and text-to-text models by triggering them to generate unsafe/inappropriate content.In summary, the central research question is how to efficiently and automatically red team AI systems to expose vulnerabilities, with the hypothesis that the proposed FLIRT framework will achieve this through iterative in-context learning and adaptive attack strategies.
