# Learning to Memorize Entailment and Discourse Relations for   Persona-Consistent Dialogues

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be:How can we improve the consistency and coherence of dialog systems by learning to memorize entailment and discourse relations?The key hypothesis appears to be:By learning latent entailment relations from natural language inference data and discourse relations from dialog context-response pairs, and incorporating them into a seq2seq model, we can improve the consistency and coherence of dialog responses. Specifically, the paper proposes:1) Learning latent entailment relations between premise-hypothesis text pairs from NLI datasets, and storing them in an external memory module. This aims to help with persona consistency.2) Learning latent discourse relations between dialog context-response pairs and storing them in an internal memory module. This aims to help with response coherence. 3) Incorporating the entailment and discourse representations from the two memory modules into a seq2seq model to generate more consistent and coherent responses for dialog tasks.4) Imposing orthogonality constraints between the two latent memory spaces to ensure entailment relations remain dialog-independent.The key hypothesis is that by explicitly modeling these two types of relations in latent memory modules, the model can better capture consistency and coherence for dialog generation. Experiments on PersonaChat and DSTC7-AVSD datasets seem to confirm this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution is proposing a method to improve persona consistency and discourse coherence in dialog systems by learning to memorize entailment and discourse relations. Specifically:- They introduce an external memory module called Entailment Relation Memory (ERM) which learns latent entailment relations from natural language inference data to help the model better understand persona consistency. - They also have an internal Dialogue Discourse Memory (DDM) module to learn discourse relations from the dialog history and improve discourse coherence.- The two memory modules work together during dialog generation to incorporate both entailment and discourse information, allowing the model to produce more persona-consistent and coherent responses. - They show improved performance on two dialog datasets - PersonaChat and DSTC7-AVSD - demonstrating the effectiveness of learning these latent relations to enhance persona consistency and discourse coherence.So in summary, the key innovation is using separate external and internal latent memory modules to capture entailment and discourse relations respectively, and leveraging both during generation to improve persona consistency and coherence in dialog systems.
