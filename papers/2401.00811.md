# [PerSHOP -- A Persian dataset for shopping dialogue systems modeling](https://arxiv.org/abs/2401.00811)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is a lack of annotated conversational datasets in Persian, especially for shopping dialogue systems to train chatbots. Existing datasets are mostly in English or Chinese.

- Collecting and annotating a conversational dataset from scratch is expensive and time-consuming. 

Proposed Solution:
- The authors developed a web application to collect shopping dialogues between customers and sellers through crowd-sourcing. 

- The application partially automated the annotation process using a rule-based system during data collection. Additional manual annotation was then done to complete the dataset.

- In total, they collected 1061 dialogues consisting of 21,925 utterances over 30 days using 122 crowd workers. This is the largest open Persian language dataset for shopping dialogue systems.

- The dataset contains conversations across 15 domains and 36 slots (product attributes). It has both user intents and system actions annotated.

- The authors experimented with intent classification and entity extraction models using DIETClassifier, CRF and BERT-based language models as baselines. They achieved F1 scores of over 90% for intent classification and over 92% for entity extraction.

Main Contributions:

- Created the first open, annotated Persian dataset for training shopping dialogue systems with 1061 dialogues and 21,925 utterances.

- Developed a crowdsourcing mechanism and rule-based semi-automated annotation system to efficiently collect and annotate conversational data.

- Provided benchmark NLU models for intent classification and entity extraction as baselines for future research.

Overall, the authors presented an effective approach to create a dataset for low-resource Persian language and introduced the first shopping dialogue dataset along with baseline models for advancing research in this domain.
