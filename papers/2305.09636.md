# [SoundStorm: Efficient Parallel Audio Generation](https://arxiv.org/abs/2305.09636)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to efficiently generate long, high-quality audio sequences by modeling the tokens of a neural audio codec. Specifically, the paper proposes a method called SoundStorm that can generate audio two orders of magnitude faster than prior autoregressive approaches while maintaining high perceptual quality. The key ideas are:- Using an architecture adapted to the hierarchical structure of the audio tokens produced by residual vector quantization in SoundStream. This allows reducing the sequence length that needs to be modeled.- A parallel, iterative decoding scheme inspired by MaskGIT that predicts the RVQ tokens level-by-level instead of autoregressively. This exploits the conditional independence of finer RVQ levels and enables parallel generation.- A masking scheme during training that mimics the inference procedure.Overall, the paper shows that by designing the model architecture and decoding scheme while accounting for the structure of the discrete audio representations, high-quality and efficient long-form audio generation can be achieved. The results demonstrate that SoundStorm matches the quality of autoregressive modeling baselines while being up to 100x faster.
