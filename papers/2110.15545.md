# [Improving Fairness via Federated Learning](https://arxiv.org/abs/2110.15545)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research questions seem to be:1. Is federated learning necessary for training fair models on decentralized data? In other words, can we simply train locally fair models on each decentralized dataset and aggregate them to get a fair global model?2. How does the performance (accuracy and fairness tradeoff) of current federated learning algorithms for fair learning compare to training on centralized data? Can federated learning match the performance of centralized training? 3. Can we develop an improved federated learning algorithm that achieves better accuracy-fairness tradeoff compared to current approaches and comes closer to the performance of centralized training?To summarize, the key goals of the paper appear to be:- Analyze whether federated learning provides benefits over non-federated approaches for fair decentralized learning.- Identify performance gaps between current federated fair learning algorithms and centralized training.- Propose a new federated learning algorithm called FedFB that improves on current approaches and achieves near-centralized performance.The central hypothesis seems to be that federated learning is necessary but current algorithms are limited, and the proposed FedFB algorithm can bridge the gap by more effectively mimicking centralized training. The theoretical analysis and empirical evaluations aim to validate these claims.
