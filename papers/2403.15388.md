# [LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal   Models](https://arxiv.org/abs/2403.15388)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large multimodal models (LMMs) have shown strong reasoning abilities by combining a visual encoder like CLIP and a large language model. However, they have high computational costs that increase quadratically with the number of input tokens.
- Recent LMMs use more complex visual inputs like high-resolution images and videos which significantly increases the number of visual tokens, exacerbating the computation costs.
- Prior works on efficient LMMs mainly replace the language model backbone with a smaller model, but this sacrifices reasoning performance.

Proposed Solution - LLaVA-PruMerge:  
- The paper proposes an adaptive visual token reduction approach called LLaVA-PruMerge that largely reduces the number of redundant visual tokens while maintaining comparable model performance.

Key Ideas:
- Select the unpruned visual tokens based on their similarity to the class token and spatial tokens using an outlier detection method (IQR). Tokens with higher similarity are more important for capturing visual information.
- Cluster the pruned tokens based on key similarity and merge them with the unpruned tokens using weighted averaging to supplement their information.

Results/Contributions:
- When applied to LLaVA-1.5, LLaVA-PruMerge compresses the visual tokens by 18 times on average (from 576 to 32 tokens) while achieving comparable performance on diverse VQA and reasoning tasks.
- With just 5.5% of the visual tokens, performance is matched to the original LLaVA-1.5 using all tokens.
- The approach demonstrates the redundancy in visual tokens and the viability of building efficient LMMs through visual token reduction.
- In addition to computational savings, LLaVA-PruMerge can complement other LLM acceleration techniques for greater efficiency gains.

In summary, the paper explores a plug-and-play visual token reduction module for LMMs that adaptively prunes redundant tokens and merges important information to maintain model performance with significantly fewer visual tokens as input context. This paves the road for more research into the efficiency-performance trade-off in LMMs.
