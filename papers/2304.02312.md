# [How to choose your best allies for a transferable attack?](https://arxiv.org/abs/2304.02312)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we estimate the transferability of adversarial examples between a source model and a target model, and select the best source model for attacking a given target model?More specifically, the paper seems to address the following key questions:- How should we measure transferability in a way that considers both attack success rate and distortion? The paper argues that only looking at attack success rate provides an incomplete picture.- What factors affect transferability of adversarial examples? The paper examines how transferability depends on the input image, source model, and attack method. - Can we estimate transferability between a source and target model using a limited number of queries to the target model? The paper proposes using fingerprinting methods and estimating adversarial example quality on source models.- Can this transferability estimate be used to select the best source model for attacking a given target? The paper introduces the FiT score that combines model similarity and adversarial example quality to select good source models.- How does this source model selection impact transferability in different attack scenarios like single-model attacks, ensemble attacks, etc? The paper evaluates the FiT selection method in different settings.So in summary, the central hypothesis is that by carefully estimating transferability and selecting source models, the attacker can achieve much higher attack success rates against black-box models compared to random or arbitrary selection. The FiT score is proposed to enable this.
