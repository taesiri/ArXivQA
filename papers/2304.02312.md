# [How to choose your best allies for a transferable attack?](https://arxiv.org/abs/2304.02312)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we estimate the transferability of adversarial examples between a source model and a target model, and select the best source model for attacking a given target model?

More specifically, the paper seems to address the following key questions:

- How should we measure transferability in a way that considers both attack success rate and distortion? The paper argues that only looking at attack success rate provides an incomplete picture.

- What factors affect transferability of adversarial examples? The paper examines how transferability depends on the input image, source model, and attack method. 

- Can we estimate transferability between a source and target model using a limited number of queries to the target model? The paper proposes using fingerprinting methods and estimating adversarial example quality on source models.

- Can this transferability estimate be used to select the best source model for attacking a given target? The paper introduces the FiT score that combines model similarity and adversarial example quality to select good source models.

- How does this source model selection impact transferability in different attack scenarios like single-model attacks, ensemble attacks, etc? The paper evaluates the FiT selection method in different settings.

So in summary, the central hypothesis is that by carefully estimating transferability and selecting source models, the attacker can achieve much higher attack success rates against black-box models compared to random or arbitrary selection. The FiT score is proposed to enable this.


## What is the main contribution of this paper?

 This paper proposes FiTEst, a new methodology to estimate the transferability of adversarial examples between a source model and a target model. The key contributions are:

- It proposes a new transferability score that considers the distortion of adversarial examples, rather than just the attack success rate. This provides a more fair comparison between different attacks. 

- It highlights the large variability in transferability performance depending on the choice of source model, target model, and attack method. Transferable attacks can sometimes perform worse than black-box attacks without careful selection.

- It introduces a selection mechanism called FiTEst that allows an attacker to choose a good source model for a given target using a combination of model similarity estimation and quality of transferable examples.

- Experiments show FiTEst is effective at selecting the best source model for single model attacks, ensemble attacks, and with different combinations of attack methods. With FiTEst, transferability is significantly improved and approaches white-box attack performance.

In summary, the main contribution is the proposal of FiTEst to help select the best ally (source model) for generating transferable attacks against a target model. This is done by considering model similarity and quality of transferable examples rather than just attack success rate.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a new methodology to evaluate the transferability of adversarial examples by comparing the distortion trade-off of transferable attacks to white box and black box attacks, and introduces a selection mechanism called FiT to choose the best source model for transferable attacks using only a few queries to the target model.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other research on adversarial transferability:

- It proposes a new methodology for evaluating transferability that considers distortion/perturbation in addition to just attack success rate. This provides a more nuanced evaluation compared to only looking at attack success rate. 

- It highlights the importance of carefully selecting the source model for transfer attacks, showing that random selection can often perform worse than black-box attacks. Most prior work does not evaluate performance across a wide range of source models.

- It proposes a new selection mechanism (FiT) to identify good source models with minimal queries to the target model. This is a novel contribution compared to prior work.

- It evaluates performance across a large set of models from different architectures. Many prior papers only evaluate on a small set of similar models, so the diversity here is an advantage.

- It compares multiple attack methods (both transferable attacks and traditional white-box attacks) in terms of transferability. Looking at multiple attack paradigms is less common.

- It considers both single model and ensemble model attacks. Many papers focus on just one. Evaluating both provides a more complete picture.

Overall, the large-scale experiments across diverse models and attacks make the results more convincing compared to prior work. The proposed FiT selection method is also a notable new technique for improving transferability. The focus on distortion is another key differentiator from most existing literature.
