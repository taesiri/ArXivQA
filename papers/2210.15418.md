# [FreeVC: Towards High-Quality Text-Free One-Shot Voice Conversion](https://arxiv.org/abs/2210.15418)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to achieve high-quality text-free one-shot voice conversion without requiring text annotation or a large amount of data. 

Specifically, the paper proposes strategies to:

1) Disentangle content information from speaker information without text annotation, in order to convert the voice while preserving the linguistic content. 

2) Improve the purity of the extracted content information and strengthen the disentanglement ability of the model, without needing a large annotated dataset.

3) Adopt an end-to-end framework for high-quality waveform reconstruction that reduces the mismatch between the conversion model and vocoder.

4) Perform one-shot voice conversion using only a single utterance from the target speaker.

The key hypothesis is that by disentangling content and speaker information through techniques like information bottleneck on speech SSL features and spectrogram-resize based data augmentation, high-quality one-shot voice conversion can be achieved without relying on textual annotation or a large dataset.
