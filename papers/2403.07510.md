# [Relevance Score: A Landmark-Like Heuristic for Planning](https://arxiv.org/abs/2403.07510)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Landmark-based heuristics have been very successful for guiding search in automated planning. Landmarks are facts/actions that must be achieved at some point in all valid plans. However, computing complete landmark information is expensive and many planning problems lack non-trivial landmarks beyond those in the initial state or goals. This limits the effectiveness of landmark-based heuristics on such problems.

Proposed Solution:
The authors propose a new "relevance score" heuristic that generalizes landmarks. Rather than facts/actions that must occur in all plans, it estimates how frequently each fact/action occurs across the space of possible plans. Facts irrelevant to achieving the goals will have low scores, while those critical to all plans will be landmarks with maximal scores. This provides an informative heuristic even when no non-trivial landmarks exist.

Computation: 
The relevance score is computed by sampling state trajectories using a hypothetical non-deterministic planning agent. The agent randomly selects actions that achieve required facts until reaching the goals. The score estimates the probability that each fact/action would be sampled across many trajectories. The final heuristic sums the scores of facts not yet achieved.

Contributions:
- Formalizes the concept of a relevance score that generalizes landmarks to capture facts/actions that commonly appear in plans without requiring they appear in all plans
- Provides equations to incrementally compute this score during search tree construction
- Empirically demonstrates that while more expensive on normal planning problems, the relevance score heuristic can solve problems on which landmark-counting fails by lacking heuristics gradients
- Suggests a hybrid approach that uses each heuristic selectively based on the availability of non-trivial landmarks

Overall, the paper introduces a novel heuristic that advances state-of-the-art capabilities for planning problems lacking well-defined landmarks. The generality of the relevance score also creates opportunities to apply similar ideas to other search-based AI problems.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper defines a novel "relevance score" heuristic that generalizes landmarks to estimate the frequency with which facts appear in partial plans, experimentally shows it performs worse than landmark counting on standard planning problems but substantially better on problems lacking non-trivial landmarks, and proposes using both heuristics by selecting landmark counting when good landmarks exist and the relevance score otherwise.


## What is the main contribution of this paper?

 The key contribution of this paper is to define and describe an approach for computing a novel "Relevance Score" heuristic ($h_\Xi$). This heuristic generalizes the concept of a landmark, which must be true at some point in all plans (under delete relaxation), to relevance, which evaluates facts or actions according to how often they appear in plans (also under the delete relaxation). The paper shows experimentally that while the original landmark-based heuristic leads to better performance on problems with well-defined landmarks, the relevance score approach substantially improves performance on problems that lack non-trivial landmarks.

In summary, the main contribution is the definition, computation, and experimental validation of a new relevance score heuristic that guides search more effectively than landmark counting for a class of planning problems lacking good landmarks.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Landmarks - facts or actions that appear in all valid solutions to a planning problem, used to create heuristics to guide search
- Relevance score - a proposed extension of landmarks that considers facts/actions that appear frequently but not necessarily in all plans
- Heuristic function - a function that estimates the cost/distance to reach the goal state from a given state
- Delete relaxation - a common simplification of planning problems that removes negative preconditions and effects 
- Weighted A* search - the underlying search procedure used with the heuristics to find plans
- Performance measures - metrics used to evaluate and compare the heuristics, including proportion of problems solved, time, states expanded, plan length
- Landmark-free problems - planning problems generated by the authors that intentionally lack non-trivial landmarks

The key terms reflect the paper's focus on defining and evaluating a novel relevance score heuristic in comparison to existing landmark-based heuristics for guiding search in automated planning. The experimental results demonstrate strengths and weaknesses of the relevance score on problems with and without clear landmarks.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper defines a "relevance score" that generalizes the concept of landmarks. How is this relevance score calculated? What equation is used to compute it? How does it differ from simply counting landmarks?

2. The paper proposes using a non-deterministic agent (NDA) to sample partial plans and estimate the relevance score. What is the NDA's sampling strategy? How does it decide which actions and facts to include in a partial plan sample? 

3. When computing the relevance score, the paper refers to something called the "choices counter." What is this and what role does it play in the calculation? How does it relate to the probability that a node gets sampled?

4. The paper describes using a depth-first search procedure to explore the planning graph and estimate relevance scores. What threshold and stopping conditions are used? How was this threshold selected or tuned? 

5. For practical problems, the full planning graph cannot be explored. The paper refers to using a "lower bound" for the relevance score based on a partially explored graph. How tight is this lower bound in practice? How quickly does it converge?

6. The LCA (Lowest Common Ancestor) of two nodes plays a key role. The paper mentions more efficient ways to calculate LCAs. What is the complexity of the approach they use? What is the complexity of alternative approaches?

7. When using the relevance score heuristic to guide search, scores are calculated for a given state. How are scores adjusted or truncated to account for facts that are already satisfied in the state? 

8. The heuristic guide search by preferring actions that achieve facts with higher relevance scores. Does this create any unintended biases or effects on the resulting plans compared to landmark-based heuristics?

9. The paper identifies a class of planning problems where landmark-based heuristics fail but relevance scores succeed. What are the key properties of this class of problems? Why do landmarks fail and relevance scores succeed?

10. The results show worse performance on standard problems with well-defined landmarks. What explains this behavior? Is there a way to get the best of both landmark-based and relevance score-based heuristics?
