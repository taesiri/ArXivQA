# [Rejuvenating image-GPT as Strong Visual Representation Learners](https://arxiv.org/abs/2312.02147)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes D-iGPT, an enhanced version of image GPT (iGPT) that achieves state-of-the-art performance on ImageNet classification using only publicly available datasets. D-iGPT makes two key modifications to iGPT: (1) it shifts the prediction target from raw pixels to semantic tokens provided by CLIP, enabling more high-level understanding of image content, and (2) it adds supervision on visible tokens using a separate discriminative decoder, supplementing the main autoregressive modeling. Extensive experiments show D-iGPT significantly outperforms masked image modeling approaches like MAE and prior autoregressive methods across tasks like classification, segmentation, and robustness evaluation. Notably, D-iGPT attains 89.5% ImageNet accuracy using only public data, comparable to private data models with billions of parameters. The simplicity yet effectiveness of D-iGPT demonstrates autoregressive pre-training is highly scalable and should inspire more research on vision foundation models.
