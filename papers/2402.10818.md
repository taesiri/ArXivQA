# [Trading off Consistency and Dimensionality of Convex Surrogates for the   Mode](https://arxiv.org/abs/2402.10818)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- In multiclass classification with a large number of outcomes, optimizing a consistent and convex surrogate loss often requires a very high dimensional (n-1 dims) prediction space, which is computationally intractable. 
- The paper examines ways to trade off between surrogate loss dimension, consistency, and number of problem instances.

Proposed Solution:
- The paper proposes using polytope embeddings that map outcomes to the vertices of low dimensional polytopes to reduce the prediction space. 
- This induces a natural loss function and link function between the prediction and outcome spaces.
- The paper analyzes the consistency properties of these surrogate losses, showing there always exist both calibrated and "hallucination" regions where consistency does or does not hold respectively.
- Under low noise assumptions, consistency can be restored. Examples are shown for cube and permutahedron embeddings.
- With multiple problem instances, consistency for the mode can be achieved over the whole simplex using just n/2 dimensions.

Main Contributions:
- Formalization and analysis of polytope embedding based surrogates for multiclass classification.
- Proof that some consistency always holds, but hallucinations are inevitable in low dims.
- Demonstration of consistency under low noise for cube and permutahedron embeddings.  
- Result showing the mode can be elicited over the whole simplex using n/2 dims and multiple problem instances.
- Provides guidance to practitioners on appropriate embedding dim tradeoffs.

In summary, the paper provides an extensive analysis of polytope embedding based surrogates, highlighting tradeoffs between consistency, dimension, and problem instances. Key results help guide the practical usage of such computationally simpler surrogates.
