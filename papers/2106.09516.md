# [Transductive Few-Shot Learning: Clustering is All You Need?](https://arxiv.org/abs/2106.09516)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main contributions of this paper are:1. It proposes a general formulation for clustering and transductive few-shot learning that integrates prototype-based objectives (e.g. K-means, K-modes), Laplacian regularization, and supervision constraints. 2. It develops a concave-convex relaxation of the problem and derives an efficient block-coordinate bound optimization algorithm called SLK with convergence guarantees. The algorithm performs parallel updates of the assignment variables.3. It adapts the formulation for transductive few-shot learning tasks, where the goal is to classify query samples given a support set with a few labeled examples per class.4. It provides a thorough convergence analysis of SLK based on point-to-set maps and Cauchy sequences. 5. It evaluates SLK extensively on clustering and few-shot learning tasks, showing it is competitive in terms of accuracy and optimization quality while scaling to large problems.6. Surprisingly, it finds that basic clustering methods like K-means perform competitively to state-of-the-art transductive few-shot learning techniques on standard benchmarks, indicating potential limitations of current evaluations.In summary, the central hypothesis is that formulating few-shot learning as a constrained clustering problem, relaxing it appropriately, and optimizing it with a scalable block-coordinate approach can yield an effective and efficient solution for transductive few-shot tasks. The experiments aim to validate the viability of this approach against the state-of-the-art.
