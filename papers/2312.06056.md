# [METAL: Metamorphic Testing Framework for Analyzing Large-Language Model   Qualities](https://arxiv.org/abs/2312.06056)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

The paper proposes a Metamorphic Testing (MT) framework called METAL for systematically evaluating the quality attributes of Large Language Models (LLMs) such as robustness, fairness, non-determinism, and efficiency. The framework defines Metamorphic Relation (MR) templates covering combinations of quality attributes and tasks in LLMs, and then automatically generates hundreds of MRs using textual perturbation functions. The MR satisfaction is evaluated using the Attack Success Rate metric combined with semantic similarity metrics. Experiments conducted on GooglePaLM, ChatGPT, and Llama2 demonstrate METAL's effectiveness in revealing quality risks of LLMs - GooglePaLM outperforms others, while Llama2 shows more fluctuating results. The framework also identifies the most effective MRs for testing each LLM task. A key finding is that character and word-level perturbations work best for classification and generative tasks respectively. The feasibility of self/cross-examination of LLMs using the framework is also validated, with ChatGPT generating the most effective MRs overall. The modular and automated nature of METAL provides a systematic LLM testing approach adaptable across quality attributes, tasks, and models.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) have potential risks due to their blackbox and probabilistic nature, lacking guarantees on quality attributes like robustness and fairness.  
- Existing methods for testing LLMs have limited coverage of quality attributes and tasks, are not easily extensible, and rely only on attack success rate to evaluate effectiveness.

Proposed Solution:
- The authors propose METAL, a metamorphic testing framework for systematically analyzing quality attributes of LLMs.  
- METAL defines modular metamorphic relations (MRs) covering robustness, fairness, non-determinism and efficiency over 6 common LLM tasks.
- It generates hundreds of MRs automatically from templates using textual perturbations at character, word and sentence levels.
- New metrics are introduced that combine attack success rate with semantic/structural text similarities to accurately assess MR effectiveness.

Contributions:
- Comprehensive set of MR templates to evaluate essential quality attributes over primary LLM tasks.
- Automated MR generation for self/cross-examination of LLMs using perturbations.  
- Novel effectiveness metrics integrating attack success rates with text similarities.
- Experiments on 3 prominent LLMs validate METAL reveals quality risks, guides optimal MRs per task, and shows feasibility of LLM self/cross-examination.

In summary, the paper proposes a systematic metamorphic testing framework called METAL to evaluate quality attributes of large language models by automatically generating customizable metamorphic relations using perturbations and new effectiveness metrics. Experiments demonstrate its ability to reveal quality risks in major LLMs.
