# [CORE: Mitigating Catastrophic Forgetting in Continual Learning through   Cognitive Replay](https://arxiv.org/abs/2402.01348)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Continual learning aims to enable neural networks to continuously learn new information over time. However, catastrophic forgetting remains a key challenge, where models tend to forget previously learned knowledge upon learning new information. This is analogous to how human memory can deteriorate when learning new things. 

Existing approaches like parameter isolation and regularization have limitations in scalability and determining parameter importance. Replay-based methods that store data in a buffer are promising but fail to fully utilize the buffer's potential. Specifically, they lack strategic buffer allocation across tasks and overlook the quality/representativeness of replayed data.

Proposed Solution:
This paper introduces COgnitive REplay (CORE) to optimize replay buffers by mimicking human memory mechanisms. It evaluates each task's forgetting rate and anticipated interference to calculate an "attention" score. This enables two key strategies:

1) Adaptive Quantity Allocation (AQA): Dynamically allocates more buffer space to tasks needing more attention based on their forgetting rates to implement targeted recall. It also spaces out review for less forgetful tasks.  

2) Quality-Focused Data Selection (QFDS): Selects representative, balanced data samples for each task to cover the feature space based on the model's latent representation. This prevents biased sample selection.

Together, AQA and QFDS enhance replay efficacy to alleviate catastrophic forgetting in continual learning.

Main Contributions:
- Novel replay-based method CORE that integrates insights from human memory mechanisms 
- Adaptive Quantity Allocation strategy to dynamically adjust buffer allocation across tasks
- Quality-Focused Data Selection strategy to select representative, balanced replay data
- Extensive experiments showing CORE outperforms baselines by large margins in average and lowest (most forgetful) task accuracy
- Establishes more advanced benchmark for replay-based continual learning methods
