# [Continual Forgetting for Pre-trained Vision Models](https://arxiv.org/abs/2403.11530)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
The paper addresses the novel problem of "continual forgetting", which involves selectively and continuously removing unwanted information from pre-trained vision models while preserving other knowledge. This is important for privacy protection and reducing model bias. Key challenges are (1) efficiently and effectively deleting unwanted knowledge upon request, and (2) minimizing the impact on remaining knowledge (catastrophic forgetting).

Method: 
The paper proposes Group Sparse LoRA (GS-LoRA) to address the above challenges. The key ideas are:

(1) Use LoRA modules to fine-tune the feedforward networks (FFNs) in Transformer blocks to erase unwanted knowledge. This achieves efficient and effective forgetting by modifying only a small set of parameters. 

(2) Adopt group sparse regularization to automatically select only a few FFNs to modify instead of all. This mitigates catastrophic forgetting on remaining knowledge by minimizing model changes.

(3) Additional techniques like sparsity warmup and selective loss functions further enhance the method.

Experiments:
Extensive experiments were conducted on face recognition and object detection tasks requiring privacy protection. Both single-step and continual forgetting scenarios were evaluated. GS-LoRA managed to effectively erase specific classes with minimal impact on other classes. Only ~1% of parameters needed tuning. GS-LoRA outperformed baselines including continual learning and machine unlearning methods.

Contributions:
(1) Identified and formulated the novel continual forgetting problem.
(2) Proposed GS-LoRA to address key challenges via efficient LoRA fine-tuning and group sparsity.
(3) Demonstrated state-of-the-art performance in erasing vision model knowledge continually while preserving the rest.

The work has strong practical value in enforcing privacy and fairness by selectively removing unwanted knowledge from pre-trained models.
