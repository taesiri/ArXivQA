# [Towards Foundation Time Series Model: To Synthesize Or Not To   Synthesize?](https://arxiv.org/abs/2403.02534)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Industry faces challenges of forecasting for large number of short time series data with limited historical data points. Training individual models is computationally expensive. 
- There is a need for "foundation models" that can work in zero-shot and few-shot settings to address these challenges.
- Synthetic data can potentially help train such models, but there is limited analysis on whether real or synthetic data is better.

Proposed Solution:
- The paper proposes an approach to train a transformer-based foundation time series model on synthetic data.
- The synthetic data is generated by sampling Fourier coefficients and combining seasonal patterns with trends like linear, quadratic etc.
- The model is evaluated on real-world time series datasets in zero-shot, few-shot and fully supervised settings.
- Its performance is compared to state-of-the-art models like Transformers, CNNs and baseline models.

Key Contributions:
- Systematic comparison of foundation models trained on real vs synthetic data for time series forecasting.
- Analysis showing that even with limited real data, supervised learning outperforms pre-training with abundant synthetic data.
- Proposed data generation process to create versatile synthetic time series.
- Demonstrated importance of selecting appropriate source dataset for transfer learning in time series.
- Analysis of model performance in few-shot setting with varying training data sizes.

In summary, the paper shows that while synthetic data offers flexibility, real data is still better for training foundation forecasting models even if available in limited quantities. The choice of source dataset significantly impacts model transferability. With enough real samples, supervised learning surpasses pre-training on synthetic data.
