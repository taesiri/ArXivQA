# Small Models are Valuable Plug-ins for Large Language Models

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: How can we effectively combine large language models (LLMs) with smaller fine-tuned models to improve performance on supervised NLP tasks?Specifically, the paper proposes a new method called "Super In-Context Learning" (SuperICL) that allows large black-box language models like GPT-3 to work together with smaller locally fine-tuned models like RoBERTa. The key hypothesis is that by incorporating predictions and confidence scores from the smaller "plug-in" models into the context for the LLM, the overall model can achieve better performance compared to just using the LLM alone with in-context learning. The paper aims to demonstrate that SuperICL can:- Achieve superior performance compared to just using the LLM or smaller model alone- Address instability issues with standard in-context learning- Enhance capabilities of smaller models, like extending multilinguality- Provide interpretability by having the LLM generate explanationsIn summary, the central research question is how to effectively combine large black-box LLMs with smaller plug-in models trained on task-specific data to get performance gains on supervised NLP tasks. The proposed SuperICL method aims to test the hypothesis that this combination can outperform either model individually.


## What is the main contribution of this paper?

The main contribution of this paper is proposing Super In-Context Learning (SuperICL), a method that combines large language models (LLMs) with locally fine-tuned smaller models to improve performance on supervised NLP tasks. The key ideas are:- Using a smaller pre-trained model as a "plug-in" that is fine-tuned on the full training set of a task, since smaller models are more accessible for fine-tuning. - Constructing a context for the LLM that includes labeled examples from the training set along with the plug-in model's predictions and confidences. This allows the LLM to learn from the plug-in's expertise.- During inference, the LLM takes the test input, plug-in prediction, and makes the final prediction, optionally providing an explanation when overriding the plug-in's prediction.- Experiments show SuperICL outperforms LLM in-context learning and fine-tuned smaller models on GLUE and XNLI benchmarks. It also demonstrates improved stability and interpretability compared to standard in-context learning.In summary, the main contribution is using fine-tuned smaller models as plug-ins to improve large model performance on supervised NLP tasks, overcoming limitations like model size and limited accessibility that hinders directly fine-tuning large models. The combination provides strengths of both small and large models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes Super In-Context Learning (SuperICL), a method that combines large language models with locally fine-tuned smaller models as plug-ins to improve performance on supervised NLP tasks.


## How does this paper compare to other research in the same field?

Here are my thoughts on how this paper compares to other related work:- The key idea of combining large and small models is novel compared to prior work on in-context learning. Most prior work focuses on selecting or optimizing the examples for the context, whereas this paper introduces the idea of using a separately fine-tuned small model as a "plug-in". - The paper demonstrates state-of-the-art results by combining large and small models, outperforming both in-context learning and fine-tuned models alone. This shows the effectiveness of the proposed approach.- The idea of incorporating confidence scores from the small model is unique. This provides helpful uncertainty information to guide the large model's predictions. Prior work does not consider confidence in this way.- The paper provides useful analysis into the model's prediction override behavior based on confidence scores. This sheds light on the internal mechanics of how the large model utilizes the small model's knowledge.- The stability analysis demonstrates an advantage over standard in-context learning, which is known to be unstable based on example selection. Leveraging a separately trained small model helps absorb task-specific knowledge.- Exploring the effect of adversarial attacks on the small model is insightful. It reveals a potential limitation of relying on the small model, if it is not robust.Overall, I would say the core idea of SuperICL and the analyses around confidence scores, stability, and adversarial attacks help advance the field's understanding of combining large pretrained models with smaller task-specific models. The state-of-the-art results also demonstrate the effectiveness of the approach as a practical technique. The paper makes several novel contributions compared to prior work on in-context learning.
