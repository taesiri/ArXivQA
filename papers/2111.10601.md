# [Deep Safe Multi-Task Learning](https://arxiv.org/abs/2111.10601)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is how to achieve safe multi-task learning, where the performance of a multi-task learning model is guaranteed to be no worse than training separate single-task models. The key ideas and contributions are:- The paper formally defines negative sharing, where multi-task learning can hurt performance on some tasks compared to single-task models. It also defines safe multi-task learning, where performance is guaranteed to be at least as good as single-task models.- It proposes a Deep Safe Multi-Task Learning (DSMTL) model to achieve safe MTL through a gating mechanism to combine public and private encoders. - Two variants are proposed - DSMTL with Individual Learning (DSMTL-IL) and DSMTL with Joint Learning (DSMTL-JL). Theoretical analysis shows these can achieve empirical or probable safe MTL.- An extension called DSMTL with Architecture Learning (DSMTL-AL) is proposed to improve scalability by learning a compact architecture.- Experiments on CV datasets like Cityscapes, NYUv2, PASCAL-Context and Taskonomy demonstrate the proposed methods can achieve safe MTL and outperform baselines.In summary, the key contribution is proposing methods to guarantee safe MTL performance along with theoretical analysis and empirical validation. This addresses the important problem of potential negative transfer in MTL.
