# [Deep Safe Multi-Task Learning](https://arxiv.org/abs/2111.10601)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is how to achieve safe multi-task learning, where the performance of a multi-task learning model is guaranteed to be no worse than training separate single-task models. The key ideas and contributions are:- The paper formally defines negative sharing, where multi-task learning can hurt performance on some tasks compared to single-task models. It also defines safe multi-task learning, where performance is guaranteed to be at least as good as single-task models.- It proposes a Deep Safe Multi-Task Learning (DSMTL) model to achieve safe MTL through a gating mechanism to combine public and private encoders. - Two variants are proposed - DSMTL with Individual Learning (DSMTL-IL) and DSMTL with Joint Learning (DSMTL-JL). Theoretical analysis shows these can achieve empirical or probable safe MTL.- An extension called DSMTL with Architecture Learning (DSMTL-AL) is proposed to improve scalability by learning a compact architecture.- Experiments on CV datasets like Cityscapes, NYUv2, PASCAL-Context and Taskonomy demonstrate the proposed methods can achieve safe MTL and outperform baselines.In summary, the key contribution is proposing methods to guarantee safe MTL performance along with theoretical analysis and empirical validation. This addresses the important problem of potential negative transfer in MTL.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It provides formal definitions for negative sharing, safe multi-task learning, empirically safe multi-task learning, and probably safe multi-task learning in the context of multi-task learning. 2. It proposes a Deep Safe Multi-Task Learning (DSMTL) model with two learning strategies - individual learning and joint learning. Theoretical analysis is provided to show these strategies can achieve empirically/probably safe multi-task learning under certain conditions.3. It proposes an extension called DSMTL with Architecture Learning (DSMTL-AL) that leverages neural architecture search to learn a more compact architecture while still achieving comparable performance. 4. Extensive experiments on benchmark datasets demonstrate the proposed methods can achieve safe multi-task learning and outperform state-of-the-art baselines.In summary, the key contribution is proposing the DSMTL model and its extension DSMTL-AL to achieve safe multi-task learning along with theoretical analysis and empirical validation. The formal definitions of different types of safe multi-task learning also help characterize this new problem.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a Deep Safe Multi-Task Learning (DSMTL) model to address the negative sharing problem in multi-task learning, where the model performance on some tasks becomes worse than training them separately. The DSMTL model consists of shared and private encoders combined via a learnable gating mechanism, and is proved to achieve safe multi-task learning where the model performs no worse than single-task models. Experiments on semantic segmentation and other vision tasks demonstrate the effectiveness and safeness of the DSMTL model compared to existing multi-task learning methods.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in multi-task learning:- The paper focuses on addressing the issue of negative transfer/sharing in multi-task learning, where joint training on multiple tasks can sometimes hurt performance on some tasks. This issue has been observed empirically in some prior works, but there has been little formal study or methods proposed to directly address it. So this work provides useful formal definitions and analysis around the idea of "safe" multi-task learning.- The proposed DSMTL model architecture seems similar in spirit to some other MTL architectures like MTAN, AFA, etc. that try to balance shared and private components/representations. However, the key novelty is in the theoretical guarantees provided for avoiding negative transfer via the gating mechanism and learning strategies. - The idea of learning the architecture itself using neural architecture search is becoming more common, but the application to find optimal sharing structure for safe MTL is novel.- The paper provides formal theoretical analysis on the generalization performance of the proposed models, relating it to the single task performance. This kind of theoretical study of MTL methods is still relatively uncommon.- Empirical evaluation on multiple standard MTL benchmarks compares the proposed methods against state-of-the-art MTL baselines as well as ablation studies. The results support the effectiveness of the proposed techniques.Overall, I think the paper makes good contributions in terms of formalizing the problem, providing theoretical analysis for safe MTL, and proposing techniques that are demonstrated to achieve strong empirical performance on benchmarks while avoiding negative transfer. The connections between theory and practice are stronger than most existing MTL works. It clearly advances the state-of-the-art in principled and safe MTL.


## What future research directions do the authors suggest?

Based on my reading of the paper, here are some of the future research directions suggested by the authors:- Developing safe multi-task learning methods for other types of machine learning problems beyond computer vision, such as natural language processing tasks. The authors mention they are interested in generalizing the proposed DSMTL methods to other learning problems.- Exploring methods to theoretically prove the safeness of the DSMTL-AL model. The authors were able to prove safeness guarantees for DSMTL-IL and DSMTL-JL but not for DSMTL-AL. Developing theoretical analysis for DSMTL-AL is noted as future work.- Combining the proposed methods with additional techniques like knowledge distillation to further improve performance and safeness. The authors suggest knowledge distillation could help address the performance gap issue for safe learning methods.- Considering multi-modal and multi-source multi-task learning scenarios. The authors mention multi-modal learning as a potential direction to extend the ideas of safe multi-task learning.- Developing safe transfer learning approaches. The authors note there are similarities and differences between multi-task learning and transfer learning when it comes to negative transfer/sharing. Exploring safe transfer learning is suggested as an area for future investigation.- Applying the ideas of safe multi-task learning to other safety-critical machine learning problems, like safe reinforcement learning. The authors suggest the notion of safeness studied here could be relevant for other domains concerned with safe AI.In summary, the main future directions highlighted are extending safe multi-task learning to new problems/settings, combining it with other techniques to boost performance, and investigating theoretical safeness guarantees.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper proposes a Deep Safe Multi-Task Learning (DSMTL) method to address the problem of negative sharing in multi-task learning, where an MTL model performs worse than single-task learning on some tasks. The authors first formally define negative sharing and safe multi-task learning. Then they propose the DSMTL model consisting of a shared encoder, private encoders, gates, and decoders. Two learning strategies called individual learning and joint learning are introduced, leading to DSMTL-IL and DSMTL-JL variants. Theoretical analysis shows these variants can achieve empirically/probably safe multi-task learning. To improve scalability, an extension called DSMTL-AL is proposed to learn a compact architecture via neural architecture search. Experiments on benchmark datasets demonstrate the proposed methods can achieve safe multi-task learning and outperform baselines. The key novelty is the proposed methods can theoretically guarantee safe multi-task learning.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:The paper proposes a Deep Safe Multi-Task Learning (DSMTL) model to achieve "safe" multi-task learning, where the performance of the multi-task model is guaranteed to be no worse than single-task models on each task. The key idea is to combine both shared and private encoders for each task via a gating mechanism. This allows adapting the degree of sharing between tasks. Two learning strategies are proposed. DSMTL with Individual Learning (DSMTL-IL) learns the private encoder first and then the shared encoder. DSMTL with Joint Learning (DSMTL-JL) learns them together. Both methods are proven to achieve "empirically/probably safe" multi-task learning under mild conditions. To improve scalability, DSMTL with Architecture Learning (DSMTL-AL) is proposed to learn a compact architecture using neural architecture search. The paper makes four main contributions: (1) Formal definitions for multi-task learning safeness are provided, including "negative sharing" and different versions of "safe" multi-task learning. (2) The DSMTL model and two learning strategies are proposed with theoretical guarantees for safeness. (3) DSMTL-AL is proposed to learn compact architectures. (4) Experiments on four benchmark datasets demonstrate the effectiveness of the proposed methods in achieving safe multi-task learning and outperforming baselines. Theoretical and empirical analyses also provide insights into the model. Overall, this is a novel and thorough treatment of an important issue in multi-task learning.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper "Deep Safe Multi-Task Learning":The paper proposes a Deep Safe Multi-Task Learning (DSMTL) model to achieve "safe multi-task learning" where the performance of the multi-task model is guaranteed to be no worse than single-task models on each task. The DSMTL model consists of a shared encoder, private encoders, gates, and decoders. Two learning strategies are proposed: 1) DSMTL with Individual Learning (DSMTL-IL) which trains private and shared parts separately, and is proved to achieve "empirically/probably safe multi-task learning" 2) DSMTL with Joint Learning (DSMTL-JL) which trains all parameters together and achieves a different notion of safeness. An extension called DSMTL with Architecture Learning (DSMTL-AL) is proposed to learn a compact architecture using neural architecture search, which is more scalable while maintaining performance. Experiments on semantic segmentation, depth estimation and other vision tasks demonstrate the effectiveness and safeness of the proposed DSMTL methods.
