# [Disentangled Latent Representation Learning for Tackling the Confounding   M-Bias Problem in Causal Inference](https://arxiv.org/abs/2312.05404)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Estimating causal effects from observational data is challenging due to confounding bias caused by measured and unmeasured confounders. 
- A particularly difficult case is when there are "confounding M-bias variables" which act as both M-bias variables and confounders simultaneously. 
- Adjusting for these variables introduces bias, while not adjusting for them fails to eliminate confounding bias. So existing methods have no good solution.

Proposed Solution:  
- The paper proposes a Disentangled Latent Representation learning framework (DLRCE) to address this problem.  
- DLRCE uses variational autoencoders to learn three latent representations - Z from proxy variables of latent confounders, and Psi from proxy variables, which is further disentangled into representations of two separate latent confounders L and F.
- These latent representations along with the proxy variables are then used to estimate unbiased causal effects. 

Main Contributions:
- Identifies and formalizes the previously unsolved problem of "confounding M-bias variables".
- Proposes the DLRCE algorithm to learn disentangled latent representations to adjust for both confounding bias and M-bias when estimating causal effects.
- Provides theoretical analysis to show DLRCE can recover the true causal effects.
- Extensive experiments on synthetic and real-world datasets demonstrate superior performance of DLRCE over state-of-the-art methods.
- First solution able to address the confounding M-bias problem and shows promise for estimating causal effects from complex real-world observational data.
