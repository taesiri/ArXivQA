# [Augmenting text for spoken language understanding with Large Language   Models](https://arxiv.org/abs/2309.09390)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to improve spoken semantic parsing models by using unpaired text data, without requiring matched speech-text-semantic parse triplets. The key ideas explored are:1) Comparing methods like Joint Audio-Text training (JAT) and Text-to-Speech (TTS) to generate speech representations for unpaired text from existing textual corpora.2) Using Large Language Models like LLama 2.0 to generate synthetic text and text-semantic parse data through prompting, which can then be paired with speech using JAT or TTS. 3) Evaluating these techniques for utilizing unpaired text in two settings - existing domains where some paired data is available, and new domains where no paired data exists.The overarching goal is to show that unpaired text can be used to improve spoken semantic parsing without needing expensive labeled triplet data, using both existing textual data as well as synthetic data generated by Large Language Models.
