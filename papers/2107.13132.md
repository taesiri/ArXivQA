# [Unsupervised Learning of Neurosymbolic Encoders](https://arxiv.org/abs/2107.13132)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we learn latent representations that are both low-dimensional and interpretable, by integrating neural networks with symbolic programs? Specifically, the authors propose an approach for "unsupervised neurosymbolic representation learning", where part of the latent representation is computed by a symbolic program written in a domain-specific language (DSL). This allows incorporating human expertise into the latent space. The rest of the latent variables are learned using a neural network, to maintain the model's flexibility. The key ideas are:- Propose neurosymbolic encoders that produce latent codes by composing neural nets and symbolic programs. This leads to more interpretable and disentangled representations compared to purely neural approaches.- Integrate variational autoencoders with program synthesis techniques to learn the neural network and symbolic program jointly.- Evaluate the approach on real-world trajectory datasets from biology and sports analytics. Demonstrate improved clustering and downstream task performance compared to neural baselines.In summary, the central hypothesis is that combining neural networks with symbolic programs can produce latent representations that balance interpretability and disentanglement with model flexibility. The key research questions are around developing algorithms to learn such neurosymbolic representations in an unsupervised manner, and evaluating their benefits.
