# [Improving Contrastive Learning by Visualizing Feature Transformation](https://arxiv.org/abs/2108.02982)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we enhance generic contrastive self-supervised learning through feature-level data manipulation? The authors propose designing a visualization scheme to analyze and interpret the learning process in contrastive self-supervised models. Using this visualization, they gain insights about the characteristics of positive and negative pairs during training. They then propose two novel Feature Transformation (FT) techniques to create "harder positives" and more "diversified negatives" to improve the learned representations:- Positive extrapolation to create harder positives by increasing the view variance between positive pairs. This forces the model to learn more view-invariant representations. - Negative interpolation to provide more diversified negatives by randomly interpolating negatives in the memory bank. This makes the model more discriminative.The main hypothesis is that these FT techniques will enable learning more robust and discriminative representations compared to just using data augmentation, by directly manipulating the features rather than just augmenting the input data. Experiments on ImageNet and downstream transfer tasks validate the efficacy of the proposed techniques.In summary, the key research question is how to enhance contrastive self-supervised learning through feature transformations, with the hypothesis that manipulating features directly will be more effective than just data augmentation. The proposals of positive extrapolation and negative interpolation FT aim to address this question.
