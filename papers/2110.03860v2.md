# [Token Pooling in Vision Transformers](https://arxiv.org/abs/2110.03860v2)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How can we improve the computational efficiency and reduce redundancy in vision transformers using token downsampling/pooling methods?

More specifically, the key hypotheses appear to be:

1) Vision transformers contain redundancy in the token representations due to the smoothing effect of softmax attention. This redundancy can be exploited to reduce computations via token downsampling/pooling.

2) Existing token downsampling methods like grid pooling and score-based pruning are suboptimal. A better downsampling operator can be designed by formulating it as a reconstruction error minimization problem.

3) Clustering algorithms like k-means and k-medoids can efficiently solve the downsampling optimization problem and provide an improved trade-off between computational cost and accuracy compared to prior methods.

So in summary, the central hypothesis is that a new downsampling operator called Token Pooling, implemented via clustering algorithms, can better exploit redundancy in vision transformers to achieve superior efficiency and accuracy trade-offs. The paper aims to demonstrate this through theoretical analysis, proposing the new method, and empirical evaluations on ImageNet.
