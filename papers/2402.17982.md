# [Collaborative decoding of critical tokens for boosting factuality of   large language models](https://arxiv.org/abs/2402.17982)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Large language models (LLMs) such as ChatGPT tend to hallucinate incorrect facts after alignment tuning and when using sampling during generation. This reduces their factuality.
- Existing methods to mitigate hallucination often require dataset-specific tuning which limits their generalization ability. 

Proposed Solution:
- Introduce the concept of "critical tokens" - tokens like numbers, names etc. that do not tolerate variation in their prediction.
- Propose a "Collaborative Decoding Strategy (CDS)" where multiple models work together to generate an answer. 
- Specifically, propose "Model CDS" where a critical token classifier decides which model should generate the next token. An aligned model generates most tokens using sampling. For critical tokens, a pretrained model generates the token greedily.

Main Contributions:
- Model CDS framework allows harnessing factuality of pretrained models without impacting alignment quality or requiring dataset-specific tuning.
- Critical token concept explains factuality issue - only small subset of tokens in an answer impact the factuality.
- Experiments show Model CDS reduces hallucination and outperforms previous approaches, while maintaining diversity.
- Easy to deploy and generalizable due to no external knowledge or tuning needed.
- Allows updating knowledge model without impacting aligned model.

In summary, the paper introduces a collaborative decoding strategy to leverage both aligned and pretrained models for reducing factuality hallucination, through the concept of critical tokens. The approach is model-agnostic, easy to deploy and outperforms previous methods.
