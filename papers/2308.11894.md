# [Does Physical Adversarial Example Really Matter to Autonomous Driving?   Towards System-Level Effect of Adversarial Object Evasion Attack](https://arxiv.org/abs/2308.11894)

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the central research question this paper aims to address is whether existing works on physical adversarial object evasion attacks can effectively achieve the desired system-level attack effects (e.g. traffic rule violations, vehicle collisions) under realistic autonomous driving (AD) system settings. Specifically, the authors find that prior works on such attacks predominantly evaluate their success only at the targeted AI component level (e.g. object misdetection rates), without considering the overall AD system context and semantics. However, errors at the AI component level do not necessarily translate to undesired system-level effects. Therefore, the key research question is - can these existing attack designs that look effective in isolation actually achieve meaningful system-level impacts when evaluated end-to-end within a realistic AD pipeline? Through empirical measurement studies and system-level evaluations, the paper aims to systematically analyze and answer this critical research question.


## What is the main contribution of this paper?

Based on my review, the main contributions of this paper appear to be:- Conducting the first measurement study on the system-level effects of prior physical adversarial object evasion attacks in autonomous driving. The authors evaluate representative prior attacks and find they cannot achieve any system-level effects like traffic violations when evaluated in a closed-loop AD system. - Identifying two key limitations of prior attack designs that hinder their effectiveness at the system level: inconsistent object size sampling and lack of vehicle/AD system model considerations.- Proposing a novel system-driven attack design called SysAdv that addresses the identified limitations by incorporating physical/AD system models into the attack generation process. - Evaluating SysAdv and showing it can significantly improve system-level attack effectiveness, increasing the traffic violation rate by around 70% on average compared to prior attacks.In summary, the main contribution appears to be identifying limitations in prior physical adversarial attacks on AD systems when evaluated from an end-to-end perspective, and proposing a new attack design that integrates system knowledge to enhance system-level attack impacts. The paper seems to provide the first analysis and improvement of AD adversarial attacks at the full system level.
