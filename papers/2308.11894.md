# [Does Physical Adversarial Example Really Matter to Autonomous Driving?   Towards System-Level Effect of Adversarial Object Evasion Attack](https://arxiv.org/abs/2308.11894)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the central research question this paper aims to address is whether existing works on physical adversarial object evasion attacks can effectively achieve the desired system-level attack effects (e.g. traffic rule violations, vehicle collisions) under realistic autonomous driving (AD) system settings. 

Specifically, the authors find that prior works on such attacks predominantly evaluate their success only at the targeted AI component level (e.g. object misdetection rates), without considering the overall AD system context and semantics. However, errors at the AI component level do not necessarily translate to undesired system-level effects. 

Therefore, the key research question is - can these existing attack designs that look effective in isolation actually achieve meaningful system-level impacts when evaluated end-to-end within a realistic AD pipeline? Through empirical measurement studies and system-level evaluations, the paper aims to systematically analyze and answer this critical research question.


## What is the main contribution of this paper?

 Based on my review, the main contributions of this paper appear to be:

- Conducting the first measurement study on the system-level effects of prior physical adversarial object evasion attacks in autonomous driving. The authors evaluate representative prior attacks and find they cannot achieve any system-level effects like traffic violations when evaluated in a closed-loop AD system. 

- Identifying two key limitations of prior attack designs that hinder their effectiveness at the system level: inconsistent object size sampling and lack of vehicle/AD system model considerations.

- Proposing a novel system-driven attack design called SysAdv that addresses the identified limitations by incorporating physical/AD system models into the attack generation process. 

- Evaluating SysAdv and showing it can significantly improve system-level attack effectiveness, increasing the traffic violation rate by around 70% on average compared to prior attacks.

In summary, the main contribution appears to be identifying limitations in prior physical adversarial attacks on AD systems when evaluated from an end-to-end perspective, and proposing a new attack design that integrates system knowledge to enhance system-level attack impacts. The paper seems to provide the first analysis and improvement of AD adversarial attacks at the full system level.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Based on my review of the abstract and introduction, a one-sentence TL;DR summary could be: 

This paper conducts the first study evaluating how effectively prior works on physical adversarial attacks against autonomous driving perception can achieve real-world system-level effects like collisions, identifies limitations in prior works, and proposes a new system-driven attack design that significantly improves system-level attack success.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other research in the field of adversarial machine learning for autonomous driving:

- The key novel contribution of this paper is conducting a measurement study on the system-level impacts of prior physical adversarial object evasion attacks. Most prior work has focused on attack success at the AI component level, but this paper systematically evaluates the real-world system-level impacts. This helps address an important gap in understanding the true risks posed by these attacks.

- The paper focuses specifically on adversarial STOP sign evasion attacks due to their high relevance and potential safety impacts for autonomous driving. Many prior physical adversarial attack papers target traffic signs, but the focus on STOP signs specifically allows more in-depth analysis of this important attack vector. 

- The proposed system model provides a conceptual framework for evaluating physical attacks in the context of the full AD pipeline. While others have pointed out the need to evaluate beyond just the perception component, this paper provides a concrete model for doing so.

- The system-driven attack design concept integrates system-level considerations directly into the attack optimization process. This differs from most prior work that ignores the system context when crafting physical adversarial examples.

- The evaluations using both physical sign patches and simulation provide more realism than pure simulation-based evaluations. However, real-world experiments on full AD vehicles would provide the most definitive results.

- Compared to digital attack papers, this work provides more practical insights by focusing specifically on physical attacks. But it still relies on simulated AD vehicles rather than demonstrations on commercial systems.

Overall, the measurement studies and system-aware attack designs make important contributions. But extensions to digital attacks, real-world AD systems, and additional attack vectors would help strengthen the conclusions and generalizability. Further work is still needed to fully understand real-world risks.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Exploring the practicality and real-world feasibility of the proposed attack designs. The authors mention that while they demonstrate system-level effects in simulation, the feasibility on real AD systems remains unclear. Testing the attacks on physical AD vehicles would be an important next step.

- Developing attacks with more practical threat models. The current attack is in a white-box setting, but attacks that work in a black-box manner on real commercial AD systems would be more impactful. 

- Evaluating potential defenses against these types of attacks, such as adversarial training or using multiple complementary perception sources like cameras and LiDAR. The authors say systematic exploration of mitigation strategies is an open challenge.

- Expanding the evaluation to additional AD system configurations beyond those tested. The effects may differ on other commercial AD system setups or parameters.

- Trying more complex and stealthy attack methods beyond patching. The current attack uses visible patches, but more subtle perturbations merged into the environment could be harder to detect.

- Applying the attack concepts to different objects, not just STOP signs. Testing on other road objects like traffic lights or vehicles could demonstrate generality.

- Optimizing the attacks to improve success rates, especially at closer distances which are more challenging. There is room to boost the component-level attack performance.

So in summary, the key directions pointed out are: 1) real-world testing, 2) new threat models, 3) evaluating defenses, 4) more system configurations, 5) new attack types, 6) different objects, and 7) improving attack optimization and performance. The authors lay out several interesting open challenges for future research in this space.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper conducts the first measurement study on the system-level effects of prior works on physical adversarial object evasion attacks in autonomous driving. It focuses on STOP sign evasion attacks due to their high impact on driving safety. The results show that existing attacks, despite being effective on the AI component level, cannot achieve any system-level effects like traffic violations under real autonomous driving system settings. Two key limitations are identified in prior works: 1) inconsistent object size sampling distributions compared to the physical world model, and 2) lack of considerations for the vehicle dynamics and full autonomous driving system pipeline. To address this, the paper proposes a novel system-driven attack design called SysAdv that integrates the system model into the attack generation process. Evaluations demonstrate SysAdv can significantly improve system-level attack effects like violation rates by around 70% on average. The concept of incorporating a system model is highlighted as an important guideline for future adversarial testing of autonomous driving systems.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper proposes a system-level evaluation framework to measure the real-world effectiveness of prior adversarial object evasion attacks in autonomous driving (AD) systems. The authors point out that existing attacks are only evaluated on AI component metrics like misdetection rates, without considering the full AD pipeline. They focus on stop sign evasion attacks and build a simulation platform integrating real-world perception modeling, AD system components like tracking and planning, and a vehicle dynamics model. Evaluating prior attacks in this system reveals they cannot actually cause stop sign violations under normal driving conditions, despite successful component-level attacks. 

To improve system-level effectiveness, the authors identify two limitations in prior works: inconsistent object size sampling and lack of AD system modeling. They propose SysAdv, a system-driven attack approach overcoming these issues. It samples object sizes based on camera geometry and focuses perturbations on the system-critical range where attacks can actually impact driving behavior before braking. Evaluating SysAdv shows significantly higher system-level violation rates, highlighting the importance of holistic AD system modeling and metrics when designing and evaluating robust physical attacks. Overall, this work provides novel perspectives on bridging the gap between component and system effects for adversarial robustness in AD.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes a novel system-driven attack design called System-Driven Adversarial Object Evasion Attack (SysAdv) to improve the system-level effects of physical adversarial object evasion attacks in autonomous driving. The key ideas are: 1) Using a physics-based model to sample object sizes rather than sampling uniformly, which better matches real-world distance distributions. 2) Considering the vehicle plant model and AD system model to determine a system-critical distance range for attack optimization rather than using arbitrary ranges. Within this critical range, the attack is optimized to maximize object misdetections in order to delete object tracks and trigger system-level effects like traffic violations. Experiments show SysAdv significantly increases system-level violations compared to prior attacks that lack this physics and system-based optimization.


## What problem or question is the paper addressing?

 Based on my reading, the key problem this paper is addressing is evaluating whether existing physical adversarial attacks on autonomous driving perception can effectively achieve system-level attack effects like causing collisions or traffic violations. 

The paper points out that prior work has mainly evaluated attacks at the component level, like measuring success in fooling a targeted AI model. However, it's unclear if attacks that succeed at the component level will actually translate to meaningful impacts when considering the full autonomous driving system. 

To address this question, the authors conduct measurement studies to evaluate representative prior attacks in a simulated autonomous driving system. They find that attacks effective at the component level fail to cause any traffic violations at the system level. 

The paper then identifies limitations in prior attack designs that prevent system-level success, such as inconsistent assumptions about object size distributions. The authors propose a new attack approach called SysAdv that incorporates system-level context to achieve improved system-level attack effectiveness.

In summary, the key problem is assessing and improving the real-world viability of physical adversarial attacks on autonomous driving systems. The paper aims to understand if prior attacks can truly threaten driving safety, and if not, how attacks can be enhanced to cause bonafide system-level harm.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and concepts include:

- Autonomous driving (AD) systems
- AD perception
- Physical adversarial object evasion attacks
- STOP sign evasion attacks
- System-level effects
- System model
- AD system pipeline 
- Vehicle plant model
- Operation scenario model
- Measurement study
- System-level evaluation
- System-driven attack design
- \system (proposed attack design)
- Pixel sampling
- Object size distribution  
- Minimum braking distance
- Tracking distance

In summary, the key terms revolve around conducting a measurement study of prior physical adversarial attacks on AD perception at the system level rather than just the component level. It proposes a system model for evaluating attacks more holistically in an AD context. Based on limitations identified in prior works, the authors propose a new system-driven attack design called \system that incorporates the system model into the attack generation process in order to improve system-level effects like traffic violations. Core components of their system model include the AD pipeline, vehicle dynamics, and the driving scenario. Key factors they improve in the attack design relate to inconsistent object size sampling and lack of system model awareness.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to ask to create a comprehensive summary of the paper:

1. What is the key research problem or gap that the paper aims to address?

2. What is the core contribution or main finding of the paper? 

3. What is the background context related to the research problem, such as the state of prior work?

4. What methodology does the paper use to address the research problem, such as experiments, simulations, theoretical analysis, etc.?

5. What are the key results, measurements, evaluations, or validations presented in the paper? 

6. What are the limitations, assumptions, or scope conditions stated in the paper?

7. Does the paper identify any future work or open questions for further research?

8. Does the paper make any novel definitions, abstractions, models, or frameworks as part of the technical approach?

9. What claims, arguments, or hypotheses does the paper make regarding the research problem?

10. Does the paper discuss any broader impact or generalizable lessons based on the presented work?

Asking these types of targeted questions can help unpack the key information contained in the paper to enable creating a thorough yet concise summary. The questions aim to identify the core technical concepts as well as contextualize the relevance and implications of the work.


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. The paper proposes a novel system model for evaluating adversarial attacks in autonomous driving systems. How does this system model improve upon previous evaluation approaches? What key components allow it to better capture the system-level impacts of attacks?

2. The paper identifies two key limitations of prior attack methods: inconsistent object size sampling and lack of system model integration. Why do these limitations prevent existing attacks from achieving real system-level impacts? How do the proposed solutions S1 and S2 address these limitations?

3. Solution S1 involves defining a new object size distribution based on the camera pinhole model. What assumptions does this distribution rely on? How could it be adapted if these assumptions do not perfectly hold in a real AV system?

4. Solution S2 focuses on identifying the critical distance ranges for achieving system effects. What factors determine these minimal and maximal distances? How sensitive are the results to the specific values chosen?

5. The system model incorporates downstream components like tracking, planning, and control. How do these impact the effectiveness of evasion attacks? What aspects of the system model are most critical to capture?

6. The paper evaluates attacks using a simulation-based approach. What are the advantages and limitations of this compared to real-world testing? How could the fidelity of the simulator setup be further improved? 

7. The results demonstrate significantly increased violation rates from the proposed system-driven attack. What performance metrics best capture this system-level impact? Are there other metrics that could reveal additional attack consequences?

8. How might the proposed attack design approach extend to other evasion attack scenarios, like hiding pedestrians or vehicles? What components of the method generalize vs need scenario-specific adaptation?

9. The paper focuses on white-box attacks with full knowledge of the AV system. How could the attack be adapted to a more practical black-box threat model? What information would be needed about the target?

10. Beyond evasion attacks, how could this system-driven approach improve the realism of other AV adversarial attacks like spoofing or denial-of-service? What modifications would be required?
