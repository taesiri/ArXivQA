# [Stochastic Two Points Method for Deep Model Zeroth-order Optimization](https://arxiv.org/abs/2402.01621)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large foundation models like large language models (LLMs) have shown great performance but fully fine-tuning them is often infeasible due to compute/memory constraints. 
- Zeroth-order methods that rely only on function evaluations to update models are promising but existing analyses focus on general smoothness assumptions that limit applicability.

Proposed Solution:
- Proposes Stochastic Two-Point (S2P) method that improves over prior zeroth-order approaches by removing a redundant function evaluation.
- Provides theoretical analysis of S2P convergence under both general and relaxed smoothness assumptions.
- Based on new convergence properties, proposes Accelerated S2P (AS2P) variant that exploits relation between step size, gradient norm, and hessian captured by the standard deviation of the stochastic metric γ.
- Key ideas in AS2P: Progressive γ-clipping to mimic optimal step size relation and automatic learning rate based on statistics of γ.

Main Contributions:
- Analyzes S2P method under both general and relaxed smoothness assumptions, with query complexity bounds.
- New convergence properties shed light on faster AS2P variant that captures gradient and curvature information through statistics of the stochastic metric γ.   
- Comprehensive experiments including LLM fine-tuning show AS2P significantly outperforms prior zeroth-order approaches, with ~2x speedup across tasks.

In summary, the paper presents an efficient stochastic two-point zeroth-order optimization method, analyzes its properties, and uses the analysis to develop an accelerated variant that shows strong empirical performance in optimizing objectives for large deep models.
