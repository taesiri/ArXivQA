# [Augmenting Autotelic Agents with Large Language Models](https://arxiv.org/abs/2305.12487)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we augment artificial agents with the ability to represent, generate, and learn diverse, abstract, and human-relevant goals in an open-ended way, without relying on hand-coded goal representations or reward functions?In particular, the paper proposes a method to address this question by using a pretrained language model as a model of human cultural transmission. The language model is used to implement three key components of an autotelic agent architecture:1) A relabeler that describes goals achieved in the agent's trajectories.2) A goal generator that suggests new high-level goals and decomposes them into subgoals. 3) Reward functions for the generated goals.By leveraging the language model as a proxy for human cultural transmission and common sense knowledge, the goal is to enable the agent to autonomously discover and pursue more complex, creative, and human-relevant goals, in a way that moves beyond pre-defined goal spaces. The central hypothesis seems to be that augmenting autotelic agents in this way will allow for more open-ended skill discovery and goal-directed learning.So in summary, the key research question is how to use language models to provide autotelic agents with the ability to generate and learn diverse, meaningful goals in an open-ended fashion, without hand-coded goal representations. The paper proposes and evaluates an approach using LMs as a model of cultural transmission to address this question.
