# [Deep dive into language traits of AI-generated Abstracts](https://arxiv.org/abs/2312.10617)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
The paper examines the problem of detecting abstracts of scientific papers that are generated by AI systems like ChatGPT versus those written by humans. There is a growing concern about AI-generated text infiltrating academic writing and research without proper attribution or transparency. The authors aim to scrutinize differences in linguistic patterns between human-written and AI-generated abstracts.

Proposed Solution 
The authors curate two small datasets of abstracts - one with abstracts written by known authors along with ChatGPT-generated versions, and another by extracting abstracts from recent ChatGPT-related papers along with ChatGPT-generated versions. They extract semantic, linguistic and pragmatic features from these abstracts, including sentence similarity, entities, conjunctions, hedge words, boosters and hype words. Using these features, they train classical ML models like LDA, Logistic Regression, SVM, XGBoost and Extra Trees to discriminate between human and AI-generated abstracts.  

Key Contributions
- Curate two new datasets of human-written and ChatGPT-generated scientific abstracts for further research
- Extract semantic, linguistic and pragmatic features that can discriminate between human and AI-generated scientific abstracts
- Demonstrate that classical ML models can identify ChatGPT-generated abstracts reasonably well using these features
- Show that a small subset of 25 selected features can achieve comparable performance to using all 115 features
- Performance is comparable to recent deep learning models for detecting AI-generated text

In summary, the key novelty is in compiling discriminative features and datasets to detect ChatGPT-generated scientific abstracts, and showing that simple ML models can effectively identify them. The findings advocate for greater transparency in use of AI tools in academic writing.
