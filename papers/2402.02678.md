# [Counterfactual Explanations of Black-box Machine Learning Models using   Causal Discovery with Applications to Credit Rating](https://arxiv.org/abs/2402.02678)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Explainable AI (XAI) methods that provide counterfactual explanations using causal models require the causal graph between features to be known. However, in most real-world applications, the causal relationships are unknown. This limits the applicability of such XAI methods that rely on causal graphs. 

Proposed Solution:
The paper proposes a new XAI framework that relaxes the constraint that the causal graph needs to be known. The key ideas are:

1) Use causal discovery algorithms to estimate the causal graph from data, while using some useful prior causal structure information:
   - Target variable is a sink variable (no variable causes it)
   - Target variable has direct causal relationships with all explanatory variables

2) Explain black-box model predictions by estimating counterfactual explanation scores like necessity, sufficiency and reversal probability scores using the estimated causal graph.

Main Contributions:

- Analysis of how different causal structures affect counterfactual explanation scores
- Proposal of useful prior causal structure information to improve causal discovery
- Numerical experiments on artificial data showing the proposed method can recover importance scores closer to true values compared to assuming no graph
- First application of counterfactual XAI with causal discovery on real financial credit rating data from Shiga Bank, demonstrating usefulness even when true causal graph is unknown

The method provides a practical way to apply counterfactual explanation methods using causal models to real-world applications where the causal relationships are typically unknown. By combining causal discovery and prior causal knowledge, reasonable estimates of feature importance scores could be obtained.
