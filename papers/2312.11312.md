# [APE-then-QE: Correcting then Filtering Pseudo Parallel Corpora for MT   Training Data Creation](https://arxiv.org/abs/2312.11312)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Neural machine translation (NMT) models require large amounts of high-quality parallel data to train effectively, which is not available for low-resource languages like Marathi. 
- Existing pseudo-parallel corpora contain a lot of noise which degrades NMT performance.

Proposed Solution:
- Use an automatic post-editing (APE) system to correct errors in the target side of a noisy English-Marathi pseudo-parallel corpus. 
- Use a quality estimation (QE) system to select the best output between the original target sentence and the APE-corrected sentence.
- Extract a cleaned parallel corpus using APE and QE to train an English-Marathi NMT system.

Key Contributions:
- Novel adaptation of APE and QE to extract high-quality parallel data from noisy pseudo-parallel corpora.
- APE system trained using curriculum training strategy and augmented with phrase-level triplets.
- NMT models trained on APE-QE filtered pseudo-parallel corpus achieve +5.64 BLEU (En->Mr) and +9.91 BLEU (Mr->En) over baseline.
- Approach is language-agnostic given availability of APE and QE resources.
- Analyzed for English-Marathi due to availability of APE and QE data, but can be extended to other languages.

In summary, the key idea is to use APE to correct and QE to filter noisy parallel data, in order to train better NMT models for low-resource languages. The approach shows significant NMT quality improvements for English-Marathi and is independent of specific language properties.
