# [The Impact of Quantization on the Robustness of Transformer-based Text   Classifiers](https://arxiv.org/abs/2403.05365)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Transformer-based NLP models like BERT are vulnerable to adversarial attacks, lowering their robustness. 
- These large models also have high computational complexity, making them unsuitable for real-world applications.

Proposed Solution:
- Apply quantization to BERT and DistilBERT models to reduce model size and evaluate its impact on robustness. 
- Quantization involves mapping high-precision float values to lower-precision integers to reduce model size.
- Evaluate quantized models on SST-2, Emotion, and MR datasets against TextFooler, PSO, and PWWS attacks.

Main Contributions:
- Propose quantization to improve robustness of NLP models against adversarial attacks.
- Analyze impact of quantization on various models and datasets against different attacks.
- Show quantization can likely be applied to other NLP tasks beyond text classification.
- Demonstrate quantization boosts robustness significantly more than adversarial training, without extra training overhead.

Key Results:
- Quantization reduced model sizes by 41-52% with minimal accuracy drop (0.98% avg)
- Quantization improved adversarial accuracy by 18.68% on average against attacks
- More effective at boosting robustness than adversarial training for BERT model

Limitations:
- Quantization alone not sufficient for robustness needed in real applications
- More analyses needed on other models, tasks, and attack algorithms
