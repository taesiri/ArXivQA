# [Unsupervised Discovery of Steerable Factors When Graph Deep Generative   Models Are Entangled](https://arxiv.org/abs/2401.17123)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Deep generative models (DGMs) have been widely used to model graph data like molecules and point clouds. However, understanding the latent space of pretrained graph DGMs is less explored. This understanding can enable important downstream tasks like graph controllable generation/editing.

- One key property for unsupervised data editing using DGMs is disentanglement. The authors examine three pretrained graph DGMs using six metrics and find that their latent spaces are entangled, not disentangled.

- Given an entangled pretrained DGM, it is unclear if graph controllable generation can still be achieved in an unsupervised manner. 

Proposed Solution:
- The authors propose GraphCG, a flexible model-agnostic framework for unsupervised graph editing with pretrained DGMs. 

- GraphCG maximizes the mutual information (MI) between latent codes edited along the same direction/step size. This assumes graphs edited similarly should share semantic information. GraphCG uses an energy-based model and the authors further derive a GraphCG-NCE solution using noise contrastive estimation.

- During training, GraphCG learns semantic directions by aligning positive pairs (same editing) and contrasting negative pairs (different editing). During inference, it can generate sequences of edited graphs by traversing the directions.

Main Contributions:
- Empirically examine disentanglement of 3 graph DGMs using 6 metrics and find they are entangled.

- Propose GraphCG for model-agnostic unsupervised graph editing with pretrained DGMs by maximizing mutual information through an energy-based contrastive formulation.

- Achieve superior quantitative editing performance compared to baselines on 2 molecular graph datasets.

- Demonstrate qualitative visualization of 7 steerable factors discovered by GraphCG on 5 graph datasets, including molecules and point clouds.


## Summarize the paper in one sentence.

 This paper proposes GraphCG, a model-agnostic method for unsupervised discovery of steerable factors in the latent space of pretrained graph deep generative models to enable graph controllable generation.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1) They conduct an empirical study on the disentanglement property of three pretrained graph deep generative models (DGMs) using six metrics, and observe that the latent space of these models is entangled.

2) They propose a model-agnostic method called GraphCG for unsupervised graph controllable generation or graph editing. GraphCG aims to learn the steerable factors by maximizing the mutual information among corresponding directions.

3) They quantitatively verify that GraphCG outperforms four competitive baselines when evaluated on two pretrained graph DGMs over two molecule datasets. 

4) They further qualitatively demonstrate the effectiveness of GraphCG by illustrating seven semantic factors on five pretrained graph DGMs over five graph datasets, including molecular graphs and point clouds.

In summary, the main contribution is proposing GraphCG, an unsupervised method for learning steerable factors in the latent space of pretrained but entangled graph generative models, which enables graph controllable generation. Both quantitative and qualitative results are provided to demonstrate its effectiveness.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Graph controllable generation/graph editing - Modifying the steerable factors of a graph to obtain graphs with desired properties. A key application is editing molecular graphs by modifying functional groups.

- Disentanglement - The separation of distinct, informative, and controllable factors of variation in the latent representation. The paper examines the disentanglement of pretrained graph generative models. 

- Entanglement - The paper observes that the latent spaces of common graph generative models are entangled rather than disentangled.

- Mutual information (MI) - A key idea in the GraphCG method is to maximize the MI between latent codes edited in the same direction/step size. This aligns variations due to editing. 

- Energy-based model (EBM) - GraphCG is formulated as an EBM which provides a flexible framework for modeling distributions. Specifically, GraphCG-NCE uses noise contrastive estimation.

- Semantic direction - Directions in the latent space of a generative model that correspond to semantic changes in the generated graphs. GraphCG aims to learn these.

- Sequence monotonic ratio (SMR) - A metric proposed in the paper to evaluate whether editing a graph along a direction induces monotonic change in a structural property.

- Molecular graphs, point clouds - The two main graph data modalities examined in experiments. Editing explores modification of functional groups and shapes.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes using mutual information maximization between edited latent codes to learn semantic directions. What are the advantages and disadvantages of this approach compared to using other metrics like reconstruction error or property prediction objectives?

2. The paper formulates the editing framework as an energy-based model and solves it with noise contrastive estimation. How does this compare to other possible solutions like score matching or denoising diffusion models? What are the tradeoffs?  

3. The paper evaluates performance using a new metric called Sequence Monotonic Ratio (SMR). What are the strengths and weaknesses of this metric? How could it be improved or supplemented?

4. For molecule graph editing, the paper assumes that functional group changes correspond to changes in semantic factors. However, some factors like activity cliffs may not follow this assumption. How could the method account for exceptions?

5. The visualization results show clear semantic changes in molecular graphs and point clouds. However, quantitative gains over baselines are modest. What factors contribute to this and how could performance be further improved?

6. The paper argues that graph data does not have the same level of disentanglement as vision models like StyleGAN. What modifications could be made to graph generative models to improve disentanglement and interpretability?

7. The inference process requires human selection of semantic vectors post-training. How could this process be automated to remove the need for supervision? Are there unsupervised criteria for identifying important directions?

8. The method trains each semantic direction independently. Could training them jointly lead to more diversity and less redundancy? What modifications would enable this?

9. For discrete graph structured data, evaluating generation quality is an open challenge. Beyond SMR, what quantitative evaluation protocols could better measure performance?

10. The paper focuses on molecule and point cloud graphs. What adjustments would enable application to other graph data modalities like social networks or biological networks? How would the notion of semantic factors change?
