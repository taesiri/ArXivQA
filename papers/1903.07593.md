# [Learning Correspondence from the Cycle-Consistency of Time](https://arxiv.org/abs/1903.07593)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to learn visual correspondence from raw unlabeled video in a self-supervised manner. The key ideas and hypotheses are:- Visual correspondence is crucial for visual reasoning, but obtaining ground truth supervision is expensive and limited.- There is inherent correspondence between observations in raw video adjacent in time due to the continuity of the visual world. This can provide free supervision through temporal cycle consistency.- By tracking patches backwards and forwards in time in a learned feature space and optimizing for cycle consistency, a model can learn a feature representation useful for establishing correspondences. - The learned representation can support correspondence at various levels, from pixel-level optical flow to mid-level patch correspondence to high-level object tracking, without specific fine-tuning.So in summary, the main hypothesis is that cycle consistency in time is a powerful self-supervised signal that can be used to learn visual correspondence from scratch on raw video data. The key idea is that correspondence requires a feature space that is invariant to transformations; by optimizing cycle consistency the model is encouraged to develop such feature representations.


## What is the main contribution of this paper?

The main contribution of this paper is presenting a self-supervised method to learn visual correspondence from unlabeled video by optimizing for temporal cycle-consistency. Specifically:- The authors propose a method to learn a feature representation by tracking image patches along cycles in time in video. By tracking a patch forward and backward in time and minimizing the inconsistency between start and end points, the model learns features useful for correspondence.- They introduce cycle-consistent tracking losses based on forward-backward tracking that allow learning from longer cycles as well as skip connections to deal with occlusions or drift. - The proposed framework is used to learn a spatial feature representation in a deep convnet for mid-level correspondence. This is evaluated without finetuning on propagation tasks like video object segmentation, human pose estimation, semantic segmentation, and optical flow estimation.- Experiments demonstrate the effectiveness of the learned features on these tasks compared to self-supervised baselines. The method performs competitively with supervised approaches despite being trained only on raw indoor videos without labels or finetuning.In summary, the key contribution is a self-supervised framework to learn visual correspondence from unlabeled video through optimizing cycle-consistency in time, and demonstrating its effectiveness for mid-level feature learning and propagation tasks. The main value is in providing a way to learn representations for correspondence without human annotation.
