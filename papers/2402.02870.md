# [Statistics without Interpretation: A Sober Look at Explainable Machine   Learning](https://arxiv.org/abs/2402.02870)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points made in the paper:

Problem:
- The field of explainable ML lacks clarity on what constitutes an "explanation" and how explanation algorithms should be interpreted. Complex statistical methods are introduced without clear guidance on what questions they can actually answer about a model.

- This leads to invalid interpretations and usage of explanations. Even simple statistical methods like p-values are frequently misinterpreted, so complex explanation methods without clear interpretations are prone to misuse.

Proposed Perspective: 
- Clearly differentiate between the mathematical properties of an explanation algorithm (the "statistic") and the matter of interpretation (what questions it can answer).

- Explanation algorithms are statistics of functions, just as common statistics summarize properties of distributions. But most statistics don't have clear interpretations.

- Valid interpretations require showing what specific questions about a model can be answered, either directly from the definition or via rigorous empirical analysis.

Implications:
- Papers should state what interpretative questions an explanation method is designed to answer.

- Explanations without clear interpretations are themselves a black box that requires careful empirical analysis.

- Benchmarks can assess mathematical properties but not validate interpretations.

- It's better to measure properties like fairness directly rather than via proxy explanations. 

- Many explanations may only be useful to experts. Clear communication of limitations is important.

Main Contributions:
- Conceptual framework to separate statistic and interpretation of explanations

- Drawing parallels to challenges of interpretation in statistics

- Argues for more rigor and transparency on what explanations can and cannot explain

- Outlines implications for research on evaluation/benchmarks and communication of limitations
