# [DualBEV: CNN is All You Need in View Transformation](https://arxiv.org/abs/2403.05402)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
Existing methods for bird's eye view (BEV) perception use either a 3D-to-2D or 2D-to-3D view transformation (VT) approach. 3D-to-2D methods use computationally expensive Transformers to establish correspondences between 3D and 2D features. 2D-to-3D methods use less efficient lift-splat-shoot pipelines and can miss distant information. Two-stage fusion methods are also constrained by reliance on initial features.

Proposed Solution:
The paper proposes a unified CNN-based feature transformation to bridge gaps between 3D-to-2D and 2D-to-3D strategies. It introduces HeightTrans for efficient 3D-to-2D sampling using lookup tables and precomputation. It enhances 2D-to-3D with Prob-LSS using probabilities for invalid features. A Dual Feature Fusion module fuses features and predicts BEV probability in one stage.  

Main Contributions:
1) Unified feature transformation covering dual VT using image, projection, and BEV probabilities for correspondences.
2) HeightTrans for fast 3D-to-2D sampling using precomputation and probabilities.  
3) Dual Feature Fusion module to fuse features and predict BEV probability in one stage.
4) State-of-the-art 55.2% mAP on nuScenes using precise dual-view probabilities, without Transformers or two-stage fusion.

In summary, the paper proposes a unified CNN-based feature transformation to seamlessly integrate 3D-to-2D and 2D-to-3D strategies for BEV perception. The method achieves excellent accuracy and efficiency by establishing precise dual-view correspondences in a one-stage fashion.
