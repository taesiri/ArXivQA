# Iteratively Prompt Pre-trained Language Models for Chain of Thought

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question addressed is: How can we equip pre-trained language models (PLMs) with the ability to develop a "chain of thought" for complex multi-step reasoning? Specifically, the authors are investigating how to elicit relevant knowledge from PLMs step-by-step in order to perform multi-step inference to answer complex queries. This involves iteratively prompting the PLM to recall the necessary knowledge statements to derive the answer.The key hypotheses are:- An iterative prompting framework where knowledge is elicited from the PLM incrementally will be more effective than non-iterative approaches for complex multi-step reasoning.- A context-aware prompting approach that dynamically generates prompts conditioned on the current step's context will be superior to prior prompting methods that use static prompts for this iterative elicitation.So in summary, the central research question is how to guide PLMs to develop a logical chain of thought via iterative context-aware prompting in order to perform complex multi-step reasoning. The core hypotheses focus on the benefits of the iterative prompting framework and a context-aware prompt generation method.


## What is the main contribution of this paper?

The main contribution of this paper is proposing an iterative prompting framework to guide pre-trained language models to perform multi-step reasoning. Specifically:- They propose an iterative prompting scheme where the pre-trained language model (PLM) is prompted repeatedly to recall a series of relevant knowledge facts needed to answer a complex query. This mimics how humans develop a "chain of thought".- They design a context-aware prompter module that dynamically generates prompts based on the current context (query + previously recalled facts). This allows the prompts to vary across reasoning steps and integrate necessary context.- They conduct experiments on multi-hop QA and commonsense reasoning datasets. Results show their approach outperforms prior prompting methods by large margins and approaches fine-tuning performance, while keeping the PLM parameters frozen.- They perform analysis to demonstrate the faithfulness of the learned prompting behavior, ruling out exploitation of spurious patterns. This helps validate that their method genuinely guides the PLM through multi-step reasoning.In summary, the key contribution is an iterative prompting framework with an adaptive context-aware prompter to elicit knowledge from PLMs for complex multi-step inference, together with supporting experiments and analysis. The work helps advance prompting as a technique for reasoning over implicit knowledge in large PLMs.
