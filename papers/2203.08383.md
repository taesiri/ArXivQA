# Iteratively Prompt Pre-trained Language Models for Chain of Thought

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question addressed is: How can we equip pre-trained language models (PLMs) with the ability to develop a "chain of thought" for complex multi-step reasoning? Specifically, the authors are investigating how to elicit relevant knowledge from PLMs step-by-step in order to perform multi-step inference to answer complex queries. This involves iteratively prompting the PLM to recall the necessary knowledge statements to derive the answer.The key hypotheses are:- An iterative prompting framework where knowledge is elicited from the PLM incrementally will be more effective than non-iterative approaches for complex multi-step reasoning.- A context-aware prompting approach that dynamically generates prompts conditioned on the current step's context will be superior to prior prompting methods that use static prompts for this iterative elicitation.So in summary, the central research question is how to guide PLMs to develop a logical chain of thought via iterative context-aware prompting in order to perform complex multi-step reasoning. The core hypotheses focus on the benefits of the iterative prompting framework and a context-aware prompt generation method.


## What is the main contribution of this paper?

The main contribution of this paper is proposing an iterative prompting framework to guide pre-trained language models to perform multi-step reasoning. Specifically:- They propose an iterative prompting scheme where the pre-trained language model (PLM) is prompted repeatedly to recall a series of relevant knowledge facts needed to answer a complex query. This mimics how humans develop a "chain of thought".- They design a context-aware prompter module that dynamically generates prompts based on the current context (query + previously recalled facts). This allows the prompts to vary across reasoning steps and integrate necessary context.- They conduct experiments on multi-hop QA and commonsense reasoning datasets. Results show their approach outperforms prior prompting methods by large margins and approaches fine-tuning performance, while keeping the PLM parameters frozen.- They perform analysis to demonstrate the faithfulness of the learned prompting behavior, ruling out exploitation of spurious patterns. This helps validate that their method genuinely guides the PLM through multi-step reasoning.In summary, the key contribution is an iterative prompting framework with an adaptive context-aware prompter to elicit knowledge from PLMs for complex multi-step inference, together with supporting experiments and analysis. The work helps advance prompting as a technique for reasoning over implicit knowledge in large PLMs.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the main idea in the paper:The paper proposes an iterative prompting framework to progressively elicit knowledge stored in pre-trained language models and guide them to develop a logical "chain of thought" for complex reasoning tasks.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other related work:- This paper explores iterative prompting to help pre-trained language models (PLMs) perform multi-step reasoning by eliciting a "chain of thought". Other work has shown PLMs struggle at complex reasoning despite having a lot of knowledge, so this aims to address that gap.- The proposed iterative prompting framework progressively prompts the PLM to recall relevant knowledge across multiple steps for a given reasoning task. This differs from prior prompting work that focused on single-step factual knowledge retrieval.- The context-aware prompter model is designed to dynamically generate prompts conditioned on the evolving context at each reasoning step. This aims to capture the variability needed across steps, unlike static/context-agnostic prompting methods.- Experiments compare iterative prompting against non-iterative baselines using fine-tuning and prompting methods like prompt/prefix tuning on multi-hop QA and commonsense reasoning datasets. Results show benefits of the iterative scheme and context-aware prompter.- Analysis examines faithfulness of prompting, including test-train overlap analysis and random model/embedding probes to evaluate spurious pattern exploitation. This helps interpret the validity of results.- The focus is on knowledge elicitation and reasoning from a fixed PLM, rather than end task performance. So it differs from dataset-specific reasoning methods that incorporate other specialized components.Overall, the key novelty is in iterative prompting to elicit chained reasoning from PLMs, enabled by the context-aware dynamic prompter. Experiments demonstrate strengths over non-iterative and static prompting baselines. The faithfulness analysis also helps advance understanding of learned prompting behaviors.


## What future research directions do the authors suggest?

The authors propose several potential future research directions in the paper:1. Experiment with larger-scale PLMs. The authors used BART-large in their experiments, but suggest experimenting with even larger PLMs that have more knowledge internalized. This could further improve the performance of iterative prompting. However, larger models also have higher computational costs.2. Explore alternative architectural designs for the context-aware prompter. The authors only implemented one intuitive design, but suggest exploring other choices like different prompter-PLM interfaces, dynamic prompt lengths, etc.3. Apply the ideas to PLM pretraining. The authors suggest incorporating iterative prompting into the pretraining phase of PLMs, so they inherently develop stronger multi-step reasoning abilities.4. Enable human intervention during inference. The iterative framework allows humans to track and edit the PLM's chain of thought during inference. This could improve transparency, trustworthiness, and reduce error propagation.5. Make the framework robust to noisy knowledge statements. The current method struggles with noisy knowledge as supervision. Improving this could allow the approach to work with more realistic, noisy data.In summary, the main future directions are 1) scaling up, 2) architectural improvements, 3) incorporating into pretraining, 4) enabling human-in-the-loop, and 5) handling noisy data. The authors provide promising initial results, but suggest several ways to extend the approach in future work.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper explores an iterative prompting framework to guide pre-trained language models (PLMs) to develop a "chain of thought" for complex multi-step reasoning tasks. While PLMs have shown an ability to internalize factual knowledge, prior work reveals they struggle with composing this knowledge over multiple steps to answer complex questions. The authors propose an approach where they augment the PLM with a "prompter" module that iteratively provides prompts to elicite the next relevant piece of knowledge based on the current context. At each step, the prompter processes the query and previously gathered evidence to compose a new prompt steering the PLM to recall the next fact. Experiments on question answering datasets requiring multi-hop reasoning show the benefits of this iterative prompting scheme and the context-aware prompter design compared to prior prompting methods and fine-tuning. The work also conducts analysis to examine the faithfulness of the learned prompting behaviors. Overall, the iterative prompting framework shows promise for equipping PLMs with stronger multi-step reasoning abilities while keeping the model parameters fixed.
