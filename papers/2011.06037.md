# [Unsupervised Video Representation Learning by Bidirectional Feature   Prediction](https://arxiv.org/abs/2011.06037)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the abstract and introduction, the key research question this paper seeks to address is:How can we improve self-supervised video representation learning by incorporating both past and future frame predictions, compared to only using future frame prediction as in prior work? The central hypothesis is that utilizing both past and future frame predictions as complementary supervisory signals will encourage the model to better explore the temporal structure of videos and learn richer video representations. Specifically, the authors argue that the supervisory signal from unobserved past frames provides a complementary signal to the commonly used future frame prediction.The key ideas and contributions are:- Proposing a novel pretext task of bidirectional (past and future) feature prediction for self-supervised video representation learning. - Showing how to effectively incorporate past and future frame predictions jointly in a contrastive learning framework. This allows using swapped past/future order as temporal hard negatives.- Demonstrating through experiments that the proposed bidirectional prediction method outperforms unidirectional future prediction baselines on action recognition benchmarks.In summary, the paper introduces a new approach for self-supervised video representation learning that exploits past and future frame predictions bidirectionally rather than just future prediction unidirectionally. The central hypothesis is that this will enable learning more powerful video representations by better capturing temporal structure.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It proposes a novel method for self-supervised video representation learning through bidirectional (past and future) feature prediction. 2. It shows how to jointly incorporate past and future prediction signals in a contrastive learning framework, using the wrong order of future/past frames as "temporal hard negatives".3. It provides extensive empirical evaluation showing the proposed method outperforms unidirectional (future-only) feature prediction on downstream action recognition tasks. Specifically, the key ideas are:- Using both past and future frames provides complementary supervision signals to learn video representations.- Simply combining losses from independent future and past prediction is not very effective.- Jointly predicting future and past allows creating hard negatives by swapping their order, forcing the model to encode temporal structure.- This bidirectional prediction method gives improved transfer learning performance on action recognition compared to predicting future only.So in summary, the main contribution is proposing and demonstrating the benefits of a novel self-supervised pretext task for videos based on joint future and past feature prediction with temporal hard negatives.
