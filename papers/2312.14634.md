# [Mining multi-modal communication patterns in interaction with   explainable and non-explainable robots](https://arxiv.org/abs/2312.14634)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is little knowledge about human communication patterns when interacting with explainable (robots that explain their actions) versus non-explainable robots (robots that do not explain their actions). 
- Such knowledge is important for designing explainable robots that can adapt their behavior to improve understandability for humans.

Methods:
- 20 humans played a board game with either an explainable or non-explainable Pepper robot, instructing it to move pieces on the board. 
- The interactions were video recorded and manually annotated for verbal utterances, gestures, etc from both the human and robot. 
- The annotations were transformed into 295 transactions for association rule mining to find patterns.

Key Results:
- Humans tended to mirror the robot's choice of communication modality (verbal, gesture, or no feedback). 
- A strong correlation found between male users and non-explainable robots; and female users and explainable robots.
- Men reacted verbally to non-explainable verbal robots, women reacted verbally to explainable verbal robots.
- Humans provide no feedback when interacting with an explainable robot that executes an instruction.
- Lack of human feedback doesn't necessarily signal non-understanding.

Main Contributions:
- Demonstrated using association rules to investigate contextualized human behavior patterns in HRI. 
- Showed importance of contextualizing human behavior when analyzing HRI.
- Discovered statistically significant multi-modal communication patterns between humans and explainable/non-explainable robots.
- Provided new insights to inform the design of explainable robots that can adapt behavior to improve understandability.

In summary, the paper used an innovative methodology to uncover noteworthy context-dependent communication patterns between humans and robots with different explainability capabilities. The discoveries contribute to the area of explainable AI and can help guide robot designers towards improved human-robot understanding.
