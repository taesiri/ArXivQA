# [Random Projection Neural Networks of Best Approximation: Convergence   theory and practical applications](https://arxiv.org/abs/2402.11397)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Artificial neural networks (ANNs) have shown remarkable capabilities in approximating functions. However, there still remain concerns about their stability, convergence and efficiency for numerical analysis.
- Random projection neural networks (RPNNs) have emerged as a promising alternative with better computational efficiency than fully trainable networks but it is unclear if they achieve comparable convergence and precision, especially for problems with high smoothness. 

Main Contributions:
1) The paper proves that there exists a choice of weights and biases in an RPNN with infinitely differentiable, non-polynomial activation functions that exponentially converges to any smooth function, matching the behavior of polynomial approximations like Legendre. This improves upon current convergence rates.

2) To achieve this in practice, the authors propose a "function-informed" approach for a priori selection of internal parameters in the RPNN based on the shape of the function to approximate rather than naive random selection. 

3) Through numerical tests on a variety of benchmark problems, the authors demonstrate that the proposed RPNNs with informed parameter selection achieve accuracy comparable to Legendre polynomials (upto 14 digits) while also being computationally more efficient than standard ANNs that require iterative training. The method however encounters limitations for approximating near-singularities/rapid oscillations.

4) The work strengthens theoretical understanding of convergence properties of RPNNs and their potential as an efficient alternative to fully-trainable ANNs for problems in numerical analysis and science. It also highlights best practices for overcoming challenges in their practical implementation. Overall, RPNNs provide a promising bridge between theory and practice of neural networks for function approximation.
