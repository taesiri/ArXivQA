# [Automated Code generation for Information Technology Tasks in YAML   through Large Language Models](https://arxiv.org/abs/2305.02783)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How can large language models be applied to generate Ansible YAML code from natural language prompts, and can models customized for Ansible outperform general code generation models?More specifically, some key aspects the paper investigates are:- Developing transformer-based models specialized for generating Ansible YAML code from natural language, through pretraining on YAML and Ansible YAML data. - Proposing novel performance metrics tailored for evaluating Ansible YAML generation.- Comparing models pretrained on Ansible/YAML data against existing general code generation models like CodeGen and Codex in few-shot settings.- Analyzing the effects of various factors like prompt formulation, context window size, model size, and training data size when fine-tuning for the Ansible generation task.- Demonstrating that their customized Ansible Wisdom models can achieve better performance on Ansible YAML generation compared to Codex and CodeGen, especially when fine-tuned on Ansible data.So in summary, the main hypothesis seems to be that large language models customized for Ansible through pretraining and fine-tuning will outperform general code generation models on the task of generating Ansible YAML. The paper presents experiments and results to validate this hypothesis.
