# [Automated Code generation for Information Technology Tasks in YAML   through Large Language Models](https://arxiv.org/abs/2305.02783)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How can large language models be applied to generate Ansible YAML code from natural language prompts, and can models customized for Ansible outperform general code generation models?More specifically, some key aspects the paper investigates are:- Developing transformer-based models specialized for generating Ansible YAML code from natural language, through pretraining on YAML and Ansible YAML data. - Proposing novel performance metrics tailored for evaluating Ansible YAML generation.- Comparing models pretrained on Ansible/YAML data against existing general code generation models like CodeGen and Codex in few-shot settings.- Analyzing the effects of various factors like prompt formulation, context window size, model size, and training data size when fine-tuning for the Ansible generation task.- Demonstrating that their customized Ansible Wisdom models can achieve better performance on Ansible YAML generation compared to Codex and CodeGen, especially when fine-tuned on Ansible data.So in summary, the main hypothesis seems to be that large language models customized for Ansible through pretraining and fine-tuning will outperform general code generation models on the task of generating Ansible YAML. The paper presents experiments and results to validate this hypothesis.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:- The authors explore the application of large language models (LLMs) to generating Ansible YAML code from natural language prompts. Ansible YAML is widely used for IT automation but has received little attention in terms of AI-assisted coding. - They build a new dataset containing Ansible YAML code for both pretraining and finetuning tasks. The dataset comes from sources like GitHub, Google BigQuery, GitLab, and Ansible Galaxy.- They develop transformer-based models called "Ansible Wisdom" for generating Ansible YAML from natural language. These models are pretrained on their YAML dataset and then finetuned for the natural language to Ansible YAML task.- They propose two new evaluation metrics tailored for assessing Ansible YAML generation: Ansible Aware and Schema Correct. - Their experiments show that their Ansible Wisdom models can generate Ansible YAML accurately from natural language prompts, outperforming existing code generation models like Codex and CodeGen in few-shot settings.- After finetuning, their best model (BLEU of 66.67) can even surpass a much larger Codex model (BLEU of 50.4), which was evaluated in few-shot mode. In summary, the key contribution is demonstrating the feasibility of applying LLMs to generate Ansible YAML code from natural language, including creating Ansible-specific models, metrics and datasets. The results show strong performance on this task, outperforming general code generation models.
