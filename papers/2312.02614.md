# [Prompt Optimization via Adversarial In-Context Learning](https://arxiv.org/abs/2312.02614)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes a new method called Adversarial In-Context Learning (Adv-ICL) to optimize prompts for in-context learning with large language models (LLMs). Adv-ICL sets up a minimax game between two LLMs acting as a generator and discriminator, with the goal of fooling the discriminator into classifying the generator's outputs as real. A third LLM called the prompt modifier iteratively suggests edits to the prompts given to the generator and discriminator based on the adversarial loss. Experiments over 11 NLP tasks involving summarization, reasoning, translation, etc. show that Adv-ICL significantly boosts the performance of state-of-the-art LLMs by updating only the prompts instead of model parameters. As a computationally efficient approach requiring very limited data, Adv-ICL demonstrates strong potential for real-world deployment. Core strengths highlighted are its model-agnostic architecture, ease of implementation, effectiveness in low resource scenarios, and applicability to complex reasoning prompts like chain-of-thought.
