# [Stochastic-Constrained Stochastic Optimization with Markovian Data](https://arxiv.org/abs/2312.04312)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper studies stochastic-constrained stochastic optimization, where the goal is to minimize an expected loss function subject to an expected constraint being below a threshold. The key challenge is that the functions are sampled from a Markov chain, so data samples have inherent dependence and bias. The paper develops primal-dual stochastic gradient algorithms based on extending the drift-plus-penalty method to the Markovian data setting. Two algorithms are proposed - one for known mixing time that sets parameters based on mixing time, and one adaptive method for unknown mixing time using AdaGrad-style parameter tuning. Both methods provide regret and constraint violation guarantees that reveal the dependence on mixing time. The adaptive method automatically tunes parameters without knowledge of horizon length or mixing time. Experiments demonstrate the effectiveness of the methods on a classification problem with fairness constraints. Overall, the paper initiates the study of stochastic approximation methods for constrained stochastic optimization that can handle non-i.i.d. Markovian data.
