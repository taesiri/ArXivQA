# [A Configurable Multilingual Model is All You Need to Recognize All   Languages](https://arxiv.org/abs/2107.05876)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main research question addressed in this paper is: How can we train a single multilingual speech recognition model that can be easily configured/adapted at inference time to recognize speech from any combination of languages selected by the user?The key points are:- The paper proposes a new "configurable multilingual model" (CMM) that can be configured at runtime to recognize speech from any combination of user-selected languages. - The CMM consists of a universal multilingual module plus small language-specific modules for each language. This allows it to leverage shared information across languages while still being adaptable for specific languages.- The CMM uses language-specific embedding, layers, and vocabularies to enable it to recognize speech from the user's selected languages.- A single CMM model only needs to be trained once, but can then be deployed in many usage scenarios based on different user language selections.- Experiments show the CMM improves over baseline universal and monolingual models, especially when users select just 1-3 languages.So in summary, the main research goal is developing a single multilingual model that is highly configurable at inference time based on user language selection, while still leveraging shared multilingual information during training.


## What is the main contribution of this paper?

The main contributions of this paper are:- Proposing a novel configurable multilingual model (CMM) that can be configured at inference time to recognize speech from any combination of languages based on user selection. - CMM consists of a universal multilingual module and small language-specific modules. It is trained only once but can be deployed as different models per user's language selection.- CMM employs language-specific embedding, layers, and vocabularies to achieve configurability. The language-specific layers model the residue information that is not covered by the universal module.- Experiments on 75K hours of Microsoft multilingual data with 10 languages show CMM significantly improves over the universal multilingual model without language ID input by 26.0%, 16.9%, 10.4% relative WER reduction when users select 1, 2, 3 languages respectively.- CMM also performs much better than the universal model on code-switching test sets, improving by 4.8-16.3% relative WER reduction.- Ablation studies validate the effectiveness of the proposed language-specific modules. Fine-tuning from a universal model is better than training CMM from scratch.In summary, the key novelty is proposing the configurable multilingual model that can be deployed to any user scenario based on language selection, while only requiring to be trained once. This greatly simplifies model training and deployment for multilingual ASR systems.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a configurable multilingual speech recognition model that can be adapted at inference time to recognize any combination of languages based on user selection, achieving improved performance over universal multilingual models.


## How does this paper compare to other research in the same field?

Here are a few key points on how this paper compares to other research in multilingual speech recognition:- The main goal of this paper is to develop a single multilingual model that can be configured at inference time to recognize speeches from any combination of languages based on user selection. This goal of a configurable multilingual model is novel compared to prior work. - Most prior work has focused on training universal multilingual models without language ID, or models that take a 1-hot language ID vector as input. However, these have limitations - the universal model cannot leverage language selection, while the 1-hot model can only handle one pre-selected language.- This paper proposes a new model architecture called the configurable multilingual model (CMM) that consists of a universal module plus small language-specific modules. At inference, the relevant language modules are extracted based on user language selection.- Compared to mixture-of-experts approaches, the language-specific modules in CMM are much smaller, allowing better scalability to more languages. The key innovation is the decomposition into a universal model plus residue modeling.- The paper demonstrates strong results by training a single CMM on 75K hours of 10 languages. The CMM outperforms universal and 1-hot models significantly when users pre-select languages.- The configurable model also shows gains on code-switching tasks without specific customization, demonstrating flexibility.- Overall, this paper introduces a novel multilingual modeling approach to address flexible user language selection, which is not addressed effectively in prior work. The configurable architecture and training method appear promising based on the presented results.


## What future research directions do the authors suggest?

Based on my reading of the paper, some future research directions the authors suggest are:- Improving the performance of universal multilingual models without language ID input to bridge the gap with monolingual models. The authors note the challenges the universal model faces without knowing the language in advance.- Exploring different training strategies for the configurable multilingual model (CMM), such as training from scratch versus fine-tuning from a universal model. The authors found fine-tuning worked better in their experiments.- Scaling up the CMM approach to even more languages. The authors tested up to 10 languages but note memory consumption as a concern when scaling up further. Options include using simpler language-specific modules or applying them only to certain layers.- Extending the configurable modules like the language-specific layer to other components beyond just the encoder network. The authors currently apply their method to the encoder but suggest extending it to other parts of the network.- Improving the modeling when users select many languages in the CMM, as performance declined as more languages were chosen. This could be addressed by balancing the frequency of language combinations better during training.- Applying the CMM model to other multilingual tasks beyond speech recognition, such as machine translation. The configurable nature of selecting language combinations could be useful in other domains.In summary, key future work revolves around improving universal and configurable multilingual models, scaling them up, extending the configurable modules, and applying the CMM approach to other multilingual applications. The authors lay out promising research directions to build on their work.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:This paper proposes a novel configurable multilingual model (CMM) for automatic speech recognition that can be configured at inference time to recognize any combination of languages selected by the user. The model consists of a universal module that captures shared information across languages, plus small language-specific modules that model the residue for each language. At runtime, the universal module and corresponding language-specific modules are activated based on the user's language selection. The model employs language-specific embedding, layers, and vocabularies to achieve this configurability with minimal increase in parameters over a standard multilingual model. Experiments on 75K hours of Microsoft data with 10 languages show CMM improves over a universal multilingual model without language ID by 26.0%, 16.9%, and 10.4% relative WER when users select 1, 2, or 3 languages respectively. CMM also significantly outperforms the universal model on code-switching tasks. The model provides flexibility to deploy a single multilingual model supporting any language combinations selected by users.


## Summarize the paper in two paragraphs.

Here is a summary of the paper in two paragraphs:The paper proposes a novel configurable multilingual speech recognition model (CMM) that can be configured at inference time to recognize speech from any combination of languages based on user selection. The model consists of a universal multilingual module that captures shared information across languages, as well as small language-specific modules for each language that model the language residues. At runtime, the universal module and corresponding language-specific modules are activated based on user language selection. The CMM model employs language-specific embedding, layers, and vocabularies to allow it to be highly configurable while requiring minimal additional parameters beyond a standard multilingual model. Experiments on a 75k hour Microsoft corpus with 10 languages showed the CMM model improved Word Error Rate (WER) by 26.0%, 16.9% and 10.4% relative over a universal multilingual model when users selected 1, 2 or 3 languages respectively. The model also performed significantly better on code-switching test sets. Overall, the proposed CMM model provides the flexibility to support user language selection while improving accuracy over standard multilingual models. Key innovations are the small language-specific modules and configurable training procedure.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper:The paper proposes a novel configurable multilingual model (CMM) for speech recognition that can be configured at inference time to recognize speeches from any combination of languages based on user selection. The CMM consists of a universal multilingual module that models shared information across languages, plus small language-specific modules for each language that model the residue/difference from the universal information. The language-specific modules include language-specific embeddings, a language-specific linear layer, and language-specific vocabularies. At inference time, the universal module together with only the language-specific modules of the user-selected languages are activated to form the deployed model per user choice. The CMM is trained only once with all languages using a special training algorithm that simulates random user selections of language combinations. This allows the single trained CMM to be configured for optimized recognition of any language combination at runtime based on user selection, overcoming limitations of prior multilingual models.
