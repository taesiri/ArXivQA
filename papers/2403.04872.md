# [Code-Mixed Probes Show How Pre-Trained Models Generalise On   Code-Switched Text](https://arxiv.org/abs/2403.04872)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Code-switching (CS) is a prevalent phenomenon where multilingual speakers seamlessly switch between languages. 
- CS data is useful for evaluating how well language models can capture meaning, since the presence of multiple languages requires models to learn meaning across languages instead of relying on spurious patterns.
- However, research on CS is challenging due to the scarcity of labelled CS data/resources.

Proposed Solution:
- The authors create a novel Spanglish (Spanish-English) CS dataset with parallel translations in both languages to allow for controlled evaluation. 
- They perform experiments probing popular language models (LMs) - mBERT, XLM-RoBERTa base/large - on their ability to:
   (a) detect CS text 
   (b) capture syntactic structure of CS  
   (c) represent semantics of CS consistently compared to monolingual text
- They also generate synthetic CS data for comparison.

Main Contributions:
- First curated corpus of naturalistic Spanglish CS sentences with parallel Spanish/English translations
- Extensive experiments probing LMs' CS detection ability, syntactic structure encoding, semantic consistency
- Findings show LMs are surprisingly effective at generalizing to real CS text in all three dimensions, indicating potential to harness monolingual data for CS
- Reveals high performance degrades significantly on synthetic CS data, highlighting importance of naturalistic data
- Provides framework for future empirical verification of linguistic theories of CS based on usage-based language acquisition

The paper makes key contributions in creating resources and methodology to systematically evaluate language models' capabilities on code-switched text. The findings reveal promising model generalization abilities to real code-switching without explicit training.
