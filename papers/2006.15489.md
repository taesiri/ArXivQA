# [Video Representation Learning with Visual Tempo Consistency](https://arxiv.org/abs/2006.15489)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: Can visual tempo consistency serve as an effective self-supervision signal for video representation learning? The key hypotheses appear to be:- Videos of the same action instance but with different visual tempos (i.e. fast vs slow) share high similarity in terms of discriminative semantics.- Maximizing mutual information between representations of slow and fast videos of the same instance via contrastive learning can allow encoders to learn useful representations without labels.- A hierarchical contrastive learning scheme that matches representations from multiple network depths can provide stronger supervision, especially for deeper networks.The authors propose the visual tempo consistency as a novel pretext task for self-supervised video representation learning. Their method trains video encoders by maximizing agreement between representations of slow and fast videos of the same instances using contrastive learning. The goal is to learn representations that capture semantics shared across different visual tempos.
