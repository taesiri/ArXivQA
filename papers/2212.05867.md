# [ALSO: Automotive Lidar Self-supervision by Occupancy estimation](https://arxiv.org/abs/2212.05867)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we develop an effective self-supervised pretext task for 3D point clouds that produces features useful for downstream semantic segmentation and object detection tasks?

The key ideas and approach proposed to address this question are:

- Using surface reconstruction from point clouds as a pretext task for self-supervision, without requiring ground truth shape labels.

- Estimating occupancy in local neighborhoods around each point by predicting whether query points are inside or outside the implicit surface. 

- Exploiting visibility information from the sensor viewpoint to automatically generate supervised query points. 

- Encouraging each point's features to capture semantics beyond just local geometry by reconstructing occupancy in a larger region.

- Showing this approach is effective for pre-training features that transfer well to semantic segmentation and object detection across different datasets and network architectures.

In summary, the central hypothesis is that surface reconstruction can be adapted as an effective self-supervised pretext task for point clouds that learns semantically useful features for perception tasks. The experiments aim to validate this idea across various settings.
