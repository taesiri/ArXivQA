# [Neutral Editing Framework for Diffusion-based Video Editing](https://arxiv.org/abs/2312.06708)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Neutral Editing Framework for Diffusion-based Video Editing":

Problem: 
Existing diffusion-based text-to-video editing systems have limited capabilities and can only perform rigid types of editing like style transfer or object overlay. They struggle with more complex non-rigid editing that involves changing the motion of objects/people in the video based on text prompts. For example, if prompted to change a video of a man walking to show him jumping, current systems fail to make this change and just output the original video again. 

Proposed Solution:
The paper proposes a "Neutral Editing (NeuEdit)" framework that enhances the tuning-editing pipeline of diffusion editing systems to enable non-rigid motion editing. The key ideas are:

1) Neutral Prompt Tuning: Replace the additional "source prompt" used currently with a "neutral prompt" that masks words related to editing from the target prompt. This focuses tuning on just the video without spurious reliance on the source prompt. 

2) Neutral Video Editing: Construct a "neutral video" by reducing the influence of original motion in the region to be edited using visual neutralization. This amplifies possibilities for editing by reducing motion constraints.

The neutral prompt and video are constructed using a new "neutralization" technique to disentangle editing factors. NeuEdit can be integrated into existing systems easily.

Main Contributions:
- Proposes the first framework to achieve complex non-rigid motion editing in videos using just text prompts 
- Introduces the novel concept of neutralization to improve tuning and editing
- Achieves state-of-the-art performance in editing alignment, fidelity and consistency
- Can be integrated into existing diffusion editing systems easily in a model-agnostic manner

The experiments validate NeuEdit's ability to change object/human motions based on text as well as its adaptability across multiple recent editing systems.
