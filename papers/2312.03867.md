# [Multi-Group Fairness Evaluation via Conditional Value-at-Risk Testing](https://arxiv.org/abs/2312.03867)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Fairness in machine learning models is typically evaluated by comparing performance metrics across pre-defined groups (e.g. race, gender). However, evaluating fairness across combinations of multiple sensitive attributes (intersectional groups) causes the number of groups to grow exponentially, making fairness evaluation challenging.

- Existing "max-gap" fairness metrics that measure the maximum performance gap across groups require Ω(K) samples to reliably estimate, where K is the number of groups. This becomes infeasible for intersectional groups where K is exponentially large.

Proposed Solution:
- The paper proposes a more lenient "conditional value at risk" (CVaR) fairness metric that allows capturing tail fairness violations while requiring less samples to estimate. 

- Two auditing algorithms paired with weighted or attribute-specific sampling strategies are provided to test if CVaR fairness exceeds a threshold using the proposed estimators.

Main Contributions:
- CVaR fairness is formally defined and shown to lower bound max-gap fairness notions, while still allowing recovery of max-gap violations.

- Under weighted sampling, the auditing algorithm can reliably estimate CVaR fairness using O(√K) samples, vs Ω(K) for max-gap fairness, an exponential improvement.

- Under attribute-specific non-i.i.d. sampling, the auditing algorithm can reliably estimate CVaR fairness using O(1) samples, independent of number of groups K.

- For weighted sampling and uniform groups, optimality of the √K dependence on number of groups K is formally shown.

In summary, the paper introduces CVaR fairness to enable feasible and reliable auditing for fairness violations across intersectional groups, overcoming limitations of prior max-gap notions. Theoretical analysis is provided on sample complexities and optimality.
