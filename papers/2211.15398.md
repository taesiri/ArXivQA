# [Leveraging per Image-Token Consistency for Vision-Language Pre-training](https://arxiv.org/abs/2211.15398)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question addressed in this paper is:

How can we improve vision-language pre-training methods to learn better associations between visual and textual concepts, overcoming issues like modality bias and underutilization of unmasked tokens? 

The key hypothesis is that explicitly identifying salient visual tokens, generating inconsistent alternatives, and training the model to recognize token-image (in)consistency across all tokens can improve vision-language association learning compared to existing pre-training objectives like masked language modeling.

The authors propose a new pre-training approach called EPIC to test this hypothesis. The main components are:

1) Saliency-based masking to identify visually salient tokens to mask 

2) Inconsistent token generation by replacing masked tokens with alternatives from a language model

3) Image-token consistency task to predict whether each token is consistent with the image

Through experiments on various vision-language models and datasets, the authors demonstrate that EPIC improves performance on downstream tasks compared to strong baselines, supporting their hypothesis. The proposed method allows learning associations between more tokens and images, and reduces reliance on just the textual modality.
