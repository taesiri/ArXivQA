# [LuoJiaHOG: A Hierarchy Oriented Geo-aware Image Caption Dataset for   Remote Sensing Image-Text Retrival](https://arxiv.org/abs/2403.10887)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
Existing remote sensing image caption datasets lack geographic diversity in sampling, use limited labels, and have brief, repetitive descriptions. This hinders the development of sophisticated image-text retrieval models. There is a need for a geo-aware dataset with rich labels and detailed captions. 

Proposed Solution:
The authors introduce LuojiaHOG, a hierarchical geo-aware image caption dataset with 94,856 images categorized into 131 labels across 21 parent classes. Images are globally and heterogeneously sampled using landscape indexes. An extensible OGC standard-aligned classification system allows expansion. Captions are professionally annotated and enhanced using vision-language models with prompt engineering for quality and diversity.

A CLIP-based Image Semantic Enhancement Network (CISEN) is also proposed. It transfers knowledge from CLIP into dual encoders and fuses global visual features with local multi-level features for enhanced representations, facilitating sophisticated retrieval.

Main Contributions:
1) LuojiaHOG - a large-scale geo-aware image caption dataset with hierarchical sampling, an extensible classification system, and high-quality diverse annotations.

2) CISEN - an architecture that transfers knowledge from CLIPs and hierarchically fuses global and local visual features for enhanced image representations.

3) Extensive experiments including baselines for 7 state-of-the-art models over 2 granularities of labels. CISEN outperforms all models, especially benefiting smaller models.

4) Resources to facilitate sophisticated remote sensing image-text retrieval research including the dataset, code, and baselines.
