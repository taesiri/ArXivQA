# [MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions](https://arxiv.org/abs/2403.19651)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Image retrieval suffers from ambiguous search intents that are hard to capture solely based on visual similarity. Using text instructions allows users to better express diverse real-world search intents.  
- However, existing methods focus on pre-defined relations and synthesized instructions, limiting the richness of relations they can model.

Proposed Solution:
- Key idea: Image pairs naturally co-occurring on web pages contain implicit relations beyond visual similarity. Explicit instructions for those relations can be synthesized with large language/multimodal models.

- Construct 36.7M (query image, instruction, target image) triplets with rich relations by:
  1) Extracting co-occurring image pairs from web pages
  2) Annotating image metadata with multimodal models
  3) Generating open-ended instructions with language models

- Propose MagicLens - Lightweight dual encoders trained on constructed triplets to embed (image, instruction) pairs for retrieval.

Main Contributions:

- Novel insight to use natural web image pairs as self-supervised signals 

- Method to construct 36.7M high-quality triplets with open-ended instructions  

- MagicLens models achieve better results than prior arts on 8 benchmarks, with 50x smaller size

- In-depth analysis on 1.4M corpus shows MagicLens captures diverse search intents, especially complex beyond-visual ones

- Recipe to create large-scale self-supervised data can enable advances in other multimodal tasks
