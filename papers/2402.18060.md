# [Benchmarking Large Language Models on Answering and Explaining   Challenging Medical Questions](https://arxiv.org/abs/2402.18060)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Existing benchmarks for evaluating medical question answering capabilities of large language models (LLMs) rely on textbook-style questions or general clinical questions, which do not capture the complexity of real clinical cases that doctors face.  
- Moreover, these benchmarks do not contain expert explanations of the answers, which are crucial for doctors to understand the reasoning behind medical decisions.

Proposed Solution:
- The authors construct two new challenging medical QA datasets - JAMA Clinical Challenge and Medbullets - which contain questions based on complex real-world clinical cases and USMLE Step 2/3 exam-style questions, respectively.
- Each question is a multiple choice problem with 4/5 answer options, accompanied by an expert-written explanation justifying the correct answer and incorrect choices.

Experiments and Results: 
- Four LLMs (GPT-3.5, GPT-4, PaLM 2, Llama 2) are evaluated on the two datasets using different prompting strategies. Performance drops compared to previous easier benchmarks, showing the challenge posed by these new datasets.
- Model-generated explanations under prompting are evaluated both automatically and by human annotators. Inconsistency is observed, highlighting the need for better evaluation metrics aligned with human judgment.

Main Contributions:
- Construction of two new challenging medical QA datasets with high-quality human explanations
- Demonstration that the new datasets are harder for current LLMs compared to previous benchmarks
- Analysis of model-generated explanations and findings on limitations of current automatic evaluation metrics

The paper makes an important step towards more realistic evaluation of medical reasoning capabilities of LLMs to support doctors in clinical practice. Developing better explanation evaluation metrics is highlighted as an important direction for future work.
