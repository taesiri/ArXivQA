# [Three Sentences Are All You Need: Local Path Enhanced Document Relation   Extraction](https://arxiv.org/abs/2106.01793)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: Given an entity pair in a document, how many sentences are sufficient to identify the relationship between them?The key findings and contributions of the paper are:- Through analysis on 3 document-level RE datasets (DocRED, CDR, GDA), the authors find that most entity relation instances (95%+) can be identified using no more than 3 sentences as evidence. This suggests reading the full document may not be necessary for relation extraction.- The authors propose 3 heuristic rules to extract "paths" between entities that serve as good proxies for the annotated supporting evidence. Up to 87.5% of supporting evidence can be covered by the extracted paths.  - By feeding just the extracted paths (instead of full documents) to a BiLSTM model, the authors achieve strong performance on DocRED, even outperforming more complex graph-based models. This shows the sufficiency of their path extraction heuristics.- The key contributions are: (1) Empirical analysis showing relations can be identified from just a few sentences, motivating focused modeling; (2) Simple but effective path extraction heuristics to approximate supporting evidence; (3) Demonstrating strong performance can be achieved using just extracted paths, without full documents.In summary, the paper shows that for document-level RE, modeling just a few key sentences connecting entities is sufficient, instead of using full documents. The proposed path extraction heuristics are an effective way to achieve this.


## What is the main contribution of this paper?

The main contributions of this paper are:1. An analysis on 3 document-level relation extraction datasets showing that most relation instances can be identified using just 1-3 sentences, instead of the full document context. 2. Proposing heuristic rules to extract "paths" connecting entity pairs as a simple but effective way to select the most relevant evidence sentences. The paths include consecutive sentences, multi-hop connections via bridge entities, and default sentence pairs.  3. Demonstrating that feeding just the extracted paths to a simple BiLSTM model achieves strong performance on the DocRED benchmark, even outperforming more complex graph neural network models.4. Providing explanations for the observation that few sentences suffice for relation extraction from linguistic and cognitive science perspectives.In summary, the key ideas are:- Relation instances typically require only 1-3 sentences as evidence, not full documents.- Heuristic path extraction can effectively filter documents to relevant evidence. - Simple models over extracted paths can achieve very strong results.- The sufficiency of few sentences may be explained by linguistic patterns and cognitive factors.The overall contribution is showing that simple path extraction and modeling over a few sentences is a surprisingly effective approach for document-level relation extraction.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper shows that for document-level relation extraction, most relation instances can be identified using only 1-3 sentences as evidence, and proposes a simple but effective method to heuristically select these key evidence sentences for each entity pair which improves performance when combined with a BiLSTM model.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other research in document-level relation extraction:- The core finding that most relation instances can be identified with just 1-3 sentences is novel. Prior work largely assumed reasoning over full documents was needed. This paper empirically analyzes real datasets to show relations are more locally identifiable.- The proposed path extraction method is simple and interpretable compared to prior graph neural network based approaches. By explicitly extracting paths connecting entities, the method provides intuitive selected evidence.- The performance of the path extraction + BiLSTM model is very competitive. It outperforms prior sequence models and even some graph models on the DocRED benchmark. This shows the effectiveness of focused sentence selection.- The interdisciplinary discussion bringing in linguistics and cognitive science provides helpful context for the findings. Connecting the observed localization of relations to co-reference and working memory limitations gives plausible explanations.- Overall, the paper makes a compelling argument that full document reasoning may be unnecessary, and that better performance can be achieved by careful sentence filtering. The simple proposed method matches or exceeds more complex models. The empirical analysis and findings appear novel and impactful.


## What future research directions do the authors suggest?

Based on the analysis and discussion in the paper, the authors suggest several future research directions:- Further investigate the linguistic and cognitive explanations for the "three sentences are sufficient" phenomenon in document-level relation extraction. The authors provide some initial hypotheses from linguistic and cognitive perspectives, but more in-depth analysis is needed. - Explore different ways to select the most informative sentences/paths from documents for relation extraction. The heuristic rules proposed in this work serve as a strong baseline, but there may be better or more principled ways to identify key evidence sentences. - Study if the "three sentences" finding generalizes to other long context NLP tasks besides relation extraction, such as event extraction, coreference resolution, etc. - Develop models that can take advantage of the focused evidence sentences rather than modeling the full document. The authors show this is beneficial for a BiLSTM model, but more sophisticated models can be explored.- Evaluate the real-world applicability of focused evidence selection, and whether it leads to efficiency gains for human annotation or deployment.- Extend the analysis to other document-level NLP tasks like machine reading comprehension, summarization, etc. to see if similar evidence filtering is helpful.In summary, the key future directions are: 1) further investigate the linguistic and cognitive hypotheses, 2) explore better evidence selection techniques, 3) study wider applicability to other tasks, 4) develop models leveraging selected evidence, and 5) validate real-world utility.
