# [Large Language Models for Expansion of Spoken Language Understanding   Systems to New Languages](https://arxiv.org/abs/2404.02588)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Spoken language understanding (SLU) models are core to voice assistants but developing them requires extensive labeled datasets which poses challenges for expanding to low-resource languages. 
- Existing approaches to cross-lingual SLU use code-switching methods which have limitations, especially for low-resource languages. 
- Machine translation (MT) of SLU training data has faced difficulties with slot alignment across languages.

Proposed Solution:
- Use large language models (LLMs) fine-tuned for machine translation to translate English SLU training data to other languages. 
- Adopt the EasyProject method of annotating named entities with HTML-like tags to enable better transfer of slots.  
- Fine-tune BigTranslate LLM on MASSIVE dataset with adapted HTML-like annotations for named entity translation.
- Translate MultiATIS++ English train set to 8 languages - German, Spanish, French, Turkish, Hindi, Japanese, Portuguese, Chinese.

Main Contributions:
- Achieved new state-of-the-art on MultiATIS++ benchmark for cross-lingual SLU, improving Overall Accuracy from 53% to 62.18% in cloud scenario and from 5.31% to 22.06% in on-device scenario.
- Showcased superiority of LLM-based MT for slot alignment compared to complex existing methods.  
- Proposed approach is slot-agnostic, not requiring slot descriptions or examples.
- Demonstrated method's effectiveness by training compact on-device SLU model from scratch with 17% relative improvement over baseline.
- Presented streamlined and scalable solution that does not require changes to SLU production architecture.
