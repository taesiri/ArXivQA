# [The Impact of Unstated Norms in Bias Analysis of Language Models](https://arxiv.org/abs/2404.03471)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) trained on vast datasets can carry societal biases, which often manifest as performance disparities that harm underprivileged groups. 
- A common approach to quantifying bias is to use template-based probes that explicitly state group membership (e.g. White, Black) and check if predictions are invariant to changing the stated group. 
- However, the authors find that when using such probes, text examples associated with White ethnicities appear to be classified as more negative compared to other groups.

Proposed Explanation:  
- The authors hypothesize this occurs due to a mismatch between LLM pre-training data and template probes due to "reporting bias".
- In pre-training data, membership in dominant groups like White is often presumed without being stated explicitly. However, template probes explicitly state race.
- This makes probe examples with stated White race seem unusual relative to training data, potentially causing higher error rates.

Key Contributions:
- Empirically demonstrates that template probes can produce misleading measurements of biases against privileged groups like Whites due to reporting bias in training data.   
- Highlights need to consider interaction between training data distributions and probe design when quantifying biases.
- Suggests techniques like using metadata or classifications for establishing group membership to avoid stated race in probes.
- Opens up further investigations into impact of reporting bias on societal bias measurements and whether multimodal models can help.

In summary, the key insight is that mismatch between biases in training data and probe design can lead to misleading bias measurements, especially for privileged groups. Authors highlight this issue and suggest directions for further work.
