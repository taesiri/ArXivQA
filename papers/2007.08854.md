# DVI: Depth Guided Video Inpainting for Autonomous Driving

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we develop an effective video inpainting method to remove objects and fill in missing regions in videos captured from autonomous vehicles, using the available image and depth data? The key points are:- Video inpainting is useful for creating clean background images for autonomous driving applications, by removing dynamic agents like vehicles and pedestrians. - Existing inpainting methods have limitations in handling complex outdoor scenes with perspective changes and long-term occlusions.- The authors propose using depth data along with images to guide video inpainting, by building 3D maps to establish geometric correlations across frames.- They introduce techniques like candidate color sampling, belief propagation regularization, color harmonization, and video fusion to generate high quality inpainting results.- A new dataset is collected to evaluate the proposed approach against state-of-the-art methods, and both qualitative and quantitative results demonstrate the effectiveness of their depth guided video inpainting technique.In summary, the key hypothesis is that leveraging depth data and 3D geometry can significantly improve video inpainting quality compared to existing image-only methods, especially for autonomous driving scenarios. The experiments validate this hypothesis.
