# [Class Incremental Learning for Adversarial Robustness](https://arxiv.org/abs/2312.03289)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes a new method called Adversarially Robust Class Incremental Learning (ARCIL) to improve the adversarial robustness of deep learning models in an incremental learning setting. The authors identify a problem they term "flatness forgetting", where models lose the flatness of their loss landscape on past tasks when learning new tasks incrementally. This flatness is important for adversarial robustness. To address this, they propose a Flatness Preserving Distillation (FPD) loss that aligns the difference in outputs between clean and adversarial examples from the current model to a previous model, helping to transfer flatness. They also introduce a Logit Adjustment Distillation (LAD) loss that adapts the previous model's knowledge to new tasks by modifying its logits on new data based on feature robustness. Experiments across datasets demonstrate state-of-the-art performance, with substantially higher robust accuracy and reduced catastrophic forgetting compared to baselines. The method provides an effective approach for incremental learning with adversarial robustness and introduces the novel concept of flatness forgetting in this setting.
