# [Good Questions Help Zero-Shot Image Reasoning](https://arxiv.org/abs/2312.01598)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes Question-Driven Visual Exploration (QVix), a new prompting strategy to enhance large vision-language models (LVLMs) for complex zero-shot image reasoning tasks. LVLMs tend to focus on sparse image regions related to textual prompts, overlooking contextual details. To address this "tunnel vision", QVix leverages language models to generate exploratory pre-questions guiding LVLMs to uncover subtle, relevant visual information. Specifically, pre-questions are generated from the task instructions and original query, directing attention beyond prominent objects to contextual clues. The enriched representation then conditions an LVLM's final reasoning. Evaluations on challenging vision-language tasks like VQA, visual entailment, and fine-grained classification show QVix boosts different LVLMs' reasoning accuracy and depth. Qualitative analysis reveals pre-questions enable more nuanced visual interpretation, e.g. distinguishing similar dog breeds by facial details. Compared to chain-of-thought prompting, QVix better utilizes LVLMs' reasoning potential. The ability to elicit prior knowledge for comprehensive image analysis highlights QVix's value in complex visual reasoning.
