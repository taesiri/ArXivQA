# Statler: State-Maintaining Language Models for Embodied Reasoning

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can large language models (LLMs) be better leveraged for long-horizon robotic planning tasks? The key hypothesis is that equipping LLMs with an external world state model to explicitly track state updates over time will improve their capacity for long-term reasoning in robotics applications.Specifically, the paper proposes a framework called Statler that uses a world-model reader LLM and a world-model writer LLM to interact with and maintain a symbolic world state representation. This aims to mitigate the limited context window and implicit memory of standard LLMs when reasoning over complex planning tasks with long action sequences.The experiments then evaluate whether Statler enables better performance on simulated tabletop manipulation tasks and a real robot task compared to a strong baseline method (Code-as-Policies) without an explicit world model. The results suggest that maintaining the external world state does indeed improve the long-term reasoning capabilities of the LLM.In summary, the central hypothesis is that augmenting LLMs with a persistent, updatable symbolic world model will make them more suitable for long-horizon robotic planning problems needing memory over many time steps. The experiments aim to validate this hypothesis.


## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is how to enable large language models (LLMs) to perform long-horizon robotic planning tasks. Specifically, the paper argues that existing methods that use LLMs for robotics struggle with long-horizon planning due to the limited context window of LLMs. The key hypothesis is that equipping LLMs with an external world state model to explicitly track state information over time will improve their ability to reason and plan over longer horizons.The central goal of the paper is to develop a framework called Statler that maintains an external world state model using two LLM modules - a world model reader and a world model writer. The world model reader generates plans and code based on user instructions and the current world state, while the world model writer updates the external state representation after actions are taken. The central hypothesis is that by relying on this explicit external state model rather than just the implicit memory of the LLM, Statler will enable LLMs to successfully carry out long-horizon robot planning tasks that require reasoning over an extended time history. The paper evaluates this hypothesis through experiments in simulated tabletop domains as well as a real robot domain.
