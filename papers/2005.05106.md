# [Multi-band MelGAN: Faster Waveform Generation for High-Quality   Text-to-Speech](https://arxiv.org/abs/2005.05106)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to build a faster and higher quality neural vocoder for text-to-speech based on generative adversarial networks (GANs). 

Specifically, the paper aims to improve upon the MelGAN neural vocoder to make it faster and produce higher quality speech synthesis. The main hypotheses are:

1. Increasing the receptive field of the generator will improve speech quality by better modeling long-term dependencies. 

2. Replacing the feature matching loss with a multi-resolution STFT loss will enable better measurement of differences between real and fake speech.

3. Using a multi-band architecture with a shared generator for all bands will reduce computational complexity and speed up waveform generation. 

4. Combining sub-band and full-band multi-resolution STFT losses will improve quality and training stability of the multi-band model.

The experiments aim to test these hypotheses and demonstrate a faster high-quality neural vocoder based on an improved MelGAN model with multi-band processing. The vocoder is evaluated both in isolation and when integrated into an end-to-end TTS system.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposes several important improvements to the original MelGAN vocoder:
- Increases receptive field size of generator to improve quality
- Uses multi-resolution STFT loss instead of feature matching loss to improve quality and training stability 
- Adds generator pre-training to improve quality and speed up training

2. Proposes a multi-band version of MelGAN (MB-MelGAN) that generates speech in multiple frequency bands, then sums them to produce full-band audio. This significantly reduces computational complexity.

3. Shows combining sub-band and full-band multi-resolution STFT losses improves MB-MelGAN quality and training stability.

4. Evaluations show the improved MelGAN vocoder achieves a MOS of 4.35 compared to 3.98 for original MelGAN. 

5. MB-MelGAN retains comparable quality but reduces model size to 1.91M parameters and runs 7x faster than original MelGAN with a real-time factor of just 0.03 on CPU.

6. Validates proposed MelGAN vocoders in a Tacotron 2 TTS system, showing significant quality improvements over original MelGAN.

In summary, the key contribution is proposing an improved and efficient MelGAN vocoder that runs much faster but retains high speech quality, enabling faster neural TTS systems. The improvements to original MelGAN and multi-band processing approach are the main novelties presented.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 The paper proposes a faster and higher quality neural vocoder called multi-band MelGAN for text-to-speech synthesis by improving MelGAN with a larger receptive field, multi-resolution STFT loss, and multi-band processing.


## How does this paper compare to other research in the same field?

 Here are a few key points on how this paper compares to other research on waveform generation for text-to-speech:

- This paper proposes improvements to MelGAN, an existing vocoder based on generative adversarial networks. It shows techniques like increasing receptive field, using multi-resolution STFT loss, and pre-training can significantly improve MelGAN's quality.

- It introduces a multi-band extension to MelGAN that generates sub-band signals, reducing computational complexity. This is similar to prior work on multi-band WaveRNN but applied to the MelGAN architecture. 

- Evaluations show the improved MelGAN matches or exceeds the quality of other vocoders like WaveRNN and WaveNet while being much faster. The multi-band version achieves real-time CPU synthesis.

- This is one of the earlier papers showing GAN-based vocoders like MelGAN can reach state-of-the-art quality for TTS. Later work has built on these techniques.

- Compared to autoregressive models, this parallel vocoder trades off some potential quality for substantially improved inference speed. But it matches Flow-based approaches like WaveGlow without requiring weeks of GPU training.

- For TTS, this vocoder improves on basic MelGAN and helps close the gap between Tacotron-2 TTS and real recordings. But some artifacts remain compared to highest quality TTS systems.

In summary, this paper demonstrates optimized MelGAN as a fast, lightweight and high-quality vocoder for TTS, with innovations in architecture, losses and multi-band processing. It expands the viability of GAN-based vocoders. The techniques contribute to an ongoing research direction toward real-time TTS.


## What future research directions do the authors suggest?

 The authors suggest a few future research directions:

- Continue to improve the quality of speech synthesized by GAN-based neural vocoders to close the gap with real human speech. The paper notes there is still a quality difference between the best GAN vocoders and natural speech.

- Explore ways to further improve the efficiency and speed of neural vocoders while maintaining high audio quality. The multi-band MelGAN proposed in this paper is very fast but there may be room for additional optimizations.

- Extend the vocoder models to handle multiple speakers and higher sampling rates. The current work focuses on a single speaker at 16kHz but the authors mention informal testing on multi-speaker and 24kHz versions. Formal experiments on those setups could be worthwhile.  

- Combine the proposed vocoder models with other neural TTS acoustic models beyond Tacotron 2. The benefits of the improved MelGAN as a vocoder could be verified in other state-of-the-art TTS frameworks.

- Apply the vocoder for other speech generation tasks beyond TTS, such as voice conversion, speech enhancement, etc. The improved neural vocoder could potentially improve audio quality in those applications as well.

In summary, the main future directions are to continue improving GAN-based vocoder quality and efficiency, and evaluate the vocoders on expanded conditions, tasks and frameworks. The results so far are promising for MelGAN-type models.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper proposes a multi-band MelGAN model for fast and high-quality waveform generation for text-to-speech. The authors make several improvements to the original MelGAN architecture, including expanding the receptive field of the generator, using multi-resolution STFT loss instead of feature matching loss, and pre-training the generator. They then propose a multi-band architecture where the generator takes mel spectrograms as input and predicts signals for multiple frequency bands, which are summed to produce the final waveform. This allows for a much smaller and faster model while retaining high audio quality. Experiments show the proposed model achieves a MOS score of 4.34 for waveform generation and 4.22 for TTS while reducing computational complexity nearly 6 times compared to the original MelGAN. The model can run in real-time on CPU without optimization. Overall, the multi-band MelGAN provides an efficient and high-quality neural vocoder for text-to-speech applications.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper presents improvements to MelGAN, a fast neural vocoder for waveform generation. The improvements include expanding the receptive field of the generator, using pre-training and multi-resolution STFT loss, and introducing multi-band processing. These changes lead to higher quality speech synthesis and faster waveform generation compared to the original MelGAN model. 

The key contribution is a multi-band MelGAN (MB-MelGAN) which predicts audio in multiple frequency bands using a shared generator network. Sub-band signals are summed to produce the final waveform. This approach greatly reduces model complexity and speeds up waveform generation. Evaluations show the improved MelGAN achieves a MOS of 4.35 compared to 3.98 for the original model. MB-MelGAN retains this high quality with only 1.91M parameters and runs 7x faster than MelGAN, achieving a real-time factor of 0.03 on CPU. The vocoder improvements also benefit text-to-speech, with the MB-MelGAN model producing the closest quality to real recordings when combined with a Tacotron 2 acoustic model. Overall, this work demonstrates how modifications to MelGAN can achieve faster and higher quality speech synthesis while retaining the efficiency of the original model.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes Multi-band MelGAN, an improved version of MelGAN for faster waveform generation in text-to-speech. The key improvements are:

1) Increasing the receptive field of the generator to better model long-term dependencies in speech. 

2) Using multi-resolution STFT loss instead of feature matching loss to better measure differences between real and generated speech.

3) Adopting multi-band processing - the generator predicts sub-band signals which are summed to get full-band signal. This significantly reduces computational complexity. 

4) Combining sub-band and full-band multi-resolution STFT losses for better quality and training stability.

Experiments show the proposed model achieves excellent quality with only 1.91M parameters and runs 7x faster than MelGAN. When used as a vocoder in Tacotron2 TTS, it achieves higher MOS of 4.22 compared to 3.87 for original MelGAN.
