# [BloomVQA: Assessing Hierarchical Multi-modal Comprehension](https://arxiv.org/abs/2312.12716)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Current VQA datasets focus on fact-based memorization and simple reasoning, without systematic scientific grounding to evaluate comprehension. 
- No principled framework exists to characterize and improve models on advanced comprehension skills.

Proposed Solution:
- Authors propose a new VQA dataset called BloomVQA, based on picture stories for early childhood education.
- Data samples are collected and annotated based on Bloom's Taxonomy from education research, which categorizes learning objectives into 6 levels of complexity reflecting different comprehension skills.
- A hierarchical graph-based representation called Story Graph is introduced to model relations between events at different Bloom's levels. This enables automatic data augmentation and analysis.

Key Contributions:  
- BloomVQA dataset containing 1200 multiple-choice QA samples categorized into 6 levels of Bloom's Taxonomy to enable graded evaluation.
- Novel Story Graph representation extending concept of scene graphs to model cross-level relations based on cognitive processes from Bloom's levels. Enables data augmentation and consistency analysis.  
- Proposed consistency metrics quantify model reliability by examining impact of contextual knowledge at different Bloom's levels on QA performance.
- Analysis of state-of-the-art VLP models demonstrates performance degradation on high-level comprehension tasks. Consistency analysis also reveals model behaviors misaligned with human comprehension patterns.

In summary, the paper introduces a principled methodology grounded in learning science to facilitate analysis, assessment and improvement of vision-language models on comprehension capabilities of varying complexity. Both dataset and consistency metrics enable richer characterization of model reliability.
