# [REFACTOR: Learning to Extract Theorems from Proofs](https://arxiv.org/abs/2402.17032)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper aims to mimic the human ability to extract reusable, modular theorems from complex mathematical proofs. Such theorems help simplify and generalize proofs, just as concepts like integrals and derivatives crystallized techniques like exhaustion. Automatically extracting reusable theorems can aid automated theorem provers and simplify large proof libraries.

Proposed Solution:
The paper proposes REFACTOR, a method to train graph neural networks to extract theorem components from proofs. It creates training data by "expanding" proofs - substituting an invoked theorem with its full proof tree. The model is trained to identify the original theorem's proof subtree. At test time, predictions are checked for validity as theorems. 

Contributions:
1) A novel supervised approach to mimic human theorem extraction, formalized as node classification on proof trees.
2) Accuracy of 19.6% extracting same theorems as humans, improved with larger models.
3) From test proofs, REFACTOR extracts 1907 novel reusable theorems. 
4) Applying extracted theorems to refactor the Metamath library compresses proofs by 400k nodes.
5) A prover trained on refactored proofs proves 75 more test theorems than baseline, with 31% of proofs leveraging extracted theorems. This demonstrates their reusability.

In summary, the paper presents the first proof-of-concept for neural theorem extraction on real proofs, shows accuracies on par with human extractions, and demonstrates downstream benefits for compression and automated reasoning. The diversity of usable extracted theorems indicates promise for further research.
