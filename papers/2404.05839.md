# [ÚFAL LatinPipe at EvaLatin 2024: Morphosyntactic Analysis of Latin](https://arxiv.org/abs/2404.05839)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- The paper describes the winning system "ÚFAL LatinPipe" for the EvaLatin 2024 Dependency Parsing shared task. The goal is to develop an accurate dependency parser and morphological analyzer for Latin.

Proposed Solution:
- LatinPipe is based on UDPipe 2, using a graph-based parser with a neural network to score edges. The network architecture is a fine-tuned pretrained language model (LM) like LaBerta, with additional heads for parsing and morphology.

- LatinPipe is trained on 7 Latin treebanks in a multi-treebank approach. The treebanks are harmonized to reduce annotation divergence. 

- Enhancements include: frozen LM pretraining, stacked BiLSTM layers for contextualization, feeding gold UPOS tags as input, and ensembling multiple models.

Main Contributions:
- Sets new state-of-the-art results for Latin dependency parsing and morphological analysis, surpassing previous systems on all UD 2.13 treebanks.

- Shows strong gains from concatenating multiple pretrained LMs like LaBerta+PhilBerta+XLM-RoBERTa.

- Demonstrates effectiveness of multi-treebank training and treebank harmonization for improving parser generalization.

- Provides thorough evaluation and analysis of various architecture choices to guide future work on graph-based dependency parsing.

The paper provides valuable insights and techniques for developing accurate neural parsers for morphologically-rich and low-resource languages like Latin. The source code is publicly available to facilitate further research.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper describes LatinPipe, a graph-based dependency parser and joint morphological analyzer using fine-tuned pre-trained language models which won the EvaLatin 2024 shared task through ensembling models trained on harmonized multi-treebank data.


## What is the main contribution of this paper?

 Based on the content summarized in the paper, the main contributions are:

1) The development of LatinPipe, the winning system for the EvaLatin 2024 shared task on morphosyntactic analysis of Latin. LatinPipe is an evolution of UDPipe 2, using a fine-tuned pretrained language model architecture to jointly perform dependency parsing and morphological analysis.

2) An extensive evaluation of different approaches for building LatinPipe: comparing monolingual vs multilingual PLMs, concatenating multiple PLMs, adding frozen pretraining and BiLSTM layers on top of PLMs, using gold UPOS tags as input, and ensembling multiple models.

3) Leveraging and harmonizing multiple Latin treebanks for multi-treebank training of the models, which is shown to improve performance over single-treebank training.

4) Setting new state-of-the-art results on the UD 2.13 Latin test sets for dependency parsing, UPOS tagging, and UFeats tagging.

5) Releasing the source code for LatinPipe to support future work on processing Latin and other languages.

In summary, the main contribution is the development and thorough evaluation of LatinPipe, a new state-of-the-art neural model for morphosyntactic analysis of Latin.


## What are the keywords or key terms associated with this paper?

 Based on scanning the content of the paper, some of the main keywords and key terms associated with it are:

- dependency parsing
- part of speech tagging
- EvaLatin 
- Latin
- LatinPipe
- Universal Dependencies (UD)

The paper describes the LatinPipe system developed by the authors for joint dependency parsing and morphological analysis of Latin. It was the winning system at the EvaLatin 2024 shared task. The paper provides details on LatinPipe's architecture, training data, multi-treebank harmonization, ensembling techniques, and experimental results on Universal Dependencies treebanks and the EvaLatin test sets. So the key terms reflect this focus on dependency parsing of Latin, participation in the EvaLatin shared task, use of Universal Dependencies resources, and the LatinPipe system itself. The keywords listed at the end of the abstract capture the main topics well.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions harmonizing the annotation styles among the different Latin treebanks used for training. What specific differences in annotation style were observed between the original PROIEL treebank and the other Latin treebanks? How were these differences harmonized?

2. The paper compares multiple pre-trained language models like LaBerta, PhilBerta and XLM-RoBERTa. What are the key differences between these models in terms of training data and methodology? Why does ensembling these models lead to better performance? 

3. The method uses an initial pretraining stage with frozen Transformer weights before fine-tuning. What is the motivation behind this? How many epochs are used for this pretraining and what hyperparameters are used?

4. The parser incorporates two bidirectional LSTM layers on top of the Transformer encoder(s). What is the motivation for adding these LSTM layers? What input do they receive and what is their output used for? 

5. Gold universal part-of-speech (UPOS) tags are provided as input to the parser. How exactly are these incorporated into the model? What gains in performance are observed from the inclusion of UPOS tags?

6. The final submitted systems ensemble multiple instances of the model. How many models are ensembled? Are there any differences between the ensemble members or are they identically configured? What is the ensembling method used?

7. For training without the PROIEL treebank, artificial punctuation is added to the test data to mitigate domain shift issues. Why is this necessary and what impact does it have on parsing performance? 

8. The parser is trained on mini-batches sampled from the multiple treebanks. What sampling strategy is used? What impact does the multi-treebank training have on parsing accuracy, especially for smaller treebanks?

9. The model predicts both syntactic dependencies and morphological features. How are these two objectives incorporated into the model architecture? What parsers do the syntactic dependencies and morphology heads build upon?

10. What variations were explored for incorporating multiple pre-trained language models? What seems to work best - ensembling, concatenation of embeddings or a hybrid approach? Why?
