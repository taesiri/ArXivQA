# [Mixed-Integer Optimisation of Graph Neural Networks for Computer-Aided   Molecular Design](https://arxiv.org/abs/2312.01228)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Graph neural networks (GNNs) have shown promising results for modelling graph-structured data like molecules for computer aided molecular design (CAMD). 
- However, using GNNs for optimisation in CAMD poses challenges as typical optimisation methods like Bayesian optimisation and genetic algorithms cannot guarantee finding the global optimum.  
- Recent works have formulated neural networks with ReLU activations as mixed integer linear programs (MILPs), enabling optimisation to global optimality. But these works have focused only on standard multilayer perceptrons.

Proposed Solution:
- This paper proposes for the first time MILP and MINLP (mixed integer nonlinear programming) formulations for two types of trained graph neural networks - the Graph Convolutional Network (GCN) and the GraphSAGE network.

- For GCN, an MINLP formulation is proposed by linearising the components using big-M constraints and introducing support variables and constraints to handle the nonlinear terms involving the graph structure.

- For GraphSAGE, an MILP formulation is proposed by using big-M constraints to encode conditional sums that depend on the graph structure.

Contributions:
- MINLP formulation for the GCN network, enabling optimisation of GCNs to global optimality.

- MILP formulation for the GraphSAGE network, also enabling global optimisation for GraphSAGE models.

- Demonstration of the approach on a case study for optimising boiling points of molecules by modelling them with GCN and GraphSAGE networks and then optimising the MILP/MINLP formulations. The case study found molecules with optimal predicted boiling points, some matched real experimentally observed molecules.

So in summary, the paper proposes novel optimisation formulations for GNNs to enable their use in computer aided molecular design and other optimisation applications while guaranteeing global optimal solutions. The viability is shown on a case study for optimising boiling points.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The paper proposes mixed integer linear and non-linear programming formulations of graph neural networks for computer-aided molecular design, applies these to a case study of optimizing boiling points of small molecules, and finds promising performance in discovering feasible molecules compared to a genetic algorithm approach.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing mixed integer (non-)linear programming formulations of trained graph neural networks, specifically the Graph Convolutional Network (GCN) and GraphSAGE architectures. These formulations allow using the trained GNNs as surrogate models in optimization problems. In particular, the paper develops an MINLP formulation for GCN and an MILP formulation for GraphSAGE. The paper demonstrates the application of these formulations in a case study of optimizing boiling points of molecules for computer-aided molecular design. Some key outcomes are:

- An MINLP formulation for the commonly used GCN architecture
- An MILP formulation for the GraphSAGE architecture 
- Applying these formulations in a case study to optimize boiling points of molecules, where 12 out of 20 derived molecules were experimentally observed

In summary, the main contribution is developing MI(N)LP formulations of GCN and GraphSAGE neural networks to enable using them as surrogate models in optimization problems, with a case study application to molecular design.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper's content, some of the key terms and keywords associated with this paper include:

- Graph neural networks (GNNs)
- Mixed integer (non-)linear programming (MI(N)LP) 
- Graph Convolutional Networks (GCN)
- GraphSAGE
- Computer-aided molecular design (CAMD)
- Bound tightening techniques
- Surrogate models
- Optimization
- Molecular graphs
- Chemical property prediction
- Boiling points

The paper focuses on formulating graph neural networks, specifically GCN and GraphSAGE architectures, as mixed integer linear and nonlinear programming problems. This allows the trained GNNs to be embedded and solved to optimality for tasks like computer-aided molecular design. Key methods include developing MI(N)LP formulations of GCN and GraphSAGE and applying bound tightening techniques. A case study is presented using the formulations to optimize boiling points of molecular graphs. So the core focus is on optimization of GNNs and their application to chemical informatics problems.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. The paper proposes MILP/MINLP formulations for two graph neural network architectures: GCN and GraphSAGE. What are the key differences in how these two architectures aggregate neighborhood information and how does this impact the complexity of formulating them as optimization problems?

2. Bound tightening techniques like Feasibility Based Bound Tightening (FBBT) are used to compute tighter variable bounds and improve solving time. Explain how FBBT is adapted for the GCN and GraphSAGE formulations. What are the differences?  

3. The GraphSAGE MILP formulation introduces a large number of additional constraints compared to GCN, especially for deeper/wider networks. Analyze the order of growth of constraints and variables for both formulations and discuss the tradeoffs. 

4. While GCN is formulated as an MINLP and GraphSAGE as an MILP, the empirical results show GraphSAGE solving faster in most cases. Speculate on why this is the case, even though linear programs are typically easier to solve.

5. The paper finds 20 molecules through optimization of which 12 are experimentally observed. Discuss what additional constraints could be added to the formulation to restrict the search space to more feasible molecules.  

6. Both deterministic (MILP) and non-deterministic (GA) optimization methods are tested. Compare and contrast the strengths and limitations of these approaches for optimizing trained GNNs. When would you prefer one vs the other?

7. The mean absolute error of boiling point prediction is higher for the optimized molecules compared to the training data. Hypothesize potential reasons for why this might be happening.

8. The current formulations only scale to small molecules. Propose method(s) to potentially make the formulations more scalable to larger graph structures. What are the challenges?

9. Discuss the broader potential applications of MILP formulations for trained GNNs beyond the molecule optimization case study presented. What are some promising areas where this could have impact? 

10. The paper considers two common GNN architectures. Outline how you might approach formulating other categories of GNNs (e.g. attention-based, RNN-based etc.) as optimization problems. What are the challenges?
