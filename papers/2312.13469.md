# [Neural feels with neural fields: Visuo-tactile perception for in-hand   manipulation](https://arxiv.org/abs/2312.13469)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
To achieve dexterous manipulation of novel objects, robots need spatial awareness which requires estimating the pose and shape of objects while manipulating them in-hand. However, current methods for in-hand perception mostly track known objects using vision and avoid situations with occlusion. There is a need for a more generalizable approach that can perceive unknown objects and handle occlusion during manipulation.  

Proposed Solution - NeuralFeels:
The paper proposes NeuralFeels, a method that combines vision, touch sensing, and proprioception to estimate the pose and shape of unknown objects while manipulating them in-hand. The key ideas are:

1) Represent the object shape as a neural signed distance field (SDF) that is optimized online from multimodal sensory input during manipulation.

2) Track the pose of this neural SDF using a pose graph optimizer. 

3) Handle occlusion by incorporating touch sensing from multiple fingertip sensors. Touch provides local shape information when vision is occluded.

4) Use a proprioception-driven policy to rotate objects in-hand, generating rich visual and tactile data for perception.

Main Contributions:

1) First demonstration of full simultaneous localization and mapping (SLAM) with vision, touch and proprioception for dexterous in-hand manipulation.

2) Introduces a method to incorporate touch sensing directly into neural scene representations like Neural SDFs. 

3) Evaluates the role of touch in improving perception, especially in handling occlusion. Touch leads to low pose drift of 4.7mm and reconstructs object shape with 81% F-score.

4) Releases a multimodal dataset of 70 in-hand manipulation experiments in simulation and real-world for benchmarking visuo-tactile perception.

In summary, the paper presents NeuralFeels, a neural multimodal perception system for reconstructing and tracking novel objects manipulated in-hand. This is enabled by online optimization of a neural SDF with vision, touch and proprioception.
