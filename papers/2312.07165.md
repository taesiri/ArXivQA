# [Language-Guided Transformer for Federated Multi-Label Classification](https://arxiv.org/abs/2312.07165)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality summary paragraph of the key points from the paper:

This paper tackles the challenging problem of multi-label image classification under federated learning (FL) settings. Whereas standard FL methods perform poorly when transferred directly to multi-label tasks due to differing label distributions and relationships across clients, the authors propose a novel framework called FedLGT (Federated Language-Guided Transformer). FedLGT introduces two key components to address this issue. First, a Client-Aware Masked Label Embedding (CA-MLE) technique calibrates the self-attention masking during local client training based on the global model's predictions, allowing uncertain classes to be selectively focused on. Second, a Universal Label Embedding (ULE) derived from the CLIP text encoder provides pre-aligned label representations to avoid corrupted relationships after aggregation. Experiments demonstrate that FedLGT substantially boosts results on the large-scale FLAIR multi-label FL benchmark compared to baselines by effectively transferring knowledge between the global and local models to handle varying label correlations. The gains are especially pronounced in the challenging fine-grained classification case. Impact is also shown on centralized multi-label datasets adapted to FL settings. Overall, through language guidance and masking, FedLGT presents an effective solution to multi-label image classification in practical decentralized environments.
