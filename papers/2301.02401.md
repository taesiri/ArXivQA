# You Truly Understand What I Need: Intellectual and Friendly Dialogue   Agents grounding Knowledge and Persona

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research focus of this paper is developing an effective dialogue agent that can generate informative and engaging responses by grounding both external knowledge as well as the personal profile (persona) of the speakers. Specifically, the paper proposes a model called INFO that aims to address two limitations of prior work on knowledge-grounded and persona-grounded dialogue:1) Hallucination in responses when using only a generative model without grounding in external knowledge sources.2) Passive usage of personas when generating responses, leading to less engaging conversations. To address these issues, the INFO model incorporates the following key components:- Knowledge selector and persona selector modules implemented with a poly-encoder architecture to select the most relevant knowledge source and persona sentences to ground the response. - Retrieval augmented generation using a retriever module to retrieve relevant knowledge from an external index, which helps reduce hallucination.- Constructing a knowledge-persona enhanced query as input to the retriever by combining predicted knowledge, predicted personas and dialogue context.- Multi-task training to learn to select appropriate knowledge and personas as well as generate an informative and engaging response.The central hypothesis is that by jointly learning to ground both knowledge and personas during response generation, the INFO model can produce more human-like dialogue that is both knowledgeable and personalized, while reducing hallucination compared to purely generative models. The experiments aim to validate if INFO can outperform previous approaches on both automatic metrics and human evaluations of informativeness, engagingness and hallucination.


## What is the main contribution of this paper?

The main contribution of this paper is proposing an effective dialogue agent that grounds both external knowledge and persona information simultaneously to generate more knowledgeable and engaging responses. Specifically, the key contributions are:- Implementing knowledge selector and persona selector using poly-encoder architecture to better capture relevance between context and candidates for grounding.- Constructing a knowledge-persona enhanced query (KPEQ) with predicted sources and dialogue history as input to the retriever-augmented generator. This maintains consistency between grounding and generation.- Achieving state-of-the-art performance on automatic metrics for both grounding and generation tasks on the persona-knowledge chat dataset FoCus.- Demonstrating through human evaluation and examples that the model generates responses with less hallucination and more engagingness by properly utilizing knowledge and persona.- Comparing different candidate scoring modules like bi-encoder, cross-encoder, and showing poly-encoder's effectiveness. Also comparing the retriever to sparse and dense retrievers.In summary, the main contribution is proposing an interpretable and effective approach for knowledge and persona grounded dialogue that achieves strong performance while generating more human-like responses. The model grounds both knowledge and persona properly to produce informative yet engaging answers.
