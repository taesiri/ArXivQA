# [EfficientSCI: Densely Connected Network with Space-time Factorization   for Large-scale Video Snapshot Compressive Imaging](https://arxiv.org/abs/2305.10006)

## What is the central research question or hypothesis that this paper addresses?

 The central research question is how to develop an efficient deep learning based method for high quality video reconstruction from snapshot compressive measurements. 

The key points are:

- Video snapshot compressive imaging (SCI) uses a single 2D measurement to capture high-speed video frames. Efficient reconstruction algorithms are needed.

- Existing model-based methods are slow and produce poor quality. Learning-based methods have high complexity and cannot handle large-scale data. 

- This paper proposes an efficient end-to-end deep network called EfficientSCI using dense connections and space-time factorization for video SCI reconstruction.

- EfficientSCI establishes spatial-temporal correlation efficiently using convolution in space and Transformer in time.

- Experiments show EfficientSCI achieves state-of-the-art results and fast running speed. It can reconstruct UHD color video from a single measurement with PSNR above 32dB.

In summary, the central hypothesis is that an efficient deep network leveraging dense connections and space-time factorization can achieve high performance video SCI reconstruction with low complexity. The results validate this hypothesis and demonstrate the effectiveness of the proposed EfficientSCI network.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes a new deep learning network called EfficientSCI for video snapshot compressive imaging (SCI) reconstruction. The key innovations are using dense connections and space-time factorization within network modules to improve efficiency and performance.

2. It introduces two new network blocks:

- ResDNet block that uses hierarchical dense connections within a residual block to reduce model complexity while enhancing learning ability. 

- CFormer block that utilizes convolution in spatial domain and Transformer in temporal domain based on space-time factorization, to efficiently capture spatial-temporal correlations.

3. Extensive experiments show the proposed EfficientSCI method achieves state-of-the-art performance on both simulated and real video SCI datasets. Notably, it is the first demonstration of reconstructing UHD color video with high compression ratio using a single end-to-end deep network. 

4. The method has very high efficiency with fewer parameters and FLOPs compared to previous methods. It also has better real-time performance.

In summary, the key innovation is a highly efficient deep network architecture for high-quality video SCI reconstruction, with superior performance compared to prior arts. The efficiency enables reconstructing large-scale and high frame rate video data.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes an efficient end-to-end deep learning model called EfficientSCI that achieves state-of-the-art results for reconstructing high-quality video frames from compressed measurements in video snapshot compressive imaging by using dense connections and space-time factorization within residual blocks.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other research in video snapshot compressive imaging:

- It proposes a new deep learning architecture called EfficientSCI that achieves state-of-the-art performance for video reconstruction from compressive measurements. Many prior works have used deep learning, but this paper demonstrates superior results.

- It introduces two new components - the ResDNet block and CFormer block - that help improve model performance while reducing complexity. The design of these components draws inspiration from other work in CNNs and vision transformers, adapting them to this problem.

- The paper demonstrates reconstruction of ultra high-definition (UHD) color video at high compression ratios using a single end-to-end model. Prior deep learning methods have struggled with large-scale and high compression ratio data due to model complexity and memory constraints. This represents a significant advance.

- Extensive experiments and ablation studies are provided to analyze the proposed method. Comparisons to several state-of-the-art model-based and learning-based techniques demonstrate the advantages of this approach.

- The model efficiency and real-time performance are substantially improved compared to prior arts. This is enabled by the network design and could expand the applicability of these methods.

Overall, this paper makes several notable contributions that advance video compressive imaging research. The network design, performance improvements, and demonstrations on large-scale data move the state-of-the-art forward in this field.
