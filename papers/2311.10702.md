# [Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2](https://arxiv.org/abs/2311.10702)

## Summarize the paper in one sentence.

 The paper proposes enhancing language model adaptation with \modelname~2, a suite of \llama-2 models finetuned on an improved instruction dataset mixture and further trained with techniques like direct preference optimization, achieving state-of-the-art performance among open models.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the paper:

This paper introduces \modelname{} 2, a suite of improved instruction-tuned language models aimed at advancing research on adapting large language models to user preferences. The key components of \modelname{} 2 include: (1) \modelname-V2-mix, an improved data mixture for instruction tuning containing high-quality datasets; (2) \modelname{} 2 models, which are \llama{}-2 models finetuned on \modelname-V2-mix at sizes of 7B, 13B, and 70B parameters; (3) \modelname{} 2+DPO, versions of \modelname{} 2 models further trained with direct preference optimization (DPO) using human feedback data, including a 70B model representing the largest publicly released DPO-trained model; (4) \codemodelname{} 2, instruction-tuned \codellama{} models for improved coding abilities. Evaluations across diverse tasks show \modelname{} 2 models match or exceed GPT-3.5-turbo-0301 and achieve state-of-the-art results among open models in several benchmarks. The public release of all models, data, and code provides resources to facilitate future research on adapting large language models.
