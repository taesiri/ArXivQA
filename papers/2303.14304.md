# [Ensemble-based Blackbox Attacks on Dense Prediction](https://arxiv.org/abs/2303.14304)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is: 

How can we develop an effective approach for generating blackbox adversarial attacks against dense prediction models like object detectors and semantic segmentation networks?

Specifically, the paper proposes using an ensemble of surrogate models to craft adversarial examples that can transfer to unseen victim models, rather than relying on a single surrogate as done in prior work. The key ideas explored are:

1) Balancing the loss contributions from different surrogate models in the ensemble, since they may use very different losses. 

2) Optimizing the ensemble weights according to victim model feedback to further improve attack success.

The main hypothesis is that an ensemble-based approach with proper weighting and optimization can generate more effective blackbox attacks compared to methods based on single surrogate models. The experiments aim to validate this hypothesis and demonstrate the effectiveness of the proposed techniques.

In summary, this paper focuses on designing an ensemble-based framework to generate adversarial examples that can fool arbitrary blackbox models for dense prediction tasks like object detection and semantic segmentation, with a particular emphasis on improving targeted attacks.
