# [Do Language Models Care About Text Quality? Evaluating Web-Crawled   Corpora Across 11 Languages](https://arxiv.org/abs/2403.08693)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large web-crawled corpora like CC100, MaCoCu, mC4 and OSCAR play a vital role in training state-of-the-art language models. However, there has been little analysis on the quality of these corpora.  
- It is unclear how qualitative differences between these corpora actually impact downstream model performance when used for language model pretraining.

Methodology: 
- The authors perform both an intrinsic evaluation (human evaluation of sample texts) and an extrinsic evaluation (language model pretraining and downstream task performance) on the quality of web-crawled corpora.
- The evaluation covers 11 European languages across 4 major web-crawled corpora.  
- For intrinsic evaluation, professional linguists annotated sample paragraphs on quality criteria like well-formedness and publishability.  
- For extrinsic evaluation, XLM-R was pretrained on each corpus per language and evaluated on structured prediction (NER, POS) and language understanding (COPA, CommitmentBank) tasks.

Key Findings:
- Intrinsic: MaCoCu and OSCAR have highest quality based on human judgements, while mC4 has more non-textual or wrong language data.  
- Extrinsic: Surprisingly, CC100 achieves best downstream task performance instead of highest rated corpora from human evaluation. The qualitative differences did not directly impact model performance.
- Even when controlling for corpus size by early stopping, the human-annotated quality does not influence end results.

Main Conclusions:
- There are clear intrinsic differences between quality of web-crawled corpora based on human evaluation.  
- However, the quality does not seem to significantly influence the downstream performance of language models trained on them.
- So for language model pretraining, size seems far more important than qualitative subtle differences between web-crawled data sets.
