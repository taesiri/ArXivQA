# [TigerBot: An Open Multilingual Multitask LLM](https://arxiv.org/abs/2312.08688)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality one-paragraph summary of the key points from the paper:

The authors introduce TigerBot, a family of open-source large language models ranging from 7 billion to 180 billion parameters, built by pretraining from strong foundations like Llama and BLOOM models. The TigerBot models achieve state-of-the-art performance through careful data curation, advanced model training techniques, and computational optimizations. Thorough evaluations on major benchmarks demonstrate meaningful gains over prior models like Llama, especially for Chinese language understanding. The authors provide extensive details on their methods to promote open research, emphasizing democratized LLM development with cost-effectiveness. They also describe hands-on experiences applying TigerBot across diverse real-world use cases like long-form question answering, summarization, function calling APIs, search augmentation, game dialog systems, and intelligent hardware. Overall, this work pushes the frontier of large language model capabilities while exemplifying an open, economical, and practical approach to developing and deploying such models.
