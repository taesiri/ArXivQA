# [Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision](https://arxiv.org/abs/2403.09472)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
Current AI alignment methods rely on human supervision, limiting model capabilities to human levels. This raises the challenge of continuing to improve systems beyond human capabilities, which the authors term "scalable oversight." Specifically, can models be trained on easier tasks but still solve more complex problems without direct human supervision? The authors refer to this as "easy-to-hard generalization."

Proposed Solution:
The key insight is that evaluation is easier than generation. So the authors first train process-supervised reward models (PRMs) on easy problems to act as easy-to-hard evaluators. Then they use these PRMs to score solutions to harder problems, facilitating easy-to-hard generalization in generators via re-ranking sampled solutions or reinforcement learning.  

Contributions:
- Propose using PRMs as easy-to-hard evaluators to enable easy-to-hard generalization in generators beyond just prompting or supervised fine-tuning.
- Introduce Outcome & Process Reward Models (OPRMs) combining strengths of outcome and process supervision.
- Show PRM re-ranking substantially improves performance on harder problems, demonstrating better easy-to-hard generalization for evaluators over generators.  
- Demonstrate optimization of generators against PRM evaluators via RL outperforms training on full dataset, highlighting effectiveness of leveraging easy-to-hard evaluation.
- Achieve new SOTA on MATH dataset through easy-to-hard generalization, suggesting promising path to systems advancing beyond frontier of human supervision.

In summary, the paper makes both conceptual and empirical contributions in using easy-to-hard evaluators to unlock stronger easy-to-hard generalization in generators, enabling progress on complex tasks without direct human supervision.
