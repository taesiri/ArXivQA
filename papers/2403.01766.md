# [Improving Visual Perception of a Social Robot for Controlled and   In-the-wild Human-robot Interaction](https://arxiv.org/abs/2403.01766)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Social robots rely on visual perception to understand users and environments. Recent advancements in deep learning models have shown potential for enhancing robots' visual perception. However, the high computational demands of deep learning models compared to more efficient shallow learning models raise questions regarding their effects on real-world interactions and user experience. It is unclear how objective interaction performance and subjective user experience will be influenced when a social robot adopts a deep learning-based visual perception model.

Proposed Solution: 
The authors employed state-of-the-art human perception and tracking models to improve the visual perception capabilities of the Pepper social robot. They conducted a lab study and an in-the-wild study to evaluate this enhanced perception system for following a specific user with other people present. The visual perception framework establishes a client-server architecture to integrate advanced deep learning models while overcoming compatibility issues with Pepper's functions.

Main Contributions:
1) Implementation of an open-sourced visual perception framework for social robots using state-of-the-art human tracking models, demonstrated on the Pepper robot
2) Lab-based and in-the-wild evaluation showing improved performance by the proposed framework 
3) Demonstration that advanced deep learning models can enhance a social robot's visual perception and interaction capabilities
4) Analysis of different state-of-the-art trackers for robustness against occlusion and suitability for real-world deployments
5) Insights that improved objective robot performance does not directly translate to better subjective user experiences, highlighting areas for future HRI research

In summary, the paper proposed and evaluated a novel visual perception framework to enhance a social robot's capabilities of detecting, tracking and interacting with humans using state-of-the-art deep learning models. Both lab-based and in-the-wild studies demonstrated the potential of this approach.
