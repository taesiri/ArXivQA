# [AniFaceDrawing: Anime Portrait Exploration during Your Sketching](https://arxiv.org/abs/2306.07476)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is: How can AI be used to assist users in creating high-quality anime portraits from rough freehand sketches throughout the entire sketching process?Specifically, the paper focuses on developing an AI system that can take a sequence of incomplete freehand sketches as input, and generate corresponding high-quality anime portraits as guidance to match the sketches and assist the user in creating the portrait. The key challenges are:- Maintaining high quality anime portrait generation from very rough and incomplete sketches during early sketching stages due to the ill-posed nature of conditional image generation.- Achieving stroke-level matching between the input sketches and generated portraits throughout the sketching process.To address these challenges, the paper proposes a novel approach based on latent space exploration of StyleGAN using a two-stage training strategy and stroke-level disentanglement learning, without requiring additional paired data. Experiments and user studies demonstrate the proposed system can generate high-quality matched portraits to assist users in creating anime portraits from scratch.In summary, the core hypothesis is that by using the proposed latent space exploration and disentanglement learning approach, an AI system can achieve stroke-level matching to assist in anime portrait creation from freehand sketches throughout the drawing process. The paper aims to demonstrate this capability.


## What is the main contribution of this paper?

The main contribution of this paper is developing an AI system to assist users in creating high quality anime portraits from their freehand sketches. Specifically:- They propose a novel framework called "AniFaceDrawing" that can generate high quality anime portraits matching a user's sketch strokes throughout the entire drawing process. - They introduce the concept of "stroke-level disentanglement" which allows mapping sketch strokes to the corresponding parts of the anime portrait at a local level without needing semantic labels. This is achieved through a two-stage training strategy.- They simulate the drawing process on-the-fly during training to teach the system how sketches evolve from simple to complex. This allows it to handle progressive and incomplete sketches.- They conduct both qualitative and quantitative experiments to demonstrate the stability and effectiveness of the proposed method in generating high quality and locally matching anime portraits from rough sketches.- They validate the system through a user study, showing it can assist novice users in creating anime portraits following their intentions and improving their sketches.In summary, the key contribution is developing an end-to-end AI framework for interactive anime portrait drawing assistance that can generate high quality results matched to the user's sketch throughout the drawing process. The proposed "stroke-level disentanglement" concept and training strategy enables handling progressive rough sketches.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes AniFaceDrawing, an interactive AI system that assists users in creating anime portraits by generating high-quality matching guidance images from users' freehand sketches throughout the sketching process using latent space exploration of StyleGAN with unsupervised stroke-level disentanglement learning.


## How does this paper compare to other research in the same field?

Here are my thoughts on how this paper compares to other research in the field of sketch-based anime portrait generation:- This paper focuses specifically on assisting users to create anime portraits during the sketching process, by generating high-quality anime portraits that match the user's rough sketches throughout. This is a novel application that I am not aware has been explored before in the sketch-based image synthesis literature. Most prior work has focused on generating complete images from finished sketches.- The proposed method adopts a latent space exploration approach with StyleGAN, which is different from prior sketch-to-image (S2I) synthesis techniques. Rather than training an end-to-end model, this work matches strokes to disentangled attributes in StyleGAN's latent space through a two-stage training strategy. This allows leveraging an existing high-quality StyleGAN model.- A key contribution is the unsupervised "stroke-level disentanglement" training that aligns sketch strokes with structural attributes in the latent space, without needing semantic labels. This is a creative way to achieve the desired stroke-level control for sketch guidance.- The paper presents both qualitative and quantitative experiments to demonstrate the method's ability to generate high-quality, matching portraits from progressive sketch inputs. The user study also provides evidence that their system assists anime portrait creation.- Compared to recent GAN inversion approaches like pSp, this method seems to perform better for incomplete sketch inputs, likely due to the proposed training strategy. The comparisons to pSp in the paper help highlight these advantages.- The interactive interface for providing sketch guidance during drawing seems well designed. The different guidance modes are useful for creativity support. The interface aspects are not a core contribution but help enable an effective drawing assistance system.Overall, I think the idea of interactive anime portrait generation during sketching and the proposed training approach are novel contributions to the fields of sketch-based interfaces and image synthesis. The results demonstrate effectiveness for the stated aim of assisting anime portrait creation.


## What future research directions do the authors suggest?

The authors suggest several future research directions at the end of the paper:- Improving the matching of input sketches for hair: The current training strategy of treating hair as background limits the matching performance for hair. The authors suggest exploring new training strategies to improve hair matching.- Expanding the diversity of generated anime styles: Currently, the generated anime style is relatively constant as it depends on the pre-trained StyleGAN model. The authors suggest researching ways to extract more diverse anime styles from StyleGAN while maintaining control. - Expanding to more artistic styles like Ukiyo-e and painting: The current approach focuses on the anime style. The authors suggest expanding it to other artistic styles like Ukiyo-e and painting while preserving the stroke matching capability.- Reducing the computation time: The current response time after each stroke is around 1.65 seconds, which affects user experience. The authors suggest reducing the computation time to improve immersion.- Exploring new applications: The progressive sketch-based image generation approach could be explored for new applications beyond portrait drawing assistance.In summary, the main future directions are improving hair matching, expanding diversity of styles, reducing computation time, and exploring new applications based on the proposed progressive sketch-based image generation approach. The key is to maintain the stroke-level matching while improving quality and diversity.
