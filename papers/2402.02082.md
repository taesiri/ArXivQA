# [GliDe with a CaPE: A Low-Hassle Method to Accelerate Speculative   Decoding](https://arxiv.org/abs/2402.02082)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) suffer from high latency during inference due to their autoregressive nature, limiting their use for applications requiring real-time responses.  
- Speculative decoding has been proposed to accelerate LLM decoding by using a faster draft model to propose tokens that are then verified in parallel by the LLM. However, existing solutions are limited in improving the acceptance rate of proposed tokens.

Proposed Solution:
- Introduce \textsc{GliDe}, a draft model architecture that leverages the key-value (KV) cache from the target LLM's past computations to help generate proposal tokens that are more likely to be accepted. This is done via cross-attention layers in \textsc{GliDe}.
- Propose \textsc{CaPE} method to expand proposal sequences with additional candidate tokens at each position based on the draft model's confidence scores, further increasing acceptance chances.

Main Contributions:
- \textsc{GliDe} significantly improves acceptance rates over previous draft models, with over 19.9% average increase across benchmarks. It also reduces expected decoding latency.
- Adding \textsc{CaPE} proposal expansion brings further speedups, achieving up to 2.61x faster decoding over standard autoregressive decoding.
- Proposed methods are easy to implement and require low additional computational overhead.
- Extensive experiments demonstrate clear improvements in acceptance rates and walltime speedups using the proposed \textsc{GliDe} and \textsc{CaPE} techniques.
