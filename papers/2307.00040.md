# [DisCo: Disentangled Control for Referring Human Dance Generation in Real   World](https://arxiv.org/abs/2307.00040)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is:How can we generate realistic human dance images and videos that are faithful to a given reference image, generalizable to unseen subjects/poses/backgrounds, and composable from different image sources? The key challenges they aim to address are:- Maintaining fidelity and consistency of human appearance and background when altering the pose.- Generalizing to novel combinations of human subjects, poses, and backgrounds without needing human-specific fine-tuning. - Allowing flexible composition of seen or unseen elements (subjects, poses, backgrounds) sourced from different images.To tackle these challenges, the authors propose a new framework called DisCo with two key components:1) A model architecture with disentangled control of human foreground, background, and pose to improve faithfulness and compositionality. 2) A human attribute pre-training strategy to enhance generalizability by learning diverse human attributes from large-scale human image datasets.In summary, the main hypothesis is that by disentangling control and leveraging diverse human pre-training data, their proposed DisCo framework can generate realistic and controllable human dance content that is faithful, generalizable, and composable. The experiments aim to demonstrate DisCo's abilities on these fronts compared to prior arts.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It defines a new problem setting called "referring human dance generation", which focuses on synthesizing realistic human dance images/videos with controllable attributes like human subject, background, and pose. This is motivated by real-world applications like user-specific short video generation.2. It proposes a novel framework called DisCo to address this problem. DisCo has two key components:(a) A model architecture with disentangled control of human foreground, background, and pose. This is designed to ensure faithfulness and compositionality in the generated content. (b) A human attribute pre-training strategy to improve generalization to unseen human subjects. This avoids the need for subject-specific fine-tuning.3. It provides extensive experiments on human image editing and dance video generation tasks to demonstrate DisCo's effectiveness. The results show DisCo can generate high quality and controllable human-centric content while generalizing well to novel combinations of human subjects, backgrounds, and poses.In summary, the main contribution is proposing the DisCo framework to enable controllable and realistic referring human dance generation, which could facilitate applications like image/video editing and content creation. The disentangled control architecture and human attribute pre-training are key innovations to achieving faithfulness, compositionality and generalizability.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other related work in controllable image/video generation:- Compared to other diffusion models for text-to-image/video generation (e.g. DALL-E 2, Imagen, Make-A-Video), this paper focuses more on precise control over human appearance, background, and pose in a dance setting. The proposed DisCo model aims for better faithfulness, generalizability, and compositionality.- For human dance synthesis, previous work relied on video-to-video transfer, still image animation, or motion transfer methods. These often require person-specific fine-tuning or cascaded training stages. DisCo simplifies training with a unified model and pre-training strategy. - DisCo builds upon recent advances like Stable Diffusion and ControlNet for controllable generation. The key novelty is the disentangled control mechanism and human attribute pre-training. This enables better adaptation to unseen combinations of subjects, backgrounds, and poses.- Compared to the most related DreamPose model, DisCo shows substantially better quantitative scores and qualitative results on real-world dance synthesis. This highlights the benefits of the proposed approach for faithful and generalizable human-centric generation.- The problem formulation of "referring human dance generation" is new and focused on practical applications. DisCo represents an advance towards controllable generation of real-world content, whereas much prior work used cleaner datasets.In summary, DisCo makes notable research contributions in controllable human image/video generation, introducing architectural innovations for disentangled control and compositional generalization. The evaluations demonstrate state-of-the-art results on challenging real-world dance synthesis.
