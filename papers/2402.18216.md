# [LLM Task Interference: An Initial Study on the Impact of Task-Switch in   Conversational History](https://arxiv.org/abs/2402.18216)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Recent large language models (LLMs) are being used in conversational AI systems and can perform well when conditioned on full conversational history. 
- However, performance can degrade when there is a "task switch" in the conversation, i.e. switching from one task to a completely different one.
- This sensitivity to task switches has not been formally studied before. 

Proposed Solution
- The authors introduce the concept of "task switch" in conversations and propose a metric called "task-switch sensitivity" to quantify the extent of performance degradation when switching tasks.
- They conduct experiments with multiple LLMs by simulating conversations with a task switch and measure the change in performance relative to zero-shot.
- They also analyze the underlying dynamics like change in probability of responses that influences the overall performance change.

Key Contributions 
- Formalizes the problem of performance degradation in LLMs due to task switches in conversational history.
- Presented extensive analysis on impact of task switches for multiple models across diverse tasks.
- Proposed a metric to quantify the sensitivity of models to various task switches.  
- Found that both large 175B and small 7B models can be susceptible to performance drops from task switching.
- Showed different models are impacted differently by different types of task switches.

In summary, this paper makes the first attempt at studying task interference issues in conversational LLMs and provides both analysis and metrics that are valuable for developing more robust models.
