# [Saliency-Aware Automatic Buddhas Statue Recognition](https://arxiv.org/abs/2402.16980)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Buddha statue recognition is important for understanding culture/history but is difficult and costly even for experts
- Convolutional neural networks (CNNs) are good for visual tasks but suffer from class imbalance problems

Proposed Solution:
- Develop an end-to-end automatic Buddha statue recognition model using saliency map sampling
- Propose a Grid-Wise Local Self-Attention Module (GLSA) to provide extra salient visual features 
- GLSA module uses depth-separable convolutions and self-attention to enhance salient regions
- Model has two branches - one for salient features from GLSA, one for global features
- Branches are concatenated and fed to classifier 

Contributions:
- GLSA module to enhance and magnify salient visual features
- Saliency-guided sampling to improve classification performance:
  - GLSA extracts salient regions
  - Regions are fed to CNN branch to get salient embeddings
  - Combined with global embeddings from second branch

Results:
- Evaluated on Buddha statue dataset with 6 categories
- Proposed model outperforms ResNet, ResNext, EfficientNet baselines
- Achieves 4.63% higher top-1 accuracy on average
- Only marginal increase in computations (MUL-ADD)
- Handles class imbalance better than single branch CNNs

In summary, the paper develops a novel dual-branch model with saliency sampling to improve Buddha statue recognition. The GLSA module provides extra salient features to help address class imbalance issues in CNNs.
