# [Deciphering 'What' and 'Where' Visual Pathways from Spectral Clustering   of Layer-Distributed Neural Representations](https://arxiv.org/abs/2312.06716)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Interpreting and repurposing deep neural networks is challenging due to the distributed nature of information within them. It is unclear where relevant information is stored and how to extract it.
- Existing interpretation methods are limited in scope, being task-specific or only analyzing small parts of a network. 

Proposed Solution:
- The paper introduces a new analysis approach inspired by spectral clustering. It forms a collection of affinity matrices from attention layers across the whole network. 
- An optimization problem is formulated to find pseudo-eigenvectors that best satisfy spectral partitioning objectives averaged across affinity matrices.
- This allows interpreting the network's internal feature grouping behavior without needing to guess where information is stored.
- The method scales to dataset-level analysis by using gradient optimization instead of standard eigen-solvers. 

Key Contributions:
- The introduced analysis approach works across various models like CLIP, Stable Diffusion etc. without modification and outperforms baselines.
- It enables training-free extraction of semantic segmentation from generative models on par with state-of-the-art contrastive methods. 
- Analysis provides new insight - key/query vectors in Transformers coordinate spatial information ('where' pathway) while value vectors handle semantics ('what' pathway).
- The global analysis technique motivates further work on dataset-level interpretation tools to peer inside neural networks.

In summary, the paper introduces a novel spectral-clustering based analysis approach that works across neural network layers. It allows superior training-free segmentation and reveals a 'what/where' pathway split in vision Transformers. The global analysis technique holds promise for better interpretability of large deep learning models.
