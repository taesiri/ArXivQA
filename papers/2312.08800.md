# [Evaluating Large Language Models for Health-related Queries with   Presuppositions](https://arxiv.org/abs/2312.08800)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper evaluates the factual accuracy and consistency of large language models (LLMs) like InstructGPT, ChatGPT, and BingChat when answering health-related queries that contain varying degrees of presuppositions. The authors source a set of 1,779 verified health claims, pose them as questions to LLMs, and check if the LLM responses agree or disagree with claims using an entailment model. They find that while models rarely contradict true claims, they often fail to refute false ones - InstructGPT agrees with 32% of false claims, ChatGPT 26%, and BingChat 23%. As presuppositions in queries increase, agreements with claims also increase regardless of veracity, especially for InstructGPT and ChatGPT. When demands presume falsehoods and request evidence to support them, InstructGPT agrees 76% of the time, ChatGPT 62%, and BingChat 28%. Overall accuracy is low and consistency across presupposition levels is poor. The authors conclude that the inability of models to reliably correct false assumptions calls for careful assessment before deployment in high stakes scenarios like healthcare.
