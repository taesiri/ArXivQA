# [SelfAugment: Automatic Augmentation Policies for Self-Supervised   Learning](https://arxiv.org/abs/2009.07724)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper aims to address is: How can we evaluate self-supervised representation learning models and select effective data augmentation policies when labeled data is not available?The key hypotheses are:1) A self-supervised image rotation prediction task can serve as an effective proxy for evaluating representations learned via self-supervised contrastive learning, without requiring labels.2) Optimization algorithms can leverage this self-supervised evaluation to automatically select good augmentation policies for contrastive representation learning.In summary, the paper investigates using rotation prediction as an unsupervised way to evaluate and guide data augmentation selection for self-supervised learning. This removes the need for labeled data during unsupervised training.


## What is the main contribution of this paper?

The main contribution of this paper is presenting a fully unsupervised method for evaluating and selecting data augmentation policies for self-supervised learning. The key points are:- They show that a self-supervised image rotation prediction task is highly correlated (Spearman rank correlation > 0.94) with standard supervised evaluations across datasets, tasks, architectures, and augmentation policies. This allows rotation prediction to be used as an evaluation metric without requiring labels.- Using rotation prediction, they adapt two data augmentation selection algorithms from the supervised domain (RandAugment and Fast AutoAugment) to work in a fully unsupervised manner. - Their unsupervised "SelfAugment" method finds augmentation policies that match or exceed the performance of policies found by exhaustive supervised search, while using a fraction of the compute time.- They demonstrate the effectiveness of SelfAugment across CIFAR-10, SVHN, ImageNet, Pascal VOC, COCO, and Places datasets on linear classification, detection, segmentation, and few-shot transfer tasks.In summary, the key contribution is presenting an unsupervised pipeline for representation learning that removes the need for labels during training, evaluation, and augmentation policy selection. This could enable more effective self-supervised learning when labels are unavailable.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes SelfAugment, an unsupervised approach to automatically learn data augmentation policies for self-supervised representation learning that is as effective as policies learned with supervised data.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper on self-supervised learning compares to other related work:- It proposes using a self-supervised image rotation prediction task for evaluating representations, rather than relying on labeled data. This allows the method to be fully unsupervised. Other recent self-supervised methods like SimCLR and MoCo rely on labeled data for evaluation.- The paper shows the rotation prediction evaluation has a very high correlation (Spearman rho > 0.94) with standard supervised evaluations across many datasets and tasks. This helps validate rotation prediction as a proxy for measuring representation quality without labels.- The proposed SelfAugment and SelfRandAugment algorithms can automatically learn augmentation policies for self-supervised learning without any labeled data. They are adapted from recent supervised augmentation learning methods like Fast AutoAugment.- Experiments show SelfAugment and SelfRandAugment find competitive policies compared to hand-designed and supervised-learned policies from prior work. The learned policies even outperform on some datasets like SVHN.- The paper demonstrates the utility of self-supervised evaluation and augmentation learning across various architectures like ResNet, datasets like CIFAR and ImageNet, and transfer tasks. This shows the general applicability of the methods.Overall, a key contribution is developing a fully unsupervised pipeline for representation learning and augmentation policy search. The results validate that self-supervised evaluation like rotation prediction can act as an effective proxy for standard supervised evaluation in many cases. This helps remove the reliance on labeled data.


## What future research directions do the authors suggest?

Some of the key future research directions suggested by the authors include:- Studying the trade-offs between image invariances and self-supervised evaluations. For example, rotation evaluation will not work well for rotation-invariant images like textures. Similarly, color prediction will not work for black-and-white images. The authors suggest investigating which self-supervised evaluation tasks are best suited for different types of image datasets.- Improving the augmentation policy search algorithm. The authors suggest exploring different weightings for the rotation prediction loss and contrastive loss when using the minimax objective for augmentation search. This could potentially lead to better performing augmentation policies.- Using established augmentation policies like MoCoV2 as the base policy. The authors show that using MoCoV2 augmentations as the base and then minimizing rotation loss finds better CIFAR-10 policies than the full SelfAugment pipeline. This is worth exploring further as a way to improve on strong baseline augmentations.- Applying SelfAugment to new domains like medical imaging, satellite imagery, etc. The authors demonstrate SelfAugment on common computer vision datasets, but it could be useful for unlabeled datasets from other domains. Exploring this is an area for future work.- Combining multiple self-supervised losses for augmentation search. The authors mainly use rotation prediction but suggest combining it with other self-supervised losses like jigsaw puzzle solving when possible.- Developing better proxy tasks for self-evaluation. The authors show rotation prediction works well but suggest investigating other proxy tasks that could work for rotation-invariant images.In summary, key future directions are improving the search algorithm, applying it to new domains, combining self-supervised tasks, and developing better proxy evaluation tasks. The overall goal is to make SelfAugment more robust and widely applicable as an unsupervised augmentation selection method.


## Summarize the paper in one paragraph.

The paper presents SelfAugment, an unsupervised algorithm to automatically select data augmentation policies for self-supervised learning. Current self-supervised methods often rely on labeled data to select augmentations via supervised evaluation of the learned representations. However, labeled data is not always available. SelfAugment instead uses a self-supervised image rotation prediction task to evaluate representations. Through experiments on CIFAR-10, SVHN, ImageNet and transfer tasks, the authors show image rotation prediction has a high correlation (rho>0.94) with standard supervised evaluations like linear separability. Using this as a proxy, SelfAugment can efficiently search over augmentation policies without labels. The discovered policies match or exceed the performance of those found via extensive supervised evaluation, demonstrating the efficacy of self-supervised evaluation for representation learning.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:This paper studies how to evaluate and select data augmentation policies for self-supervised learning when labeled data is not available. The authors first show that linear self-supervised rotation prediction is highly correlated with supervised downstream performance across datasets, tasks, architectures, and augmentation policies. This enables unsupervised evaluation of learned representations. The authors then propose two algorithms, SelfRandAugment and SelfAugment, that adapt prior automatic augmentation techniques to use rotation prediction instead of supervised accuracy for augmentation selection. These methods find competitive augmentation policies without requiring any labeled data. The key findings are: (1) Self-supervised rotation prediction provides a strong proxy for supervised evaluation of representations when labeled data is unavailable. (2) Using rotation prediction, the proposed SelfAugment and SelfRandAugment methods obtain augmentation policies that match or exceed the performance of policies found with extensive supervised search. For example, SelfAugment matches the supervised MoCoV2 policy on ImageNet and outperforms it on CIFAR-10 and SVHN. (3) Without supervision, the proposed methods obtain these results with substantially lower computational cost than exhaustive supervised search. Overall, this work provides an effective approach for unsupervised learning and evaluation of representations and data augmentations.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in this paper:This paper proposes SelfAugment, an unsupervised approach for automatically learning data augmentation policies for self-supervised learning methods like MoCo. The key idea is to use a self-supervised linear evaluation task, specifically predicting the rotation of an image among 4 orientations, to evaluate learned representations and guide the search for better augmentations. The paper first shows that rotation prediction accuracy is highly correlated with downstream supervised performance across models, architectures, and tasks. Then it adapts two data augmentation search algorithms, RandAugment and Fast AutoAugment, to work in a self-supervised manner by substituting rotation prediction in place of a supervised loss function. This allows efficiently searching for augmentations tailored to self-supervised MoCo training, without needing any labeled data. Experiments show the learned policies match or exceed those found with exhaustive supervision, demonstrating SelfAugment is an effective approach for unsupervised augmentation learning.
