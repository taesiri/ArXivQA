# [SoD$^2$: Statically Optimizing Dynamic Deep Neural Network](https://arxiv.org/abs/2403.00176)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper addresses the challenge of optimizing dynamic deep neural networks (DNNs), where tensor shapes, sizes, and even the operators used can vary depending on the input. Such dynamism makes many existing optimizations like operator fusion and memory optimization difficult. The paper argues that most prior works either use static solutions incurring high overhead or runtime solutions that are expensive.

Solution:
The key idea is to classify DNN operators based on how the output shape relates to the input, leading to 4 types:
1) Input Shape Determined Output 
2) Input Shape Determined Output Shape  
3) Input Shape & Value Determined Output Shape
4) Execution Determined Output

Using this, the paper develops a dataflow analysis called Rank and Dimension Propagation (RDP) to infer shapes of tensors, even symbolically. RDP considers both forward and backward analysis iteratively.  

Then, leveraging RDP, the paper presents several optimizations:
1) Operator fusion 
2) Static execution order planning using graph partitioning and RDP information
3) Runtime memory allocation plan generation starting from peak memory locations 
4) Multi-version code generation for hotspot operators based on common shapes

Contributions:
- Comprehensive DNN operator dynamism classification
- Novel static analysis (RDP) to propagate shapes in dynamic DNNs  
- Set of optimizations like fusion, execution planning, memory planning and multi-version code generation enabled by RDP
- Extensive evaluation on 10 emerging dynamic DNNs showing up to 88% memory savings and 3.9x speedup over state-of-the-art frameworks

The techniques offer promise for optimizing inference across devices from data centers to mobile devices, especially in single-input scenarios. Future work includes handling dynamism in batched inference on GPUs and integration with model compression techniques for large language models.
