# [Prototype Based Classification from Hierarchy to Fairness](https://arxiv.org/abs/2205.13997v1)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to design a neural network architecture that can flexibly learn different types of concept relationships, such as those required for fair classification or hierarchical classification. 

The key hypothesis is that a single neural network model, called a Concept Subspace Network (CSN), can be adapted to learn a spectrum of concept relationships by controlling the alignment between different sets of prototypes that define concept subspaces. The paper shows that CSNs can match performance of specialized models for fair classification or hierarchical classification by learning orthogonal or parallel subspaces, respectively. Furthermore, CSNs can learn multiple types of concept relationships simultaneously within a single model.

The main contributions are:

- Proposing CSNs, a new neural network architecture that uses prototype-based representations to define concept subspaces 

- Showing CSNs can learn orthogonal subspaces for fair classification and parallel subspaces for hierarchical classification

- Demonstrating CSNs match performance of state-of-the-art specialized models on fair and hierarchical classification tasks

- Illustrating how a single CSN can enforce both fairness and hierarchy constraints by controlling alignment of different concept subspaces

The central hypothesis is that by controlling alignment between concept subspaces, a single flexible model architecture like CSN can learn the diverse concept relationships required for different applications.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution appears to be a new neural network architecture called the Concept Subspace Network (CSN). The key aspects of the CSN are:

- It uses sets of trainable prototypes to define concept subspaces in the neural network's latent space. This builds on prior work on prototype-based classifiers for interpretability.

- It supports multiple sets of prototypes, allowing it to simultaneously learn multiple concepts/classification tasks. 

- It uses a measure of concept subspace alignment to control the relationships between different concepts, such as independence or hierarchy.

- This allows the CSN to achieve state-of-the-art performance on tasks like fair classification (by enforcing independence of concepts) and hierarchical classification (by encouraging concept alignment). 

- Moreover, a single CSN can reconcile multiple constraints like fairness and hierarchy within one model, as demonstrated on a human motion prediction task.

In summary, the main contribution appears to be the proposal of the CSN architecture that unifies and generalizes various specialized classifiers using the notions of concept subspaces and subspace alignment. The results demonstrate the flexibility of CSNs to learn different types of concept relationships for tasks ranging from fairness to hierarchies within a single framework.
