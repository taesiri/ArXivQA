# Maieutic Prompting: Logically Consistent Reasoning with Recursive   Explanations

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is that prompting large language models (LMs) to recursively generate explanations can lead to more logically consistent reasoning, even if the individual explanations are noisy or unreliable. Specifically, the paper proposes a method called "Maieutic Prompting" which generates a tree structure of explanations in an abductive and recursive manner. It then models the logical relationships between these explanations and uses a symbolic inference algorithm (MAX-SAT) to find the optimal truth value assignments that maximize consistency. The key idea is that by generating many layered explanations in a tree structure and modeling their logical relations, the approach can infer the correct answer even if some of the individual explanations are incorrect. This allows it to overcome the limitation that LMs often generate logically inconsistent or unreliable explanations when prompted for a single explanation.So in summary, the central hypothesis is that recursive, structured explanation generation combined with symbolic logical inference can substantially improve logical consistency in LM reasoning, despite the inherent unreliability of individual model-generated explanations. The experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

Based on my reading, the main contribution of this paper is proposing a new method called Maieutic Prompting to improve the logical consistency and reasoning capability of large language models (LMs) through recursively generating and resolving explanatory statements. Specifically, the key ideas and contributions are:- Proposes a novel inference method called Maieutic Prompting that generates a tree structure of explanatory statements (abductively for both possible answers and recursively to validate the explanations) for a given question, defines logical relationships between them, and uses a MAX-SAT solver to find the best consistent assignments.- Aims to improve logical reasoning consistency of LMs by modeling and resolving relationships between possibly noisy or contradictory explanatory statements.- Achieves significantly better accuracy (up to 20% higher) compared to prior prompting methods on commonsense reasoning benchmarks while being competitive with supervised models.- Shows improved robustness against semantic perturbations and across different prompt examples/orders compared to other prompting methods.- Provides an interpretable framework to understand the model's reasoning process through the generated explanatory statements and their logical relationships.- Introduces the concepts of logical integrity and maieutic tree to recursively elicit, validate and relate the knowledge from language models.Overall, the key novelty is in developing a framework to recursively generate explanatory statements in a tree structure, model logical relationships between them, and infer consistent answers, which improves reasoning capability of LMs in an unsupervised manner. The paper demonstrates the effectiveness of this method empirically on reasoning tasks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new method called Maieutic Prompting that generates a tree of recursive explanations from a language model to logically reason about the answer to a question, framing it as a satisfiability problem to infer consistent truth values.
