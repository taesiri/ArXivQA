# Maieutic Prompting: Logically Consistent Reasoning with Recursive   Explanations

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is that prompting large language models (LMs) to recursively generate explanations can lead to more logically consistent reasoning, even if the individual explanations are noisy or unreliable. Specifically, the paper proposes a method called "Maieutic Prompting" which generates a tree structure of explanations in an abductive and recursive manner. It then models the logical relationships between these explanations and uses a symbolic inference algorithm (MAX-SAT) to find the optimal truth value assignments that maximize consistency. The key idea is that by generating many layered explanations in a tree structure and modeling their logical relations, the approach can infer the correct answer even if some of the individual explanations are incorrect. This allows it to overcome the limitation that LMs often generate logically inconsistent or unreliable explanations when prompted for a single explanation.So in summary, the central hypothesis is that recursive, structured explanation generation combined with symbolic logical inference can substantially improve logical consistency in LM reasoning, despite the inherent unreliability of individual model-generated explanations. The experiments aim to validate this hypothesis.
