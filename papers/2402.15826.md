# [Reward Design for Justifiable Sequential Decision-Making](https://arxiv.org/abs/2402.15826)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper addresses the challenge of designing reward functions for reinforcement learning (RL) agents that incentivize the agents to not only carry out a given task, but also justify the decisions they make with supporting evidence. This is important for accountable and transparent decision-making, especially in high-stakes domains like healthcare. However, specifying rewards that achieve this is difficult.

Proposed Solution: 
The paper proposes using a debate-based reward model to quantify the justifiability of an RL agent's decisions. In this model, the reward comes from a two-player zero-sum debate game between argumentative agents. One agent argues for the RL agent's decision using supporting evidence, while the other argues for an alternative decision. A proxy of a human judge then evaluates which decision was better justified based on the evidence presented. The outcome of this debate game is used to shape the rewards for the RL agent, called the "justifiable" agent.

Specifically, the justifiable agent's actions are compared to a baseline agent's actions. If the judge prefers the justifiable agent's action based on the debate, a positive reward is given. This incentivizes the justifiable agent to take not only good decisions for the task, but also ones that are more easily justified.

The key components enabling this framework are: (1) a proxy judge model trained on human preferences to evaluate decisions; (2) contextualized argumentative agents that can argue different instances of the debate game; (3) mixing the debate reward with the environment reward to optimize policy performance and justifiability.

Contributions:
The main contributions are:

(i) Formalizing the problem of justifiable sequential decision-making and using debate games to model the justifiability reward.

(ii) Providing a method to learn a proxy judge from human preferences that can evaluate decisions using limited evidence.

(iii) An approach to learn contextualized argumentative agents that can solve debate game instances.

(iv) Demonstrating the framework's effectiveness in learning policies for treating sepsis patients that are preferred by the judge over a baseline, with limited performance loss. Also testing properties like robustness of argumentative agents.

In summary, the paper makes a novel connection between debate games and interpretable reward design for RL, enabled through key algorithmic components. It shows promising results on a healthcare task, substantiating the framework's practical promise.
