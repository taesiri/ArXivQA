# Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation
  Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we build a system that combines ChatGPT and visual foundation models to enable conversational interactions involving both language and visuals?The key ideas and contributions towards this goal appear to be:- Proposing Visual ChatGPT, a system that incorporates different visual foundation models (VFMs) to allow users to interact with ChatGPT using images in addition to text.- Designing a Prompt Manager module to convert visual signals into language so ChatGPT can understand and leverage the VFMs. This involves defining prompts for system principles, VFMs, user queries, and VFM outputs. - Demonstrating how Visual ChatGPT can accomplish complex visual tasks like image generation, editing, and QA through collaboratively invoking multiple VFMs in a logical chain, guided by the prompts from the Prompt Manager.- Conducting experiments on a variety of visual tasks to showcase the capabilities enabled by combining ChatGPT and VFMs through the proposed system.So in summary, the central hypothesis is that by designing appropriate prompts and chaining of VFMs, ChatGPT can be augmented to handle conversational interactions involving visuals in addition to just text. The Visual ChatGPT system is proposed and evaluated to demonstrate this hypothesis.


## What is the main contribution of this paper?

The main contribution of this paper appears to be proposing Visual ChatGPT, a system that combines ChatGPT with various visual foundation models (VFMs) to enable conversational interaction involving both text and images. Specifically, the key contributions are:- Proposing the architecture for Visual ChatGPT that integrates ChatGPT with multiple VFMs using a Prompt Manager module.- Designing the Prompt Manager to convert visual signals into language so ChatGPT can understand and leverage the VFMs. This includes managing system principles, foundation models, user queries, and model outputs.- Defining prompts to specify VFM capabilities, inputs/outputs, usage scenarios, etc. to guide ChatGPT on when and how to use them. - Supporting complex visual tasks that require collaborations between multiple VFMs in a multi-step chain-of-thought process.- Conducting extensive experiments to validate Visual ChatGPT's ability to understand and generate visual content through conversational interactions. In summary, the key contribution is developing a framework and methodology to combine the conversational capabilities of ChatGPT with the visual competencies of diverse VFMs, enabling richer human-AI interaction involving both text and images.
