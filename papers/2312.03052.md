# [Visual Program Distillation: Distilling Tools and Programmatic Reasoning   into Vision-Language Models](https://arxiv.org/abs/2312.03052)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Visual Program Distillation: Distilling Tools and Programmatic Reasoning into Vision-Language Models":

Problem:
- Vision-language models (VLMs) still struggle with complex visual reasoning tasks like counting, understanding spatial relationships, and reasoning compositionally. 
- Although generating explicit programs with language models can solve such tasks, this approach is error-prone, computationally expensive, and achieves lower accuracy than end-to-end models.
- Existing methods for distilling instruction-following abilities from language models into VLMs rely only on image captions, which lack detailed visual information.

Proposed Solution: 
- The paper proposes Visual Program Distillation (VPD), a novel distillation method to induce complex reasoning capabilities from language models into VLMs.

Key Ideas:
- VPD leverages recent advances in program synthesis to generate candidate programs that solve a visual task using specialized vision tools. 
- It executes the programs to select only the ones that yield the correct solution.
- It then converts the execution traces into natural language chain-of-thought instructions.
- Finally, it distills these instructions into the VLM using step-by-step distillation.

Main Contributions:
- VPD combines the reasoning power of program synthesis with the efficiency of end-to-end VLMs through distillation.
- Experiments show VPD sets new SOTA on 8 VQA tasks and 2 zero-shot benchmarks, outperforming all prior VLMs.
- VPD also improves model quality - human evaluation confirms it produces more accurate, consistent and interpretable rationales.
- VPD helps quickly adapt models to new domains, establishing SOTA on Hateful Memes even without any labels.

In summary, VPD advances the state-of-the-art in complex visual reasoning for VLMs by distilling executable programs, unlocking abilities like counting, spatial relations, and compositionality. The gains span across accuracy, robustness, interpretability and adaptability.
