# [Forging Tokens for Improved Storage-efficient Training](https://arxiv.org/abs/2312.10105)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Recent advances in deep neural networks (DNNs) have significantly improved performance across computer vision tasks. However, training highly accurate and robust vision models requires extensive datasets, leading to large storage requirements. This poses a critical bottleneck when scaling up vision models. An alternative is to use discrete representations like vectors quantized (VQ) tokens instead of images as model inputs for efficient storage. However, applying existing image-based data augmentations to tokens faces challenges due to input domain shift between continuous pixel values and discrete tokens.

Proposed Solution: 
The paper introduces two token-based data augmentation strategies - TokenAdapt and ColorAdapt. TokenAdapt transforms tokens to an augmentation-compatible space, applies pixel-based augmentations, and reverts back to original token space. This allows reusing existing augmentation policies without model fine-tuning. ColorAdapt adapts AdaIN for token color augmentation to introduce variations while preserving structure.  

Main Contributions:
- Identify limitations of directly applying pixel-based augmentations to tokens
- Propose TokenAdapt to transform tokens for compatibility with pixel augmentations 
- Introduce ColorAdapt for color augmentation of tokens while retaining structure
- Achieve 70% ImageNet accuracy using just 1% pixel storage via proposed augmentation strategies 
- Show consistent improvements across tasks like efficiency, fine-grained classification, robustness and segmentation
- Demonstrate wide applicability across tokenizers and input formats like DCT coefficients

In summary, this paper tackles the problem of inefficient data augmentation for token-based vision models via TokenAdapt and ColorAdapt. It highlights their effectiveness across multiple scenarios, overcoming storage and robustness limitations to advance scalable vision model development.
