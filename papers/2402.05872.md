# [You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for   Semantic and Property Prediction](https://arxiv.org/abs/2402.05872)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Semantic segmentation methods rely heavily on training data and often produce inconsistent predictions from different viewpoints/lighting. Estimating physical properties from these semantics is also challenging.
- Existing methods condition property estimates on semantic classes, but this conditioning is static and cannot be updated at runtime. The conditioning is also one-way, from semantics to properties.
- There is a need for a method to jointly estimate semantics and properties in a probabilistic way, allowing bidirectional conditioning and runtime updates with new measurements.

Proposed Solution:
- Introduce a probabilistic model to jointly represent semantic class predictions and physical properties using conjugate distributions (Dirichlet-Categorical and Dirichlet-Normal-Gamma).
- Leverage vision to do semantic segmentation and map building to initialize semantics and predict properties.
- Use tactile sensing to get property measurements, then update property belief and also update semantic beliefs using Bayesian inference in closed form.

Key Contributions:
- Novel joint probabilistic representation for semantics and properties enabling closed-form multi-modal Bayesian updates at runtime without retraining.
- Demonstrate semantic prediction accuracy improves by 21.3% on average in simulation by using property measurements to correct visual semantics.
- Show method can update friction estimate for challenging legged robot traversal task, enabling adaptive gaits, unlike state-of-the-art vision-only traversability methods.
- Also show method can model affordance properties for tasks like opening doors with unknown interactions.
- Provide open source implementation and hardware demonstration videos.

In summary, the key novelty is in the joint semantic-property probabilistic model and multi-modal Bayesian updates it enables. This provides more accurate predictions and task-focused property estimates that can be updated at runtime to change robot behavior appropriately.
