# Robots That Ask For Help: Uncertainty Alignment for Large Language Model
  Planners

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is that conformal prediction can be used to align the uncertainty of large language model (LLM)-based robot planners in order to minimize reliance on human assistance while still maintaining high levels of task success. Specifically, the paper proposes a framework called "KnowNo" that applies conformal prediction to LLM-based planners in order to generate prediction sets over possible next actions. If the prediction set contains multiple options, this signals uncertainty on the part of the LLM planner, triggering a request for human assistance. The conformal prediction methodology allows KnowNo to provide statistical guarantees on task success for a given level of human assistance. The central hypothesis is that by aligning the LLM's uncertainty in this way, KnowNo can minimize the amount of human help requested while still ensuring reliable task completion.Experiments across simulated and real robot platforms on various manipulation tasks seem to validate this hypothesis, showing that KnowNo reduces the rate of human assistance compared to baselines, while maintaining calibrated confidence at a user-specified level. The central contribution is demonstrating that conformal prediction provides a promising approach to aligning uncertainty in LLM-based planners in order to balance autonomy and human assistance.
