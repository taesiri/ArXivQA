# [PEEKABOO: Interactive Video Generation via Masked-Diffusion](https://arxiv.org/abs/2312.07509)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes Peekaboo, a training-free method to add spatio-temporal control to off-the-shelf video generation models based on latent diffusion. Peekaboo works by using masked attention to guide the model to generate desired objects in specific locations across frames. It introduces separate attention masks in the cross-, self-, and temporal attention layers to isolate foreground and background generation for several initial diffusion steps, after which free generation allows integration. This attention masking enables explicit spatial control over object size, location and movement without retraining models or increasing inference latency. The method is evaluated quantitatively and qualitatively on two new datasets introduced in the paper for measuring spatio-temporal control, showing significant improvements in metrics like mIoU and AP50 over baseline models. Ablations reveal the importance of each masking component. The approach also improves video quality and alleviates some common failure cases of text-to-video models. Its zero-training property allows easy adoption with different base models. Limitations include mismatches between user masking and model priors. Overall, Peekaboo enables interactive video editing by giving end users spatial and temporal control over generation.
