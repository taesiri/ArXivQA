# [Zero- and Few-Shots Knowledge Graph Triplet Extraction with Large   Language Models](https://arxiv.org/abs/2312.01954)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes a pipeline to enhance the performance of large language models (LLMs) on the task of triplet extraction (TE) from text in zero-shot and few-shot settings. The pipeline dynamically gathers contextual triplets or sentence-triplet pairs from a knowledge base (KB) that are relevant to the input sentence, and includes this contextual information in the LLM prompt. Experiments showed that adding just 5 contextual triplets substantially improved LLM performance on TE over using the prompt alone, making even smaller LLM models competitive with some classical NLP baselines. Further gains were achieved by instead providing 5 relevant sentence-triplet examples. There is evidence that TE performance correlates more strongly with the quality of the retrieved KB context than LLM scale. While still below state-of-the-art classical models, prompting LLMs with relevant KB context makes them much more capable on TE in low-resource scenarios compared to relying solely on the prompt. The paper recommends focusing efforts on improving KB quality and retrieval over pursuing ever-larger LLMs for advancing TE.
