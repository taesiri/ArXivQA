# [Beating Backdoor Attack at Its Own Game](https://arxiv.org/abs/2307.15539)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: Can we utilize backdoor techniques to defend against backdoor attacks? 

The key hypothesis is that injecting a "non-adversarial backdoor" targeting poisoned samples can suppress the effectiveness of an adversarial backdoor attack. Specifically, the non-adversarial backdoor changes the model's behavior on poisoned inputs to counteract the adversarial backdoor.

The paper proposes a framework called "Non-Adversarial Backdoor (NAB)" which detects a small set of suspicious samples and processes them to inject a non-adversarial backdoor. This backdoor suppresses the adversarial backdoor on poisoned inputs but has limited influence on clean inputs.

In summary, the paper explores using backdoor techniques in a novel way for defense rather than attack. The central hypothesis is that a non-adversarial backdoor targeting poisoned samples can effectively counteract an adversarial backdoor attack.


## What is the main contribution of this paper?

 This paper proposes a new defense method against backdoor attacks on deep neural networks. The key contributions are:

- It introduces the idea of using a "non-adversarial backdoor" to defend against adversarial backdoor attacks. This involves injecting a backdoor targeting the poisoned samples rather than the clean samples. 

- It proposes a flexible framework called Non-Adversarial Backdoor (NAB) to implement this idea. The framework has two main steps - detecting a small set of suspected poisoned samples, and injecting a backdoor into them by adding a trigger pattern and changing their labels. 

- During inference, the non-adversarial backdoor is kept triggered on all inputs, which suppresses the adversarial backdoor on the poisoned data. This allows clean accuracy to be maintained while reducing attack success rate.

- The method achieves state-of-the-art performance on CIFAR-10 and Tiny ImageNet datasets against various backdoor attacks. It has significantly higher clean accuracy and lower attack success rate compared to prior defenses.

- The framework is simple, flexible and does not require modifications to the standard training pipeline. The components like backdoor detection and poisoning strategies are replaceable.

In summary, the key contribution is introducing and implementing the idea of using non-adversarial backdoors to defend against backdoor attacks, through a flexible framework that achieves excellent defense performance. The paper demonstrates the promise of using backdoors for defense rather than just attacks.
