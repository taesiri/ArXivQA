# [Cartoon Explanations of Image Classifiers](https://arxiv.org/abs/2110.03485v5)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research question seems to be:

How can we develop a new explanation method for image classifiers that extracts the relevant piece-wise smooth part of an image, rather than just pixel-sparse regions as in previous methods?

The key hypothesis is that extracting the piece-wise smooth parts of an image, by requiring sparsity in the wavelet domain, will provide more meaningful and interpretable explanations for image classifiers compared to existing methods. 

In particular, the authors propose a new method called CartoonX that:

- Reformulates the rate-distortion explanation (RDE) framework to allow flexibility in the input representation, to enable new interpretation queries.

- Applies RDE in the wavelet domain to extract piece-wise smooth explanations for images, taking advantage of wavelets' ability to sparsely represent such images. 

- Demonstrates qualitatively and quantitatively that CartoonX reveals novel explanatory insights and achieves better rate-distortion performance than pixel-based methods.

So in summary, the main research question is how to develop a new explanation method tailored for image classifiers that provides piece-wise smooth explanations by exploiting wavelet sparsity, instead of just pixel-sparse explanations. The hypothesis is that this approach will lead to more meaningful and interpretable explanations.
