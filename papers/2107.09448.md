# [DNN is not all you need: Parallelizing Non-Neural ML Algorithms on   Ultra-Low-Power IoT Processors](https://arxiv.org/abs/2107.09448)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can key non-neural machine learning (ML) algorithms be efficiently parallelized to run on resource-constrained parallel ultra-low power (PULP) IoT processors?The authors aim to optimize the parallel design of six widely-used non-neural ML algorithms (including SVM, logistic regression, Gaussian Naive Bayes, etc.) to maximize performance on two RISC-V based PULP platforms - the commercial GAP8 chip and the PULP-OPEN research architecture. The key ideas and contributions appear to be:- Comparing performance of optimized sequential implementations on GAP8 using different floating point emulation libraries vs. native FP support on PULP-OPEN- Parallelization strategies and fine-grained analysis to maximize parallel speedup on the multi-core clusters of the PULP platforms- Experimental results demonstrating the achieved speedups and efficiencies when running the parallelized non-neural ML algorithms on the PULP platforms- Comparison to ARM Cortex-M4 showing the performance benefits of using the PULP architectures, especially with multi-core parallelismSo in summary, the central hypothesis seems to be that careful optimization and parallelization of key non-neural ML algorithms can enable efficient deployment of ML at the edge on parallel ultra-low power IoT processors like PULP. The paper provides extensive experimental analysis to demonstrate and validate this idea.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:- The authors optimize the parallel design of six key non-neural machine learning algorithms (logistic regression, support vector machine, Gaussian naive Bayes, random forest, k-nearest neighbors, k-means) to maximize performance on two RISC-V based parallel ultra-low power (PULP) platforms - GAP8 and PULP-OPEN. - They analyze the performance of these algorithms using two different floating point emulation libraries on GAP8, which lacks native FPU support, versus using the native FPU on PULP-OPEN. Their optimized FP emulation library (RVfplib) achieves 1.61x average speedup over the standard libgcc emulation on GAP8. The FPU support on PULP-OPEN leads to up to 32x speedup over emulation on GAP8.- They evaluate the parallel performance of the optimized implementations on the 8-core clusters of GAP8 and PULP-OPEN, achieving near ideal speedups of 6.56-7.64x versus single core. Detailed analysis highlights the architectural factors limiting parallel speedups on each platform.- Comparison with ARM Cortex-M4 shows 1.36-2.39x speedup on single core PULP-OPEN over Cortex-M4, and 9.27-15.85x speedup using 8-core PULP-OPEN.In summary, the key contributions are the optimized parallel design and implementation of non-neural ML algorithms on PULP platforms, extensive performance analysis exploring different hardware configurations, and demonstration of significant speedups over ARM Cortex-M4.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The TL;DR version of this paper is: This paper presents optimized parallel designs and implementations of 6 non-neural machine learning algorithms - SVM, Logistic Regression, Gaussian Naive Bayes, Random Forest, k-Nearest Neighbors, and k-Means - on two RISC-V based parallel ultra-low power IoT processors, demonstrating significant speedups and efficiency improvements over sequential execution and ARM Cortex-M4 processors.


## How does this paper compare to other research in the same field?

Here is a brief analysis of how this paper compares to other related research in the field:- Topic and goals: This paper focuses on optimizing the performance of non-neural machine learning algorithms on parallel ultra-low power IoT processors. This is an important topic as many IoT devices have tight power and compute constraints. The goal is to enable efficient deployment of ML at the edge. This aligns with broader trends in TinyML research.- Approach: The authors optimize both sequential and parallel implementations of six common non-neural ML algorithms targeting two RISC-V based PULP platforms. They use detailed performance analysis to guide optimizations like memory access patterns and parallelization schemes. This hands-on optimization work differentiates it from more high-level ML system design papers.- Results: Key results include 1.6-32x speedups from FP emulation libraries and near ideal 6.6-7.6x parallel speedups on the PULP platforms. They also show 1.4-2.4x speedups over ARM Cortex M4. The detailed empirical performance data is a strength.- Novelty: While there is prior work on individual parts (e.g. parallel ML, code optimization), this paper combines them and is one of the first to deeply optimize non-neural ML across multiple algorithms on RISC-V PULP.- Limitations: It focuses only on inference without training results. The scope is limited to six algorithms and two RISC-V platforms. More algorithm and hardware diversity could strengthen it.Overall, this paper makes solid contributions to advancing TinyML research by demonstrating optimized non-neural ML execution on cutting-edge parallel IoT processors. The thorough empirical optimization work helps fill a gap in rigorous TinyML systems research.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions the authors suggest are:- Developing an automatic tool to deploy non-neural ML algorithms on PULP-based MCUs, to help optimize performance by determining optimal tiling and double-buffering operations.- Expanding the parallel ML library they have developed by integrating more non-neural ML algorithms. This could help provide optimized implementations of a wider range of important ML methods for resource-constrained edge devices.- Supporting emerging PULP architectures in their library and tools. As new PULP-based designs emerge, adapting their work to target those platforms could help maximize performance and efficiency.- Exploring techniques to reduce power consumption and memory footprint even further when running ML inference on PULP devices. Their work focuses mainly on computational performance, but further optimizing other aspects like power and memory could be impactful.- Evaluating their parallelization techniques on additional datasets and ML methods beyond the ones studied in the paper. This could help demonstrate the general applicability of their approach to a wider range of ML workloads.- Comparing performance against a broader range of embedded devices and architectures beyond the Cortex-M4 baseline used in the paper. This could reveal further advantages of the PULP approach.- Investigating how their techniques could be integrated with neural network execution on PULP devices. Much recent work has focused on neural nets, but combining non-neural and neural techniques could be beneficial.In summary, the authors point to automating deployment, expanding support for algorithms and architectures, reducing power and memory demands, and broadening evaluation as key next steps for this line of research on efficient parallel ML on embedded devices.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper presents the parallel design and optimization of six key non-neural machine learning algorithms - SVM, Logistic Regression, Gaussian Naive Bayes, Random Forest, k-Nearest Neighbors, and k-Means - for efficient execution on two RISC-V based parallel ultra-low power (PULP) microcontroller platforms - GAP8 and PULP-OPEN. The algorithms are optimized through extensive profiling and analysis to maximize performance on the multi-core shared memory architecture. Different floating point emulation libraries are evaluated on the FPU-less GAP8, with the custom RVfplib achieving 1.6x speedup over standard libgcc emulation. Leveraging native FPU support on PULP-OPEN leads to up to 32x speedup. Near ideal parallel speedups of 6.56-7.64x are attained on the 8-core platforms through optimized parallelization schemes and data access patterns. Comparisons to the ARM Cortex-M4 show 1.36-2.39x speedups on single core PULP-OPEN and 9.27-15.85x speedups using 8-cores, demonstrating significant performance benefits. Overall, the work enables efficient deployment of non-neural ML at the extreme edge through extensive optimization for the PULP multi-core architecture.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the key points from the paper:The paper presents an optimized parallel design and implementation of six common non-neural machine learning algorithms on two RISC-V based parallel ultra-low power (PULP) platforms - GAP8 and PULP-OPEN. The algorithms optimized include support vector machines (SVM), logistic regression (LR), Gaussian naive Bayes (GNB), random forest (RF), k-nearest neighbors (kNN), and k-means clustering. The work focuses on enabling efficient parallel execution of these algorithms to meet the computational constraints of IoT edge devices. The authors utilize a fine-grained analysis to determine efficient memory access patterns and parallelization schemes. They also optimize the runtime through extensive modifications to maximize performance. Comparing single-core execution, they find optimized software routines can achieve 1.61x average speedup over standard emulation libraries on GAP8. Native floating point support on PULP-OPEN achieves up to 32.09x speedup. Their optimized parallel design enables near-ideal speedups from 6.56x to 7.64x using the 8-core cluster. Finally, even a single core PULP-OPEN configuration achieves 1.36x to 2.39x speedup over the ARM Cortex-M4, while the 8-core cluster attains 9.27x to 15.85x speedup. The work demonstrates the potential of parallel ultra-low power platforms for efficient non-neural ML at the edge.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper:The paper presents an approach for optimizing and parallelizing six common non-neural machine learning algorithms - logistic regression, support vector machines, Gaussian naive Bayes, random forests, k-nearest neighbors, and k-means clustering - to efficiently run on two types of parallel ultra-low power (PULP) IoT processors. The algorithms were coded in C and optimized through sequential code profiling and analysis to maximize performance on the single-core processors. Parallel versions utilizing the 8-core clusters were then developed using data partitioning, workload distribution, and synchronization schemes tailored for the PULP architecture. The optimized parallel algorithms were benchmarked on the GAP8 commercial chip and the PULP-OPEN research platform, using two different floating point emulation libraries for GAP8. Performance was quantified by runtime, energy usage, code size, and architectural metrics like pipeline stalls and cache misses. Substantial speedups and efficiency gains were demonstrated versus baseline sequential implementations and versus a commercial ARM Cortex M4 processor.
