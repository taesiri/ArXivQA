# [DNN is not all you need: Parallelizing Non-Neural ML Algorithms on   Ultra-Low-Power IoT Processors](https://arxiv.org/abs/2107.09448)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can key non-neural machine learning (ML) algorithms be efficiently parallelized to run on resource-constrained parallel ultra-low power (PULP) IoT processors?The authors aim to optimize the parallel design of six widely-used non-neural ML algorithms (including SVM, logistic regression, Gaussian Naive Bayes, etc.) to maximize performance on two RISC-V based PULP platforms - the commercial GAP8 chip and the PULP-OPEN research architecture. The key ideas and contributions appear to be:- Comparing performance of optimized sequential implementations on GAP8 using different floating point emulation libraries vs. native FP support on PULP-OPEN- Parallelization strategies and fine-grained analysis to maximize parallel speedup on the multi-core clusters of the PULP platforms- Experimental results demonstrating the achieved speedups and efficiencies when running the parallelized non-neural ML algorithms on the PULP platforms- Comparison to ARM Cortex-M4 showing the performance benefits of using the PULP architectures, especially with multi-core parallelismSo in summary, the central hypothesis seems to be that careful optimization and parallelization of key non-neural ML algorithms can enable efficient deployment of ML at the edge on parallel ultra-low power IoT processors like PULP. The paper provides extensive experimental analysis to demonstrate and validate this idea.
