# [Semi-supervised Hand Appearance Recovery via Structure Disentanglement   and Dual Adversarial Discrimination](https://arxiv.org/abs/2303.06380)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the introduction and abstract, the central research question this paper seeks to address is: 

How can we simultaneously capture high-fidelity hand appearance and motion data, overcoming the dilemma that accurate motion capture relies on markers that degrade appearance, while detailed appearance capture without markers makes motion tracking difficult?

The key hypothesis proposed is that this can be achieved by:

1) First disentangling the bare hand structure from marker-degraded images into pixel-aligned maps. 

2) Then wrapping the appearance information from the original degraded images onto the disentangled bare hand structure using a dual adversarial discrimination scheme.

In summary, the central hypothesis is that by explicitly disentangling structure and appearance into separate representations, then intelligently combining them, it is possible to recover high-fidelity bare hand appearance from degraded marker-based motion capture data.


## What is the main contribution of this paper?

 The main contribution of this paper is developing a semi-supervised framework for recovering the bare hand appearance from images with degraded appearance due to the use of markers in motion capture. The key ideas are:

1. Disentangling the bare hand structure from the input image using a ViT-based sketcher. This allows extracting just the structure information and removing the degraded appearance. 

2. Wrapping the appearance from the input image onto the disentangled bare hand structure using a novel dual adversarial discrimination (DAD) scheme. This enables translating the degraded appearance to the target bare domain in an unpaired setting.

Specifically, the paper makes the following main contributions:

- A ViT sketcher that disentangles the bare hand structure from monocular RGB images without relying on parametric hand models. It uses a learned bare structure prior, hand saliency guidance, and a semi-supervised training approach.

- A DAD scheme for appearance wrapping that uses both process and result discriminators to enable unpaired degraded-to-bare translation. It trains with both real degraded data and a synthesized partner domain.

- A semi-supervised framework combining the above to recover photo-realistic bare hand appearance from diverse marker-degraded datasets as well as object-occluded hands.

In summary, the main contribution is a novel approach and framework for bare hand appearance recovery through structure disentanglement and dual adversarial discrimination in a semi-supervised manner.
