# [MotionChain: Conversational Motion Controllers via Multimodal Prompts](https://arxiv.org/abs/2404.01700)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "MotionChain: Conversational Motion Controllers via Multimodal Prompts":

Problem:
- Recent language models have shown ability for multi-turn dialogues and retaining conversation context, but this has not been explored much for multimodal generative models, especially for human motion models. 
- Integrating multi-turn conversations to control continuous virtual human movements can help achieve intuitive and step-by-step human task execution, useful for humanoid robots, game agents, etc.
- Two main challenges: (1) Contextually generating human motion continuously resembling real human movement; (2) Scarcity of text-motion paired datasets compared to other modalities.

Proposed Solution:
- Propose MotionChain, a conversational human motion controller to generate long-term human motion through multimodal (text, image, motion) prompts.
- It has multi-modal tokenizers to transform text, images, motions into discrete tokens.
- Also has a Vision-Motion aware Language Model trained on large-scale language, vision-language, vision-motion datasets.  
- Leverages a motion-specific VQ-VAE model to construct a "motion vocabulary" to convert motion data into motion token sequence.
- Introduces a vision tokenizer to convert images into tokens in language model's embedding space.
- Unified vocabulary integrates text tokens, motion tokens, special tokens.
- Adopts 3-stage training strategy: (1) Pre-train motion tokenizer; (2) Connect all components and pre-train on text-motion, image-motion data; (3) Tune on instruction-based conversation dataset.

Main Contributions:
- Propose MotionChain unified vision-motion-language model for conversational generation via multimodal prompts.
- Introduce motion composition technique to temporally generate motions following prompt order. 
- Construct multimodal motion conversation benchmark where MotionChain shows strong performance across diverse motion tasks.
