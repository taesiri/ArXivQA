# [ColorMNet: A Memory-based Deep Spatial-Temporal Feature Propagation   Network for Video Colorization](https://arxiv.org/abs/2404.06251)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Video colorization aims to add realistic colors to grayscale videos. It is challenging because it not only needs to colorize each frame well but also requires ensuring good temporal consistency across frames. Existing methods either do not effectively model long-range temporal information or require large GPU memory for processing long videos. 

Proposed Solution:
This paper proposes a memory-based deep spatial-temporal feature propagation network (ColorMNet) for video colorization. The key components and contributions are:

1. Large-pretrained Visual Model Guided Feature Estimation (PVGFE) Module: Leverages features from large pretrained models like DINOv2 to guide the feature learning of each frame. This helps capture non-local semantics and robust features for colorization. 

2. Memory-based Feature Propagation (MFP) Module: Propagates features between far-apart frames by selectively storing important features in a memory bank. This establishes reliable long-range connections while being memory-efficient.

3. Local Attention (LA) Module: Explores spatial-temporal correlations in local neighborhoods to complement the long-range information from MFP.

These components are formulated into an end-to-end network. Extensive experiments show ColorMNet achieves state-of-the-art performance in terms of colorization quality and temporal consistency, while being very fast and memory-efficient.
