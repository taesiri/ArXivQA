# [Vocabulary Attack to Hijack Large Language Model Applications](https://arxiv.org/abs/2404.02637)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) are being used in more applications, leading to increased attacks by hackers trying to make the models reveal confidential information or generate offensive/false outputs. 
- Existing attacks use special characters as separators or require gradient optimization, making them easier to detect.
- There is a need for a more subtle attack that manipulates the user prompt to trick the LLM.

Proposed Solution:
- Insert words from the LLM's vocabulary, found using an optimization procedure and embeddings from another "attacker" LLM.
- Words are selected based on maximizing a similarity loss between generated and desired outputs.
- Allow the attack to position 1-3 top words anywhere in the user prompt.
- Evaluate the simplest successful attack (hardest to detect).

Experiments:
- Attack two popular open-source LLMs - Flan-T5-XXL and Llama2-7B-CHAT-HF.
- Use Llama2-CHAT-HF and T5-BASE as attacker models.  
- Test on 35 cases from prior work, aiming for offensive or misinformation outputs.

Results:
- The attack succeeds in several test cases with only 1 inserted word needed.  
- Attacking with a different LLM still works fairly well.
- Insertions are subtle and hard to detect compared to prior separator attacks.
- Even accidental insertions could lead to unintended offensive/false outputs.

Main Contributions:
- Demonstrated a more subtle vocabulary insertion attack than prior work.
- Showed that attack can work without access to target LLM.
- Revealed possibility of unintentional goal hijacking from minor prompt changes.
- Provided insights into LLM security, testing, and defenses.
