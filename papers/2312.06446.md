# [Experimental demonstration of a robust training method for strongly   defective neuromorphic hardware](https://arxiv.org/abs/2312.06446)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper experimentally demonstrates a robust training method for neural networks implemented on hardware containing defects. The authors fabricate 36 chips each with 20,000 magnetic tunnel junctions (MTJs) integrated with CMOS transistors into a crossbar array for performing neural network inference. They show that even a small number of defects in the mapped neural network can significantly degrade performance versus training on ideal software. Using a hardware-aware training method that accounts for each chip's specific defects recovers accuracy comparable to software-only training. However, solutions trained for one chip do not transfer robustness to others. Therefore, the authors develop a statistics-aware training method that trains networks according to the defect statistics across the chip population. By accumulating gradients across parallel network instances with random defects, they produce weight solutions that achieve low classification error consistently across chips, despite varying defect locations. This method could enable robust solutions for industry-scale production and usage of hardware neural networks using devices prone to defects. Key results are that statistics-aware solutions can match software baselines within 2% on average, reduce across-chip variation by an order of magnitude, and show reduced sensitivity to weight perturbations versus non-robust training.
