# [TransTroj: Transferable Backdoor Attacks to Pre-trained Models via   Embedding Indistinguishability](https://arxiv.org/abs/2401.15883)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Pre-trained models (PTMs) are vulnerable to backdoor attacks where adversaries inject backdoors so downstream models inherit them. 
- Existing attacks require downstream task knowledge, are not durable ( forgotten during fine-tuning), or only partially task-agnostic.

Proposed Solution:
- Propose TransTroj, a novel transferable backdoor attack that is functionality-preserving, durable and task-agnostic.
- Convert the attack to achieving embedding indistinguishability between poisoned and target class samples. 
- Decompose indistinguishability into pre- (before attack) and post- (after attack) and formulate objectives.
- Use a two-stage optimization to achieve the objectives:
   - Stage 1: Optimize trigger to enhance similarity between poisoned and target embeddings (pre-indistinguishability).
   - Stage 2: Optimize victim PTM to align poisoned embeddings with target embeddings (post-indistinguishability).

Main Contributions:
- Propose TransTroj, which meets functionality-preserving, durable and task-agnostic goals.
- Formulate and decompose transferable attacks into pre- and post- embedding indistinguishability.
- Design a two-stage optimization to achieve the indistinguishability objectives.
- Extensive experiments showing TransTroj is effective and outperforms state-of-the-art attacks significantly.

The summary covers the key aspects - the problem, proposed solution and contributions. It describes the core ideas and techniques at a high-level without going into too much detail. This allows a reader to fully understand TransTroj and its significance.


## Summarize the paper in one sentence.

 This paper proposes a novel transferable backdoor attack method called TransTroj that can inject durable and task-agnostic backdoors into pre-trained models by optimizing triggers and models to achieve embedding indistinguishability between poisoned and target class samples.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Proposing TransTroj, a novel transferable backdoor attack against pre-trained models (PTMs) that can simultaneously meet functionality-preserving, durable, and task-agnostic properties. 

2. Formulating and decomposing transferable attacks into pre- and post- embedding indistinguishability objectives.

3. Designing a two-stage optimization to achieve the indistinguishability objectives - first optimizing a trigger, then optimizing the victim PTM.

4. Conducting comprehensive experiments to evaluate the effectiveness of TransTroj under various system settings. The results show it significantly outperforms state-of-the-art attacks.

In summary, the key contribution is proposing TransTroj, a transferable backdoor attack that is more effective, durable, and task-agnostic compared to prior art. The attack is enabled by formulating and solving for embedding indistinguishability using a two-stage optimization approach.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts related to this paper include:

- Transferable backdoor attack - The paper proposes a novel transferable backdoor attack method against pre-trained models called TransTroj. The goal is to inject durable and task-agnostic backdoors that transfer to downstream tasks.

- Pre-trained models (PTMs) - The victim models that are attacked are various pre-trained models like ResNet, VGG, ViT, and CLIP. These models are pre-trained on large datasets and then fine-tuned for downstream tasks.

- Embedding indistinguishability - The key idea behind the attack is to make poisoned inputs indistinguishable from clean target class inputs in the embedding space of the PTM. This causes the model to misclassify poisoned inputs.

- Pre- and post-indistinguishability - The embedding indistinguishability is decomposed into similarity of embeddings before and after injecting the backdoor into the PTM. Two optimization stages enhance these.

- Trigger optimization - The first stage that optimizes a global perturbation trigger to increase similarity between poisoned and target embeddings in the clean PTM.

- Model optimization - The second stage that updates the weights of the backdoored PTM to further make poisoned and target embeddings similar.

- Task agnostic - The attack transfers and succeeds on multiple downstream tasks without needing knowledge of those tasks, making it more dangerous.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes decomposing embedding indistinguishability into pre- and post-indistinguishability. What is the intuition behind this decomposition and how does it help craft a durable and task-agnostic backdoor?

2. The paper uses a two-stage optimization strategy to achieve the pre- and post-indistinguishability objectives. Can you explain the rationale behind adopting a two-stage approach instead of a joint optimization? 

3. The trigger optimization stage aims to enhance pre-indistinguishability. Why is using a global perturbation based trigger better suited for this compared to other types of triggers?

4. The victim PTM optimization stage aligns poisoned embeddings with reference embeddings to achieve post-indistinguishability. What modifications need to be made to the optimization objective to balance effectiveness and functionality preservation?

5. How does the use of reference embeddings from target class images downloaded from the internet help make the attack more task-agnostic compared to manually crafted PORs?

6. The results show high attack success rates across models and datasets. Analyze the results and discuss why the attack fails on certain datasets. Is it an inherent limitation?

7. The sensitivity analysis studies the impact of factors like trigger norm and shadow dataset size. What practical insights do these results provide towards deploying the attack in real scenarios?  

8. The paper evaluates defense strategies like re-initialization and fine-pruning. Why do these defenses fail to effectively mitigate the attack?

9. The visualization and analysis of embeddings provides insights into why the attack is successful. Can you summarize the key inferences from this analysis?

10. The attack is evaluated on fine-tuning based transfer learning. How do the results compare when using other paradigms like zero-shot learning and linear probing? What can you infer?
