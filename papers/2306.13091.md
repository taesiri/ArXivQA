# [Evading Forensic Classifiers with Attribute-Conditioned Adversarial   Faces](https://arxiv.org/abs/2306.13091)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we generate realistic fake face images with specified attributes that can fool forensic classifiers trained to detect synthetically generated faces?The key points are:- Recent advances in generative models like GANs can generate highly realistic fake face images. These can potentially be misused for malicious purposes like creating fake online profiles. - As a defense, deep learning based forensic classifiers have been developed that can detect synthetic face images with high accuracy. - However, these forensic classifiers are vulnerable to adversarial attacks. Prior work has shown that exploring the latent space of GANs can produce adversarial examples. - But existing approaches lack fine-grained control over facial attributes like skin color, age, expression etc. The authors aim to address this limitation.- Their proposed approach leverages the disentangled latent space of StyleGAN to generate adversarial fake faces conditioned on reference images or text prompts specifying the desired attributes.- The key hypothesis is that by semantically manipulating the latent vectors, they can produce adversarial examples that exhibit specified attributes, fool forensic classifiers, and appear realistic to humans.In summary, the central research question is whether they can generate attribute-specific adversarial fake faces by searching in the latent space of StyleGAN in an adversarial manner. The key hypothesis is that their approach will allow better control over facial attributes compared to prior art.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a framework to generate adversarial fake faces with specified attributes defined by either a reference image or a text prompt. This is achieved by manipulating the latent space of a pre-trained StyleGAN generator through semantic changes and adversarial optimization.2. For image-based attribute conditioning, semantic attributes are transferred from a reference image to a randomly generated image by optimizing over attribute-specific layers of StyleGAN. 3. For text-based conditioning, the text embeddings from CLIP are leveraged to guide the search for adversarial latent codes that match the text description.4. A meta-learning based optimization strategy is proposed to improve the transferability of the generated adversarial examples to unknown target models compared to an ensemble-based approach.5. Extensive experiments show that the proposed approach can successfully generate realistic adversarial fake faces with desired attributes that fool state-of-the-art forensic face classifiers while being indistinguishable to humans.In summary, the key contribution is a unified framework to generate semantically manipulated adversarial fake faces guided by either reference images or text prompts, that can evade detection by forensic classifiers. The use of StyleGAN's disentangled latent space enables fine-grained attribute control.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes an approach to generate realistic adversarial fake face images with specified attributes using StyleGAN that can fool forensic classifiers, while being visually imperceptible to humans.
