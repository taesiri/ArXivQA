# [GRAFFORD: A Benchmark Dataset for Testing the Knowledge of Object   Affordances of Language and Vision Models](https://arxiv.org/abs/2402.12881)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key aspects of the paper:

Problem:
- Pre-trained language models (PTLMs) and vision-language models (VLMs) have shown impressive capabilities but lack proper grounding and reasoning about real-world concepts. 
- Specifically, these models have limited understanding of object affordances - the set of possible actions that can be performed on an object given its physical capabilities.

Proposed Solution:
- The authors introduce a new dataset called GrAFFORD for evaluating affordance knowledge of language and vision models. It has 2,368 sentence-object pairs annotated with 15 affordance types.

- They evaluate various PTLMs like RoBERTa, BART and VLMs like CLIP, ViLT on zero-shot affordance prediction using this dataset. They also explore an ensemble of language and vision models.

- Additionally, they perform few-shot fine-tuning of models on a subset of examples from GrAFFORD dataset. They also evaluate in-context learning capabilities of generative models like FLAN, ChatGPT.

Key Contributions:

- Novel GrAFFORD dataset for textual affordance reasoning comprising diverse real-world situations.

- Analysis revealing limitations of reasoning about uncommon object affordances in state-of-the-art models.

- Demonstrating that combining language and vision models can improve affordance prediction performance.  

- Evidence that targeted fine-tuning significantly enhances affordance knowledge even for very large language models.

- The dataset and evaluations provide concrete direction for future work towards enhancing language grounding in AI models w.r.t conceptual understanding.

In summary, the paper makes notable contributions in evaluating and improving affordance knowledge and reasoning capabilities of language and vision AI models using a purpose-built dataset.
