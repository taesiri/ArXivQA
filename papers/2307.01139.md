# SCITUNE: Aligning Large Language Models with Scientific Multimodal
  Instructions

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can large language models be aligned with scientific concepts and goals through multimodal instruction tuning, in order to improve their performance on science-focused tasks? The key hypothesis appears to be:Scientifically aligned multimodal foundation models that are tuned via instructions grounded in scientific concepts and data modalities (like figures, captions, text) will be better able to learn from the unique patterns in scientific language and follow precise scientific instructions. This will lead to improved performance on downstream science tasks compared to models tuned only with general human feedback.The authors propose a framework called SciTune that performs scientific multimodal instruction tuning, with two main stages:1) Scientific concept alignment, where the model learns alignments between scientific visuals (plots, figures, etc.) and textual signals (captions, text).2) Scientific instruction tuning, where the model is fine-tuned on a multimodal scientific reasoning task. The hypothesis is that by grounding the model in scientific concepts and then tuning it with scientific instructions, the model will gain improved scientific reasoning abilities. The authors test this hypothesis by evaluating variants of the SciTune model on scientific QA and image tasks.In summary, the central question is how to adapt LLMs like LLaMA to the scientific domain via grounded instruction tuning, and the hypothesis is that this approach will improve multimodal scientific reasoning compared to general tuning. The SciTune framework and experiments aim to validate this hypothesis.
