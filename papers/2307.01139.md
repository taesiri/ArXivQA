# SCITUNE: Aligning Large Language Models with Scientific Multimodal
  Instructions

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can large language models be aligned with scientific concepts and goals through multimodal instruction tuning, in order to improve their performance on science-focused tasks? The key hypothesis appears to be:Scientifically aligned multimodal foundation models that are tuned via instructions grounded in scientific concepts and data modalities (like figures, captions, text) will be better able to learn from the unique patterns in scientific language and follow precise scientific instructions. This will lead to improved performance on downstream science tasks compared to models tuned only with general human feedback.The authors propose a framework called SciTune that performs scientific multimodal instruction tuning, with two main stages:1) Scientific concept alignment, where the model learns alignments between scientific visuals (plots, figures, etc.) and textual signals (captions, text).2) Scientific instruction tuning, where the model is fine-tuned on a multimodal scientific reasoning task. The hypothesis is that by grounding the model in scientific concepts and then tuning it with scientific instructions, the model will gain improved scientific reasoning abilities. The authors test this hypothesis by evaluating variants of the SciTune model on scientific QA and image tasks.In summary, the central question is how to adapt LLMs like LLaMA to the scientific domain via grounded instruction tuning, and the hypothesis is that this approach will improve multimodal scientific reasoning compared to general tuning. The SciTune framework and experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

After reviewing the paper, it seems the main contribution is presenting SciTune, a new framework for aligning large language models (LLMs) with scientific concepts and goals through scientific multimodal instruction tuning. Specifically, the key ideas presented are:- SciTune includes two stages: scientific concept alignment and task-specific instruction tuning. The first stage aligns LLMs with scientific visual and textual signals like plots, captions, equations, etc. The second stage fine-tunes the model on a science reasoning task.- SciTune uses human-generated scientific instructions from research papers and datasets like SciCap to provide natural scientific concepts and intent, rather than relying on machine-generated instructions.- Experiments show SciTune helps models like LLaMA perform better on scientific visual tasks like figure captioning and classification compared to baseline vision-language models.- A model called LLaMA-SciTune trained with SciTune achieves state-of-the-art results on the ScienceQA benchmark, outperforming human accuracy on scientific reasoning questions.- Ablation studies demonstrate the benefits of SciTune's multimodal alignment and scaling up model size. The 13B parameter LLaMA-SciTune outperforms the 7B version significantly.In summary, the key contribution is presenting SciTune as a novel way to adapt and improve general LLMs for scientific domains by grounding them in human scientific instructions and concepts. The results demonstrate strong improvements on scientific understanding and reasoning compared to both human and machine baselines.
