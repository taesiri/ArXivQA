# [EGformer: Equirectangular Geometry-biased Transformer for 360 Depth   Estimation](https://arxiv.org/abs/2304.07803)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we design an efficient transformer architecture that achieves high performance for equirectangular image depth estimation? 

The key challenges are:

- Equirectangular images have a wide field of view and geometric distortion which makes convolutional networks ineffective. Transformers can handle the wide field of view through global attention, but global attention is computationally expensive.

- Local attention can be more efficient but it is challenging to apply effectively to equirectangular images due to the distortion and limited receptive field.

The main hypothesis of the paper is that the known equirectangular geometry can be used as a structural prior or bias to improve the efficiency and effectiveness of a transformer with local attention for this task.

Specifically, the paper proposes an "Equirectangular Geometry-biased Transformer" (EGformer) that uses the equirectangular geometry:

- As a bias when computing self-attention within local windows, through an Equirectangular Relative Position Embedding (ERPE)

- To compute attention scores based on distances on the sphere rather than softmax

- To rearrange local attention windows based on their estimated importance, enabling local windows to interact indirectly to increase receptive field.

Through experiments, the paper aims to demonstrate that EGformer can achieve state-of-the-art depth estimation performance for equirectangular images, with high efficiency and fewer parameters compared to prior work.


## What is the main contribution of this paper?

 The main contributions of this paper seem to be:

- Proposing an equirectangular geometry-biased transformer called EGformer for efficient and accurate 360 degree depth estimation. 

- Introducing three main components to EGformer:
   - Equirectangular relative position embedding (ERPE) to impose geometry bias within local windows.
   - Distance-based attention score (DAS) to re-weight attention scores based on distances in spherical coordinates.
   - Equirectangular-aware attention rearrangement (EaAR) to impose geometry bias between local windows.

- Demonstrating that by utilizing the known equirectangular geometry as a bias, EGformer can achieve better depth estimation performance than previous methods while having lower computational cost and fewer parameters. 

- Conducting experiments on standard 360 degree depth estimation datasets like Structured3D and Pano3D to show quantitative and qualitative improvements over prior arts.

In summary, the key contribution is using the equirectangular geometry as an explicit bias to enable efficient and accurate extraction of local attention in transformers for 360 degree depth estimation. This improves performance while reducing computational requirements compared to prior work.
