# [EGformer: Equirectangular Geometry-biased Transformer for 360 Depth   Estimation](https://arxiv.org/abs/2304.07803)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we design an efficient transformer architecture that achieves high performance for equirectangular image depth estimation? The key challenges are:- Equirectangular images have a wide field of view and geometric distortion which makes convolutional networks ineffective. Transformers can handle the wide field of view through global attention, but global attention is computationally expensive.- Local attention can be more efficient but it is challenging to apply effectively to equirectangular images due to the distortion and limited receptive field.The main hypothesis of the paper is that the known equirectangular geometry can be used as a structural prior or bias to improve the efficiency and effectiveness of a transformer with local attention for this task.Specifically, the paper proposes an "Equirectangular Geometry-biased Transformer" (EGformer) that uses the equirectangular geometry:- As a bias when computing self-attention within local windows, through an Equirectangular Relative Position Embedding (ERPE)- To compute attention scores based on distances on the sphere rather than softmax- To rearrange local attention windows based on their estimated importance, enabling local windows to interact indirectly to increase receptive field.Through experiments, the paper aims to demonstrate that EGformer can achieve state-of-the-art depth estimation performance for equirectangular images, with high efficiency and fewer parameters compared to prior work.
