# [EGformer: Equirectangular Geometry-biased Transformer for 360 Depth   Estimation](https://arxiv.org/abs/2304.07803)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we design an efficient transformer architecture that achieves high performance for equirectangular image depth estimation? 

The key challenges are:

- Equirectangular images have a wide field of view and geometric distortion which makes convolutional networks ineffective. Transformers can handle the wide field of view through global attention, but global attention is computationally expensive.

- Local attention can be more efficient but it is challenging to apply effectively to equirectangular images due to the distortion and limited receptive field.

The main hypothesis of the paper is that the known equirectangular geometry can be used as a structural prior or bias to improve the efficiency and effectiveness of a transformer with local attention for this task.

Specifically, the paper proposes an "Equirectangular Geometry-biased Transformer" (EGformer) that uses the equirectangular geometry:

- As a bias when computing self-attention within local windows, through an Equirectangular Relative Position Embedding (ERPE)

- To compute attention scores based on distances on the sphere rather than softmax

- To rearrange local attention windows based on their estimated importance, enabling local windows to interact indirectly to increase receptive field.

Through experiments, the paper aims to demonstrate that EGformer can achieve state-of-the-art depth estimation performance for equirectangular images, with high efficiency and fewer parameters compared to prior work.


## What is the main contribution of this paper?

 The main contributions of this paper seem to be:

- Proposing an equirectangular geometry-biased transformer called EGformer for efficient and accurate 360 degree depth estimation. 

- Introducing three main components to EGformer:
   - Equirectangular relative position embedding (ERPE) to impose geometry bias within local windows.
   - Distance-based attention score (DAS) to re-weight attention scores based on distances in spherical coordinates.
   - Equirectangular-aware attention rearrangement (EaAR) to impose geometry bias between local windows.

- Demonstrating that by utilizing the known equirectangular geometry as a bias, EGformer can achieve better depth estimation performance than previous methods while having lower computational cost and fewer parameters. 

- Conducting experiments on standard 360 degree depth estimation datasets like Structured3D and Pano3D to show quantitative and qualitative improvements over prior arts.

In summary, the key contribution is using the equirectangular geometry as an explicit bias to enable efficient and accurate extraction of local attention in transformers for 360 degree depth estimation. This improves performance while reducing computational requirements compared to prior work.


## How does this paper compare to other research in the same field?

 Here are some thoughts on how this paper compares to other research in the field of 360 degree depth estimation:

- This paper focuses on using transformers and attention mechanisms for depth estimation, while much prior work has relied on CNNs and RNNs. The use of transformers is a relatively new approach in this field. 

- Compared to previous transformer-based methods like PanoFormer, this paper proposes more efficient attention mechanisms like the equirectangular-aware attention modules. This allows the model to achieve better performance with lower computational cost.

- The proposed EGformer model achieves state-of-the-art results on standard datasets like Structured3D and Pano3D, outperforming prior arts like Bifuse, SliceNet, and PanoFormer. This demonstrates the effectiveness of the proposed techniques.

- A key novelty is the use of explicit geometric priors and biases based on the equirectangular image properties in the attention modules. This allows better modeling of the distortions and characteristics of 360 degree images compared to generic attention.

- The ablation studies do a good job of isolating the improvements from the different components like ERPE, Das, and EaAR. This provides evidence that the proposed techniques contribute directly to the performance gains.

- Compared to global attention models, the local window attention allows greater efficiency and scalability. Compared to other local attention methods, the equirectangular-aware modules capture wider contexts and long-range dependencies.

In summary, the paper demonstrates state-of-the-art results by using transformer-based attention with explicit modeling of equirectangular geometry. The novel attention modules and efficiency improvements push forward the state of the art in 360 degree depth estimation.
