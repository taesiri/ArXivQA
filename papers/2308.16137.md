# LM-Infinite: Simple On-the-Fly Length Generalization for Large Language   Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How to enable transformer-based large language models (LLMs) to generalize to longer text sequences beyond what they were trained on, without requiring extensive fine-tuning or re-training?The paper identifies that current LLMs struggle with "length generalization failure" - their ability to process longer text sequences degrades rapidly when the length exceeds what they saw during pre-training. This is an important problem to solve as LLMs are being applied to more complex tasks involving longer reasoning and document understanding. The central hypothesis seems to be that the length generalization failure is caused by certain "out-of-distribution" factors that arise when LLMs process sequences much longer than training. By identifying and removing these OOD factors, their length generalization abilities can be restored without parameter updates or fine-tuning.The solutions proposed involve:1) A Lambda-shaped attention mask 2) Bounding token distances during attentionwhich aim to control the number of tokens attended and distance values to keep them in-distribution. Together these solutions are called the LM-Infinite technique.The central research question is whether LM-Infinite can enable existing LLMs to generalize to much longer sequences without degradation in fluency or task performance. The paper provides experimental results demonstrating this capability across several LLMs and datasets.
