# [CMDA: Cross-Modality Domain Adaptation for Nighttime Semantic   Segmentation](https://arxiv.org/abs/2307.15942)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we leverage both image and event modalities in an unsupervised manner to improve nighttime semantic segmentation, when only labels for daytime images are available? The key hypotheses are:1) Event cameras, with their high dynamic range, can capture more details at night compared to conventional cameras. So utilizing events along with images can improve nighttime semantic segmentation.2) The gaps between images and events, as well as between daytime and nighttime images, can be bridged by:- Extracting motion information from images to simulate events. - Extracting just the content information from images while removing style information.3) Combining images and events, with adaptations to bridge modality and domain gaps, can achieve better nighttime semantic segmentation in an unsupervised domain adaptation setting.The paper proposes a Cross-Modality Domain Adaptation (CMDA) framework to address this question and validate these hypotheses. CMDA introduces event modality to nighttime segmentation and uses an Image Motion-Extractor and Image Content-Extractor to connect images and events across domains.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel framework called Cross-Modality Domain Adaptation (CMDA) for nighttime semantic segmentation. The key highlights are:- It introduces the use of event cameras with images for nighttime semantic segmentation for the first time. Event cameras have high dynamic range and can capture more details at night compared to regular cameras. - It proposes the Image Motion-Extractor and Image Content-Extractor to bridge the gap between images and events as well as daytime and nighttime domains.- It presents a new image-event dataset for nighttime semantic segmentation evaluation by manually annotating parts of the DSEC dataset. - Experiments show the CMDA framework achieves superior performance by effectively combining the complementary modalities of images and events.In summary, the main contribution is proposing CMDA, the first cross-modality domain adaptation approach for nighttime semantic segmentation that leverages both images and events. The proposed extractors help connect the modalities and domains. Experiments verify improved performance over image-only methods.
