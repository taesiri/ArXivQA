# [Chain-of-Thought Unfaithfulness as Disguised Accuracy](https://arxiv.org/abs/2402.14897)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Recently, \citet{lanham2023measuring} proposed a metric to measure the faithfulness of chain-of-thought (CoT) explanations generated by large language models (LLMs). On a set of MCQ tasks, they found that model faithfulness exhibits a scaling then inverse-scaling trend, decreasing after models reach 13B parameters.

- This raises questions around whether this trend generalizes across LLM families or is unique to the proprietary models they evaluated. The paper examines:
  - If inverse scaling in faithfulness occurs once models become sufficiently capable, across families
  - If the drop in faithfulness happens at a similar model size of 13B parameters
  - If the optimally faithful model size depends on task difficulty

Methodology
- The authors replicate the experimental setup from \citet{lanham2023measuring} using the unfaithfulness metric, CoT prompting methods, and 8 MCQ benchmarks.

- They evaluate models from 3 openly available families: Llama 2, FLAN-T5+UL2, Pythia DPO, covering up to 70B parameters.

Key Findings
- Under certain conditions, inverse scaling trends are observed, but the onset of unfaithfulness happens before 13B parameters.

- The metric has high correlation (R^2=0.91) with accuracy for capable models, questioning its validity.  

- The trends are very sensitive to answer choice orderings. Shuffling order between CoT/no-CoT conditions can reduce scores by up to 73 percentage points.

Conclusions
- The inverse scaling trend occurs across families but does not reliably start at 13B parameters.

- The faithfulness metric correlates strongly with accuracy, reducing it to a simple accuracy measurement.

- The high sensitivity to implementation details raises doubts about the suitability of this metric to measure CoT faithfulness. The drop in scores likely stems from other confounding factors versus genuine reasoning unfaithfulness.
