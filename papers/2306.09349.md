# [UrbanIR: Large-Scale Urban Scene Inverse Rendering from a Single Video](https://arxiv.org/abs/2306.09349)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we build a model that allows realistic, free-viewpoint renderings of a scene under novel lighting conditions from a video? Specifically, the paper aims to develop a method that can:- Infer shape, albedo, visibility, and sun and sky illumination from a single video of unbounded outdoor scenes with unknown lighting.- Produce a neural scene representation that facilitates controllable editing and photorealistic renderings of relit scenes and inserted objects from arbitrary viewpoints. The key challenges are handling illumination uncertainty in outdoor scenes captured under natural lighting, and controlling errors in the inverse graphics inference process that can lead to rendering artifacts. To address these challenges, the proposed UrbanIR method introduces novel losses to refine geometry, disentangle albedo from shadows, and optimize visibility fields. This enables high-quality estimation of shadow volumes and intrinsic scene properties from monocular video.In summary, the main research question is how to enable realistic free-viewpoint rendering under novel lighting from a single video through improved inverse graphics scene decomposition and representation. The proposed UrbanIR method aims to tackle this problem for large-scale outdoor urban scenes.
