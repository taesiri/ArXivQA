# [Differentiable DAG Sampling](https://arxiv.org/abs/2203.08509)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we develop a fast, differentiable method for probabilistic modeling and sampling of DAGs that guarantees valid DAG outputs during training?The key points are:- The paper proposes a new probabilistic model over DAGs called DP-DAG that allows fast and differentiable DAG sampling. - DP-DAG samples a DAG by sampling a node ordering using Gumbel-Sinkhorn or Gumbel-Top-k, then sampling edges consistent with that ordering using Gumbel-Softmax.- This approach guarantees valid DAG outputs at any point during training, without needing complex augmented Lagrangian optimization schemes. - The paper develops VI-DP-DAG, a variational inference method that combines DP-DAG with neural networks to learn DAGs from observational data.- VI-DP-DAG approximates the posterior over DAG structures given the observed data.- Experiments show VI-DP-DAG learns high-quality DAG structures faster than existing differentiable DAG learning methods.So in summary, the main research question is how to develop a fast, differentiable, and probabilistic approach to DAG modeling and sampling that avoids issues with previous methods and enables high-quality causal learning. DP-DAG and VI-DP-DAG are proposed as solutions.
