# [OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?](https://arxiv.org/abs/2307.11636)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research goals appear to be:1) To introduce a new large-scale dataset called OxfordTVG-HIC for humor generation and understanding that helps address the lack of sufficient data for humor-related image captioning tasks.2) To develop humor captioning models trained on this new dataset and evaluate their performance using novel metrics inspired by psychological theories of humor. 3) To provide insights into what visual and linguistic cues are important for evoking humor by explaining and analyzing the trained models.Specifically, the authors aim to show that the proposed OxfordTVG-HIC dataset can enable more robust humor captioning models compared to existing small-scale datasets. They also want to demonstrate that tailored losses like their position-conditioned loss can improve caption diversity and humor compared to standard cross-entropy loss. Finally, through visualization and analysis of model attention, they seek to gain a quantitative understanding of how their models perceive and generate humor aligned with psychological theories like the Benign Violation theory.In summary, the main research goals are: 1) introducing a large-scale humor dataset 2) developing improved humor captioning models using this dataset, and 3) providing insights into humor generation/perception by explaining the models. The overarching motivation is to push towards AI's ability to handle high-level abstract concepts like humor.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper seem to be:1. Introduction of a large-scale dataset called OxfordTVG-HIC for humor-oriented image captioning. This dataset contains around 2.9 million image-text pairs with humor scores, which helps address the lack of data for training and evaluating humor generation models. 2. Development of a humor captioning model trained on the proposed dataset using a position-conditioned loss function. This loss function is designed to handle the high diversity of captions per image in the dataset.3. Analysis of the trained models to identify visual and linguistic cues that are important for humor generation and perception. The findings suggest consistency with the benign violation theory from psychology.In summary, the key contribution appears to be the creation of a large-scale dataset to enable new research into neural humor generation, along with baseline methods and analysis. The authors frame humor captioning as a useful task for evaluating abstract reasoning in AI.
