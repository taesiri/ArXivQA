# [OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?](https://arxiv.org/abs/2307.11636)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research goals appear to be:1) To introduce a new large-scale dataset called OxfordTVG-HIC for humor generation and understanding that helps address the lack of sufficient data for humor-related image captioning tasks.2) To develop humor captioning models trained on this new dataset and evaluate their performance using novel metrics inspired by psychological theories of humor. 3) To provide insights into what visual and linguistic cues are important for evoking humor by explaining and analyzing the trained models.Specifically, the authors aim to show that the proposed OxfordTVG-HIC dataset can enable more robust humor captioning models compared to existing small-scale datasets. They also want to demonstrate that tailored losses like their position-conditioned loss can improve caption diversity and humor compared to standard cross-entropy loss. Finally, through visualization and analysis of model attention, they seek to gain a quantitative understanding of how their models perceive and generate humor aligned with psychological theories like the Benign Violation theory.In summary, the main research goals are: 1) introducing a large-scale humor dataset 2) developing improved humor captioning models using this dataset, and 3) providing insights into humor generation/perception by explaining the models. The overarching motivation is to push towards AI's ability to handle high-level abstract concepts like humor.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper seem to be:1. Introduction of a large-scale dataset called OxfordTVG-HIC for humor-oriented image captioning. This dataset contains around 2.9 million image-text pairs with humor scores, which helps address the lack of data for training and evaluating humor generation models. 2. Development of a humor captioning model trained on the proposed dataset using a position-conditioned loss function. This loss function is designed to handle the high diversity of captions per image in the dataset.3. Analysis of the trained models to identify visual and linguistic cues that are important for humor generation and perception. The findings suggest consistency with the benign violation theory from psychology.In summary, the key contribution appears to be the creation of a large-scale dataset to enable new research into neural humor generation, along with baseline methods and analysis. The authors frame humor captioning as a useful task for evaluating abstract reasoning in AI.


## How does this paper compare to other research in the same field?

Here are a few key points of comparison between this paper and other related work in humour recognition and generation with vision-language models:- Dataset size and diversity: At 2.9 million image-caption pairs, the OxfordTVG-HIC dataset introduced in this paper is significantly larger and more diverse than previous humour datasets like DANK and HumorHawk. The captions have high grammatical and semantic diversity which poses new challenges.- Task formulation: This paper frames humour captioning as a distinct task from standard image captioning, with the goal being to elicit humour rather than describe factual image content. Previous work has evaluated humour generation using standard captioning metrics which may not capture humour well. - Model architecture: The authors experiment with different architectures like ClipCap and BLIP trained with a custom position-conditioned loss function. Other work has used simpler encoder-decoder models without tailoring to humour generation.- Evaluation: New humour-specific metrics are proposed based on benign violation theory and hate speech detection. Prior work relied more on linguistic metrics like BLEU, METEOR etc. which don't measure humour directly.- Explainability: Attention map and gradient visualization provides insights into how models perceive humorous cues in images and text. This analysis of what makes something funny from a model's perspective is novel.Overall, this paper pushes the boundaries of humour recognition by pretrainined vision-language models through a large-scale dataset, new task formulation, custom models and losses, humour-focused evaluation metrics, and model explainability. It represents significant progress in this challenging and relatively less explored problem space.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Applying the dataset to other humor-related tasks involving visual and linguistic modalities, such as humorous image generation guided by text or simultaneous humor-oriented image-text generation. - Exploring the cultural and linguistic differences in humor using the dataset, since it contains data collected from different cultural websites and communities. - Creating similar video-based datasets to extend the humor generation and evaluation tasks to video.- Improving the connection between the proposed humor evaluation metrics and psychological theories of humor. For example, linking the benign violation humor score more directly to benign violation theory.- Addressing the limitations mentioned in the paper, such as the potential bias in the humor classifier towards captions from the same dataset, and the indirect correlation between the dataset's funny scores and true humor intensity.- Generally improving the sophistication and nuance of the neural humor generators to better match human-generated humorous captions.In summary, the main suggested future directions are: applying the dataset to other multimodal humor tasks, analyzing cultural/linguistic aspects of humor, extending to video data, strengthening connections to psychological theory, addressing current limitations, and improving the neural humor generators. Advancing research in these areas could lead to better computational understanding and generation of humor.
