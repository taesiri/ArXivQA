# [Turning Strengths into Weaknesses: A Certified Robustness Inspired   Attack Framework against Graph Neural Networks](https://arxiv.org/abs/2303.06199)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

Can we design a general attack framework that can further enhance both existing graph evasion and poisoning attacks against graph neural networks (GNNs)?

The key hypothesis is that by leveraging properties of certified robustness (which was originally used for defense), the authors can design a more effective attack framework against GNNs. 

Specifically, the authors propose to:

1) Derive nodes' certified perturbation sizes against graph evasion and poisoning attacks using randomized smoothing. This indicates how robust each node is theoretically to graph perturbations.

2) Design a certified robustness inspired loss function that assigns larger weights to nodes with smaller certified perturbation sizes. This helps focus the attack on more vulnerable nodes. 

3) Develop a certified robustness attack framework that can enhance existing graph evasion and poisoning attacks by incorporating the certified robustness inspired loss.

The authors evaluate their framework on benchmark datasets by applying it to state-of-the-art attacks. Results validate that their framework can significantly improve existing attacks' performance against GNNs.

In summary, the central hypothesis is that leveraging properties of certified robustness can lead to more effective attacks against graph neural networks. The authors propose and evaluate an attack framework to validate this hypothesis.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- Proposing a certified robustness inspired attack framework against graph neural networks (GNNs). This framework can enhance both existing graph evasion attacks and graph poisoning attacks. 

- Deriving nodes' certified perturbation sizes against graph evasion and poisoning attacks by generalizing randomized smoothing. This allows assessing nodes' theoretical robustness to graph perturbations.

- Designing a certified robustness inspired attack loss. This modifies the standard node-wise loss by assigning weights to nodes based on their certified perturbation sizes. This results in more focus on vulnerable nodes during the attack.

- Demonstrating the effectiveness of the proposed certified robustness inspired framework by applying it to existing graph evasion and poisoning attacks like PGD and Minmax. Experiments on benchmark datasets show the enhanced performance of attacks integrated with the proposed framework.

In summary, the key contribution is a novel certified robustness inspired attack framework that can strengthen graph perturbation attacks against GNNs. The core ideas include deriving nodes' certified robustness, using it to guide attack loss design, and integrating the loss into existing attack methods. Evaluations validate the improvement in attack effectiveness due to the proposed techniques.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points in this paper:

This paper proposes a new attack framework for adversarial attacks against graph neural networks that is inspired by certified robustness and aims to reverse engineer its properties to identify and target more vulnerable nodes in order to achieve higher attack success.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other research on adversarial attacks against graph neural networks:

- It proposes a new attack framework inspired by certified robustness. Most prior work has focused on designing new attack methods, but this paper takes a novel approach of leveraging certified robustness, which was originally proposed for defending models, to create more effective attacks. 

- It generalizes certified robustness to graph poisoning attacks. Prior work on certified robustness for graphs has focused on evasion attacks. This paper extends the theory to derive certified robustness against poisoning attacks as well.

- The attack framework is model-agnostic. The proposed certified robustness loss can be incorporated into any existing attack method for both evasion and poisoning attacks. This makes the framework widely applicable.

- It evaluates the framework by applying it to state-of-the-art attack methods like PGD attack and Metattack. Results show the framework can enhance existing attack performance.

- It provides both theoretical analysis and empirical evaluations of the approach. Theoretical connections are made between certified robustness and effective attacks, and experiments on real-world graphs validate the analysis.

Overall, this paper offers a novel perspective on how certified robustness can be leveraged to create stronger rather than defend against attacks. The model-agnostic certified robustness inspired framework allows improving existing attack methods, which is demonstrated through comprehensive experiments. It expands the scope of certified robustness and represents an important direction for future work on adversarially robust graphs.
