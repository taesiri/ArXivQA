# [Joint Visual Grounding and Tracking with Natural Language Specification](https://arxiv.org/abs/2303.12027)

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the central research question this paper tries to address is:How to jointly perform visual grounding and tracking for the task of tracking by natural language specification in an end-to-end framework? The key points are:1) Existing methods separate the visual grounding and tracking steps, using independent models for each. This overlooks the connections between the two steps. 2) The paper proposes a joint visual grounding and tracking framework that unifies the two tasks into a single end-to-end model. 3) The core of their framework is a multi-source relation modeling module that can accommodate the different references (language, template image) used in grounding and tracking.4) They also propose a semantic-guided temporal modeling module to exploit historical target states and improve adaptation to appearance changes.5) Experiments show their joint framework achieves favorable performance on both tracking and grounding benchmarks compared to state-of-the-art separated methods.In summary, the central hypothesis is that joint modeling of grounding and tracking in an end-to-end manner can improve performance on tracking by natural language specification. Their proposed framework and modules aim to validate this hypothesis.
