# [ICICLE: Interpretable Class Incremental Continual Learning](https://arxiv.org/abs/2303.07811)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we develop an interpretable approach to class-incremental learning that reduces catastrophic forgetting while maintaining consistent explanations over time?The key points are:- The paper proposes a new method called Interpretable Class-Incremental Learning (ICICLE) for incremental learning of new classes without forgetting previous ones. - ICICLE is based on prototypical parts, which are interpretable by design. This allows the model to provide explanations through prototype-based reasoning.- A core challenge is that the rationale behind model predictions can change over time as new classes are learned, leading to "interpretability concept drift". This makes explanations inconsistent. - To address this, ICICLE incorporates several mechanisms:  - Interpretability regularization to distill old concepts while allowing new learning  - Proximity-based prototype initialization to leverage previous prototypes  - Task-recency bias compensation to balance prototype importance- Experiments show ICICLE reduces interpretability drift and outperforms baseline continual learning methods on standard benchmarks. So in summary, the main hypothesis is that an interpretable class-incremental learner based on prototypes can be developed that maintains consistent explanations while reducing catastrophic forgetting. The paper introduces ICICLE to test this hypothesis.
