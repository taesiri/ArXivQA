# [GIVL: Improving Geographical Inclusivity of Vision-Language Models with   Pre-Training Methods](https://arxiv.org/abs/2301.01893)

## What is the central research question or hypothesis that this paper addresses?

This paper proposes GIVL, a geographically inclusive vision-language pre-trained model, to address the issue of geographical bias in existing vision-language pre-trained models (VLPs). The key hypothesis is that by pre-training VLPs on a geographically diverse image dataset along with novel pre-training objectives, the models can learn to better understand visual concepts and knowledge from different regions of the world. This should lead to improved performance and more balanced accuracy across images from Western vs non-Western regions on downstream geo-diverse vision-language tasks.The main research questions addressed are:1) How can we construct a geographically diverse pre-training corpus to provide images depicting concepts from diverse regions? 2) What novel pre-training objectives can encourage the model to learn alignments between geo-diverse images and corresponding textual knowledge during pre-training?3) Will the proposed model, GIVL, achieve better performance on geo-diverse vision-language tasks compared to prior VLPs? Can it obtain more balanced accuracy on Western vs non-Western test data?4) Can GIVL still achieve competitive performance on common vision-language tasks, demonstrating its generalizability?To summarize, the central hypothesis is that with a geographically diverse pre-training corpus and objectives aimed at aligning images and knowledge, GIVL can learn improved representations to understand concepts from different world regions. This should lead to state-of-the-art and more equitable performance on downstream geo-diverse vision-language tasks.
