# [Contextual Restless Multi-Armed Bandits with Application to Demand   Response Decision-Making](https://arxiv.org/abs/2403.15640)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
The paper addresses the challenge of making sequential decision under uncertainty in many real-world applications such as demand response management in smart grids. Specifically, in such problems, there are multiple arms/agents (e.g. users with flexible loads) that have individual internal states and state transition dynamics. Additionally, there are external environmental factors, termed global contexts (e.g. temperature, electricity prices), that influence the state transitions and rewards of the arms over time. Existing works on restless bandits can model arm state transitions but do not account for contextual influence. Contextual bandits methods model the impact of contexts but treat arms as context-free. Hence, this paper introduces the Contextual Restless Bandits (CRB) framework to concurrently model both the internal arm state transitions and the external global contexts.

Proposed Solution:
The paper develops the CRB model formulation where each arm is a context-augmented Markov decision process (MDP) and the global context evolves as a Markov chain. A scalable index policy is proposed to solve the CRB by using dual decomposition and subproblem decomposition. This index policy selects arms based on indices calculated from the relaxed CRB problem. The index indicates the benefit of activating an arm. For unknown arm models, an online reinforcement learning algorithm is developed to estimate model parameters and derive index policy simultaneously.  

Main Contributions:
1) Proposes the novel CRB framework that integrates both restless bandits and contextual bandits features for enhanced modeling capability.

2) Develops the index policy algorithm to solve CRB problems and establishes its asymptotic optimality theoretically.

3) Further designs an online learning algorithm when arm models are unknown.  

4) Applies the CRB model and algorithms specifically to the demand response management problem in smart grid systems. Simulations demonstrate efficiency of the index policy, its asymptotic optimality, and superiority over traditional restless bandits approaches.
