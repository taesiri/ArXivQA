# [Aligning Bag of Regions for Open-Vocabulary Object Detection](https://arxiv.org/abs/2302.13996)

## What is the central research question or hypothesis that this paper addresses?

 The central research question addressed in this paper is: How can we better leverage the knowledge of rich and unseen categories from pre-trained vision-language models (VLMs) to improve open-vocabulary object detection (OVD)?

The key hypothesis is that VLMs have implicitly learned the inherent compositional structure of multiple semantic concepts from massive image-text pairs. Aligning the embedding of bag of regions, instead of just individual regions, with VLMs can help the detector learn this compositional structure and scene-level context to improve OVD performance, especially on novel categories.

To summarize, the core ideas are:

- VLMs capture compositional semantic structure due to pre-training on image-text pairs containing multiple concepts.

- Aligning bag-of-regions embeddings with VLMs teaches the detector this compositional structure.

- This improves OVD, especially on novel categories, by providing scene-level context.

The proposed BARON method implements this idea by forming bags of contextually related regions, obtaining their joint embeddings, and aligning with frozen VLMs using contrastive learning. Experiments show BARON outperforms previous SOTA methods on OV-COCO and OV-LVIS benchmarks.
