# [RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal   LLM Agents](https://arxiv.org/abs/2402.03610)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Recent advances have enabled the use of Large Language Models (LLMs) as agents for complex decision-making applications like robotics, gaming, and API integration. However, the ability to leverage past experiences during current decision-making, an innate human skill, remains a significant challenge for these models. 

Proposed Solution:
The authors propose Retrieval-Augmented Planning (RAP), a novel framework to enhance LLM agents' planning capacities by retrieving and utilizing relevant past experiences. 

Key aspects:
- RAP stores logs of prior successful task executions in a memory bank, including context, actions taken, and observations.

- For a new task instance, RAP selectively retrieves the most relevant memory samples based on similarity of context. This provides vital environmental knowledge to inform the agent's planning.

- The retrieved experiences are provided as additional context to the LLM agent before action generation. This allows in-context learning to derive smarter actions grounded in relevant prior executions.

- RAP handles both text-only and multimodal observations, making it versatile across different environments. For embodied tasks, it can leverage visual perceptions in memory retrieval.

Main Contributions:
- Proposes RAP, a novel planning framework for LLM agents that strategically utilizes relevant experiences from memory to enhance reasoning.

- Achieves state-of-the-art performance across textual benchmarks like ALFWorld and Webshop. Outperforms prior approaches by 13-33\% on task success metrics.

- Demonstrates RAP enables memory-augmented planning for multimodal LLM agents in simulated robotics tasks. Boosts success rates by 13-18\% over baseline embodied agents.

- First framework enabling memory retrieval techniques for multimodal agent's planning, pioneering effort in this domain.

- Showcases RAP's potential in advancing LLM agent functionality for complex, real-world decision-making applications.
