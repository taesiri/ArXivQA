# [Domain Invariant Adversarial Learning](https://arxiv.org/abs/2104.00322)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central hypothesis is that enforcing a domain-invariant feature representation can improve the tradeoff between robustness and standard accuracy in adversarial training. Specifically, the authors propose a new adversarial training method called "Domain Invariant Adversarial Learning" (DIAL) that incorporates ideas from domain-adversarial neural networks (DANN) into the adversarial training process. The key ideas are:- View the natural examples as the source domain and corresponding adversarial examples as the target domain.- Add a domain classifier alongside the main classification network. The goal is to learn a feature representation that cannot discriminate between natural vs. adversarial domains.- This is achieved by adversarial training on the domain classifier - maximizing the loss to incorrectly classify domains. - Intuitively, making the features invariant to domains will make the model more robust to adversarial perturbations.The central hypothesis is that enforcing such domain-invariant representations during adversarial training will allow improving both robustness and standard accuracy compared to prior adversarial training methods. The results on MNIST, CIFAR-10/100, and SVHN seem to validate this hypothesis.In summary, the key novelty is in using DANN-style adversarial training on domains to learn invariant features, rather than just improving the classification loss. This regularizer allows improving upon the typical robustness vs accuracy tradeoff.
