# [How to Backdoor Diffusion Models?](https://arxiv.org/abs/2212.05400)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How to effectively implant backdoors into diffusion models? 

Specifically, the authors propose a novel attack framework called "BadDiffusion" to engineer compromised diffusion processes during model training for backdoor implantation. The key hypothesis is that by maliciously modifying both the training data and the forward/backward diffusion steps, the proposed BadDiffusion approach can train a backdoored diffusion model that achieves two main attack objectives:

1. High utility: The backdoored model has similar performance to a clean (untampered) diffusion model on regular inputs.

2. High specificity: The backdoored model exhibits a specific targeted behavior when a trigger pattern is present in the input.

The paper aims to demonstrate that BadDiffusion can successfully create backdoored diffusion models with high attack effectiveness, measured by utility and specificity. The findings suggest potential security risks of diffusion models being compromised via backdoor attacks.

In summary, the central research question is how to effectively backdoor diffusion models, and the key hypothesis is that the proposed BadDiffusion attack framework can achieve this by jointly tampering with the training data and diffusion processes. The attack effectiveness is evaluated through quantitative metrics on model utility and specificity.
