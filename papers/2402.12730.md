# [UMBCLU at SemEval-2024 Task 1A and 1C: Semantic Textual Relatedness with   and without machine translation](https://arxiv.org/abs/2402.12730)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- The paper focuses on SemEval 2024 Task 1 to build models for identifying semantic textual relatedness (STR) between sentence pairs for African and Asian languages. 
- Currently there is a lack of sentence relatedness datasets and relatedness is often limited to similarity. The task aims to develop STR models and resources for several languages.

Proposed Solution: 
- The authors explore supervised (Subtask A) and cross-lingual (Subtask C) training approaches.  
- For Subtask A, they translate sentences to English and train a unified model using sentence embeddings. This TranSem model allows finding STR between sentences from different languages.
- For Subtask C, they fine-tune T5 models (FineSem) on the English STR dataset and evaluate cross-lingual transferability.

Main Contributions:
- Explore if a single unified STR model can be trained on translations to English
- Evaluate machine translation quality by comparing performance to an English dataset
- Explore transfer learning from English STS task to other languages using T5 models

Key Results:
- For Subtask A, TranSem model beats baseline for 3 languages and is on par for 4 other languages
- For Subtask C, FineSem gets top ranks for Afrikaans, Indonesian and English but struggles with other languages

The paper provides useful analysis of different model training strategies for textual semantic relatedness in multiple languages.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper describes two systems developed for the SemEval-2024 shared task on semantic textual relatedness for African and Asian languages - one using machine translation and sentence embeddings for the supervised track and another fine-tuning T5 models on the English STR dataset for the cross-lingual track.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1. The authors explore if a single unified model can be trained based on translations of the source language sentences into English using machine translation.

2. They explore the use of translation models for augmenting the training data by creating 4 translated datasets for each language. 

3. They explore whether a T5 model fine-tuned on the English STR dataset can work well for the target languages in the cross-domain setting of Subtask C.

So in summary, the main contributions relate to exploring machine translation and transfer learning techniques for developing semantic textual relatedness models for multiple languages in a low-resource setting. The authors examine both a translation-based approach and a cross-lingual transfer learning approach.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Semantic textual relatedness (STR) - The main task the paper is addressing, which involves identifying the degree of semantic relatedness between two sentences.

- SemEval-2024 Task 1 - The shared task that this paper was written for, with a focus on STR for African and Asian languages.

- Supervised training (Subtask A) - One of the subtasks, involving training models on labeled STR data. 

- Cross-lingual training (Subtask C) - Another subtask, involving transfer learning from English labeled data to other languages.

- Machine translation - Used in the Subtask A model to translate sentences to English before computing relatedness. Models from "No Language Left Behind" project were used.

- Sentence embeddings - Encodings of sentences used to compute the semantic relatedness. DistilRoberta model was used.

- Siamese network architecture - The model architecture used where two sentence encoders with tied weights encode the pair of sentences.

- T5 model - A text-to-text Transformer model fine-tuned on the STS benchmark dataset for the Subtask C model.

- Contrastive experiments - Comparisons of different models, translation methods, sentence pooling techniques, etc.

Let me know if you need any clarification or have additional questions!


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes two models, TranSem and FineSem. What are the key differences in the model architecture and training methodology between these two models? 

2. In the TranSem model, the authors use machine translation to translate the sentences to English before computing sentence embeddings. What are some potential issues with relying on machine translation, especially for low resource languages? How could this impact performance?

3. For the TranSem model, the authors experiment with different encoding models like DistilRoberta and pooling techniques like mean pooling. Based on the results, what seems to work best and why might certain approaches be better suited for this task? 

4. The FineSem model leverages transfer learning from English STS models. However, performance varies significantly across languages. What factors might explain why the transfer works well for some languages but not others?  

5. The paper mentions trying different sized T5 models for FineSem, but results are only shown for T5-XL. What benefits might larger T5 models provide? What challenges might they introduce?

6. Both models underperform on certain languages. What analysis is provided in the paper regarding the potential reasons behind poor performance for some languages? What additional analysis could be done?  

7. For the TranSem modelâ€™s translation component, what other translation methods could be explored beyond the NLLB models used in the paper? What are some recent advances in multilingual translation that could be applicable?

8. The FineSem model relies solely on the English STS dataset before fine-tuning on target languages. What other transfer learning approaches could be taken to better adapt to the target languages? 

9. Both models are supervised, but the authors mention an unsupervised subtask B that they did not participate in. What unsupervised methods could be promising for this semantic textual similarity task? 

10. The paper mentions some societal biases that could be present in the models and datasets. What steps could the authors take to measure or mitigate some of these biases? What cautions should be taken if deploying these models in real-world applications?
