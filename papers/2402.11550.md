# [LongAgent: Scaling Language Models to 128k Context through Multi-Agent   Collaboration](https://arxiv.org/abs/2402.11550)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like GPT-4 and LLaMA have limited context windows during pre-training (e.g. 4K tokens), which causes severe performance degradation when processing long texts exceeding this length. This significantly limits their effectiveness for tasks like querying books, legal documents, etc.
- Existing methods to expand context window like positional encoding manipulation or recurrent structures have downsides like losing long-term dependencies or valuable contextual information.

Proposed Solution: 
- The paper proposes LongAgent, a novel method to handle long texts through multi-agent collaboration. 
- An agent team is constructed with a Leader agent and many Member agents. The long text is split into chunks and each Member processes one chunk.
- The Leader coordinates Members to gather information from chunks and reasons answers to user queries. It organizes discussions among Members, identifies conflicting responses, and resolves them through inter-member communication.

Key Contributions:
- Proposes LongAgent to effectively scale LLMs to process texts longer than 100K tokens through multi-agent collaboration
- Develops an inter-member communication mechanism to alleviate hallucinations and conflicting responses from Members
- Constructs a more comprehensive benchmark, Needle-in-a-Haystack PLUS, to evaluate long-text capabilities
- Experimental results show LongAgent built on LLaMA-7B significantly outperforms GPT-4 in tasks like long-text QA, retrieval over lengths from 1K to 128K tokens.

In summary, the paper introduces a promising approach LongAgent to handle long texts through agent collaboration, and demonstrates its potential to surpass state-of-the-art models like GPT-4. The method, benchmark and analyses provide valuable insights on improving LLMs for long-text processing.
