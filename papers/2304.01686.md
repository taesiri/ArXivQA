# [HyperCUT: Video Sequence from a Single Blurry Image using Unsupervised   Ordering](https://arxiv.org/abs/2304.01686)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: How can we train a model to recover a video sequence from a single blurry image, when there is inherent ambiguity in the ordering of the recovered frames?The key points are:- Image-to-video deblurring (recovering a sharp video from a blurry image) is an important and challenging task. - A major issue is the ambiguity in the ordering of the recovered frames, since both forward and reverse sequences are valid solutions given the blurry input.- Existing methods rely on order-invariant losses during training, but this does not fully resolve the issue.- This paper proposes a new method called HyperCUT to assign an explicit ordering to the recovered sequences, avoiding the ambiguity problem. - HyperCUT maps sequences to a latent space such that forward and reverse sequences are separable by a hyperplane. The side of this "HyperCUT" hyperplane defines the sequence order.- This allows imposing constraints during training to produce sequences following a consistent order.- They also introduce a new real-image dataset called RB2V for this task, across three domains (street, face, hand).In summary, the key hypothesis is that assigning an explicit ordering to recovered sequences can help train better models for the ambiguous image-to-video deblurring task. The HyperCUT method is proposed to achieve this.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes HyperCUT, a new method to solve the order ambiguity issue in image-to-video deblurring (blur2vid). 2. It introduces a new real image dataset called Real blur2vid (RB2V) for image-to-video deblurring. This is the first real and large-scale dataset for this task.3. It demonstrates two potential real-world applications of image-to-video deblurring - recovering facial and hand trajectories from blurry images.To summarize, the key contribution is the HyperCUT method to address the order ambiguity problem in blur2vid using an unsupervised ordering scheme. It maps video sequences to a high dimensional space such that the sequence and its reverse are separable by a hyperplane. This allows assigning an explicit order to each sequence, avoiding the ambiguity issue. The paper also contributes a new real image blur2vid dataset and shows applications in motion tracking.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes HyperCUT, an unsupervised ordering scheme that assigns each video sequence an explicit ordering label to solve the ambiguity issue in image-to-video deblurring, and introduces a new real-image dataset called RB2V with street, face and hand categories for this task.
