# [HyperCUT: Video Sequence from a Single Blurry Image using Unsupervised   Ordering](https://arxiv.org/abs/2304.01686)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: How can we train a model to recover a video sequence from a single blurry image, when there is inherent ambiguity in the ordering of the recovered frames?The key points are:- Image-to-video deblurring (recovering a sharp video from a blurry image) is an important and challenging task. - A major issue is the ambiguity in the ordering of the recovered frames, since both forward and reverse sequences are valid solutions given the blurry input.- Existing methods rely on order-invariant losses during training, but this does not fully resolve the issue.- This paper proposes a new method called HyperCUT to assign an explicit ordering to the recovered sequences, avoiding the ambiguity problem. - HyperCUT maps sequences to a latent space such that forward and reverse sequences are separable by a hyperplane. The side of this "HyperCUT" hyperplane defines the sequence order.- This allows imposing constraints during training to produce sequences following a consistent order.- They also introduce a new real-image dataset called RB2V for this task, across three domains (street, face, hand).In summary, the key hypothesis is that assigning an explicit ordering to recovered sequences can help train better models for the ambiguous image-to-video deblurring task. The HyperCUT method is proposed to achieve this.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes HyperCUT, a new method to solve the order ambiguity issue in image-to-video deblurring (blur2vid). 2. It introduces a new real image dataset called Real blur2vid (RB2V) for image-to-video deblurring. This is the first real and large-scale dataset for this task.3. It demonstrates two potential real-world applications of image-to-video deblurring - recovering facial and hand trajectories from blurry images.To summarize, the key contribution is the HyperCUT method to address the order ambiguity problem in blur2vid using an unsupervised ordering scheme. It maps video sequences to a high dimensional space such that the sequence and its reverse are separable by a hyperplane. This allows assigning an explicit order to each sequence, avoiding the ambiguity issue. The paper also contributes a new real image blur2vid dataset and shows applications in motion tracking.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes HyperCUT, an unsupervised ordering scheme that assigns each video sequence an explicit ordering label to solve the ambiguity issue in image-to-video deblurring, and introduces a new real-image dataset called RB2V with street, face and hand categories for this task.


## How does this paper compare to other research in the same field?

This paper presents a novel method for addressing the order ambiguity issue in image-to-video deblurring. Here is a summary of how it relates to other recent work in this field:- The order ambiguity problem in image-to-video deblurring was first identified by Jin et al. (2018). They proposed using an order-invariant loss to mitigate this issue. However, as this paper points out, the order-invariant loss does not fully resolve the ambiguity. - Purohit et al. (2019) and Pan et al. (2019) also proposed image-to-video deblurring methods based on recurrent architectures. However, they did not explicitly address the order ambiguity problem.- Zhong et al. (2022) converted the ill-posed image-to-video problem into a nearly deterministic one using motion guidance as additional input. However, this method relies heavily on the quality of the estimated motion guidance.- In contrast, this paper proposes HyperCUT, which assigns an explicit temporal order to each video sequence. This avoids the order ambiguity issue without relying on motion estimation or loss design. The core idea of mapping sequences to a latent space is novel.- The proposed RealBlur2Vid dataset is also a key contribution, as it provides real training data for this task. Previous datasets were synthetic.In summary, this paper makes significant advances over prior art by directly addressing the order ambiguity problem through a creative latent space mapping approach. The results demonstrate clear improvements in video deblurring quality compared to existing methods. The real dataset is also an important community contribution. This work moves the field forward in generating sharp video from a single blurry photo.


## What future research directions do the authors suggest?

The authors suggest a few potential future research directions at the end of the paper:- Adapting HyperCUT for handling complex movements and long exposure blur. The current method focuses on standard motion blur with consistent direction and velocity. Extending it to handle more complex blur would be interesting.- Exploring other potential applications of image-to-video deblurring besides face and hand tracking demonstrated in this paper. The ability to recover object motion from a single blurry image could benefit other applications as well.- Improving the quality and diversity of real-world image-to-video deblurring datasets. While this paper introduces a new real dataset (RB2V), collecting more real blurry/sharp sequence pairs covering diverse scenarios would help advance research in this direction. - Investigating other self-supervised approaches to solve the order ambiguity problem without relying on explicit ordering labels. The key contribution here is the use of HyperCUT to assign explicit ordering, but other techniques may be possible.- Extending the approach to handle video input instead of just a single blurry image. Recovering a sharp video from a blurry video could be useful for some applications.In summary, the main future directions are around handling more complex blur, exploring new applications, improving datasets, investigating new techniques to address order ambiguity, and extending to video input. Overall the paper lays out an interesting new task and approach, while highlighting many possibilities for future work in this area.


## Summarize the paper in one paragraph.

The paper proposes a method for image-to-video deblurring, which aims to recover a sequence of sharp frames from a single blurry image. The key challenge is the ambiguity in the ordering of the recovered sharp frames, as both forward and backward sequences are valid solutions. The main contribution is a self-supervised framework called HyperCUT to impose an ordering on the recovered sequences. Specifically, they train a function to map sequences into a high-dimensional space such that the feature vectors for a sequence and its reverse are separable by a hyperplane. The side of this hyperplane is then used to assign an order label to sequences during training, forcing the deblurring model to generate videos following this order.Experiments are conducted on synthetic and real image datasets. Results show that HyperCUT helps resolve the ordering ambiguity issue and leads to improved image quality, especially for the end frames. The paper also contributes a new real image dataset for image-to-video deblurring covering street, face and hand categories. Potential applications in face and hand tracking are demonstrated.
