# [CounterCurate: Enhancing Physical and Semantic Visio-Linguistic   Compositional Reasoning via Counterfactual Examples](https://arxiv.org/abs/2402.13254)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Current large multimodal models like CLIP and LLaVA perform poorly on compositional reasoning tasks that require understanding physical relationships (e.g. left/right, up/down, counting) between objects in an image or complex semantic relationships between concepts.

- Existing methods for improving compositional reasoning have limitations:
    - Focus only on semantic reasoning, neglect physically grounded reasoning
    - Use rule-based approaches to generate counterfactual examples which are not sufficiently challenging

Proposed Solution:
- Introduce CounterCurate, a framework to improve physical and semantic reasoning via counterfactual examples
- Generate challenging counterfactual images and captions using state-of-the-art generative models like GPT-4V, DALLE-3 and GLIGEN 

- Physically Grounded Reasoning:
    - Curate datasets testing left/right, up/down, counting understanding between objects
    - Use horizontal flipping, GLIGEN bounding box manipulation to generate counterfactual images
    
- Semantic Reasoning:  
    - Use GPT-4V to generate changed noun, adjective, swapped phrase counterfactual captions 
    - Use DALLE-3 to generate corresponding counterfactual images

- Fine-tune CLIP and LLaVA models on these counterfactual datasets 

Key Contributions:
- First framework to improve both physical and semantic compositional reasoning for multimodal models
- Showcases poor performance of CLIP, LLaVA on new position and counting datasets
- Significantly boosts performance via counterfactual training - up to 33-37% gains
- Surpasses prior state-of-the-art like GPT-4V on semantic reasoning benchmarks
- Provides code, datasets and models to facilitate future research
