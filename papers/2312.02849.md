# [Algorithms for mean-field variational inference via polyhedral   optimization in the Wasserstein space](https://arxiv.org/abs/2312.02849)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key contributions in this paper:

This paper develops a novel framework for optimizing over polyhedral subsets of the Wasserstein space of probability measures. Leveraging the notion of compatibility from optimal transport theory, the authors construct families of parameterized measures that induce a Riemannian geometry equivalent to a Euclidean geometry on the parameter space. This equivalence enables the application of scalable first-order optimization algorithms with convergence guarantees. As a key application, the authors provide the first end-to-end computational guarantees for mean-field variational inference, a widely used technique in statistical machine learning. Under standard regularity assumptions, they construct an explicit approximation scheme based on piecewise polynomials that allows the mean-field variational optimization problem to be solved over a polyhedral set using accelerated first-order methods, with a near-optimal iteration complexity that adapts to the conditioning of the posterior distribution. The modular framework developed in this paper paves the way for further applications of polyhedral optimization over probability measures in machine learning.
