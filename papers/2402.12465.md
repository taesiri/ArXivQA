# [Neuro-mimetic Task-free Unsupervised Online Learning with Continual   Self-Organizing Maps](https://arxiv.org/abs/2402.12465)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper tackles the problem of catastrophic forgetting in continual learning systems. Specifically, it examines forgetting in unsupervised architectures like self-organizing maps (SOMs). SOMs could potentially mitigate forgetting due to their sparse representations, but the authors empirically observe that fixed-size SOMs still experience substantial forgetting when processing continuous data streams. Thus, new methods are needed to reduce interference in SOMs for continual unsupervised learning.

Solution: 
The authors propose a generalization of SOMs called Continual SOMs (CSOMs) to enable online unsupervised learning with reduced forgetting. The CSOM maintains additional parameters for each neuron - a running variance vector and individual dynamic radius and learning rate per neuron. The per-neuron radius and learning rate decay as a function of how often a neuron gets selected as the Best Matching Unit (BMU). Distance calculation in CSOM uses these running variance vectors to better allocate under-trained neurons to new classes. This localizes synaptic changes to relevant neurons. The specialized distance metric balances stability to retain prior knowledge while enabling plasticity to learn new classes.

Contributions:
The key contributions are:
(1) Adapting the classical SOM model to the continual learning setting and empirically demonstrating that fixed-size SOMs suffer from catastrophic forgetting.
(2) Proposing the Continual SOM model which significantly mitigates forgetting through per-neuron running variances, radii and learning rates.
(3) Evaluating CSOMs on MNIST, FashionMNIST, KMNIST and CIFAR-10, showing close to 2x test accuracy gains over classical SOMs. CSOMs also beat or match state-of-the-art on (online) unsupervised class-incremental learning on these datasets.

Overall, the paper makes useful progress on mitigating catastrophic forgetting in unsupervised neural systems through the proposed CSOM model and evaluations demonstrating reduced interference in continual learning settings.
