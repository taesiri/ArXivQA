# [LM-Combiner: A Contextual Rewriting Model for Chinese Grammatical Error   Correction](https://arxiv.org/abs/2403.17413)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Over-correction is a critical issue in Chinese grammatical error correction (CGEC). Recent methods using model ensemble can mitigate over-correction but require multiple system outputs, leading to reduced recall. There is a need for a method that can alleviate over-correction from a single system while maintaining high recall.

Method:
The paper proposes LM-Combiner, an LM-based contextual rewriting model. It takes the original sentence and a single GEC system output as input. It is trained on an over-correction dataset constructed by a proposed k-fold cross inference method. This allows it to learn to generate corrected sentences by combining parts of the original and over-corrected sentences.  

In training, candidate over-corrected sentences are obtained by k-fold cross-validation style inference. Gold edits are merged into the candidates to fully decouple correction from rewriting. In inference, LM-Combiner directly rewrites the GEC system output conditioned on the original sentence.

Contributions:
- Proposes LM-Combiner, which mitigates over-correction without model ensembling, improving precision substantially (+18.2) while maintaining recall.
- Introduces k-fold cross inference to construct in-domain over-correction data from existing corpora. 
- Shows LM-Combiner is lightweight, achieving good performance even with small models and little data.
- Provides an inexpensive solution to alleviate over-correction for black-box GEC systems.

Overall, the paper makes notable contributions in tackling the key CGEC challenge of over-correction via a simple but effective rewriting approach. The proposed methods enable precision gains unmatched by prior work without sacrificing recall.
