# [Punctuation Matters! Stealthy Backdoor Attack for Language Models](https://arxiv.org/abs/2312.15867)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Existing textual backdoor attacks insert trigger words/sentences or modify syntax, making them detectable. They lack stealthiness and can alter original meaning.  

Proposed Solution:
- Propose PuncAttack, using combinations of punctuation marks as triggers to replace original ones. Triggers are inconspicuous but help model learn to associate them with target labels.

- Use BERT's masking and prediction to select optimal positions to replace punctuation combinations based on prediction confidence. Improves stealthiness.

- For text classification, replace punctuation combinations and set target label. For QA, wrap target sentence with punctuation triggers and set word in wrapped sentence as answer.

Main Contributions:
- First to use inconsecutive punctuation combinations as backdoor triggers for textual attacks.

- Leverage BERT masking and prediction to strategically select locations to place triggers based on fluency.

- Evaluate on text classification (AG's News, Jigsaw, IMDb datasets) and QA (SQuAD dataset). Shows high attack success rate and stealthiness.

- Extensive experiments demonstrate effectiveness against BiLSTM, BERT and RoBERTa models on multiple datasets. Attack success rates mostly above 95% and stealthiness better than other methods.

- Overall, proposes stealthier textual backdoor attack using punctuation combinations and masking strategy to place triggers. Evaluated extensively.
