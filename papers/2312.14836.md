# [Learning Lagrangian Multipliers for the Travelling Salesman Problem](https://arxiv.org/abs/2312.14836)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The traveling salesman problem (TSP) is a classic NP-hard combinatorial optimization problem with many practical applications. Exact solvers for TSP like branch-and-bound require good dual bounds to prune the search space and prove optimality. The Held-Karp relaxation is a commonly used approach to generate strong Lagrangian dual bounds for TSP. However, the conventional process of iteratively deriving good Lagrangian multipliers is computationally intensive, limiting its practicality for large or time-sensitive TSP instances. 

Proposed Solution:
This paper proposes an innovative unsupervised learning approach to predict accurate Lagrangian multipliers for the Held-Karp TSP relaxation. The core ideas are:

1) Train a graph neural network (GNN) model in an unsupervised manner to predict node-based Lagrangian multipliers given a TSP instance graph.

2) Use the predicted multipliers to warm start the Held-Karp relaxation process and generate tight dual bounds.

3) Integrate these bounds within a branch-and-bound TSP solver to enhance the filtering/pruning process.

The key novelty is the unsupervised training process which directly maximizes the Held-Karp relaxation bound by differentiating through the entire combinatorial optimization process. This is achieved by carefully deriving gradients wrt the Lagrangian multipliers.

Contributions:

- Novel learning formulation to warm start a combinatorial optimization relaxation process 
- Integrates unsupervised deep learning, combinatorial optimization and mathematical programming
- Reduces optimality gap of unfinished TSP instances by 50%
- Cuts solving time of finished TSP instances by 10% 
- Enhances filtering percentage of a global constraint for TSP
- Evaluated on various metric TSP benchmark datasets

The proposed ideas open up new research directions at the intersection of combinatorial optimization and deep learning. The methodology also has practical benefits for companies solving large-scale routing problems on a regular basis.
