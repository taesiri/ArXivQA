# [Boosting Long-tailed Object Detection via Step-wise Learning on   Smooth-tail Data](https://arxiv.org/abs/2305.12833)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be: 

How can we improve object detection performance on long-tailed datasets, where there is an extreme imbalance between the number of examples from different classes?

The key hypothesis seems to be:

A step-wise learning approach of pre-training, fine-tuning on head classes, and knowledge transfer to tail classes can gradually improve detection accuracy on all classes in a long-tailed distribution.

Specifically, the key aspects appear to be:

- Pre-train on the full long-tail dataset to learn discriminative representations between all classes. 

- Fine-tune only the class-specific modules on a head class dominant dataset to get a "head expert" focused on head classes.

- Transfer knowledge from the "head expert" to a "unified" model trained on tail-dominant data, using techniques like feature distillation and shared predictions.

- Use "smooth-tail" data, re-sampled to be less imbalanced, at each stage to alleviate forgetting and bias issues.

The central hypothesis is that this step-wise approach can unify fine-tuning and knowledge transfer to obtain a model with strong performance on both head and tail classes from an imbalanced distribution.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- Proposing a step-wise learning framework to gradually enhance the capability of models for detecting all categories in long-tailed datasets. 

- Building "smooth-tail" data where the long-tail distribution decays smoothly to correct bias towards head classes. A model is pre-trained on the whole long-tailed data to preserve discriminability.

- Proposing a confidence-guided exemplar replay scheme to build head class dominant and tail class dominant datasets.

- Fine-tuning the pre-trained model on the head class dominant data to get an expert model focused on head classes.

- Training a unified model on the tail class dominant data while transferring knowledge from the head class expert model to ensure detection accuracy on all categories.

- Achieving state-of-the-art performance on the LVIS v0.5 and LVIS v1.0 long-tailed object detection benchmarks, especially improving accuracy on rare categories.

In summary, the main contribution appears to be the novel step-wise learning framework that combines fine-tuning and knowledge transfer on smooth-tail data to enhance long-tailed object detection performance.
