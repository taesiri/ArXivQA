# [`Keep it Together': Enforcing Cohesion in Extractive Summaries by   Simulating Human Memory](https://arxiv.org/abs/2402.10643)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Extractive summaries usually lack cohesion as they are just concatenations of sentences. Previous work has focused more on controlling for informativeness and redundancy.
- Cohesion relies on explicit textual connections called "cohesive ties" between concepts, which makes a text read as a unified whole.

Proposed Solution:
- A summarization pipeline that has two control mechanisms - one to control redundancy during input text understanding, and another to control the tradeoff between informativeness and cohesion during summary extraction.
- The input text is split into blocks which are selected iteratively based on relevance and redundancy with already selected blocks. This reduces redundancy for the later modules.
- Sentences are then selected incrementally to build the summary by balancing informativeness score from an encoder model and cohesion score from a separate model based on the Kintsch and van Dijk (KvD) theory of human text comprehension. 
- The KvD model tracks "lexical chains" of related noun phrases to enforce cohesive ties between sentences during extraction. It simulates working memory to focus only on recent chains.

Main Contributions:
- A cascaded pipeline with explicit control mechanisms to balance redundancy, informativeness and cohesion
- KvD-Select sentence extraction module that simulates human memory and builds lexical chains to improve summary cohesion  
- Experiments across domains like scientific articles, patents etc. showing the pipeline is effective at controlling properties and allowing configurable tradeoffs
- Human evaluation revealing improved cohesion results in higher perceived informativeness, with chains connecting adjacent sentences for smooth topic flow


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes an extractive summarization methodology that controls redundancy during input processing and balances informativeness and cohesion during sentence selection by modeling noun phrase interaction across sentences to improve summary coherence.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Proposing a cascaded encoder capable of consuming arbitrary long textual input that controls the level of content redundancy the rest of the pipeline is exposed to.

2. Proposing a summary extraction method that models informativeness and cohesion independently and allows controlling the balance between the two when building the summary. 

3. Showing through automatic and human experiments that the proposed control mechanisms are effective and summary properties can be balanced according to user needs in a straightforward way.

In summary, the key contributions are developing methods to control redundancy during input processing and to balance informativeness and cohesion during summary extraction, and demonstrating their effectiveness.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Extractive summarization - The task of generating a summary by selecting sentences from the original document(s). This paper focuses on extractive methods.

- Cohesion - A language mechanism that links semantic units in a text to make it unified. The paper aims to enforce cohesion in summaries while controlling for informativeness and redundancy. 

- Lexical cohesion - Cohesion created by linking units with the same lexical form, synonyms, etc. The paper models lexical cohesive ties between noun phrases.

- Informativeness - The amount of salient information conveyed in the summary. One goal is to balance informativeness and cohesion.

- Redundancy - Repeating information unnecessarily in the summary. The paper controls redundancy in long inputs. 

- Lexical chains - Groups of semantically related words, used to track topics/cohesion. The sentence selector simulates memory to track lexical chains.

- Micro-Macro theory - A psycholinguistic theory of discourse comprehension. The selector is based on processes from this theory to model working memory.

- Cascaded summarization - Summarization performed in stages, here by first selecting non-redundant passages then extracting sentences.

Some other keywords: noun chunks, summary properties, cohesive score, sentence graph, local coherence.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions controlling for redundancy during input processing and controlling the trade-off between informativeness and cohesion during sentence selection. Can you elaborate on why it is important to control these properties at different stages of the pipeline?

2. The block selection method balances relevance and redundancy when retrieving passages from the input text. What are the advantages of selecting non-redundant yet relevant passages compared to selecting passages greedily or in their original order? 

3. The local encoder module selects sentences from each passage. What is the motivation behind having a separate local extraction step before the global extraction? How does this architecture benefit the overall summarization?

4. The paper argues that modeling cohesion is a better approach than modeling coherence for extractive summarization without post-editing. Can you explain the difference between coherence and cohesion and why the authors make this argument?  

5. The KvD-Select sentence scoring method is based on the Micro-Macro theory from psycholinguistics. Can you explain this theory and how concepts like working memory and long-term memory are implemented in the scoring function?

6. The cohesion score used in KvD-Select encourages noun phrases to be assigned to recent chains. Why is recency important for cohesion in this context? How does it help enforce ties between nearby sentences?

7. The trade-off parameter Î»sel allows balancing informativeness and cohesion during sentence selection. Based on the results, how robust is KvD-Select to different values of this parameter compared to the baseline selectors?

8. What are the limitations of only extracting full sentences and concatenating them without any post-editing of discourse markers between sentences? Do the human evaluation results provide any insight into this?

9. Could you compare and contrast the cohesion results from the automatic metrics versus the human annotation of lexical chains? What differences stand out in terms of the chain properties?

10. The paper demonstrates the effectiveness of controlling redundancy and cohesion for long input texts across multiple domains. Do you think similar conclusions could be drawn for medium-length input documents? Why or why not?
