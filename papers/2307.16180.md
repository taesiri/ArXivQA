# Do LLMs Possess a Personality? Making the MBTI Test an Amazing   Evaluation for Large Language Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is:Do large language models (LLMs) with human-like abilities possess human-like personalities? More specifically, the authors investigate whether the Myers-Briggs Type Indicator (MBTI), a common human personality assessment tool, can serve as a reasonable evaluation metric for assessing the "personality" of LLMs. The key hypotheses explored in the paper are:1) Different LLMs will exhibit different "personality" types based on their training data and methods.2) The "personality" of LLMs can be influenced by techniques like prompt engineering. 3) The training dataset will impact the resulting "personality" of the LLM.4) While not scientifically rigorous, the MBTI may still serve as a rough indicator of model "personality" and provide insights.In summary, this paper centers around using the MBTI assessment as a lens to analyze whether advanced LLMs demonstrate human-like personalities, what factors impact their "personality", and whether the MBTI can provide a useful, if rough, evaluation approach for large language models. The authors aim to explore these hypotheses through extensive experiments on major LLMs.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Investigating whether large language models (LLMs) with human-like abilities exhibit human-like personalities, by using the Myers-Briggs Type Indicator (MBTI) test as an evaluation metric. 2. Conducting extensive experiments to explore:- The personality types of different LLMs, and finding they possess diverse "personality" types similar to humans.- The possibility of changing LLM personality types via prompt engineering. Finding that models without sufficient instruction-tuning are resistant to change, but can be influenced after proper tuning.- How training datasets affect LLM personality types. Observing the type of training data impacts personality, especially the T/F and J/P dimensions of MBTI.- Evaluating whether MBTI can reasonably assess LLMs. Concluding that while not rigorously scientific, MBTI may serve as a rough indicator for LLMs.3. Providing observations that while not definitive, using MBTI as an evaluation metric can offer insights into LLMs in terms of their training data, ability to follow instructions, reasoning capabilities, and more.In summary, the main contribution is using MBTI personality types as a novel way to evaluate and understand the capabilities of LLMs, through comprehensive experiments exploring if and how LLMs exhibit human-like personalities. While not rigorous, MBTI offers a creative angle to assess LLMs.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper investigates whether large language models exhibit human-like personalities by using the MBTI personality assessment, finding that different models do have distinct personality types similar to humans, these types are difficult to change without proper instruction tuning, training corpora impacts personality especially on thinking/feeling and judging/perceiving dimensions, and while not scientifically rigorous, MBTI can serve as a rough indicator of model personality.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other related research:- This paper explores using the MBTI personality test as an evaluation metric for large language models (LLMs). Using existing personality tests to evaluate LLMs is an interesting and novel idea. Most prior work has focused on evaluating LLMs through question-answering datasets or other knowledge tests. Applying a personality assessment is a creative approach to evaluating more human-like qualities of LLMs.- The idea of assessing whether LLMs exhibit human-like personalities relates to the broader goal of making LLMs more aligned with human values and psychology. There is a growing body of literature on training LLMs to be more ethical, reduce harmful biases, and demonstrate positive social attributes. Evaluating personality traits connects to assessing these human-centric capabilities.- Prior work such as Li et al. (2023) has also looked at administering the MBTI to large models like GPT-3. However, this paper conducts a more thorough investigation by testing multiple models, exploring the impact of training data and prompts, and assessing the limitations of the MBTI for evaluating LLMs. The analysis is more comprehensive.- The personality testing is still fairly rudimentary. Other recent papers have proposed more nuanced Turing tests to evaluate conversational ability, theory of mind, and social intelligence more deeply. The MBTI provides a relatively simple personality assessment compared to some of these newer evaluation frameworks.- The scale of experiments is limited due to compute constraints, as acknowledged by the authors. Testing larger models trained on more diverse data could reveal more insights into emerging personality traits. Follow-up work could expand on the experimental scope.Overall, using the MBTI to evaluate LLMs is a novel approach that aligns with assessing human-like capabilities. This paper provides a fairly comprehensive initial analysis, but there are opportunities to build on this work with more sophisticated evaluations and expanded experiments in future research. The personality testing idea shows promise as one evaluation methodology among many for human-centric AI.


## What future research directions do the authors suggest?

Based on my reading of the paper, the main future research directions suggested by the authors are:1. Expanding the research by integrating additional pre-training datasets, especially tasks that enhance commonsense reasoning abilities like math datasets. The authors note that more intriguing findings could emerge from using larger models and corpora than they were able to use due to resource limitations.2. Considering more challenging multi-modal scenarios, which the authors state presents a promising avenue for future exploration. The current work focused solely on language, but evaluating multimodal LLMs on personality could yield interesting insights.3. Utilizing a broader range of personality tests beyond just the MBTI, to provide a more comprehensive personality assessment of LLMs. The authors acknowledge MBTI has limitations as a rigorous metric. 4. Exploring personality development and indicators in the context of building artificial general intelligence (AGI) systems that align with human values. The authors suggest the MBTI could potentially serve as a rough indicator during the development of AGI.5. Considering additional datasets in the self-supervised fine-tuning, instruction tuning, and reinforcement learning from human feedback stages of training. The authors believe further tuning steps could continue to shape the emerging personalities of LLMs.In summary, the main suggested future directions are using more training data, evaluating multimodal scenarios, incorporating additional personality tests, linking personality to AGI development, and studying how further training stages impact personality.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:This paper investigates whether large language models (LLMs) with human-like abilities also exhibit human-like personalities, using the Myers-Briggs Type Indicator (MBTI) test as an evaluation metric. The authors conduct experiments on several LLMs like ChatGPT, GPT-4, Bloom, BaiChuan, and OpenLlama to determine their MBTI personality types. They find LLMs have diverse "personalities" consistent with their training style, but models without sufficient instruction tuning are hard to change via prompting. Training corpora can also impact MBTI types, especially thinking/feeling and judging/perceiving values. Although not rigorous, the authors conclude MBTI can serve as a rough indicator of model capabilities and similarity to human cognition. Experiments explore model "personalities," modifiability, and effects of training data, overall indicating MBTI is a reasonable evaluation approach despite limitations.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the key points from the paper:The paper investigates whether large language models (LLMs) with human-like abilities also exhibit human-like personalities, using the Myers-Briggs Type Indicator (MBTI) assessment as an evaluation tool. The authors conduct extensive experiments exploring: 1) LLMs have different "personality" MBTI types, related to their training data and methods, 2) It is difficult to change an LLM's MBTI type with prompt engineering alone, but possible after instruction tuning, 3) The training dataset impacts the MBTI type, especially thinking/feeling and judging/perceiving values, and 4) While not scientifically rigorous for humans, MBTI can serve as a rough indicator of similarities between LLM and human personalities. They conclude that different LLMs exhibit diverse "personalities" according to their training, tuning, and datasets, and while imperfect, MBTI may be a useful preliminary indicator of human-like personalities in LLMs, especially for thinking/feeling and judging/perceiving tendencies. Key limitations are the small model scale and datasets used. Overall, the work provides early exploration into evaluating human-like personalities in LLMs.
