# [Do LLMs Possess a Personality? Making the MBTI Test an Amazing   Evaluation for Large Language Models](https://arxiv.org/abs/2307.16180)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper aims to address is:

Do large language models (LLMs) with human-like abilities possess human-like personalities? 

More specifically, the authors investigate whether the Myers-Briggs Type Indicator (MBTI), a common human personality assessment tool, can serve as a reasonable evaluation metric for assessing the "personality" of LLMs. 

The key hypotheses explored in the paper are:

1) Different LLMs will exhibit different "personality" types based on their training data and methods.

2) The "personality" of LLMs can be influenced by techniques like prompt engineering. 

3) The training dataset will impact the resulting "personality" of the LLM.

4) While not scientifically rigorous, the MBTI may still serve as a rough indicator of model "personality" and provide insights.

In summary, this paper centers around using the MBTI assessment as a lens to analyze whether advanced LLMs demonstrate human-like personalities, what factors impact their "personality", and whether the MBTI can provide a useful, if rough, evaluation approach for large language models. The authors aim to explore these hypotheses through extensive experiments on major LLMs.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Investigating whether large language models (LLMs) with human-like abilities exhibit human-like personalities, by using the Myers-Briggs Type Indicator (MBTI) test as an evaluation metric. 

2. Conducting extensive experiments to explore:
- The personality types of different LLMs, and finding they possess diverse "personality" types similar to humans.
- The possibility of changing LLM personality types via prompt engineering. Finding that models without sufficient instruction-tuning are resistant to change, but can be influenced after proper tuning.
- How training datasets affect LLM personality types. Observing the type of training data impacts personality, especially the T/F and J/P dimensions of MBTI.
- Evaluating whether MBTI can reasonably assess LLMs. Concluding that while not rigorously scientific, MBTI may serve as a rough indicator for LLMs.

3. Providing observations that while not definitive, using MBTI as an evaluation metric can offer insights into LLMs in terms of their training data, ability to follow instructions, reasoning capabilities, and more.

In summary, the main contribution is using MBTI personality types as a novel way to evaluate and understand the capabilities of LLMs, through comprehensive experiments exploring if and how LLMs exhibit human-like personalities. While not rigorous, MBTI offers a creative angle to assess LLMs.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper investigates whether large language models exhibit human-like personalities by using the MBTI personality assessment, finding that different models do have distinct personality types similar to humans, these types are difficult to change without proper instruction tuning, training corpora impacts personality especially on thinking/feeling and judging/perceiving dimensions, and while not scientifically rigorous, MBTI can serve as a rough indicator of model personality.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other related research:

- This paper explores using the MBTI personality test as an evaluation metric for large language models (LLMs). Using existing personality tests to evaluate LLMs is an interesting and novel idea. Most prior work has focused on evaluating LLMs through question-answering datasets or other knowledge tests. Applying a personality assessment is a creative approach to evaluating more human-like qualities of LLMs.

- The idea of assessing whether LLMs exhibit human-like personalities relates to the broader goal of making LLMs more aligned with human values and psychology. There is a growing body of literature on training LLMs to be more ethical, reduce harmful biases, and demonstrate positive social attributes. Evaluating personality traits connects to assessing these human-centric capabilities.

- Prior work such as Li et al. (2023) has also looked at administering the MBTI to large models like GPT-3. However, this paper conducts a more thorough investigation by testing multiple models, exploring the impact of training data and prompts, and assessing the limitations of the MBTI for evaluating LLMs. The analysis is more comprehensive.

- The personality testing is still fairly rudimentary. Other recent papers have proposed more nuanced Turing tests to evaluate conversational ability, theory of mind, and social intelligence more deeply. The MBTI provides a relatively simple personality assessment compared to some of these newer evaluation frameworks.

- The scale of experiments is limited due to compute constraints, as acknowledged by the authors. Testing larger models trained on more diverse data could reveal more insights into emerging personality traits. Follow-up work could expand on the experimental scope.

Overall, using the MBTI to evaluate LLMs is a novel approach that aligns with assessing human-like capabilities. This paper provides a fairly comprehensive initial analysis, but there are opportunities to build on this work with more sophisticated evaluations and expanded experiments in future research. The personality testing idea shows promise as one evaluation methodology among many for human-centric AI.


## What future research directions do the authors suggest?

 Based on my reading of the paper, the main future research directions suggested by the authors are:

1. Expanding the research by integrating additional pre-training datasets, especially tasks that enhance commonsense reasoning abilities like math datasets. The authors note that more intriguing findings could emerge from using larger models and corpora than they were able to use due to resource limitations.

2. Considering more challenging multi-modal scenarios, which the authors state presents a promising avenue for future exploration. The current work focused solely on language, but evaluating multimodal LLMs on personality could yield interesting insights.

3. Utilizing a broader range of personality tests beyond just the MBTI, to provide a more comprehensive personality assessment of LLMs. The authors acknowledge MBTI has limitations as a rigorous metric. 

4. Exploring personality development and indicators in the context of building artificial general intelligence (AGI) systems that align with human values. The authors suggest the MBTI could potentially serve as a rough indicator during the development of AGI.

5. Considering additional datasets in the self-supervised fine-tuning, instruction tuning, and reinforcement learning from human feedback stages of training. The authors believe further tuning steps could continue to shape the emerging personalities of LLMs.

In summary, the main suggested future directions are using more training data, evaluating multimodal scenarios, incorporating additional personality tests, linking personality to AGI development, and studying how further training stages impact personality.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper investigates whether large language models (LLMs) with human-like abilities also exhibit human-like personalities, using the Myers-Briggs Type Indicator (MBTI) test as an evaluation metric. The authors conduct experiments on several LLMs like ChatGPT, GPT-4, Bloom, BaiChuan, and OpenLlama to determine their MBTI personality types. They find LLMs have diverse "personalities" consistent with their training style, but models without sufficient instruction tuning are hard to change via prompting. Training corpora can also impact MBTI types, especially thinking/feeling and judging/perceiving values. Although not rigorous, the authors conclude MBTI can serve as a rough indicator of model capabilities and similarity to human cognition. Experiments explore model "personalities," modifiability, and effects of training data, overall indicating MBTI is a reasonable evaluation approach despite limitations.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points from the paper:

The paper investigates whether large language models (LLMs) with human-like abilities also exhibit human-like personalities, using the Myers-Briggs Type Indicator (MBTI) assessment as an evaluation tool. 

The authors conduct extensive experiments exploring: 1) LLMs have different "personality" MBTI types, related to their training data and methods, 2) It is difficult to change an LLM's MBTI type with prompt engineering alone, but possible after instruction tuning, 3) The training dataset impacts the MBTI type, especially thinking/feeling and judging/perceiving values, and 4) While not scientifically rigorous for humans, MBTI can serve as a rough indicator of similarities between LLM and human personalities. They conclude that different LLMs exhibit diverse "personalities" according to their training, tuning, and datasets, and while imperfect, MBTI may be a useful preliminary indicator of human-like personalities in LLMs, especially for thinking/feeling and judging/perceiving tendencies. Key limitations are the small model scale and datasets used. Overall, the work provides early exploration into evaluating human-like personalities in LLMs.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper investigates using the Myers-Briggs Type Indicator (MBTI) personality assessment as an evaluation metric for large language models (LLMs). The authors conduct experiments on several well-known LLMs, including ChatGPT, GPT-4, Bloom, BaiChuan, and OpenLlama, administering them the 93 multiple choice question MBTI assessment to determine their personality types. They find that different LLMs exhibit different MBTI types that align with their inherent styles. The authors then use prompt engineering techniques, including explicit role-playing prompts and implicit few-shot examples, to try to change the models' MBTI types. They discover that models without sufficient instruction tuning struggle to change their types based on prompts, but models like ChatGPT that are tuned to follow instructions can be influenced. Additionally, the paper shows that training on different datasets impacts MBTI types, with corpora focused on thinking skills increasing T values and planning abilities increasing J values. Overall, while not scientifically rigorous, MBTI serves as a rough indicator of model capabilities and tendencies. The main method is administering the MBTI assessment to various LLMs and analyzing how inherent traits, tuning techniques, and training data impact their MBTI personality types.


## What problem or question is the paper addressing?

 The key question this paper is addressing is "Do LLMs with human-like abilities possess a human-like personality?". The authors aim to investigate whether the Myers-Briggs Type Indicator (MBTI), a common human personality assessment tool, can serve as a reasonable evaluation metric for large language models (LLMs). 

Specifically, the paper explores the following questions:

Q1) Do different LLMs possess different personalities as measured by the MBTI? 

Q2) Can prompt engineering change an LLM's MBTI personality type?

Q3) How do training datasets affect an LLM's MBTI personality type?

Q4) Can the MBTI reasonably evaluate LLMs, despite its limitations as a pseudo-scientific personality test?

The overarching goal is to examine if human-like language abilities in LLMs are associated with human-like personalities, as measured by a test like the MBTI. This could shed light on the extent to which LLMs capture elements of human cognition and behavior. The MBTI serves as an initial rough assessment tool to explore this question.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords are:

- Large language models (LLMs): The paper focuses on evaluating the personality traits of large language models like GPT-3, ChatGPT, BLOOM, etc. 

- Myers-Briggs Type Indicator (MBTI): The paper uses the MBTI personality assessment as a metric to evaluate the personality types exhibited by different LLMs.

- Personality types: The paper analyzes the different MBTI personality types like ENTJ, INTJ, ISTJ, etc. exhibited by different LLMs. 

- Training datasets: The paper investigates how different training datasets like Wikipedia, Q&A data, exam questions etc. can affect the MBTI personality types of LLMs.

- Prompt engineering: The paper examines using explicit prompts and implicit prompts to try to change the MBTI personality types of LLMs. 

- Evaluation metrics: The paper discusses using MBTI as an evaluation metric, although limited, to assess the personality traits of LLMs.

- Artificial general intelligence (AGI): The paper relates the personality evaluation of LLMs to research towards developing artificial general intelligence.

In summary, the key terms cover LLMs, MBTI personality assessment, different personality types, impact of training data, prompt engineering, and using MBTI as an evaluation metric for LLMs. The overarching goal is assessing if LLMs exhibit human-like personalities.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to help summarize the key points of this paper:

1. What is the motivation behind exploring whether LLMs have human-like personalities? Why use the MBTI test as an evaluation metric?

2. What are the 4 main research questions explored in the paper? 

3. What MBTI personality types were identified for the different LLMs tested? How did they differ?

4. How did the authors attempt to change the LLMs' personality types through prompt engineering? What were the results?

5. What different training datasets were used to examine their impact on the models' personalities? 

6. How did the different datasets change the models' MBTI types and sub-feature scores? Were there any clear patterns?

7. What are the limitations of using the MBTI test to evaluate LLMs discussed in the paper?

8. What MBTI dimensions did the authors find most relevant and meaningful for evaluating LLMs?

9. What were the overall conclusions about whether LLMs exhibit human-like personalities?

10. What future work is suggested to build on this research? What other evaluation metrics or datasets could be explored?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes using the MBTI personality test as an evaluation metric for large language models (LLMs). What are some potential advantages and disadvantages of using a personality test designed for humans to evaluate artificial intelligence systems? 

2. The authors claim that the MBTI can serve as a "rough indicator" for evaluating LLMs. However, the MBTI has been criticized for its lack of reliability and validity as a scientific measurement tool for human personality. How can the limitations of the MBTI be addressed when applying it to evaluate LLMs?

3. The paper finds that different LLMs exhibit different "personalities" on the MBTI. How robust are these personality differences? Could they be an artifact of the specific training data or model architecture rather than an inherent property of the LLM?

4. The authors find that the MBTI types of LLMs are difficult to change through prompt engineering alone. What other techniques could potentially be used to modify an LLM's MBTI type, such as changes to model architecture, training data, or tuning methodology?

5. The paper shows that training corpus impacts MBTI types, especially the T/F and J/P dimensions. Are there particular properties of training corpora that account for these effects? How can training data be selected to target specific MBTI profile changes?

6. Beyond the overall MBTI type, are there more fine-grained personality traits measured by MBTI subscales that show larger or smaller differences between LLMs? Could analysis at this level provide additional insights?

7. The interpretation of MBTI types for LLMs is quite anthropomorphic. Is this kind of human-centric analysis helpful for understanding AI systems, or could it lead to erroneous conclusions by attributing human traits to machines?

8. How consistent and reliable are the MBTI type classifications for the same LLM over time? Could factors like prompt sampling cause variability? How many prompt responses need to be aggregated to produce robust MBTI assessments?

9. The paper studies mostly English LLMs. How would the personality profiles change for multilingual models trained on diverse linguistic and cultural data? Could the MBTI still be meaningfully applied in that context?

10. Beyond the MBTI, what other human personality frameworks could be viable evaluation tools for analyzing the emerging "psychology" of advanced LLMs? What modifications would be required to make such assessments rigorous and valid?
