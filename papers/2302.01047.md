# [Real-Time Evaluation in Online Continual Learning: A New Hope](https://arxiv.org/abs/2302.01047)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is:

How do current online continual learning (OCL) methods perform under a practical real-time evaluation protocol that factors in training complexity/computational cost? 

The key hypothesis is that existing OCL methods will underperform simple baselines when evaluated realistically on fast streams where training time matters.

In summary:

- The paper proposes a new real-time evaluation protocol for OCL that considers training complexity. This contrasts with prior OCL evaluations that ignore computational cost. 

- Under this new evaluation, the paper hypothesizes that current OCL methods will struggle compared to simple baselines.

- Experiments on a large-scale dataset validate this hypothesis, showing simple experience replay outperforms recent OCL methods when training complexity is considered.

- The paper argues this highlights a need to rethink OCL methods to prioritize efficiency for real-world deployment.

So in essence, the paper questions if existing OCL methods are practical given training constraints, and shows even simple methods outperform them under a realistic real-time evaluation.
