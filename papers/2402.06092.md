# [CLIP-Loc: Multi-modal Landmark Association for Global Localization in   Object-based Maps](https://arxiv.org/abs/2402.06092)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing methods for global localization or relocalization in object-based maps typically rely on matching all possible combinations of detected objects and map landmarks with the same category. This leads to an exponential growth in correspondence candidates as the number of landmarks increases, making the methods infeasible for larger maps. 

Proposed Solution:
This paper proposes a multi-modal data association method that leverages natural language descriptions assigned to landmarks and a Vision-Language Model (VLM), specifically CLIP. Landmarks are labeled with text descriptions of their appearance. Given a query image, objects are detected and matched to the closest landmark descriptions in the CLIP embedding space. This allows focusing only on the most promising correspondence candidates. 

The paper also introduces an efficient inlier extraction method inspired by Progressive Sample Consensus (PROSAC) that samples candidates based on the CLIP similarity score, favoring more likely inliers earlier.

Main Contributions:
- A method to associate landmarks and observations using natural language labels and CLIP embeddings for efficient global localization
- An adapted PROSAC sampling strategy using text-image similarity scores to enable faster convergence 

Experiments show the proposed method enables more accurate pose estimation with fewer iterations compared to baseline methods relying only on object categories, demonstrating its improved efficiency.
