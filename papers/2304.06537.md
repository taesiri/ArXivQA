# [Transfer Knowledge from Head to Tail: Uncertainty Calibration under   Long-tailed Distribution](https://arxiv.org/abs/2304.06537)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to calibrate classification models trained from long-tailed distributions when the test data follows a balanced distribution. 

Specifically, the paper explores the problem of calibration under long-tailed distributions, where the training and validation data follow a long-tailed distribution but the test data is balanced. This causes issues for traditional calibration methods like temperature scaling, which assume the validation and test data come from the same distribution. 

The key hypothesis is that transferring knowledge from head (majority) classes to tail (minority) classes can help estimate the balanced distribution of tail classes for calibration.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel importance weight-based strategy for calibrating models trained under long-tailed distributions. The key points are:

- The paper explores the problem of calibration under long-tailed distributions, where the training and validation data follow a long-tailed distribution but the test data is balanced. This is an important but rarely studied problem. 

- To tackle the distribution mismatch between training/validation and test data, the paper applies an importance weighting strategy to re-weight the instances from tail classes. This helps enhance the estimation of tail classes for more accurate calibration.

- The paper proposes to model the distribution of each class as a Gaussian and transfer knowledge from head classes to tail classes to estimate the target probability density of tail classes. This allows estimating importance weights for tail class instances.

- Extensive experiments on CIFAR-10-LT, CIFAR-100-LT, MNIST-LT and ImageNet-LT show the proposed method outperforms existing calibration techniques under long-tailed distributions.

In summary, the key contribution is proposing an importance weighting based calibration method that transfers knowledge from head to tail classes to deal with the long-tailed distribution mismatch, which is shown to be effective through experiments.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a new method for calibrating classification models trained on long-tailed datasets by estimating importance weights to rebalance the validation set distribution before temperature scaling, where the weights are computed by modeling each class distribution as a Gaussian and transferring knowledge from head to tail classes.
