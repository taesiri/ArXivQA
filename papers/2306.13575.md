# [Scaling MLPs: A Tale of Inductive Bias](https://arxiv.org/abs/2306.13575)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research questions/hypotheses appear to be:1) Do MLPs reflect the empirical advances exhibited by practical models when subjected to modern training protocols like large-scale pre-training? This aims to assess whether MLPs are a good proxy for modern architectures in theoretical studies.2) Can lack of inductive bias in MLPs be compensated by simply providing more compute in the form of model scale and dataset size? This tests whether "less inductive bias is better" and if bad inductive biases like in MLPs can be overcome given enough data and model capacity. 3) Do MLPs exhibit predictable scaling behavior akin to modern architectures when model size and dataset size are increased? The goal seems to be understanding if MLPs follow similar power law trends linking compute to performance.Overall, the paper seems focused on empirically evaluating MLPs in modern training settings to both validate their use as a theoretical proxy and test hypotheses about the role of inductive bias and predictable scaling laws in deep learning. The authors aim to bridge the gap between theory and practice regarding MLPs.


## What is the main contribution of this paper?

This paper presents an empirical study of multi-layer perceptrons (MLPs) for image classification. The key contributions are:- Filling the gap between theory and practice by providing the first comprehensive results for MLPs trained in modern large-scale settings with pre-training and transfer learning. - Showing that MLPs mostly mimic the behavior of modern architectures like CNNs and Transformers. However, the roles of regularization and implicit SGD bias differ significantly for MLPs, so theory needs to adapt.- Providing evidence that lack of inductive bias can be compensated by scale. MLPs can achieve surprisingly strong performance (e.g. 93% on CIFAR10) when subjected to enough compute and data. - Observing that optimal MLPs invest compute more heavily into dataset size rather than model size compared to CNNs/Transformers, reflecting their weaker inductive bias.- Demonstrating the computational efficiency of scaling MLPs, enabling large-scale experiments on a single GPU.Overall, this work cements MLPs as a good theoretical proxy while also revealing their limitations. It provides evidence that inductive bias becomes less crucial at large scales. The empirical insights contribute to both theory and practice of deep learning.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper investigates multi-layer perceptrons (MLPs) for image classification, showing that their performance drastically improves with scale and that they largely mirror the behavior of modern convolutional networks, making them a suitable proxy for theory, though regularization and implicit bias differ.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research on multi-layer perceptrons (MLPs) for vision:- This paper provides the first comprehensive evaluation of MLPs in modern deep learning settings, including large-scale pre-training and transfer learning. Most prior work on MLPs for vision has focused on smaller-scale training from scratch. So this paper helps fill an important gap.- The results demonstrate that MLPs can achieve surprisingly strong performance when scaled up, despite their lack of inductive bias. This supports the notion that less inductive bias can be compensated by more data and compute. However, the scale here is still far below the regimes where vision transformers start to outperform CNNs.- The paper finds that MLPs exhibit predictable scaling behavior similar to CNNs and Transformers, making them a reasonable proxy architecture for theory. However, the roles of regularization and SGD differ, so theory may need to adapt.- The inverted bottleneck MLP architecture used here incorporates some modifications like skip connections that add a small degree of inductive bias. Fully vanilla MLPs may exhibit somewhat different behavior.- The computational efficiency of MLPs is highlighted as a major advantage. This enables scaling experiments that would be infeasible for CNNs and Transformers without massive compute resources.Overall, this paper provides valuable new insights into the capabilities and limits of MLPs for vision. The results generally support their use as a theoretical test bed, but identify some areas where theoretical models may need refinement to better match MLP behavior in practice. More work is still needed to determine if MLPs can match state-of-the-art vision models with enough scale.


## What future research directions do the authors suggest?

The paper suggests several future research directions:1. Train and evaluate MLPs at even larger scales of compute, especially in terms of more training examples, to further test the limits of how much inductive bias matters with enough scale.2. Investigate the role of image resolution on MLP performance. The paper uses reduced resolution of 64x64 but studying higher resolutions could reveal if inductive bias becomes more important. 3. Further explore the theoretical implications of the counter-intuitive findings around batch size and data augmentation. The standard role of MLPs as a theoretical proxy needs to be adapted based on these results.4. Given their computational efficiency, study specialized hardware and architectures for fast training and inference with MLPs.5. Leverage the feasibility of large-scale MLP training to explore different architectural variants andregularization techniques to improve performance.6. Use MLPs as a testbed for studying emerging topics like self-supervised learning at scale and prompting. Their simplicity makes large-scale experiments more accessible.In summary, the authors suggest directions to further scale MLPs, adapt theory based on new findings, and exploit their efficiency to enable research advancements. The results indicate MLPs remain a useful model class despite lacking inductive bias.
