# [Scaling MLPs: A Tale of Inductive Bias](https://arxiv.org/abs/2306.13575)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research questions/hypotheses appear to be:1) Do MLPs reflect the empirical advances exhibited by practical models when subjected to modern training protocols like large-scale pre-training? This aims to assess whether MLPs are a good proxy for modern architectures in theoretical studies.2) Can lack of inductive bias in MLPs be compensated by simply providing more compute in the form of model scale and dataset size? This tests whether "less inductive bias is better" and if bad inductive biases like in MLPs can be overcome given enough data and model capacity. 3) Do MLPs exhibit predictable scaling behavior akin to modern architectures when model size and dataset size are increased? The goal seems to be understanding if MLPs follow similar power law trends linking compute to performance.Overall, the paper seems focused on empirically evaluating MLPs in modern training settings to both validate their use as a theoretical proxy and test hypotheses about the role of inductive bias and predictable scaling laws in deep learning. The authors aim to bridge the gap between theory and practice regarding MLPs.


## What is the main contribution of this paper?

This paper presents an empirical study of multi-layer perceptrons (MLPs) for image classification. The key contributions are:- Filling the gap between theory and practice by providing the first comprehensive results for MLPs trained in modern large-scale settings with pre-training and transfer learning. - Showing that MLPs mostly mimic the behavior of modern architectures like CNNs and Transformers. However, the roles of regularization and implicit SGD bias differ significantly for MLPs, so theory needs to adapt.- Providing evidence that lack of inductive bias can be compensated by scale. MLPs can achieve surprisingly strong performance (e.g. 93% on CIFAR10) when subjected to enough compute and data. - Observing that optimal MLPs invest compute more heavily into dataset size rather than model size compared to CNNs/Transformers, reflecting their weaker inductive bias.- Demonstrating the computational efficiency of scaling MLPs, enabling large-scale experiments on a single GPU.Overall, this work cements MLPs as a good theoretical proxy while also revealing their limitations. It provides evidence that inductive bias becomes less crucial at large scales. The empirical insights contribute to both theory and practice of deep learning.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper investigates multi-layer perceptrons (MLPs) for image classification, showing that their performance drastically improves with scale and that they largely mirror the behavior of modern convolutional networks, making them a suitable proxy for theory, though regularization and implicit bias differ.
