# [Large Language Models on Graphs: A Comprehensive Survey](https://arxiv.org/abs/2312.02783)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the paper:

This paper provides a comprehensive review of techniques for utilizing large language models (LLMs) on graphs. It first categorizes three main graph scenarios for applying LLMs: pure graphs without text, text-rich graphs where nodes/edges have text, and text-paired graphs with whole graph-level text. The techniques are then categorized based on the LLM's role. As a predictor, LLMs directly output representations or predictions, enhanced by making them graph-aware. As an encoder, LLMs encode node/edge text to serve as features for graph neural networks. As an aligner, LLMs and GNNs are trained in parallel to align representations for both text and graphs. For each category of techniques, the paper thoroughly reviews, illustrates, and compares representative methods on aspects like model architectures and training objectives. It also summarizes available datasets, open source implementations, diverse applications in scientific discovery, social science, and specific domains. Potential future directions are provided including better benchmarks, exploring decoder-based LLMs, pretraining on heterogeneous graphs, improving efficiency, and designing LLMs as dynamic agents that can retrieve knowledge.
