# [Imagen Editor and EditBench: Advancing and Evaluating Text-Guided Image   Inpainting](https://arxiv.org/abs/2212.06909)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be how to advance and evaluate text-guided image inpainting, which refers to the task of editing images in localized regions based on textual descriptions. 

Specifically, the paper makes two main contributions:

1. It proposes a new model called Imagenator for high-quality text-guided image inpainting. The key innovations include using object detectors to propose better training masks and architectural improvements to enable high-resolution editing.

2. It introduces a new benchmark called EditBench for systematically evaluating text-guided image inpainting models. EditBench has a diverse set of example images, masks, and textual prompts to probe model performance on different attributes, objects, and scenes.

The overarching goal is to both improve text-guided image inpainting models through contributions like Imagenator, and also enable more rigorous evaluation of different models through benchmarks like EditBench. The research questions revolve around how to generate higher fidelity and more controllable image edits based on text prompts, and how to thoroughly assess progress on this task.
