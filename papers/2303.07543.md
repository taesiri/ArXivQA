# [WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminant   Analysis](https://arxiv.org/abs/2303.07543)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the abstract, this paper does not seem to pose a specific research question or hypothesis. Rather, it provides a review and overview of the current state of knowledge regarding bias in machine learning systems. The key points I gathered are:- Machine learning systems can inherit and amplify bias present in data and society. This is a concern as these systems are increasingly used in high-stakes domains like criminal justice, healthcare, and hiring.- Sources of bias include historical biases encoded in data, representation bias in datasets, biases in human labeling, technical bias due to optimization objectives, and biases in real-world deployment. - Mitigation strategies involve techniques like data augmentation, reweighting, and changes to model architecture/training. But there are challenges around detecting bias, defining fairness, and making tradeoffs.- Understanding how bias manifests in ML systems requires interdisciplinary collaboration drawing on social sciences, ethics, law, and human-computer interaction.So in summary, this paper seems aimed at providing a broad synthesis of the current knowledge and open challenges related to bias in machine learning, rather than testing a specific hypothesis. The review spans different types of biases, sources, measurement techniques, mitigations, and need for interdisciplinary perspectives.
