# [WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminant   Analysis](https://arxiv.org/abs/2303.07543)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the abstract, this paper does not seem to pose a specific research question or hypothesis. Rather, it provides a review and overview of the current state of knowledge regarding bias in machine learning systems. The key points I gathered are:

- Machine learning systems can inherit and amplify bias present in data and society. This is a concern as these systems are increasingly used in high-stakes domains like criminal justice, healthcare, and hiring.

- Sources of bias include historical biases encoded in data, representation bias in datasets, biases in human labeling, technical bias due to optimization objectives, and biases in real-world deployment. 

- Mitigation strategies involve techniques like data augmentation, reweighting, and changes to model architecture/training. But there are challenges around detecting bias, defining fairness, and making tradeoffs.

- Understanding how bias manifests in ML systems requires interdisciplinary collaboration drawing on social sciences, ethics, law, and human-computer interaction.

So in summary, this paper seems aimed at providing a broad synthesis of the current knowledge and open challenges related to bias in machine learning, rather than testing a specific hypothesis. The review spans different types of biases, sources, measurement techniques, mitigations, and need for interdisciplinary perspectives.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- Proposing a new out-of-distribution (OOD) detection method called WDiscOOD that is based on Whitened Linear Discriminant Analysis (WLDA). The key idea is to use WLDA to project image features into two subspaces - a discriminative subspace and a residual subspace. 

- Demonstrating that the proposed residual subspace, referred to as the Whitened Discriminative Residual Space (WDRS), is highly effective for OOD detection. This provides new insights into how OOD samples may trigger different activations compared to in-distribution samples.

- Achieving state-of-the-art OOD detection performance on ImageNet-1k benchmark using various classifier models (CNNs and Vision Transformers) as well as contrastive visual encoders (SupCon and CLIP models). The method is shown to be robust across different model architectures and training objectives.

- Providing ablation studies and analysis to understand the contributions of different components of the proposed method, such as feature whitening, the discriminative vs residual subspaces, and method hyperparameters.

In summary, the main contribution appears to be proposing a new OOD detection method that leverages WLDA to reason about class-specific and class-agnostic information purely in the feature space, without needing classifier outputs. The efficacy of the residual subspace for OOD detection is also an important discovery of this work.
