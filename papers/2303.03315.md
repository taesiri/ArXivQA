# [MACARONS: Mapping And Coverage Anticipation with RGB Online   Self-Supervision](https://arxiv.org/abs/2303.03315)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question addressed in this paper is: How can an autonomous system efficiently explore and reconstruct unknown 3D environments using only RGB images, without relying on depth sensors or 3D supervision?The key points are:- The paper focuses on the problem of Next Best View (NBV) prediction and path planning for 3D reconstruction. NBV refers to identifying the next best camera position to improve coverage and reconstruction of a scene. - Most existing NBV methods rely on depth sensors and 3D supervision (e.g. 3D meshes or point clouds) for training. However, depth sensors have limitations for outdoor scenes captured by drones, and 3D supervision does not scale well to large, complex environments.- The paper proposes a method called MACARONS that can explore and reconstruct scenes using only RGB images, without depth sensors or 3D supervision. It uses a self-supervised, online learning strategy.- MACARONS has three main modules: depth prediction from RGB, volume occupancy prediction, and surface coverage gain prediction for NBV. These modules are jointly trained in an end-to-end manner.- A key contribution is the self-supervised training procedure that allows MACARONS to scale to large, unknown environments where no 3D ground truth is available. The model builds its own training data by exploring new scenes.In summary, the main research question is how to achieve efficient scene exploration and reconstruction using only RGB images in a self-supervised way, removing the need for depth sensors or 3D supervision data. The paper proposes MACARONS to address this challenge.
