# [SPTNet: An Efficient Alternative Framework for Generalized Category   Discovery with Spatial Prompt Tuning](https://arxiv.org/abs/2403.13684)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Generalized Category Discovery (GCD) aims to classify unlabeled images into both seen and unseen categories by transferring knowledge from labeled images of seen classes. 
- Existing methods rely on fine-tuning large pre-trained models like DINO, which can lead to overfitting and is computationally expensive.  
- Simply applying existing visual prompt learning methods struggles to achieve good performance on the GCD task.

Proposed Solution: 
- The paper proposes a two-stage iterative framework called SPTNet that optimizes both model parameters (model fine-tuning) and data parameters (prompt learning).
- It introduces a novel Spatial Prompt Tuning (SPT) method that attaches learnable pixel-level prompts around local image patches to help the model focus better on discriminative object parts.

Key Components:
- Stage 1: Fix model, update prompts
- Stage 2: Fix prompts, update model with contrastive loss using raw and prompted image pair
- Alternate the two stages until convergence  
- Spatial Prompt Tuning: Attach small learnable rectangular prompts around each image patch

Main Contributions:
- An efficient two-stage iterative framework SPTNet for GCD that integrates model fine-tuning and prompt learning
- A novel spatial prompt tuning method (SPT) that considers spatial properties of images and focuses on object parts 
- Comprehensive experiments on 7 datasets demonstrating SPTNet outperforms state-of-the-art with only 0.117% extra parameters
- Insights that prompt learning acts as an effective learned augmentation suitable for contrastive learning in GCD

In summary, the paper introduces an iterative optimization framework for GCD that alternates between model fine-tuning and spatial prompt tuning. The spatial prompts help the model focus better on discriminative object parts for improved feature learning. Extensive experiments validate the effectiveness and efficiency of the approach.
