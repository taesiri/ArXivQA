# [Invariant Graph Transformer](https://arxiv.org/abs/2312.07859)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a new graph neural network model called Invariant Graph Transformer (IGT) for graph classification and regression tasks. IGT introduces a novel node/virtual node-level intervention mechanism between the rationale subgraph and environment subgraph to ensure the extracted rationale retains maximum utility despite changes in the environment subgraph. Specifically, IGT employs a Transformer encoder to model fine-grained interactions between rationale and environment nodes. Additionally, IGT formulates a min-max game between the modules extracting the rationale subgraph and the intervener module to further enhance the quality of the extracted rationale. Through comprehensive experiments on 7 graph datasets, IGT and its variants IGT-N and IGT-VN demonstrate superior performance over 13 state-of-the-art graph neural networks. The rationale visualization also verifies that the proposed intervention mechanism can effectively minimize interactions between the rationale and environment. Overall, the node/virtual node-level intervention of IGT ensures the extracted graph rationale has strong discrimination ability for prediction tasks.
