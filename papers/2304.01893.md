# [Trace and Pace: Controllable Pedestrian Animation via Guided Trajectory   Diffusion](https://arxiv.org/abs/2304.01893)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is how to generate realistic pedestrian trajectories and full-body animations that can be controlled to meet user-defined goals. Specifically, the authors aim to develop a generative model of trajectories that is data-driven yet controllable at test time through the use of guided diffusion models. This controllable trajectory model is then integrated with a physics-based humanoid controller to enable full-body pedestrian animation that can be directed by a user through high-level objectives like specifying waypoints or social groups.In summary, the key research questions are:1) How can recent advances in guided diffusion modeling be leveraged to achieve test-time controllability for trajectory generation?2) How can this controllable trajectory model be tightly integrated with a physics-based animation system to enable user-directed simulation of full-body pedestrian motions?3) Can this integrated system robustly handle varying tasks, terrains, and characters in a controllable manner based on user high-level goals?The main hypothesis is that by combining a controllable trajectory diffusion model with a general-purpose pedestrian animation controller, it is possible to develop an end-to-end pedestrian animation system that gives users control over high-level behavioral objectives while generating realistic physics-based motions.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. A controllable trajectory diffusion model called TRACE that can generate realistic pedestrian trajectories and be guided at test time to meet user-defined objectives like waypoints, social groups, and collision avoidance. The key novelty is the use of guidance with a trajectory diffusion model to enable test-time control.2. A novel physics-based pedestrian animation controller called PACER that can drive simulated humanoid characters with diverse body types along trajectories from a high-level planner like TRACE. It is trained with terrain/social awareness and adversarial imitation learning for natural motions.3. An end-to-end pedestrian animation system combining TRACE and PACER in closed-loop feedback, enabling controllable simulation of crowds. The connection is strengthened by using PACER's learned value function to guide TRACE's trajectory diffusion, making planning aware of the animation model's preferences.In summary, the main contribution is an animation system with a controllable high-level trajectory planner based on guided diffusion and a robust low-level character controller, which can generate animations of pedestrians that meet user-defined objectives and constraints. The integration of the two components in closed-loop while leveraging the value function for planning is a key contribution.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points in the paper:The paper proposes a novel method for generating controllable pedestrian trajectories and full-body animations by integrating a guided diffusion model for high-level planning with a physics-based humanoid controller, enabling user control over waypoints, speed, social groups, and collision avoidance in simulated crowds and environments.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in pedestrian trajectory modeling and controllable character animation:- The use of a diffusion model for trajectory generation is novel. Most prior work has used RNN/Transformer architectures for trajectory prediction. Diffusion models have advantages like efficient parallel sampling and test-time control through guidance.- Integrating the trajectory model with a full physics-based character controller is a key contribution. Many prior trajectory forecasting papers focus only on 2D positions. The authors demonstrate controlling simulated humanoids driven by the trajectories.- The idea of classifier-free guidance during diffusion training is an interesting way to improve controllability. Randomly dropping conditioning allows more flexible generation at test time. - Using the value function from the animation controller to guide the trajectory model is clever. It connects the high- and low-level models in a unidirectional way.- For animation, this work follows a two-stage planning-control approach. Some recent methods like DeepLoco and Haworth et al. do end-to-end control with learned implicit planning. The advantage here is the trajectory model can be re-used.- For trajectories, modeling longer-term multi-modal futures conditioned on context is still an open problem. This method generates a single deterministic path. Capturing diverse behaviors and far futures remains challenging.So in summary, key novelties are using diffusion for pedestrian trajectory modeling, enabling test-time control through guidance, and the integrated animation system. The work represents an advance in controllable data-driven character animation. Like other learning-based methods, modeling diversity and complex interactions between agents and environments over longer time horizons is still an area for future work.
