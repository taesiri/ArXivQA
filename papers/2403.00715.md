# [Adaptive Learning Rate for Follow-the-Regularized-Leader: Competitive   Ratio Analysis and Best-of-Both-Worlds](https://arxiv.org/abs/2403.00715)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- The paper considers the problem of optimally adjusting the learning rate in Follow-The-Regularized-Leader (FTRL) online learning algorithms to minimize regret bounds. 
- Appropriate choice of learning rate is crucial in FTRL methods for good practical performance and tighter regret bounds.

Proposed Solution:
- Formulates the learning rate selection as a sequential decision making problem and analyzes it using competitive ratio framework.
- Shows the optimal competitive ratio can be characterized by the approximate monotonicity of the penalty terms in FTRL regret bounds.
- Proposes a "stability-penalty matching" (SPM) update rule for the learning rate that achieves the optimal competitive ratio up to constant factors under approximate monotonicity.

Key Contributions:  
- Establishes a lower bound on the competitive ratio under approximate monotonicity of penalty terms.
- The SPM update rule matches this lower bound up to constants and does not require knowledge of future penalty terms.
- Applies SPM learning rate to design FTRL algorithms with tight "Best-of-Both-Worlds" regret bounds for bandit problems in both stochastic and adversarial settings.
- Shows the flexibility of choosing Tsallis entropy parameter alpha due to the adaptive learning rate, allowing optimization of problem-specific bounds.

In summary, the paper provides a principled and optimal approach to adjusting FTRL learning rates, with applications to obtaining tight, best-of-both-worlds regret bounds in bandit problems. The competitive ratio analysis reveals the key role of approximate monotonicity.
