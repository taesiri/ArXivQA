# [ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent](https://arxiv.org/abs/2312.10003)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Answering complex natural language questions often requires multi-step reasoning and integrating external information. Existing systems that combine knowledge retrieval with large language models (LLMs) suffer from failure cases. 
- These systems are not end-to-end differentiable due to interaction with non-differentiable external knowledge. So we cannot directly train them to fix failure cases.

Proposed Solution:  
- The paper defines a ReAct-style LLM agent with explicit reasoning and action steps to answer questions by searching and summarizing information.
- It refines the agent through a ReST-like method with growing-batch reinforcement learning using AI feedback for continuous self-improvement and self-distillation.

Key Contributions:
- Defines a flavor of ReAct agent with self-critique for long-form question answering using a search tool.
- Introduces a proxy evaluation metric using Bamboogle and BamTwoogle datasets with emphasis on auto-eval.
- Shows agent performance can be improved through Rest-style iterative fine-tuning purely from stepwise AI feedback without human-labeled data.
- Demonstrates the synthetic data from self-improvement iterations can distill the agent into smaller models with comparable performance. For example, after two iterations, a fine-tuned small model achieves performance close to the pre-trained large model teacher.

In summary, the paper presents an iterative self-improvement framework to train an LLM agent for multi-step reasoning and knowledge integration without human involvement. The trained agent also allows distillation into much smaller models while preserving most of the performance.
