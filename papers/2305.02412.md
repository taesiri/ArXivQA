# Plan, Eliminate, and Track -- Language Models are Good Teachers for   Embodied Agents

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key points of this paper are:- The paper proposes a new framework called Plan, Eliminate, and Track (PET) for using large language models (LLMs) to assist embodied agents in completing tasks. - The goal is to leverage the knowledge and common sense captured in LLMs to help agents, rather than having the LLM directly serve as the agent policy. This is because LLMs have limitations like fixed input lengths that make them ill-suited to directly control agents.- The PET framework has 3 components:  - Plan module uses an LLM to generate high-level sub-tasks for an input task  - Eliminate module uses a QA model to mask irrelevant objects/receptacles  - Track module uses a QA model to track progress on sub-tasks- Experiments on the AlfWorld benchmark show PET assists an Action Attention agent, achieving strong results, especially on human goal specifications where it outperforms prior work.- Ablations and analysis indicate each PET module provides a useful capability for assisting the agent.The central hypothesis seems to be that leveraging LLMs for knowledge and simplifying the task, rather than directly acting, will produce better task completion by embodied agents. The results support this claim, showing benefits from the PET framework versus prior methods.The paper also suggests there is room for improvement in the PET approach, such as by handling cases where progress is undone or integrating LLM knowledge in different ways. So it does not position PET as the complete solution, but rather a promising direction for utilizing LLM knowledge.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. Proposing the PET (Plan, Eliminate, Track) framework that leverages pre-trained large language models (LLMs) to assist embodied agents in three key ways:- The Plan module uses an LLM to generate high-level sub-tasks for a given complex task description. This simplifies the task by breaking it down into simpler steps.- The Eliminate module uses a QA-based LLM to remove irrelevant objects/receptacles from observations, reducing noise. - The Track module uses a QA-based LLM to track progress on sub-tasks.2. An Action Attention agent architecture that handles the variable action space in text environments like AlfWorld.3. Demonstrating that the PET framework leads to significant improvements in generalization performance on the AlfWorld benchmark, especially for human goal specifications. The method achieves state-of-the-art results.4. Analysis showing the complementary benefits of the different PET modules.5. A study demonstrating that the PET framework is much more sample-efficient than prior work relying on DAGGER, enabling practical training.The key idea is using LLMs in a novel way - not to directly act, but to simplify the task for a trainable agent through planning, elimination of distractions, and progress tracking. This improves generalization and sample efficiency.The authors also discuss limitations like the inability to revisit completed sub-tasks, and suggest future work could focus on dynamic replanning or other ways LLMs could assist policy learning. Overall, the paper demonstrates creative ways to leverage LLMs to simplify embodied control tasks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a novel framework called Plan, Eliminate, and Track (PET) that uses large language models in a multi-step process to assist embodied agents by generating high-level plans, filtering irrelevant objects from observations, and tracking progress on subtasks, leading to improved performance and generalization compared to prior methods on complex instruction following tasks.


## How does this paper compare to other research in the same field?

Here are a few thoughts on comparing your paper to other research and discussing future improvements with language models:- Your PET framework shows impressive results on the AlfWorld benchmark, achieving state-of-the-art performance on generalizing to human goal specifications. This demonstrates the value of using language models for planning, elimination, and tracking in embodied agents. - Compared to prior work like SayCan that directly uses LM scores for action selection, your method maintains a trainable policy while leveraging LMs for task simplification. This makes your approach more adaptable to different environments and modalities beyond just text.- Using multiple LM modules in coordination is a novel concept not explored before. You show this can be more effective than relying on a single LM, since each module targets a different aspect of assisting the agent.- There is still room for improvement in how language models are incorporated. For example, future work could explore:1) More advanced prompting techniques to get better subtask plans from the LM. 2) Using LMs for dynamic replanning when subtasks fail. 3) Leveraging LMs to provide knowledge about the environment and dynamics (like reading an instruction manual).4) Integrating commonsense reasoning and affordance modeling from LMs more tightly into the policy learning.5) Scaling up the frameworks to more complex environments beyond AlfWorld.Overall, your PET framework advances the state-of-the-art in effectively utilizing LM knowledge for embodied agents. The modular coordination of multiple LMs is innovative. There are many exciting avenues to further improve agents by incorporating additional LM capabilities in future work.
