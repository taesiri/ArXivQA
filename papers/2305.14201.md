# [Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks](https://arxiv.org/abs/2305.14201)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: Can a large language model be fine-tuned to excel at basic arithmetic tasks through supervised training alone, without needing to apply special techniques like chain-of-thought prompting?The key hypotheses seem to be:1) LLaMA's consistent tokenization of numbers enables it to learn to perform addition and subtraction of large integers with near perfect accuracy simply through end-to-end supervised fine-tuning.2) For more complex tasks like large integer multiplication and division, decomposition into simpler subtasks guided by basic arithmetic principles can enable the model to learn these tasks more effectively. 3) The proposed decomposition results in a chain-of-thought that is easily interpretable by humans.4) The fine-tuned model, dubbed Goat, can match or surpass the performance of powerful models like GPT-4 on arithmetic reasoning, even in a zero-shot setting.In summary, the central research question is whether supervised tuning alone is sufficient for LLaMA to master arithmetic tasks, with the key hypothesis being that leveraging its consistent number tokenization and proposing an interpretable decomposition scheme enables this. Evaluating Goat's performance verifies these hypotheses.
