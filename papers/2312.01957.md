# [Distilled Self-Critique of LLMs with Synthetic Data: a Bayesian   Perspective](https://arxiv.org/abs/2312.01957)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the paper:

This paper proposes a new method called distilled Self-Critique (dSC) for aligning large language models (LLMs) with human values. dSC builds on prior work framing reinforcement learning from human feedback as Bayesian inference. The key idea is to refine LLM outputs through a Markov Chain Monte Carlo sampler that alternates between critique and revision steps, using only synthetic data. The samples are then used to fine-tune the LLM to distill the refined responses. Experiments on improving safety, sentiment, and privacy control demonstrate that dSC can effectively steer LLMs at low cost. The method incorporates an explicit likelihood model based on an external reward (unlike Self-Refine), includes explicit critique and revision steps (unlike ReST), and has a distillation phase (unlike both). dSC provides a novel perspective of criticizing and revising an LLM's own generations as Bayesian inference, opening avenues for further improvements.
