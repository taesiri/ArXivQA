# [ANLS* -- A Universal Document Processing Metric for Generative Large   Language Models](https://arxiv.org/abs/2402.03848)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Evaluating generative language models (GLMs) on document processing tasks is challenging since the binary true/false metrics used for discriminative models don't apply. 
- Existing GLM evaluation metrics like ANLS can only handle strings and lists, not more complex outputs needed for information extraction.

Proposed Solution:  
- The paper introduces a new metric called ANLS* that extends ANLS to support more data types like dictionaries, enables handling of complex nested output structures, and is compatible with prior ANLS scores.

- ANLS* works by converting the ground truth and prediction into tree structures and comparing them, allowing flexibility in handling different data types and combinations. Things like typos, missing elements, incorrect types, etc. are penalized.

Main Contributions:
- Definition and implementation of the ANLS* metric that is a drop-in replacement for ANLS while being more versatile.

- Evaluation of ANLS* on 7 datasets and 3 GLMs, establishing strong quantitative evidence for its usefulness. 

- Introduction and evaluation of a new prompting method called SFT that outperforms prior prompting techniques like LATIN in 15 out of 21 test cases.

- Providing benchmark scores on multiple datasets using various GLMs that set a baseline for future work. 

In summary, the paper makes important contributions in GLM evaluation for document tasks by proposing the flexible ANLS* metric, showing its effectiveness empirically, and advancing prompting techniques. The resources released also enable further research.
