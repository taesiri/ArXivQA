# [Elysium: Exploring Object-level Perception in Videos via MLLM](https://arxiv.org/abs/2403.16558)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Multi-modal large language models (MLLMs) have shown strong capabilities for perceiving objects in images, but their application to video-related tasks like object tracking remains limited. This is due to: 1) Lack of large-scale pretraining video data to equip models with temporal understanding and 2) Processing many frames strains compute resources.  

Proposed Solution: 
- Introduce Elysium, an end-to-end trainable MLLM for object-level perception in videos. Main components:
1) Visual encoder (CLIP-ViT-L)
2) Language model (Vicuna)
3) Token compression model (T-Selector) to reduce token usage

- Construct ElysiumTrack-1M, a new 1.27M video dataset with trajectories and descriptions to support tasks like single object tracking (SOT), referring SOT (RSOT) and video referring expression generation (Video-REG).

- Use progressive training strategy with image pretraining then video finetuning. Employ techniques like random frame sampling and clipping to handle varying frame rates.

Main Contributions:

1) ElysiumTrack-1M large-scale video dataset with 1.27M annotated video frames to support SOT, RSOT and Video-REG tasks.

2) Elysium MLLM architecture with T-Selector token compressor to enhance video perception while using fewer tokens.

3) State-of-the-art results on tasks like image grounding, zero-shot VideoQA, SOT and strong performance on new RSOT and Video-REG tasks.

4) Demonstrated MLLMs can effectively perceive objects in videos and handle temporal relationships, expanding their applicability.

Limitations:
- Performance drops for tiny objects. Future work needed for tasks like video object segmentation.
