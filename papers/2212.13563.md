# [Noise-aware Learning from Web-crawled Image-Text Data for Image   Captioning](https://arxiv.org/abs/2212.13563)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the main research question this paper aims to address is:How can we develop an image captioning model that is robust to noisy image-text pairs in web-crawled datasets, while still being able to leverage the rich visual knowledge in the data? The key hypothesis seems to be that by making the captioning model alignment-level-controllable via a discrete conditioning signal during training, it can learn to generate high quality captions at inference time by setting the control signal to indicate a high desired alignment level. This allows the model to take advantage of the full dataset during training without being overly disrupted by misaligned noisy pairs.
