# [LibriTTS-R: A Restored Multi-Speaker Text-to-Speech Corpus](https://arxiv.org/abs/2305.18802)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is whether applying speech restoration to improve the audio quality of the LibriTTS corpus leads to improved performance of text-to-speech (TTS) models trained on the restored data. Specifically, the authors hypothesize that by restoring the audio in LibriTTS to higher quality using a speech restoration model, they can create a new dataset called LibriTTS-R that will enable training higher quality TTS models compared to training on the original LibriTTS data.The key points are:- LibriTTS is a large multi-speaker TTS corpus but has audio quality issues that limit TTS performance. - The authors apply a speech restoration model called Miipher to clean up and improve the audio quality of LibriTTS, creating a new dataset called LibriTTS-R.- They evaluate LibriTTS-R by training TTS models on it and comparing to models trained on original LibriTTS data. - Results show TTS models trained on LibriTTS-R achieve significantly higher quality and naturalness, validating their hypothesis that restoring the audio improves TTS performance.So in summary, the central research question is whether applying speech restoration to LibriTTS can create a better dataset for training higher quality TTS models. The experiments aim to demonstrate that LibriTTS-R enables improved TTS compared to the original LibriTTS corpus.


## What is the main contribution of this paper?

The main contribution of this paper is the release of LibriTTS-R, a restored and improved version of the LibriTTS speech corpus for text-to-speech (TTS). The key points are:- LibriTTS-R was created by applying a speech restoration model called Miipher to the original LibriTTS corpus. This improved the sound quality compared to the original LibriTTS.- Subjective evaluations showed the speech naturalness of a TTS model trained on LibriTTS-R was significantly improved compared to one trained on the original LibriTTS, and reached near parity with real human speech.- LibriTTS-R has the same amount of data (585 hours), speakers (2,456), and texts as LibriTTS, but with enhanced audio quality. This makes it a large, free, multi-speaker corpus suitable for training high-quality TTS models.- The corpus is freely released for download to facilitate TTS research. Comparisons showed it enables better TTS models compared to the widely used but lower audio quality LibriTTS.In summary, the key contribution is creating and releasing an improved version of an existing TTS corpus to advance research - LibriTTS-R with better audio but same speakers/texts as LibriTTS. The evaluations and release enable the community to train better TTS models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper introduces LibriTTS-R, a restored and improved version of the LibriTTS multi-speaker speech dataset for text-to-speech, created by applying speech restoration to the original LibriTTS samples.
