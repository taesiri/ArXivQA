# Compression, Transduction, and Creation: A Unified Framework for   Evaluating Natural Language Generation

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is: A unified perspective based on information change from input to output can facilitate the design of effective and interpretable evaluation metrics across diverse natural language generation tasks.In particular, the key claims are:1) NLG tasks can be categorized into compression, transduction and creation based on how information changes from input to output. 2) The concept of information alignment, measuring the overlap between input, output, context etc., plays a central role in characterizing the quality of generation across tasks.3) Metrics designed based on information alignment can achieve strong correlation with human judgements of quality for key aspects of various NLG tasks.4) A single accurate alignment prediction model benefits metrics for multiple tasks/aspects.So in summary, the paper proposes and validates a framework based on information change and alignment that provides a unified perspective for developing and improving NLG evaluation metrics.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a unified framework for evaluating various natural language generation (NLG) tasks based on the concept of information alignment. The key points are:- It categorizes NLG tasks into compression, transduction and creation based on how information changes from input to output. - It proposes that information alignment, defined as the overlap between the information in different components like input, output and context, is a core concept connecting evaluation across diverse NLG tasks. - It demonstrates the framework by devising intuitive metrics for key aspects of summarization, style transfer and dialog tasks purely based on measuring information alignment. - The metrics are shown to achieve strong correlation with human judgments, often outperforming prior specialized metrics designed individually for each task.- The framework offers a systematic way to design and improve evaluation metrics by improving the underlying information alignment estimation. It also provides interpretability by examining the token-level alignments.In summary, the paper presents a principled and unified perspective for tackling the challenging problem of automatic NLG evaluation across different tasks. The information-alignment based techniques formulate effective metrics and also open up possibilities for modular and composable NLG systems.
