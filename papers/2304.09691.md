# [DarSwin: Distortion Aware Radial Swin Transformer](https://arxiv.org/abs/2304.09691)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be: How can we design a transformer-based model that can automatically adapt to the distortion produced by different wide-angle lenses?

The key ideas and contributions seem to be:

- Proposing a novel transformer encoder architecture called DarSwin that embeds knowledge of the lens distortion profile into its structure. This allows it to adapt to different distortion profiles.

- Introducing distortion-aware components into DarSwin:
  - Polar patch partitioning 
  - Distortion-based sampling for token embeddings
  - Angular relative positional encoding for patch merging

- Showing through classification experiments on distorted ImageNet that DarSwin can perform zero-shot generalization to different lens distortion profiles much better than baseline methods like Swin and deformable attention transformers.

So in summary, the main hypothesis is that by designing a distortion-aware transformer model like DarSwin, we can enable better generalization and adaptation to different lens distortion profiles in a zero-shot manner. The paper aims to demonstrate this via extensive experiments.
