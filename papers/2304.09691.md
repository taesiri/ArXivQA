# [DarSwin: Distortion Aware Radial Swin Transformer](https://arxiv.org/abs/2304.09691)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be: How can we design a transformer-based model that can automatically adapt to the distortion produced by different wide-angle lenses?

The key ideas and contributions seem to be:

- Proposing a novel transformer encoder architecture called DarSwin that embeds knowledge of the lens distortion profile into its structure. This allows it to adapt to different distortion profiles.

- Introducing distortion-aware components into DarSwin:
  - Polar patch partitioning 
  - Distortion-based sampling for token embeddings
  - Angular relative positional encoding for patch merging

- Showing through classification experiments on distorted ImageNet that DarSwin can perform zero-shot generalization to different lens distortion profiles much better than baseline methods like Swin and deformable attention transformers.

So in summary, the main hypothesis is that by designing a distortion-aware transformer model like DarSwin, we can enable better generalization and adaptation to different lens distortion profiles in a zero-shot manner. The paper aims to demonstrate this via extensive experiments.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution appears to be proposing a new transformer-based architecture called DarSwin that can automatically adapt to the distortion profile of a camera lens. The key ideas are:

- Using a polar patch partitioning strategy rather than the cartesian strategy typically used in vision transformers like Swin. This allows the image patches to better match the radial distortion of wide-angle lenses.

- Employing a distortion-aware sampling technique to create token embeddings from the polar patches. This helps embed knowledge of the lens distortion into the model architecture.

- Using an angular relative positional encoding scheme to capture relationships between the polar patch tokens. 

- Introducing distortion-aware polar patch merging operations in the hierarchical architecture.

Through experiments on distorted ImageNet images, the authors demonstrate that DarSwin can perform zero-shot generalization to new lens distortion profiles not seen during training. Compared to baselines like Swin and deformable attention transformers, DarSwin achieves superior performance when evaluating on out-of-distribution distortions.

In summary, the key contribution appears to be proposing a novel transformer architecture that can implicitly adapt to lens distortion profiles, enabling better generalization across different wide-angle lenses compared to prior approaches. The polar coordinate-based design choices allow embedding distortion knowledge into the model itself.
