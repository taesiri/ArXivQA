# Large Language Models are Zero-Shot Reasoners

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be whether large language models (LLMs) like GPT-3 can demonstrate effective reasoning abilities in a zero-shot setting, without task-specific examples or prompts. The key hypothesis appears to be that LLMs contain untapped "dark knowledge" related to reasoning and logic that can be elicited through a simple, general prompt like "Let's think step by step" rather than requiring carefully engineered, task-specific prompts or demonstrations. The authors compare their proposed "Zero-shot Chain of Thought" (Zero-shot-CoT) prompting method against standard zero-shot prompting as well as few-shot prompting methods like "Chain of Thought" (CoT) prompting. Their goal is to show that Zero-shot-CoT can substantially improve reasoning performance across diverse tasks compared to standard zero-shot prompting, while approaching or exceeding the performance of few-shot methods without needing task-specific engineering.In summary, the central research question seems to be whether LLMs have strong latent zero-shot reasoning abilities that can be unlocked with a simple prompt, rather than needing task-specific examples or prompts. The hypothesis is that Zero-shot-CoT prompting can elicit this "logical dark knowledge" and significantly improve zero-shot reasoning performance.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:1. Proposing a simple yet effective template-based prompt called "Zero-shot Chain of Thought (Zero-shot-CoT)" that elicits reasoning chains from large language models in a zero-shot manner, without needing any per-task prompt engineering or reasoning examples.2. Showing that this single, fixed prompt facilitates multi-step reasoning and significantly improves the zero-shot reasoning capability of large LMs across diverse benchmark reasoning tasks, including arithmetic, symbolic, and logical reasoning.3. Demonstrating that large LMs have untapped zero-shot reasoning capabilities that can be uncovered through careful prompting, rather than only being good few-shot reasoners as commonly believed. 4. Providing insights into the importance of analyzing the zero-shot knowledge already present in large LMs before crafting task-specific prompts or datasets.5. Introducing the notion of "logical dark knowledge" - the high-level, task-agnostic reasoning skills latent in LMs that can be extracted through prompts like Zero-shot-CoT.6. Establishing a strong zero-shot reasoning baseline that significantly outperforms prior work, serving as a minimal reference for future research into reasoning capabilities of large LMs.In summary, the key contribution is unveiling the surprisingly capable zero-shot reasoning skills of large LMs using a simple yet broadly effective prompt, and advocating for further research into extracting multi-task cognitive abilities from LMs. The proposed Zero-shot-CoT prompt establishes new state-of-the-art zero-shot reasoning performance across multiple benchmark tasks.
