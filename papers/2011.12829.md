# [All You Need is a Good Functional Prior for Bayesian Deep Learning](https://arxiv.org/abs/2011.12829)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we impose more interpretable, Gaussian process-like functional priors on Bayesian neural networks, and what effect does this have on the predictive performance of the models?The key points are:- Specifying sensible priors over the many parameters of modern neural nets is challenging. The induced functional prior (distribution of functions obtained by sampling the parameters) is hard to characterize. - In contrast, Gaussian process priors offer a more intuitive way to define distributions over functions in terms of properties like smoothness and lengthscale.- The authors propose matching the functional prior of a neural net to a target GP prior by minimizing the Wasserstein distance between them. This is done by optimizing the parameters of the neural net prior.- They show that using GP-induced priors instead of standard parameter priors (like i.i.d. Gaussians) leads to improved predictive performance across a range of neural network architectures and datasets when doing full Bayesian inference.So in summary, the central hypothesis is that using more interpretable functional priors from GPs can improve Bayesian neural nets, and they provide evidence for this via the Wasserstein matching procedure and experiments. The overall goal is advancing the usability of Bayesian deep learning.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution is developing a method to impose interpretable functional priors on Bayesian neural networks (BNNs) by matching the prior distribution over functions induced by the BNN to a target Gaussian process (GP) prior. Specifically, the key points are:- Reasoning about functional priors is more intuitive than specifying priors over weights for BNNs, but directly imposing GP priors on BNNs is analytically intractable due to their nonlinear nature.- The authors propose minimizing the Wasserstein distance between the BNN and GP functional priors by optimizing the parameters of the BNN prior. This provides an efficient way to match the BNN prior to a desired GP prior.- They demonstrate that using common GP priors like the RBF kernel as targets leads to improved performance over standard parameter priors across various BNN models and tasks.- The benefits are shown through extensive experiments including Bayesian CNNs and regression/classification tasks. The GP-induced priors give systematic improvements in generalization and robustness compared to standard weight priors and competitive baselines.In summary, the main contribution is a practical framework to impose interpretable GP functional priors on BNNs by optimizing the Wasserstein distance between priors. This allows translating the intuitions and properties of GP priors to BNNs, leading to performance improvements.
