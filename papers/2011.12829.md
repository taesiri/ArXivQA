# [All You Need is a Good Functional Prior for Bayesian Deep Learning](https://arxiv.org/abs/2011.12829)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we impose more interpretable, Gaussian process-like functional priors on Bayesian neural networks, and what effect does this have on the predictive performance of the models?The key points are:- Specifying sensible priors over the many parameters of modern neural nets is challenging. The induced functional prior (distribution of functions obtained by sampling the parameters) is hard to characterize. - In contrast, Gaussian process priors offer a more intuitive way to define distributions over functions in terms of properties like smoothness and lengthscale.- The authors propose matching the functional prior of a neural net to a target GP prior by minimizing the Wasserstein distance between them. This is done by optimizing the parameters of the neural net prior.- They show that using GP-induced priors instead of standard parameter priors (like i.i.d. Gaussians) leads to improved predictive performance across a range of neural network architectures and datasets when doing full Bayesian inference.So in summary, the central hypothesis is that using more interpretable functional priors from GPs can improve Bayesian neural nets, and they provide evidence for this via the Wasserstein matching procedure and experiments. The overall goal is advancing the usability of Bayesian deep learning.
