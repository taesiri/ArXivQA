# [Self-Supervised Feature Learning by Learning to Spot Artifacts](https://arxiv.org/abs/1806.05024)

## What is the central research question or hypothesis that this paper addresses?

The central research question of this paper is:Can a discriminative model trained to distinguish between real images and images with synthetic artifacts learn useful visual representations without human supervision?The key hypothesis is that a model trained to spot artificial artifacts in images will need to build an accurate internal representation of real object appearance and thus develop features that could transfer well to other visual tasks like classification, detection and segmentation.The paper proposes a novel self-supervised learning framework based on adversarial training to address this question. The key ideas are:- Generate images with artifacts by encoding real images, dropping feature entries in the bottleneck, and decoding with a limited "repair" network.- Train a discriminator model adversarially against the repair network to classify images as real or with artifacts.- Make the discriminator also predict the mask of dropped features so it localizes all artifacts.- Use the same autoencoder to replicate real images to avoid the discriminator exploiting low-level cues. - Transfer the discriminator features to other tasks to evaluate how useful the learned representations are.The central hypothesis is that to accurately spot images with synthetic artifacts, the discriminator would need to develop a strong internal representation of real object appearance. The paper aims to demonstrate this through extensive experiments showing transfer learning performance on several standard benchmarks.


## What is the main contribution of this paper?

The main contribution of this paper is a novel self-supervised learning method for feature learning that does not require manual image annotations. The key ideas are:- They propose a new pretext task of training a model to distinguish real images from images with synthetic artifacts. The artifacts are created by corrupting an image's feature representation rather than the raw pixels.- They introduce a "damage and repair" strategy to generate the synthetic images with artifacts. An autoencoder is used to first encode the image. Then the encoded features are partially "damaged" by dropping feature values randomly. A "repair" network is used to try to reconstruct the damaged representation back into a realistic image, but it has limited capacity so artifacts remain.- The model is trained adversarially, with a discriminator trying to detect the synthetic images and a repair network trying to fool it. The discriminator learns features that capture the statistics of real images in order to detect the artifacts.- The features learned by the discriminator transfer well to other tasks like classification, detection and segmentation, achieving state-of-the-art results on several benchmarks.In summary, the key contribution is a novel self-supervised approach for learning visual features by classifying real vs artificially corrupted images, which does not require manual annotation. The adversarial damage and repair method generates useful artifacts for this task.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper introduces a self-supervised learning method that trains a neural network to distinguish real images from images with synthetic artifacts, in order to learn features that can be transferred to other computer vision tasks.


## How does this paper compare to other research in the same field?

This paper introduces a novel approach for self-supervised feature learning using adversarial training. Here are a few key ways it compares to prior work:- It proposes a new pretext task of distinguishing real images from images with synthetic artifacts for self-supervision. Most prior work uses other pretext tasks like predicting context, colorization, solving jigsaw puzzles, etc. This artifact detection task is unique.- It uses a combination of autoencoders and adversarial networks to generate the images with artifacts in a controlled way. This allows creating artifacts that are non-trivial for a model to spot. Many papers use adversarial training but not in this manner.- The model trains a discriminator network to classify real vs artifact images and predict a spatial mask localizing the artifacts. This helps ensure the discriminator learns robust features focusing on semantic content rather than textures.- It incorporates a "repair" network that is restricted to only modify the masked regions, preventing unrealistic global changes. This differs from typical GAN architectures.- The transfer learning results achieve state-of-the-art on several benchmarks like ImageNet, Pascal VOC, and STL-10. This demonstrates the usefulness of the learned features.Overall, the key novelty is in the artifact detection pretext task combined with the adversarial training approach to generate controlled artifacts. The strength of the method is shown in the strong transfer learning performance. It represents an innovative way to exploit adversarial nets for self-supervised representation learning.
