# [Self-Supervised Feature Learning by Learning to Spot Artifacts](https://arxiv.org/abs/1806.05024)

## What is the central research question or hypothesis that this paper addresses?

The central research question of this paper is:Can a discriminative model trained to distinguish between real images and images with synthetic artifacts learn useful visual representations without human supervision?The key hypothesis is that a model trained to spot artificial artifacts in images will need to build an accurate internal representation of real object appearance and thus develop features that could transfer well to other visual tasks like classification, detection and segmentation.The paper proposes a novel self-supervised learning framework based on adversarial training to address this question. The key ideas are:- Generate images with artifacts by encoding real images, dropping feature entries in the bottleneck, and decoding with a limited "repair" network.- Train a discriminator model adversarially against the repair network to classify images as real or with artifacts.- Make the discriminator also predict the mask of dropped features so it localizes all artifacts.- Use the same autoencoder to replicate real images to avoid the discriminator exploiting low-level cues. - Transfer the discriminator features to other tasks to evaluate how useful the learned representations are.The central hypothesis is that to accurately spot images with synthetic artifacts, the discriminator would need to develop a strong internal representation of real object appearance. The paper aims to demonstrate this through extensive experiments showing transfer learning performance on several standard benchmarks.


## What is the main contribution of this paper?

The main contribution of this paper is a novel self-supervised learning method for feature learning that does not require manual image annotations. The key ideas are:- They propose a new pretext task of training a model to distinguish real images from images with synthetic artifacts. The artifacts are created by corrupting an image's feature representation rather than the raw pixels.- They introduce a "damage and repair" strategy to generate the synthetic images with artifacts. An autoencoder is used to first encode the image. Then the encoded features are partially "damaged" by dropping feature values randomly. A "repair" network is used to try to reconstruct the damaged representation back into a realistic image, but it has limited capacity so artifacts remain.- The model is trained adversarially, with a discriminator trying to detect the synthetic images and a repair network trying to fool it. The discriminator learns features that capture the statistics of real images in order to detect the artifacts.- The features learned by the discriminator transfer well to other tasks like classification, detection and segmentation, achieving state-of-the-art results on several benchmarks.In summary, the key contribution is a novel self-supervised approach for learning visual features by classifying real vs artificially corrupted images, which does not require manual annotation. The adversarial damage and repair method generates useful artifacts for this task.
