# [Self-Supervised Feature Learning by Learning to Spot Artifacts](https://arxiv.org/abs/1806.05024)

## What is the central research question or hypothesis that this paper addresses?

The central research question of this paper is:Can a discriminative model trained to distinguish between real images and images with synthetic artifacts learn useful visual representations without human supervision?The key hypothesis is that a model trained to spot artificial artifacts in images will need to build an accurate internal representation of real object appearance and thus develop features that could transfer well to other visual tasks like classification, detection and segmentation.The paper proposes a novel self-supervised learning framework based on adversarial training to address this question. The key ideas are:- Generate images with artifacts by encoding real images, dropping feature entries in the bottleneck, and decoding with a limited "repair" network.- Train a discriminator model adversarially against the repair network to classify images as real or with artifacts.- Make the discriminator also predict the mask of dropped features so it localizes all artifacts.- Use the same autoencoder to replicate real images to avoid the discriminator exploiting low-level cues. - Transfer the discriminator features to other tasks to evaluate how useful the learned representations are.The central hypothesis is that to accurately spot images with synthetic artifacts, the discriminator would need to develop a strong internal representation of real object appearance. The paper aims to demonstrate this through extensive experiments showing transfer learning performance on several standard benchmarks.


## What is the main contribution of this paper?

The main contribution of this paper is a novel self-supervised learning method for feature learning that does not require manual image annotations. The key ideas are:- They propose a new pretext task of training a model to distinguish real images from images with synthetic artifacts. The artifacts are created by corrupting an image's feature representation rather than the raw pixels.- They introduce a "damage and repair" strategy to generate the synthetic images with artifacts. An autoencoder is used to first encode the image. Then the encoded features are partially "damaged" by dropping feature values randomly. A "repair" network is used to try to reconstruct the damaged representation back into a realistic image, but it has limited capacity so artifacts remain.- The model is trained adversarially, with a discriminator trying to detect the synthetic images and a repair network trying to fool it. The discriminator learns features that capture the statistics of real images in order to detect the artifacts.- The features learned by the discriminator transfer well to other tasks like classification, detection and segmentation, achieving state-of-the-art results on several benchmarks.In summary, the key contribution is a novel self-supervised approach for learning visual features by classifying real vs artificially corrupted images, which does not require manual annotation. The adversarial damage and repair method generates useful artifacts for this task.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper introduces a self-supervised learning method that trains a neural network to distinguish real images from images with synthetic artifacts, in order to learn features that can be transferred to other computer vision tasks.


## How does this paper compare to other research in the same field?

This paper introduces a novel approach for self-supervised feature learning using adversarial training. Here are a few key ways it compares to prior work:- It proposes a new pretext task of distinguishing real images from images with synthetic artifacts for self-supervision. Most prior work uses other pretext tasks like predicting context, colorization, solving jigsaw puzzles, etc. This artifact detection task is unique.- It uses a combination of autoencoders and adversarial networks to generate the images with artifacts in a controlled way. This allows creating artifacts that are non-trivial for a model to spot. Many papers use adversarial training but not in this manner.- The model trains a discriminator network to classify real vs artifact images and predict a spatial mask localizing the artifacts. This helps ensure the discriminator learns robust features focusing on semantic content rather than textures.- It incorporates a "repair" network that is restricted to only modify the masked regions, preventing unrealistic global changes. This differs from typical GAN architectures.- The transfer learning results achieve state-of-the-art on several benchmarks like ImageNet, Pascal VOC, and STL-10. This demonstrates the usefulness of the learned features.Overall, the key novelty is in the artifact detection pretext task combined with the adversarial training approach to generate controlled artifacts. The strength of the method is shown in the strong transfer learning performance. It represents an innovative way to exploit adversarial nets for self-supervised representation learning.


## What future research directions do the authors suggest?

Based on my reading of the paper, some future research directions suggested by the authors include:- Exploring other types of artifacts and corruptions to generate the fake images for the discriminator training. The paper focuses on dropping out feature channels, but other ways of introducing artifacts could further improve the self-supervised learning.- Applying the approach to other data modalities like video, audio, etc. The current method is demonstrated on still images, but could potentially work for other data types.- Investigating the effect of different encoder architectures in terms of feature locality and overlap. The design of the encoder impacts how localized the damage is when dropping feature channels.- Analyzing what the discriminator focuses on for its real vs fake classification decision. More detailed understanding of what it learns to spot as artifacts could further improve the framework.- Combining the approach with other self-supervised methods in a multi-task learning setup. Joint training on multiple pretext tasks could potentially lead to even better feature learning.- Exploring semi-supervised learning by combining the approach with a small amount of labeled data. The self-supervised task could complement supervised learning when labels are scarce.- Applying the learned features to other downstream tasks like video analysis, reinforcement learning, etc. Testing how well the features transfer across a diverse set of applications.In summary, the authors propose several promising research directions to build on their approach for artifact detection as a pretext task for self-supervised feature learning. The key opportunities are around exploring different ways to generate artifacts, combining with other learning signals, and evaluating the transferability to various downstream tasks.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:This paper introduces a novel self-supervised learning method for training a neural network to extract useful image features without human-provided labels. The key idea is to train a discriminator network to distinguish real images from images with synthetic artifacts. To generate images with artifacts, the authors first pre-train a high-capacity autoencoder. They then damage the output of the encoder by randomly dropping feature map values, and augment the decoder with a repair network that partially inpaints the missing information. This results in images that look locally real but globally incoherent. The repair network and discriminator are trained adversarially - the repair network tries to generate more realistic images that fool the discriminator, while the discriminator tries to identify the artifacts. The discriminator learns a robust model of real images in the process. The authors show that features from the discriminator transfer well to other domains, achieving state-of-the-art results on ILSVRC2012, Pascal VOC and STL-10 classification benchmarks. The key contributions are: 1) a novel self-supervised feature learning framework based on classifying real vs artificially damaged images 2) a method to synthesize images with non-trivial artifacts using autoencoders and adversarial training 3) state-of-the-art transfer learning performance on several benchmarks.
