# Building Cooperative Embodied Agents Modularly with Large Language
  Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:Can Large Language Models (LLMs) help build cooperative embodied agents that can collaborate with other agents and humans to accomplish complex tasks through collaborative planning and communication?The key hypothesis appears to be that recent LLMs, such as GPT-4, have the reasoning capacity and language skills to enable embodied agents to plan, communicate, and cooperate effectively with minimal training. The authors aim to investigate whether LLMs have the necessary abilities for embodied multi-agent cooperation, including extracting information from observations, revising beliefs about the world and other agents, deciding when and what to communicate, and collaboratively planning to achieve shared goals. To test this hypothesis, the authors propose a novel framework that utilizes LLMs to build cooperative agents and evaluate it in multi-agent embodied environments like Communicative Watch-And-Help and ThreeDWorld Multi-Agent Transport.The central research thrust seems to be demonstrating that, with their framework, LLMs can surpass planning-based methods and exhibit emergent communication and cooperation skills without requiring fine-tuning or few-shot prompting. The authors also examine whether LLM agents can gain human trust and cooperate effectively.In summary, the key research question is whether LLMs can enable embodied AI agents to successfully cooperate and communicate with minimal training, which the proposed framework aims to investigate through experiments in multi-agent cooperation tasks.
