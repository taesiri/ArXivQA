# [RakutenAI-7B: Extending Large Language Models for Japanese](https://arxiv.org/abs/2403.15484)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There has been limited development of large language models (LLMs) tailored for the Japanese language compared to English. Existing Japanese LLMs also have issues such as poor tokenization leading to inefficient text processing.

Proposed Solution: 
- The authors introduce RakutenAI-7B, a suite of Japanese-oriented LLMs with up to 7 billion parameters.
- They improve the tokenization process specifically for Japanese text, increasing the character-per-token ratio. This allows longer text sequences to be processed.
- The foundation LLM is pre-trained on filtered datasets of 175 billion Japanese and English tokens. Additional instruction- and chat-tuned models are released.
- The models are evaluated on Japanese and English benchmarks from the LM Evaluation Harness and achieve state-of-the-art results.

Main Contributions:
- Release of RakutenAI-7B foundation LLM and specialized instruction- and chat-tuned models for Japanese.
- Optimized tokenization for Japanese text resulting in more efficient processing. 
- Evaluation showing these models outperform existing open Japanese LLMs on Japanese and competitive results on English benchmarks.
- The models are freely available to the community to foster innovation for Japanese NLP.

In summary, the authors have systematically developed a suite of large language models purpose-built for Japanese that achieve excellent performance. The optimized tokenization and availability of these accurate models is a valuable contribution for Japanese NLP research and applications.
