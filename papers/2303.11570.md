# [Boundary Unlearning](https://arxiv.org/abs/2303.11570)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we efficiently unlearn or forget an entire class from a trained deep neural network model? The paper proposes a new approach called "Boundary Unlearning" to address this question. The key ideas are:- Focus on shifting the decision boundary of the DNN model rather than scrubbing model parameters directly. This allows more efficient unlearning by operating in the model's decision space rather than parameter space.- Propose two strategies to shift the decision boundary: Boundary Shrink and Boundary Expanding. These are designed to destroy the decision boundary for the forgetting class while maintaining boundaries of remaining classes.- Achieve utility guarantee by only changing the boundary of the forgetting class while keeping other boundaries intact. Achieve privacy guarantee by pushing forgetting data to boundaries to make the model uncertain about them.- Rapidly shift boundaries with just a few epochs of adjustment rather than full retraining or expensive parameter optimization.So in summary, the central hypothesis is that shifting decision boundaries can enable rapid and effective unlearning of an entire class from a DNN model. The Boundary Unlearning methods are proposed to test this hypothesis.


## What is the main contribution of this paper?

The main contributions of this paper are:- It proposes Boundary Unlearning, a new machine unlearning method to forget an entire class from a trained neural network model by shifting the decision boundary. This is the first work to focus on manipulating the decision space instead of the parameter space for unlearning.- It introduces two novel boundary shift methods - Boundary Shrink and Boundary Expanding - to effectively shift the decision boundary to forget the target class while maintaining utility on the remaining data.- It provides extensive experiments on image classification and face recognition tasks, demonstrating Boundary Unlearning can rapidly and efficiently forget the target class. It outperforms prior unlearning methods in utility, privacy and efficiency.- It reveals the connection between shifting the decision boundary and forgetting in neural networks, providing new insights into how to accomplish machine unlearning via the decision space. In summary, the key innovation is the idea of manipulating the decision boundary rather than model parameters to forget, which is more efficient and does not interfere with the original training process. The proposed Boundary Shrink and Expanding methods effectively implement this idea to rapidly unlearn a class while preserving utility and privacy.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes Boundary Unlearning, a rapid and effective machine unlearning method that shifts the decision boundary of a trained DNN model to remove information about a forgetting class while maintaining utility on remaining classes.
