# [Boundary Unlearning](https://arxiv.org/abs/2303.11570)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we efficiently unlearn or forget an entire class from a trained deep neural network model? The paper proposes a new approach called "Boundary Unlearning" to address this question. The key ideas are:- Focus on shifting the decision boundary of the DNN model rather than scrubbing model parameters directly. This allows more efficient unlearning by operating in the model's decision space rather than parameter space.- Propose two strategies to shift the decision boundary: Boundary Shrink and Boundary Expanding. These are designed to destroy the decision boundary for the forgetting class while maintaining boundaries of remaining classes.- Achieve utility guarantee by only changing the boundary of the forgetting class while keeping other boundaries intact. Achieve privacy guarantee by pushing forgetting data to boundaries to make the model uncertain about them.- Rapidly shift boundaries with just a few epochs of adjustment rather than full retraining or expensive parameter optimization.So in summary, the central hypothesis is that shifting decision boundaries can enable rapid and effective unlearning of an entire class from a DNN model. The Boundary Unlearning methods are proposed to test this hypothesis.


## What is the main contribution of this paper?

The main contributions of this paper are:- It proposes Boundary Unlearning, a new machine unlearning method to forget an entire class from a trained neural network model by shifting the decision boundary. This is the first work to focus on manipulating the decision space instead of the parameter space for unlearning.- It introduces two novel boundary shift methods - Boundary Shrink and Boundary Expanding - to effectively shift the decision boundary to forget the target class while maintaining utility on the remaining data.- It provides extensive experiments on image classification and face recognition tasks, demonstrating Boundary Unlearning can rapidly and efficiently forget the target class. It outperforms prior unlearning methods in utility, privacy and efficiency.- It reveals the connection between shifting the decision boundary and forgetting in neural networks, providing new insights into how to accomplish machine unlearning via the decision space. In summary, the key innovation is the idea of manipulating the decision boundary rather than model parameters to forget, which is more efficient and does not interfere with the original training process. The proposed Boundary Shrink and Expanding methods effectively implement this idea to rapidly unlearn a class while preserving utility and privacy.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes Boundary Unlearning, a rapid and effective machine unlearning method that shifts the decision boundary of a trained DNN model to remove information about a forgetting class while maintaining utility on remaining classes.


## How does this paper compare to other research in the same field?

Here are my thoughts on how this paper on Boundary Unlearning compares to other research in the field of machine unlearning:- This paper focuses specifically on unlearning an entire class from a trained deep neural network model. Many other papers have looked at more general machine unlearning techniques that can remove arbitrary data samples or subsets. Focusing on unlearning a class is novel and has useful applications like removing a person's face data.- The key idea of shifting the decision boundary to mimic a model retrained from scratch is a unique approach not explored much before. Most prior work focuses on locating and scrubbing parameters related to the forgetting data. The boundary shifting perspective provides a more holistic view of how to alter the model's behavior.- The proposed methods of Boundary Shrink and Boundary Expanding offer new techniques to actually implement the boundary shifting idea. Using adversarial-style perturbations or adding/pruning shadow classes are clever ways to manipulate the decision boundary that haven't been proposed previously.- Experiments show Boundary Unlearning can effectively forget a class rapidly, with 17-19x speedups over retraining. This demonstrates practical efficiency improvements over alternatives like parameter scrubbing or rapid retraining methods.- Boundary Unlearning does not require any intervention in the original training process, unlike some prior rapid retraining techniques. This makes it easy to apply to any pretrained model.- The visualization of the decision space gives useful insights into how Boundary Unlearning actually transforms sample classifications and cluster densities. This level of understanding is missing from many existing methods.Overall, I think this paper makes excellent contributions by framing machine unlearning from a decision boundary viewpoint and introducing innovative techniques to shift boundaries. The experimental results validate the effectiveness and efficiency of Boundary Unlearning for forgetting classes. It pushes forward the state-of-the-art in making machine unlearning more practical.
