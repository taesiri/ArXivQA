# [TensoIR: Tensorial Inverse Rendering](https://arxiv.org/abs/2304.12461)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is: How can we perform inverse rendering to estimate scene geometry, materials, and unknown natural illumination from multi-view images in an efficient and accurate manner using neural representations? 

Specifically, the key hypotheses are:

1. By extending the TensoRF representation to jointly model both a radiance field and a physically-based rendering model, we can achieve high-quality reconstruction of scene properties like geometry, reflectance, and lighting for inverse rendering.

2. The efficiency of the tensor factorization-based representation allows accurate online computation of visibility and indirect lighting during optimization, leading to better accuracy compared to distilling them into separate networks. 

3. Modeling an additional lighting dimension in the tensor representation supports efficient multi-light capture and provides useful cues to resolve ambiguities and improve reconstruction.

In summary, the central goal is developing an efficient neural inverse rendering approach that can estimate high-fidelity scene properties from multi-view images under unknown natural illumination. The key hypotheses are using a joint radiance field and physical model representation based on tensor factorization, computing accurate light transport effects online, and supporting multi-light capture in the framework.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel inverse rendering approach based on tensor factorization and neural fields. Specifically:

- It extends TensoRF, a state-of-the-art radiance field modeling method, to also estimate scene geometry, surface reflectance, and environment illumination for inverse rendering. 

- It achieves joint radiance field reconstruction and physically-based model estimation, enabling high-quality novel view synthesis and relighting.

- It can accurately model secondary shading effects like shadows and indirect lighting by efficiently computing visibility and lighting integrals online during training. This is enabled by the tensor factorization representation.

- It supports input images captured under multiple unknown lighting conditions by adding a lighting dimension in the tensor representation. This provides more supervision and reduces ambiguity.

- It demonstrates superior performance over previous neural inverse rendering methods, like NeRF-based NeRFactor and SDF-based InvRender, in terms of both quality and efficiency on complex synthetic and real scenes.

In summary, the key contribution is a novel inverse rendering framework that leverages an efficient tensor factorization scene representation to achieve high-quality reconstruction of geometry, materials, and lighting from multi-view images. It outperforms previous methods and enables photorealistic novel view synthesis and relighting applications.
