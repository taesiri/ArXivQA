# [Efficient Off-Policy Safe Reinforcement Learning Using Trust Region   Conditional Value at Risk](https://arxiv.org/abs/2312.00342)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a new off-policy safe reinforcement learning algorithm called off-policy TRC that aims to maximize returns while satisfying risk measure-based safety constraints defined by conditional value at risk (CVaR). The key idea is to develop novel surrogate functions to estimate the CVaR constraint using off-policy data without suffering from distributional shift. An adaptive trust region is also introduced to ensure the updated policy does not deviate too much from the data distribution in the replay buffer. Through experiments on various MuJoCo and Safety Gym simulations as well as a real robot platform, off-policy TRC demonstrates excellent sample efficiency - rapidly satisfying safety constraints while achieving higher final returns compared to prior methods. The results highlight the benefits of an off-policy trust region approach for safe RL and the effectiveness of the proposed techniques to properly leverage off-policy data with distributional shift. Off-policy TRC provides a way forward for sample-efficient learning of policies that are both high-performing and safety-constrained based on risk measures.
