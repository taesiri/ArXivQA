# [Towards Generalist Prompting for Large Language Models by Mental Models](https://arxiv.org/abs/2402.18252)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Towards Generalist Prompting for Large Language Models by Mental Models":

Problem:
- Existing prompting methods for large language models (LLMs) either rely on task-specific examples requiring domain knowledge, or are simple but only work well on limited tasks. There is a need for a generalist prompting method that achieves strong performance across diverse tasks without manual selection of prompts.

Proposed Solution: 
- The paper introduces the concept of "generalist prompting" - optimal or near-optimal performance across tasks without manual prompt tuning.
- The paper proposes MeMo (Mental Models), an innovative prompting method fulfilling generalist prompting criteria. 
- MeMo introduces the concept of "mental models" to LLMs - cognitive structures for problem-solving and decision-making. 
- MeMo provides a definition and examples of mental models to LLMs.
- In downstream tasks, LLMs are guided to select suitable mental models themselves based on the problem context.

Main Contributions:
- Proposition of the novel concept of generalist prompting for LLMs.
- Design of MeMo, an effective generalist prompting method using mental models. 
- MeMo matches or approaches state-of-the-art performance across diverse logical reasoning, STEM, and commonsense reasoning tasks.
- MeMo eliminates need for manual selection/tuning of prompts for different tasks. 
- Analysis reveals LLMs' nuanced understanding and appropriate selection of mental models.
- Exploration of MeMo advances research towards truly generalist prompting paradigms.

In summary, the paper introduces generalist prompting and proposes MeMo as an innovative implementation leveraging mental models to make prompting more versatile across tasks while requiring less human effort in prompt engineering. Evaluations demonstrate MeMo's effectiveness as a generalist prompting technique for enhanced LLM performance.
