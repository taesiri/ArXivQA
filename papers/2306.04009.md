# [Triggering Multi-Hop Reasoning for Question Answering in Language Models   using Soft Prompts and Random Walks](https://arxiv.org/abs/2306.04009)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can language models be improved at multi-hop reasoning and chaining together multiple facts to answer questions, when they already encode a lot of factual knowledge?The key hypothesis appears to be:Training language models on random walks over knowledge graphs can provide a useful signal to improve their ability to compose facts and perform multi-hop reasoning.In particular, the paper proposes and tests two main methods:1) Modular Prompts (PaTH): Using separate prompt modules to first parse questions into incomplete random walk queries, and then generate full paths to the answer. 2) Mixture Training: Jointly training a single prompt on a mixture of QA data and random walk data.The central goal is to trigger the language models' ability to chain factual knowledge that they already encode, in order to perform better logical reasoning and answer multi-hop questions. The key hypothesis is that learning to map questions to knowledge graph paths provides a useful training signal for this.In summary, the paper aims to improve language models' multi-hop reasoning abilities by learning to leverage their existing factual knowledge in a more compositional way, using random walks over knowledge graphs as a training signal.


## What is the main contribution of this paper?

Here are the key points regarding the main contribution of this paper:- The paper focuses on improving the ability of language models like T5 to perform multi-hop reasoning in question answering. This involves composing together multiple facts to answer questions, rather than just relying on single-hop knowledge.- The main proposal is to use random walks over knowledge graphs as a training signal to teach the language models to chain facts together. The random walks provide paths connecting entities that the model can learn to mimic. - Two main methods are proposed to leverage the random walks: 1) A modular approach with separate prompts for parsing and chaining, 2) A joint training approach that mixes QA data and random walks.- Experiments show substantial gains over standard tuning methods, especially for very large T5 models (T5-XXL). The modular prompt approach performs the best, improving around 16 points over fine-tuning for T5-XXL.- The main conclusion is that random walks over structured knowledge provide a useful training signal for triggering multi-hop reasoning in large language models. The paper demonstrates improvements on a challenging 2-hop QA dataset using this technique.In summary, the core contribution is using random walks over knowledge graphs with soft prompts to improve multi-hop reasoning and question answering in large pre-trained language models like T5.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes using soft prompts trained on random walks over knowledge graphs to improve the ability of T5 language models to perform multi-hop reasoning and answer compositional questions, showing substantial gains over standard tuning methods.
