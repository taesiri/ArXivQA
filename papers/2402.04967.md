# [Text or Image? What is More Important in Cross-Domain Generalization   Capabilities of Hate Meme Detection Models?](https://arxiv.org/abs/2402.04967)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing multimodal hate meme detection models exhibit poor generalization capabilities when tested on out-of-domain datasets. Their performance drops significantly compared to in-domain testing.

- Prior work has shown text-only hate speech classifiers to have better cross-domain generalization. This paper investigates whether this also holds for multimodal hate meme detection. 

Methodology:
- Fine-tune 3 state-of-the-art multimodal hate meme classifiers (VisualBert, Uniter, RoBERTa+ResNet) on one dataset, test on other datasets. Performance drops hugely out-of-domain.

- Train text-only hate speech classifiers (SVM, BERT) on mixed-domain text corpora. Test on meme text only - performance on par with multimodal classifiers.

- Transform memes into text by concatenating meme text and captions from image. Performance of text classifiers improves further. 

- Analyze contribution of modalities using Shapley values. Text modality contributes 83% on average. Introduction of captions reduces text contribution to 52%.

- Evaluate on confounder dataset with text/image confounders. Classifiers are more sensitive to text confounders.

Key Findings:
- Text-only classifiers perform comparably (even better) than multimodal classifiers on memes in cross-domain setting.

- Including image captions in training worsens multimodal classifier performance.

- Images serve more as facilitators and provide context. Most contribution comes from text modality. Models struggle to effectively incorporate visual semantics. 

- Confounder analysis further proves models' sensitivity towards text changes compared to image changes.

Main Conclusions:
- For hate meme detection, cross-domain generalization stems primarily from textual part. Image part is sensitive to nuances of training data.

- Current multimodal models aligned more concrete text-image alignments. Captions misdirect attention to low-level alignments.

- Text-image alignment happens more at abstract metaphorical level which models fail to capture.

So in summary, text-only classifiers generalize better for multimodal hate meme detection, indicating models struggle to properly integrate visual information. Image meaning could be incorporated at a higher metaphorical level which needs addressing.
