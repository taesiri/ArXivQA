# [Automated Machine Learning on Graphs: A Survey](https://arxiv.org/abs/2103.00742)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main focus is to provide a comprehensive review of automated machine learning (AutoML) methods for graph data. The key topics covered are:

- Hyperparameter optimization (HPO) for graph machine learning models
- Neural architecture search (NAS) for graph neural networks (GNNs) 
- Existing libraries and tools for AutoML on graphs
- Future research directions in this area

The paper does not have an explicit hypothesis or propose a new method. Rather, it aims to summarize and discuss the current progress on applying AutoML techniques like HPO and NAS to graph data, highlight the unique challenges compared to other data types, and outline promising future work in this emerging research field. The overall goal seems to be providing the first dedicated review of AutoML methods tailored for graphs and promoting further studies on automating graph machine learning.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It provides a comprehensive and systematic review of automated machine learning on graphs, focusing on hyperparameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. 

2. It reviews and compares different methods for automating graph machine learning from three key aspects: search space design, search strategies, and performance estimation strategies. The challenges and advantages of different methods are discussed.

3. It gives an overview of libraries related to automated graph machine learning, with an in-depth discussion and introduction to AutoGL, the first dedicated open-source library for AutoML on graphs. The design principles and main modules of AutoGL are highlighted.

4. It outlines several promising future research directions for automated machine learning on graphs, including using graphs to facilitate AutoML, improving model robustness and explainability, incorporating hardware awareness, and developing more comprehensive evaluation protocols. 

In summary, this is the first comprehensive survey reviewing the studies on combining the strengths of graph machine learning and AutoML for automated machine learning on graph data. It provides useful guidelines and insights to facilitate future research in this direction.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

This paper provides a comprehensive review of automated machine learning (AutoML) methods for graph data, focusing on hyperparameter optimization and neural architecture search for graph machine learning models, and introduces AutoGL, an open-source library designed specifically for AutoML on graphs.


## How does this paper compare to other research in the same field?

 Here are a few key points about how this paper compares to other research in automated machine learning on graphs:

- This appears to be the first comprehensive survey focused specifically on automated machine learning for graph data. Other papers have surveyed broader topics like graph neural networks or AutoML, but not the intersection.

- The paper provides a structured categorization and review of methods for hyperparameter optimization and neural architecture search tailored to graph machine learning. It compares approaches based on search space design, search strategies, and performance estimation strategies.

- The paper gives an overview of libraries and tools that can support automated graph ML, with a particular focus on introducing AutoGL - the first open source library dedicated to this topic. 

- The paper highlights key challenges unique to automated graph ML vs general AutoML, like handling the complexity of graph structure, diversity of graph tasks, and scaling issues. It discusses how different methods address these challenges.

- The paper concludes with insightful discussion of limitations of current research and future directions needed to advance automated graph ML, like using graphs to help AutoML, improving robustness and explainability, hardware-aware models, and better evaluation protocols.

In summary, this paper provides a comprehensive organizing framework and review of the emerging research area of automated ML tailored to graph data. It introduces AutoGL as a new open source library to support progress. The review is structured around key criteria for comparing approaches and highlights unique considerations for automating graph ML. The paper concludes by outlining important open questions and opportunities for future work in this area.


## What future research directions do the authors suggest?

 Based on my reading of the paper, the authors suggest the following future research directions for automated machine learning on graphs:

- Graph models for AutoML: Using graphs to help AutoML, such as modeling neural networks as graphs or using GNNs to facilitate neural architecture search. The goal is for graphs and AutoML to facilitate each other.

- Robustness and explainability: Studying how to make automated graph machine learning models more robust and explainable, since many applications are risk-sensitive.

- Hardware-aware models: Improving scalability by developing hardware-aware graph models and AutoML models that are optimized for specific hardware environments.

- Comprehensive evaluation protocols: Developing more comprehensive benchmarks and evaluation protocols beyond small citation graph datasets, to better evaluate and compare different automated graph machine learning methods.

In summary, the key future directions are leveraging connections between graphs and AutoML, improving model robustness and explainability, optimizing for hardware efficiency, and establishing better evaluation methodologies. The overall goal is to advance the automated development and deployment of graph machine learning models.


## Summarize the paper in one paragraph.

 This paper presents a comprehensive survey on automated machine learning (AutoML) methods for graph data. It focuses on reviewing hyperparameter optimization (HPO) and neural architecture search (NAS) techniques for graph machine learning models such as graph neural networks (GNNs). The key challenges of AutoML on graphs are identified, including the uniqueness of graph models, complexity of graph tasks, and scalability issues. The paper systematically reviews and compares different HPO and NAS approaches for graphs from various perspectives like search spaces, search strategies, and performance estimation. It also gives an overview of related libraries and tools, with an emphasis on introducing AutoGL, the first open-source library dedicated to AutoML on graphs. Future research directions are outlined at the end, which include using graphs to facilitate AutoML, improving model robustness and explainability, hardware-aware model designs, and comprehensive evaluation protocols. Overall, this is the first extensive survey reviewing the intersection of graph machine learning and AutoML.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points from the paper:

This paper provides a comprehensive review of automated machine learning (AutoML) methods for graph data. The authors focus on two main topics: hyperparameter optimization (HPO) and neural architecture search (NAS) for graph machine learning models like graph neural networks (GNNs). 

For HPO, the paper discusses methods to efficiently search the hyperparameter space for large-scale graph data, such as using subgraph sampling or graph coarsening. For NAS, the authors organize methods based on search space design, search strategies like reinforcement learning controllers or evolutionary algorithms, and performance estimation tricks like weight sharing to avoid fully training each architecture. The paper also provides an overview of libraries for graph AutoML, with an emphasis on AutoGL, the first open-source Python library dedicated to automated graph learning. Future directions are outlined including using graphs to facilitate AutoML, improving model robustness and explainability, incorporating hardware awareness, and developing more comprehensive benchmarks. Overall, this is a thorough review covering the key challenges, methods, and tools for applying AutoML to graph machine learning tasks.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes AutoGL, a dedicated open-source library for automated machine learning on graphs. AutoGL has four key components:

1) Auto Feature Engineering: Automatically processes graph data using generators, selectors, and subgraph generators. 

2) Model Training: Handles training and evaluation of graph machine learning models like GNNs.

3) Hyperparameter Optimization: Conducts hyperparameter optimization using methods like AutoNE and general algorithms like random search. 

4) Auto Ensemble: Integrates optimized individual models into a more powerful ensemble via voting or stacking.

The components are designed in a modular fashion to enable flexibility. AutoGL aims to facilitate research and applications of automated graph machine learning through its easy usage, flexibility, and open-source implementation.


## What problem or question is the paper addressing?

 Based on my reading of the paper, the main problem the paper is addressing is how to effectively apply automated machine learning techniques to graph machine learning tasks. Specifically, the paper provides a comprehensive review of existing work on hyperparameter optimization and neural architecture search for graph machine learning. 

The key questions and goals of the paper appear to be:

- How can we automate the design and optimization of graph machine learning models like graph neural networks? This is challenging because graph data has unique properties compared to other data like images or text.

- What methods have been proposed for hyperparameter optimization and neural architecture search tailored for graph data? The paper categorizes and compares these methods in depth.

- What software libraries and tools exist to facilitate research and application of automated machine learning on graphs? The paper discusses available open source libraries in this emerging field.

- What are promising future research directions for automated graph machine learning? The paper outlines several open problems and opportunities for future work.

In summary, the paper aims to provide the first comprehensive review of the emerging field of automated machine learning applied to graph data and models, in order to summarize progress so far and help guide future research in this area. The overall goal is to reduce the need for costly manual tuning and design of graph machine learning algorithms.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms are:

- Automated machine learning (AutoML) on graphs: The main focus of this survey paper is on automated machine learning methods applied to graph data. This combines graph machine learning with AutoML techniques.

- Hyperparameter optimization (HPO): One major topic covered is using HPO to automatically find the best hyperparameters for graph machine learning models. The paper reviews methods like AutoNE and JITuNE.

- Neural architecture search (NAS): The other major topic is using NAS to automate the design of graph neural network architectures. Various search strategies like differentiable NAS and evolutionary algorithms are discussed. 

- Graph neural networks (GNNs): The paper focuses on applying AutoML to GNNs, which are currently state-of-the-art graph representation learning models.

- Message passing: GNNs utilize message passing frameworks, which are reviewed as the basis for designing the search spaces for NAS.

- Scalability: A key challenge in AutoML for graphs is scalability to large datasets. Methods to improve efficiency are discussed.

- AutoGL: The paper introduces AutoGL, the first open-source library dedicated to AutoML on graphs. Its design principles and components are reviewed.

In summary, the key themes are applying AutoML techniques like HPO and NAS to graph machine learning, especially graph neural networks, in order to automate and improve the model design process.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to ask when summarizing this paper:

1. What is the main focus and goal of this paper?

2. What are the key challenges of automated machine learning on graphs that the paper identifies?

3. How does the paper formulate the problems of machine learning on graphs and AutoML?

4. What methods for hyperparameter optimization on graphs does the paper review? 

5. What are the main components of the neural architecture search space, search strategy, and performance estimation strategy for graphs covered in the paper?

6. What libraries for automated graph machine learning does the paper discuss? 

7. What are the main characteristics and components of the AutoGL library?

8. What design principles and considerations went into the development of AutoGL?

9. What future research directions for automated graph machine learning does the paper propose?

10. What are the key contributions and main takeaways of this survey paper?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 potential in-depth questions about the methods proposed in this survey paper on automated machine learning for graphs:

1. The paper focuses on hyperparameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. What are some other promising directions for automated machine learning on graphs that are not covered in detail?

2. For HPO methods like AutoNE and JITuNE, what are the advantages and disadvantages of using subgraph sampling versus graph coarsening to improve efficiency? How could these two approaches be combined? 

3. In the NAS section, the paper discusses search spaces, search strategies, and performance estimation strategies. How do innovations in one area influence or interact with innovations in the other areas?

4. What modifications need to be made to adapt differentiable NAS methods like DARTS and SNAS to work effectively for graph neural networks? What are some challenges faced?

5. For evolutionary NAS methods, how can we determine effective mutation and crossover operations to generate new architectures tailored for graphs?

6. The paper mentions transferability of architectures across tasks and datasets as an issue. How can we better understand what architectural properties lead to transferable architectures? 

7. For large-scale graphs, the paper discusses sampling subgraphs as a strategy to improve efficiency. Are there other potential solutions to handle billions of nodes and edges?

8. The AutoGL library is introduced for automating graph machine learning. What are some ways the library could be extended to support more methods and applications?

9. What new datasets or benchmarks are needed to properly evaluate and compare different AutoML methods for graphs?

10. How can insights from automated graph representation learning be used to improve general automated ML, and vice versa? What is the potential for tighter integration?


## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper presents an overview of automated machine learning on graphs, focusing on hyperparameter optimization (HPO) and neural architecture search (NAS). It first introduces the challenges unique to automating graph machine learning, including the non-Euclidean structure of graphs, complexity and diversity of graph tasks, and scalability issues. For HPO, the paper reviews methods like AutoNE, JITuNE, and HESGA that use techniques like subgraph sampling, graph coarsening, and early stopping to improve efficiency of hyperparameter tuning. For NAS, it compares methods on search space design, search strategies like controllers, differentiable methods, and evolutionary algorithms, and performance estimation strategies like weight sharing. It then discusses related software libraries, with an emphasis on introducing AutoGL, an open-source library specifically for automating graph learning. Finally, it outlines future research directions such as using graphs to help AutoML, improving model robustness and explainability, hardware-aware model design, and developing better evaluation protocols. Overall, the paper provides a comprehensive review of the emerging field of automated machine learning tailored to graph data.


## Summarize the paper in one sentence.

 The paper proposes a framework and open-source library AutoGL, the first dedicated library for automated graph learning, with modular and object-oriented designs of Auto Feature Engineering, Model Training, Hyper-Parameter Optimization, and Auto Ensemble.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the paper:

This paper provides a comprehensive review of automated machine learning (AutoML) on graphs, focusing on hyper-parameter optimization (HPO) and neural architecture search (NAS). The authors first point out key challenges of AutoML on graphs such as the uniqueness of graph data, complexity of graph tasks, and scalability issues. Then they review various HPO methods for graph machine learning, highlighting techniques to improve efficiency like transferring from small subgraphs. For NAS, they compare methods based on search space, search strategy, and performance estimation. They also overview libraries for automated graph learning, with an in-depth discussion of AutoGL, the first dedicated open-source library for AutoML on graphs. Finally, they outline future directions such as using graphs to facilitate AutoML, improving model robustness and explainability, designing hardware-aware models, and establishing comprehensive evaluation protocols. Overall, this is the first systematic survey of AutoML on graphs.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the automated machine learning on graphs survey paper:

1. The paper focuses primarily on hyperparameter optimization and neural architecture search for graph machine learning. What are some other important components of automated machine learning on graphs that could be explored more, such as automated feature engineering or model interpretability?

2. The paper mainly reviews automated methods for inductive graph representation learning tasks like node classification. How might automated machine learning differ for transductive or unsupervised graph learning tasks?

3. For neural architecture search, the paper compares search spaces, search strategies, and performance estimation strategies. Which of these three do you think is most important or impactful to the success of architecture search for graph neural networks?

4. The paper argues scalability is a key challenge for hyperparameter optimization on large graphs. Beyond the graph sampling and coarsening methods reviewed, what are some other potential solutions to improve scalability?

5. The paper highlights over-smoothing as a key obstacle to learning deeper graph neural networks. Do you think neural architecture search could help provide insights into alleviating over-smoothing, and if so, how?

6. The paper focuses on general graph representation learning. How might the automated machine learning techniques need to be adapted for domain-specific graphs like biological networks or traffic networks? 

7. The paper proposes combining evolutionary algorithms and differentiable methods as a promising search strategy. What are the main benefits and potential pitfalls of this hybrid approach?

8. For performance estimation, the paper discusses weight sharing and inherited weights. What precautions need to be taken when reusing weights for graph networks compared to CNNs?

9. The paper argues designing the search space is crucial and domain knowledge is needed. In your opinion, what makes a good search space for graph neural architecture search? What basic operators should it include?

10. The paper introduces AutoGL, the first dedicated library for automated graph learning. What features would you suggest adding to AutoGL in the future to make it more useful?
