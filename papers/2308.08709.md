# [Dynamic Neural Network is All You Need: Understanding the Robustness of   Dynamic Mechanisms in Neural Networks](https://arxiv.org/abs/2308.08709)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research questions addressed in this paper are:1) How does introducing dynamic mechanisms into static deep neural networks (DNNs) impact their robustness against adversarial attacks? 2) What design choices for dynamic neural networks (DyNNs) can help improve robustness against attacks generated for static DNNs?3) What is the additional attack surface introduced by dynamic mechanisms, and what DyNN design choices can improve robustness against such attacks?The key hypothesis seems to be that incorporating dynamic mechanisms like early exits into DNNs generally does not reduce robustness against existing attacks on static DNNs. The paper investigates this through empirical studies on transferability of attacks between static and dynamic networks. It also proposes a new attack specifically targeting the dynamic mechanism and analyzes design choices that impact robustness against this attack.In summary, the central research questions focus on systematically understanding the robustness trade-offs of introducing dynamic mechanisms into DNNs, and providing insights into designing robust dynamic networks. The hypothesis is that dynamic networks can achieve efficiency gains without significantly sacrificing robustness.


## What is the main contribution of this paper?

The main contribution of this paper is investigating the robustness of dynamic mechanisms in neural networks through empirical studies. Specifically, the paper focuses on evaluating three key aspects:1. Robustness of the dynamic mechanism itself against adversarial attacks generated on static models. This includes studying attack transferability between static and dynamic models, and evaluating if adversarial examples impact the efficiency robustness of dynamic models.2. Analyzing design choices for dynamic neural networks that can improve robustness against attacks generated on static models. This provides insights into exit placement strategies to make early exits in dynamic models more robust. 3. Introducing a new attack specifically targeting the dynamic mechanism, and evaluating design choices that can improve robustness against this attack. The attack aims to modify early exit behavior without changing final prediction.Through extensive empirical studies on CIFAR and Tiny ImageNet datasets, the paper provides novel findings into the robustness implications of using dynamic mechanisms in neural networks. It also gives guidance on designing more robust dynamic models, while revealing potential vulnerabilities that should be addressed. Overall, the work advances understanding of the robustness tradeoffs when transitioning from static to dynamic neural network architectures.
