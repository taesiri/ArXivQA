# [Benchmarking the Full-Order Model Optimization Based Imitation in the   Humanoid Robot Reinforcement Learning Walk](https://arxiv.org/abs/2312.09757)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Designing robust and human-like gaits for bipedal robots is challenging due to their complex dynamics and many degrees of freedom. Using only model-free deep reinforcement learning tends to lead to visually unappealing and energy inefficient gaits. On the other hand, relying solely on reference trajectories from motion optimization lacks robustness to disturbances.  

Proposed Solution:
- The paper investigates combining deep reinforcement learning with full-body motion optimization to balance gait quality, efficiency and robustness. Three methods are explored: (1) training with only imitation rewards (2) balancing imitation, tracking velocity and other rewards (3) no imitation rewards.

Methods:
- Reference trajectories are generated using the FROST framework and full 23 DoF humanoid model. Policies are trained using PPO algorithm in Isaac Gym simulator and transferred to PyBullet. Three gaits are compared on tracking performance, push recovery, cost of transport and human ratings.

Key Results:
- Balancing imitation and other rewards (gait 2) gave the best tradeoff - more efficient than no imitation and more robust than only imitation. Imitation-only gait was rated as most natural by users. No imitation gait was most robust to pushes.

Main Contributions:  
- Evaluation of effect of imitation rewards on quality, efficiency and robustness of learned gaits
- Implementation of full body gaits on new 23 DoF humanoid model with arms and torso
- Analysis and benchmarking of different imitation ratios for locomotion learning
- Successful sim-to-sim transfer of learned policies
