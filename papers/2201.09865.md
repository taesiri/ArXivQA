# RePaint: Inpainting using Denoising Diffusion Probabilistic Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be:How can we develop an image inpainting method using denoising diffusion probabilistic models (DDPMs) that is able to handle diverse and extreme inpainting masks while generating high-quality and semantically meaningful completions?The key points are:- Image inpainting aims to fill in missing or masked regions in images with synthesized content. Most existing approaches train models for specific mask distributions, limiting generalization.- DDPMs have emerged as a powerful generative modeling approach, but have not been extensively explored for conditional image generation tasks like inpainting. - The authors propose a novel way to condition an unconditionally trained DDPM to perform free-form image inpainting for arbitrary masks. Their RePaint method does not require training on masks.- RePaint introduces a resampling strategy during the DDPM's reverse diffusion process to better harmonize the image and improve coherence.- Experiments show RePaint generates higher quality and more robust inpaintings compared to state-of-the-art autoregressive and GAN methods, especially for sparse and extreme masks.In summary, the main hypothesis is that leveraging unconditional DDPMs in a novel conditioning framework can achieve superior performance and generalization for diverse image inpainting masks. The experiments aim to validate this approach.


## What is the main contribution of this paper?

This paper proposes RePaint, a method for free-form image inpainting using denoising diffusion probabilistic models (DDPMs). The key contributions are:- Leveraging a pretrained unconditional DDPM as a powerful image prior for inpainting. The DDPM is not trained specifically for inpainting.- Conditioning the DDPM sampling process on the known pixels by sampling from the conditional distribution in the masked region. This allows using any DDPM for inpainting without modifying the model architecture.- Introducing a resampling strategy during the reverse diffusion process that repeatedly denoises and diffuses the image. This better harmonizes the generated content with the known pixels.- Achieving state-of-the-art inpainting results on CelebA-HQ, ImageNet and Places2 datasets for a variety of mask types. The method generalizes very well to different masks compared to GAN and autoregressive baselines.- Producing high quality and diverse inpainting results by leveraging the strong image prior learned by DDPMs, without being limited by losses used during training as in other approaches.In summary, the key innovation is using a pretrained DDPM for inpainting by conditioning the sampling process, and introducing a resampling strategy that harmonizes the generated content. This provides a simple yet effective approach for free-form inpainting that generalizes very well to diverse masks.
