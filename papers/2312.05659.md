# [Optimal Unbiased Randomizers for Regression with Label Differential   Privacy](https://arxiv.org/abs/2312.05659)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
The paper studies the problem of training machine learning models under the constraint of label differential privacy (DP). Label DP protects the privacy of the training labels while allowing the features to be public. Prior work optimized the "noisy label loss" between the true and privatized labels to construct the privatization mechanism. However, the noisy label loss does not guarantee that the Bayes optimal predictor is preserved, which is important for the model's test performance. 

Key Ideas:
- The paper shows that requiring the privatization mechanism to be unbiased, i.e. preserve the expectation of the labels, guarantees that the Bayes optimal predictor is unchanged. This motivates designing unbiased mechanisms.

- They formulate an linear program (LP) to compute the optimal unbiased mechanism for a given label prior and discretization of output labels. The LP minimizes the noisy label loss subject to DP, unbiasedness and other constraints.

- They prove structural results showing the optimal unbiased mechanism has at most $2|\gY|$ output labels and takes a "staircase" form, allowing for a finite LP.

- They use a grid heuristic to set the output labels for the LP based on the debiased randomized response. This ensures feasibility while keeping the output set small.

- For unknown priors, they split the privacy budget to privately estimate a prior using the Laplace mechanism, and then find the optimal unbiased mechanism for this estimated prior.

Experiments:
- Evaluate on 3 real-world regression tasks and compare to prior DP baselines.

- The optimal unbiased mechanism significantly outperforms prior work in test loss, even though its noisy label loss is much higher. This validates the benefits of unbiasedness.

Main Contributions:
- Novel unbiased mechanisms for label DP with structural characterization and practical computation.

- Empirically demonstrate state-of-the-art accuracy under label DP constraints.

- Theoretical and empirical justification of the importance of unbiased label perturbations for good test performance.
