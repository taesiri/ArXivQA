# [SeeABLE: Soft Discrepancies and Bounded Contrastive Learning for   Exposing Deepfakes](https://arxiv.org/abs/2211.11296)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How can we design an effective deepfake detector that generalizes well to unseen deepfake generation techniques?

The key hypotheses appear to be:

1) Formulating deepfake detection as a one-class out-of-distribution detection task and training only on real faces will lead to better generalization compared to binary classification models trained to discriminate between real and (pseudo) fake faces.

2) Localizing subtle artificially-generated image perturbations and regressing them to predefined prototypes will allow the model to learn semantically meaningful and robust features for detection. 

3) Combining soft spatial and frequency domain discrepancies along with auxiliary geometric guidance will further enhance the model's capabilities.

The authors propose a new deepfake detection model called SeeABLE that incorporates these ideas. The main goals are to improve generalization across different datasets and unseen manipulation techniques compared to prior art.

In summary, the central research focus is on designing a deepfake detector with strong generalization abilities by treating it as an anomaly detection task and using ideas like soft discrepancies and bounded contrastive learning. The key hypotheses relate to the benefits of the proposed techniques.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. Proposing SeeABLE, a new deepfake detector that formulates the detection problem as a one-class anomaly detection task. SeeABLE is trained only on real face images using a novel self-supervised method.

2. Introducing a Bound Contrastive Regression (BCR) loss that maps locally perturbed facial images (called soft discrepancies) to a set of predefined prototypes. This enables efficient anomaly scoring via distance-based prototype matching. 

3. Using both spatial and frequency domain perturbations as soft discrepancies during training. This allows SeeABLE to learn robust features for detecting various deepfake artifacts.

4. Demonstrating through extensive experiments that SeeABLE achieves state-of-the-art performance on multiple datasets, outperforming many existing deepfake detection methods. The results also show SeeABLE's superior generalization ability to unseen deepfake techniques compared to previous discriminatively trained models.

In summary, the key innovation is formulating deepfake detection as a one-class learning problem and using self-supervised contrastive regression on localized facial perturbations to learn a generalized anomaly scoring model. The experiments validate SeeABLE's effectiveness and cross-technique generalization ability.
