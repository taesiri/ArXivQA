# [Representation Learning by Learning to Count](https://arxiv.org/abs/1708.06734)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we learn useful visual representations from images in an unsupervised manner using counting as a pretext task? More specifically, the key hypotheses appear to be:1) Counting visual primitives in an image requires learning discriminative features that can be useful for downstream visual recognition tasks like classification and detection.2) We can formulate counting via equivariance constraints that relate an image to its spatial transforms, without needing any manual annotations. 3) Satisfying these equivariance constraints for counting visual primitives will force the model to learn features that capture higher-level semantic concepts rather than low-level statistics.4) The learned features will therefore transfer well to other visual tasks compared to other unsupervised representation learning approaches.The main contribution seems to be proposing this novel self-supervised approach for learning visual representations by enforcing equivariance constraints related to counting, without needing any manual labels. The paper then empirically evaluates this hypothesis by benchmarking the transfer learning performance of the learned features on standard datasets like ImageNet and PASCAL VOC.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel method for unsupervised representation learning using the pretext task of counting visual primitives. The key ideas are:- They introduce counting visual primitives as a pretext task for unsupervised representation learning. The hypothesis is that learning to count requires the model to learn useful semantic features that can transfer well to other vision tasks like classification and detection. - They formulate the counting task by exploiting the equivariance between an image and its downsampled/tiled version. Specifically, they enforce the constraint that the count of visual primitives in the original image should equal the sum of counts in each of its non-overlapping tiles. - They train a convolutional neural network with a contrastive loss to satisfy this counting constraint, without requiring any manual annotations.- They show that the learned features perform on par or better than prior state-of-the-art in transfer learning benchmarks on classification, detection and segmentation.- They analyze the learned features, showing they capture high-level semantics rather than just textures or edges. The features cluster semantically similar images in nearest neighbor search.In summary, the key novelty is using the equivariance-based counting formulation as an unsupervised pretext task to learn visual representations that transfer well to downstream tasks. This is achieved without requiring any manual labels or annotations.
