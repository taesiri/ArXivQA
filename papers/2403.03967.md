# [Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability](https://arxiv.org/abs/2403.03967)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem Statement
- Neural networks are known to be vulnerable to small adversarial perturbations that are imperceptible to humans but cause misclassification. 
- This paper introduces a distinction between "natural/on-manifold" attacks which are perceptible and try to cross the true decision boundary, and "unnatural/off-manifold" attacks which are imperceptible and cross only the estimated decision boundary learned by the model. 
- The paper argues that the existence of off-manifold attacks is due to the gap between the intrinsic dimension (where the true signal resides) and ambient dimension (where the data is observed).

Proposed Solution
- The paper models the data as originating from a union of low-dimensional manifolds, transformed isometrically to a higher-dimensional ambient space. 
- It studies a 2-layer ReLU network trained on this data, and shows that the network learns "authentic" weights that depend on the intrinsic signal and "volatile" weights that act as biases.
- Off-manifold attacks exploit these volatile weights to cause misclassification without crossing the true decision boundary. 
- Theoretical upper bounds are derived on the $\ell_2$ and $\ell_\infty$ strengths of both on-manifold and off-manifold attacks.

Main Contributions
- Formal distinction introduced between on-manifold and off-manifold adversarial attacks based on whether they cross the true decision boundary.
- Off-manifold attacks are shown to originate from the gap between intrinsic and ambient dimensions, irrespective of network initialization.
- Explicit connections derived between the dimension gap and strengths of both on-manifold and off-manifold attacks.
- Analysis and results generalize previous implicit bias works and provide new insights into adversarial vulnerability.

In summary, the paper provides a fresh perspective on adversarial attacks by relating them to the dimension gap, gives theoretical grounding for the existence of imperceptible perturbations, and derives attack strength bounds that quantify the effect of this gap.
