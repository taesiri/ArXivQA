# [Neural Intrinsic Embedding for Non-rigid Point Cloud Matching](https://arxiv.org/abs/2303.01038)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to establish correspondences between non-rigidly aligned point clouds. The key hypotheses are:

1. Learning an embedding that respects the intrinsic geometry of the underlying surface can help establish reliable correspondences between non-rigid shapes. 

2. Training the embedding network using relative geodesic errors and statistical distribution matching can improve local intrinsic geometry preservation.

3. Replacing handcrafted spectral embeddings with a learned embedding in a deep functional maps framework can lead to a simple yet effective pipeline for weakly supervised non-rigid point cloud matching.

4. The proposed pipeline is robust to common artifacts like noise and varying sampling density, and generalizes well even when trained on a small dataset.

In summary, the main hypothesis is that a learned neural intrinsic embedding can enable effective non-rigid point cloud matching in a weakly supervised setting, while being robust and generalizable. The paper presents a method and experiments to validate these hypotheses.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a learning-based framework called Neural Intrinsic Embedding (NIE) and Neural Intrinsic Mapping (NIM) for non-rigid point cloud matching. 

The key ideas are:

1. NIE embeds each point in a point cloud into a high-dimensional space that respects the intrinsic geometry of the underlying surface. It is trained to make the Euclidean distance between embeddings approximate the geodesic distance on the surface. 

2. NIM is a weakly supervised framework for non-rigid point cloud matching, built upon NIE. It learns to extract optimal features from input point clouds and estimate correspondences without ground truth correspondence labels.

3. The entire pipeline only requires point clouds that are rigidly aligned, along with geodesic distances for the training point clouds. It does not need triangulation or other structural information.

4. Experiments show the method achieves good matching performance compared to state-of-the-art baselines, generalizes well, and is robust to noise and partiality. 

In summary, the key contribution is a simple yet effective learning-based approach to leverage intrinsic geometry for non-rigid point cloud matching in a weakly supervised manner. The method is insensitive to point sampling density and robust to common artifacts.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points in the paper:

The paper proposes Neural Intrinsic Embedding (NIE) to learn intrinsic geometry-aware embeddings for point clouds, and Neural Intrinsic Mapping (NIM) for weakly supervised non-rigid point cloud matching, which achieves comparable or better performance than state-of-the-art methods requiring more supervision or structural input.


## How does this paper compare to other research in the same field?

 Here are a few key thoughts on how this paper compares to other research on non-rigid point cloud matching:

- The main contribution is proposing a learning-based framework called Neural Intrinsic Embedding (NIE) to embed point clouds into a high-dimensional space that respects the intrinsic geometry. This is different from common spectral embedding methods like functional maps that rely on eigen-decomposition of Laplacian operators. 

- NIE aims to be more robust to noise and artifacts in point clouds compared to spectral methods. The authors design losses and network modifications to handle issues like sampling density bias.

- Based on NIE, the paper presents a weakly supervised matching network called Neural Intrinsic Mapping (NIM). This is related to Deep Functional Maps frameworks but replaces spectral embedding with the learned NIE embeddings.

- A key difference is NIM is trained without ground truth correspondence labels, using only a self-supervised loss based on geodesic distances. So it requires less supervision than similar learning-based matching networks.

- Experiments show NIE and NIM perform on par or better than state-of-the-art intrinsic and extrinsic matching methods, especially in cases of noise, partiality, and generalization across datasets.

- Limitations are the sensitivity to pose differences and reliance on nearly rigid alignment for training. Extending to be invariant to SO(3) transformations could be interesting future work.

Overall, the main novelties seem to be the proposed NIE embedding and weakly supervised NIM network compared to both classic spectral methods and recent learning-based approaches. The results demonstrate competitive matching performance with greater robustness and less supervision required.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the key future research directions suggested by the authors include:

- Improving robustness to different poses/alignments: The authors note their method is currently sensitive to inaccurate rigid alignment of the point clouds due to unusual poses. They suggest incorporating recent advances in SO(3)-invariant networks could help enhance the pipeline in this regard.

- Generalizing to broader shape classes: The current method focuses on human shapes. Expanding the approach to more diverse shape classes like animals, objects, etc could be an interesting direction.

- Weakly supervised learning: The authors highlight the weakly supervised nature of their framework as a benefit. Further exploring ways to reduce the supervision, like approximating geodesics without any ground truth data, could be worthwhile. 

- Incorporating topological information: The current method relies primarily on geometric information like geodesics. Incorporating topological cues about the underlying surface could potentially improve the learned embeddings.

- Applications to point cloud synthesis: The learned embeddings could potentially be useful for synthesizing novel point clouds by interpolating in the embedded space. This could be an interesting application direction to explore.

- Combining extrinsic and intrinsic models: The paper focuses on intrinsic models leveraging geometric information. Combining these with extrinsic deformation models could be a promising direction for future hybrid methods.

In summary, the key opportunities highlighted are improving robustness, generalization, reducing supervision, incorporating more shape information like topology, exploring novel applications like point cloud synthesis, and combining intrinsic and extrinsic modeling approaches.
