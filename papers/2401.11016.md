# [Bounding Consideration Probabilities in Consider-Then-Choose Ranking   Models](https://arxiv.org/abs/2401.11016)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper studies ranking models that incorporate the idea of "consideration sets" - where a decision-maker first narrows down the options into a small set that they will consider, before making a choice/ranking. The standard Plackett-Luce model for rankings does not account for this two-stage choice process. While consideration sets have been studied in discrete choice models, they suffer from a fundamental issue of non-identifiability (the unobserved consideration probabilities cannot be uniquely determined from observed choices). This issue has received limited attention in ranking models.

Proposed Solution:
The paper proposes a natural extension of the Plackett-Luce model by adding an independent consideration stage, termed the "Plackett-Luce with Consideration" (PL+C) model. Although consideration probabilities remain non-identified in PL+C, the authors are able to derive both relative and absolute bounds on the consideration probabilities, using knowledge of item utilities and a lower bound on expected consideration set size. 

First, they show that if item j appears more often in top rankings than a higher-utility item i, then item j must have higher consideration probability than item i. By propagating such constraints transitively, they derive relative bounds between consideration probabilities. Next, by comparing an item's ranking frequency to a hypothetical scenario where other items have consideration probability 1, they derive absolute upper and lower bounds on each item's consideration probability.

They provide efficient algorithms to initialize bounds using ranking frequencies, and then iteratively tighten them by propagating constraints. They demonstrate the feasibility of learning non-trivial consideration probability bounds on a real dataset of US state history rankings.

Main Contributions:
- Formalization and analysis of PL+C model for rankings with consideration sets
- Theoretical results showing non-identifiability but possibility of learning bounds 
- Efficient algorithms to derive tight relative and absolute bounds on consideration probabilities
- Demonstration of learning informative consideration bounds from real ranking dataset


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper studies ranking with consideration sets by proposing a model combining Plackett-Luce and independent item consideration, proving consideration probabilities are non-identifiable but bounds can be inferred, and demonstrating how these bounds reveal insights on real ranking data.


## What is the main contribution of this paper?

 The main contribution of this paper is developing methods to learn about consideration probabilities in a ranking model that combines Plackett-Luce with an independent consideration stage (PL+C). Specifically:

- The paper proves that exact consideration probabilities are not identifiable in the PL+C model, even with full knowledge of utilities and ranking probabilities (Theorem 1).

- However, the paper shows how to derive relative bounds between pairs of items' consideration probabilities using ranking data and known utilities (Theorems 2 and 3). These allow propagating constraints through a directed acyclic graph.

- The paper also derives absolute lower and upper bounds on consideration probabilities by making an assumption about expected consideration set size and using ideas about how changing one item's consideration probability affects others' chances of being ranked first (Theorems 4-6). 

- Algorithms are provided to compute these bounds and tighten them by propagating constraints (Algorithms 1 and 2).

- The methods are demonstrated on real psychology data, revealing insights about which U.S. states were most and least likely to be considered when ranking state contributions to history.

In summary, the main contribution is developing theoretical machinery to learn about unobserved consideration probabilities through ranking data, despite it being impossible to identify them exactly. Both relative and absolute bounds are derived to quantify possible ranges of consideration probabilities.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it are:

- Discrete choice models
- Plackett-Luce model
- Consideration sets
- Ranking models
- Bounded rationality
- Non-identifiability
- Relative bounds
- Absolute bounds
- Propagating constraints
- Directed acyclic graphs

The paper studies a model of ranking called "Plackett-Luce with consideration" (PL+C), which augments the standard Plackett-Luce ranking model with a consideration stage. It shows that exact consideration probabilities are not identifiable from observed rankings, but derives relative and absolute bounds on consideration probabilities. It provides algorithms to propagate these bounds and tighten them. The methods are demonstrated on a psychology dataset about perceptions of US states' historical importance.

The key focus is on modeling consideration sets and bounded rationality within a ranking framework, building on discrete choice models like Plackett-Luce. The core contributions relate to bounding unidentifiable consideration probabilities.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1) The paper shows that consideration probabilities are not identifiable in the PL+C model. What are some possible approaches the authors could have tried to identify consideration probabilities? Why do you think they would or would not work?

2) The paper uses known item utilities as one source of information for learning about consideration probabilities. In what real-world settings might you actually have access to reasonably accurate utility estimates that could be used in this way?

3) The propagation algorithm for tightening bounds relies on the graph G being acyclic. Under what conditions might G end up having cycles? How could the algorithm be modified to handle cycles in G?

4) How does the complexity of computing PL+C probabilities compare to computing standard Plackett-Luce probabilities? Could any speedups be achieved by approximating PL+C probabilities? 

5) The empirical evaluation uses two different data sources to estimate utilities and compare consideration sets. What are some other potential experimental designs or data sources that could produce useful inputs for this method?

6) How sensitive are the inferred bounds on consideration probabilities to inaccuracies in the estimated utilities or ranking probabilities? Could you develop any robustness guarantees?

7) The paper assumes consideration sets are generated independently for each ranking. How could the method be extended to handle cases where consideration sets are correlated across respondents?

8) How does the expressive power of the PL+C model compare to other extensions of Plackett-Luce for choice modeling, like the Contextual Repeated Selection (CRS) model?

9) The method yields relative and absolute bounds on consideration probabilities. What other kinds of constraints on consideration could you derive from ranking data?

10) The empirical evaluation relies on assumptions about expected consideration set sizes. How could these assumptions be tested or relaxed? Are there any ways to infer lower bounds on consideration set sizes from the data?
