# [RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in   Long-Horizon Generation](https://arxiv.org/abs/2403.05313)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Large language models (LLMs) can sometimes generate incorrect or hallucinated information when performing complex, multi-step reasoning required in long-horizon generation tasks like code generation, mathematical reasoning, creative writing, and embodied task planning.  
- Simply combining retrieval augmented generation (RAG) with chain of thought (CoT) prompting in a naive way does not necessarily improve performance on these tasks.

Proposed Solution: 
- The paper proposes Retrieval Augmented Thoughts (RAT), a method that synergizes RAG and CoT prompting to improve reasoning and mitigate hallucination in LLMs for long-horizon generation tasks.

Key Ideas of RAT:
1) Generate an initial zero-shot chain of thought (CoT) for the task using the LLM 
2) Use the task prompt and initial CoT as queries for RAG to retrieve relevant information from corpora/internet to help revise the potentially flawed CoT
3) Progressively revise each CoT step using the retrieved information - only revise the current step based on task prompt, current step, and previously revised steps (casual reasoning)

Evaluation:
- Evaluated RAT on code generation, math reasoning, embodied planning, and creative writing tasks using GPT-3.5, GPT-4, CodeLLAMA-7b
- RAT improves performance over vanilla CoT and RAG methods across tasks:
   - Code generation: 13.6% higher pass rate 
   - Math reasoning: 16.96% higher accuracy
   - Embodied planning: 2.96x executability, 51.94% higher plausibility  
   - Creative writing: 19.2% higher human rating
- Ablations show importance of progressive revision and retrieval strategy

Main Contributions:
- Novel prompting strategy RAT that combines strengths of CoT and RAG to improve complex reasoning and mitigate hallucination
- Demonstrated significant quantitative improvements from RAT over strong baselines across diverse long-horizon generation tasks
- Detailed analyses providing insights into how iterative, progressive revision and retrieval facilitates more grounded and accurate reasoning in LLMs

The paper shows RAT is an effective prompting technique for improving factuality and logical soundness in LLMs for complex, long-horizon generative tasks involving multiple steps of reasoning.
