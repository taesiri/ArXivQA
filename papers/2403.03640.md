# [Apollo: Lightweight Multilingual Medical LLMs towards Democratizing   Medical AI to 6B People](https://arxiv.org/abs/2403.03640)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Despite vast medical knowledge being in English, local languages are crucial for delivering tailored healthcare, especially in areas with limited resources. 
- Extending reach of medical AI advancements to broader populations requires developing medical AI across multiple languages.

Proposed Solution:
- Created ApolloCorpora multilingual medical dataset covering English, Chinese, French, Spanish, Arabic and Hindi.
- Developed Apollo series of multilingual medical LLMs ranging from 0.5B to 7B parameters, outperforming models of equivalent size. 
- Introduced lightweight model-agnostic ProxyTuning method to improve larger general LLMs' multilingual medical capabilities without directly exposing them to sensitive medical data.

Main Contributions:
- High-quality multilingual ApolloCorpora medical dataset and XMedBench benchmark
- State-of-the-art Apollo multilingual medical LLMs, especially in relatively small sizes 
- Innovative ProxyTuning approach that enhances larger models' capabilities without fine-tuning, mitigating privacy risks
- Overall furthering access to medical AI for 6 billion people across 132 countries by supporting six most widely spoken languages

The paper makes notable contributions in compiling multilingual resources, developing specialized models, and introducing methods to safely improve larger models, helping democratize access to medical AI globally, especially in underserved communities.


## Summarize the paper in one sentence.

 This paper introduces Apollo, a suite of open-source multilingual medical language models ranging from 0.5B to 7B parameters, trained on a new curated multilingual medical dataset ApolloCorpora to serve 6 billion people and achieve state-of-the-art performance among models of equivalent size.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Collection and organization of a high-quality multilingual medical corpus ApolloCorpora covering the most widely spoken languages and encompassing a global population of 6.1 billion.

2. Development of a series of state-of-the-art multilingual medical language models named Apollo ranging in size from 0.5B to 7B parameters. 

3. Introduction of a multilingual medical evaluation benchmark XMedBench for assessing models' medical knowledge across languages.

4. Demonstration that Apollo models can significantly improve larger general language models' multilingual medical capabilities using proxy tuning, without directly exposing sensitive medical data.

5. Open sourcing of the training corpora, code, model weights and evaluation benchmark to promote research and exploration in multilingual medical AI.

The key innovation is enabling wider access to advanced medical AI for broader communities, including those speaking non-English and under-resourced languages, through careful multilingual corpus construction and adaptable model development.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper content, some of the key terms and keywords associated with this paper include:

- Apollo - The name given to the series of multilingual medical language models developed in this work, named after the Greek god of healing and light.

- Multilingual medical LLMs - A key focus of the paper is developing large language models with medical expertise across multiple languages, including English, Chinese, French, Spanish, Arabic and Hindi.

- ApolloCorpora - The multilingual medical dataset collected and organized to train the Apollo models, encompassing over 2.5 billion tokens.

- XMedBench - The multilingual medical evaluation benchmark introduced to assess models' medical knowledge across different languages.  

- Proxy tuning - A method explored to improve larger general language models' multilingual medical capabilities using the smaller Apollo models, without directly exposing the larger models to sensitive medical data.

- Democratization of medical AI - A core motivation highlighted is making medical AI innovations more accessible globally, including to underrepresented communities with scarce resources.

- Reproducibility - The paper emphasizes releasing open-source training corpora, models, code and benchmarks to promote reproducibility of multilingual medical LLMs.

The key focus areas are around developing performant and accessible multilingual medical AI to serve broader populations worldwide. Let me know if you need any clarification or have additional questions!


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 suggested in-depth questions about the method proposed in this paper:

1. The paper proposes rewriting pre-training data into QA format before domain-specific fine-tuning. What are the potential advantages and disadvantages of this approach compared to typical continued pre-training? 

2. The priority sampling method smoothly transitions between pre-training and fine-tuning stages. How is the priority of data items determined? What impact could the priority values have on model performance?

3. What considerations were made in selecting the prompt format and ChatGPT model used to rewrite pre-training data into QA pairs? Could different prompts or models affect the quality?  

4. ApolloCorpora contains books, clinical guidelines, papers etc. What principles guided the inclusion criteria and proportions of different data sources? How might changing the data composition impact multilinguality?

5. The paper finds joint training on multilingual medical data improves performance. What factors drive this effect? Could incorporating non-medical multilingual data also be beneficial?  

6. What tradeoffs were considered in setting epoch numbers for pre-training vs fine-tuning stages? How sensitive is model performance to these hyperparameters?

7. Proxy tuning steers base model predictions without changing its parameters. What modifications could enhance this method's ability to transfer knowledge from the teacher to base model?

8. How was the prompt formulation for few-shot evaluation decided? What impact could changing prompt length/content have on benchmark scores?

9. XMedBench includes both expert-made and translated test sets. What are the limitations of using translated test data? How could test set curation be improved?

10. What societal considerations should be weighed regarding the access, use cases and governance of models like Apollo, as we work towards democratizing medical AI?
