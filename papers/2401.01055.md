# [LLaMA Beyond English: An Empirical Study on Language Capability Transfer](https://arxiv.org/abs/2401.01055)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Mainstream large language models (LLMs) like LLaMA are pretrained primarily on English data, limiting their performance on other languages. 
- Transferring capabilities to non-English languages typically requires large-scale vocabulary extension, further pretraining, and instruction tuning, which is computationally expensive.

Proposed Solution: 
- The authors conduct a comprehensive empirical study on transferring LLaMA's capabilities to Chinese and 13 other low-resource languages. 
- They analyze the impact of key factors like vocabulary extension, pretraining data scale, and instruction tuning scale on transfer effectiveness.

Main Contributions:
- Vocabulary extension hinders transfer with small-scale further pretraining (billions of tokens). Extending vocabulary is likely unnecessary.  
- Further pretraining of hundreds of billions of tokens fails to significantly improve LLaMA's knowledge. However, tuning on just hundreds of thousands of instruction examples can enhance response quality.
- Exclusive reliance on Chinese data for transfer compromises LLaMA's original English capabilities. Multilingual joint training alleviates this.
- Comparable performance to state-of-the-art transfer models is achieved with less than 1% of their pretraining data, through instruction tuning.
- The trends hold across 13 low-resource languages. Code-switching is observed during transfer tuning, indicating cross-lingual alignment in LLaMA.

In summary, the paper provides guidance on minimal-cost transfer of LLMs to non-English languages via comprehensive analysis of key factors on a diverse set of languages.


## Summarize the paper in one sentence.

 This paper empirically investigates key factors influencing the transfer of language generation and instruction following capabilities from English-centric LLMs to non-English languages, finding that effective transfer is achievable with minimal data and without vocabulary extension.


## What is the main contribution of this paper?

 This paper makes several key contributions:

1. It conducts a comprehensive empirical study on how to effectively transfer the capabilities of language generation and following instructions from English to non-English languages in large language models (LLMs). 

2. It analyzes the necessity of vocabulary extension and finds that it is not needed for effective transfer with small-scale further pretraining (tens of billions of tokens).

3. It investigates the training scales required for transfer and shows that comparable performance to state-of-the-art transfer models can be achieved with less than 1% of their pretraining data.  

4. It reveals that exclusive reliance on non-English corpora for transfer compromises the original English capabilities of LLMs, while multilingual joint training helps preserve them.

5. It observes the phenomenon of code-switching during transfer training, suggesting cross-lingual alignment has been internalized within LLMs.

6. It validates similar trends hold across 13 low-resource languages beyond just Chinese. 

In summary, this paper provides helpful guidance to efficiently transfer capabilities of LLMs to non-English languages at lower costs. The analysis and empirical findings contribute to developing non-English LLMs.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts include:

- Large language models (LLMs)
- Capability transfer 
- Non-English languages
- Vocabulary extension
- Further pretraining  
- Instruction tuning
- Training scales
- Low-resource languages
- Code-switching
- Knowledge alignment
- Response quality
- Standardized testing benchmarks (C-Eval, MMLU, AGI-Eval, GAOKAO-Bench)
- LLM-Eval benchmark

The paper conducts an empirical study on how to effectively transfer the capabilities of language generation and following instructions from English-centric LLMs like LLaMA to non-English languages. It analyzes factors like vocabulary extension, pretraining scales, instruction tuning data size, etc. It also evaluates performance using standardized testing benchmarks and the LLM-Eval benchmark. The analysis is extended to 13 low-resource non-English languages. Overall, the paper provides guidance on developing non-English capabilities for LLMs.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. This paper analyzes the impact of vocabulary extension, further pretraining, and instruction tuning on transferring LLaMA's capabilities to non-English languages. What are the key findings regarding vocabulary extension? Why does vocabulary extension seem unsuitable for small-scale incremental pretraining?

2. The paper discovers that enhancing LLaMA's response quality requires far less data than elevating its knowledge level. What implications does this have for the community in terms of priorities when transferring capabilities? What mechanisms might account for this phenomenon?  

3. When analyzing the impact of exclusive reliance on Chinese corpora for transfer training, the authors find it compromises LLaMA's original English capabilities. How is this issue resolved? What does this reveal about the nature of transfer learning in large language models?

4. The authors hypothesize the existence of cross-lingual semantic alignment within LLaMA based on observed code-switching behavior. How might this alignment occur during pretraining? What are some ways to test this hypothesis more rigorously? 

5. Could the lack of necessity for vocabulary extension be tied to the scale of further pretraining? What evidence from past literature suggests vocabulary extension benefits emerge only at larger scales?

6. The paper claims comparable performance to SOTA transfer models using less than 1% of training data. But what specific aspects of performance are deemed comparable? How should we interpret this finding?

7. What implications does the extension study on 13 low-resource languages have for the future development of capabilities in these languages? What barriers remain?

8. The authors utilize perplexity to analyze impacts on original vs target language capabilities. What are some limitations of perplexity? How could a more multi-faceted capability analysis be conducted?  

9. How do the conclusions generalize to transfer learning scenarios not explored here, such as transferring between high-resource languages or to genetically isolated languages?

10. What questions remain regarding the underlying mechanisms that enable transfer learning in large language models? How can this methodology be combined with analysis techniques like probing to further scientific understanding?
