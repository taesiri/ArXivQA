# [Confounded Budgeted Causal Bandits](https://arxiv.org/abs/2401.07578)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem Statement
The paper studies the problem of sequential decision making in a stochastic environment modeled by an underlying causal graph. The goal is to learn the best intervention (called "arm") that maximizes the expected reward, subject to a budget constraint. Different arms can have non-uniform costs. Two settings are studied: minimizing cumulative regret (foregone reward over time) and minimizing simple regret (regret at the end). The problem is challenging due to the need to trade off exploration and exploitation given the budget constraint and non-uniform costs. Additionally, the causal graph can have hidden confounders, relaxing structural assumptions made in prior work.

Proposed Solution
Two algorithms are proposed:

1. For cumulative regret: A UCB-based algorithm that incorporates cost-dependent exploration criteria. It uses estimators that leverage both observational and interventional data to estimate expected rewards. 

2. For simple regret: An algorithm that spends half the budget on observational data to get initial estimates, then explores "infrequent" arms using a cost-aware threshold. It uses a procedure to estimate rewards from observational data alone.

Main Contributions
- Allow non-uniform costs and hidden confounders, generalizing prior work
- Develop cost-dependent exploration criteria for both objectives
- Propose estimators that avoid spurious correlations from confounders  
- Provide algorithms for both simple and cumulative regret with theoretical guarantees
- Empirically show proposed algorithms outperform state-of-the-art, even in specialized settings favorable to prior methods
- Present lower bounds and show algorithm bounds are tight up to problem-dependent constants

In summary, the paper provides a comprehensive treatment of budgeted causal bandits under a relaxed set of assumptions. Theoretically and empirically it advances the state of the art in sequential decision making in stochastic causal environments.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper studies the problem of sequential decision-making to maximize rewards under a budget constraint in a stochastic environment modeled by an underlying causal graph, proposing algorithms that leverage causal information to trade off exploration and exploitation for both simple and cumulative regret objectives, providing theoretical performance guarantees, and empirically evaluating the algorithms.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1) It generalizes the state-of-the-art in causal bandit literature by allowing non-uniform costs among the arms and hidden confounders (unobserved variables) in the causal graph. This makes the setting more realistic for many real-world applications. 

2) It proposes two algorithms - one for minimizing cumulative regret (Algorithm 1) and another for minimizing simple regret (Algorithm 2) in causal bandits. Both algorithms work for general causal graphs and non-uniform costs.

3) It provides theoretical guarantees on the expected regrets for both algorithms, including upper bounds. It also discusses lower bounds and shows the proposed upper bounds are tight up to logarithmic factors.

4) It evaluates the proposed algorithms empirically and shows they outperform prior methods designed for special cases of the problem (like uniform costs or no hidden confounders). This demonstrates the value of the proposed generalized setting and algorithms.

In summary, the key novelty is developing causal bandits algorithms for practical non-uniform cost settings with hidden confounders and providing both theoretical and empirical evidence to demonstrate their effectiveness over prior specialized methods.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it are:

- Causal multi-armed bandits
- Cumulative regret
- Simple regret  
- Budgeted bandits
- Non-uniform costs
- General causal graphs
- Hidden confounders
- Identifiability
- Exploration vs exploitation trade-off

The paper studies the problem of causal bandits with non-uniform costs for different arms and general causal graphs that may contain hidden confounders. It considers both objectives of minimizing cumulative regret and simple regret under a budget constraint. The algorithms proposed aim to balance the trade-off between exploration and exploitation effectively based on the costs, while leveraging the causal graph structure and identifiability assumptions to estimate the expected rewards. Both theoretical analysis and empirical evaluations are provided for the regret bounds.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions I would ask about the method proposed in this paper:

1. The paper assumes the underlying causal graph is known. How would the performance of the proposed algorithms degrade if the causal graph is only partially known or estimated from data? How can the algorithms be adapted to be more robust to errors in the causal graph?

2. Theorem 1 provides an upper bound on the cumulative regret of the proposed Algorithm 1. Can you derive a lower bound on the cumulative regret to characterize how tight this upper bound is? 

3. Algorithm 1 requires the identifiability of the causal effects of all intervenable variables. However, many real-world causal graphs may not satisfy this condition. How can the algorithm and theory be extended to handle non-identifiable causal effects?

4. The paper assumes binary intervenable variables for ease of presentation. How does allowing for non-binary discrete or continuous intervenable variables impact the performance of Algorithm 1? Does the regret scale with the size of the variable domains?

5. Algorithm 2 for simple regret uses an exploration threshold based on $q_{i,x}$. Can you further optimize this threshold or provide an adaptive data-driven approach to set the exploration threshold? 

6. How does the performance of Algorithm 2 degrade if the no-backdoor assumption is slightly violated, i.e., if there are some weak backdoor paths present in the causal graph? Can the algorithm be adapted to become more robust?

7. The regret bounds have logarithmic dependence on time/budget. Can regret bounds with a constant dependence be proven under additional assumptions? If so, what assumptions enable constant cumulative/simple regret?

8. The paper assumes a fixed underlying causal model. How can the algorithms and theory be extended to handle non-stationary environments where the underlying causal mechanisms change over time?

9. The experiments are limited in scale and complexity of the causal graphs. What additional large-scale experiments would better demonstrate the effectiveness of the algorithms? What complex real-world causal graphs should be tested?  

10. The paper focuses on learning optimal binary interventions. How can the scope of interventions be expanded to optimize over stochastic policies and sequences of interventions over time?
