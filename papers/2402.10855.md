# [Control Color: Multimodal Diffusion-based Interactive Image Colorization](https://arxiv.org/abs/2402.10855)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Control Color: Multimodal Diffusion-based Interactive Image Colorization":

Problem:
Existing automatic image colorization methods have several key limitations, including lack of user interaction, inflexibility in local colorization, unnatural color rendering, insufficient color variation, and color overflow issues. Recent diffusion model-based methods also exhibit low fidelity when applied directly to colorization tasks.  

Proposed Solution:
This paper proposes a novel multi-modal diffusion framework called CtrlColor for highly controllable interactive image colorization. The key ideas are:

1) Leverage rich generative priors from a pre-trained Stable Diffusion (SD) model for high-quality and diverse colorization. 

2) Support various colorization modes in a unified framework, including unconditional, text prompt-based, stroke-based, exemplar-based and combinations. 

3) Introduce self-attention guidance and content-guided deformable autoencoder to address color overflow and incorrect coloring issues inherent in diffusion models.

4) Propose a new stroke encoding method to enable precise local color control by feeding stroke positions and colors into the diffusion process.

5) Employ contextual and grayscale losses to ensure exemplar guidance translates properly to colorization outputs.

Main Contributions:

1) A novel diffusion framework unifying diverse colorization modes with high controllability and quality.

2) Solutions to address key color fidelity issues in diffusion colorization via self-attention guidance and content-guided deformable autoencoder.

3) Precise local color control method via stroke encoding that allows flexible object-specific color edits.

4) State-of-the-art results across unconditional, stroke-based, prompt-based and exemplar-based colorization tasks over existing methods.

In summary, this paper presents a high-quality controllable colorization framework built on diffusion models that supports diverse colorization modes in a unified architecture with user interactivity. The proposed techniques to enhance color fidelity and local control unlock new capabilities for this important creative task.
