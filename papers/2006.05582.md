# [Contrastive Multi-View Representation Learning on Graphs](https://arxiv.org/abs/2006.05582)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How can we learn effective node and graph level representations in a self-supervised manner by maximizing the mutual information between different structural views of the graphs?The key hypotheses appear to be:1) Contrasting node encodings from one structural view with graph encodings from a different structural view (and vice versa) is an effective approach for self-supervised representation learning on both node and graph classification tasks. 2) Using a graph diffusion process to generate an additional global structural view, along with the local view from the adjacency matrix, provides useful congruent and incongruent signals for contrastive learning.3) Increasing the number of views or contrasting multi-scale encodings, unlike in visual representation learning, does not improve performance on graph tasks. The best results come from contrasting the local view (adjacency matrix) and global view (graph diffusion).4) Simple graph readout functions like sum pooling work better than hierarchical pooling methods like DiffPool for this self-supervised graph learning.So in summary, the main focus is on developing and evaluating a self-supervised contrastive learning framework for graphs that relies on contrasting local and global structural views. The key hypotheses center around the design choices for effectively generating views and integrating mutual information maximization on graphs.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a self-supervised approach for learning node and graph level representations by contrasting encodings from different structural views of graphs. The key points are:- They introduce a method to generate different structural views of a graph, including using the original adjacency matrix and a diffusion matrix, to create correlated views of the same graph. - They use these views as input to two graph neural networks to encode node representations for each view. The node representations are then aggregated to obtain a graph representation for each view.- They maximize the mutual information between the node representations from one view and the graph representation from the other view, and vice versa, as the training signal. This allows the model to learn rich node and graph representations without relying on label data.- Through systematic experiments, they show that unlike visual representation learning, increasing the number of views or contrasting multi-scale encodings does not improve performance on graph tasks. The best results are obtained by contrasting node and graph encodings from two views.- The proposed method achieves new state-of-the-art results on several node and graph classification benchmarks under a linear evaluation protocol, outperforming previous unsupervised methods. It also matches or exceeds the performance of supervised baselines on some tasks.In summary, the key contribution is a self-supervised approach for learning node and graph representations by contrasting local and global structural views, which achieves strong performance without relying on label data. The analysis provides insights into effective strategies for contrastive representation learning on graphs.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a self-supervised approach for learning node and graph representations by contrasting encodings from different structural views of graphs, and shows this achieves state-of-the-art results on node and graph classification benchmarks.
