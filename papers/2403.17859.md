# [ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on   Historical American Newspaper Pages](https://arxiv.org/abs/2403.17859)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Question answering (QA) datasets are predominantly created from modern synchronous documents like Wikipedia and the web. There is a lack of QA datasets based on archival document collections such as historical newspapers, which contain valuable information from the past.  
- Historical newspapers pose challenges for QA such as noisy OCR text, archaic language, and different historical context. There is no comprehensive analysis of the impact of OCR errors on QA performance.

Proposed Solution:
- The authors introduce ChroniclingAmericaQA, a large-scale QA dataset with 485K question-answer pairs created from historical American newspapers spanning 120 years (1800-1920).
- They adopt an automatic approach for dataset creation using GPT-3.5 for OCR text correction and T5-base for question generation.
- The dataset can be used to benchmark QA models on raw OCR text, corrected text, as well as scanned newspaper images.

Key Contributions:
- The first large-scale QA dataset based on historical newspapers covering the longest time period of 120 years
- Comprehensive analysis of multiple models (transformers like BERT, RoBERTa, T5 and large language models like LLaMA, Mistral) on the dataset 
- Quantification of performance degradation of models due to noisy OCR text, highlighting the need for OCR correction
- Establishing strong baseline results on the dataset to facilitate future research on QA for heritage collections

In summary, the paper introduces a valuable, realistic and challenging QA dataset to promote research on QA for historical documents and benchmark model robustness. The analysis offers insights into the impact of OCR errors and need for domain-specific fine-tuning.
