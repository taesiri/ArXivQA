# Ontologically Faithful Generation of Non-Player Character Dialogues

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper seeks to address is:How can we automatically generate high-quality, coherent dialogue trees for non-player characters (NPCs) in video games that accurately reflect underlying quest objectives and game lore?The key points are:- The paper introduces a new dataset called Knudge that contains professionally authored NPC dialogue trees paired with granular quest and entity annotations derived from the RPG game The Outer Worlds. - The authors frame the core research problem as knowledge-constrained NPC dialogue generation - given quest objectives, entity biographies, dialogue history etc., can models generate dialogue trees that are realistic, coherent, and faithfully reflect the input knowledge?- The paper proposes and evaluates neural generation models termed DialogueWriters that leverage large language models like GPT-3 in a zero-shot or few-shot setting to generate utterances conditioned on the input knowledge.- Experiments reveal competent performance but significant room for improvement, especially in jointly reasoning over the complex input specifications.In summary, the core research question is around developing models that can automatically generate high-quality NPC dialogue trees grounded in complex game quest and lore specifications, with Knudge introduced as a platform to facilitate progress.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. Introduction of a new dataset called KNUDGE (Knowledge Constrained User-NPC Dialogue GEneration) containing dialogue trees extracted from the video game The Outer Worlds. The trees are paired with granular ontological constraints in the form of quest and biography passages. 2. Formulation of the challenging task of knowledge-constrained NPC dialogue generation, where the goal is to generate coherent dialogue trees that accurately reflect the provided quest and biography specifications.3. Introduction of DialogueWriter models that leverage large neural language models like GPT-3 to generate utterance candidates conditioned on the quest/biography constraints and dialogue context. Experiments are conducted with different model variations, like knowledge selection mechanisms, to encourage faithfulness to the constraints.4. Evaluation protocols prescribed for testing models on their abilities to reflect the ontological constraints in addition to generating fluent dialogues. Experiments conducted on in-context utterance generation as well as end-to-end dialogue tree generation.5. Analysis showing competent performance by neural models on the task, but significant room for future improvement on aspects like jointly reasoning over facts, covering all quest objectives, and achieving human-level coherence and narrative quality.In summary, the paper introduces a new challenging grounded dialogue generation task along with dataset, models, and evaluations to drive progress in this direction. The dataset and task are designed to facilitate research towards AI tools that can assist game developers in efficiently authoring high-quality NPC dialogues.
