# [RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic   Manipulations With Large Language Models](https://arxiv.org/abs/2403.06420)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models":

Problem:
Reinforcement learning (RL) has shown promise in solving robotic manipulation tasks, but suffers from low sample efficiency. Large language models (LLMs) possess extensive prior knowledge that could help address this limitation, but directly using LLMs to generate robot controllers can result in poor performance. This paper explores how to leverage LLMs to improve RL sample efficiency in robotic tasks.

Proposed Solution: 
The authors propose RLingua, a framework to extract rule-based controllers from LLMs through prompt engineering and use them to guide RL exploration. Specifically:

1) Prompt design methods (with human feedback or code templates) are introduced to obtain preliminary, imperfect controllers from LLMs like GPT-4. These sequence low-level actions but may fail to fully capture environment dynamics.  

2) The LLM controllers generate demonstration samples to prefill RL replay buffers. A modified actor-critic RL loss regularizes policy learning towards the LLM controller, while allowing compensation for its imperfections. An annealing schedule transfers control from LLM to learned policy.

3) RLingua refines the capabilities of imperfect LLM controllers through the RL process.

Main Contributions:

- A novel prompt engineering approach to extract rule-based robot controllers from LLMs, requiring only high-level task specs.

- Using LLM controllers for guided exploration that significantly enhances RL sample efficiency.

- Validation of RLingua on robotic tasks with sparse rewards, where it reduces sample complexity and achieves higher success rates than standard RL.

- Demonstration of Sim2Real transferability through real robot experiments on learned policies.

In summary, RLingua provides an effective framework to leverage LLMs' knowledge to address RL sample inefficiency in robotic manipulations. Both simulated and real robot results highlight the promise of this approach.
