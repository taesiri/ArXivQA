# [Safe Learning of PDDL Domains with Conditional Effects -- Extended   Version](https://arxiv.org/abs/2403.15251)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Powerful domain-independent planners require a model of the agent's actions, defined in a planning domain description language like PDDL. Manually designing such models is extremely challenging. 
- An alternative is to learn action models automatically from observations/trajectories. However, learned models may allow plans that fail or have unintended effects when executed. 
- Existing algorithms for learning "safe" action models cannot handle conditional effects, which specify that some action outcomes only occur if certain conditions hold in the current state. Conditional effects are very common in planning domains.

Proposed Solution:
- The paper introduces Conditional-SAM (C-SAM), the first algorithm for learning safe PDDL action models with conditional effects.
- C-SAM learns from noise-free, fully observable trajectories demonstrating sequences of actions and their outcomes.
- It makes reasonable assumptions, like bounding the size of conditional effect antecedents, to ensure tractable learning.
- C-SAM extends SAM algorithm rules to handle conditional effects and compiles the learned action models into PDDL.
- The paper proves C-SAM learns safe models using a minimal number of trajectories, analyzes its complexity, and shows how to extend it to lifted (parameterized) models and universal effects.

Contributions:
- First algorithm for learning safe PDDL action models with conditional effects.
- Theoretical analysis showing learning requires number of trajectories exponential in the antecedent size, and C-SAM matches this lower bound.
- Empirical evaluation on planning competition benchmarks showing C-SAM learns perfect models for most domains given just a few sample trajectories.
- Demonstration of how C-SAM extends to lifted models with universal effects.

Overall, the paper addresses the challenging problem of learning executable action models with conditional effects, while providing safety guarantees on generated plans. Theoretical and empirical results validate the usefulness of the approach.


## Summarize the paper in one sentence.

 This paper presents Conditional-SAM, an algorithm for learning safe action models with conditional and universal effects from observed plan executions.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing \consam, the first algorithm capable of learning safe action models for PDDL domains with conditional effects. Specifically:

1) The paper proves that learning non-trivial safe action models with conditional effects may require an exponential number of samples, but identifies reasonable assumptions under which learning is tractable. 

2) It introduces the \consam algorithm along with theoretical analysis showing it learns a safe action model using an asymptotically optimal number of examples, given a bound on the size of antecedents.

3) The paper shows how \consam can be extended to support learning lifted action models and effects with universally quantified variables. 

4) It provides an experimental evaluation on several planning domains demonstrating that with just a few example trajectories, \consam can learn action models that are logically equivalent to the real models and can perfectly solve most of the test problems in those domains.

In summary, the key contribution is a safe learning algorithm for action models with conditional effects, including theoretical results and an empirical demonstration of its effectiveness. The ability to safely learn such action models helps enable automated planning agents to be deployed in real-world settings.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, here are some of the main keywords and key terms:

- Safe Action Model Learning (SAM)
- Conditional effects
- Universally quantified variables
- Planning Domain Definition Language (PDDL) 
- Execution soundness
- Trajectories
- Sample complexity
- Conditional-SAM algorithm
- Inductive learning rules
- Lifted action models
- Disjunctive antecedents

The paper presents an algorithm called Conditional-SAM that learns safe action models for PDDL planning domains with conditional effects. Key aspects include the inductive learning rules used by Conditional-SAM, the theoretical analysis proving the algorithm is safe and asymptotically optimal, and the experimental results on planning benchmark domains with conditional and universal effects.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper states that learning non-trivial safe action models with conditional effects may require an exponential number of samples. Can you expand on why this is the case theoretically? What specific properties of conditional effects lead to this exponential sample complexity?

2. Assumption 3 in the paper bounds the maximal number of literals in an antecedent to a fixed parameter n. What is the impact on complexity and sample efficiency if this assumption is relaxed or removed? Can you analyze or prove how the complexity scales as n grows?

3. Theorem 1 shows that the space complexity grows exponentially with the bound n on antecedent size. Can you propose methods to reduce this space complexity while preserving safety? For example, can incremental learning help here? 

4. The inductive learning rules handle conditional effects by tracking possible antecedents in the PosAnte data structure. Can you critically analyze this approach and discuss its limitations? Are there alternative strategies you can propose?  

5. Algorithm 2 describes the key steps for compiling the learned action model. Can you explain the intuition and theoretical justification behind the restrictive preconditions added in lines 16 and 18? What role do they play in ensuring safety?

6. The lower bound result in Theorem 3 relies on a particular hard instance distribution. Can you discuss how this construction encapsulates the inherent difficulty of learning conditional effects? Are there other insightful hard instance distributions you can propose?

7. The paper does not handle disjunctive antecedents in conditional effects. Can you analyze the additional complexities this presents? Are the proposed modifications sufficient or can you suggest better approaches?

8. How does the inductive binding assumption in Section 5 simplify handling of universality in conditional effects? Can this assumption be relaxed and how would it impact the learning approach?

9. The empirical results show low coverage on certain domains like CityCar. What are some hypotheses for why coverage drops as trajectory length increases in Figure 3?

10. A key limitation is the bounded antecedent size assumption. Can you propose methods to handle unrestricted antecedent sizes? For example, can you adopt approaches from rule learning literature?
