# [scInterpreter: Training Large Language Models to Interpret scRNA-seq   Data for Cell Type Annotation](https://arxiv.org/abs/2402.12405)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing large language models (LLMs) have limitations in directly reading and interpreting single-cell gene expression data. However, they have potential as foundation models for this task.  

Proposed Solution:
- The paper proposes a model called "scInterpreter" which trains an LLM to interpret and categorize cell types from single-cell RNA sequencing (scRNA-seq) data. 

- It first generates gene embeddings using the descriptive text of each gene from an NCBI dataset. The top expressed genes in each cell are embedded and fed into the Llama-13b LLM.

- The LLM is given an instruction like "what is the cell type of this given embedding?" and outputs a class token embedding which is fed to a classifier to predict the cell type.

- Only the classifier and projections are trained, while the LLM is kept frozen. A cross-entropy loss is used.

Contributions:

- Demonstrates that incorporating common knowledge from LLMs significantly improves performance in categorizing cell types from scRNA-seq data compared to a baseline (GenePT).

- Visualizations show that the LLM-enhanced method produces better separated embeddings for cells of the same type. This indicates better feature representation and classification capabilities.

- Shows potential for using foundation models like LLMs to unlock biological insights from gene expression data by harnessing their expansive knowledge.

In summary, the key idea is to leverage the knowledge inside LLMs to better interpret single-cell gene expression data for tasks like cell type annotation. Both quantitative and qualitative results demonstrate clear improvements over baselines.
