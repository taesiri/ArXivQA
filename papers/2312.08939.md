# [EAT: Towards Long-Tailed Out-of-Distribution Detection](https://arxiv.org/abs/2312.08939)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel framework called EAT to address the challenging problem of long-tailed out-of-distribution (OOD) detection, where the training data follows a long-tailed class distribution. The key difficulty lies in distinguishing OOD data from tail-class samples. To overcome this, EAT presents two main ideas: (1) Expanding the classification space by introducing multiple abstention classes and assigning OOD data to these classes using dynamic virtual labels. This builds clear decision boundaries between inliers and outliers. (2) Augmenting tail-class images by overlaying them onto context-rich OOD images using CutMix. This forces the model to focus on discriminative foreground features of tail classes. Additionally, the paper provides insights into the impact of virtual labels through an analysis of gradient noise. Extensive experiments demonstrate that EAT boosts the AUROC by 2.0% and inlier accuracy by 2.9% over previous state-of-the-art on benchmark datasets. Notably, EAT serves as an effective add-on to improve OOD detection for existing long-tail methods. The key findings challenge the notion that a strong inlier classifier necessarily translates to good OOD detection.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Most prior work on out-of-distribution (OOD) detection assumes that the in-distribution training data is class-balanced. However, real-world data often follows a long-tailed class distribution, where a few head classes have abundant samples while most tail classes only have scarce samples. It is very challenging to distinguish OOD data from tail-class samples in such scenarios. 

Proposed Solution:
The paper proposes a novel framework called EAT to tackle long-tailed OOD detection. The key ideas include:

1. Expand the classification space by introducing multiple abstention classes for OOD data. Virtual labels are dynamically generated for OOD samples and optimized via the cross-entropy loss. This allows clearer decision boundaries between inlier data and OOD data.  

2. Augment tail-class images by overlaying them onto context-rich OOD images using CutMix. This forces the model to focus more on discriminative features of tail classes rather than the background.

3. Adopt classifier fine-tuning and mixture of experts to further enhance OOD detection and inlier classification.

Main Contributions:

1. Formally study the challenging but practical problem of long-tailed OOD detection. Propose innovative solutions tailored for this setup.  

2. Introduce virtual labels for OOD data as an alternative to maximize their predictive uncertainty. Analyze the impact of virtual labels through the lens of gradient noise.

3. Extensive experiments show the proposed EAT framework boosts AUROC by 2.0% and inlier accuracy by 2.9% over previous state-of-the-art on average.

4. Demonstrate EAT can serve as an effective add-on to boost OOD detection for existing long-tail learning methods, challenging the notion that a strong inlier classifier implies good OOD detection.

In summary, the paper presents an effective framework to tackle the practical but under-explored long-tailed OOD detection problem with solid empirical validation. The proposed techniques offer valuable insights and can benefit future research in this direction.
