# [Annotation-Free Group Robustness via Loss-Based Resampling](https://arxiv.org/abs/2312.04893)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality summary paragraph of the key points from the paper:

This paper proposes a new method called loss-based feature re-weighting (LFR) to improve the robustness of image classification models to spurious correlations in the data, without requiring group annotations. The method first trains a model using standard empirical risk minimization (ERM). It then evaluates this model on a subset of the training data, splits the predicted samples into correctly classified and misclassified groups per class, and selects an equal number of high-loss and low-loss samples from each group. These selected samples form a balanced dataset that is used to retrain just the last linear layer of the model. On variants of the Waterbirds and CelebA datasets with different spurious correlation rates, LFR outperforms previous methods not using group labels, and even a method using the true groups, especially in high correlation settings. LFR shifts the model's attention from spurious to causal features for both majority and minority groups. The method is fast, straightforward, and achieves state-of-the-art performance by effectively balancing groups using the loss to infer majority/minority status, without requiring additional group annotations.
