# [Describing Images $\textit{Fast and Slow}$: Quantifying and Predicting   the Variation in Human Signals during Visuo-Linguistic Processes](https://arxiv.org/abs/2402.01352)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Humans show ample variation in behavior when describing images, as seen in speech onsets, first words uttered (starting points), full descriptions, and eye movements. 
- This variation likely stems in part from properties of the images themselves.
- However, current pretrained multimodal models do not receive information about such human behavioral signals and variation during training.

Approach:
- The authors use the Dutch Image Description and Eye-tracking (DIDEC) corpus which contains spoken descriptions and eye-tracking data for images.
- They preprocess the data to extract speech onsets, starting points, full descriptions, and gaze patterns.
- They propose metrics to quantify the variation in these signals across participants for each image.
- They find significant correlations between the variations, indicating an underlying image-based cause. 
- They hypothesize that if images contribute to the variation, then similar images should elicit similar amounts of variation in human signals.
- They test if pretrained encoders like CLIP and ViT capture information about the variation by predicting the variation scores using a similarity-based approach.

Key Findings:
- Moderate correlations found between variation in speech onsets, starting points, descriptions, and eye movements.
- Image representations from CLIP and ViT are weakly-to-moderately predictive of the variation scores.
- Signals more closely related to the models' training objectives (e.g. descriptions for CLIP) are better predicted.

Main Contributions:
- First study to quantify and reveal correlations between variation in multiple human signals during visuo-linguistic tasks using the DIDEC dataset.
- Demonstration that pretrained encoders capture meaningful signals about human visual and linguistic variation, but rather weakly, suggesting room for improvement.
- Proposing metrics to measure variation in starting points, descriptions, gaze patterns.
- Directing attention to incorporating human signals and modeling their variation when training multimodal models.
