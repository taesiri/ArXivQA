# [Mitigating Over-smoothing in Transformers via Regularized Nonlocal   Functionals](https://arxiv.org/abs/2312.00751)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes a novel transformer model called NeuTRENO to mitigate over-smoothing in self-attention layers, which is an issue that causes token representations to become nearly identical in deeper transformer models, thus limiting their representation capacity. The key idea is to view self-attention from a nonlocal variational denoising perspective, where it minimizes a functional that promotes smoothness, thereby causing token uniformity. To address this, NeuTRENO minimizes a regularized energy functional with an additional fidelity term that penalizes deviations of the output tokens from the input tokens, helping preserve information. NeuTRENO is shown to effectively reduce token similarity in deeper layers on ImageNet, ADE20K, and language modeling tasks. Analytically, transformers with softmax attention are shown to be prone to over-smoothing, while NeuTRENO helps avoid this issue. Experiments across computer vision and NLP tasks demonstrate NeuTRENO's advantages over baseline transformers and state-of-the-art methods in mitigating over-smoothing and improving model representation capacity. The simplicity of NeuTRENO makes it widely applicable to enhancing various transformer architectures.
