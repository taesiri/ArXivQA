# [Information structures and their cohomology](https://arxiv.org/abs/1709.07807)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How can entropy be characterized from a cohomological perspective, and what new insights does this topological viewpoint provide about the nature and properties of entropy?

More specifically, the paper introduces a framework of "information structures" and associated "information cohomology" to give an algebraic characterization of entropy. The key ideas are:

- Defining information structures as categories of observables, abstracting the relations between their outputs. This provides a unified setting to treat classical and quantum measurements.

- Introducing information cohomology via derived functors, as a topological invariant associated to an information structure. 

- Showing that Shannon and Tsallis entropies arise naturally as 1-cocycles in this cohomology theory, with the 1-cocycle condition encoding their chain rule / additive property.

- Proving that under suitable nondegeneracy conditions, these entropies are essentially the unique nontrivial 1-cocycles, providing an alternative characterization.

Overall, the central hypothesis seems to be that taking a cohomological viewpoint can provide new conceptual insights and unify the understanding of entropy across different settings like classical probability, quantum mechanics, etc. The paper aims to develop the mathematical framework to support this claim.


## What is the main contribution of this paper?

 This paper introduces the category of information structures and defines information cohomology on them. The key contributions are:

- It provides a general definition of an information structure as a conditional meet semilattice equipped with a functor to measurable spaces. This captures both classical probability models and quantum ones. 

- It defines information cohomology using derived functors, extending the work of Baudot and Bennequin. The coefficients are modules over the structure ring generated by the semilattice. 

- It shows the bar resolution gives an explicit projective resolution that can be used to compute information cohomology. This recovers the previous cochain complexes used for classical/quantum information cohomology.

- For probabilities as coefficients, it proves the only 1-cocycles are Shannon or Tsallis entropy, depending on the module parameter α. This generalizes a previous characterization result.

- It studies how the 1-cohomology behaves under different conditions on the information structure, relating it to connectivity properties. Entropy behaves like a "fundamental class" in nicely connected cases.

In summary, the main contribution is providing a unified framework to define and study information cohomology across classical and quantum settings, using categorical and homological techniques. The computations characterize entropy through its cocycle property.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other research in the field of information theory and entropy:

- The paper takes a novel, categorical approach to studying entropy by introducing "information structures" and associating entropy with cohomology classes. This is quite different from most information theory research that studies entropy from an axiomatic, probabilistic, or algorithmic perspective. The categorical framework seems innovative.

- Relating entropy to cohomology classes provides an algebraic perspective on entropy. Some other algebraic approaches have been taken before, like studying entropy in terms of solutions to functional equations. But formulating entropy in terms of cocycles seems new. 

- The paper connects entropy to the combinatorics encoded in the information structures. This differs from most information theory that focuses just on the probabilistic or statistical properties of entropy. Looking at the combinatorial foundations seems interesting.

- The generality of information structures means the results could apply across classical probability, quantum mechanics, continuous variables, etc. This is more broad than most entropy research that sticks to one domain like discrete random variables. The unified approach is noteworthy.

- Compared to abstract approaches that axiomatize entropy from scratch, this work builds on existing definitions of entropy like Shannon and Tsallis. So it leverages established knowledge while providing new perspective.

Overall, the categorical viewpoint and links to cohomology seem to distinguish this paper from prior art. The work appears novel while building on foundations of information theory. Of course, fully assessing the impact would require examining follow-up research that applies and extends these ideas. But at first glance, the approach looks innovative and promising.


## What future research directions do the authors suggest?

 The authors suggest several directions for future research:

1. Compute cocycles of higher degrees, which are conjectured to provide new measures of mutual information of all orders.

2. Reformulate Shannon's coding theorems as cohomological obstruction problems. The authors suggest information cohomology could provide a framework to reformulate and generalize Shannon's classical results.

3. Compute cohomology for categories of symplectic manifolds and reductions, to obtain adapted measures of information in those settings.

4. Establish a functorial relation between classical and quantum information cohomology (and corresponding concentration theorems) through geometric quantization. The authors suggest this could unify the classical and quantum cohomological approaches. 

5. Develop a categorical formulation of Ruzsa's dictionary, which relates inequalities for cardinalities and entropies. The authors suggest a categorical framework could help formalize these connections.

Overall, the authors propose applying information cohomology and category theory more broadly to strengthen connections between information theory, probability, algebra, and geometry. Developing the cohomological approach further could lead to new theorems, unifying perspectives, and a deeper conceptual understanding of information and entropy.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper introduces the category of information structures, whose objects are diagrams of measurable sets representing the outputs of observables and their relationships. Each information structure can be seen as a ringed site with the structure ring generated by the observables. The authors extend the definition of information cohomology to this setting, as a derived functor in the category of modules over the structure ring, and show that the bar construction provides an explicit projective resolution. They study the case where the coefficients are probability distributions, proving that the only 1-cocycles are Shannon entropy or Tsallis entropy, and determine the first cohomology group under suitable hypotheses, illustrating how entropy emerges naturally in this framework. The general constructions allow classical and quantum information structures to be treated in a unified manner.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points in the paper:

This paper introduces the category of information structures, whose objects are diagrams of measurable sets encoding the possible outputs of a collection of observables and their relationships in terms of refinement. Information structures serve as mathematical models of contextuality in both classical and quantum settings. Each structure can be seen as a ringed site with trivial topology, where the structure ring is generated by the observables. The authors extend Baudot and Bennequin's definition of information cohomology to this setting, treating it as a derived functor in the category of modules over the structure ring. They show explicitly that the bar construction provides a projective resolution in this category, thus recovering the cochain complexes used in previous works. 

The paper then focuses on the case of coefficient modules made of real-valued functions of probability distributions, parameterized by α. The only 1-cocycles in this setting are Shannon entropy or Tsallis α-entropy, depending on α. Under suitable hypotheses, Shannon entropy generates the 1-dimensional cohomology group, analogously to the fundamental class of an orientable manifold. The interpretation of 0-cohomology as invariant sections, 1-cohomology in terms of crossed homomorphisms, and 2-cohomology in terms of extensions, is also discussed. Overall, the paper provides a unified perspective on entropy through information cohomology.


## Summarize the main method used in the paper in one paragraph.

 The paper introduces the category of information structures, whose objects are suitable diagrams of measurable sets that encode the possible outputs of a given family of observables and their mutual relationships of refinement. Information structures serve as mathematical models of contextuality in classical and quantum settings. Each structure is viewed as a ringed site with trivial topology, where the structure ring is generated by the observables and multiplication corresponds to joint measurement. The authors extend Baudot and Bennequin's definition of information cohomology to this setting, as a derived functor in the category of modules over the structure ring, and show that the bar construction provides a projective resolution that recovers the previous cochain complexes. For probabilistic coefficients made of functions of probability distributions, the only 1-cocycles are Shannon entropy or Tsallis α-entropy. The cohomological approach provides an alternative characterization of entropy through its algebraic properties.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Based on skimming the paper, here is a one sentence summary:

The paper introduces a category of "information structures" to model contextuality in classical and quantum systems, defines an associated "information cohomology" using sheaf theory and derived functors, and shows this recovers entropy as a cohomology class, providing a new topological interpretation of entropy.
