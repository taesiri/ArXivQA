# [Diversity Enhanced Active Learning with Strictly Proper Scoring Rules](https://arxiv.org/abs/2110.14171)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Active learning (AL) aims to reduce labelling costs by judiciously selecting the most informative samples to be labelled by experts. However, designing good acquisition functions that measure sample informativeness is still an open research problem.

- Recent methods have issues: BALD ignores actual errors, MOCU/ELR have convergence issues, WMOCU only minimizes errors. Semi-supervised AL methods are unfair to compare against. 

- Need robust and flexible acquisition functions suitable for different tasks, with theoretical guarantees, and that work well with neural networks.

Proposed Solution:

- Propose BEMPS framework based on strictly proper scoring rules and Bregman divergences used to train neural networks. Defines acquisition function using expected increase in proper scores.

- Instantiate BEMPS with mean squared error (CoreMSE) and log probability (CoreLog). Prove convergence for BEMPS acquisition functions.

- Complement BEMPS with batch mode AL algorithm that encourages diversity using k-means on vectors of expected score changes.

- Use ensembles and dynamic validation sets to get uncertainty estimates from neural networks without separate validation set.

Contributions:

- BEMPS framework and accretion functions based on proper scoring rules 

- Convergence guarantees for BEMPS and BALD acquisition functions

- Batch algorithm to complement BEMPS acquisition functions

- Ensembling with dynamic validation sets for neural network uncertainty

- Extensive evaluation on multiple text classification datasets verifies efficacy of CoreMSE and CoreLog for active learning.

The key advantage is the flexibility and theoretical foundation of BEMPS allowing its use in different tasks, along with the robust overall system design.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The authors propose new active learning acquisition functions called Bayesian Estimate of Mean Proper Scores (BEMPS) based on strictly proper scoring rules, develop associated convergence theory, enhance performance with batch diversity and dynamic validation, and demonstrate state-of-the-art performance of the BEMPS functions using mean square error and log probability on text classification.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1) It develops the BEMPS (Bayesian Estimate of Mean Proper Scores) framework for acquisition functions in active learning based on strictly proper scoring rules/Bregman divergences. This generalizes expected errors to expected scores that can be tailored for different inference tasks.

2) It provides convergence guarantees for BEMPS borrowing techniques used with MOCU, showing that learning converges to the true model under BEMPS. This also extends to the convergence of BALD acquisition function. 

3) It develops complementary techniques to evaluate the BEMPS acquisition functions: (a) a batch active learning strategy that encourages diversity in the batch; (b) a dynamic validation set approach to generate ensembles without requiring a separate large validation set.

4) Extensive experiments on text classification datasets compare BEMPS to recent techniques like WMOCU and BADGE. The results show the mean squared error and log probability scoring rules with BEMPS yield robust acquisition functions that consistently outperform others.

In summary, the paper makes theoretical and empirical contributions in developing and evaluating a principled Bayesian framework for acquisition functions that relies on proper scoring rules, along with complementary techniques for batch active learning and model ensembling.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it are:

- Active learning (AL)
- Acquisition functions
- Expected loss reduction (ELR)
- Mean objective cost of uncertainty (MOCU) 
- Bayesian estimate of mean proper scores (BEMPS)
- Strictly proper scoring rules
- Bregman divergences
- Log probability scoring rule
- Mean squared error scoring rule  
- Batch active learning
- Diversity enhancement
- CoreMSE and CoreLog acquisition functions
- Text classification 
- Pretrained language models
- Dynamic validation set
- Neural network ensembles

The paper proposes a new Bayesian active learning framework called BEMPS based on strictly proper scoring rules and Bregman divergences. It develops the CoreMSE and CoreLog acquisition functions under this framework. For evaluation, the paper focuses on text classification tasks using pretrained language models with dynamic validation sets and neural network ensembles. It also proposes batch active learning algorithms to enhance diversity. The key terms and keywords listed capture the main technical contributions and aspects explored in the paper.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes a new acquisition function framework called BEMPS that is based on strictly proper scoring rules. How does the use of proper scoring rules for quantifying uncertainty relate theoretically to ensuring convergence compared to other uncertainty measures like entropy or expected error?

2. CoreMSE and CoreLog are introduced in BEMPS using mean squared error and log probability scoring rules respectively. What are the theoretical advantages or disadvantages of using these particular scoring rules over others for text classification tasks? 

3. Algorithm 2 returns the sample with maximum expected increase in proper scoring rule. Could you suggest some ways to extend this to find an optimal diverse batch rather than a single sample?

4. The paper excludes comparisons with recent semi-supervised AL methods. What modifications would need to be made theoretically to ensure BEMPS works in a semi-supervised learning framework?

5. Dynamic validation set construction is proposed to avoid needing a separate validation set. What are the potential downsides of this approach compared to having a fixed validation set?

6. Smaller batch sizes seem to work better than larger batches or no batches. What theoretical justification could there be for why a small diverse batch works better than greedy sequential selections?

7. What other kinds of proper scoring rules could be used with BEMPS and what benefits might they have for uncertainty estimation compared to MSE or log probability?

8. How valid are the convergence guarantees when using ensembles rather than a single model for uncertainty estimates? Does anything need to change theoretically?

9. Could the diversity mechanism be improved by using clusters of validation performance over epochs rather than expected score changes on the unlabelled set?

10. The method beats BALD significantly, suggesting parameter uncertainty is less useful. Could BALD be improved by using BEMPS style scoring rules on model parameters rather than data predictions?
