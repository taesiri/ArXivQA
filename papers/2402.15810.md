# [OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining](https://arxiv.org/abs/2402.15810)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing academic knowledge graphs and benchmarks lack multi-aspect annotations, cover limited tasks/domains, or diverge from real-world scenarios. This hinders research in academic graph mining.

Proposed Solution - OAG-Bench:
- Presents OAG-Bench, a meticulously human-annotated benchmark for academic graph mining, built on top of the Open Academic Graph (OAG).

Key Contributions:
- Covers the full spectrum of academic graph mining with 10 diverse tasks spanning entity construction, graph completion, knowledge acquisition and trace/prediction.
- Includes 20 datasets, with over 10 newly constructed ones, ranging from thousands to millions in size. 
- Provides strong baselines with 70+ methods and 120+ experimental results as a testbed.
- New annotation strategies proposed for tasks like incorrect paper-author assignment detection.
- Open-sources data processing pipelines, implementations and evaluation protocols to facilitate research.
- Experiments reveal advanced models like LLMs still struggle on key challenges like paper source tracing.
- Introduces the Open Academic Graph Challenge with leaderboard to encourage community contribution.

Overall, OAG-Bench serves as a unified, meticulously-curated benchmark to systematically evaluate algorithms across different facets of academic graph mining, aimed at accelerating progress in this space. Its comprehensiveness, fine-grained annotation, reproducibility and openness make it a valuable resource for researchers.
