# [Evaluating Fairness Metrics Across Borders from Human Perceptions](https://arxiv.org/abs/2403.16101)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Fairness in AI systems is an important issue, with examples like gender bias in algorithms. Group fairness aims to ensure fair outcomes between groups.
- Many fairness metrics have been proposed but it's impossible to satisfy all simultaneously. So which metrics align with human perceptions of fairness? 
- Prior survey studies were limited in scope to a few hundred participants from one country. Larger and more diverse studies are needed.

Methods:
- 4,000 participant survey across China, France, Japan and US (1,000 each)
- Survey covers demographics, explanation of 4 fairness metrics (quantitative parity, demographic parity, equal opportunity, equalized odds), and 3 decision scenarios (hiring, art project awards, employee awards)
- Participants rate agreement on applicability of metrics in each scenario, and choose most appropriate one

Results: 
- Country has biggest influence on choice of metric. France favors quantitative parity more. Japan/US choose equal opportunity more.
- Gender has small influence - males slightly favor demographic parity, females equalized odds
- Religion has little impact but ethnicity trends differ between countries
- In France, agreement levels on metrics did not vary much 

Limitations:
- Participant demographics may not perfectly match populations
- Compared Asia to Western countries, but trends differed between France and US

Contributions:
- Large international study on human perceptions of AI fairness metrics
- Key findings on influence of country, gender, religion, ethnicity on metric preferences
- Provides guidance for selecting appropriate fairness metrics in different contexts

The paper makes an important contribution in evaluating human perceptions of fairness metrics across diverse populations and scenarios to help guide the appropriate selection of metrics.
