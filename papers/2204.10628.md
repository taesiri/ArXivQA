# [Autoregressive Search Engines: Generating Substrings as Document   Identifiers](https://arxiv.org/abs/2204.10628)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is: Can autoregressive language models be directly applied to the retrieval problem with minimal changes to model architecture?The key points are:- Prior work has explored generating hierarchical document identifiers (e.g. titles, cluster paths) with autoregressive models. However, this forces structure and identifiers that may not exist naturally. - This paper proposes an alternative approach - using all ngrams in a document as potential identifiers that can be generated and scored by an autoregressive LM.- They introduce SEAL, which pairs an autoregressive LM with an FM-index to:  - Constrain generation to valid corpus ngrams  - Efficiently retrieve documents matching generated ngrams- This allows "generating and scoring arbitrary ngrams without needing to explicitly encode all substrings", avoiding drawbacks of prior structured approaches.- Empirically, they show SEAL matches or improves over prior autoregressive and non-autoregressive retrievers on Natural Questions and KILT benchmarks.In summary, the key hypothesis is that autoregressive LMs can be adapted for high performance retrieval by generating/scoring ngrams matched against an FM-index, without needing to impose external structures. Their results support this claim and show improvements over prior approaches.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing SEAL, an autoregressive search engine that combines an autoregressive language model with an FM-Index to perform passage retrieval. Specifically, the key contributions are:- Proposing to use all ngrams in a passage as possible identifiers for retrieval, rather than forcing a hierarchical structure. This allows generating and scoring any substring from the corpus.- Using an FM-Index to constrain decoding to valid corpus ngrams and jointly retrieve matching documents. This prevents generating invalid strings while enabling efficient retrieval.- Introducing a novel intersective scoring function to aggregate evidence from multiple generated ngrams, improving over scoring based on the single best ngram.- Empirically showing SEAL matches or improves upon prior autoregressive retrievers on Natural Questions and establishes new SOTA on passage retrieval for several KILT datasets.- Demonstrating a much smaller memory footprint compared to methods like DPR, as the FM-Index compresses the corpus.In summary, the key contribution is presenting an autoregressive retriever using corpus ngrams and an FM-Index that achieves strong empirical results while being efficient. The method does not force any structure on the corpus and can leverage future progress in autoregressive LMs.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:The paper proposes a new autoregressive search engine called SEAL that combines a language model with an FM-index to generate and score ngrams as document identifiers, outperforming prior retrieval methods on passage-level retrieval benchmarks while using a lighter memory footprint.


## How does this paper compare to other research in the same field?

 This paper presents an autoregressive approach for passage retrieval called SEAL (Search Engines with Autoregressive LMs). Here are some key ways it compares to other work in passage retrieval:- It uses an autoregressive language model (LM) to generate identifier strings for passages, similar to recent work like GENRE and DSI-BART. However, instead of titles or cluster paths, it generates arbitrary ngrams occurring in the passages. - Unlike methods that generate passages directly, it uses an FM-index to constrain generation to existing ngrams and retrieve matching passages. This prevents hallucination while allowing open-ended generation.- Compared to traditional sparse retrieval methods like BM25, it incorporates the capabilities of large pretrained LMs for scoring and query reformulation.- It outperforms previous autoregressive retrieval methods like GENRE and DSI-BART on some benchmarks. It also beats strong neural sparse retrieval methods like DPR on the KILT benchmark.- It has a much smaller memory footprint compared to dense retrievers like DPR due to the compressed FM-index. This could enable scaling to larger corpora.- The intersective scoring technique aggregates evidence from multiple predicted ngrams in a novel way compared to prior passage scoring methods.Overall, SEAL pushes the capabilities of autoregressive models for retrieval while also addressing key challenges like hallucination. The results demonstrate these types of models are becoming competitive or superior to established sparse and dense retrievers. The lightweight indexing approach also points to opportunities for future scaling.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some future research directions the authors suggest are:- Exploring the use of larger autoregressive language models like GPT-3. The paper used BART-large, but notes that larger models could lead to improved performance.- Scaling up to index and retrieve from even larger corpora like the web. The FM-index has a small memory footprint, so could potentially be more efficient than existing methods.- Developing more efficient approaches to constrained decoding, such as the method proposed by de Cao et al. (2021). This could help improve the speed of inference.- Dynamic variants of the FM-index that allow updating the index on-the-fly without full re-indexing. This could enable scaling to rapidly changing corpora.- Applying the technique to other tasks beyond information retrieval, such as only generating sequences from a predefined whitelist.- Evaluating the approach when trained on additional synthesized data, as has been shown to help for methods like MT-DPR.- Combining the approach with some of the latest term weighting and query/document expansion techniques from literature.So in summary, the main future directions revolve around scaling up the approach to larger models and datasets, improving inference speed, and exploring additional applications of the core idea of constraining generation with an FM-index.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:This paper proposes Autoregressive Search Engines (SEAL), a novel retrieval system that combines an autoregressive language model with a compressed full-text substring index (FM-Index) for passage retrieval. SEAL generates multiple ngrams conditioned on the query using constrained beam search, where the FM-Index guides the generation to produce only valid substrings occurring in the corpus. The FM-Index also allows efficiently retrieving documents containing the generated ngrams. Three scoring formulations are explored: 1) LM scoring based just on generation probabilities, 2) LM+FM scoring which also factors in FM-Index frequencies to favor distinctive ngrams, and 3) An intersective scoring that aggregates evidence from multiple ngrams while avoiding repetition. Experiments on Natural Questions and KILT benchmarks demonstrate SEAL matches or exceeds performance of existing sparse and dense retrievers, while having a much smaller memory footprint. The intersective scoring formulation establishes new SOTA downstream performance on several KILT datasets. Overall, the work shows the potential of combining autoregressive language models with compressed indexes for state-of-the-art retrieval.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:The paper proposes Autoregressive Search Engines: Generating Substrings as Document Identifiers, a new information retrieval method that combines an autoregressive language model with a compressed full-text substring index. The method generates ngrams from the query using the language model, constraints the ngrams to only valid subsequences in the corpus using the index, and then retrieves documents containing the ngrams. This allows leveraging the capabilities of large autoregressive models for retrieval while avoiding issues like hallucination.The proposed model, SEAL, is evaluated on passage retrieval tasks from the Natural Questions and KILT benchmarks. It matches or exceeds the performance of prior sparse retrieval methods like BM25 and dense methods like DPR, while requiring substantially less memory. The intersective scoring variant of SEAL establishes new state-of-the-art results on several KILT datasets when paired with a reader model. The gains demonstrate the capability of SEAL to generate distinctive query expansions capturing salient aspects of the information need. The method provides a promising direction to transfer recent autoregressive modeling advances to information retrieval.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:The paper proposes Autoregressive Search Engines (SEAL), a retrieval approach that combines an autoregressive language model with a compressed full-text substring index called the FM-index. SEAL uses the language model to autoregressively generate multiple ngrams (substrings) from the query, and uses the FM-index to constrain the generation to only valid ngrams that actually occur in the corpus. The FM-index also allows efficiently looking up all documents that contain each generated ngram. Documents are then scored based on the probabilities of the ngrams they contain. The authors experiment with different scoring formulations, including using just the language model probability of the ngrams, incorporating the ngram frequency from the index, and an "intersective" scoring that aggregates evidence from multiple ngrams in a document. Empirically they show this approach matches or exceeds the performance of prior work on Natural Questions and establishes a new state-of-the-art on the KILT benchmark when paired with a reader model. The use of the FM-index allows the approach to scale to large corpora while using a small memory footprint.


## What problem or question is the paper addressing?

 The paper is addressing the challenge of leveraging the capabilities of powerful autoregressive language models for retrieval. Specifically, it is looking at how to use autoregressive language models to generate identifiers that can be used to retrieve relevant documents from a corpus, rather than generating the documents directly. The key problems/questions it aims to tackle are:- How to constrain the identifier generation space so that the model only generates valid identifiers that correspond to documents in the corpus.- How to map the generated identifiers back to full document passages efficiently.- How to effectively score identifiers and aggregated document relevance based on both language model probabilities and corpus statistics.- Whether this approach can match or exceed the performance of existing retrieval methods like sparse methods and dense retrievers.So in summary, the core focus is on developing an effective strategy to harness autoregressive language models for high-performance retrieval, using generated substrings as grounded document identifiers. The paper aims to show this is a viable alternative to other retrieval paradigms.
