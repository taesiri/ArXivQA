# [Optimizing ViViT Training: Time and Memory Reduction for Action   Recognition](https://arxiv.org/abs/2306.04822)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: How can we reduce the substantial training time and memory consumption associated with video transformers, specifically the factorised encoder variant of the ViViT model, in order to make them more accessible for researchers and practitioners with limited resources?The key hypothesis seems to be:By freezing the spatial transformer and adding a lightweight adapter module during fine-tuning, along with properly initializing the temporal transformer, it is possible to significantly cut down on training costs and memory usage of the ViViT model without sacrificing accuracy or model sophistication.In summary, the paper aims to investigate strategies to optimize ViViT training to address the challenges posed by the model's demanding computational requirements, with the goal of enabling broader access and application of advanced video transformers. The proposed methods focus on harnessing the sophistication of ViViT while minimizing its resource demands.
