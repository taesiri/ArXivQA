# [WebVoyager: Building an End-to-End Web Agent with Large Multimodal   Models](https://arxiv.org/abs/2401.13919)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing web agents typically handle only one input modality (text or vision) and are evaluated in simplified web simulators or static web snapshots. This limits their applicability in real-world scenarios with dynamic websites. There is a need for web agents that can interact with real websites in an end-to-end manner using both text and vision.

Proposed Solution: 
The paper proposes WebVoyager, an end-to-end web agent powered by large multimodal models (LMMs) like GPT-4V that integrates textual and visual information. WebVoyager interacts with real websites using Selenium and takes screenshots as primary inputs for decision making. It also extracts text from key HTML elements. Bounding boxes are overlaid on interactive elements in the screenshots to guide the agent. The action space consists of click, type, scroll, wait, goBack, jumpToSearchEngine, and answer actions.

For evaluation, a benchmark of 300 real-world web tasks over 15 popular websites is created using self-instruct. Both manual and automated evaluations using GPT-4V are conducted on navigation trajectories.

Main Contributions:

- Proposes WebVoyager, a multimodal LMM-based web agent that interacts with real websites end-to-end to accomplish user instructions 

- Builds an online web environment and a benchmark with diverse real-world web tasks centered around commonly used websites

- Employs manual evaluation of navigation trajectories and proposes an automated evaluation protocol using GPT-4V

- Shows WebVoyager achieves 55.7% task success rate, significantly higher than GPT-4 (32.7%) and WebVoyager without visual inputs (39%), demonstrating the efficacy of the multimodal approach.

- Analysis shows GPT-4V automated evaluation has 85.3% agreement with human judgement, demonstrating feasibility of automatic evaluation for web agents.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper introduces WebVoyager, a multimodal web agent powered by large language models that can complete real-world web tasks end-to-end by interacting with web browsers, and proposes new evaluation protocols using both human judgement and an automatic evaluator based on GPT-4V.


## What is the main contribution of this paper?

 This paper introduces WebVoyager, a multimodal web agent powered by large language models that can complete end-to-end web tasks by interacting with real-world websites online. The main contributions are:

1) It employs a multimodal agent that integrates textual and visual information from webpages to make decisions during navigation. This allows it to leverage the visual structure and information on real websites.

2) It builds an online web browsing environment using Selenium that allows the agent to directly access and interact with 15 popular real-world websites. This poses unique challenges compared to simulated environments.

3) It creates a benchmark of 300 diverse tasks centered around these websites using a semi-automated self-instruct method. Tasks have open-ended answers that change dynamically.

4) It proposes both manual evaluation by humans and an automated evaluation protocol leveraging GPT-4V to judge navigation trajectories. Results show over 85% agreement between human and GPT-4V judgements.

In summary, the key innovation is in enabling multimodal end-to-end completion of tasks by interacting with real, open websites online. The combination of vision and language, dynamic benchmark, and evaluation methods advance web agent research.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- Web agent - The paper introduces "WebVoyager", which is an LMM-powered web agent designed for end-to-end web task resolution.

- Multimodal models - The paper utilizes large multimodal models (LMMs) with both vision and language capabilities to power the WebVoyager agent.

- Online environment - The WebVoyager agent interacts with real-world websites through an online Selenium environment instead of simplified simulated environments. 

- Evaluation - The paper proposes both human evaluation and automatic evaluation using GPT-4V to assess the performance of web agents on real-world web tasks.

- Task success rate - A key evaluation metric that measures the rate at which agents successfully complete real-world web tasks. 

- Visual grounding - The paper analyzes issues with visual grounding, which is the ability to correctly interpret and act on visual inputs.

- Accessibility tree - A text-only baseline is included that relies on the accessibility tree rather than visual screenshots.

So in summary, key terms cover the web agent itself, the use of multimodal models, the real-world evaluation, and analysis of the results including visual grounding issues.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper introduces a new multimodal web agent called WebVoyager. What are the key capabilities of WebVoyager that distinguish it from prior web agents? How does it leverage both textual and visual information during web navigation?

2. The paper proposes a new benchmark for evaluating web agents, comprising real-world tasks gathered from 15 popular websites. What was the semi-automated process used to construct these tasks? What strategies were employed to ensure diversity and quality?  

3. The paper highlights the limitations of existing web agent evaluations using predefined action trajectories. Explain the issues with this approach that motivated the design of a new evaluation protocol. How does the proposed human + GPT-4V evaluation better assess end-to-end task completion capabilities?

4. Explain the online web browsing environment developed in the paper using Selenium. What considerations influenced the choice to have the agent interact with real-world websites instead of simulated or locally hosted ones? What unique challenges does the open web introduce?

5. The paper employs a prompting strategy to generate the agent's action at each step. Explain this interaction formulation in detail - what is the context, observation space and action space? How does thought prompting enhance the efficiency and interpretability of the agent?

6. WebVoyager overrides bounding boxes and labels on interactive web elements to guide the agent's actions. Motivate this design decision - how does it simplify visual perception and planning compared to processing raw HTML text? What strategies are used to accurately locate and label elements?  

7. Analyze figure 8, which relates website complexity and trajectory length to task success rate. What inferences can be drawn about the current capabilities and limitations of WebVoyager based on this analysis? What steps could improve performance on complex websites?

8. The paper conducts comprehensive error analysis attributing failures to 4 major categories. Elaborate on the key issues in each failure mode and discuss potential strategies to mitigate them. Which modes require improvements in vision, language or reasoning capabilities?

9. Explain the motivation for using GPT-4V as an automated evaluator, instead of solely relying on human assessment. How reliable was GPT-4V found to be in emulating human judgments? What are the practical benefits if this approach can be scaled effectively? 

10. What limitations of WebVoyager are outlined by the authors? Which abilities would need enhancement for the agent to handle a broader range of real-world web interactions? Discuss 2-3 promising research directions that could build on this work.
