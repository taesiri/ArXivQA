# [Concentric Spherical GNN for 3D Representation Learning](https://arxiv.org/abs/2103.10484)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research questions/hypotheses addressed in this paper are:1. Can learning over concentric spherical feature maps, as opposed to a single sphere, lead to more expressive and generalizable representations for 3D data? The authors argue that projecting 3D data onto a single sphere, as done in previous spherical CNN works, may result in loss of information and be insufficiently expressive. They propose using multiple concentric spheres instead, to more natively capture 3D distributions.2. Can convolutional architectures be designed to incorporate information both within and between concentric spheres in a rotationally equivariant manner?The authors propose combining intra-sphere graph convolutions with inter-sphere radial convolutions to incrementally aggregate information over the concentric spheres representation. They argue this allows retaining rotational equivariance properties of spherical CNNs.3. Can the proposed concentric spherical architecture and convolutions improve performance on 3D classification tasks, especially when training and testing on arbitrarily rotated data?The authors demonstrate improved classification accuracy on ModelNet40 point clouds and SHREC17 meshes compared to state-of-the-art methods, particularly in the challenging setting of arbitrary rotations. This provides evidence for the benefits of the proposed architecture.In summary, the main hypotheses are around the advantages of using concentric spheres over a single sphere for representing 3D data, designing convolutions over this representation, and showing these translate to empirical gains in tasks involving arbitrarily oriented 3D data.


## What is the main contribution of this paper?

This paper presents a new multi-resolution convolutional neural network architecture for learning on concentric spherical feature maps. The key contributions are:- Proposing a concentric spherical discretization of 3D space using multiple spheres at different radii. This is more flexible than using a single sphere discretization as in previous spherical CNN works.- Introducing two new convolution operations - graph convolutions for incorporating intra-sphere information and radial convolutions for incorporating inter-sphere information. The combination allows capturing 3D relationships while retaining rotational equivariance. - Demonstrating state-of-the-art performance on 3D classification tasks with two different input types - mesh objects and point clouds. For point clouds, they propose an efficient mapping based on radial basis functions to map unstructured points to the concentric spherical grids.- Overall, showing that incorporating the radial dimension through concentric spheres and new convolution operations leads to more expressive and robust learned representations compared to single sphere CNNs. The multi-sphere architecture with specialized convolutions is the main conceptual contribution.In summary, the key innovation is a new multi-resolution convolutional architecture over concentric spheres that achieves state-of-the-art 3D classification results. The new convolutions and discretization allow learning more expressive 3D representations in a rotationally equivariant manner.


## How does this paper compare to other research in the same field?

Based on my reading of the paper, here is a summary of how it compares to related work:- The paper introduces a new multi-sphere convolutional neural network architecture for 3D representation learning. This builds on prior work on spherical CNNs like Cohen et al. 2018 and Esteves et al. 2018, but proposes using multiple concentric spheres rather than a single sphere discretization.- Compared to other spherical CNN methods, the proposed model achieves better performance on 3D classification tasks involving rotated inputs. For example, on ModelNet40 point cloud classification with arbitrary SO3 rotations, the proposed model improves accuracy by 1.7% over the next best spherical CNN model (SFCNN).- The concentric spheres representation allows incorporating both intra-sphere and inter-sphere information through specific graph and radial convolutions. This provides greater representational capacity compared to methods limited to a single sphere.- For processing raw point clouds, the paper introduces a mapping based on radial basis functions to represent points on the concentric spheres. This allows bridging spherical convolutions defined on grids with irregular point inputs.- Compared to pointwise convolution networks like PointNet, DGCNN, and RIConv, the proposed model achieves significantly higher accuracy on ModelNet40 classification with rotated inputs. This suggests an advantage of the spherical representation for rotational robustness.- The computational complexity of the model remains linear in the number of discretization points due to the choice of graph and 1D radial convolutions. This matches or improves the scalability of other state-of-the-art spherical and pointwise convolution models.In summary, the paper introduces a novel concentric spherical representation and corresponding convolution operations that achieve new state-of-the-art results for 3D classification tasks involving arbitrary rotations. The proposed architecture offers greater representational capacity compared to previous spherical CNN methods.


## What future research directions do the authors suggest?

The authors suggest a few potential future research directions in the discussion section:- Exploring more descriptive mappings of point cloud data to the discretization. The current work uses a simple Gaussian RBF mapping, but a learned assignment may better learn vertex features for describing nearby points.- Exploring sparse convolutions by utilizing sparsity of point cloud data. This could help improve scalability and efficiency.- Exploring the tradeoff between the number of concentric spheres (R) and the discretization resolution (number of vertices per sphere) given a fixed budget on total discretization size. The current work fixes one and varies the other but does not explore optimizing the balance.- Applying the proposed concentric spherical convolutions to other 3D tasks such as segmentation, object detection, etc. The current work focuses on classification.- Extending the concentric spherical representation and convolutions to other domains such as graphs and manifolds.- Combining the benefits of the proposed approach with pointwise convolution networks, which operate directly on points.- Improving the mapping to handle cases where multiple mesh surfaces are incident between concentric spheres. Currently information is discarded in such cases.In summary, the main future directions are: exploring more optimal discretization parameters, applying to other tasks and data modalities, improving the data mapping, and combining benefits with other approaches like pointwise convolutions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new multi-resolution convolutional neural network architecture for learning on concentric spherical feature maps, demonstrating improved performance for 3D classification tasks involving mesh objects and point clouds compared to existing spherical CNN and point convolution methods.
