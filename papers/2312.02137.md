# [MANUS: Markerless Hand-Object Grasp Capture using Articulated 3D   Gaussians](https://arxiv.org/abs/2312.02137)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of this paper:

This paper presents a new method called MANUS for markerless capture of human hand grasps by accurately estimating the shape, appearance, and precise contact between the hand and grasped object from multi-view RGB videos. The key innovation is an articulated 3D Gaussian hand model called MANUS-Hand that represents the personalized hand geometry using Gaussian primitives. By also modeling the grasped object with 3D Gaussians, instantaneous and accumulated hand-object contacts can be efficiently computed thanks to the explicit Gaussian positions and orientations. To support the data needs of the method, the authors introduce a large-scale multi-view grasp dataset called MANUS-Grasps comprising over 7 million frames captured by 53 cameras showing 400+ grasp sequences across 30 everyday scenarios. Notably, the dataset provides ground truth accumulated contacts obtained through paint transfer from objects onto the grasping hands. Experiments demonstrate superior hand modeling accuracy over prior work and more precise hand-object contact estimation compared to using alternative hand representations like MANO or HARP. Ablation studies further justify the method and dataset design decisions. While not targeting photorealism, MANUS produces visually convincing grasp sequences that could enable new applications in areas like robotics and mixed reality.
