# [Compressing Volumetric Radiance Fields to 1 MB](https://arxiv.org/abs/2211.16386)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key points of this paper are:

- The paper proposes a framework called vector quantized radiance fields (VQRF) for compressing volumetric radiance field models like Plenoxels and DVGO. 

- Volumetric radiance fields methods can be very storage intensive, often requiring hundreds of MB to represent a scene. The goal is to significantly compress these models while maintaining rendering quality.

- The paper presents a 3-stage compression pipeline: voxel pruning to remove redundant voxels, vector quantization to encode features into a compact codebook, and post-processing steps like quantization and entropy encoding. 

- A key contribution is developing an adaptive voxel pruning strategy based on a cumulative importance score metric, which allows pruning to be generalized across scenes and models. 

- Another contribution is the proposed vector quantization method that incorporates voxel importance into codebook learning and allows joint fine-tuning to recover rendering quality after compression.

- Experiments show the framework can compress volumetric models by up to 100x down to 1MB with little loss of rendering quality. The method also generalizes well across datasets and volumetric model architectures.

In summary, the central hypothesis is that an effective compression framework can be developed to significantly reduce the storage requirements of volumetric radiance fields while maintaining high rendering fidelity. The paper presents VQRF as an approach to achieve this goal.
