# [Compressing Volumetric Radiance Fields to 1 MB](https://arxiv.org/abs/2211.16386)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key points of this paper are:

- The paper proposes a framework called vector quantized radiance fields (VQRF) for compressing volumetric radiance field models like Plenoxels and DVGO. 

- Volumetric radiance fields methods can be very storage intensive, often requiring hundreds of MB to represent a scene. The goal is to significantly compress these models while maintaining rendering quality.

- The paper presents a 3-stage compression pipeline: voxel pruning to remove redundant voxels, vector quantization to encode features into a compact codebook, and post-processing steps like quantization and entropy encoding. 

- A key contribution is developing an adaptive voxel pruning strategy based on a cumulative importance score metric, which allows pruning to be generalized across scenes and models. 

- Another contribution is the proposed vector quantization method that incorporates voxel importance into codebook learning and allows joint fine-tuning to recover rendering quality after compression.

- Experiments show the framework can compress volumetric models by up to 100x down to 1MB with little loss of rendering quality. The method also generalizes well across datasets and volumetric model architectures.

In summary, the central hypothesis is that an effective compression framework can be developed to significantly reduce the storage requirements of volumetric radiance fields while maintaining high rendering fidelity. The paper presents VQRF as an approach to achieve this goal.


## What is the main contribution of this paper?

 The main contribution of this paper is developing a framework for compressing volumetric radiance fields. The key points are:

- They propose a voxel pruning method to remove less important voxels and reduce model size. An adaptive importance score threshold is used for pruning to make it generalizable across scenes and models.

- They introduce vector quantization to encode the features of remaining important voxels into a compact codebook, allowing substantial model compression. An iterative optimization strategy is used for codebook learning.

- They propose joint fine-tuning to recover the rendering quality of the compressed model close to the original uncompressed model. 

- Additional techniques like weight quantization and entropy encoding are used as a post-processing step to further reduce model size.

- Extensive experiments show the proposed framework can compress volumetric radiance fields by up to 100x with negligible loss of rendering quality. The method demonstrates good generalization across multiple models and datasets.

In summary, the key contribution is developing an effective general framework for compressing volumetric radiance fields to very small sizes, enabling their practical use in real applications. The proposed techniques including pruning, vector quantization and joint finetuning are simple yet efficient for volumetric model compression.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence TL;DR summary of the paper:

The paper proposes a framework called vector quantized radiance fields (VQRF) to compress volume-grid-based radiance field models by pruning unimportant voxels, vector quantizing features, and post-processing, achieving 100x compression rates with negligible loss in rendering quality.
