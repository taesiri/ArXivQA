# [MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM   Hallucination Detection](https://arxiv.org/abs/2403.00964)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Natural language generation (NLG) models can produce fluent but inaccurate, "hallucinated" text outputs. 
- The Shared Task on Hallucinations and Related Observable Overgeneration Mistakes (SHROOM) at SemEval 2024 aims to address this by detecting semantic hallucinations in generated text.

Proposed Solution:
- Introduce a pipeline with two key components:
   1) Data augmentation using pseudo-labeling by a large language model (LLM) and sentence rephrasing 
   2) A 3-model voting ensemble leveraging models pre-trained on natural language inference (NLI) and fine-tuned on diverse datasets

- Data Augmentation:
   - Pseudo-labeling: Use SOLAR LLM to label 30K unlabelled instances
   - Sentence rephrasing: Rephrase 500 labelled instances using GPT-4 

- Ensemble contains:
   - Baseline BERT-based binary classifier
   - Model trained with Conditioned Reinforcement Learning Fine Tuning (C-RLFT)
   - Sequential model based on iterative fine-tuning
   
- Ensemble allows trading off precision for improved recall in detecting hallucinations

Main Contributions:
- Novel data augmentation pipeline using LLM-assisted pseudo-labeling and sentence rephrasing
- Ensemble model combining complementary approaches for improved recall
- Exploration of different training strategies: C-RLFT weighting schemes, sequential fine-tuning 
- Achieved 80.07% accuracy on SHROOM SemEval 2024 Task 6

In summary, the paper introduces an automated pipeline to detect semantic hallucinations in NLG models, using data augmentation and an ensemble that combines multiple complementary approaches. The techniques help improve recall for identifying hallucinated text.
