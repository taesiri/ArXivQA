# [Universal Source Separation with Weakly Labelled Data](https://arxiv.org/abs/2305.07447)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to build a universal audio source separation system that can separate arbitrary sounds using only weakly labeled training data. The key points are:- Most prior work focuses on separating specific sound sources like speech or music. This paper proposes a framework for universal source separation that can handle hundreds of sound classes using a single model.- Previous methods rely on clean source data for training. This paper proposes using only weakly labeled data like AudioSet where the recordings have tags but no isolated sources.- The paper proposes an approach with 1) a sound event detection model to locate anchor segments likely to contain target sounds, 2) an audio tagging model to generate embedding vectors that indicate the desired source to separate, and 3) a conditional separation model that takes the mixture and embedding as input to output the target source waveform.- The system is evaluated on separating sounds from AudioSet and also tested on various tasks like music separation and speech enhancement without being trained on those specific datasets. This demonstrates the generalization of the universal separation approach.So in summary, the key hypothesis is that a universal source separation system can be trained on weakly labeled data alone and generalize to separating a wide variety of sounds, which is validated through the experiments in the paper.
