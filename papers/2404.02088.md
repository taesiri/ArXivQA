# [LastResort at SemEval-2024 Task 3: Exploring Multimodal Emotion Cause   Pair Extraction as Sequence Labelling Task](https://arxiv.org/abs/2404.02088)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Emotion and cause analysis from conversational text has been explored, but not extensively from a multimodal perspective involving text, audio and video. 
- The paper tackles the problem of Multimodal Emotion Cause Pair Extraction (MC-ECPE) - identifying emotions expressed in utterances in a conversation and extracting the corresponding cause utterances from multiple modalities.

Proposed Solution:
- A 3-step approach - emotion detection, candidate cause identification, and emotion-cause pairing
- Baseline I: Utterance labeling with CNN/RNN/Transformer encoders for each modality and an MLP classifier in each step 
- Baseline II: Sequence labeling using BiLSTM and MLP classifiers 
- Baseline III: Sequence labeling with BiLSTM + CRF for emotion detection and BiLSTM + MLP for other steps

Key Contributions:
- Comparative study of utterance labeling vs sequence labeling approaches for the MC-ECPE task
- Analysis of different encoders like BERT, DeBERTa, EmotionRoBERTa for text, Wav2Vec, WavLM for audio and MViT for video
- EmotionRoBERTa + WavLM + MViT gave the best performance
- Observation that sequence labeling does not help much for this dataset due to short conversation lengths
- The paper provides strong baselines for the MC-ECPE task with extensive experimentation

The paper tackles a novel and important problem of multimodal emotion cause analysis. It provides a systematic study of different modeling choices and suggests promising future work in joint multimodal modeling.
