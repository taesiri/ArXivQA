# [Comparison of Waymo Rider-Only Crash Data to Human Benchmarks at 7.1   Million Miles](https://arxiv.org/abs/2312.12675)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Assessing the real-world safety performance of automated driving systems (ADS) is important but methodologically challenging. Prior studies comparing ADS crash rates to human benchmarks have had limitations such as biases or improper statistical comparisons.

- This paper examines the safety performance of the Waymo Driver ADS used in a rider-only ride-hailing service by analyzing its crash data reported to NHTSA and comparing to human driving benchmarks.

Methods:
- The study analyzed the first 7.14 million miles of Waymo's rider-only service across Phoenix, San Francisco and Los Angeles using crashes reported to NHTSA's Standing General Order.

- Crashes were categorized as: all reported, in-transport vehicles only, excluding minor crashes (delta-V < 1mph), police-reported, and any injury reported.

- Waymo crash rates per million miles were compared to human driving benchmarks from literature, using valid statistical methods for rate ratios and confidence intervals. Benchmarks were selected to match geography and reporting criteria.

Results:
- The Waymo ADS had statistically significantly lower rates of police-reported crashes (57% lower) and any injury crashes (85% lower) compared to human benchmarks, when considering all locations together.

- For any property damage crashes, Waymo rates were generally lower than human benchmarks but there was greater uncertainty due to data limitations on crash reporting thresholds.

- The Waymo ADS had a 6.8 times lower any injury crash rate and 2.3 times lower police-reported crash rate compared to human drivers overall.

Conclusions: 
- The study shows the Waymo ADS operating in rider-only mode has a lower crashed vehicle rate for injury and police-reported crashes compared to human drivers over 7.14 million miles.

- This helps demonstrate safety improvements from the ADS technology. However, there are still data limitations in assessing any property damage crash performance.

- As ADS exposure increases, additional retrospective analyses will further understanding of real-world ADS safety. Benchmarking crash rates is one part of the overall safety case approach.


## Summarize the paper in one sentence.

 The paper compares crash rates from over 7 million miles of Waymo's rider-only autonomous vehicles to human driving benchmarks, finding the autonomous vehicles had significantly lower rates of police-reported and injury crashes.


## What is the main contribution of this paper?

 The main contribution of this paper is:

1) It compares the crash rates of Waymo's autonomous vehicles operating in rider-only mode (without a safety driver) to human driving benchmarks. Specifically, it examines crashes per million miles for any property damage/injury, police-reported crashes, and any injury crashes.

2) It uses over 7 million miles of public ridyer-only data reported to NHTSA under the Standing General Order to calculate Waymo's crash rates. This is one of the first studies to use a large dataset of truly driverless crash data rather than testing data with a safety driver.

3) It adjusts the human driving benchmarks to correct for biases and underreporting, making the comparison to Waymo's self-reported crash data more valid. For example, it excludes "not-in-transport" parked vehicle crashes and excludes low speed delta-V crashes below 1 mph in the Waymo data.

4) It finds Waymo's rider-only vehicles have significantly lower rates of police-reported and any-injury crashes compared to the human benchmarks, with 57-85% lower rates depending on category and location. This helps validate Waymo's safety determinations prior to deploying rider-only operations.

In summary, this paper contributes a rigorous analysis of the crash rates of a Level 4 driverless ride-hailing service compared to adjusted human benchmarks, enabled by publicly available data, helping to advance understanding of AV safety.


## What are the keywords or key terms associated with this paper?

 Based on my review, some of the main keywords and key terms associated with this paper include:

- Automated Driving Systems
- Safety Impact Analysis 
- Traffic Safety
- Crashed vehicle rates
- Benchmarking
- Underreporting adjustment
- Naturalistic driving studies
- Police-reported crashes 
- Injury crashes
- Retrospective analysis
- Confidence intervals

The paper compares the crashed vehicle rates of an automated driving system (the Waymo Driver) operating in rider-only mode to various human driving benchmarks. It conducts this retrospective safety impact analysis using publicly available crash data reported to NHTSA under a Standing General Order. The analysis examines crashes of all severities, as well police-reported and injury crashes specifically. It also discusses methodological considerations like correcting for underreporting biases in the benchmarks and computing valid confidence intervals. So keywords related to these aspects of crash rate analysis, benchmarks, crash severity, and statistics are central to characterizing this work.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the methods proposed in the paper:

1. The paper compares the ADS crash rate to human benchmarks that are adjusted for underreporting or use naturalistic driving study (NDS) data. What are some limitations of using these adjusted/NDS benchmarks compared to using raw police-reported crash data?

2. The paper excludes ADS crashes where the vehicle was not "in-transport" to match the human benchmark data. What other decisions were made in selecting the ADS crashes to facilitate an "apples-to-apples" comparison and what are the potential limitations? 

3. Table 1 shows the comparable benchmarks selected for the ADS injury, police-reported, and property damage outcomes. What other human driving populations or benchmarks could have been selected and what are the advantages/disadvantages of those alternatives?

4. The paper finds a large discrepancy between the underreporting adjusted property damage benchmarks and the NDS property damage benchmarks. What are some possible reasons for this discrepancy? How does this uncertainty impact interpreting the property damage results?

5. How was the threshold for excluding low delta-V ADS crashes determined? What are some limitations of using a delta-V threshold for determining crash severity? 

6. The statistical power analysis in section 4.3 concludes that billions of miles are needed to determine fatal crash reductions. What interim metrics could be used to gather evidence of risk mitigation for high severity crashes with less mileage?

7. How do the findings on overall crash rate reduction compare to the Waymo liability claim rate analysis done in Di et al 2023? What are the advantages and disadvantages of each method?

8. Section 5.2 discusses limitations of comparing aggregate ADS crash rates across different operating years and platforms. What analyses could be done with more mileage to investigate differences over time?

9. How do the reported confidence intervals in Tables 3 and 4 change depending on whether the Poisson or Beta distribution method is used? How could this impact interpretations of statistical significance?

10. What recommendations does this study make regarding future standardization of methods for retrospective automated driving system safety analyses? What areas need further development?
