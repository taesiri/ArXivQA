# [The ObjectFolder Benchmark: Multisensory Learning with Neural and Real   Objects](https://arxiv.org/abs/2306.00956)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: how can we collect multisensory data from real-world objects and use it to enable research in multisensory object-centric learning? The key contributions are:1. Introducing the ObjectFolder Real (OFR) dataset, which contains multisensory measurements of 100 real household objects, including 3D meshes, videos, impact sounds, and tactile data. 2. Designing a pipeline to systematically collect high-fidelity visual, acoustic, and tactile data for real objects.3. Proposing the ObjectFolder Benchmark, a suite of 10 tasks centered around object recognition, reconstruction, and manipulation using multiple senses. 4. Conducting experiments on the neural objects from ObjectFolder V2 and real objects from OFR to analyze the distinct roles of vision, audio, and touch for different object-centric tasks.5. Demonstrating the value of OFR for transfer learning and sim2real, achieving improved performance by pretraining on OFR compared to other datasets.In summary, the central hypothesis is that multisensory modeling of real objects can enable more robust perception for various object-centric tasks, which is validated through the systematic data collection, benchmarking, and analysis.


## What is the main contribution of this paper?

This paper introduces the ObjectFolder Benchmark, which consists of two main contributions:1. The ObjectFolder Real dataset: This contains multisensory data (3D meshes, videos, impact sounds, tactile readings) collected from 100 real-world household objects. It represents the first dataset with comprehensive real-world visual, acoustic, and tactile measurements. 2. A benchmark suite of 10 tasks for multisensory object-centric learning: The tasks cover object recognition (e.g. cross-sensory retrieval), reconstruction (e.g. 3D shape reconstruction), and manipulation (e.g. grasp stability prediction). Experiments are conducted on both the neural objects from ObjectFolder v2 and the real objects from ObjectFolder Real.The key novelty is providing a standardized benchmark for multisensory perception research, including both simulated and real data. By releasing the dataset and benchmark tasks, the work aims to enable and catalyze new research directions in multisensory object modeling.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper introduces a new multisensory dataset of real objects called ObjectFolder Real and a benchmark suite of 10 tasks for multisensory object-centric learning involving vision, sound, and touch modalities.
