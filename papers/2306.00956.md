# [The ObjectFolder Benchmark: Multisensory Learning with Neural and Real   Objects](https://arxiv.org/abs/2306.00956)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: how can we collect multisensory data from real-world objects and use it to enable research in multisensory object-centric learning? The key contributions are:1. Introducing the ObjectFolder Real (OFR) dataset, which contains multisensory measurements of 100 real household objects, including 3D meshes, videos, impact sounds, and tactile data. 2. Designing a pipeline to systematically collect high-fidelity visual, acoustic, and tactile data for real objects.3. Proposing the ObjectFolder Benchmark, a suite of 10 tasks centered around object recognition, reconstruction, and manipulation using multiple senses. 4. Conducting experiments on the neural objects from ObjectFolder V2 and real objects from OFR to analyze the distinct roles of vision, audio, and touch for different object-centric tasks.5. Demonstrating the value of OFR for transfer learning and sim2real, achieving improved performance by pretraining on OFR compared to other datasets.In summary, the central hypothesis is that multisensory modeling of real objects can enable more robust perception for various object-centric tasks, which is validated through the systematic data collection, benchmarking, and analysis.
