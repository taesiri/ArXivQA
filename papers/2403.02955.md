# [XAI-Based Detection of Adversarial Attacks on Deepfake Detectors](https://arxiv.org/abs/2403.02955)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Deepfakes, or AI-generated fake media, are a growing issue with potential for misinformation and harm. Deepfake detection systems aimed at identifying fakes are vulnerable to adversarial attacks designed to fool them.  

- There is a need for enhanced security and robustness of deepfake detectors against adversarial manipulation. Understanding decision-making in detectors using eXplainable AI (XAI) can aid detecting attacks.

Methodology:
- Proposes an XAI-based adversarial detector to identify attacks on deepfake detectors like XceptionNet and EfficientNetB4ST. 

- Employs XAI methods like Guided Backpropagation, Saliency Maps, Input*Gradient, Integrated Gradients to generate visual interpretability maps along with input images.

- Processes image and matching XAI map through ResNet50 extractor to obtain feature embeddings, classified as real/attacked by added classifier layers.

- Assesses performance against white-box attacks like PGD and APGD, and black-box attacks like NES and Square crafted on FaceForensics++ dataset.

Key Results:
- Demonstrates XAI's capability in detecting subtle adversarial perturbations that may otherwise be missed. 

- XAI-enabled detector obtained 85.95% average accuracy against attacks across tested models, showing promise.

- Highlights vulnerabilities still present in deepfake detectors against gradient-based and black-box adversarial attacks. 

- Shows that model finetuning on target dataset boosts attack resilience over just finetuning classifier.

Main Contributions:  
- Novel XAI-based methodology to identify adversarial attacks on deepfake detectors

- Empirical evidence that leveraging XAI enhances detection of subtle adversarial manipulations  

- Analysis of performance against diverse white-box and black-box attack techniques

- Demonstrates method's capability to generalize across multiple deepfake detectors 

- Underscores need for further research into adversarial robustness for deepfake detectors
