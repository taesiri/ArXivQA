# [GMML is All you Need](https://arxiv.org/abs/2205.14986)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: How can we enable vision transformers to be trained efficiently from scratch on small/medium datasets through self-supervised pre-training, without relying on large datasets like ImageNet?The key hypotheses seem to be:1) By manipulating images using the proposed Group Masked Model Learning (GMML) approach during pre-training, the model can learn useful contextual representations from all concepts in an image, not just foreground objects.2) This will allow the vision transformer to generalize well to downstream tasks, even when trained on limited data, overcoming the typical data hungry nature of transformers. 3) The proposed GMML pre-training approach will outperform state-of-the-art supervised and self-supervised methods, especially on smaller datasets, due to its ability to extract contextual information from all concepts.In summary, the main research question is how to make vision transformers data-efficient through a self-supervised pre-training approach, with the central hypothesis being that the proposed GMML method can enable this. The experiments aim to validate if GMML allows transformers to train on and generalize well from small/medium datasets.
