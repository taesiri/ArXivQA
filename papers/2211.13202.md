# [Lite-Mono: A Lightweight CNN and Transformer Architecture for   Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2211.13202)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to design an effective and lightweight neural network architecture for self-supervised monocular depth estimation. The key points are:- The authors aim to develop a lightweight model that can achieve competitive accuracy compared to larger models for monocular depth estimation. This allows the model to be deployed on edge devices.- They propose a hybrid CNN and Transformer architecture called Lite-Mono to extract both enhanced local features and global context.- Two novel modules are introduced - Consecutive Dilated Convolutions (CDC) to capture multi-scale local features, and Local-Global Features Interaction (LGFI) to incorporate global context via a modified self-attention mechanism.- Experiments on KITTI and Make3D datasets demonstrate Lite-Mono achieves state-of-the-art accuracy with much fewer parameters compared to previous methods. It also has a good trade-off between accuracy and speed.In summary, the central hypothesis is that by carefully designing a lightweight hybrid CNN-Transformer network with modules to capture multi-scale local and global features, competitive monocular depth estimation can be achieved for efficient deployment. The results validate this hypothesis.


## What is the main contribution of this paper?

The main contributions of this paper are:- It proposes a new lightweight architecture called Lite-Mono for self-supervised monocular depth estimation. The model uses a hybrid CNN and Transformer design to extract both local and global features from images.- The proposed model achieves state-of-the-art accuracy on the KITTI dataset while having much fewer parameters than other methods. It demonstrates superior performance compared to larger models like Monodepth2 and MonoFormer.- The model generalizes well, as evidenced by its strong performance on the Make3D dataset without any fine-tuning.- Lite-Mono achieves a good balance between accuracy and efficiency. It has low inference times on both a high-end GPU and an embedded Jetson platform.- The paper presents ablation studies that validate the effectiveness of key components of the architecture like the Consecutive Dilated Convolutions (CDC) and Local-Global Features Interaction (LGFI) modules.In summary, the main contribution is a new lightweight and accurate architecture for monocular depth estimation that combines CNNs and Transformers in an efficient way. The experiments demonstrate its state-of-the-art accuracy and efficiency trade-off.
