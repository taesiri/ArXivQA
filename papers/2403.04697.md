# [AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit   Detectors](https://arxiv.org/abs/2403.04697)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Facial Action Unit (AU) detection is an important task in affective computing, but suffers from overfitting due to large number of parameters in models and limited AU-annotated data. 
- Existing methods rely on additional relevant data to mitigate overfitting, which is still insufficient.
- Parameter-Efficient Transfer Learning (PETL) methods have not been explored for AU detection.

Proposed Solution:
- Propose AUFormer, first work to investigate PETL for AU detection.
- Develop a Mixture-of-Knowledge Expert (MoKE) collaboration mechanism to efficiently adapt pre-trained Vision Transformer (ViT) for AU detection.
- Introduce minimal learnable parameters into ViT via MoKEs specialized for each AU.
- MoKE integrates Multi-Receptive Field (MRF) and Context-Aware (CA) operators to capture multi-scale and correlation knowledge crucial for AU detection.
- MoKEs collaborate within group, aggregate information, and inject it back into frozen ViT to adapt it.
- Design Margin-truncated Difficulty-aware Weighted Asymmetric Loss (MDWA-Loss) focusing more on activated AUs, differentiating difficulty of unactivated AUs, and discarding mislabeled samples.

Main Contributions:
- First to explore PETL paradigm for AU detection and propose AUFormer with MoKE collaboration mechanism.
- Design tailored MoKEs integrating MRF and CA operators to extract multi-scale and correlation knowledge. 
- Propose MDWA-Loss considering properties of AU datasets and difficulty differences among AUs.
- Achieve state-of-the-art performance on BP4D and DISFA from within-domain, cross-domain and data efficiency perspectives without using any additional data.
- Demonstrate effectiveness on micro-expression dataset, a novel evaluation for AU detection methods.

In summary, the paper innovatively investigates PETL for AU detection via a specialized MoKE collaboration mechanism and loss function design, achieving superior performance and robustness.
