# [Can Large Language Models Infer Causation from Correlation?](https://arxiv.org/abs/2306.05836)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: Can large language models infer causation from correlation?Specifically, the paper proposes a novel task called "correlation-to-causation inference" (Corr2Cause) to probe and benchmark the pure causal inference abilities of large language models. The key hypothesis is that current LLMs may not perform well on inferring causality purely from correlational statements, without relying on empirical knowledge.To test this hypothesis, the authors:- Formulate the Corr2Cause task, which takes correlational statements as input and determines the causal relationship between variables. - Create a dataset of over 400K examples following principles from causal discovery research.- Evaluate 17 existing LLMs on this dataset and find they perform poorly, close to random guess levels.- Explore finetuning LLMs on this dataset, showing improved performance but lack of out-of-distribution generalization.In summary, the main research question is whether LLMs can perform pure causal inference given only correlational statements. The key finding is that current LLMs lack this reasoning skill, motivating further research into improving LLMs' abilities for causal reasoning. The Corr2Cause dataset provides a valuable benchmark for this line of research.
