# [Can Large Language Models Infer Causation from Correlation?](https://arxiv.org/abs/2306.05836)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: Can large language models infer causation from correlation?Specifically, the paper proposes a novel task called "correlation-to-causation inference" (Corr2Cause) to probe and benchmark the pure causal inference abilities of large language models. The key hypothesis is that current LLMs may not perform well on inferring causality purely from correlational statements, without relying on empirical knowledge.To test this hypothesis, the authors:- Formulate the Corr2Cause task, which takes correlational statements as input and determines the causal relationship between variables. - Create a dataset of over 400K examples following principles from causal discovery research.- Evaluate 17 existing LLMs on this dataset and find they perform poorly, close to random guess levels.- Explore finetuning LLMs on this dataset, showing improved performance but lack of out-of-distribution generalization.In summary, the main research question is whether LLMs can perform pure causal inference given only correlational statements. The key finding is that current LLMs lack this reasoning skill, motivating further research into improving LLMs' abilities for causal reasoning. The Corr2Cause dataset provides a valuable benchmark for this line of research.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a new task and dataset to test the pure causal inference abilities of large language models (LLMs). Specifically:- The paper formulates a novel task called "correlation-to-causation inference" (Corr2Cause), which involves inferring causality purely from correlational statements, without relying on empirical knowledge. - The authors compose a large-scale dataset with over 400K examples for this task, using insights from causal discovery research to systematically generate correlation statements and causal hypotheses.- The paper evaluates 17 existing LLMs on this dataset and shows they perform poorly, close to random guess levels. This demonstrates a key limitation of current LLMs' reasoning abilities.- The authors further explore whether LLMs can learn this skill by finetuning on the dataset. Finetuned models achieve high accuracy on the original test set but fail to generalize to out-of-distribution perturbations of the test set.- This is the first benchmark dataset and set of experiments probing the pure causal inference abilities of LLMs. The authors argue this is an important reasoning skill for LLMs to have and that their dataset can motivate further research to improve LLMs in this aspect.In summary, the key contribution is proposing a new task and dataset to measure and improve LLMs' skills at inferring causality purely from correlational data/statements, without relying on empirical knowledge. This tests an important aspect of reasoning that is currently limited in LLMs.
