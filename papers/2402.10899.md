# [Taxonomy-based CheckList for Large Language Model Evaluation](https://arxiv.org/abs/2402.10899)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
As large language models (LLMs) are being used in many downstream tasks, their internal stereotypical representations may affect the fairness of the outputs. However, existing methods for evaluating bias in LLMs have limitations in terms of probing "deeper" into the models' biased behaviors. 

Proposed Solution:
The authors propose a taxonomy-based checklist framework to evaluate LLMs' biased behaviors in a question-answering setting. The key ideas are:

1) Introduce human knowledge taxonomies as additional context to allow "deeper" probing of biases, inspired by chain-of-thought prompting. 

2) Design a checklist consisting of different question types to evaluate models from four aspects: consistency, biased tendency, model preference, gender preference switch.

3) Construct a dataset covering 62 occupations with gendered name pairs and corresponding skills/knowledge/abilities drawn from O*NET taxonomy.

4) Evaluate a SQuAD-fine-tuned BERT model and GPT-3.5-turbo on this dataset in a zero-shot setting.

Main Contributions:

- First framework to incorporate human knowledge taxonomies for evaluating QA model biases

- A new checklist-style dataset for comparative evaluation of transformer QA models and LLMs

- An analysis showing BERT exhibits high gender bias that correlates with its consistency, while GPT-3.5 shows lower bias but inconsistent stereotypical preferences

- The framework and dataset can assist future efforts in discovering and mitigating biases in LLMs.

Limitations include binary gender view, potential Western-centric taxonomy, and need to evaluate more diverse models.
