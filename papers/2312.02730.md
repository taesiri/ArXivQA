# [Towards Measuring Representational Similarity of Large Language Models](https://arxiv.org/abs/2312.02730)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper explores measuring the representational similarity of large language models (LLMs) to better understand differences between models beyond just architectures and benchmark performances. The authors focus on studying similarity of representations in the last layer, as this implies functional similarity in outputs while also providing insight into how models generate those outputs. Using a set of 11 freely available 7B parameter LLM models, the authors apply several representational similarity measures on two datasets - Winogrande for commonsense reasoning and HumanEval for code generation. The results reveal significant differences between some models, suggesting representations are not universal across current LLM models. This limits the generalizability of studies on individual models. The analysis also uncovers discrepancies between similarity measures, highlighting the need to use multiple measures to avoid false conclusions. Additionally, similarity patterns differ substantially between the two datasets, emphasizing that similarity claims are application-dependent. Overall, this preliminary analysis identifies representational differences between LLMs as well as challenges that need to be addressed to reliably compare LLMs. The findings motivate further research to better understand model similarities and differences across a broader range of models, tasks, and methods.
