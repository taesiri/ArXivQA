# [Training Data Protection with Compositional Diffusion Models](https://arxiv.org/abs/2308.01937)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we train diffusion models on disjoint datasets and compose them to match the performance of a model trained on their union, while enabling various forms of data protection?The key ideas and contributions are:- Deriving a closed-form expression to compose the reverse flows of diffusion models trained on disjoint data distributions. This allows generating samples by combining models without loss of performance.- Using prompt tuning to efficiently train compartmentalized diffusion models, avoiding the need to train separate full models. - Demonstrating selective forgetting, continual learning, and differential privacy via compartmentalization.- Quantifying the contribution of individual data sources to generated samples.- Empirically showing that the compartmentalized model can match the performance of a model trained on the combined data, owing to the diffusion modeling objective and use of a safe training set.So in summary, the paper introduces compartmentalized diffusion models as a way to decompose diffusion models into components that can be composed to enable various forms of data protection and attribution, while maintaining generative performance.


## What is the main contribution of this paper?

The main contribution of this paper is introducing Compartmentalized Diffusion Models (CDMs). CDMs allow training different diffusion models (or prompts) on distinct data sources and arbitrarily composing them at inference time. The key benefits highlighted are:- Models can be trained in isolation on different distributions and domains and later combined to match performance of a model trained on all data simultaneously. This enables collaborative training without sharing raw data.- Each model only contains information about the data it was trained on. This enables selective forgetting of training data, continual learning as new data is acquired, and serving customized models based on user access rights. - The method allows attributing the contribution of different training data sources to generating a particular sample.The key technical contribution is deriving a closed-form expression to compose diffusion models trained on different distributions into a mixture model. This relies on a weighting scheme that gives higher weight to models more likely to have generated the current sample based on the diffusion timestep.The proposed method is simple to implement via prompt tuning of a shared backbone diffusion model. Empirical results demonstrate the effectiveness on conditional and unconditional image generation tasks while enabling the above applications related to data privacy and attribution.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper introduces Compartmentalized Diffusion Models (CDMs) which allow training separate diffusion models on distinct data sources that can later be composited together to match the performance of a model trained on all data jointly, enabling selective forgetting, continual learning, and determining data contribution in diffusion models.
