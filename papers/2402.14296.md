# [Mitigating Biases of Large Language Models in Stance Detection with   Calibration](https://arxiv.org/abs/2402.14296)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like ChatGPT achieve good performance on many NLP tasks but have biases on the stance detection task. Specifically, LLMs exhibit two main types of biases:
  1) Sentiment-stance spurious correlations: Sentiment expressed in the text misleads the judgment of stance towards a target. 
  2) Target preference biases: Biased stance judgments for certain targets/individuals/topics.
- Existing debiasing methods have limitations when applied to LLMs as they require retraining or modifying the input in ways that disrupt the LLM's reasoning abilities.

Proposed Solution:  
- A new framework called MB-Cal (Mitigating Biases of LLMs in stance detection with Calibration) with two main components:
  1) Gated calibration network: Controls the contribution of causal vs non-causal reasoning from the LLM to make an unbiased stance prediction.
  2) Counterfactual data augmentation: Constructs additional training samples to enhance the calibration network's ability to rectify stance biases.

Main Contributions:
- First work to analyze and categorize biases of LLMs in stance detection. Proposes metrics to quantify the biases.
- MB-Cal framework to mitigate LLM biases on stance detection without needing to retrain the LLM.
- Experiments show MB-Cal reduces LLM biases on stance detection and achieves state-of-the-art performance on in-target and zero-shot stance detection benchmarks.

In summary, this paper identifies and analyzes the biases of LLMs in stance detection, and proposes a practical calibration framework to mitigate those biases and improve stance detection performance.
