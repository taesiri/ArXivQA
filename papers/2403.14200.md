# [Debiasing surgeon: fantastic weights and how to find them](https://arxiv.org/abs/2403.14200)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Algorithmic biases and over-reliance on spurious correlations are a concerning issue with deep learning models. This can lead to unfair and unsafe models when deployed in the real world.

- Most debiasing approaches require complex retraining procedures and hyperparameter tuning which have high computational costs. It is unclear if this complexity is necessary. 

- An open question is whether vanilla trained models already contain "unbiased subnetworks" that can solve tasks without relying on biases. If so, these could potentially be extracted without expensive retraining.

Proposed Solution:
- The paper proposes a method called "Finding Fantastic Weights" (FFW) to extract unbiased subnetworks from vanilla trained models, without any retraining. 

- FFW involves attaching a "privacy head" to estimate upper bound on bias information propagation to the task head. It then learns a mask on the weights to filter this.

- Two variants are proposed - unstructured (prunes individual weights) and structured (prunes neuron outputs) to remove bias information.

- A theory is provided linking bias reliance, its removal and impact on task performance. Removing bias does not always improve performance.

Contributions:
- First parameter selection strategy to extract unbiased subnetworks from vanilla models without retraining.

- Demonstrates existence of unbiased subnetworks in common benchmark datasets. Comparable performance to state-of-the-art debiasing methods.

- Shows later stages of vanilla training learns non-biased features, suggesting debiasing may not need complex training.

- Links between bias reliance and task performance. Performance may drop if bias features inherently needed for task.

- Opens path for more efficient debiasing methods without needing to retrain models.
