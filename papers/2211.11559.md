# Visual Programming: Compositional visual reasoning without training

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is that large language models can be used to convert natural language instructions into modular and interpretable visual programs, allowing complex visual tasks to be solved without task-specific training. The key ideas are:- Complex visual tasks can be decomposed into simpler steps by generating a visual program from natural language instructions using large language models. - The visual program invokes specialized modules (neural and non-neural) to execute each step. This allows incorporating symbolic reasoning and avoids end-to-end training.- The modular and step-by-step nature makes the model more interpretable. The visual rationale summarizes intermediate outputs at each step.- The flexibility of this approach is shown by applying it to diverse tasks like visual QA, visual reasoning on image pairs, knowledge tagging, and image editing without any task-specific training.So in summary, the central hypothesis is that large language models can generate interpretable and modular visual programs from natural language to solve complex visual tasks without traditional supervised training. The results on diverse tasks support this hypothesis.
