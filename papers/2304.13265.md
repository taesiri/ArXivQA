# [StepFormer: Self-supervised Step Discovery and Localization in   Instructional Videos](https://arxiv.org/abs/2304.13265)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research question seems to be: 

How can we develop a self-supervised model to discover and localize key instructional steps in long, untrimmed instructional videos, without relying on any human annotations or video-level labels during training?

The key points are:

- The goal is to develop a model for key-step discovery and localization in instructional videos. 

- The model should be trained in a completely self-supervised manner, without any human annotations or video-level labels.

- It should handle long, untrimmed instructional videos, where only a small portion may be relevant to the actual steps.

- The model should both discover the steps (i.e. determine what they are) and also temporally localize them in the video.

The main hypothesis seems to be that it is possible to train such a self-supervised model by extracting verb phrases from automatically generated video subtitles and using sequence-to-sequence alignment techniques to match steps and narrations. The proposed StepFormer model aims to demonstrate this capability.

In summary, the key research question is around developing an unsupervised model for instructional video understanding that can discover and localize steps without any human supervision, just using narrations. StepFormer is proposed as a solution.
