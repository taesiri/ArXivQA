# [Stability and Multigroup Fairness in Ranking with Uncertain Predictions](https://arxiv.org/abs/2402.09326)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
The paper considers the problem of deriving rankings from machine learning predictors that output probability distributions over classes rather than deterministic predictions. When predictions have inherent uncertainty, it is unclear how to best convert them into rankings in a way that is fair, stable, and preserves the uncertainty information. 

The authors argue that the following properties are important for a ranking function that maps predictions to rankings:

- Anonymity: Treat all individuals symmetrically, without using identity information
- Stability: Small changes in predicted class probabilities should only induce small changes in rankings 
- Fairness: Composition with an individually fair predictor should result in fair rankings

Key Results

- The authors show that stability composes gracefully with individual fairness - if the predictor satisfies individual fairness and the ranking function is stable, the composition also satisfies a natural notion of individual fairness. This motivates desiring stability.

- They prove that no non-trivial deterministic ranking can be stable or anonymous. Hence randomness is necessary for stability and anonymity.

- They demonstrate that the uncertainty aware (UA) ranking function, which randomly orders individuals by sampling possible classifications based on predicted class probabilities, is anonymous and stable.

- A key theorem shows that UA ranking provably preserves statistical notions of multiaccuracy and multicalibration. That is, if the predictor outputs unbiased estimates over groups of individuals, then the induced UA ranking also remains unbiased over those groups in a natural sense.

- Through the choice of which groups to enforce multiaccuracy/multicalibration over, UA ranking effectively interpolates between individual and group fairness at the granularity specified by the predictor accuracy guarantees.

- Experiments on real data corroborate the stability guarantees and demonstrate that UA rankings can achieve reasonable utility compared to baselines.

In summary, the paper establishes uncertainty aware rankings as a principled approach to handle uncertainty in machine learning predictors, with strong fairness and stability guarantees. The rankings provably interpolate between individual and group fairness notions while preserving information about uncertainty.
