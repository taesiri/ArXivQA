# [A Tensor Network Implementation of Multi Agent Reinforcement Learning](https://arxiv.org/abs/2401.03896)

## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions I would ask about the method proposed in this paper:

1. I notice you are mapping individual glyphs to Unicode characters. What was the rationale behind choosing Unicode as the target encoding versus something else like ASCII or Latin-1? How does using Unicode impact the flexibility of applying this method to other writing systems?

2. Could you explain more about why you decided to explicitly enumerate the glyph-to-character mappings versus trying to algorithmically generate them? What trade-offs did you consider when making this decision? 

3. You provide mappings for thousands of glyphs. How did you go about compiling this initial mapping list? Did you manually encode some relationships or start from an existing glyph collection? What challenges did you face in terms of missing or inconsistent mappings?

4. The paper mentions supporting variant glyph forms. Does your method handle context-dependent glyph choice as part of those variants? If so, how does the context dependency get encoded? If not, is it possible to extend your approach to support it?

5. You use the term "virtual font" at times. Can you clarify what constitutes a virtual font versus a regular font in your methodology? Are there capabilities unique to virtual fonts that are taken advantage of?

6. Have you considered using your virtual font method for font development tasks like expanding glyph coverage or filling in stylistic variants? What sorts of applications do you envision this approach enabling on the font design side? 

7. The paper states the method is programming language agnostic. Can you comment more on how challenging it would be to port an implementation from one programming language to something entirely different like C vs Python vs Javascript?

8. Can you walk through your approach applied to a non-Latin glyph system like Chinese Hanzi in more detail? Would the steps differ meaningfully from what was described for Latin script?

9. The paper mentions Unicode normalization potentially simplifying some complexity. Can you expand on where normalization helps most? When would relying on normalization make implementing this method more complicated or limited?  

10. What future directions are you considering taking this research? Are there opportunities to apply machine learning to improve the glyph mappings or otherwise enhance the flexibility of the methodology?
