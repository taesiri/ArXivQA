# [ReALM: Reference Resolution As Language Modeling](https://arxiv.org/abs/2403.20329)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key aspects of the paper:

Problem:
- Reference resolution is an important capability for conversational agents to understand context and user requests referencing entities like those seen on-screen or from previous conversation turns. 
- Existing approaches have limitations in scaling to new types of entities, relying on hand-crafted rules, and treating entities independently without considering contextual screen information.
- Large language models (LLMs) have shown promise for end-to-end tasks, but have challenges encoding visual screen context as text.

Proposed Solution:
- Formulate reference resolution as a language modeling problem of selecting relevant entity/entities from a provided set.
- Encode entities from conversational context, on-screen context, and background processes into natural text representations. 
- For on-screen entities, propose a novel textual encoding to represent screen layout and annotate entity locations to retain spatial information.
- Fine-tune an LLM (FLAN-T5) on datasets of varying types of references for the selection task.

Main Contributions:
- Demonstrate how reference resolution can be effectively modeled as a language modeling problem despite non-conversational entities that are not traditionally text-based.
- Propose a first approach to encode on-screen visual context into purely textual representation conducive for LLM understanding.
- Show proposed model outperforms prior reference resolution methods across different reference types and datasets. Smallest model achieves over 5% absolute gains on on-screen dataset.
- Benchmark against GPT models, with smallest proposed model achieving comparable performance to GPT-4, and larger proposed models substantially outperforming it.

In summary, the paper presents a novel method to convert reference resolution into a language modeling task, including a new textual screen encoding approach, to allow LLMs to effectively perform this capability even with non-conversational entities. Experiments demonstrate strong improvements over prior specialized models.
