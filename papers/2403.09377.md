# [Introducing Routing Functions to Vision-Language Parameter-Efficient   Fine-Tuning with Low-Rank Bottlenecks](https://arxiv.org/abs/2403.09377)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Mainstream parameter-efficient fine-tuning (PEFT) methods like LoRA and Adapter use a low-rank bottleneck to compress and update part of a pre-trained model for downstream tasks. However, for vision-language (VL) downstream tasks, simply compressing the features may not effectively balance and align the information from the two modalities in the low-rank space. Hence, there is a need to better route the multimodal features through the bottleneck to learn cross-modal alignments.

Proposed Solution: 
The paper proposes routing functions for the low-rank bottleneck in PEFT methods to enhance vision-language alignment. Four types of linear routing functions are introduced: element-wise multiplication/addition and matrix multiplications. They route the down-projected hidden states and visual features in the bottleneck without extra parameters.

Experiments and Results:
Extensive experiments were conducted on VL tasks using encoder-only (RoBERTa), decoder-only (GPT2) and encoder-decoder models (CLIP-BART) with ViT visual encoder. Routing functions consistently improve performance over baseline PEFT by over 20% on VQA and 30% on image captioning. Benefits are shown on both single-task and multi-task settings. Comparisons to cross-attention also demonstrate that routing functions achieve better performance with fewer parameters. 

Main Contributions:
1) Identify issues with standard PEFT bottlenecks for VL fine-tuning 
2) Introduce routing functions to enhance VL alignment in the bottlenecks
3) Demonstrate significant gains across models and tasks; provide insights on using routing functions for VL PEFT

In summary, this paper makes important contributions in improving vision-language parameter-efficient fine-tuning by proposing and demonstrating the efficacy of routing functions for the low-rank bottlenecks.
