# [Fine-grained Controllable Video Generation via Object Appearance and   Context](https://arxiv.org/abs/2312.02919)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes FACTOR, a method for fine-grained controllable video generation that allows users to precisely control object appearances and context in generated videos. The key idea is to augment existing text-to-video models with additional control signals specifying object trajectories drawn by users and reference images defining object appearances. Specifically, FACTOR introduces a joint encoder to model interactions between text prompts and control signals, as well as adaptive cross-attention layers that are inserted into the text-to-video model to enable controllability. A key advantage is that FACTOR achieves controllable video generation without needing per-subject finetuning or optimization at test time. Extensive experiments on MSR-VTT and user studies validate that FACTOR significantly improves controllability metrics by 67-73% over baselines, and generates higher-quality videos with better alignment to user-provided object trajectories and appearance references. The method brings an additional benefit of synthesizing more complex videos involving interactions between customized entities. Overall, FACTOR provides an intuitive interface for users to translate creative ideas into customized video content with precision control.
