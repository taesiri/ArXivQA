# [SCAN: Learning to Classify Images without Labels](https://arxiv.org/abs/2005.12320)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: Can we automatically group images into semantically meaningful clusters when ground-truth annotations are absent?The paper is investigating unsupervised image classification, where the goal is to cluster images into groups corresponding to semantic classes, without having access to label information during training. The key hypothesis appears to be that separating feature learning (through self-supervised pretext tasks) from clustering (through a novel loss function) will lead to better semantic clustering compared to recent end-to-end approaches.Specifically, the paper hypothesizes that:- Using a self-supervised pretext task to obtain semantically meaningful features provides a better prior for clustering compared to relying on the network architecture. - Integrating semantic nearest neighbors from the pretext task into a custom clustering loss avoids issues like dependence on low-level features or cluster degeneracy.- Decoupling feature learning and clustering in a two-step approach is better than end-to-end learning for unsupervised semantic clustering.In summary, the main research question is how to perform unsupervised semantic clustering of images, with the key hypothesis being that a two-step approach separating feature learning and clustering will outperform recent end-to-end methods.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper appear to be:- Proposing a two-step approach for unsupervised image classification that first learns semantic feature representations using a self-supervised pretext task, and then clusters the images using those features. This is in contrast to recent end-to-end approaches.- Using the nearest neighbors in the learned feature space as a prior for clustering. The paper shows both empirically and analytically that nearest neighbors tend to belong to the same semantic class. - Introducing a loss function that classifies an image and its nearest neighbors together by maximizing their dot product after softmax. This enforces consistent and discriminative cluster assignments.- A self-labeling step to further refine the clusters using the most confident predictions as pseudo-labels. This allows correcting mistakes from noisy nearest neighbors.- Demonstrating strong performance of the proposed approach, dubbed SCAN (Semantic Clustering by Adopting Nearest neighbors), on CIFAR10, CIFAR100, STL10, and ImageNet datasets. SCAN outperforms prior unsupervised methods by large margins, achieving 26.6% higher accuracy on CIFAR10 for instance.- Showing that SCAN can scale to large datasets like ImageNet. It is the first unsupervised method to perform well on ImageNet, even outperforming some semi-supervised approaches.In summary, the key contribution is a novel and effective framework for unsupervised image classification, justified both theoretically and empirically, that decouples feature learning from clustering. The results significantly advance the state-of-the-art in this direction.
