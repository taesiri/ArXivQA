# [Contrastive Chain-of-Thought Prompting](https://arxiv.org/abs/2311.09277)

## Summarize the paper in one sentence.

 The paper proposes contrastive chain-of-thought prompting, which provides both valid and invalid reasoning demonstrations, to enhance language model reasoning ability.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the paper:

The paper proposes a new method called contrastive chain-of-thought prompting to improve reasoning skills in large language models. Chain-of-thought prompting guides models to solve problems step-by-step using demonstrations of reasoning chains. However, previous work found minimal impact from using invalid reasoning chains as demonstrations. The authors hypothesize that providing both valid and invalid reasoning chains in a contrastive manner can enhance learning. Their preliminary study on arithmetic and factual QA datasets confirms this, with models performing better when given contrastive demonstrations. To improve generalization, they propose an automatic method to construct contrastive demonstrations by shuffling entities in valid chains. Experiments on multiple reasoning tasks show consistent and significant gains over conventional chain-of-thought prompting. The authors conclude that contrastive chain-of-thought serves as a general enhancement by reducing reasoning errors through learning from both positive and negative examples.


## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality one-paragraph summary of the key points in the paper:

The paper proposes a new method called contrastive chain-of-thought (CoT) prompting to enhance the reasoning ability of large language models (LLMs). CoT prompting guides models to solve problems step-by-step using demonstrations of reasoning chains. However, conventional CoT does not indicate common reasoning mistakes to avoid. This paper introduces contrastive CoT which provides LLMs with both valid and invalid reasoning demonstrations in a contrastive manner. Through a preliminary study, the authors find that contrastive demonstrations with incoherent intermediate steps boost performance. To automate contrastive CoT, the authors propose constructing invalid demonstrations by shuffling intermediate objects in valid chains. Experiments on arithmetic and factual QA datasets show consistent and significant gains over regular CoT prompting. The gains are further amplified when combined with self-consistency decoding. Overall, contrastive CoT is shown to be an effective general enhancement for CoT prompting that reduces reasoning errors in LLMs. The simple automatic construction also improves generalization across tasks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes contrastive chain-of-thought prompting, which provides language models with both valid and invalid reasoning demonstrations in a contrastive manner, in order to enhance their reasoning abilities.


## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is: Can invalid reasoning demonstrations be used to enhance chain of thought prompting for language models? 

Specifically, the authors aim to investigate whether providing both valid and invalid reasoning demonstrations in a "contrastive" manner can improve the reasoning abilities of language models over just using valid demonstrations alone. The key hypothesis is that exposing models to both correct and incorrect reasoning chains will allow them to better learn how to perform logical reasoning tasks.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing contrastive chain-of-thought prompting to enhance reasoning in language models. Specifically:

- They conduct a preliminary study analyzing the effect of using invalid/negative reasoning demonstrations together with valid demonstrations in a contrastive manner. The results show this can improve reasoning performance over just using valid demonstrations. 

- Based on this finding, they propose the contrastive chain-of-thought method which provides both valid and invalid reasoning steps as demonstrations to the model. This guides the model to generate more accurate reasoning while avoiding common mistakes.

- To improve generalization, they propose an automatic method to construct contrastive demonstrations by extracting entities from valid rationales and shuffling them to create incoherent rationales.

- Experiments on multiple reasoning datasets show consistent and significant gains compared to conventional chain-of-thought prompting, demonstrating it is an effective general enhancement.

In summary, the key contribution is proposing contrastive chain-of-thought prompting and showing it can serve as a general way to improve reasoning performance in language models by providing both positive and negative reasoning demonstrations.
