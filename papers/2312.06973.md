# [Anytime Approximate Formal Feature Attribution](https://arxiv.org/abs/2312.06973)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality summary paragraph of the key points from the paper:

This paper tackles the problem of efficiently approximating formal feature attribution (FFA), which defines the importance of a feature as the fraction of abductive explanations (AXp's) containing that feature. While FFA has an intuitive appeal, actually computing FFA values is challenging since it requires counting large sets of AXp's. The paper first shows that determining FFA is intractable even when given all contrastive explanations (CXp's), by proving the problem is \#P-hard. To enable anytime approximation of FFA, the paper proposes an efficient heuristic that starts by enumerating CXp's and generating AXp's as a side effect due to their hitting set duality, but then adaptively switches to directly enumerating AXp's once the rate of discovering new AXp's drops during CXp enumeration. This adaptive switching approach combines the strength of using CXp enumeration to initially get good FFA approximations, with the faster completion of full AXp enumeration. Experiments on image and text datasets demonstrate the effectiveness of the proposed method in approximating FFA over time, consistently replicating the performance of the better-performing MARCO variant and outperforming both MARCO configurations in some metrics.


## Summarize the paper in one sentence.

 This paper proposes an anytime approach to efficiently approximate formal feature attribution by dynamically switching between abductive and contrastive explanation enumeration based on the relative sizes and growth rates of the explanations.


## What is the main contribution of this paper?

 According to the abstract, the main contributions of this paper are:

1. It gives evidence that computing formal feature attribution (FFA) is intractable, even if the set of contrastive formal explanations (CXp's) is provided, by proving that the problem is \#P-hard. 

2. It proposes an efficient heuristic to switch from CXp enumeration to AXp enumeration on-the-fly, resulting in an adaptive explanation enumeration algorithm that effectively approximates FFA in an anytime fashion.

3. It presents experimental results on a range of datasets demonstrating the effectiveness of the proposed FFA approximation approach in terms of:
- The error of FFA approximation  
- The number of explanations computed 
- The diversity of explanations given a fixed time limit

In summary, the main contribution is an anytime algorithm that adaptively switches between CXp and AXp enumeration to efficiently approximate formal feature attribution. Both theoretical and empirical evidence is provided to demonstrate the effectiveness of this approach.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts include:

- Formal feature attribution (FFA) - A crisp definition of feature importance based on the proportion of abductive explanations (AXp's) containing a given feature.

- Abductive explanations (AXp's) - A minimal set of features that guarantees the same classification decision. 

- Contrastive explanations (CXp's) - A minimal set of features where changing one feature may change the classification.

- Hitting set duality - The minimal hitting set relationship between AXp's and CXp's that allows switching between them.

- Anytime approximation - Efficiently approximating FFA over time with no predefined limit. 

- Adaptive explanation enumeration - Starting with CXp enumeration and adaptively switching to AXp enumeration based on simple heuristics.

- \#P-hardness - Showing computing FFA from CXp's alone is intractable.

- Error metrics - Including Manhattan distance of FFA values, Kendall's Tau and rank-biased overlap for feature rankings, and KL divergence for feature distributions.

So in summary, the key focus is on anytime approximation of the formally defined FFA concept, using an adaptive approach exploiting the duality between two types of formal explanations, AXp's and CXp's.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes an anytime approach to computing approximate FFA. What are the key ideas behind this approach and why is it useful compared to computing the exact FFA?

2. The paper shows that determining FFA from a given set of CXps is #P-hard. Intuitively explain why this problem is so difficult even when given the CXps. 

3. Explain the two heuristic conditions proposed in the paper for deciding when to switch between CXp and AXp enumeration. What is the rationale behind each condition?

4. The proposed approach starts by enumerating CXps and switches to enumerating AXps later on. Why is enumerating CXps beneficial early on and enumerating AXps better later for approximating FFA?

5. How does the paper experimentally show that the proposed approach replicates the "best of both worlds" of CXp vs AXp enumeration? What metrics are used to demonstrate this?

6. What SAT-based technique does the paper use to allow seamless switching between CXp and AXp enumeration? Why is this important? 

7. The paper finds that directly enumerating AXps leads to faster completion than enumerating CXps. Yet initially enumerating CXps gives better FFA approximation. Explain this paradoxical finding.  

8. How exactly does the proposed approach avoid reproducing the inferior performance between AXp vs CXp enumeration, as shown experimentally?

9. The experiments show the proposed approach outperforms competitors on KL divergence. What does this indicate about the quality of the approximate FFA distribution?

10. The paper claims the proposed technique can be adapted to other problems involving hitting set duality, such as for MUS/MCS enumeration. Explain how the key ideas could carry over.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Explainable AI (XAI) is important for understanding and trusting AI systems. A key explainability question is: what features contributed to a particular decision? 
- Existing XAI methods like approximating Shapley values have issues. Formal feature attribution (FFA) defines feature importance as the fraction of formal abductive explanations (AXp's) containing that feature. This crisply measures importance from the model's behavior. 
- However, computing FFA by counting AXp's is challenging. Prior work approximates FFA via implicit hitting set enumeration using AXp-CXp duality, but has limitations.

Proposed Solution:
- The paper first proves counting AXp's for FFA is #P-hard, even given all CXp's.
- It then proposes an efficient "anytime" approach: start by enumerating CXp's and switch to enumerating AXp's when CXp rate drops, approximating FFA.
- Two criteria are used to trigger the switch: when average AXp size is much bigger than CXp size, and when new CXp size stabilizes.

Contributions:
- Proves computing exact FFA given CXp's is #P-hard. 
- Develops adaptive algorithm for effectively approximating FFA by switching CXp to AXp enumeration.
- Shows strong experimental results on accuracy and efficiency of FFA approximation over time on image and text datasets.

In summary, the paper formally shows hardness of exact FFA computation, and contributes an anytime enumeration approach that adaptively switches to efficiently approximate FFA to a high quality. Experiments demonstrate its effectiveness across different metrics and datasets.
