# [Vision Transformers Need Registers](https://arxiv.org/abs/2309.16588)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be:How can we alleviate artifacts and improve the quality of feature maps in vision transformer models, both supervised and self-supervised?The key hypotheses proposed in the paper are:1) Modern vision transformers exhibit "outlier" tokens during inference that correspond to artifacts in feature maps and attention maps.2) These outliers appear because the model is repurposing redundant/uninformative patches to store and process global information. 3) Explicitly providing the model with additional "register" tokens as buffers will isolate this behavior and avoid collateral side effects like loss of local information in the patch tokens.4) Adding registers will remove artifacts, smooth feature maps, improve performance on dense prediction tasks, and enable methods like unsupervised object discovery.So in summary, the main research question is how to improve feature maps in vision transformers, and the central hypothesis is that providing register tokens can isolate the model's behavior of recycling redundant patches, avoiding artifacts and improving representation quality. The paper aims to demonstrate and validate these hypotheses through quantitative and qualitative experiments.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Identifying and characterizing artifacts in the feature maps of supervised and self-supervised vision transformers, in the form of high-norm "outlier" tokens appearing primarily in background regions of images. - Proposing an interpretation that models are recycling redundant tokens to store and process global image information during inference.- Validating this interpretation by showing that the outlier tokens contain less local patch information but more global image information compared to normal tokens.- Demonstrating that simply appending additional "register" tokens to the input sequence fixes the artifact problem by providing dedicated tokens for the model to use for internal computations. - Showing that fixing the artifacts with register tokens improves performance on dense prediction tasks, enables usage with object discovery methods, and results in smoother and more interpretable feature maps and attention maps.So in summary, the main contribution appears to be identifying artifacts in vision transformers and proposing a simple and effective solution via register tokens to mitigate the artifacts, which improves model interpretability and performance on certain downstream tasks.


## How does this paper compare to other research in the same field?

Based on the abstract, this paper seems to make several contributions to the field of vision transformers and self-supervised learning:- It identifies and characterizes artifacts in the feature maps of vision transformers, including both supervised models like DeiT-III and self-supervised models like DINOv2. The artifacts manifest as high-norm outlier tokens that contain less local image information. - It proposes that these artifacts arise because transformers learn to discard less informative patches and repurpose them to aggregate global information. This provides an interesting analysis into the inner workings of vision transformers.- It introduces a simple fix of adding "register" tokens to isolate and eliminate this behavior. This removes the artifacts and leads to performance improvements on downstream tasks.- It demonstrates improved performance on dense prediction tasks and enables the use of vision transformers for unsupervised object discovery. Compared to prior work, this seems to provide new insights into artifacts and deficiencies in vision transformers, which have not been extensively studied before. The interpretation of the artifacts and proposed register mechanism to mitigate them is novel. The extensive experiments across different training methods (supervised, self-supervised) help validate the generality of the findings. The gains on dense prediction and object discovery also demonstrate the practical utility of the ideas.Overall, this seems like an insightful study into the representations learned by vision transformers, identifying limitations and proposing techniques to improve them. The analysis and simple yet effective solution helps advance the understanding and performance of this increasingly important class of models.


## What future research directions do the authors suggest?

Based on my reading of the paper, some key future research directions suggested by the authors include:- Developing methods to better regularize and control the behavior of the proposed register tokens. The authors note that the registers exhibit some natural diversity in their learned attention patterns, but do not enforce any specific behavior. They suggest further study on how to potentially regularize or control the roles/behaviors of the registers.- Exploring different configurations and numbers of register tokens. The authors experimentally vary the number of registers and find a trade-off between removing artifacts and downstream performance. They suggest further exploration of optimal register configurations. - Applying registers in other self-supervised, supervised, and generative models. The authors demonstrate registers improve several standard self-supervised and supervised models. They suggest expanding studies to other models like MAE, BEiT, etc.- Understanding the core training dynamics that lead to artifacts arising in the first place. While registers mitigate artifacts, the root causes of their emergence remain unclear. Further analysis of training dynamics could shed light.- Developing alternative solutions to the artifact problem registers solve. The register solution is effective but simple - the authors suggest exploring other potential solutions.- Testing the impact of registers on additional dense prediction tasks. The authors show improved performance on semantic segmentation and depth estimation. More comprehensive benchmarking on dense predictions could be beneficial.In summary, the main future directions focus on better understanding registers, exploring their applications in other models, analyzing the root causes of artifacts, and developing new solutions. Broadening evaluation and testing on more tasks is also suggested.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper identifies and characterizes artifacts, corresponding to high-norm tokens, that appear in the feature maps of supervised and self-supervised vision transformers, primarily in low-informative background areas during inference. The authors propose that the model learns to recognize redundant patches, discards their information, and repurposes the tokens to aggregate global image information. They hypothesize that providing additional 'register' tokens allows the model to isolate this behavior and avoid the artifacts. Experiments adding register tokens show the artifacts disappear, performance on dense prediction tasks increases, feature maps become smoother, and object discovery methods become more effective with the updated models. Overall, the paper demonstrates how providing extra register tokens can fix artifacts, enable object discovery, and lead to performance gains by giving vision transformers dedicated locations to store and retrieve global information during inference.
