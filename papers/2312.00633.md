# [Towards Efficient 3D Object Detection in Bird's-Eye-View Space for   Autonomous Driving: A Convolutional-Only Approach](https://arxiv.org/abs/2312.00633)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality summary paragraph of the key points from the paper:

This paper proposes BEVENet, an efficient 3D object detection framework for autonomous driving that operates in the bird's-eye view (BEV) space. Unlike most existing BEV detection methods that rely on vision transformers, BEVENet adopts a convolutional neural network (CNN) based architecture for computational efficiency and real-world deployment capability. BEVENet utilizes only RGB images from six surrounding-view cameras and achieves an inference speed of 47.6 FPS on a 704x256 image resolution with mAP of 0.456 and NDS of 0.555 on the challenging NuScenes dataset. This represents nearly 3x speedup compared to prior state-of-the-art while maintaining competitive accuracy. The authors systematically analyze major components of the 3D detection pipeline including backbone, view projection, depth estimation, temporal fusion, BEV encoder and detection head modules. Through extensive experiments, they identify optimal architectures to balance accuracy versus efficiency, such as ElanNet backbone with residual blocks, LSS view projection with lookup tables, convolutional depth estimator, 2-second temporal fusion, and a simplified detection head. As the first work to focus specifically on efficiency for real-world BEV methods, BEVENet demonstrates the feasibility of deploying such techniques effectively on autonomous vehicles with limited compute resources.
