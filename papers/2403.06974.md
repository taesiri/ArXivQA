# [Memory-based Adapters for Online 3D Scene Perception](https://arxiv.org/abs/2403.06974)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem Statement:
Existing 3D scene perception methods are either designed for offline settings, where a full 3D reconstruction of the scene is provided as input, or for single-view perception on individual frames. However, in many robotics applications like navigation and manipulation, the input is a streaming RGB-D video where data is collected and scene perception needs to be performed simultaneously in an online manner over the video frames. Hence, there is a need for online 3D scene perception methods that can effectively model the temporal relations across video frames.

Proposed Solution: 
The authors propose a general framework to empower existing offline 3D perception models for online setting by adding plug-and-play memory-based adapters. Specifically, they introduce:

1) Point cloud adapter: Caches point cloud features extracted by the backbone in a queued voxel grid memory over time. It then enhances current frame features using a 3D convolutional network over the neighbor voxel features from memory.

2) Image adapter: Stores a proportion of channels from current image features into memory, replaces those channels with previous memory, and refines with 2D conv. 

3) 3D-to-2D adapter: Projects 3D memory to 2D space to provide global context and refine image features.

The adapters can be inserted into common offline architectures like MinkowskiNet, FCAF3D, TD3D etc. and finetuned on RGB-D videos to achieve online temporal modeling.

Main Contributions:
- First framework to empower offline 3D perception models for online setting using modular memory-based adapters
- Point cloud and image adapters to effectively aggregate intra- and inter-modal temporal relations 
- State-of-the-art online performance on semantic segmentation, detection and instance segmentation tasks on ScanNet and SceneNN datasets

The adapters are model-agnostic and bring significant gains over single-view models and offline models adapted for online setting. Hence, this is a valuable contribution towards online 3D perception for robotics.
