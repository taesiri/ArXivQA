# [DREAM: Efficient Dataset Distillation by Representative Matching](https://arxiv.org/abs/2302.14416)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: How can we improve the training efficiency and performance of optimization-based dataset distillation methods?The key hypothesis is that by selectively matching only representative samples from the original dataset during distillation, rather than random samples, both training efficiency and end performance can be improved. Specifically, the paper hypothesizes that:- Randomly selecting samples can result in uneven/biased distributions that lead to unstable optimization.- Matching only representative (evenly distributed, diverse) samples will provide more consistent supervision and avoid optimization instability.- This representative matching strategy will accelerate training convergence and enable higher end accuracy with fewer iterations.The paper proposes a representative matching strategy called DREAM to test this hypothesis and demonstrates improved training efficiency and performance on several benchmark datasets compared to prior state-of-the-art methods.
