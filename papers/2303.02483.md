# [FAME-ViL: Multi-Tasking Vision-Language Model for Heterogeneous Fashion   Tasks](https://arxiv.org/abs/2303.02483)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be:How can we design an efficient multi-task learning model to perform well on diverse heterogeneous vision-language tasks in the fashion domain? The authors identify two main challenges:1) Architecturally, it is non-trivial to design a unified model that can handle the different input/output formats and modes (contrastive, fusion, generative) required by the various fashion tasks. 2) In terms of optimization, a fashion multi-task model is prone to negative transfer due to differences in task formats as well as imbalanced dataset sizes.To address these challenges, the paper proposes FAME-ViL, which consists of:1) A task-versatile architecture built on top of CLIP, with cross-attention adapters (XAA) enabling modality interaction and task-specific adapters (TSA) handling differences between tasks.2) An efficient multi-task training strategy with multi-teacher distillation that guides optimization and prevents overfitting on small datasets.The central hypothesis seems to be that by designing a flexible architecture and training procedure, FAME-ViL can effectively multi-task on heterogeneous fashion tasks, improving parameter efficiency while boosting performance compared to independent single-task models. Experiments on four diverse tasks support this hypothesis.In summary, the main research question is how to develop an efficient yet flexible multi-task learning approach for heterogeneous vision-language tasks in the fashion domain. The paper proposes and evaluates the FAME-ViL model to address this question.
