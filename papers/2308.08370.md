# [Agglomerative Transformer for Human-Object Interaction Detection](https://arxiv.org/abs/2308.08370)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper tries to address is: How can we enable Transformer-based human-object interaction (HOI) detectors to flexibly exploit extra instance-level cues (e.g. pose, gaze) in an efficient, single-stage manner? The key hypotheses appear to be:1) Instance-level cues like human pose and gaze are important for HOI detection, especially for recognizing subtle differences between highly similar interactions. 2) Prior Transformer-based HOI detectors struggle to leverage these cues due to misalignment between local patch tokens and instance-level information.3) By proposing "instance tokens" that dynamically cluster patches into integral instance representations, the authors' method AGER allows efficient incorporation of extra cues in a single-stage Transformer pipeline.In summary, the paper aims to improve HOI detection in Transformers by better aligning representations with full instance context, enabling flexible utilization of extra cues without compromising efficiency or pipeline complexity. The key novelty is the dynamically learned instance tokens aligned to entire object/human extent.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes AGER, a new framework for human-object interaction (HOI) detection that enables Transformer-based detectors to flexibly exploit extra instance-level cues in a single-stage and end-to-end manner. 2. It introduces the concept of instance tokens, which are generated by dynamically clustering patch tokens using a text-guided mechanism. Instance tokens encourage the integrality of instance representations, allowing the flexible extraction of cues like human pose, spatial locations, and object categories.3. AGER achieves new state-of-the-art performance on the HICO-Det dataset, demonstrating the benefits of exploiting extra cues with integral instance tokens in a single-stage pipeline. It reduces GFLOPs by 8.5% and improves FPS by 36% compared to prior Transformer-based methods.4. The proposed text-guided clustering mechanism enables end-to-end training of the instance encoder in AGER, eliminating the need for additional object detectors or instance decoders. 5. AGER provides the first demonstration of incorporating clustering into Transformers for HOI detection, opening up new possibilities for efficient utilization of extra cues in this domain.In summary, the main contribution is the proposal of AGER, a new single-stage Transformer-based framework for HOI detection that leverages integral instance tokens to flexibly exploit extra cues while achieving efficiency gains. The instance tokens are generated via a novel text-guided clustering approach.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes AGER, an agglomerative Transformer that dynamically clusters image patches into instance tokens aligned to object instances, enabling efficient and flexible extraction of instance-level cues like pose and location in a single-stage framework to improve human-object interaction detection.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other research on human-object interaction (HOI) detection:- It proposes a new single-stage Transformer-based framework (AGER) for HOI detection, while most prior work uses two-stage CNN-based models. The single-stage design improves efficiency.- It introduces a new tokenization method through text-guided dynamic clustering to generate "instance tokens" that capture complete instance-level representations. This allows flexible incorporation of extra cues (e.g. pose, location, etc.) in an end-to-end manner. Prior work typically relies on predefined regions from a detector which limits cue integration.- It achieves state-of-the-art results on the HICO-Det benchmark, outperforming prior art by 2-3% mAP. The gains are especially large for rare HOI categories. This demonstrates the benefits of the proposed approach.- It provides the first Transformer HOI detector that can incorporate various instance-level cues in a single network, while maintaining high efficiency. Prior Transformer methods lacked this capability.- The token clustering method is conceptually simple yet effective. It eliminates the need for complex multi-decoder networks or additional object detectors used in other work.- Analysis shows the instance tokens provide more complete instance coverage and better support cue extraction compared to common methods like object queries or detection regions.Overall, this paper pushes Transformer-based HOI detection to a new level through innovations in representation learning and cue integration. The proposed techniques address limitations of prior art and demonstrate improved efficiency, flexibility and performance on this complex visual relationship detection task.


## What future research directions do the authors suggest?

Based on my reading of the paper, some key future research directions suggested by the authors include:- Exploring more flexible and effective ways to incorporate linguistic knowledge into visual models for HOI detection. The authors used a simple strategy of prompting class names to get text representations from CLIP, but suggest exploring more fine-grained textual prompts or jointly training the text encoder could further improve results. - Improving the clustering mechanism to handle small and occluded instances better. The current dynamic clustering struggles with small objects.- Extending the interaction decoder to consider interactiveness or relevance between human-object pairs rather than just enumerating all possible pairs.- Applying the proposed instance tokenization strategy to other vision tasks beyond HOI detection where exploiting integral instance representations could be beneficial.- Evaluating how the approach could generalize to detecting unseen/novel interactions at test time. The current experiments focus on seen HOI categories.- Exploring video HOI detection, since the current method is designed for still images. Extending it to leverage temporal information could be valuable.- Reducing reliance on human pose annotations which can be expensive to scale up. Self-supervised approaches to extract pose cues could help increase applicability.In summary, the main future directions are around improving the incorporation of language/text, better handling small instances, considering relevance of human-object pairs, applying the approach to new tasks and settings like video, and reducing annotation dependence. Overall the authors propose their instance tokenization strategy as a promising research direction for HOI and other vision tasks.


## Summarize the paper in one paragraph.

The paper proposes an agglomerative Transformer (AGER) for human-object interaction detection. AGER performs tokenization as a text-guided dynamic clustering process to generate instance tokens that encourage the integrality of instance-level representations. This allows AGER to flexibly and efficiently incorporate extra instance-level cues like human poses, spatial locations, and object categories in a single-stage pipeline. AGER eliminates the need for an additional object detector or instance decoder as in prior methods. It achieves state-of-the-art performance on HICO-Det with 36.75 mAP while reducing FLOPs by 8.5% and improving FPS by 36% compared to a vanilla Transformer pipeline. The key innovation is the dynamical clustering mechanism for generating expressive instance tokens aligned to arbitrary shaped instances, which ensures extraction of integral instance representations for incorporating useful cues.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:This paper proposes AGER, an Agglomerative Transformer for human-object interaction (HOI) detection. The key idea is to perform tokenization as a dynamic clustering process guided by textual representations. Specifically, the model initializes human and object clustering centers and updates them along with image tokens through a Transformer encoder. By assigning image tokens to centers based on feature affinity, the tokens are clustered into integral instance tokens that cover full object regions. This allows flexible extraction of instance cues like pose, location, and category using lightweight decoders, eliminating the need for an additional object detector. These cues are aggregated to instance tokens for interaction recognition in a decoder. Compared to prior methods, AGER's instance tokens enable single-stage extraction of useful cues lacking in DETR queries, while ensuring efficiency unlike CNN detectors. Experiments show state-of-the-art HOI detection on HICO-Det and V-COCO datasets. AGER reduces FLOPs by 8.5% and improves FPS by 36% versus a vanilla DETR pipeline, with higher gains as image size increases. The clustering mechanism encourages full instance coverage, enabling more accurate cue extraction. Overall, AGER advances single-stage, flexible incorporation of useful cues for HOI detection in Transformers.
