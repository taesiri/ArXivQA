# [Composite Motion Learning with Task Control](https://arxiv.org/abs/2305.03286)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is: How can we train physics-based character controllers to perform composite motions by combining multiple motion clips as reference, while also accomplishing goal-directed tasks?The key points are:- The paper proposes a new approach for training physics-based character controllers to perform composite motions. This means combining partial body motions from multiple reference motion clips into a single full-body motion.- Existing methods rely on having full-body motion capture as reference. This paper aims to synthesize composite motions without needing full-body reference motions.- The approach also incorporates goal-directed control objectives, so the character can accomplish specific tasks while performing the composite motions. - A multi-objective reinforcement learning framework is proposed to balance learning from disparate motion references and task objectives.- An incremental learning scheme is introduced to quickly adapt existing policies to new composite motions by reusing parts of the original motions.In summary, the central research contribution is a new training methodology to create physics-based character controllers capable of composite motions from multiple motion clips and goal-directed control, using multi-objective reinforcement learning.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel approach for physics-based character control that can learn complex composite motions by combining multiple motion clips as reference. The key ideas include:- Decoupling full-body control into learning partial-body motions from different reference sources. This allows combining motions in a modular way without needing pre-blended full-body motions. - Converting the problem into a multi-objective learning framework with a multi-critic architecture. This allows handling the multiple imitation objectives and task goals in a balanced way.- An incremental learning scheme to accelerate training by reusing a pre-trained policy as a meta policy. The new policy cooperates with the meta policy to adapt it for new tasks.In summary, the main contribution is a new framework for physics-based character control that can effectively learn complex composite motions involving multiple imitation sources and task goals. The key novelty is decoupling full-body control and formulating it as a multi-objective learning problem. This provides an automated way to blend motions and balance multiple objectives without tedious manual effort.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:The paper proposes a new framework for training physics-based controllers that enables simulated characters to perform complex, multi-objective behaviors by combining multiple motion clips and task goals.


## How does this paper compare to other research in the same field?

 Here are some key ways this paper compares to other related work in physics-based character control and motion imitation:- The main novelty is in learning composite motions by combining partial-body motions from multiple reference clips, without needing full-body blended motions as input. This is different from prior work that learns either from full-body motion clips or attempts to blend motions before training a policy.- The multi-objective learning framework with multiple critics is novel, allowing the method to effectively balance learning from disparate motion clips and goal-directed rewards. This avoids tricky manual tuning of weights.- Incremental learning by cooperating with a meta-policy is a new way to enable fast adaptation to new tasks. This allows building on top of prior skills rather than always learning from scratch.- The method is demonstrated on a range of complex tasks, including challenging composite motions like chest open + jumping jacks. It also handles complex goal-directed control like tennis swings and juggling while walking.- The approach does not require tracking target poses or carefully designing reward functions for imitation. It uses an adversarial learning approach based on GAIL/GANs as recent methods have, but adapts this for multi-objective learning.- For goal-directed control, the method shows the ability to learn behaviors from varied unstructured motion clips, not just single motions. This provides more flexibility.- Ablations analyze the effects of key components like multi-objective learning and incremental learning. Comparisons to learning without these components demonstrate their benefits.Overall, the work makes nice contributions in terms of enabling new types of complex composite behaviors, goal-directed control from varied data, and faster adaptation to new tasks. The experiments comprehensively demonstrate these capabilities on challenging motor skills.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some future research directions the authors suggest are:- Exploring the potential to add a state machine with state transitions to handle behaviors with multiple phases, since currently the system is not well-equipped to handle behaviors with distinct stages. - Accounting for variation across the humans that recorded the motion clips, to reduce bias in imitation and improve the quality of the final animation. The current system can make adjustments based on the physical characteristics but not stylistic differences.- Developing ways to directly combine preexisting policies at runtime to create new composite activities, rather than needing to perform additional training. This could greatly improve the scalability of trained controllers.- Going beyond the anticipated upper/lower body split for composite motions to allow more fluid combinations of body parts, like a martial artist rapidly changing appendage use. The multi-objective learning framework may provide a foundation for this.- Automating the process of checking composite motion compatibility and feasibility of associated goal-directed tasks, rather than relying completely on human judgement currently.In summary, the main future directions mentioned are: exploring multi-phase behaviors, accounting for human variation, combining policies at runtime, more flexible body part combinations, and automating feasibility checks. The overall goal seems to be improving the flexibility, scalability, and automation of the system.


## Summarize the paper in one paragraph.

 The paper presents a novel framework for training controllers that can synthesize composite full-body motions for physically simulated characters. The key idea is to decouple the imitation learning problem by training the controller to imitate different partial body motions from distinct reference data sources. This converts full-body motion imitation into a multi-objective learning problem. The authors propose a multi-critic architecture and incremental learning scheme to effectively balance and learn multiple potentially competing imitation and task reward objectives. Experiments demonstrate the approach's ability to learn coordinated and natural looking full-body motions by combining partial body motions from different reference clips and accomplishing simultaneous goal-directed tasks. The method avoids needing to manually generate blended full-body motion clips as training data.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:This paper proposes a novel approach for physics-based character control that allows generating composite motions by combining partial body motions from multiple reference data sources. The key idea is to decouple full body motion control into controlling different body part groups independently for imitation learning. This enables synthesizing motions that combine upper body poses from one reference with lower body poses from another, without needing full body composite motions as reference. To achieve this, the method employs a multi-objective reinforcement learning framework with multiple discriminators for evaluating imitation performance of different body parts. This converts the problem into optimizing multiple objectives, including imitation rewards for different body parts as well as optional goal-directed control rewards. An incremental learning scheme is also introduced that allows new composite policies to be trained faster by cooperating with a pre-trained meta-policy network. The method is evaluated on a variety of challenging tasks, including target navigation with combined upper body motions, tennis swings by combining separate footwork and swing motions, and juggling while walking using different reference motions for arms and legs. Results demonstrate the approach can effectively synthesize natural and coordinated full body motions by mixing different partial body motions from unstructured references. The multi-objective training is shown to successfully balance imitating disparate motion examples while still optimizing goal-driven rewards. The incremental learning scheme also substantially reduces training time compared to learning composite policies from scratch.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes a novel framework for physics-based character control that enables learning of composite motions by imitating partial-body motions from multiple reference sources and incorporating task-specific goals. The key idea is to decouple full-body control into multiple objectives corresponding to imitation of different body parts and goal-directed tasks. A multi-critic architecture based on generative adversarial networks and reinforcement learning is used to train policies that can balance learning across these potentially competing objectives. Specifically, each objective has its own critic that provides rewards and value estimates for policy optimization. This converts the problem into a multi-objective optimization that does not require manual tuning of weights or priorities across the different objectives. An incremental learning scheme is also introduced that leverages a pre-trained meta-policy for basic motions (e.g. walking) which can then be adapted quickly through cooperative training to acquire new composite skills (e.g. walking while greeting). This avoids having to learn complex skills completely from scratch.


## What problem or question is the paper addressing?

 The paper is addressing the issue of learning composite motions and behaviors for physically simulated characters. Some key points:- Existing techniques for physics-based character control rely on full-body motion capture data as reference. This makes it difficult to synthesize novel composite behaviors by combining different motions. - The paper proposes a new approach to learn composite motions by training policies to imitate partial-body motions from multiple reference clips. This avoids needing full-body mocap data of the composite behaviors.- They formulate it as a multi-objective learning problem with separate objectives for imitating different partial body motions. This allows balancing and combining disparate motions.- They also incorporate goal-directed tasks as additional objectives, enabling composite motions with simultaneous task goals.- An incremental learning scheme is introduced to fast learn new composite policies by reusing and adapting pretrained policies as meta-policies.In summary, the key idea is learning composite physics-based character control through multi-objective imitation of partial-body motions from multiple clips, while also incorporating goal-directed tasks. This provides more flexibility than prior approaches relying solely on full-body motion capture reference.
