# [MSLM-S2ST: A Multitask Speech Language Model for Textless   Speech-to-Speech Translation with Speaker Style Preservation](https://arxiv.org/abs/2403.12408)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Recently there has been growing interest in speech-to-speech translation (S2ST) models that can translate speech from one language directly to speech in another language. Most prior work relies on textual data or speech-text alignments during training. However, there is a need for S2ST models that can work in a textless setting without relying on text data, as text data may not always be available, especially for low-resource languages. Additionally, prior S2ST models struggle to preserve the vocal style or speaker identity from the source speech in the translated speech.

Proposed Solution:
This paper proposes a novel Multitask Speech Language Model (MSLM) for high-quality textless speech-to-speech translation while preserving speaker style. The key ideas are:

1) Leverage recent advances in learned discrete speech representations from models like HuBERT (for semantic units) and EnCodec (for acoustic units). 

2) Formulate a multitask causal language modeling objective where a single decoder model is trained on two tasks: (a) Semantic-to-semantic translation of source speech units to target speech units  (b) Semantic-to-acoustic generation of target acoustic units conditioned on translated semantic units and source speech encoding to preserve style.

3) Utilize source speech encoding as a style prompt during target acoustic unit generation.

4) Support multiple translation directions in a single model via conditioning on special language tokens.

Main Contributions:

- Proposes a novel and simplified speech LM architecture for high-quality style-preserving S2ST without reliance on text

- Achieves good translation quality and speaker style similarity for English â†” Spanish speech translation

- Shows that a single multitask model can support multiple translation directions, unlike prior work which requires separate models

- Reduces overall parameters needed compared to cascaded LM baselines while preserving quality

Overall, the paper introduces an efficient and high-quality textless multilingual S2ST model with demonstrated speaker style preservation abilities. The simplified model design is more parameter-efficient compared to prior LM-based S2ST approaches.
