# [Symbol tuning improves in-context learning in language models](https://arxiv.org/abs/2305.08298)

## What is the central research question or hypothesis that this paper addresses?

Based on the abstract, the central research question this paper addresses is:Can symbol tuning, which involves finetuning language models on input-label pairs where natural language labels are replaced with arbitrary symbols, improve the ability of language models to learn and reason from few-shot examples presented in-context?The key hypothesis is that symbol tuning, by removing semantic information from labels, forces models to rely more on reasoning over the input-label mappings in the provided examples in order to determine the task, rather than relying on prior knowledge or instructions. This results in models that are more robust learners from small amounts of in-context examples.In summary, the paper explores whether symbol tuning can improve in-context learning in language models by making models focus more on reasoning over input-label mappings rather than leveraging prior knowledge or instructions. The central hypothesis is that symbol tuning will strengthen in-context learning abilities.
