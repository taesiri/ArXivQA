# [Exploring Lightweight Hierarchical Vision Transformers for Efficient   Visual Tracking](https://arxiv.org/abs/2308.06904)

## What is the central research question or hypothesis that this paper addresses?

The central research question is how to develop an efficient visual tracking framework based on lightweight hierarchical vision transformers. Specifically, the key points are:- How to adapt lightweight hierarchical vision transformers like LeViT for visual tracking while maintaining high efficiency. There is a gap between the image classification models and the tracking task.- How to mitigate the information loss caused by the large-stride downsampling in hierarchical networks, which is crucial for tracking. - How to effectively encode the position information of the search region and template image jointly.To address these issues, the main technical contributions proposed in this paper are:- A Bridge Module to fuse multi-stage features from the hierarchical transformer, combining semantic and detailed information.- A dual-image position encoding method to jointly encode the position information of the search and template images.Based on these components, the paper proposes HiT, a family of efficient tracking models that achieve promising performance while maintaining high speeds on different devices. Experiments demonstrate that HiT outperforms previous efficient trackers significantly.In summary, the central hypothesis is that by developing specialized model components like the Bridge Module and dual-image position encoding, lightweight hierarchical vision transformers can be adapted for efficient visual tracking effectively. The experiments validate this hypothesis, showing strong results compared to prior work.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Proposing a Bridge Module that fuses features from different stages of a hierarchical vision transformer. This helps mitigate the information loss caused by large-stride downsampling in the transformer, enabling the use of hierarchical transformers for tracking. 2. Introducing a dual-image position encoding technique that jointly encodes the position information of both the template and search region images. This enhances the interaction between the template and search features.3. Developing HiT, a family of efficient transformer-based tracking models built using the above components. Experiments show HiT achieves state-of-the-art speed and performance compared to previous efficient trackers.4. Providing extensive ablation studies analyzing the effects of different components like the Bridge Module, position encodings, and backbone networks. This provides useful insights into model design choices.In summary, the main contribution is proposing techniques to bridge the gap between lightweight hierarchical vision transformers and visual tracking, resulting in the HiT family of efficient yet accurate trackers. The dual-image position encoding and Bridge Module are key innovations that enable exploiting hierarchical transformers for tracking.
