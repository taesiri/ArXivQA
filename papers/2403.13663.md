# [T-Pixel2Mesh: Combining Global and Local Transformer for 3D Mesh   Generation from a Single Image](https://arxiv.org/abs/2403.13663)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Generating accurate 3D shapes from single view images is challenging. Existing methods often fail to capture detailed local geometry and generalize well to real-world images.

Proposed Solution:
- The paper proposes a novel framework called T-Pixel2Mesh that enhances Pixel2Mesh architecture with a hybrid Transformer-based deformation module to generate 3D meshes from single images.

- It uses a global Transformer to control overall shape and local Transformers to progressively refine local geometry details. 

- It also presents a Linear Scale Search (LSS) method to improve generalization to real-world images by finding optimal scale of objects.

Main Contributions:

- First approach to combine global and local Transformers for mesh generation. Global attention learns to filter less useful features from occluded regions while local attention refines local geometry.

- LSS serves as a simple yet effective prompt tuning method to account for varying intrinsics/distances of real images.

- Achieves state-of-the-art performance on ShapeNet dataset and shows improved generalization capability to real-world images from Pix3D and CO3D datasets.

- Comprehensive experiments demonstrate the effectiveness of different components of the framework.

In summary, the paper presents a novel Transformer-boosted architecture for robust and detailed 3D mesh reconstruction from single images, with capabilities to handle both synthetic and real-world image datasets.
