# [Learning Transformations To Reduce the Geometric Shift in Object   Detection](https://arxiv.org/abs/2301.05496)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to reduce the performance drop of object detectors when there are geometric shifts between the training (source) and test (target) data distributions. 

The key hypothesis is that learning a set of geometric transformations from the unlabeled target data can help bridge this domain gap and improve object detection performance on the target data.

Specifically, the paper proposes modeling geometric transformations as a combination of homographies, and learning an optimal set of homographies in a self-training framework to minimize the geometric shift between source and target. The main hypothesis is that this will make the object detector more robust to different geometric distortions arising from changes in camera intrinsics, viewpoint, etc.

The experiments then validate this hypothesis by showing improved performance on target datasets with different field-of-view and viewpoint compared to only training on the source data. The results support the claim that learning transformations on unlabeled target data is an effective approach to adapting object detectors to geometric shifts across domains.
