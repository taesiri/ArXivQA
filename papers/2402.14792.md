# [Consolidating Attention Features for Multi-view Image Editing](https://arxiv.org/abs/2402.14792)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Consolidating Attention Features for Multi-view Image Editing":

Problem:
- Existing image editing techniques that leverage text-to-image models can successfully edit a single image, but struggle to produce consistent edits when applied to multi-view image sets depicting the same scene. 
- In particular, edits that involve geometric changes like articulations lead to inconsistent results across views.

Proposed Solution:
- Key idea is to encourage the internal attention features of the diffusion model to be consistent during the generation of the multi-view edited images. 
- Specifically, the self-attention queries significantly influence image structure, so consolidating them can improve consistency.
- Propose QNeRF - a neural radiance field trained on the queries extracted from the diffusion model during editing. QNeRF consolidates queries into a 3D-consistent representation.
- Rendered queries from QNeRF are then softly injected back into the diffusion model during editing to guide the features.
- Use a progressive, iterative approach that interleaves consolidation and evolution of queries across diffusion timesteps.

Main Contributions:
- Introduce QNeRF to consolidate attention queries across views by training a NeRF on them.
- Propose a progressive feature consolidation approach via soft query injection.
- Achieve articulation and geometry edits on multi-view sets with higher consistency than prior state-of-the-art.
- Enable training NeRFs on edited views that better align with target geometry.
- Demonstrate qualitative, quantitative and user study results validating improved multi-view consistency over baselines.

In summary, the paper presents a novel way to leverage neural radiance fields to consolidate attention features across views during editing, enabling more consistent multi-view image manipulation, especially for geometric edits.
