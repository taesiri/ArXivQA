# [HD-Eval: Aligning Large Language Model Evaluators Through Hierarchical   Criteria Decomposition](https://arxiv.org/abs/2402.15754)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Existing large language model (LLM) based text evaluators are limited in alignment and coverage due to potential bias in the evaluation prompts and criteria used. They fail to comprehensively capture the complexity and diversity of human evaluation. 

Proposed Solution: The paper proposes HD-Eval, a framework to align LLM-based evaluators with human preference through hierarchical criteria decomposition. It decomposes the evaluation task into multiple layers of criteria, from high-level aspects to more fine-grained metrics. An aggregator is trained to estimate human preference and integrate judgments across criteria layers. Attribution techniques prune insignificant criteria and focus decomposition on more critical ones.  

Key Contributions:
1) Proposes hierarchical criteria decomposition to capture nuanced aspects of evaluation at different granularity, inspired by human evaluation mindsets.
2) Learns a human preference-guided aggregator to produce overall judgments in a more controllable, explainable way than just prompting. 
3) Enables iterative alignment training to obtain finalized criteria hierarchy and aggregator optimized towards human preference.
4) Demonstrates superior performance in aligning state-of-the-art LLM evaluators across summarization, dialog and data-to-text tasks. Provides interpretability into human preferences.

The key novelty is in structuring the criteria space and training process to integrate top-down and bottom-up views of evaluation inspired by human cognition. This contributes to better alignment, efficiency and explainability.
