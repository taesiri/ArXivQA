# [WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents](https://arxiv.org/abs/2404.05902)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Existing web agents fail to generalize across websites due to high variance in structure. Fine-tuning and in-context learning also fail to generalize.
- Memorizing all websites is infeasible, so zero-shot approaches likely to fail. 

Proposed Solution - Wilbur Agent:
- Explore, reflect and backtrack: Faced with novel website, takes action sampled from LLM. Reflection LM verifies if action contributes progress. If fail, backtracks to previous successful state.
- Retrieve demonstrations from scalable knowledge bank: Includes goal-conditioned demos teaching how to perform similar task on potentially unseen website. Also website-conditioned demos teaching how to act on similar web page. 
- Demo ranking model selects most helpful demos to populate prompt. 
- Summarizes demos into concise instructions allowing large number to be included.

Main Contributions:
- First web agent that can recover from delayed mistakes by modeling task as graph exploration and navigating back.
- Proposes learning in-context from previous executions on similar pages/goals. Uses demo ranking model and summarizes demos into instructions.
- First to apply autocurriculum strategy with LLM scoring to obtain high quality training data without human feedback. 
- Achieves new text-only SOTA of 53% on WebVoyager benchmark, 8% higher than previous text-only SOTA. Within 5% of strong multimodal model.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the key points from the paper:

The paper introduces Wilbur, a novel web agent that can backtrack from mistakes, learn from previous task executions, and leverage an autocurriculum strategy to quickly acquire knowledge of new websites and tasks, achieving state-of-the-art accuracy on the WebVoyager benchmark.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1) Proposing the first web agent, called Wilbur, that can backtrack to previous states during execution in order to recover from mistakes. This allows the agent to explore the website more flexibly.

2) A novel in-context learning approach to populate the agent's prompt with task demonstrations from previous runs, including both successful and unsuccessful examples. This allows the agent to learn from its experiences. The paper proposes techniques to select the most useful demonstrations and synthesize instructions from them.

3) An autocurriculum strategy to automatically collect training data for the agent on new websites and tasks, without needing manual annotation. This allows the agent to quickly learn how new websites work.

4) Evaluating Wilbur on the WebVoyager benchmark and showing state-of-the-art results for a text-only agent, demonstrating the efficacy of the proposed techniques. The analysis shows the agent is close in performance to a strong multimodal agent.

In summary, the main contributions are proposing a novel web agent architecture that can backtrack and learn from experience, as well as automatically improve itself by exploring new websites. The strong empirical results demonstrate these ideas work well in practice.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper are:

- Web agents - The paper focuses on intelligent agents that can interact with and navigate the web through a browser.

- Backtracking - A key contribution is enabling the agent to backtrack and return to a previous state if it makes a mistake, instead of just retrying.

- In-context learning - The agent learns from previous demonstrations of similar tasks and websites in the context/prompt of the large language model. 

- Knowledge synthesizer - A module that summarizes multiple demonstrations into concise instructions for the agent.

- Autocurriculum - An automatic pipeline to generate goals and trajectories on new websites to populate the agent's demonstration banks.

- Differentiable ranking model - Trained to select the most useful demonstrations for the prompt.

- WebVoyager - The benchmark used to evaluate the agent, consisting of real-world websites and goals.

- Ablation study - Comparing variants of the agent to analyze the impact of different components.

- Error analysis - Discussing sources of errors, including site anti-scraping measures and limitations interacting with complex site components.

Does this summary cover the key terminology and concepts related to this paper? Let me know if you need any clarification or have additional questions.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes a new web agent called Wilbur. What are the two key novel capabilities of Wilbur that aim to improve end-to-end success rates?

2. Wilbur uses a backtracking mechanism to recover from mistakes. How does Wilbur determine when to backtrack versus continuing execution? What specific modules and information are used to make this decision?

3. The paper mentions storing both successful and unsuccessful demonstrations in Wilbur's knowledge bank. What is the motivation behind including negative examples of actions and trajectories? How does Wilbur make use of them?

4. Explain the overall process of how Wilbur selects relevant previous demonstrations to include in the actor LLM's context. What models and intermediate steps are involved in filtering and summarizing demonstrations?

5. The method uses instruction synthesis to summarize demonstrations. Compare and contrast the benefits of showing raw demonstrations versus synthesized instructions in the context prompt. Why use both?

6. Walk through how the autocurriculum works to automatically collect demonstrations on new websites. What are the different steps involved and what specific LLMs are used in each phase?  

7. The paper proposes a trained knowledge model for ranking action demonstrations. Explain how the model works, what input representation it takes, and what training data was used.

8. What practical web-specific issues did the error analysis reveal that cause failures, even when Wilbur predicts reasonable actions? How could they be addressed in future work?

9. The method outperforms prior work, including models that use vision. Analyze and discuss what percent of the gains could be attributed to better prompting strategies versus gains from backtracking.

10. The paper hypothesizes that zero-shot approaches fail due to the need to explore and learn website nuances. Discuss whether Wilbur's learned strategies could transfer and be reused across different websites.
