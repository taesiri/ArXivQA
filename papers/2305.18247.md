# [TaleCrafter: Interactive Story Visualization with Multiple Characters](https://arxiv.org/abs/2305.18247)

## What is the central research question or hypothesis that this paper addresses?

This paper proposes an interactive story visualization system for generating videos from plain text stories. The key research questions and focus areas are:- How to build a generic story visualization system that can handle novel characters and scenes beyond a specific training dataset? - How to achieve identity consistency when generating multiple characters in the story visualization?- How to enable control over the layout and local object structure in the generated images, beyond implicit determination solely by the text?The main hypotheses are:- Leveraging large pre-trained language models and text-to-image models can enable generalization to new characters and scenes.- Learning personalized weights for each character can help maintain identity consistency across generated images.- Incorporating layout and sketch as additional inputs can allow control over object locations and local structures.To summarize, this paper focuses on developing an interactive story visualization system that can adapt to novel characters and scenes while preserving identity consistency and supporting user control over layout and local object structure. The core research questions revolve around utilizing large pre-trained models and multi-modal inputs to achieve these capabilities.
