# [Learn or Recall? Revisiting Incremental Learning with Pre-trained   Language Models](https://arxiv.org/abs/2312.07887)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Incremental learning (IL) aims to learn new tasks sequentially without forgetting previous knowledge. Recently, pre-trained language models (PLMs) have been widely used as backbones for IL in NLP. 

- Most existing methods assume PLMs suffer from catastrophic forgetting and propose techniques to overcome it. However, the extent of forgetting in PLMs for IL has not been thoroughly evaluated.

Key Contributions
- Conducts extensive probing experiments on PLMs in various IL settings. Reveals that PLMs inherently preserve most knowledge even using vanilla fine-tuning (SEQ), contradicting common belief.

- Finds through analysis that catastrophic forgetting stems from the classifier rather than the PLM backbone. The relative positions between old class embeddings and features change during SEQ.

- Proposes a simple yet effective algorithm called SEQ* that freezes PLMs and old classifiers after warm-up, avoiding disturbance to old knowledge. 

- Achieves superior or competitive performance to 20+ state-of-the-art methods on various tasks, with fewer trainable parameters and less training time.

Main Conclusions
- The paper urges revisiting assumptions of catastrophic forgetting in PLMs. It shows their strong built-in ability of retaining past knowledge during IL using proper strategies.

- The findings encourage future research to have a more thorough understanding of forgetting dynamics in PLMs and design algorithms accordingly rather than relying on common assumptions.


## Summarize the paper in one sentence.

 This paper revisits incremental learning with pre-trained language models, finding that they have inherent anti-forgetting abilities that allow simple methods to achieve strong performance, challenging assumptions about catastrophic forgetting.


## What is the main contribution of this paper?

 Based on my understanding, the main contribution of this paper is:

1) It revisits the assumption that pretrained language models (PLMs) suffer from catastrophic forgetting in incremental learning settings. Through extensive experiments and analysis, it reveals that PLMs have inherent anti-forgetting abilities and do not forget much when fine-tuned sequentially on new tasks.

2) It proposes a simple yet effective method called SEQ* for incremental learning with PLMs. By freezing PLMs and old task classifiers after minimal update, using proper classifiers, and pre-allocating future classifiers, SEQ* achieves competitive or even better performance compared to state-of-the-art incremental learning methods, while requiring much less training time and parameters.

3) It provides insights into what causes forgetting in PLMs during sequential fine-tuning - the change in relative position between class embeddings and features rather than forgetting in the PLMs themselves. It also analyzes the role of pre-training and model architecture in the anti-forgetting abilities.

4) The findings and analysis urge the community to revisit assumptions about catastrophic forgetting in PLMs for incremental learning. The paper encourages future research to better understand and exploit the inherent capabilities of PLMs for incremental learning.

In summary, the main contribution is in revisiting assumptions, proposing an effective simple method, providing insights, and urging the community to rethink incremental learning with PLMs.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper abstract and contents, some of the key terms and concepts associated with this paper include:

- Incremental Learning (IL)
- Pre-trained Language Models (PLMs)
- Catastrophic forgetting
- Probing performance
- Sequential fine-tuning (SEQ)
- Class-Incremental Learning (CIL)
- Task-Incremental Learning (TIL)
- Linear probing
- Cosine probing
- Class embeddings
- Moving distance
- SEQ*

The paper revisits incremental learning methods for PLMs and questions the common assumption that PLMs suffer from catastrophic forgetting under sequential fine-tuning. Through extensive probing experiments, the authors reveal the inherent anti-forgetting abilities of PLMs and propose simple yet effective strategies to boost the performance of sequential fine-tuning (SEQ*). The key findings relate to properly measuring and understanding forgetting in PLMs, the role of pre-training and model architecture, the source of forgetting in the classifiers rather than the PLMs themselves, and how this understanding can guide the design of effective IL algorithms. Terms like probing performance, class embeddings, and moving distance are used to analyze model forgetting. SEQ* refers to their proposed improved incremental learning approach for PLMs.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a simple method called SEQ* for incremental learning with pre-trained language models. What are the key strategies used in SEQ* and what is the rationale behind each of them?

2. The paper reveals that catastrophic forgetting in PLMs during incremental learning is not as severe as commonly believed. What evidence does the paper provide to support this claim? Please elaborate.

3. The paper utilizes four different metrics for probing the knowledge retained in PLMs, including linear probing, cosine linear probing, prototype probing and cosine prototype probing. Can you analyze the advantages and disadvantages of each metric and explain why linear probing works best?

4. Pre-training is considered one of the key factors behind the anti-forgetting ability of PLMs. However, the paper shows that even randomly initialized models exhibit incremental learning ability to some extent. What implications does this finding have on our understanding of the role of pre-training?

5. The paper reveals that the forgetting in SEQ happens mainly due to the changes in the relative position between class embeddings and features. Can you explain this phenomenon in more detail and how the strategies used in SEQ* help mitigate this issue?  

6. While SEQ* shows strong performance across multiple datasets, it does not always outperform state-of-the-art methods like LAMOL. When does SEQ* fail to achieve superior performance compared to LAMOL-based methods and why?

7. The paper only focuses on incremental learning of classification tasks with PLMs. Do you think the conclusions would generalize to other incremental learning scenarios like regression, sequence generation etc.? Why or why not?

8. The paper hints that both the architecture of Transformers and pre-training lead to the anti-forgetting ability in PLMs. Can you hypothesize the potential mechanisms inside the Transformer architecture that enable incremental learning?

9. SEQ* essentially relies on freezing components of the model after initial fine-tuning. Do you think this would limit the model's ability to continue learning genuinely new knowledge after the first task? How can this issue be alleviated?

10. The paper claims SEQ* is very simple yet effective. Can you think of potential ways to extend SEQ* to make it perform even better, such as by combining it with replay strategies? What challenges might arise?
