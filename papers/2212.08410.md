# Teaching Small Language Models to Reason

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: can the reasoning capabilities of large language models be transferred to smaller language models via finetuning?The authors explore using knowledge distillation to transfer the reasoning abilities that emerge in large language models (LLMs) with over 100 billion parameters to smaller language models. Specifically, they finetune smaller language models on chains of thought generated by the LLMs to teach the smaller models to reason in a similar step-by-step fashion. Their experiments aim to determine if this chain of thought knowledge distillation can improve the reasoning capabilities of smaller models across tasks like arithmetic, commonsense and symbolic reasoning.


## What is the main contribution of this paper?

The main contribution of this paper is exploring the transfer of reasoning capabilities from large language models (LLMs) to smaller models via knowledge distillation of chain of thought (CoT) reasoning. Specifically, the authors propose finetuning smaller student models like T5 on CoT data generated by large teacher models like PaLM 540B and GPT-3 175B. Their key findings are:- Finetuning smaller models on LLMs' CoT improves task performance across arithmetic, commonsense, and symbolic reasoning datasets. For example, finetuning boosts T5 XXL's accuracy on GSM8K from 8.11% to 21.99%.- The proposed method is robust to different teacher model architectures. Finetuning on GPT-3 175B's CoT also improves T5 XXL's performance. - There is a trade-off between model size, dataset size, and accuracy. Smaller student models can match the baseline accuracy of larger models when trained on CoT data. The method is also more data-efficient than regular finetuning.- The benefits are task-dependent. For tasks requiring factual knowledge, improvements are limited as smaller models likely lack the knowledge compared to larger, higher capacity models.In summary, the key contribution is a method to transfer reasoning abilities from huge LLMs to smaller models via CoT knowledge distillation and an analysis of how model size, dataset size, and task nature affect the transfer.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The paper proposes a method to transfer the reasoning capabilities of large language models to smaller models via knowledge distillation. Specifically, it generates chains of reasoning from large models and uses them to finetune smaller models, thereby teaching the smaller models to reason in a similar way.
