# [WebGLM: Towards An Efficient Web-Enhanced Question Answering System with   Human Preferences](https://arxiv.org/abs/2306.07906)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How to construct an efficient web-enhanced question answering system based on large language models that can understand human preferences and have comparable quality to state-of-the-art systems like WebGPT?The key points related to this research question are:- The paper aims to build a practical web-enhanced QA system called WebGLM based on the 10-billion parameter General Language Model (GLM-10B). - It seeks to identify limitations of existing systems like WebGPT in terms of efficiency, cost-effectiveness and real-world deployment. - The paper proposes new strategies and designs for the retriever, generator, and scorer components to improve accuracy while being more efficient than WebGPT.- It introduces systematic criteria for evaluating web-enhanced QA systems through multi-dimensional human evaluation.- The goal is for WebGLM to have comparable quality to WebGPT, even with a smaller model size, while being more efficient and cost-effective. - Extensive experiments demonstrate WebGLM's capabilities and provide insights into future improvements.In summary, the central hypothesis is that an efficient high-quality web-enhanced QA system can be constructed through innovations in retrieval, generation, scoring and evaluation, as showcased by WebGLM. The paper presents solutions and experiments to validate this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:1. The paper presents WebGLM, an efficient web-enhanced question answering system based on the 10-billion parameter General Language Model (GLM). 2. The paper identifies limitations of WebGPT for real-world deployment, including slow speed, reliance on expert demonstrations, and high annotation costs. To address these, WebGLM proposes new strategies:- An LLM-augmented retriever for fast and accurate retrieval from the web. It combines coarse search with fine-grained LLM knowledge distillation.- A bootstrapped generator trained on automatically generated long-form QA data using GPT-3's in-context learning. This avoids expensive expert writing. - A human preference-aware scorer trained on QA forum data to pick best answers without expert labels.3. Through extensive experiments including human evaluation and Turing Tests, the paper demonstrates WebGLM matches WebGPT-175B quality while being more efficient and lower cost.4. The paper provides a set of criteria and methodology for evaluating web-enhanced QA systems.In summary, the main contribution is an effective and practical web-enhanced QA system (WebGLM) that approximates the quality of WebGPT while overcoming its deficiencies for real-world use. The techniques used in WebGLM to improve efficiency, reduce annotation cost, and leverage naturally occurring data are also valuable contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The TL;DR summary in one sentence is: The paper presents WebGLM, an efficient web-enhanced question answering system based on GLM that outperforms similar-sized WebGPT and approaches performance of the much larger 175B WebGPT while being more practical to deploy.


## How does this paper compare to other research in the same field?

Here are some key ways this paper compares to other research in the same field of web-enhanced question answering:- Datasets: This paper introduces a new dataset called WebGLM-QA with 45k high-quality long-form QA samples, bootstrapped via GPT-3 in-context learning. Other major datasets in this area include ELI5 and the proprietary dataset used to train WebGPT. - Models: The paper presents WebGLM, built on a 10B parameter GLM model. This is much smaller than WebGPT's 175B parameters but achieves strong performance. Other models in this space include WebGPT, REALM/RAG, Perplexity.ai, and Fusion-in-Decoder.- Retrieval: For retrieval, WebGLM uses a combination of web search APIs and a small dense retriever augmented with GLM. This is more efficient than WebGPT's slow step-by-step browsing. Other works use retrieve-then-read pipelines with Wikipedia articles or full web search.- Training: WebGLM trains the QA generator on the bootstrapped data and uses preference learning from online forums for the scorer. In contrast, WebGPT used expensive expert demonstrations and labeling. Other works often rely on supervised data.- Evaluation: The paper introduces a detailed human evaluation protocol for web QA. Other works have used automatic metrics, human ratings, and question answering benchmarks. - Performance: WebGLM matches or exceeds WebGPT-13B and approaches WebGPT-175B level performance with much lower parameters. It outperforms the publicly available Perplexity.ai system.Overall, WebGLM introduces efficiencies in model size, retrieval, and training data while achieving strong performance compared to other web QA systems. The human evaluation framework is also a significant contribution.
