# [WebGLM: Towards An Efficient Web-Enhanced Question Answering System with   Human Preferences](https://arxiv.org/abs/2306.07906)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How to construct an efficient web-enhanced question answering system based on large language models that can understand human preferences and have comparable quality to state-of-the-art systems like WebGPT?The key points related to this research question are:- The paper aims to build a practical web-enhanced QA system called WebGLM based on the 10-billion parameter General Language Model (GLM-10B). - It seeks to identify limitations of existing systems like WebGPT in terms of efficiency, cost-effectiveness and real-world deployment. - The paper proposes new strategies and designs for the retriever, generator, and scorer components to improve accuracy while being more efficient than WebGPT.- It introduces systematic criteria for evaluating web-enhanced QA systems through multi-dimensional human evaluation.- The goal is for WebGLM to have comparable quality to WebGPT, even with a smaller model size, while being more efficient and cost-effective. - Extensive experiments demonstrate WebGLM's capabilities and provide insights into future improvements.In summary, the central hypothesis is that an efficient high-quality web-enhanced QA system can be constructed through innovations in retrieval, generation, scoring and evaluation, as showcased by WebGLM. The paper presents solutions and experiments to validate this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:1. The paper presents WebGLM, an efficient web-enhanced question answering system based on the 10-billion parameter General Language Model (GLM). 2. The paper identifies limitations of WebGPT for real-world deployment, including slow speed, reliance on expert demonstrations, and high annotation costs. To address these, WebGLM proposes new strategies:- An LLM-augmented retriever for fast and accurate retrieval from the web. It combines coarse search with fine-grained LLM knowledge distillation.- A bootstrapped generator trained on automatically generated long-form QA data using GPT-3's in-context learning. This avoids expensive expert writing. - A human preference-aware scorer trained on QA forum data to pick best answers without expert labels.3. Through extensive experiments including human evaluation and Turing Tests, the paper demonstrates WebGLM matches WebGPT-175B quality while being more efficient and lower cost.4. The paper provides a set of criteria and methodology for evaluating web-enhanced QA systems.In summary, the main contribution is an effective and practical web-enhanced QA system (WebGLM) that approximates the quality of WebGPT while overcoming its deficiencies for real-world use. The techniques used in WebGLM to improve efficiency, reduce annotation cost, and leverage naturally occurring data are also valuable contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The TL;DR summary in one sentence is: The paper presents WebGLM, an efficient web-enhanced question answering system based on GLM that outperforms similar-sized WebGPT and approaches performance of the much larger 175B WebGPT while being more practical to deploy.
