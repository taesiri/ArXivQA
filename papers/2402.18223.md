# [Improving Open-Ended Text Generation via Adaptive Decoding](https://arxiv.org/abs/2402.18223)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Current language models use probabilistic distributions to decode text token-by-token during text generation. Determining the appropriate candidate tokens to consider at each step is crucial for high quality text generation.
- Greedy decoding and beam search can cause high repetition. Top-p sampling can cause incoherence and hallucination by allowing improbable tokens. 
- There is a tradeoff between diversity and coherence in determining the decoding algorithm and size of the candidate token set.

Proposed Solution:
- The paper proposes an "adaptive decoding" method that allows language models to dynamically determine an appropriate candidate token set during text generation.  
- They introduce a confidence metric based on entropy to measure how certain the language model is about the next token distribution.  
- The process of finding the optimal candidate set is treated as a "confidence-increasing" procedure - tokens are iteratively added to the set based on the increase in confidence they provide.
- A threshold determines when to stop adding tokens to the candidate set. This allows adaptive determination of a suitable candidate set.

Contributions:
- Integrate the concept of entropy reduction into text decoding, using confidence increment to assess when a token should be in the candidate set.
- Design an "adaptive decoding" algorithm that lets models dynamically determine a good candidate set size during generation.
- Show improved coherence/diversity balance and generation quality closer to human text across models and datasets compared to prior decoding algorithms.

In summary, the key idea is to leverage confidence increment based on entropy reduction to adaptively determine the best candidate token set during decoding to improve open-ended text generation quality. Experiments validate the effectiveness of this novel adaptive decoding approach.
