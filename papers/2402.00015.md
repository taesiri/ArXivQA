# [Maintaining User Trust Through Multistage Uncertainty Aware Inference](https://arxiv.org/abs/2402.00015)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- The authors have developed a computer vision model to help small-holder cotton farmers detect crop pests using photos. However, strict mobile app size limits and unreliable internet connectivity make it challenging to deploy high-performance models. 
- Users have high expectations for accuracy since incorrect pesticide recommendations can be harmful. So there is a need to balance performance with model accessibility.

Proposed Solution:
- A multi-stage architecture with models of increasing complexity is proposed. Images are first passed to a small on-device model. If uncertain, they are sent to a larger cloud model. If still uncertain, humans experts analyze them.
- Uncertainty is quantified using the agreement between high and low confidence object detection boxes. Disagreement triggers forwarding images down the pipeline.
- This balances model accuracy with costs like response time and expert time. Lower stages handle most easy cases. Hard cases bubble up to more accurate methods.

Main Contributions:
- A new multi-stage uncertainty-aware architecture for agricultural AI systems needing high reliability despite deployment constraints.
- A box confidence windowing technique to quantify model uncertainty for object detectors. Windows are tuned on a validation set.
- Analysis showing the multi-stage approach reduces false alarms by up to 50% compared to individual models, especially at lower abstention levels.
- The system is currently being used by thousands of Indian cotton farmers during pest management.

In summary, the paper introduces a staged inference approach that gracefully balances accuracy and accessibility to maintain user trust in challenging deployment settings. The quantitative uncertainty metric facilitates knowing when to defer to more accurate options.
