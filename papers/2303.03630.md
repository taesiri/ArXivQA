# [No One Left Behind: Improving the Worst Categories in Long-Tailed   Learning](https://arxiv.org/abs/2303.03630)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to improve the performance on worst-performing categories in long-tailed recognition. 

The key hypotheses are:

1. Focusing only on average accuracy on a balanced test set can ignore poor performance on some categories, since it incurs little penalty for very low recall values.

2. Classes in the "Few" subset do not necessarily perform worse than "Many" or "Medium", so improving "Few" accuracy alone is insufficient. 

3. Optimizing for harmonic mean of per-class recall, rather than arithmetic mean, better ensures no categories are left behind.

4. A simple fine-tuning method with a novel geometric mean loss can improve worst-case and harmonic mean accuracy.

5. Ensembling the original and fine-tuned classifiers can combine strengths of both while adding little computational cost.

In summary, the central hypothesis is that explicitly optimizing for harmonic mean recall and minimum recall will improve worst-performing categories in long-tailed recognition compared to conventional approaches. The proposed methods aim to test this hypothesis.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Pointing out issues with the common evaluation scheme in long-tailed recognition research, which splits classes into "Head", "Medium", and "Few" subsets and reports accuracy on each. The authors argue this can be problematic because:

- Reporting average accuracy on each subset obscures whether some classes are completely misclassified.

- It's not necessarily true that "Few" classes perform worse than "Medium" or "Head". 

2. Proposing new metrics focused on improving the worst performing classes: harmonic mean of per-class recall and lowest recall (accuracy of worst class).

3. A novel method to optimize these metrics:

- A Geometric Mean Loss (GML) function that maximizes geometric mean of recalls as a surrogate for harmonic mean.

- Fine-tuning the classifier of any existing model with GML.

- An optional ensemble technique combining predictions of original and fine-tuned model.

4. Experiments on CIFAR and ImageNet based datasets showing the proposed method improves harmonic mean and lowest recall while maintaining overall accuracy, achieving state-of-the-art results.

5. Analysis and visualizations demonstrating the method produces a more balanced distribution of per-class recall values.

In summary, the key contribution is identifying issues with common long-tailed recognition evaluation, proposing better metrics, and presenting a simple fine-tuning method to optimize these metrics and improve recall of the worst classes.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 The paper proposes a novel method to improve the worst-performing categories in long-tailed image recognition. The key idea is to optimize the harmonic mean of per-class recall rather than just the overall accuracy, using a surrogate loss called Geometric Mean Loss (GML) that maximizes the geometric mean. The method can be applied as a simple plug-in to existing models by retraining just the classifier, and further combines predictions from the original and retrained models. In summary, the paper aims to make sure no categories are left behind in long-tailed recognition.
