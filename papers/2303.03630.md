# [No One Left Behind: Improving the Worst Categories in Long-Tailed   Learning](https://arxiv.org/abs/2303.03630)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to improve the performance on worst-performing categories in long-tailed recognition. 

The key hypotheses are:

1. Focusing only on average accuracy on a balanced test set can ignore poor performance on some categories, since it incurs little penalty for very low recall values.

2. Classes in the "Few" subset do not necessarily perform worse than "Many" or "Medium", so improving "Few" accuracy alone is insufficient. 

3. Optimizing for harmonic mean of per-class recall, rather than arithmetic mean, better ensures no categories are left behind.

4. A simple fine-tuning method with a novel geometric mean loss can improve worst-case and harmonic mean accuracy.

5. Ensembling the original and fine-tuned classifiers can combine strengths of both while adding little computational cost.

In summary, the central hypothesis is that explicitly optimizing for harmonic mean recall and minimum recall will improve worst-performing categories in long-tailed recognition compared to conventional approaches. The proposed methods aim to test this hypothesis.
