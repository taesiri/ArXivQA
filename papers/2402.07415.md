# [Context-aware Multi-Model Object Detection for Diversely Heterogeneous   Compute Systems](https://arxiv.org/abs/2402.07415)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Object detection models (ODMs) have varying accuracy, latency, and energy profiles depending on the model architecture, hardware accelerator, and input data. Selecting the optimal ODM for a given frame is challenging.  
- Running multiple ODMs per frame to predict their accuracy is computationally prohibitive. Existing methods for ODM selection have limitations in accuracy or efficiency.

Proposed Solution - \sysname{}:
- A 3-component system for efficient multi-model, multi-accelerator scheduling and execution of ODMs on edge devices. The components are:

1. Model Characterization
   - Profiles ODM accuracy, latency, energy, confidence scores for accelerators
   - Constructs a Confidence Graph that correlates confidence scores of different ODMs to enable fast, accurate predictions of ODM accuracy at runtime.

2. Scheduler  
   - Detects context changes in input stream using simple image metrics 
   - Uses Confidence Graph to predict ODM accuracy
   - Scheduling heuristic weights models by accuracy, latency, energy to select best ODM for each frame  

3. Dynamic Model Loader
   - Manages model memory allocation across accelerators using profiling data
   - Maximizes memory utilization while minimizing model load costs
   
Key Contributions:
- Confidence Graph for enabling quick predictions of ODM accuracy from single model confidence scores
- Lightweight scheduler that detects context changes and leverages Confidence Graph to select optimal ODMs 
- Dynamic model loading system to efficiently load/unload models to minimize switching overheads
- Evaluated on automotive dataset to show improved frame processing over state-of-the-art techniques

The paper offers an efficient pipeline for multi-model scheduling on resource-constrained edge devices, using practical data-driven techniques to predict model accuracy without expensive runtime evaluation.
