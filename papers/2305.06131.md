# [Generative AI meets 3D: A Survey on Text-to-3D in AIGC Era](https://arxiv.org/abs/2305.06131)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we generate high-quality 3D models from just text descriptions, without relying on large paired text-3D datasets? The key points are:- Text-to-image synthesis has made great progress recently thanks to large text-image datasets and advances in deep learning. However, text-to-3D is more challenging due to the lack of large paired text-3D datasets and the complexity of 3D data representations. - Recent works have shown promising results in text-to-3D generation by leveraging powerful pre-trained text-to-image models as priors during 3D optimization.- The paper provides a comprehensive survey of the recent advances in text-to-3D generation enabled by text-to-image priors. It reviews the data representations, foundation technologies, successful attempts, applications, and discusses challenges and future directions.In summary, the central hypothesis is that text-to-3D generation can be achieved by utilizing text-to-image models as strong priors to guide the optimization of 3D representations like Neural Radiance Fields, despite the lack of large text-3D datasets. The survey aims to provide a comprehensive overview of this emerging research direction.


## What is the main contribution of this paper?

Here are the main contributions of this survey paper on text-to-3D:- It provides a comprehensive overview of text-to-3D generation, which is an emerging research field enabled by recent advances in generative AI and 3D representations like NeRF. - It reviews different 3D data representations, including both Euclidean (voxel grids, multi-view images) and non-Euclidean data (meshes, point clouds, neural fields).- It summarizes the foundation technologies behind text-to-3D, including NeRF, CLIP, diffusion models, and pre-trained text-to-image models. - It discusses the recent pioneering works in text-to-3D that utilize CLIP and text-to-image diffusion models to optimize 3D representations without 3D supervision. Key papers covered include Dream Fields, CLIP-NeRF, DreamFusion, Magic3D, etc.- It also overviews follow-up works that aim to address limitations of the pioneers, such as improving inference speed, 3D consistency, controllability, and applicability.- It surveys applications of text-to-3D in domains like avatar generation, texture generation, shape transformation, and scene generation. - It provides insights into open challenges and future directions, including improving fidelity, inference speed, consistency, controllability, and applicability of text-to-3D models.In summary, this paper offers a comprehensive review of the quickly evolving landscape of text-to-3D generation, which combines advances in generative AI and 3D representations to enable diverse 3D content creation from natural language prompts. It covers the key technologies, models, applications and open issues in this emerging field.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:This paper provides a comprehensive survey of the emerging research area of text-to-3D, summarizing key 3D data representations, foundation technologies like NeRF and CLIP, recent pioneering works and enhancements in text-guided 3D generation, and applications of text-to-3D in areas like avatar, texture, scene and shape generation.
