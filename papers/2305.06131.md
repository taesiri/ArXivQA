# [Generative AI meets 3D: A Survey on Text-to-3D in AIGC Era](https://arxiv.org/abs/2305.06131)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we generate high-quality 3D models from just text descriptions, without relying on large paired text-3D datasets? The key points are:- Text-to-image synthesis has made great progress recently thanks to large text-image datasets and advances in deep learning. However, text-to-3D is more challenging due to the lack of large paired text-3D datasets and the complexity of 3D data representations. - Recent works have shown promising results in text-to-3D generation by leveraging powerful pre-trained text-to-image models as priors during 3D optimization.- The paper provides a comprehensive survey of the recent advances in text-to-3D generation enabled by text-to-image priors. It reviews the data representations, foundation technologies, successful attempts, applications, and discusses challenges and future directions.In summary, the central hypothesis is that text-to-3D generation can be achieved by utilizing text-to-image models as strong priors to guide the optimization of 3D representations like Neural Radiance Fields, despite the lack of large text-3D datasets. The survey aims to provide a comprehensive overview of this emerging research direction.
