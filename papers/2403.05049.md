# [XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution](https://arxiv.org/abs/2403.05049)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Diffusion models have shown promising results for image super-resolution (ISR). However, they struggle to accurately restore semantic details from low-resolution (LR) inputs that have undergone complex unknown degradations. This is because it's challenging for the model to extract precise semantic information about the image content and quality from the degraded LR image alone.

Proposed Solution (XPSR Framework):
1) Leverage powerful multimodal large language models (LLMs) to provide multi-level semantic prompts about image content (high-level) and quality/distortions (low-level) to guide the diffusion model. 

2) Propose a Semantic-Fusion Attention (SFA) module to effectively incorporate the textual prompts as conditions into the diffusion model, fusing high-level and low-level semantics in parallel.

3) Add a Degradation-Free Constraint (DFC) to extract semantic features from LR images that are free of distortions and aligned with HR counterparts.

Main Contributions:
1) Explore the impact of using high-level vs low-level semantic textual prompts to guide diffusion models for ISR.

2) Propose the XPSR framework to leverage state-of-the-art LLMs to provide accurate cross-modal semantic prompts and effectively incorporate them into diffusion models.

3) Design components like SFA and DFC to improve fusion of semantic information and handle image degradations.

4) Achieve new state-of-the-art performance across metrics in generating realistic and detailed HR images from complex LR inputs on benchmark datasets.
