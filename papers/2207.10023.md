# [Tailoring Self-Supervision for Supervised Learning](https://arxiv.org/abs/2207.10023)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: How can we design a self-supervised pretext task that is tailored specifically for improving supervised learning? The key points are:- Existing self-supervised pretext tasks like rotation prediction are designed for unsupervised representation learning, and have limitations when applied to supervised learning. - The authors argue an ideal auxiliary self-supervised task for supervised learning should have 3 properties: (1) guide the model to learn complementary features, (2) maintain the original data distribution, (3) be lightweight and easy to implement.- They propose "Localizable Rotation (LoRot)" as a pretext task tailored for supervised learning. It rotates only a patch of the image and predicts the rotation, forcing the model to learn detailed features of object parts.- Rotating just a patch maintains the overall data distribution, unlike rotating the whole image. And it's easy to implement as a multi-task objective.- Experiments validate LoRot improves supervised models' robustness and generalization capability, achieving state-of-the-art results on tasks like out-of-distribution detection.In summary, the key hypothesis is that a self-supervised pretext task can be specifically designed to enhance supervised learning, with properties like LoRot's patch rotation. The experiments aim to validate its benefits.
