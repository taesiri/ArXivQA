# [Tailoring Self-Supervision for Supervised Learning](https://arxiv.org/abs/2207.10023)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: How can we design a self-supervised pretext task that is tailored specifically for improving supervised learning? The key points are:- Existing self-supervised pretext tasks like rotation prediction are designed for unsupervised representation learning, and have limitations when applied to supervised learning. - The authors argue an ideal auxiliary self-supervised task for supervised learning should have 3 properties: (1) guide the model to learn complementary features, (2) maintain the original data distribution, (3) be lightweight and easy to implement.- They propose "Localizable Rotation (LoRot)" as a pretext task tailored for supervised learning. It rotates only a patch of the image and predicts the rotation, forcing the model to learn detailed features of object parts.- Rotating just a patch maintains the overall data distribution, unlike rotating the whole image. And it's easy to implement as a multi-task objective.- Experiments validate LoRot improves supervised models' robustness and generalization capability, achieving state-of-the-art results on tasks like out-of-distribution detection.In summary, the key hypothesis is that a self-supervised pretext task can be specifically designed to enhance supervised learning, with properties like LoRot's patch rotation. The experiments aim to validate its benefits.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It discusses three desirable properties for auxiliary self-supervision tasks to assist supervised learning objectives: (i) learning rich representations, (ii) maintaining data distribution, and (iii) providing high applicability. 2. It proposes a simple yet effective self-supervised task called Localizable Rotation (LoRot) tailored for supervised learning. LoRot rotates only a patch of the input image and predicts the rotation, encouraging the model to learn complementary features to the primary supervised task. 3. It shows that rotating a small patch does not significantly alter the data distribution, allowing LoRot to work well in a multi-task learning framework with the primary supervised objective.4. Through extensive experiments, it demonstrates that LoRot consistently improves model robustness and generalization capability across tasks like out-of-distribution detection, imbalanced classification, adversarial attack, image classification, localization, and transfer learning.In summary, the key contribution is proposing LoRot, a lightweight and easily applicable self-supervised task designed specifically to assist supervised learning objectives, and showing its effectiveness across diverse tasks and model architectures. The discussions around desired properties of auxiliary self-supervision and maintaining data distribution are also valuable.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a new self-supervised learning method called Localizable Rotation (LoRot) tailored for supervised learning settings, which rotates only a patch of an image and asks the model to predict the rotation degree to encourage learning rich features while maintaining the original data distribution, and demonstrates its effectiveness on various computer vision tasks.


## How does this paper compare to other research in the same field?

This paper presents a new method for tailoring self-supervision to improve supervised learning. Here are some key comparisons to other related works:- Most prior work on using self-supervision for supervised learning simply applies existing pretext tasks like rotation prediction as auxiliary objectives. This paper argues that those tasks are not optimal as they were designed for unsupervised representation learning, not for assisting supervised learning. The proposed LoRot task is specifically designed as a complementary objective for supervised models.- LoRot focuses on creating a pretext task that learns rich feature representations while maintaining the data distribution and being lightweight to implement. Other self-supervision methods for supervised learning don't explicitly consider those criteria in designing the pretext task.- LoRot only performs transformations on local patches of the image rather than the full image. This is different from prior works using global transformations like image rotation for the pretext task. The local transformation helps maintain the data distribution better.- The paper shows that LoRot provides consistent benefits across many supervised learning scenarios like classification, imbalanced learning, adversarial robustness, etc. Many prior works focused on using self-supervision for just one application.- LoRot achieves superior or competitive results compared to prior self-supervision methods for supervised learning, while being simpler and more efficient to implement. This makes it more practical to incorporate into existing models.- The analysis shows that LoRot provides complementary benefits when combined with other techniques like data augmentation and contrastive learning. This demonstrates it is addressing a different aspect of representation learning compared to those methods.In summary, this work provides new insights into how to design self-supervised pretext tasks to improve supervised learning, resulting in a simple and effective approach suitable for widespread use. The comprehensive experiments and comparisons to prior art demonstrate the value of this tailored self-supervision approach.
