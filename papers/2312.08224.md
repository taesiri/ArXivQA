# [GLOP: Learning Global Partition and Local Construction for Solving   Large-scale Routing Problems in Real-time](https://arxiv.org/abs/2312.08224)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes GLOP, a unified hierarchical framework for solving large-scale routing problems like TSP, ATSP, CVRP, and PCTSP. GLOP hybridizes non-autoregressive neural heuristics for coarse-grained problem partitioning and autoregressive neural heuristics for fine-grained route construction. It first partitions large problems into sub-problems using learned heatmaps, then solves the sub-problems with neural networks trained on small instances. This combines the scalability of non-autoregressive models with the meticulousness of autoregressive ones. Experiments show GLOP achieves state-of-the-art real-time performance on routing benchmarks. Notably, it is the first neural solver to effectively scale to 100K-node TSP. The solution pipeline of GLOP is also applicable to different routing variants. Overall, GLOP pushes the boundary of neural combinatorial optimization by enhancing neural solvers to tackle large-scale problems in a parallelizable and efficient way.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes GLOP, a unified hierarchical framework that efficiently scales neural routing solvers to large-scale combinatorial optimization problems by hybridizing non-autoregressive neural heuristics to partition problems and autoregressive neural heuristics to construct solutions.


## What is the main contribution of this paper?

 Based on my understanding, the main contribution of this paper is proposing GLOP, a unified hierarchical framework that efficiently scales neural solvers toward solving large-scale routing problems in real-time. Specifically:

1) GLOP proposes to partition large routing problems into Travelling Salesman Problems (TSPs) and further partition potentially large TSPs into small Shortest Hamiltonian Path Problems (SHPPs). 

2) GLOP is the first to hybridize non-autoregressive neural heuristics for coarse-grained problem partitions and autoregressive neural heuristics for fine-grained route constructions. This hybrid framework aims to leverage the scalability of the former and the meticulousness of the latter.

3) Extensive experiments demonstrate that GLOP achieves competitive and state-of-the-art real-time performance on solving large instances of various routing problems, including TSP, ATSP, CVRP and PCTSP. It also delivers superior scaling-up and cross-distribution generalization on TSP.

In summary, the main contribution lies in proposing GLOP as an effective and unified framework to scale up neural solvers for solving large-scale routing problems in real-time.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with it are:

- GLOP (Global and Local Optimization Policies) - The name of the proposed hierarchical framework for solving large-scale routing problems. Combines global partitioning policies with local construction policies.

- Non-autoregressive and autoregressive policies - GLOP hybridizes non-autoregressive neural heuristics for coarse-grained problem partitioning and autoregressive neural heuristics for fine-grained route construction. 

- Traveling Salesman Problem (TSP) - A classic routing problem that GLOP is evaluated on. GLOP makes TSP solvers scalable to problems with tens of thousands of nodes.

- Capacitated Vehicle Routing Problem (CVRP) - Another routing problem tackled by GLOP. It outperforms prior state-of-the-art methods on large CVRP instances.  

- Prize Collecting TSP (PCTSP) - A variation of TSP also addressed by GLOP. It surpasses recent neural and conventional solvers on this problem.

- Shortest Hamiltonian Path Problem (SHPP) - Also called the open-loop TSP. GLOP learns to solve this as a subproblem for reconstructing subtours in a divide-and-conquer manner.

- Real-time performance - A key focus and selling point of GLOP is being able to solve large-scale routing problems with tens of thousands of nodes in a highly time-efficient manner.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the GLOP method proposed in the paper:

1. How does GLOP effectively integrate the strengths of both autoregressive (AR) and non-autoregressive (NAR) paradigms for neural combinatorial optimization? What are the drawbacks it aims to circumvent for each paradigm?

2. Why does GLOP choose to use non-autoregressive neural heuristics to learn the global partitioning policies? What are the advantages of using the NAR paradigm for this coarse-grained task? 

3. What neural architecture does GLOP use for the local policies that solve the Shortest Hamiltonian Path Problems (SHPP)? How is attention mechanism adapted for the SHPP formulation?

4. Explain the two-stage curriculum learning approach used to train the neural networks for solving SHPPs. Why is it beneficial to train on multi-distribution instances first?  

5. How does GLOP construct the input graphs and design the node/edge features for its global partitioning policies? How does it handle problem-specific constraints during partitioning?

6. Analyze the time complexity of GLOP and discuss how it achieves efficient scaling to large problem sizes. How does decomposing into small SHPPs aid parallelizability?

7. What results demonstrate that the holistic divide-and-conquer solution scheme, rather than particular training schemes, contributes most to GLOP's cross-distribution performance?

8. How does GLOP extend the applicability of its framework to heterogeneous vehicle routing problems like CVRP and PCTSP? What formulations allow it to handle node clustering or node subsetting?

9. Compare GLOP's performance to prior state-of-the-art methods on large scale instances of TSP, CVRP and PCTSP. What metrics clearly demonstrate its superiority? 

10. Discuss any limitations of GLOP compared to methods based on iterative solution refinement. How can these limitations be addressed in future work?


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Traditional solvers struggle with quickly solving large-scale routing problems like TSP, CVRP, etc to meet modern industry's growing demands. Recent neural combinatorial optimization (NCO) methods also face challenges in scaling up effectively for such problems under real-time constraints.

Proposed Solution: 
- The paper proposes GLOP, a hierarchical framework to tackle large routing problems by combining global coarse-grained partitioning policies and local fine-grained construction policies.

- For TSP, GLOP partitions into sub-TSPs, then into Shortest Hamiltonian Path Problems (SHPP). The SHPPs are small graph problems with fixed start/end nodes that are solved by neural autoregressive models called "revisers". Multiple rounds of divide-and-conquer are done.

- For general routing like CVRP, GLOP additionally uses a learned global policy based on graph neural networks to partition the problem into sub-TSPs satisfying constraints.

Main Contributions:

- First framework to effectively hybridize non-autoregressive (global partitioning) and autoregressive (local construction) neural policies for routing problems.

- Learns to generate global partitioning heatmaps to decompose large problems in a novel way.

- Proposes a one-size-fits-all real-time TSP/ATSP solver by using small revisers, achieving better performance than prior hierarchical solvers.

- Achieves state-of-the-art real-time performance on large CVRP and is the first neural solver to effectively scale to 100k-node TSP.

- Shows consistent performance across scales and distributions for TSP without retraining, and outperforms on multiple routing problems.
