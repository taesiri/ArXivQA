# [PlaneDepth: Self-supervised Depth Estimation via Orthogonal Planes](https://arxiv.org/abs/2210.01612)

## What is the central research question or hypothesis that this paper addresses?

 The central research question addressed in this paper is: 

How can we improve self-supervised monocular depth estimation by representing the scene with orthogonal planes and modeling depth as a mixture of Laplace distributions on those planes?

The key aspects explored in addressing this question are:

- Using both vertical planes and ground planes to represent the scene, which enables predicting continuous depth for the ground while preserving sharp edges on objects. Previous plane-based methods only used vertical/frontal planes which led to discontinuities in the ground region.

- Modeling the depth distribution as a mixture of Laplace distributions centered on the orthogonal planes. This avoids ambiguity in the loss function compared to using a weighted summation of warped images from different planes. 

- Introducing orthogonality-preserving data augmentation through explicit resizing/cropping transforms and neural positional encodings. This improves robustness and helps the network utilize both relative object size and vertical position cues.

- Combining post-processing with self-distillation through a bilateral occlusion mask to improve accuracy and efficiency.

The main hypothesis is that explicitly modeling the scene geometry with orthogonal planes and representing depth probabilistically as a mixture of Laplace distributions will improve self-supervised monocular depth estimation, especially for representing the ground region and dealing with ambiguities. The experiments aim to validate the effectiveness of the proposed orthogonal plane representation and training strategies.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes PlaneDepth, a novel orthogonal plane-based representation for monocular depth estimation, which includes vertical planes and ground planes. This representation enables estimating a continuous depth for the ground region while preserving sharp edges for other objects.

2. It models the depth distribution as a mixture of Laplacians based on orthogonal planes. This avoids the ambiguity of previous weighted color composition and leads to more stable depth estimation. 

3. It introduces an orthogonality-preserved data augmentation strategy through explicit resizing cropping transformations and neural positional encodings. This improves the robustness of network training.

4. It combines post-processing with self-distillation using bilateral occlusion masks to generate more accurate pseudo labels. This improves both the accuracy and efficiency of the method.

In summary, the main contribution is the novel orthogonal plane representation and the associated improvements to monocular depth estimation, including the mixture of Laplacians depth modeling, the orthogonality-preserved data augmentation, and the augmented self-distillation technique. These contributions enable more accurate and continuous depth estimation, especially for the ground region which is important for autonomous driving applications.
