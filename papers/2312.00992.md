# [Improving Normative Modeling for Multi-modal Neuroimaging Data using   mixture-of-product-of-experts variational autoencoders](https://arxiv.org/abs/2312.00992)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Normative models in neuroimaging learn healthy brain patterns and estimate disease deviations. Existing variational autoencoder (VAE) based multimodal normative models have limitations in modelling the joint latent distribution between modalities like MRI and PET. 

- Product-of-Experts (PoE) joint distribution can be biased towards a single modality. Mixture-of-Experts (MoE) does not result in a sharper joint distribution compared to individual modalities.

Proposed Solution:
- The paper proposes using Mixture-of-Product-of-Experts (MoPoE) to aggregate multimodal information in the latent space. MoPoE mitigates limitations of both PoE and MoE.

- A multimodal VAE model with separate MRI and PET encoders/decoders and MoPoE inference network is developed for normative modeling. 

- Mahalanobis distance based latent and feature space deviations are proposed to quantify subject-level deviations.

Contributions:
- MoPoE enables better joint latent representation and improved capture of outliers.

- Latent deviations successfully track disease progression and correlate with cognition.

- Interpretability analysis identifies informative latent dimensions and maps them to regional brain deviations to analyze neurodegeneration and amyloid deposition.

Overall, the paper demonstrates MoPoE as an effective way to aggregate multimodal data in VAE-based normative modeling frameworks for improved disease detection and interpretability.
