# [Building Open-Ended Embodied Agent via Language-Policy Bidirectional   Adaptation](https://arxiv.org/abs/2401.00006)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Building open-ended learning agents that can continuously acquire new skills and handle diverse human instructions remains challenging. Existing methods using pre-trained language models (LLMs) struggle with real-time contextual understanding, while reinforcement learning (RL) methods face efficiency issues for exploration.  

Proposed Solution:
This paper proposes OpenContra, a co-training framework that combines LLMs and goal-conditioned RL (GRL) to construct an open-ended agent. The framework has two stages:

1. Independent Training: 
- Fine-tune an LLM to translate human instructions into structured goals based on environment states. Use multi-step prompting and fine-tuning strategies to enhance precision.
- Warm-start a GRL agent with non-goal RL to acquire basic skills. Then use curriculum strategies like hindsight goal generation to expand goal achievement space.

2. Collaborative Training:
- Continue to train LLM and GRL agent to mutually adapt and improve instruction consistency and goal achievement. 
- Use an RLAF method to provide multifactor rewards to LLM based on goal completion, key sub-goal presence, etc. Periodically reset LLM to avoid local optima.

The framework is evaluated on Contra, a complex battle royale game. Goals have 68 possible sub-dimensions, posing an open-ended challenge.

Main Contributions:
- Proposes one of the first practical frameworks to combine LLMs and RL for constructing open-ended embodied agents.
- Introduces comprehensive strategies for independent and collaborative training of components.
- Demonstrates promising performance on complex FPS game by generating high-quality goals for arbitrary instructions and achieving high goal completion ratios.
- Sets strong benchmark for future open-ended learning research by releasing Contra platform.

Overall the paper makes significant progress towards building practically useful open-ended agents that can handle diverse human instructions through an efficient LLM+RL approach.
