# [The Heuristic Core: Understanding Subnetwork Generalization in   Pretrained Language Models](https://arxiv.org/abs/2403.03942)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- The paper investigates why neural networks like BERT generalize well in-domain but fail on out-of-distribution datasets, even after fine-tuning. 

Approach
- The authors fine-tune BERT models on MNLI and QQP and evaluate generalization by testing on HANS, PAWS-QQP. 
- They prune models to different sparsity levels and find subnetworks that perform similarly in-domain but differ significantly out-of-domain.
- This leads them to hypothesize the "Competing Subnetworks" idea - that models represent multiple disjoint solutions initially and generalization emerges from competition.  

Main Findings
- Contrary to the initial hypothesis, different subnetworks share a large overlap of components, with 9 attention heads common across all subnetworks. 
- These heads form a "heuristic core" that attends to simple features like token overlaps.
- Ablating these heads hurts out-of-distribution accuracy super-additively, suggesting the rest of the model relies on them.
- The effective size to approximate the model increases during training, opposed to decreasing as per the initial hypothesis.

Conclusions
- The heuristic core provides simple cues that the rest of the model builds on top of to ultimately generalize.
- There is no evidence for distinct competing subnetworks underlying generalization.
- Understanding the role of the shared low-level heuristic computations is an important direction for improving generalization.

The summary covers the key points about the problem being studied, the pruning-based approach, the main findings related to the "competing subnetworks" hypothesis, and the higher-level conclusions regarding the role of the heuristic core in generalization.


## Summarize the paper in one sentence.

 The paper finds that subnetworks pruned from BERT models fine-tuned on NLI and paraphrasing tasks share a common set of attention heads that compute simple lexical overlap features, and these heads interact with the rest of the model to enable more complex reasoning and generalization.


## What is the main contribution of this paper?

 Based on the paper, the main contribution seems to be:

1) The finding that different subnetworks of a pruned BERT model perform similarly in-domain but generalize very differently out-of-domain. Sparser subnetworks also generalize worse in general.

2) The exploration of the "competing subnetworks" hypothesis to explain this behavior. Through analyses of subnetwork overlap and effective size, the paper finds evidence against this hypothesis. 

3) The identification of a "heuristic core" - a set of 9 attention heads that appear in all subnetworks and seem to capture simple features like token overlap. The paper shows these heads interact super-additively with the rest of the model to enable generalization.

So in summary, the key contributions are the empirical characterization of how subnetworks emerge and interact in pruned BERT models, the testing of the competing subnetworks hypothesis, and the in-depth analysis of the identified heuristic core attention heads and their role in generalization.


## What are the keywords or key terms associated with this paper?

 Based on the paper content, some of the key terms and concepts are:

- Competing subnetworks hypothesis - The hypothesis that models contain disjoint subnetworks representing distinct algorithms to fit the training data, and generalization depends on which subnetwork the model converges to.

- Effective size - The size of the smallest subnetwork that approximates the full model accuracy within some tolerance on a dataset. Used to measure model reliance on different components over training.

- Heuristic core - The set of 9 attention heads that appear in all subnetworks of the MNLI model, including non-generalizing ones. Seem to compute simple, overlapping features.

- Attention heads - The components of the Transformer architecture's multi-headed attention. Heads can develop specialized roles and their ablation impacts model behavior.

- Generalization - The ability of ML models to perform well on out-of-distribution data. A key challenge in NLP.

- Subnetworks - Smaller networks derived from pruning larger neural networks that approximate the original model. Can provide insights into model behavior.

- MNLI - A natural language inference dataset for evaluating generalization.

- QQP - Quora Question Pairs, a paraphrase dataset.

- PAWS - Paraphrase Adversaries from Word Scrambling, an adversarial paraphrase dataset.

- HANS - A dataset of heuristics and biases in NLP models.

So in summary, key terms cover subnetwork analysis, the competing subnetworks hypothesis, attention heads, generalization, and the NLP datasets used.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions I would ask about the method proposed in this paper:

1. The paper finds that different subnetworks of the same model generalize very differently on out-of-distribution data. Does this indicate that the full model essentially maintains multiple "hypotheses" about the data during training? Could we potentially track and utilize these multiple hypotheses in some way?

2. The paper introduces the notion of a "heuristic core" - a set of attention heads that appear in all subnetworks and seem to compute simple syntactic features. What role does this heuristic core play in generalization? Does it provide a "scaffolding" that allows other parts of the network to learn more complex behaviors? 

3. One interesting finding is that removing certain heads in the heuristic core significantly reduces out-of-distribution generalization. Does this mean these heads interact closely with the rest of the network to enable more sophisticated reasoning? What is the nature of these interactions?

4. The paper argues against the "Competing Subnetworks Hypothesis". What alternative hypothesis could better explain the findings? Is there a way to formally define and test this hypothesis?

5. The heuristic core heads appear tuned to extract word overlap and other shallow syntactic features. Are these features inherently baked into BERT's pre-training, or do they emerge from fine-tuning on MNLI? Is the emergent heuristic core task-specific?

6. How does the notion of a heuristic core relate to findings on model pruning and the lottery ticket hypothesis? Is the heuristic core the "winning ticket" that gets rediscovered across pruned subnetworks?

7. The paper studies generalization via subnetworks of the same model. How do these findings relate to recent work on model ensembles? Could an ensemble over subnetworks provide better generalization than any individual subnetwork?

8. The paper studies the BERT architecture specifically. Do similar heuristic cores emerge in other architectures like RNNs or Transformers without pre-training? Do different architectures learn different kinds of heuristics?

9. The heuristic core provides simple features to the rest of the network. Could we instead provide these features explicitly via an auxiliary loss rather than relying on the emergent heuristic core? Would this lead to better generalization?

10. The paper studies NLP models, but do similar findings hold in computer vision or other modalities? Do convolutional networks also develop similar heuristic shortcuts to solve tasks before learning more complex behaviors?
