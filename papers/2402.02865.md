# [On combining acoustic and modulation spectrograms in an attention   LSTM-based system for speech intelligibility level classification](https://arxiv.org/abs/2402.02865)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
The paper addresses the problem of automatically predicting the speech intelligibility level (low, medium or high) of people suffering from dysarthria. Dysarthric speech is characterized by poor articulation, rhythmic disturbances, etc. which negatively impacts speech comprehension. Prior works rely on compact features that discard temporal information or do not combine acoustic (short-term) and modulation (long-term) features.

Proposed Solution:  
The paper proposes LSTM neural network systems with attention mechanisms to model the temporal sequences of per-frame acoustic log-mel spectrograms (short-term features) and modulation spectrograms (long-term features). It also explores different strategies to combine these complementary features - late fusion (decision level) and weighted pooling (WP) fusion (utterance level). The attention mechanism assigns weights to frames based on their relevance to predict intelligibility.

Main Contributions:
1) Proposes using modulation spectrograms with LSTM, which has not been explored before for speech intelligibility prediction. Shows LSTM can model them effectively.

2) Explores different fusion strategies to combine complementary log-mel and modulation spectrograms in LSTM framework. Shows both late and WP fusion outperform individual systems, with WP fusion being the best.

3) Compares basic LSTM, mean pooling LSTM and attention LSTM architectures. Attention LSTM performs the best as it emphasizes relevant frames. 

4) The combined system with WP fusion and attention pooling achieved the lowest error rates, significantly outperforming individual and SVM-based baseline systems. This demonstrates the complementarity of log-mel and modulation features.

In summary, the key novelty is effectively combining complementary acoustic features using LSTM and attention for improved dysarthric speech intelligibility prediction performance.
