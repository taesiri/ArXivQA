# [Beware of Words: Evaluating the Lexical Richness of Conversational Large   Language Models](https://arxiv.org/abs/2402.15518)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is currently little understanding of how the linguistic features like lexical richness of texts generated by conversational large language models (LLMs) such as ChatGPT depend on factors like the model parameters and assigned role. 
- Evaluating these dependencies is important to understand the potential impact of conversational LLMs on the evolution of languages.

Proposed Solution:
- The paper proposes a methodology called "Cave Verba" to evaluate lexical richness of LLM-generated texts.
- It uses a dataset of over 500 prompts covering different tasks (essay writing, question answering) and topics (TOEFL, NYT, HC3). 
- Texts are generated by assigning ChatGPT different roles (age, gender, social class) and configuring model parameters (temperature, top probability, penalties).
- Four lexical richness metrics are computed: MATTR, MTLD, RTTR, Maas.

Key Contributions:
- Evaluation results reveal trends in how factors like presence penalty and model version impact lexical richness.
- Role assignment has little effect, except for child role which reduces richness.  
- A dataset and framework facilitating further research on lexical properties of LLM-generated texts.

In summary, the paper systematically evaluates how conversational LLM-generated text's lexical richness depends on model parameters and role context. A dataset and methodology are provided to enable deeper linguistic analysis of texts from modern conversational AI systems.
