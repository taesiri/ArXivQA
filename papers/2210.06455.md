# [Token-Label Alignment for Vision Transformers](https://arxiv.org/abs/2210.06455)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper tries to address is: How to make data mixing strategies like CutMix more effective when training vision transformers (ViTs)?The key hypothesis is that there is a token fluctuation phenomenon in ViTs that causes a mismatch between the token space and label space when using conventional data mixing strategies like CutMix. This reduces the effectiveness of CutMix for training ViTs. To address this, the paper proposes a token-label alignment (TL-Align) method to obtain more accurate training targets by tracing the correspondence between input tokens and transformed tokens and aligning the labels accordingly.In summary, the paper aims to improve the compatibility and effectiveness of CutMix for training vision transformers by proposing a simple yet effective method to align the tokens and labels to obtain more accurate training signals.
