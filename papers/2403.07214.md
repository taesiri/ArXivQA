# [Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers](https://arxiv.org/abs/2403.07214)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper explores using text-to-image diffusion models like Stable Diffusion for the first time as backbones for zero-shot sketch-based image retrieval (ZS-SBIR). ZS-SBIR aims to retrieve photos matching a query sketch from unseen categories not encountered during training. Most prior works use CNNs pretrained on ImageNet or other discriminative tasks as backbones. However, the paper hypothesizes that diffusion models pretrained on text-to-image generation can better bridge the sketch-photo domain gap due to their robust cross-modal capabilities and shape bias.  

Proposed Solution: 
The paper proposes adapting a frozen Stable Diffusion model for ZS-SBIR via prompt learning. This allows task-specific adaptation without losing the model's semantic knowledge. Two prompt learning strategies are used - (1) Visual prompts: soft image perturbations to the input images to guide feature extraction; (2) Textual prompts: learnable text embeddings that influence the model's internal representations. The prompts are learned end-to-end with a triplet loss while keeping SD frozen. Additionally, feature ensembling is used during inference for stability.  

For category-level retrieval, earlier SD decoder layers capture coarse semantics and are used. For fine-grained retrieval, latter decoder layers capturing fine details are used. The method can handle both category-level and cross-category fine-grained ZS-SBIR without model fine-tuning.

Main Contributions:
- First work exploring text-to-image diffusion models for ZS-SBIR by harnessing their cross-modal transferability.
- Adaptation via prompt learning without fine-tuning the frozen model.
- Suitability for both category-level and fine-grained ZS-SBIR demonstrated through extensive experiments. 
- Significantly outperforms prior ZS-SBIR methods on multiple benchmarks.
- Better stability in low-data regimes owing to diffusion model's generalization ability.
- Extension to leverage available text for enhanced sketch+text based retrieval.

In summary, the paper successfully adapts diffusion models using prompt learning for advanced ZS-SBIR capabilities not shown before.
