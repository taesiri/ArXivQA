# [How well do LLMs cite relevant medical references? An evaluation   framework and analyses](https://arxiv.org/abs/2402.02008)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like GPT-4 are being considered for medical question answering. However, there are concerns about their propensity to hallucinate information not backed by evidence.  
- In medicine, providing accurate references is crucial for building user trust and avoiding potential patient harm from erroneous information.  
- Evaluating the quality of LLM-generated medical references has been limited by the need for expensive expert annotations.

Methods:
- The authors propose an automated framework called \textit{SourceCheckup} to evaluate LLM reference quality without human verification.
- Questions are algorithmically generated from medical documents. LLM responses to these questions are parsed into statement-source pairs that are automatically scored by a Reference Verifier module.  
- The Reference Verifier comprises the GPT-4 model fine-tuned to determine if a statement is supported by an accompanying source text.
- The authors demonstrate high (88%) agreement between GPT-4 Reference Verifier decisions and expert clinician judgments.

Experiments and Results:  
- Five top LLMs were evaluated on 1200 generated medical questions using three quality metrics related to validity of provided URLs and extent of statement/response support.
- The best performing LLM was GPT-4 (RAG), aided by search engine access, but still âˆ¼50% of its responses had unsupported statements.
- Without search access, other LLMs had 40-70% invalid URLs and could fully support only 7-22% of responses.
- Questions from Reddit elicited poorer performance than professional medical sites for all models.

Contributions:
- A scalable evaluation framework to score LLM medical reference quality without human verification
- Evidence that leading LLMs still perform inadequately as medical references 
- A dataset of algorithmically-constructed medical questions and expert annotations

The paper demonstrates an important gap in existing LLC capabilities to reliably provide medical evidence. The proposed benchmarking approach enables continued assessment of progress in this crucial facet of trustworthy medical LLMs.
