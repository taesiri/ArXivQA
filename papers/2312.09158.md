# [General Object Foundation Model for Images and Videos at Scale](https://arxiv.org/abs/2312.09158)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper introduces GLEE, a general object foundation model for locating and identifying objects in images and videos. GLEE is trained on over 5 million images across diverse datasets with varying levels of annotation granularity. It employs a unified framework consisting of an image encoder, text encoder, and visual prompter to handle multiple input modalities. This allows GLEE to concurrently solve a wide range of object-centric tasks including detection, segmentation, tracking, and grounding while maintaining state-of-the-art performance. A key advantage is that GLEE demonstrates strong zero-shot transfer capabilities to new datasets and tasks without requiring any task-specific fine-tuning. Experiments validate its versatility - GLEE outperforms specialist models designed for individual tasks and other generalist models attempting to handle multiple tasks. By incorporating 10 million automatically labeled images, its generalization ability is further improved. Moreover, GLEE provides the detailed object-level visual information currently missing from large language models, showing potential as a foundation for multimodal LLMs. The unified paradigm, task coverage, generalization ability and integration potential establish GLEE as a leading step towards versatile visual foundation models for object-centric understanding.
