# [Debating with More Persuasive LLMs Leads to More Truthful Answers](https://arxiv.org/abs/2402.06782)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: As AI systems continue to advance, they will eventually surpass human capabilities. This poses an alignment challenge - how can weaker systems provide oversight over more capable systems when traditional approaches of using human-labeled data and evaluation will no longer be feasible. 

Proposed Solution: The paper proposes using debate between AI systems as a mechanism for oversight and alignment. In a debate setup, two expert models argue for opposing answers to a question while a weaker, non-expert model or human acts as a judge to determine the winning side. The key intuition is that identifying truth may be easier than generating truth.

The paper specifically looks at an information-asymmetric setup using the QuALITY reading comprehension dataset. Expert models have access to the full passages while non-expert judges do not, simulating stronger vs weaker systems. 

Main Contributions:

- Show that both human and AI judges can use debate to accurately answer questions, outperforming non-adversarial consultancy baselines. Humans and AI judges achieve 88% and 76% accuracy with debate.

- Find that optimizing experts for "persuasiveness" also makes them better at arguing for the correct side - an advantage increases as persuasiveness increases. This suggests training via debate could improve truthfulness.

- Surface challenges unique to AI judges - biases like verbosity, position and overconfidence. Mitigation strategies and judge iterations are provided.

- Establish unsupervised metrics like Elo ratings and aggregate win rate that enable optimizing debates without human labels.

- Demonstrate scalability to different expert base models and generalization to unseen judges.

The results provide encouraging evidence that weaker systems can help align stronger systems using debate as one oversight approach, presenting opportunities for further research.
