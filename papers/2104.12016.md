# [Learning Passage Impacts for Inverted Indexes](https://arxiv.org/abs/2104.12016)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question addressed is: How can we develop a document term weighting scheme that is effective for first-stage retrieval using a standard inverted index, leveraging contextualized language models like BERT?The key ideas and contributions in the paper are:- Proposing a new method called DeepImpact (MultiBERT) that learns impact scores for terms in expanded documents to address vocabulary mismatch.- MultiBERT improves impact score modeling by jointly learning term impacts across query terms occurring in a passage, rather than training each term's impact in isolation. - MultiBERT expands documents using DocT5Query before computing impact scores to inject new terms and tackle vocabulary mismatch.- Experiments show MultiBERT significantly outperforms prior first-stage retrieval methods, improving ranking effectiveness on MS MARCO passage ranking task.- When used for candidate generation before re-ranking, MultiBERT matches or exceeds effectiveness of methods using approximate nearest neighbor search, while being much faster.So in summary, the central research question is how to develop an effective and efficient term weighting scheme using contextualized language models and inverted indexes. The key proposal is the MultiBERT method that learns impact scores over expanded documents to address this.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a new first-stage retrieval method called DeepImpact (MultiBERT) that produces more effective term weights for documents which can be stored in a standard inverted index. The key ideas are:- Using DocT5Query document expansion to enrich documents with additional terms to help address vocabulary mismatch between queries and documents.- Learning impact scores for terms in expanded documents using BERT, by directly optimizing the sum of query term impacts to maximize score difference between relevant and non-relevant documents. This allows impact scores to be learned jointly rather than independently.- Storing the learned impact scores in a quantized form in the inverted index, and using them for efficient first-stage retrieval.- Showing experimentally that DeepImpact outperforms previous inverted index based methods like BM25, DeepCT, and BM25+DocT5Query on the MS MARCO dataset. It also matches or exceeds the effectiveness of neural methods like ColBERT while being much faster.So in summary, the main contribution is a new way of learning and using term weights in an inverted index using document expansion and contextualized language models like BERT, which results in improved effectiveness and efficiency for first-stage ranking.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a new term weighting method called DeepImpact that improves retrieval effectiveness by expanding documents with relevant terms using DocT5Query and then directly learning impact scores for query terms using BERT, outperforming BM25, DeepCT, and DocT5Query baselines while also being efficient when used for first-stage retrieval before neural re-ranking.


## How does this paper compare to other research in the same field?

Here are my thoughts on how this paper compares to other related research:- This paper focuses on improving first-stage retrieval for neural ranking systems by learning better term weights/impacts for an inverted index. This differentiates it from work like ColBERT and EPIC that focus on re-ranking, as well as other techniques like doc2query that expand documents for improved ranking but still rely on BM25.- Compared to DeepCT which also learns term weights for an inverted index, this paper proposes a more effective way of modeling term impacts jointly rather than independently. The proposed MultiBERT method optimizes the sum of query term impacts directly for ranking, allowing for richer interactions.- MultiBERT also incorporates document expansion using doc2query to help address vocabulary mismatch issues, making it more robust. The combination of expansion and jointly learned impacts appears to be more effective than either approach alone.- Experiments show solid improvements over methods like BM25, DeepCT, and doc2query in first stage retrieval. When combined with ColBERT re-ranking, MultiBERT matches or exceeds end-to-end ColBERT effectiveness while being much faster.- The gains over doc2query and DeepCT are meaningful but not gigantic. However, directly optimizing term impacts for ranking vs regressing to BM25 weights seems to be a better learning approach. There is likely more room for improvement in the expansion and impact modeling.In summary, this paper makes reasonable incremental progress over prior work in learning representations for first stage retrieval. The joint impact modeling and document expansion appear beneficial, though there is likely room to push these ideas further. The results help validate the overall direction of learning neural retrievers optimized for inverted index ranking.
