# [Learning Passage Impacts for Inverted Indexes](https://arxiv.org/abs/2104.12016)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question addressed is: How can we develop a document term weighting scheme that is effective for first-stage retrieval using a standard inverted index, leveraging contextualized language models like BERT?The key ideas and contributions in the paper are:- Proposing a new method called DeepImpact (MultiBERT) that learns impact scores for terms in expanded documents to address vocabulary mismatch.- MultiBERT improves impact score modeling by jointly learning term impacts across query terms occurring in a passage, rather than training each term's impact in isolation. - MultiBERT expands documents using DocT5Query before computing impact scores to inject new terms and tackle vocabulary mismatch.- Experiments show MultiBERT significantly outperforms prior first-stage retrieval methods, improving ranking effectiveness on MS MARCO passage ranking task.- When used for candidate generation before re-ranking, MultiBERT matches or exceeds effectiveness of methods using approximate nearest neighbor search, while being much faster.So in summary, the central research question is how to develop an effective and efficient term weighting scheme using contextualized language models and inverted indexes. The key proposal is the MultiBERT method that learns impact scores over expanded documents to address this.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a new first-stage retrieval method called DeepImpact (MultiBERT) that produces more effective term weights for documents which can be stored in a standard inverted index. The key ideas are:- Using DocT5Query document expansion to enrich documents with additional terms to help address vocabulary mismatch between queries and documents.- Learning impact scores for terms in expanded documents using BERT, by directly optimizing the sum of query term impacts to maximize score difference between relevant and non-relevant documents. This allows impact scores to be learned jointly rather than independently.- Storing the learned impact scores in a quantized form in the inverted index, and using them for efficient first-stage retrieval.- Showing experimentally that DeepImpact outperforms previous inverted index based methods like BM25, DeepCT, and BM25+DocT5Query on the MS MARCO dataset. It also matches or exceeds the effectiveness of neural methods like ColBERT while being much faster.So in summary, the main contribution is a new way of learning and using term weights in an inverted index using document expansion and contextualized language models like BERT, which results in improved effectiveness and efficiency for first-stage ranking.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a new term weighting method called DeepImpact that improves retrieval effectiveness by expanding documents with relevant terms using DocT5Query and then directly learning impact scores for query terms using BERT, outperforming BM25, DeepCT, and DocT5Query baselines while also being efficient when used for first-stage retrieval before neural re-ranking.


## How does this paper compare to other research in the same field?

Here are my thoughts on how this paper compares to other related research:- This paper focuses on improving first-stage retrieval for neural ranking systems by learning better term weights/impacts for an inverted index. This differentiates it from work like ColBERT and EPIC that focus on re-ranking, as well as other techniques like doc2query that expand documents for improved ranking but still rely on BM25.- Compared to DeepCT which also learns term weights for an inverted index, this paper proposes a more effective way of modeling term impacts jointly rather than independently. The proposed MultiBERT method optimizes the sum of query term impacts directly for ranking, allowing for richer interactions.- MultiBERT also incorporates document expansion using doc2query to help address vocabulary mismatch issues, making it more robust. The combination of expansion and jointly learned impacts appears to be more effective than either approach alone.- Experiments show solid improvements over methods like BM25, DeepCT, and doc2query in first stage retrieval. When combined with ColBERT re-ranking, MultiBERT matches or exceeds end-to-end ColBERT effectiveness while being much faster.- The gains over doc2query and DeepCT are meaningful but not gigantic. However, directly optimizing term impacts for ranking vs regressing to BM25 weights seems to be a better learning approach. There is likely more room for improvement in the expansion and impact modeling.In summary, this paper makes reasonable incremental progress over prior work in learning representations for first stage retrieval. The joint impact modeling and document expansion appear beneficial, though there is likely room to push these ideas further. The results help validate the overall direction of learning neural retrievers optimized for inverted index ranking.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors are:- Improving the underlying neural relevance model in DeepImpact:1) Experimenting with more relaxed/fuzzy matching between query and document terms, rather than exact term match.2) Improving the term expansion techniques used to tackle vocabulary mismatch, using more sophisticated methods. - Optimizing the query processing speed of DeepImpact:3) Investigating how changing the distribution of learned impact scores affects efficiency of query processing algorithms like MaxScore. 4) Developing techniques to optimize DeepImpact's query processing speed to match other inverted index-based methods.- Exploring modifications and extensions to the DeepImpact framework:5) Trying different neural network architectures and training techniques.6) Applying DeepImpact to other IR tasks beyond passage ranking like document ranking.7) Combining DeepImpact with other types of indexes like learned sparse indexes.8) Experimenting with different decoding methods to compute document scores from term impacts.The key areas seem to be improving the neural relevance model itself, optimizing the query processing efficiency, and exploring modifications and extensions to the overall DeepImpact framework. The authors have laid out an interesting research agenda to build upon their proposed approach.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the key points from the paper:The paper proposes a new neural ranking model called DeepImpact for first-stage retrieval using standard inverted indexes. DeepImpact improves upon prior work like DeepCT and DocT5Query by jointly learning impact scores for query terms over expanded documents. It leverages DocT5Query to expand documents with relevant terms to handle vocabulary mismatch. Then it uses a contextualized language model like BERT to estimate importance scores for each unique term in the expanded documents. These scores are stored in a standard inverted index and summed at query time for documents matching the query terms. Experiments on the MS MARCO dataset show DeepImpact significantly outperforms prior inverted index methods like BM25, DeepCT, and BM25+DocT5Query as a first stage ranker. It also matches or exceeds the effectiveness of state-of-the-art neural ranking methods like ColBERT when used for candidate generation, while being much more efficient. Overall, DeepImpact demonstrates improved effectiveness and efficiency by combining document expansion and jointly learned term impacts with standard inverted index retrieval.
