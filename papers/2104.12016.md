# [Learning Passage Impacts for Inverted Indexes](https://arxiv.org/abs/2104.12016)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question addressed is: 

How can we develop a document term weighting scheme that is effective for first-stage retrieval using a standard inverted index, leveraging contextualized language models like BERT?

The key ideas and contributions in the paper are:

- Proposing a new method called DeepImpact (MultiBERT) that learns impact scores for terms in expanded documents to address vocabulary mismatch.

- MultiBERT improves impact score modeling by jointly learning term impacts across query terms occurring in a passage, rather than training each term's impact in isolation. 

- MultiBERT expands documents using DocT5Query before computing impact scores to inject new terms and tackle vocabulary mismatch.

- Experiments show MultiBERT significantly outperforms prior first-stage retrieval methods, improving ranking effectiveness on MS MARCO passage ranking task.

- When used for candidate generation before re-ranking, MultiBERT matches or exceeds effectiveness of methods using approximate nearest neighbor search, while being much faster.

So in summary, the central research question is how to develop an effective and efficient term weighting scheme using contextualized language models and inverted indexes. The key proposal is the MultiBERT method that learns impact scores over expanded documents to address this.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a new first-stage retrieval method called DeepImpact (MultiBERT) that produces more effective term weights for documents which can be stored in a standard inverted index. The key ideas are:

- Using DocT5Query document expansion to enrich documents with additional terms to help address vocabulary mismatch between queries and documents.

- Learning impact scores for terms in expanded documents using BERT, by directly optimizing the sum of query term impacts to maximize score difference between relevant and non-relevant documents. This allows impact scores to be learned jointly rather than independently.

- Storing the learned impact scores in a quantized form in the inverted index, and using them for efficient first-stage retrieval.

- Showing experimentally that DeepImpact outperforms previous inverted index based methods like BM25, DeepCT, and BM25+DocT5Query on the MS MARCO dataset. It also matches or exceeds the effectiveness of neural methods like ColBERT while being much faster.

So in summary, the main contribution is a new way of learning and using term weights in an inverted index using document expansion and contextualized language models like BERT, which results in improved effectiveness and efficiency for first-stage ranking.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a new term weighting method called DeepImpact that improves retrieval effectiveness by expanding documents with relevant terms using DocT5Query and then directly learning impact scores for query terms using BERT, outperforming BM25, DeepCT, and DocT5Query baselines while also being efficient when used for first-stage retrieval before neural re-ranking.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this paper compares to other related research:

- This paper focuses on improving first-stage retrieval for neural ranking systems by learning better term weights/impacts for an inverted index. This differentiates it from work like ColBERT and EPIC that focus on re-ranking, as well as other techniques like doc2query that expand documents for improved ranking but still rely on BM25.

- Compared to DeepCT which also learns term weights for an inverted index, this paper proposes a more effective way of modeling term impacts jointly rather than independently. The proposed MultiBERT method optimizes the sum of query term impacts directly for ranking, allowing for richer interactions.

- MultiBERT also incorporates document expansion using doc2query to help address vocabulary mismatch issues, making it more robust. The combination of expansion and jointly learned impacts appears to be more effective than either approach alone.

- Experiments show solid improvements over methods like BM25, DeepCT, and doc2query in first stage retrieval. When combined with ColBERT re-ranking, MultiBERT matches or exceeds end-to-end ColBERT effectiveness while being much faster.

- The gains over doc2query and DeepCT are meaningful but not gigantic. However, directly optimizing term impacts for ranking vs regressing to BM25 weights seems to be a better learning approach. There is likely more room for improvement in the expansion and impact modeling.

In summary, this paper makes reasonable incremental progress over prior work in learning representations for first stage retrieval. The joint impact modeling and document expansion appear beneficial, though there is likely room to push these ideas further. The results help validate the overall direction of learning neural retrievers optimized for inverted index ranking.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors are:

- Improving the underlying neural relevance model in DeepImpact:

1) Experimenting with more relaxed/fuzzy matching between query and document terms, rather than exact term match.

2) Improving the term expansion techniques used to tackle vocabulary mismatch, using more sophisticated methods. 

- Optimizing the query processing speed of DeepImpact:

3) Investigating how changing the distribution of learned impact scores affects efficiency of query processing algorithms like MaxScore. 

4) Developing techniques to optimize DeepImpact's query processing speed to match other inverted index-based methods.

- Exploring modifications and extensions to the DeepImpact framework:

5) Trying different neural network architectures and training techniques.

6) Applying DeepImpact to other IR tasks beyond passage ranking like document ranking.

7) Combining DeepImpact with other types of indexes like learned sparse indexes.

8) Experimenting with different decoding methods to compute document scores from term impacts.

The key areas seem to be improving the neural relevance model itself, optimizing the query processing efficiency, and exploring modifications and extensions to the overall DeepImpact framework. The authors have laid out an interesting research agenda to build upon their proposed approach.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points from the paper:

The paper proposes a new neural ranking model called DeepImpact for first-stage retrieval using standard inverted indexes. DeepImpact improves upon prior work like DeepCT and DocT5Query by jointly learning impact scores for query terms over expanded documents. It leverages DocT5Query to expand documents with relevant terms to handle vocabulary mismatch. Then it uses a contextualized language model like BERT to estimate importance scores for each unique term in the expanded documents. These scores are stored in a standard inverted index and summed at query time for documents matching the query terms. Experiments on the MS MARCO dataset show DeepImpact significantly outperforms prior inverted index methods like BM25, DeepCT, and BM25+DocT5Query as a first stage ranker. It also matches or exceeds the effectiveness of state-of-the-art neural ranking methods like ColBERT when used for candidate generation, while being much more efficient. Overall, DeepImpact demonstrates improved effectiveness and efficiency by combining document expansion and jointly learned term impacts with standard inverted index retrieval.


## Summarize the paper in two paragraphs.

 Here is a summary of the key points from the paper in two paragraphs:

The paper proposes a new term weighting scheme called DeepImpact that can be used with inverted indexes for efficient first-stage retrieval. DeepImpact improves upon prior work like DeepCT and DocT5Query by jointly learning term impact scores over expanded documents. Specifically, it first expands documents with DocT5Query to inject new terms and address vocabulary mismatch issues. It then uses a BERT-based model to directly estimate semantic term importance and produce a single impact score per term that is stored in the inverted index. 

Experiments on the MS MARCO dataset show DeepImpact outperforms previous first-stage ranking methods by up to 17% in effectiveness compared to DocT5Query. When used in a two-stage ranking pipeline, DeepImpact matched or exceeded the effectiveness of state-of-the-art approaches like ColBERT while being up to 5x faster. Key benefits are higher recall for candidate generation and improved re-ranking effectiveness due to better initial results. Future work includes exploring different matching schemes beyond exact term matching, improving term expansion techniques, and optimizing query processing speed based on the impact score distribution.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes a new first-stage retrieval method called DeepImpact that learns impact scores for terms in expanded documents which can be stored in an inverted index for efficient retrieval. DeepImpact first expands documents using DocT5Query to inject new terms to address vocabulary mismatch. It then uses a contextualized language model like BERT to estimate the semantic importance of each token in the expanded documents, producing a single impact score per unique term. These scores are summed up for matching query terms to get a query-document score. DeepImpact is trained end-to-end to maximize this score difference for relevant vs non-relevant passages. The impact scores are quantized and stored in an inverted index, which allows efficient retrieval compared to neural ranking approaches. Experiments show DeepImpact significantly outperforms baselines like BM25 and DeepCT in first-stage ranking, and competes with or outperforms neural rankers like ColBERT in a re-ranking pipeline while being much faster.


## What problem or question is the paper addressing?

 Based on my reading, the key points about the problem and questions addressed in this paper are:

- Neural ranking models like BERT have shown great effectiveness for search tasks, but are too slow for production deployment due to their complexity. The paper aims to address this problem.

- Prior work has proposed methods to speed up neural ranking by precomputing document representations (e.g. EPIC, PreTTR, ColBERT) or learning term weights (DeepCT). However, these have limitations. 

- DeepCT learns term weights independently, not optimizing for ranking directly. DocT5Query improves ranking but still uses BM25 weighting. 

- The paper proposes DeepImpact, which jointly learns term impacts over expanded documents to better optimize ranking effectiveness while enabling efficient retrieval using an inverted index.

- Specifically, the questions addressed are:

1) Can we learn a better model of term impacts for ranking compared to prior work? 

2) Can we address vocabulary mismatch and improve ranking by expanding documents?

3) Can DeepImpact outperform prior first-stage retrieval methods in effectiveness and speed?

4) How does DeepImpact compare to state-of-the-art neural methods when used in a re-ranking pipeline?

In summary, the key problem is enabling fast and effective neural ranking, which prior work is limited on. DeepImpact proposes a new method to learn term impacts over expanded documents to improve effectiveness and efficiency compared to prior approaches.
