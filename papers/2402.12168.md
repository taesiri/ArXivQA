# [Defending Against Weight-Poisoning Backdoor Attacks for   Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2402.12168)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Parameter-efficient fine-tuning (PEFT) methods like LoRA, Prompt-tuning, P-tuning v1/v2 have been proposed to reduce memory consumption when fine-tuning large language models. 
- However, the paper shows that PEFT methods are more vulnerable to weight poisoning backdoor attacks compared to full parameter fine-tuning. Backdoors injected during pre-training remain exploitable even after PEFT fine-tuning.

Proposed Solution:
- The paper proposes a Poisoned Sample Identification Module (PSIM) to defend against such attacks by identifying poisoned inputs. 
- PSIM is trained using PEFT on a dataset with random label resetting. This allows PSIM to maintain high confidence for poisoned samples but low confidence for clean samples.
- During inference, samples with confidence scores from PSIM exceeding a threshold are classified as poisoned and excluded.

Key Contributions:
- First work examining security implications of PEFT methods against weight poisoning attacks. Shows PEFT is more susceptible to retaining backdoors.
- Proposes PSIM module that leverages confidence scores to effectively identify poisoned inputs.
- Comprehensive experiments on multiple datasets, language models and attack methods demonstrate efficiency of the defense method.
- Achieves high attack mitigation rates while maintaining accuracy on clean samples.

In summary, the paper uncovers security risks of PEFT against backdoor attacks and contributes PSIM, a novel defense method that can reliably detect poisoned inputs to defend against such backdoor attacks.
