# [Lenses and Learners](https://arxiv.org/abs/1903.03671)

## What is the central research question or hypothesis that this paper addresses?

 This paper explores the mathematical relationship between lenses and learners. The central result is a theorem showing that there is a faithful, identity-on-objects, symmetric monoidal functor from the category of learners to a category of symmetric lenses. 

Specifically, the paper shows:

- Learners can be viewed as asymmetric lenses between a parameter set and an output set. 

- Learners can also be viewed as symmetric lenses, with the left leg being a constant complement lens and the right leg being the asymmetric lens corresponding to the learner.

- The composition and monoidal product of learners corresponds precisely to the composition and monoidal product of these symmetric lenses.

So in summary, the central result is a precise correspondence between learners and a certain class of symmetric lenses, established via a symmetric monoidal functor. This reveals a surprising connection between the compositional treatment of supervised learning algorithms (learners) and bidirectional transformations (lenses).


## What is the main contribution of this paper?

 The main contribution of this paper is establishing a connection between the concepts of lenses and learners by showing that there is a faithful, identity-on-objects, symmetric monoidal functor embedding the category of learners into a category of symmetric lenses. 

Specifically, the paper shows:

- Learners can be viewed as asymmetric lenses between the parameter set and the input/output sets.

- Learners can also be viewed as symmetric lenses with a constant complement left leg and a bare asymmetric lens right leg. 

- There is a functor embedding the category of learners into a category of symmetric lenses of this form that preserves composition and monoidal products.

In summary, the paper reveals a tight mathematical relationship between lenses and learners by constructing a functor between their categories that preserves the compositional structure. This is a surprising and novel connection between two previously disjoint fields.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper shows there is a close relationship between lenses, which model bidirectional transformations, and learners, which model supervised learning algorithms, by constructing functors between categories of lenses and learners that preserve the compositional structure.


## How does this paper compare to other research in the same field?

 Here are a few key points about how this paper compares to other related research on lenses and learners:

- It establishes a novel connection between the concept of "lenses" from bidirectional programming and "learners" from machine learning. Prior to this work, these two areas were seen as largely unrelated. The authors show there is actually a close mathematical relationship between them.

- The paper provides a functor embedding the category of learners into a category of symmetric lenses. This shows that learners can be viewed as a special type of symmetric lens, with constant complement lenses on the left and bare lenses on the right. 

- It generalizes the usual notion of symmetric lens composition, which normally requires well-behavedness. The authors define composition for symmetric lenses where only the left leg satisfies PutGet, allowing bare lenses on the right.

- The work suggests properties like PutGet and GetPut could be desirable for learners ("learner laws"). This frames supervised learning in terms of established lens concepts.

- The simple bare lenses corresponding to learners are not typical in lens research, which has focused more on well-behaved lenses. This demonstrates a novel application of bare lenses.

- The constant complement left legs link learners to other advanced lens concepts like amendment lenses. The paper speculates on further connections in this direction.

Overall, the key novelty is establishing a formal relationship between lenses and learners, two previously disparate areas. This sheds new light on both fields and suggests many directions for further research integrating their concepts and techniques.


## What future research directions do the authors suggest?

 The authors suggest two main directions for future research:

1. Laws for well-behaved learners: The lens laws suggest analogous "learner laws" that could help frame and guide the development of learning algorithms. In particular, the authors discuss generalizations of the GetPut and PutGet laws to the I-UR and UR-I laws. While real-world learning algorithms may violate these ideal laws for practical reasons, studying them could provide useful insights.

2. Links with multiary lenses: The authors note an interesting similarity between the symmetric lenses used in this paper (with left leg constant complement and right leg bare lenses) and the symmetric lenses used in another Bx paper (with left leg closed spg-lenses and right leg arbitrary spg-lenses). They suggest further exploring the parallels between these two structures and what it might mean.

In summary, the main suggested research directions are:

- Developing well-behavedness laws for learners based on lens laws

- Exploring connections between the symmetric lenses used here and in other Bx work on multiary lenses

The authors believe these could be fruitful areas to better understand relationships between lenses and learners.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points in the paper:

This paper establishes surprising connections between the compositional treatment of supervised learning algorithms, known as learners, and mathematical structures called lenses that are used to model bidirectional transformations. The main result is a functor embedding the category of asymmetric lenses into the category of learners. This shows that learners, which provide a framework for modeling machine learning algorithms compositionally, can be represented faithfully as a certain type of symmetric lens. Specifically, learners correspond to spans of asymmetric lenses, with constant complement lenses on the left and bare asymmetric lenses on the right. Through this correspondence, properties of lenses suggest analogous laws that well-behaved learners may satisfy. The links revealed between these two previously disjoint areas open up new directions for research at their interface.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper establishes mathematical links between two different fields: bidirectional transformations modeled using lenses, and supervised learning algorithms modeled using learners. The main result is a functor embedding the category of learners into a category of symmetric lenses. Specifically, every learner can be viewed as a symmetric lens with a constant complement left leg and a bare asymmetric lens right leg. The functor preserves identities, monoidal products, and crucially composition. This shows that learners and lenses are closely related mathematically. 

After presenting background on lenses and learners, their composition and monoidal structure, the paper proves the main theorem constructing the functor. It then discusses consequences such as possible learner laws analogous to lens laws, and connections to other recent work on amendment lenses. The similarity between the structures used here and in independent work on multiary lenses is highlighted. The paper concludes by summarizing the main results and suggesting directions for further research. Overall, this paper reveals an unexpected yet robust relationship between the theory of lenses and learners.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper establishes a connection between the concepts of lenses and learners. Lenses are a way to model bidirectional transformations, while learners provide a compositional framework for supervised learning algorithms. The main result of the paper is constructing a faithful, identity-on-objects, symmetric monoidal functor from the category of learners to a category of symmetric lenses. Specifically, the functor maps each learner to a symmetric lens whose left leg is a constant complement lens and whose right leg is a bare asymmetric lens. The composition and monoidal structure is shown to be preserved under this mapping. Overall, the paper shows that learners can be represented as a specialized form of symmetric lenses, revealing an unexpected mathematical relationship between these two areas.


## What problem or question is the paper addressing?

 The paper is addressing the relationship between two areas: lenses and learners. Specifically, it is investigating the links between:

- Lenses, which are a way to model bidirectional transformations (like between a database and a view of it). Lenses can be asymmetric or symmetric. They form the morphisms of a monoidal category.

- Learners, which provide a compositional way to model supervised learning algorithms. Learners also form the morphisms of a monoidal category. 

The main question the paper is investigating is: what is the mathematical relationship between lenses and learners? Despite seeming quite different on the surface, the paper shows that there are actually close connections between the two concepts.

The main result is the construction of a faithful, identity-on-objects symmetric monoidal functor that embeds a category of asymmetric lenses into the category of learners. Furthermore, there is a similar functor embedding learners into a category of symmetric lenses. 

So in summary, the paper establishes tight mathematical links between the previously separate concepts of lenses and learners. It shows they are closely related in a formal, categorical sense.
