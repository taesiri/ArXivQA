# [Calibrating Large Language Models with Sample Consistency](https://arxiv.org/abs/2402.13904)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like GPT-3 often make unreliable predictions, so accurately gauging their confidence is important for reliability. 
- However, LLMs are poorly calibrated out-of-the-box and conventional calibration methods are infeasible for recent massive proprietary LLMs due to high computational costs.

Proposed Solution: 
- Use consistency of multiple randomly sampled model generations as an indicator of confidence, instead of just using the agreement between samples as done in prior work.
- Specifically, study three consistency measures that focus on different aspects:
    - Agreement-based: Percentage of samples that agree with the majority answer 
    - Entropy-based: Normalized entropy of the distribution of sampled answers
    - First-Second distance (FSD): Difference in agreement percentage between the top two most popular answers

Main Contributions:
- Show that all three consistency measures significantly outperform existing post-hoc calibration methods across various open/closed-source LLMs and diverse reasoning tasks
- Find that generating explanations before answers, larger model sizes, and more samples improve calibration; instruction tuning hurts it
- Demonstrate the potential of consistency measures to not only provide reliable confidence but also enhance model performance in an oracle experiment 
- Offer practical guidance on choosing suitable consistency metrics based on model characteristics and tasks

In summary, this paper extensively validates consistency-based approaches for eliciting confidence in LLMs, reveals several factors that influence calibration, and provides both methodology and empirical evidence for building more reliable LLMs.
