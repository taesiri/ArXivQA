# [ContraQA: Question Answering under Contradicting Contexts](https://arxiv.org/abs/2110.07803)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How do question answering (QA) models behave under contradicting contexts that contain a mix of both real and fake/misleading information?The key aspects are:- The paper investigates the impact of misinformation/disinformation on QA models by constructing contradicting contexts that mix real information with fake information created both manually (by humans) and automatically (by neural models). - The hypothesis seems to be that existing QA models will struggle or be misled when presented with these kinds of contradicting contexts containing misinformation. - The paper aims to analyze the vulnerability of QA models to misinformation and propose methods to build more robust QA systems that can handle contradicting contexts.So in summary, the central research question is investigating and analyzing how QA models perform on contradicting contexts with real + fake information, in order to understand their vulnerability to misinformation and explore ways to improve robustness. The key hypothesis is that current QA models will struggle with such contexts.
