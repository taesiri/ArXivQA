# [Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based   Agents](https://arxiv.org/abs/2402.11208)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Large language models (LLMs) have been used to create powerful LLM-based agents for complex real-world tasks. However, the security vulnerabilities of these agents have not been fully explored. 
- Backdoor attacks pose a serious threat - they inject a backdoor into models to manipulate outputs when an input trigger is present. Prior work has shown LLMs are vulnerable, but backdoor attacks may manifest differently for agents.

Proposed Solution:
- Formulate a general framework of backdoor attacks on LLM-based agents. Show the larger output space compared to LLMs enables more attack possibilities.
- Categorize concrete forms of attacks into: (1) modifying final output distribution (2) only manipulating intermediate reasoning while keeping final output correct.
- In the first category, the trigger can be in the user query (Query-Attack) or in an observation (Observation-Attack). In the second category, the attack is on the reasoning process (Thought-Attack).
- Propose data poisoning mechanisms to implement the above attacks on web shopping and tool utilization tasks.  

Key Contributions:
- First comprehensive study investigating backdoor threats specific to LLM-based agents.
- Analysis of the expanded attack surface compared to LLMs and categorization of different forms of attacks.
- Experimental validation of attacks - results show agents are highly vulnerable to various backdoor attacks.
- Highlights the urgent need for developing defenses against backdoor attacks on LLM-based agents.
