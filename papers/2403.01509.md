# [Fantastic Semantics and Where to Find Them: Investigating Which Layers   of Generative LLMs Reflect Lexical Semantics](https://arxiv.org/abs/2403.01509)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Large language models (LLMs) like GPT have shown impressive performance on language tasks, but it's unclear to what extent they capture lexical semantics - the meanings of words in context. 
- This is unlike BERT models which are trained on masked language modeling so likely better encode semantics of the current word.  
- LLMs are autoregressive, so only have access to previous context. Also, higher layers may "forget" semantics as they focus more on next token prediction.

Proposed Solution:
- Probe the hidden states of different layers of the Llama2 LLM on the Word in Context (WiC) dataset to evaluate lexical semantics.
- Use cosine similarity between representations of the same word in different contexts to classify if the meaning is the same.
- Try different input formats like repeating context or prompting to provide more context.

Key Findings:
- Lower layers of Llama2 capture lexical semantics better, while higher layers focus more on prediction. This tradeoff is opposite to BERT.
- Simple techniques like repeating context can significantly improve performance over just using hidden states from target word.
- Prompting gives best results but relies more on the prompt engineering.
- Nouns are easier to disambiguate than verbs. 
- Removing anisotropy in embedding space consistently helps.

Main Contributions:
- Provides analysis and insights into how lexical semantics emerges in layers of autoregressive LLMs vs BERT.
- Gives guidance on which LLM layers to use for lexical semantic tasks. 
- Reveals tradeoff between understanding and prediction across layers.
- Simple modifications to input like repetition can better expose LLM's capabilities.

Limitations:
- Focused only on English and Llama2 model. Other languages/models may differ. 
- Probing evaluates representations but doesn't reveal what kind of semantics are learned.
