# [Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong   General Audio Event Taggers](https://arxiv.org/abs/2307.03183)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:Can we build a unified model for automatic speech recognition (ASR) and audio tagging that leverages the strengths of the Whisper ASR model?Specifically, the key hypotheses appear to be:1) The Whisper model is robust to background noise for ASR, but its representations are not noise-invariant and actually encode a lot of background sound information. 2) This property of encoding background sounds makes Whisper a good backbone model for both ASR and audio tagging in a unified model.3) By freezing the weights of the Whisper encoder and adding a small audio tagging model on top, we can build an efficient unified ASR + audio tagging model called Whisper-AT.In summary, the main research question seems to be exploring whether the Whisper model can be used as an effective unified backbone for both ASR and audio tagging, leveraging its noise robustness and background sound encoding ability. The paper proposes and evaluates the Whisper-AT model to address this question.


## What is the main contribution of this paper?

The main contributions of this paper are:- It shows that Whisper, a robust automatic speech recognition (ASR) model, actually learns noise-variant (not noise-invariant) representations that encode rich background sound information. This is counter to the common belief that robust ASR models should learn noise-invariant representations.- Based on the finding that Whisper encodes background sounds, the paper proposes a unified ASR and audio tagging model called Whisper-AT. By adding a lightweight audio tagging module on top of the frozen Whisper model, Whisper-AT can recognize background sounds in addition to spoken text in one forward pass. - Experiments show Whisper-AT achieves strong performance on audio tagging benchmarks like AudioSet and ESC-50 while having over 40x lower computational cost than stand-alone audio tagging models. This makes it suitable for applications where both ASR and audio tagging functionalities are desired but running two separate systems is expensive.In summary, the key contribution is proposing and experimentally validating Whisper-AT, a unified and efficient ASR + audio tagging model, enabled by the finding that the robust Whisper ASR model learns noise-variant representations.
