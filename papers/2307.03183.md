# [Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong   General Audio Event Taggers](https://arxiv.org/abs/2307.03183)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:Can we build a unified model for automatic speech recognition (ASR) and audio tagging that leverages the strengths of the Whisper ASR model?Specifically, the key hypotheses appear to be:1) The Whisper model is robust to background noise for ASR, but its representations are not noise-invariant and actually encode a lot of background sound information. 2) This property of encoding background sounds makes Whisper a good backbone model for both ASR and audio tagging in a unified model.3) By freezing the weights of the Whisper encoder and adding a small audio tagging model on top, we can build an efficient unified ASR + audio tagging model called Whisper-AT.In summary, the main research question seems to be exploring whether the Whisper model can be used as an effective unified backbone for both ASR and audio tagging, leveraging its noise robustness and background sound encoding ability. The paper proposes and evaluates the Whisper-AT model to address this question.
