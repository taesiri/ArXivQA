# [The effect of source disclosure on evaluation of AI-generated messages:   A two-part study](https://arxiv.org/abs/2311.15544)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a concise yet comprehensive paragraph summarizing the key points of the paper:

This two-part experimental study examines how disclosing messages as AI-generated versus human-generated impacts people's evaluation and selection of vaping prevention messages. In Study 1, source disclosure decreased the ratings difference between AI-generated and human-generated messages. However, it did not significantly change message ranking preferences. In Study 2, negative attitudes toward AI moderated the influence of source disclosure on message evaluation, such that higher negative attitudes led to lower evaluations when the source was disclosed. For message selection, source disclosure decreased selection of AI-generated messages among those with moderate negative AI attitudes. Overall, results indicate a slight bias against AI-generated messages once the source is disclosed, adding to research on AI and communication. The study highlights the importance of source effects regarding AI-generated health content and has implications for potential mandatory labeling of such content.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

This paper presents two studies examining how disclosing messages as AI-generated versus human-generated impacts people's evaluation of and preference for the messages in the context of vaping prevention, finding a slight bias against AI-generated messages once the source is disclosed.


## What is the main contribution of this paper?

 Based on the content presented in the paper, the main contribution is examining the influence of disclosing the source of a message (AI vs human) on people's evaluation of and preference for AI-generated health prevention messages compared to human-generated messages. 

Specifically, the paper conducted two studies that investigated how source disclosure impacted ratings of perceived effectiveness and selection/ranking of AI-generated vs human-generated anti-vaping messages. The key findings were:

1) Disclosing the AI source led to a smaller difference in effectiveness ratings between AI and human messages, providing qualified support for a slight bias against AI content.

2) Negative attitudes towards AI moderated the effect of source disclosure on message evaluations. Those with more negative views rated disclosed AI messages higher and human messages lower.

3) While rankings and selections did not differ significantly, there was a decrease in AI message selection when the source was disclosed among those with moderate negative AI attitudes.

Overall, the paper makes a novel contribution by being one of the first to study the intersection of AI message generation, source disclosure effects, and biases/attitudes towards AI in shaping health campaign evaluations. The results have implications for source effects theory and practice around AI-generated health promotion content.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper's content, some of the main keywords or key terms associated with this paper include:

- Artificial Intelligence (AI)
- large language model (LLM)
- health communication
- source disclosure
- vaping prevention
- mixed effects modeling

The paper examines the effect of disclosing whether a health message was AI-generated or human-generated on people's evaluation of and preference for the message. It conducts two studies in the context of vaping prevention messaging. The data is analyzed using mixed effects modeling. So the keywords listed above, which include the AI techniques, health topic, study variables, and analysis methods, effectively summarize the key focus areas of this paper.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper relies on previously published procedures to generate the AI messages and collect the human-generated messages. Could you describe in more detail the process used for generating the AI messages with Bloom and selecting the final 15 messages? What criteria were used?

2. For the human-generated tweets, the paper states they were scraped from Twitter using specific hashtags. What was the logic behind selecting those particular hashtags? Were there any steps taken to filter the tweets before randomly selecting 15 to use in the experiments? 

3. The paper examines source disclosure as the independent variable. What other message characteristics could be manipulated in future studies to further understand evaluations of AI-generated vs human-generated messages? For example, message framing, evidence type, etc.

4. The perceived message effectiveness (PME) scale is used as the key dependent variable measuring message evaluation. Why was the specific "effects perception" dimension of PME chosen rather than other subscales like message perceptions? What limitations might this choice have?  

5. For the ranking task in Study 1, participants ranked all 30 messages. What are some alternative approaches that could be used to measure preferences among messages rather than having participants rank such a large set? 

6. What other individual difference moderators beyond negative attitudes toward AI might influence reactions to source disclosure of AI-generated messages? For example, AI literacy, need for cognition, etc.

7. The vaping prevention context was used for developing and testing messages. What other health issues or risk topics would be relevant to study for understanding evaluations of AI-generated messaging?

8. How might the quality of the prompts provided to the AI system influence subsequent evaluations of the generated messages after source disclosure? What role might prompt engineering play in perceptions of AI capabilities?

9. What steps were taken in the experimental design to prevent deception and ensure fully informed consent? What ethical considerations should guide research at the intersection of AI and persuasion?  

10. The paper examines immediate evaluations of messages, but how might disclosure of an AI source influence downstream outcomes like risk perceptions, attitudes, and behaviors over time? What longitudinal studies could be useful?
