# [Against Membership Inference Attack: Pruning is All You Need](https://arxiv.org/abs/2008.13578)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is whether a DNN weight pruning technique can help defend against membership inference attacks (MIA) while also reducing model size and computational complexity. Specifically, the authors propose a pruning algorithm called "MIA-Pruning" that aims to jointly optimize for defending against MIA and minimizing model size/computation. Their hypothesis is that MIA-Pruning will be able to find a sparse subnetwork that prevents privacy leakage from MIA while maintaining competitive accuracy compared to the original dense DNN.The key research questions examined are:- Can MIA-Pruning reduce attack accuracy of MIA compared to baseline and other defenses like min-max game?- Does MIA-Pruning provide substantial model compression and computational speedup over unoptimized DNNs?- Is the utility cost (classification accuracy loss) of MIA-Pruning small?- How does MIA-Pruning compare to other MIA defenses like differential privacy?So in summary, the central hypothesis is that intelligent weight pruning can jointly defend against MIA attacks while also providing efficiency gains, with minimal impact on accuracy. The paper evaluates this hypothesis theoretically and empirically.
