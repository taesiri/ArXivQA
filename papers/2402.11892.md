# [Evaluating Program Repair with Semantic-Preserving Transformations: A   Naturalness Assessment](https://arxiv.org/abs/2402.11892)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

The paper investigates the impact of naturalness in evaluating Neural Program Repair (NPR) techniques using semantic-preserving transformations. NPR leverages deep learning to automatically fix bugs in software code. To evaluate NPR systems, prior works augment existing datasets like Defects4J using semantic-preserving transformations that create new but equivalent programs. However, these transformations may introduce unnatural code that rarely occurs in practice, leading to misleading evaluations. 

To address this, the authors first interviewed developers to establish concrete criteria for assessing the naturalness of code transformations. They found that transformations are considered unnatural if they reduce code readability or violate coding conventions. Using this, they conducted a study involving 10 developers to manually label the naturalness of 1,178 transformed programs from Defects4J. They found only 58.8% of transformations were considered natural while 19.3% were deemed unnatural.

Experiments on 5 NPR systems showed these unnatural transformations introduced a 25.2% false alarm rate in evaluating robustness. Further evaluation using only natural transformations still revealed a lack of robustness in NPR systems, with 4.1%-22.9% and 6.1%-23.6% drops in correct and plausible patches generated. This highlights the need to incorporate naturalness assessment in benchmarking NPR robustness.

Finally, the authors proposed a novel naturalness metric called Relative Naturalness Change (RNC) that had promising capability (AUC=0.7) in automatically identifying unnatural transformations.

In summary, key contributions are:
1) Concrete criteria for assessing naturalness of code transformations 
2) Analysis of naturalness of 1,178 semantic-preserving transformations
3) Demonstrating impact of unnatural transformations on misleading NPR evaluation
4) Extensive robustness evaluation of 5 NPR systems using natural transformations
5) RNC metric to automate identifying unnatural transformations

The paper provides useful implications on the importance of considering naturalness in transformation-based evaluation of NPR and other AI code models.
