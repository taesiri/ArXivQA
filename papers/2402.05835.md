# [How Much is Unseen Depends Chiefly on Information About the Seen](https://arxiv.org/abs/2402.05835)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Estimating the probability distribution of data in the presence of rare/unseen classes is a fundamental challenge in machine learning. The conventional Good-Turing (GT) estimator overestimates the probabilities of observed classes and underestimates probabilities of unobserved classes.

- Previous work has made simplifying assumptions of independence between frequencies of classes using Poisson approximation. This paper tackles the dependencies analytically without approximation.

Methodology: 
- The paper provides an exact characterization of the dependency between frequencies of different classes in the sample. This allows decomposing the expected total probability mass into components that can be estimated from frequencies in the sample and a remainder term.  

- They introduce an estimator with exponentially decaying bias by plugging in the frequencies for the terms in the decomposition. However, its variance is high.

- They formulate the estimation as an optimization problem to find representations with lower MSE. A genetic algorithm searches the space of representations to discover the estimator with minimal MSE.

Contributions:
- Precise analytical characterization of dependencies between frequencies of classes, without simplifying assumptions. Enables reasoning about properties of estimators.  

- Decomposition of expected total probability mass into sample-dependent and remainder terms. Quantifies what can and cannot be estimated from sample frequencies.

- Estimator with exponentially decaying bias, much lower than GT estimator's bias. But has high variance.  

- Methodology to discover distribution-specific estimators with lower MSE than GT by searching over representations. MSE reductions of ~20% over GT shown empirically.

In summary, the key innovation is an analytical characterization of dependencies between frequencies, which enables precise reasoning. This leads to low-bias estimators, and a strategy to discover estimators with lower MSE through search.
