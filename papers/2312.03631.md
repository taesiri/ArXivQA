# [MOCHa: Multi-Objective Reinforcement Mitigating Caption Hallucinations](https://arxiv.org/abs/2312.03631)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of the paper:

This paper proposes MOCHa, a novel reinforcement learning-based approach for mitigating hallucinations (spurious fabricated details) in image captioning models. The key insight is to use a multi-objective reward function that optimizes for both fidelity to the input image (avoiding contradictions) and semantic adequacy (inclusion of relevant details), without requiring any strong supervision. Fidelity is rewarded via natural language inference against ground-truth captions, while adequacy uses similarity metrics to references. Experiments across models like BLIP show MOCHa reduces hallucinations on both open and closed vocabulary metrics, while improving or preserving caption quality metrics like CIDEr. The paper also contributes OpenCHAIR, an open vocabulary hallucination benchmark using language models and text-to-image models to synthesize a novel test set with captioned images. Overall, MOCHa demonstrates the promise of reinforcement learning to mitigate hallucinations at the sequence level by balancing multiple objectives for constrained open-ended text generation.
