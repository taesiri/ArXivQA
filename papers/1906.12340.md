# [Using Self-Supervised Learning Can Improve Model Robustness and   Uncertainty](https://arxiv.org/abs/1906.12340)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research questions and hypotheses of this paper appear to be:1) Can self-supervised learning improve model robustness and uncertainty estimates beyond what is possible with purely supervised training? The paper hypothesizes that adding self-supervised auxiliary tasks during training can improve model robustness to adversarial examples, label noise/corruption, common input corruptions, and enhance out-of-distribution detection. 2) Can self-supervised learning surpass fully supervised methods for out-of-distribution detection, particularly on near-distribution anomalies?The paper hypothesizes that the representations learned via self-supervision may better capture the structure of in-distribution data, allowing for superior OOD detection compared to supervised methods alone.3) Should robustness and uncertainty estimation be considered as additional evaluation axes for self-supervised learning? The paper proposes that future self-supervised methods could be judged based on their ability to improve model robustness and uncertainty estimates, not just standard accuracy metrics.In summary, the key hypotheses are that self-supervision can benefit robustness and uncertainty in ways that supervised learning alone cannot, and these benefits are often masked when evaluating only on clean accuracy. The paper aims to demonstrate these gains across several robustness tasks and OOD detection.


## What is the main contribution of this paper?

The main contribution of this paper is showing that self-supervised learning can improve model robustness and uncertainty estimation, even when used in conjunction with fully supervised training on a large labeled dataset like ImageNet. Specifically, the paper demonstrates that adding an auxiliary rotation prediction task during training improves robustness to adversarial examples, label corruption, and common input corruptions. It also greatly improves out-of-distribution detection, allowing self-supervised methods to surpass fully supervised techniques on CIFAR and ImageNet experiments. The key insight is that while self-supervision may not boost standard accuracy much when combined with full supervision, it provides regularization that makes models more robust. The gains are masked when evaluating only on clean test accuracy.Overall, this suggests robustness and uncertainty tasks as new evaluation dimensions for self-supervised learning research beyond just standard accuracy. The results show the utility of self-supervision even with access to large labeled datasets, and demonstrate it can improve robustness without requiring more data or model capacity.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper shows that adding self-supervised learning techniques like predicting rotations to standard supervised training can improve model robustness to adversaries, label noise, and image corruptions, and can greatly improve out-of-distribution detection, enabling self-supervised methods to surpass fully supervised techniques on difficult near-distribution outliers.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in the field of self-supervised learning:- This paper focuses on using self-supervision to improve model robustness and uncertainty estimates, whereas most prior work has focused on using self-supervision to learn useful representations without labeled data. The authors make the case that self-supervision provides benefits beyond just reducing the need for labeled data.- The paper shows that adding self-supervised auxiliary tasks (like rotation prediction) during training can improve robustness to adversarials, label noise, and image corruptions. This is a novel contribution, as prior work did not really explore the impact of self-supervision on robustness.- For out-of-distribution detection, the paper shows that self-supervision with rotations can improve detection of near-distribution anomalies. Prior work like Hendrycks et al. focused on baseline supervised methods, so demonstrating stronger OOD detection with self-supervision is an advance.- Notably, the paper shows self-supervision surpassing supervised methods on the ImageNet OOD detection task. This suggests self-supervision could become the premier technique for this task, whereas most prior work still lags behind supervised methods on standard accuracy metrics.- The techniques like auxiliary rotation prediction are simple to implement on top of existing models. So the paper identifies straightforward ways to improve robustness and uncertainty that are compatible with other methods.Overall, I would say the main novel contributions are using self-supervision specifically to improve robustness and uncertainty estimates (not just for standard accuracy), and showing that self-supervision can surpass supervised techniques on certain tasks related to model robustness and OOD detection. The paper convincingly demonstrates new merits and applications for self-supervised learning.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Developing new self-supervised learning techniques and objectives that further improve robustness and uncertainty estimates. The authors showed rotation prediction helped in several areas, but there may be other self-supervised tasks that provide even greater benefits.- Evaluating self-supervised methods along the axes of robustness and uncertainty estimation, in addition to standard accuracy. The paper demonstrated these are useful complementary metrics that can reveal benefits of methods even when accuracy is unchanged.- Applying self-supervised learning to additional domains like robotics and video, where it could potentially improve robustness. The authors cite prior work using self-supervision in these areas.- Combining self-supervised methods with existing techniques for improving robustness and uncertainty, such as adversarial training or outlier exposure. The authors showed combining their method with these helped further.- Developing better self-supervised techniques for large-scale image datasets like ImageNet. The paper showed promising initial results but there is room for improvement.- Studying the theoretical connections between self-supervision and robustness to better understand when and why self-supervision helps.Overall, the main suggestions are to further explore self-supervision for improving robustness and uncertainty, use it as an evaluation axis, apply it to new domains, combine it with existing methods, scale it up, and theoretically understand it. The paper makes a strong case that this is a promising research direction.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the key points from the paper:The paper demonstrates that self-supervised learning with auxiliary rotation prediction can improve model robustness and uncertainty estimation. They show gains in robustness to adversarial examples, label corruptions, and common image corruptions by adding rotation prediction on top of standard supervised training, even though clean accuracy is unaffected. They also find that rotation prediction greatly improves out-of-distribution detection for near-distribution anomalies. On CIFAR and ImageNet, the self-supervised methods surpass fully supervised techniques for this task. Overall, the results suggest self-supervision can provide regularization benefits complementary to supervised learning. The gains in robustness and uncertainty estimation suggest these tasks as additional evaluation dimensions for future self-supervised learning methods.
