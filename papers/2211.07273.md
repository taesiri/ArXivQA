# [MLIC: Multi-Reference Entropy Model for Learned Image Compression](https://arxiv.org/abs/2211.07273)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research question addressed in this paper is: 

How can we design an entropy model that more effectively captures correlations in the latent representation across multiple dimensions (channel, local spatial, global spatial) to improve the rate-distortion performance of learned image compression?

The key hypothesis is that by capturing correlations in these multiple dimensions jointly in a single entropy model, rather than independently, they can achieve better compression performance. 

Specifically, the paper proposes multi-reference entropy models (MEM and MEM+) that incorporate:

- Channel-wise context module: Captures correlations between channels by conditioning each slice of the latent representation on previously decoded slices.

- Local spatial context module: Captures local spatial correlations using an enhanced checkerboard pattern context model. They propose two techniques to improve on standard checkerboard. 

- Global spatial context module: Captures global spatial correlations both within and across slices using attention mechanisms.

They hypothesize that by combining all of these context models together into a single multi-reference framework, the entropy model will be able to more accurately estimate conditional probabilities and achieve state-of-the-art rate-distortion performance. The extensive experiments demonstrate the gains of their proposed MEM/MEM+ models.

In summary, the key hypothesis is that modeling correlations across channel, local spatial, and global spatial dimensions jointly in a multi-reference entropy model will improve compression efficiency. The paper aims to demonstrate this through the proposed MEM/MEM+ models.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- Proposing the Multi-Reference Entropy Models (MEM and MEM+) that effectively capture channel-wise, local spatial, and global spatial correlations in the latent representation for image compression. 

- The MEM and MEM+ models combine channel-wise contexts, local spatial contexts, global spatial contexts within the same entropy model. This allows capturing more types of correlations compared to prior works.

- To capture local spatial contexts, the paper proposes two enhanced checkerboard context capturing techniques - stacked checkerboard contexts and checkerboard attention. These avoid performance degradation of vanilla checkerboard while retaining two-pass decoding.

- For global spatial contexts, the paper proposes an intra-slice and inter-slice global context modeling, where attention maps from decoded slices are used to predict global correlations in current slices. 

- Based on MEM and MEM+, the paper develops the MLIC and MLIC+ image compression models. Extensive experiments show they achieve state-of-the-art rate-distortion performance, reducing BD-rate significantly compared to prior arts and traditional codecs like VTM and VVC.

In summary, the key contribution is proposing the multi-reference entropy models to capture multi-dimensional contexts, and developing high performance learned image compression methods MLIC and MLIC+ based on this. The enhanced techniques for checkerboard context modeling and global context modeling are also important contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes multi-reference entropy models MEM and MEM+ that capture channel-wise, local spatial, and global spatial correlations in the latent representation for learned image compression, achieving state-of-the-art performance.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper on multi-reference entropy models for learned image compression compares to other related research:

- Most prior learned image compression methods focus on capturing correlations in just one dimension, like spatially or across channels. This paper proposes modeling correlations across multiple dimensions - spatially, both locally and globally, and across channels. Capturing these multi-dimensional correlations is novel.

- For local spatial contexts, the paper explores enhancing the commonly used checkerboard context model to avoid performance degradation. The proposed stacked checkerboard and checkerboard attention modules are new techniques aimed at improving local context modeling.

- Modeling global spatial contexts by using the attention map from a previously decoded slice to guide correlations in the current slice is a novel approach introduced in this work. Prior arts either did not consider global contexts or required sending extra information.

- Combining channel, local and global spatial context models within an entropy model has not been explored before. Most works look at these contexts separately. Jointly modeling them is a key contribution.

- The proposed models achieve state-of-the-art compression performance, demonstrating over 8-11% bit-rate savings compared to standard video compression methods like VVC. This shows the effectiveness of the proposed multi-reference context modeling approach.

In summary, the key novelty of this work is in modeling correlations across multiple dimensions jointly using channels, local and global spatial contexts. The techniques introduced for enhancing checkerboard patterns and for global context modeling are new, and significant compression gains are demonstrated. This is an important advance over prior arts in learned image compression.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the key future research directions suggested by the authors include:

- Developing more efficient and lightweight versions of the proposed models (MLIC and MLIC+) so they can be deployed on mobile devices. The current models have high computational complexity due to the intra-slice and inter-slice global context modules. Methods like knowledge distillation, network pruning, and structural re-parameterization could help address this.

- Further improving progressive decoding with the proposed models. The paper notes that progressive decoding performance with MLIC and MLIC+ is unstable and can sometimes lead to artifacts. More work is needed on optimizing information flow between slices to stabilize and enhance progressive decoding. 

- Exploring other backbone architectures beyond the simplified Cheng et al. model used in this work. The global and local context modeling approach could be integrated into other state-of-the-art backbones.

- Developing more efficient attention mechanisms for the global context modeling. The quadratic complexity of the current attention approach poses scaling challenges. Approximation methods like sparse attention could help.

- Applying the multi-reference entropy modeling approach to other domains beyond image compression like video compression. The core ideas around capturing channel, spatial and global correlations can extend to other formats.

- Investigating the performance on higher resolution images to better understand the impact of cropped patches versus full images during training and inference.

So in summary, the key future directions are around improving efficiency, progressive decoding, exploring different backbone architectures, developing more efficient attention mechanisms, extending to other domains like video, and evaluating on higher resolution image data.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper proposes Multi-Reference Entropy Models (MEM and MEM+) for learned image compression that effectively capture channel-wise, local spatial, and global spatial contexts in the latent representation. The models divide the latent representation into slices and use previously decoded slices as channel-wise context when decoding a slice. For local spatial context, the models use enhanced checkerboard context modeling techniques to avoid performance degradation while allowing two-pass decoding. For global spatial context, the models use the attention map from a previously decoded slice to predict global correlations in the current slice. Based on MEM and MEM+, the authors propose MLIC and MLIC+ models that achieve state-of-the-art performance, reducing BD-rate by 8.05% and 11.39% respectively on the Kodak dataset compared to VTM-17.0. The key contributions are developing multi-reference entropy models that combine channel, local and global contexts, and demonstrating improved performance and rate-distortion tradeoffs.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

Learned image compression has recently achieved remarkable performance, with the entropy model playing a crucial role in boosting rate-distortion performance. However, most entropy models only capture correlations in one dimension, while latent representations contain channel-wise, local spatial, and global spatial correlations. To address this, the authors propose the Multi-Reference Entropy Model (MEM) and an enhanced version MEM+ to capture these multiple types of correlations in latent representations. Specifically, they divide the latent representation into slices and use previously decoded slices as channel-wise contexts when decoding a slice. For local contexts, they propose two enhanced checkerboard context modeling techniques to avoid performance degradation. To capture global spatial contexts, they compute the attention map of a previously decoded slice to predict correlations in the current slice, assuming spatial correlations are similar across slices. Based on MEM and MEM+, they develop image compression models MLIC and MLIC+ which achieve state-of-the-art performance. On the Kodak dataset, their models reduce BD-rate by 8.05% and 11.39% over VTM-17.0 when measured by PSNR.

In summary, this paper makes two key contributions. First, it proposes novel multi-reference entropy models (MEM and MEM+) that effectively capture channel-wise, local spatial, and global spatial correlations in latent representations. Second, it develops MLIC and MLIC+, new learned image compression models achieving state-of-the-art performance by leveraging MEM and MEM+. The results demonstrate the benefit of capturing multiple types of correlations, setting a new state-of-the-art for learned image compression.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes multi-reference entropy models MEM and MEM+ that effectively capture channel-wise, local spatial, and global spatial contexts in the latent representation for learned image compression. The key ideas are: 1) Dividing the latent representation into slices and using previously decoded slices as channel-wise context when decoding a slice. 2) Adopting enhanced checkerboard context modeling techniques like stacked convolutions or window-based attention to capture local contexts while retaining parallel decoding. 3) Using the attention map from a previously decoded slice to predict global correlations within the current slice being decoded. Based on MEM and MEM+, the authors propose learned image compression models MLIC and MLIC+ which achieve state-of-the-art rate-distortion performance. The multi-reference entropy modeling allows jointly capturing correlations across channels, locally, and globally to accurately estimate distributions for the latent representations.


## What problem or question is the paper addressing?

 Based on my reading, the key points about the problem and questions addressed in this paper are:

- The paper focuses on learned image compression models. These models have achieved remarkable performance recently compared to traditional image compression methods.

- A key component in these learned models is the entropy model, which estimates the distribution of the latent representations. More accurate entropy models can help boost rate-distortion performance. 

- Most existing entropy models only capture correlations in one dimension (like spatial or channel-wise), but the latent representations contain correlations across multiple dimensions like channel, local spatial, and global spatial. 

- To address this issue, the paper proposes multi-reference entropy models MEM and MEM+ that can capture correlations across channel, local spatial, and global spatial dimensions in the latent representations.

- The key questions addressed are: How to effectively model correlations across multiple dimensions in the latent representations? How to combine channel, local spatial, and global spatial context modeling within a single entropy model? How to boost performance of learned image compression through multi-dimensional context modeling in the entropy model?

In summary, the paper focuses on improving learned image compression by proposing multi-reference entropy models that can capture richer correlations in the latent representations across channel, local spatial, and global spatial dimensions. This addresses limitations of prior entropy models that capture correlations in just one dimension.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords are:

- Learned image compression - The paper focuses on learned image compression methods rather than traditional image compression like JPEG.

- Entropy model - A key component of learned image compression is the entropy model, which estimates the entropy of the latent representation. Improving the entropy model can significantly boost performance. 

- Multi-reference entropy model (MEM) - The paper proposes a novel multi-reference entropy model to capture channel-wise, local spatial, and global spatial correlations in the latent representation. This is one of the main contributions.

- Channel-wise context - Modeling correlations between channels in the latent representation. The paper uses a channel-wise context module for this.

- Local spatial context - Modeling correlations between spatially adjacent symbols in the latent representation. The paper explores convolutional and attention-based modules for local context.

- Global spatial context - Modeling long-range spatial correlations in the latent representation. The paper proposes intra-slice and inter-slice modules to capture global context.

- Stacked checkerboard context - One of the proposed local context modules to improve on the basic checkerboard context model.

- Checkerboard attention - Another proposed local context module using shifted windows and attention.

- Rate-distortion optimization - The overall goal is to optimize the rate-distortion performance, i.e. minimize distortion at a target bitrate. The multi-reference entropy model aims to improve rate-distortion performance.

In summary, the key focus is on using a multi-reference entropy model to capture different types of correlations in the latent representation in order to improve the rate-distortion performance of learned image compression. The proposed MLIC and MLIC+ models with MEM achieve state-of-the-art performance.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 sample questions that could help create a comprehensive summary of the paper:

1. What is the main focus/contribution of the paper? What problem does it aim to solve?

2. What are the key limitations with existing learned image compression models that the paper identifies? 

3. What is the proposed Multi-Reference Entropy Model (MEM) and how does it aim to capture more contexts and correlations than existing models?

4. How does the proposed approach divide the latent representation into slices and what is the purpose of doing so? 

5. How does the proposed approach capture channel-wise, local spatial, and global spatial contexts? What modules are used for each?

6. What are the two proposed techniques to address the limitations of checkerboard context modeling while retaining two-pass decoding?

7. How does the proposed global spatial context module use attention maps from previously decoded slices? What is the purpose of this?

8. What are the main components of the overall proposed compression models MLIC and MLIC+? How do they differ?

9. What datasets were used to evaluate the performance of MLIC and MLIC+? How do they compare to state-of-the-art methods?

10. What are the limitations of the proposed approach? What future work could be done to address these?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes multi-reference entropy models (MEM and MEM+) that capture channel-wise, local spatial, and global spatial correlations in the latent representation. How exactly do these different context modules work and how are they incorporated together in the full entropy model? 

2. For the local spatial context modeling, the paper proposes two enhanced checkerboard context capturing techniques - stacked checkerboard modules and shifted window attention. What are the differences between these two approaches and what are the relative advantages/disadvantages of each?

3. The global spatial context modeling divides contexts into intra-slice and inter-slice. How do these two modules work differently? What is the motivation behind capturing global correlations both within and across slices?

4. The paper claims the model is able to capture more contexts compared to prior works. Can you quantify or visually demonstrate how much more context is being modeled? How does this translate to rate-distortion performance gains?

5. The global context modeling uses attention to capture long-range dependencies. However, the complexity is quadratic. What modifications or approximations did the authors make to improve efficiency while retaining performance?

6. For progressive decoding, the paper mentions the performance is much worse than separate optimized models. Why does adding global context modeling hurt progressive decoding capability? How can this issue be addressed?

7. The experiments optimize for both MSE and MS-SSIM losses. What differences would you expect in the rate-distortion curves or visual quality when optimizing for perceptual vs MSE losses? 

8. How does the performance compare when using different backbone architectures, like the one proposed in this paper vs. the one used in ELIC? What are the trade-offs?

9. What other types of context could potentially be incorporated into the entropy model? For example, semantic context, hierarchical priors, temporal contexts for video, etc.

10. How might this approach extend to other modalities like video, 3D, or point cloud compression, where spatial, temporal, and cross-modal contexts could be useful? What challenges might arise?


## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes novel multi-reference entropy models called MEM and MEM+ for learned image compression. These models effectively capture channel-wise, local spatial, and global spatial correlations in the latent representation, unlike previous methods that typically model correlations in only one dimension. Specifically, the latent representation is divided into slices. When decoding a slice, previously decoded slices provide channel-wise context. An attention map from the previous slice is used to predict global correlations in the current slice. For local context, the representation is divided into anchor and non-anchor parts. Two techniques are introduced to avoid performance degradation from the checkerboard pattern: stacked checkerboard context modeling and overlapped checkerboard window attention. Based on MEM and MEM+, the authors propose MLIC and MLIC+ image compression models which achieve state-of-the-art performance, reducing BD-rate by 8.05% and 11.39% respectively on Kodak compared to VTM-17.0. The key innovation is exploring and modeling the different types of correlations in the latent space via multi-reference entropy models.


## Summarize the paper in one sentence.

 The paper proposes multi-reference entropy models to capture correlations in multiple dimensions of the latent representation for learned image compression.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the paper:

This paper proposes multi-reference entropy models MEM and MEM+ for learned image compression. These models capture channel-wise, local spatial, and global spatial correlations in the latent representation, which most prior works fail to jointly model. Specifically, the latent representation is divided into slices. When decoding a slice, previously decoded slices provide channel-wise context. An attention map from the previous slice is used to predict global correlations. For local context, the authors propose stacked checkerboard convolutions and shifted window attention to avoid performance degradation from the checkerboard pattern while enabling parallel decoding. Experiments show the models achieve state-of-the-art performance, reducing BD-rate by 8.05% and 11.39% on Kodak compared to VTM-17.0. The models are end-to-end trainable and capture more contexts than prior arts.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes Multi-Reference Entropy Models (MEM and MEM+) that capture channel-wise, local spatial, and global spatial contexts in the latent representation. How do these different types of contexts complement each other? What are the limitations of only modeling one type of context?

2. The paper divides the latent representation into slices when encoding/decoding. What is the motivation behind this? How does dividing into slices enable capturing channel-wise and global contexts? What are the tradeoffs with the number of slices?

3. The paper proposes two techniques for local spatial context modeling - Stacked Checkerboard Context Module and Checkerboard Attention Context Module. How do these two techniques differ? What are the benefits and drawbacks of each one? 

4. The Intra-Slice Global Context Module uses the attention map from the previous slice to predict global correlations in the current slice. Why is the attention map a good representation for capturing global correlations? What are other potential ways to model global correlations?

5. The paper argues that the Intra-Slice Global Context Module is different from cross-attention. Elaborate on the differences and explain why masking local receptive fields is important.

6. The Inter-Slice Global Context Module captures correlations between adjacent slices. Why approximate via anchor parts instead of modeling correlations directly? What are the tradeoffs?

7. The paper shows performance gains from adding the different context modules incrementally. Analyze these gains - which contexts provide the most gains? Why do you think that is?

8. The global context modeling has quadratic complexity. The paper mentions some ways to address this. Elaborate on the solutions and their tradeoffs. Are there other potential ways to reduce complexity?

9. Analyze the differences between MLIC and MLIC+ - which components contribute to MLIC+'s better performance? What is the computational cost?

10. The paper shows worse performance for progressive decoding compared to decoding each slice independently. Hypothesize reasons for this behavior and discuss how progressive decoding could be improved.
