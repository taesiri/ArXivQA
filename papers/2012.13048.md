# ProofWriter: Generating Implications, Proofs, and Abductive Statements   over Natural Language

## What is the central research question or hypothesis that this paper addresses?

The central research question of this paper is: How can we enable neural networks to systematically generate natural language proofs, implications, and abductive inferences for logical reasoning?Specifically, the paper aims to show that generative transformer models can reliably:1) Generate natural language proofs to explain the reasoning behind an answer to a question, given a set of facts and rules. 2) Generate logical implications that follow from a set of facts and rules.3) Perform abductive inference to identify missing facts that would allow an unprovable conclusion to be proved.The overall goal is to significantly improve the viability of neural methods for logical reasoning directly over natural language by equipping them with capabilities beyond just assigning true/false labels. The paper presents a system called ProofWriter that demonstrates these capabilities.


## What is the main contribution of this paper?

The main contributions of this paper are:1. A new method for generating natural language proofs to explain the reasoning behind an answer to a question, given a set of facts and rules expressed in natural language. The method obtains state-of-the-art results on the RuleTaker benchmark datasets.2. A technique for generating logical implications that follow from statements expressed in natural language (implication enumeration). This allows enumerating consequences of a theory, rather than just assigning truth values to hypotheses.3. A method for performing a constrained form of abduction over natural language theories. Given an unprovable conclusion, the method can identify a missing fact that would allow the conclusion to be proved when added to the theory.4. New datasets to promote further research in natural language reasoning and inference tasks like proof generation, implication enumeration, and abduction.In summary, the key contribution is developing generative neural methods to produce proofs, implications, and abductive statements from natural language theories. This significantly advances the capabilities of neural models to perform systematic logical reasoning over language.
