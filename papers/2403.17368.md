# [ChatGPT Rates Natural Language Explanation Quality Like Humans: But on   Which Scales?](https://arxiv.org/abs/2403.17368)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Evaluating the quality of natural language explanations (NLEs) is important for transparency and trust in AI systems. 
- Traditional evaluation through human ratings is challenging due to subjectivity and need for fine-grained scores.
- Developing models to automate assessment can reduce cost and time of human evaluations.

Objective:
- Explore if ChatGPT can accurately evaluate explanation quality compared to human assessments. 
- Test on three explanation datasets - logical reasoning, misinformation justification, implicit hate speech.
- Evaluate on informativeness and clarity metrics using classification and pairwise comparisons.  

Methods:
- Sampled 300 instances from 3 explanation datasets.
- Had trained human annotators provide ground truth quality scores.
- Queried ChatGPT to rate explanations on 7-pt scale. 
- Formulated as classification task, with human scores as truth and ChatGPT as predictions.
- Also tested pairwise comparisons between explanations.

Key Findings:
- Strong correlation between ChatGPT and human scores, but tends to underestimate.
- Performs very well on coarse classifications but struggles with fine-grained scores.  
- Excels at pairwise comparisons, close to human performance.
- Dynamic prompting improves alignment further in comparisons.
- Best performance on misinformation justification dataset.

Contributions:
- Demonstrates ChatGPT's capability and limitations in evaluating subjective text qualities.
- Shows promise for automating annotations to reduce cost.
- Advances understanding of how to effectively use LLMs for responsible AI.
- Provides insights into configurations that improve human-AI alignment.

Let me know if you need any clarification or would like me to expand on any part of this summary further. I'm happy to provide additional details.
