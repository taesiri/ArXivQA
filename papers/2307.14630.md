# [360VOT: A New Benchmark Dataset for Omnidirectional Visual Object   Tracking](https://arxiv.org/abs/2307.14630)

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the key research focuses of this paper are:1. Proposing a new benchmark dataset 360VOT for omnidirectional (360 degree) visual object tracking, which contains diverse 360 degree videos with various challenges. 2. Exploring new representations like bounding field-of-view (BFoV) for object localization in 360 degree images, as an alternative to commonly used bounding boxes.3. Presenting a general 360 tracking framework that can adapt typical trackers for omnidirectional tracking using the proposed BFoV representation.4. Providing extensive experiments and analysis to benchmark state-of-the-art trackers on the new 360VOT dataset.In summary, this paper aims to promote research in omnidirectional visual tracking by releasing the first dedicated benchmark dataset, exploring new localization representations tailored for 360 imagery, and developing a framework to enable conventional trackers for 360 tracking. The key hypothesis is that 360 tracking encounters new challenges compared to normal perspective tracking, necessitating new datasets, metrics and techniques as proposed in this work.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes 360VOT, the first benchmark dataset for omnidirectional visual object tracking. 360VOT contains 120 sequences with up to 113K high-resolution frames in equirectangular projection. The tracking targets cover 32 categories in diverse scenarios. 2. It provides 4 types of unbiased ground truth annotations, including (rotated) bounding boxes and (rotated) bounding field-of-views. This allows more accurate evaluation of omnidirectional tracking performance compared to typical bounding box annotations.3. It proposes new metrics tailored for 360-degree images to accurately measure tracking performance, including dual success rate, angle precision, and spherical IoU. 4. It benchmarks 20 state-of-the-art trackers on 360VOT and analyzes their performance. It also develops a new baseline by adapting a tracker with the proposed 360 tracking framework, which significantly outperforms other trackers.5. It explores new representations like bounding field-of-view for visual object tracking and shows their benefits for omnidirectional scenes compared to bounding boxes.In summary, this paper makes substantial contributions by releasing the first dedicated benchmark for omnidirectional tracking, proposing more suitable annotations and metrics for 360-degree images, analyzing state-of-the-art tracker performance, and establishing improved baselines to encourage further research in this direction.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new benchmark dataset called 360VOT for evaluating omnidirectional visual object tracking, containing 120 high-resolution 360-degree video sequences with 113K frames annotated with 4 types of ground truth representations, as well as new evaluation metrics tailored for 360-degree tracking.
