# [GazeNeRF: 3D-Aware Gaze Redirection with Neural Radiance Fields](https://arxiv.org/abs/2212.04823)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper aims to address is: 

How can we formulate gaze redirection as a 3D-aware problem to improve redirection accuracy and generate more photorealistic redirected images?

The key points are:

- Existing gaze redirection methods operate on 2D images and struggle to generate consistent 3D results. 

- The authors propose to reformulate gaze redirection as a 3D task by leveraging recent advances in image-based conditional neural radiance fields.

- They propose a two-stream MLP architecture to model the face and eyes as separate 3D structures with separate neural radiance fields. 

- Rigidly rotating the eye features and compositing with the untransformed face features allows fine-grained control over gaze redirection.

- Experiments show this 3D-aware approach outperforms previous state-of-the-art 2D methods in redirection accuracy while preserving identity.

In summary, the central hypothesis is that modeling gaze redirection as a 3D-aware volumetric problem with explicit disentanglement and transformation of eye features can improve redirection performance. The proposed GazeNeRF method aims to test this hypothesis.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. Reformulating the task of gaze redirection as a 3D-aware problem by leveraging neural radiance fields. Previous methods formulate gaze redirection as 2D image manipulation, which can lead to inconsistencies. 

2. Proposing a novel two-stream MLP architecture called GazeNeRF that predicts separate feature volumes for the eye region and rest of the face. This allows disentangling and independently transforming the eyes and face.

3. Applying an explicit 3D rotation on the eye feature volume based on the target gaze direction. This injects a strong 3D prior and models the natural rotation of eyeballs. 

4. Demonstrating state-of-the-art performance in gaze redirection accuracy while preserving identity on multiple datasets. Experiments show advantages over previous 2D methods and naive NeRF approaches.

In summary, the key ideas are reformulating gaze redirection as a 3D-aware volumetric problem, proposing an architecture to disentangle face and eye features, and leveraging explicit 3D transformations on the eyeballs. The results show improved performance and consistency compared to prior 2D and 3D approaches.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a 3D-aware gaze redirection method called GazeNeRF that leverages neural radiance fields to separately model the face and eye regions, allowing rigid transformation of the eye features to redirect gaze while preserving facial identity.


## How does this paper compare to other research in the same field?

 Based on my reading of the paper, here are some key ways this research compares to other work in gaze redirection:

- It takes a 3D-aware approach using neural radiance fields, whereas most prior work formulates gaze redirection as a 2D image manipulation problem. This allows the method to better model the underlying 3D structure and movement of faces and eyes.

- It proposes a two-stream architecture that separately models the face and eye regions, allowing for explicit disentanglement and rigid rotation of the eyeball features. Other methods typically take a more holistic approach without this separation.

- It achieves state-of-the-art performance in gaze redirection accuracy across multiple datasets while better preserving identity. Many previous methods struggle with identity preservation or sacrificing accuracy.

- The use of neural radiance fields allows generating higher quality and more realistic redirected images compared to approaches relying on warping or 2D generative models.

- The method requires less training data compared to other 3D-aware approaches like EyeNeRF. It is trained from images without requiring multi-view video capture.

Overall, the key innovations seem to be in formulating gaze redirection as a 3D volumetric problem and leveraging implicit neural scene representations to achieve better redirection accuracy and realism while requiring less training data than some other 3D-aware techniques. The explicit modeling of eyes and faces is also a unique aspect not seen in prior work.
