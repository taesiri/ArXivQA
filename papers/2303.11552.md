# [Boosting Verified Training for Robust Image Classifications via   Abstraction](https://arxiv.org/abs/2303.11552)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to efficiently train neural networks that are provably robust against adversarial perturbations. 

The key hypothesis is that training neural networks on abstracted interval representations of the input data, rather than on the raw input data, will result in models that are more robust to small perturbations.

Specifically, the paper proposes:

1) An abstraction-based training method where perturbed images are mapped to intervals before being fed into the neural network. By training on intervals, the variance of the training data is reduced, resulting in smoother loss landscapes and more robust models. 

2) A formal verification method that leverages the abstraction to efficiently verify the robustness guarantees of models trained with their approach.

3) Tuning the granularity of the abstraction as a way to trade off robustness and accuracy. Coarser abstractions lead to smoother models while finer abstractions preserve more detail.

4) Evaluating their training and verification methods on image classification benchmarks, showing improved robustness and efficiency compared to prior interval bound propagation techniques.

In summary, the core hypothesis is that abstraction can enable efficient and scalable training of provably robust deep neural networks for image classification. The paper aims to demonstrate this through the proposed techniques and extensive empirical evaluation.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a novel abstraction-based training method for robust image classification. The key idea is to map perturbed images to intervals before feeding them into the neural network for training. This allows the model to be provably robust within the perturbation bound. 

2. It provides a companion black-box verification method to certify the robustness of models trained with the proposed approach. The verification is efficient and scalable since it treats the model as a black box.

3. It implements the training and verification methods in a tool called AbsCert.

4. It conducts extensive experiments on various benchmarks at different scales. The results demonstrate that AbsCert can train models with lower verified errors, less overhead, and good scalability compared to state-of-the-art methods.

In summary, the main contribution is an abstraction-based training framework that can improve model robustness with efficiency and scalability. The black-box verification and tool implementation also enable practical application of the approach. The comprehensive evaluation convincingly demonstrates the advantages over existing methods.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a novel abstraction-based certified training method for robust image classifiers that improves model robustness by mapping perturbed images to intervals before feeding them into neural networks for training, enables efficient black-box verification, and scales effectively to large models.
