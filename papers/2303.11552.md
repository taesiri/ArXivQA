# [Boosting Verified Training for Robust Image Classifications via   Abstraction](https://arxiv.org/abs/2303.11552)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to efficiently train neural networks that are provably robust against adversarial perturbations. 

The key hypothesis is that training neural networks on abstracted interval representations of the input data, rather than on the raw input data, will result in models that are more robust to small perturbations.

Specifically, the paper proposes:

1) An abstraction-based training method where perturbed images are mapped to intervals before being fed into the neural network. By training on intervals, the variance of the training data is reduced, resulting in smoother loss landscapes and more robust models. 

2) A formal verification method that leverages the abstraction to efficiently verify the robustness guarantees of models trained with their approach.

3) Tuning the granularity of the abstraction as a way to trade off robustness and accuracy. Coarser abstractions lead to smoother models while finer abstractions preserve more detail.

4) Evaluating their training and verification methods on image classification benchmarks, showing improved robustness and efficiency compared to prior interval bound propagation techniques.

In summary, the core hypothesis is that abstraction can enable efficient and scalable training of provably robust deep neural networks for image classification. The paper aims to demonstrate this through the proposed techniques and extensive empirical evaluation.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a novel abstraction-based training method for robust image classification. The key idea is to map perturbed images to intervals before feeding them into the neural network for training. This allows the model to be provably robust within the perturbation bound. 

2. It provides a companion black-box verification method to certify the robustness of models trained with the proposed approach. The verification is efficient and scalable since it treats the model as a black box.

3. It implements the training and verification methods in a tool called AbsCert.

4. It conducts extensive experiments on various benchmarks at different scales. The results demonstrate that AbsCert can train models with lower verified errors, less overhead, and good scalability compared to state-of-the-art methods.

In summary, the main contribution is an abstraction-based training framework that can improve model robustness with efficiency and scalability. The black-box verification and tool implementation also enable practical application of the approach. The comprehensive evaluation convincingly demonstrates the advantages over existing methods.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a novel abstraction-based certified training method for robust image classifiers that improves model robustness by mapping perturbed images to intervals before feeding them into neural networks for training, enables efficient black-box verification, and scales effectively to large models.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this CVPR paper compares to other related research:

- The paper proposes a new robust training method called AbsCert that uses abstraction to map perturbed images to intervals before feeding them into the neural network for training. This is a novel approach compared to prior robust training methods like adversarial training, which augment the training data with adversarial examples. 

- The key advantage of AbsCert seems to be that it can train models with much lower verified errors compared to state-of-the-art methods like LossLandscapeMatters, LBP&Ramp, and AdvIBP. The experiments show very significant improvements in verified robustness across different benchmarks. This is an important advancement over prior work.

- Additionally, AbsCert's blackbox verification approach based on the abstraction makes it more efficient and scalable than methods relying on symbolic interval propagation. The paper shows orders of magnitude speedups compared to competitors. This helps address a major weakness of prior verification-based training methods.

- The method is also shown to be applicable to different network architectures beyond standard CNNs, like fully connected networks with sigmoid/tanh activations. And it scales to large ImageNet models like ResNet18 with 138 million parameters, which many verification methods cannot handle.

- Overall, AbsCert appears to be a very promising new technique that pushes the state-of-the-art in verified robust training. The innovations of using abstraction for training and blackbox verification seem to provide substantial improvements in precision, efficiency, generality and scalability compared to related work. If validated, this could be an impactful new direction for provable defenses against adversarial attacks. The thorough benchmarking against competitive baselines is also a strength.

In summary, this paper introduces well-motivated new techniques to address limitations of prior arts and demonstrates excellent results. It likely represents important progress in training verifiably robust neural networks. The community would benefit from open-sourcing AbsCert to further build upon this research.
