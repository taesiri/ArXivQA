# [Unsupervised Information Refinement Training of Large Language Models   for Retrieval-Augmented Generation](https://arxiv.org/abs/2402.18150)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Retrieval-augmented generation (RAG) systems equip large language models (LLMs) with additional information from retrieval to improve text generation performance. However, LLMs still struggle to effectively utilize the retrieved texts, failing to extract correct answers, lacking ability to refine incomplete/incorrect retrieved information, and being misled by erroneous retrieved content.

- The core issue is that LLM pre-training does not explicitly teach models how to properly exploit input retrieved texts which can vary greatly in quality and usefulness. Mainstream pre-training is language modeling based on the prefix, which causes LLMs to just view retrieved texts as extended prefix rather than additional reference.

Proposed Solution:
- Introduce new perspective of LLMs as "Information Refiners" in RAG - regardless of correctness/completeness of retrieved texts, LLM should integrate knowledge in retrieved texts and model parameters to generate texts more concise, accurate and complete than the retrieved texts.

- Propose unsupervised training method called InFO-RAG with 3 scenarios: (1) extract knowledge from complex retrieved texts (2) verify, correct, complete retrieved texts using LLM knowledge (3) generate answers from LLM knowledge when retrieval unhelpful.

- Continue pre-train LLMs with constructed Wikipedia data for the 3 scenarios to enable information refinement ability. Training is generalized for diverse RAG tasks in zero-shot setting.

Main Contributions:  
- Novel "Information Refiner" perspective of LLM role in RAG and idea of LLMs producing "Positive Information Gain"
- Unsupervised InFO-RAG method to train LLMs for information refinement in RAG, widely applicable across tasks
- Experiments showing InFO-RAG enhances LLM zero-shot RAG performance over 11 datasets in 7 tasks, also improves robustness and in-context learning.
