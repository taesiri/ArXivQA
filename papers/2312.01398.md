# [Towards Mitigating Perceived Unfairness in Contracts from a Non-Legal   Stakeholder's Perspective](https://arxiv.org/abs/2312.01398)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Commercial contracts contain legally binding requirements that must be implemented by non-legal stakeholders like engineers and architects. However, these stakeholders do not directly participate in contract negotiations.  
- As a result, many contract clauses seem unfair or ambiguous from an implementation perspective, even though they are legally accurate. This perception of unfairness poses challenges in meeting contract requirements.

Solution:
- The authors conduct an empirical study to understand different stakeholders' perspectives on fairness. They find clauses can seem "clearly unfair" or "potentially unfair" to non-legal stakeholders.
- They formulate the problem as a 3-class text classification task - labeling sentences as fair, potentially unfair or clearly unfair. 
- They experiment with pre-trained language models using chain-of-thought prompting and semi-supervised fine-tuning to categorize unfairness automatically.

Key Contributions:
- First work analyzing fairness in commercial contracts from a non-legal implementation stakeholder's viewpoint. 
- Empirically analyze scenarios constituting unfairness from legal and non-legal perspectives.
- Introduce "potential unfairness" arising due to ambiguity as an important triggering factor.
- Formulate a novel 3-class classification task tailored to commercial contracts.
- Best model achieves 84% accuracy using BERT fine-tuning with data augmentation and self-training, outperforming prompting approaches.

In summary, this paper provides useful insights into perceptions of fairness in contracts and demonstrates automatic classification can assist in flagging potentially problematic clauses needing clarification before finalizing contracts.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

This paper analyzes fairness in commercial contracts from the perspective of non-legal stakeholders, proposes automatically detecting potentially unfair clauses using pre-trained language models, and achieves 84% accuracy in classifying contractual sentences as fair, potentially unfair or clearly unfair using a BERT-based model.


## What is the main contribution of this paper?

 The main contributions of this paper can be summarized as follows:

1. The authors empirically analyze fairness in commercial contracts from the perspective of non-legal stakeholders. 

2. They introduce a novel classification task tailored specifically for commercial contracts. This task categorizes sentences into three distinct classes - fair, potentially unfair, and clearly unfair.

3. They perform a set of experiments to examine the ability of Pre-Trained Language Models (PLMs) on the novel classification task. The best performing model uses BERT with data augmentation and self-training, achieving 84% accuracy on a proprietary contract dataset. This model outperforms chain of thought prompting using Vicuna-13B by a margin of 9%.

So in summary, the key contributions are: (1) an empirical study on contract fairness from a non-legal perspective, (2) formulation of a new 3-class classification task, and (3) experiments with PLMs on this task, with the best model achieving 84% accuracy using self-trained BERT.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and keywords associated with it include:

- Contractual fairness
- Non-legal stakeholders
- Commercial contracts 
- Unfairness perception
- Ambiguous language
- Potentially unfair clauses
- Clearly unfair clauses
- Empirical study
- Automated assistant 
- Pre-trained language models (PLMs)
- Chain of thought prompting  
- Semi-supervised fine-tuning
- Ternary classification
- Self-training
- Data augmentation

The paper focuses on analyzing fairness in commercial contracts from the perspective of non-legal stakeholders (such as engineers, architects etc.) who are responsible for implementing contractual requirements. It conducts an empirical study to understand different notions of unfairness and proposes automatically identifying unfair sentences that may be perceived as such by non-legal stakeholders. The main techniques explored are PLM based classification models involving chain of thought prompting and semi-supervised fine-tuning to categorize sentences as fair, potentially unfair or clearly unfair. Overall, the key themes are around contractual fairness, stakeholder perspectives and automation using NLP techniques.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper introduces a novel task of categorizing sentences as fair, potentially unfair and clearly unfair. What are some challenges in formulating clear definitions and guidelines for annotators to label sentences into these three categories? 

2. The paper uses a combination of data augmentation and self-training to improve model performance. What are some weaknesses of this semi-supervised approach? How can the quality of pseudo-labeled data be ensured?

3. The Chain of Thought (CoT) prompting strategy aims to enhance reasoning capability of language models by breaking down the task into smaller steps. In what ways can CoT prompting be further improved to boost performance on this task?

4. The paper focuses on detecting unfairness from the perspective of non-legal stakeholders. How can the proposed method be adapted to also incorporate the perspective of legal experts in determining fairness?

5. Ambiguity in clauses is identified as a trigger for perceived unfairness. What are some linguistic features and contextual cues that can help models reliably identify relevant ambiguities?  

6. The paper does not consider project-specific details and human-level attributes affecting fairness. What techniques can potentially help in automating the analysis of these factors?

7. How can the robustness of the proposed method be evaluated? What types of adversarial attacks or perturbations can be designed to analyze model vulnerabilities?

8. The paper focuses only on English contracts. What challenges need to be addressed to expand the scope to contracts in other languages? 

9. What validation studies need to be conducted before deploying such an automated contract negotiation assistant in real-world scenarios? 

10. What ethical considerations come into play with building automated systems that deal with sensitive contract data and have significant business impact?
