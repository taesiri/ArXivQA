# [Self-supervised Label Augmentation via Input Transformations](https://arxiv.org/abs/1910.05872)

## What is the central research question or hypothesis that this paper addresses?

This paper does not seem to have a clearly stated research question or hypothesis. However, based on my reading, the main focus appears to be introducing a new method for improving classification accuracy on fully supervised learning tasks by utilizing self-supervised learning techniques. Specifically, the paper proposes a "self-supervised label augmentation" (SLA) method which trains a model on both the original labeled data as well as artificial labels generated through input transformations like rotations. This allows the model to learn useful representations without forcing strict invariance to the transformations. The key ideas seem to be:- Learning a joint distribution over original and self-supervised labels rather than separate objectives.- Allowing different predictions on augmented examples via assigned transformation labels. - Aggregating predictions over augmentations at test time for an ensemble effect.- Using self-distillation to transfer aggregated knowledge to a single model.The central hypothesis then seems to be that SLA can improve accuracy over baselines on fully supervised tasks like image classification. The empirical evaluations aim to validate this hypothesis on datasets like CIFAR and FC100.In summary, while not directly stated, the paper appears to introduce and evaluate SLA as a novel way to leverage self-supervision to boost performance on standard supervised learning problems. The main hypothesis seems to be that their proposed techniques will improve accuracy over baselines.
