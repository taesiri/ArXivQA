# [RoomDreamer: Text-Driven 3D Indoor Scene Synthesis with Coherent   Geometry and Texture](https://arxiv.org/abs/2305.11337)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we leverage powerful natural language and 2D diffusion models to synthesize new 3D indoor scenes that match the structure of a given low-quality scanned mesh, while allowing control over the style/appearance through textual prompts?In other words, the key research goals are:1) Developing a method to generate high-quality 3D geometry and textures for indoor scenes based on an input mesh.2) Allowing control over the style/appearance of the generated scene using natural language prompts. 3) Ensuring the generated geometry and textures are properly aligned and consistent across the scene.4) Demonstrating the approach on real indoor meshes scanned by smartphones.The main hypothesis appears to be that by treating the scene as a whole and generating a cubemap texture, then optimizing both geometry and texture jointly, it should be possible to produce high-quality stylized results that match the structure of the input mesh but exhibit the style indicated by the text prompt. The experiments on real data aim to validate this hypothesis.In summary, the paper introduces a framework to edit and stylize scanned 3D scenes using natural language and 2D diffusion models, with a focus on controlling both geometry and coherent textures.
