# [Big Tech influence over AI research revisited: memetic analysis of   attribution of ideas to affiliation](https://arxiv.org/abs/2312.12881)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is a growing discourse that Big Tech companies dominate AI research, but our understanding of this phenomenon remains limited. 
- Prior studies oversimplify influence as the share of affiliations in papers, use limited datasets, and treat affiliation as binary (Big Tech vs Academia).

Objectives:
- Broaden and deepen understanding of Big Techâ€™s reach and power over AI research ideas (memes)
- Determine which AI ideas are predominantly driven by Big Tech 
- Compare papers with joint Big Tech-Academia affiliations to pure Big Tech/Academia papers

Methods:
- Performed network and memetic analysis on 166,455 AI papers from S2ORC and OpenAlex databases
- Used meme score to quantify replicative power of ideas 
- Introduced conditioned sticking factor to measure spread of ideas by affiliation
- Distinguished between pure and mixed academic/Big Tech affiliations 

Key Findings:
- Big Tech papers get more citations, but most cited papers have mixed Big Tech-Academia affiliations
- Mixed affiliation papers have distinct citation patterns from pure Big Tech/Academia papers  
- Most contagious ideas involve medical applications of ML and ML algorithms  
- Average contagiousness doesn't differ between affiliations, but specific ideas spread more via Big Tech  
- Data-related ideas especially contagious when mentioned by Big Tech companies

Implications:  
- Notion of Big Tech dominating AI research is overly simplistic
- More nuanced understanding of symbiosis between Academia and Big Tech needed
- This could foster a more balanced AI research landscape serving both societal welfare and scientific integrity

In summary, this comprehensive study challenges prevailing assumptions about Big Tech influence over AI research by employing novel memetic analysis revealing key differences in the spread of ideas based on academic vs industry affiliations. The findings advocate for a more thoughtful alliance between these key stakeholders.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The paper analyzes the propagation of ideas (memes) in AI research using network and memetic analysis of paper abstracts and citations, finding that while Big Tech papers receive more citations, the most cited papers have mixed Big Tech-Academia affiliations, and the contagiousness of specific memes does not significantly differ between groups, suggesting the notion of Big Tech dominance over AI research is oversimplified.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1. Introducing a more nuanced categorization of papers into three affiliation groups (Academia, mixed, and Big Tech/Company) rather than the binary Academia vs Big Tech/Company categorization commonly used in prior work. This allows them to better analyze differences between purely affiliated and mixed affiliation papers.

2. Using meme score and conditioned sticking factor to quantify the contagiousness of ideas (memes) in AI papers and how it differs based on author affiliation. This provides a novel way to trace the propagation of ideas through the AI research landscape. 

3. Finding that papers with joint Big Tech-Academia affiliations tend to be the most highly cited, challenging the notion that Big Tech dominates AI research. The contagiousness of the same ideas also tends to be higher when mentioned by Big Tech compared to Academia.

4. Providing a more balanced perspective that while Big Tech has disproportionate influence in some areas, the relationship between Big Tech and Academia is more nuanced and symbiotic overall in propagating ideas in AI research.

In summary, the main contribution is using meme score and network analysis to give a more in-depth quantification of Big Tech's influence over AI research ideas, finding it to be less dominant than sometimes portrayed. The introduced conditioned sticking factor also provides a new way to analyze future idea flows.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this paper include:

- Memetic analysis - The use of memes and meme scores to analyze the spread and influence of ideas in AI research. This is a central concept in the paper.

- Big Tech influence - Examining the role and influence of major technology companies like Google, Microsoft, etc. on AI research. Assessing the notion of Big Tech dominance.

- Academia influence - Also looking at the influence and role of academic institutions on AI research. Comparing this to Big Tech influence.  

- Contagiousness of ideas - Using metrics like meme score and sticking factor to quantify how easily ideas and concepts spread through the research literature and community.

- Conditioned sticking factor - A modified sticking factor metric introduced in the paper to analyze how affiliation (Big Tech, Academia, etc.) impacts the contagiousness of ideas.

- Citation analysis - Leveraging citation data and networks to study the propagation of ideas between papers and author groups.

- Affiliation categories - Dividing papers into affiliation groups like Big Tech, Academia, Companies, and mixed affiliation to compare idea contagiousness.  

- Framing theory - Concept that memes can be perceived differently depending on interpretive frames tied to author affiliations.

Those cover some of the major terms and concepts discussed in the paper related to analyzing and comparing the influence of Big Tech and Academia on AI research.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. The paper introduces the concept of a "conditioned sticking factor" to analyze the relationship between author affiliations and meme contagiousness. How does this metric build upon or differ from the original "sticking factor" proposed in prior literature on memetics? What new insights does it provide?

2. The authors make a case against binary classifications of papers into "Academia" or "Big Tech" by analyzing papers with mixed affiliations. What implications could this more nuanced perspective have on future bibliometric analyses or science policy discussions regarding industry influence? 

3. What potential limitations could there be in using noun phrases to represent memes? Could this approach fail to capture semantic similarity between different phrases expressing related concepts? How might the authors' approach address issues around synonymity?  

4. The authors find that Big Tech papers exhibit higher conditioned sticking factors compared to academic papers. What theories from communication, sociology or other disciplines could help explain this result? Does it suggest Big Tech plays a dominant role in shaping research trajectories?

5. How robust are the detected differences in conditioned sticking factors between affiliation categories? Have the authors tested the sensitivity of their results to choices around meme selection, minimum appearances, etc?  

6. Have the authors considered analyzing changes in conditioned sticking factors over time? This could shed light on whether industry influence on AI research is expanding or contracting. What challenges might this type of analysis entail?

7. What other modalities, besides author affiliation, could the conditioned sticking factor be applied to in order to study the propagation of scientific ideas? For instance, could it be used to analyze national or gender differences?   

8. The authors annotate memes into categories using human coders. How might automated clustering or topic modeling techniques complement or validate these human-generated meme categories? What are the tradeoffs between manual vs automated topic assignment?

9. The paper focuses exclusively on AI research. To what extent could the demonstrated approach generalize to other scientific domains? What adaptations would be required to study memetics in more specialized or interdisciplinary fields? 

10. The authors measure contagiousness using citation networks. What alternative signals - such as media mentions, collaborations, or policy documents - could supplement citations to develop a broader conception of meme propagation and impact? What challenges would this multi-modal approach introduce?
