# [Learning to Generate Explainable Stock Predictions using Self-Reflective   Large Language Models](https://arxiv.org/abs/2402.03659)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
- Explaining stock price predictions is difficult for traditional deep learning models, as explanations are limited to visualizing attention weights. 
- Large language models (LLMs) can generate explanations, but weighing diverse social media texts on stock prices is challenging.  
- Getting training data of expert explanations for each stock movement is expensive and not scalable.

Proposed Solution:
- Summarize-Explain-Predict (SEP) framework that allows a LLM to teach itself via self-reflection.
- Summarize module uses LLM's summarization ability to extract key facts from texts.  
- Explain module lets LLM make stock predictions and explain reasoning over summarized facts. It uses self-reflection to iteratively improve explanations without human annotation.
- Predict module fine-tunes LLM with proximal policy optimization (PPO) using self-generated explanation samples to make stock predictions at test time.

Main Contributions:
- Investigated limitations of teaching LLMs to weigh information in texts and explain stock predictions without expert-annotated samples.
- Proposed a self-reflective agent and PPO method for LLM to teach itself explainable stock prediction. 
- Showed SEP model outperforms deep learning and LLM methods in prediction accuracy and explanation quality.
- Demonstrated generalization capability of SEP framework via application on portfolio construction task.

In summary, this paper proposed an innovative self-supervised SEP framework to address the lack of training data problem for teaching LLMs how to make explainable stock market predictions. The key ideas are leveraging self-reflection so the LLM can teach itself via self-generated feedback, and using PPO to further specialize the LLM for this task.
