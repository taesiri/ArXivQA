# [Right Place, Right Time! Towards ObjectNav for Non-Stationary Goals](https://arxiv.org/abs/2403.09905)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- The paper addresses the task of Object Navigation (ObjectNav) in dynamic environments where the target objects can move during an episode. 
- Existing works have focused on ObjectNav in static environments with fixed target object locations. Navigating to non-stationary goals in dynamic environments presents unique challenges.

Proposed Solution:
- The paper formulates a new task called Portable Object Navigation (P-ObjectNav) for navigating to non-stationary target objects. 
- To enable this, the Matterport3D dataset is modified to place portable objects in different locations at different time steps, following either random or routine movement patterns.
- Both PPO-based and LLM-based navigation policies are developed. The LLM-based policy uses selective memory enhancement to leverage observations history for improved performance.

Main Contributions:
- Formulates the novel P-ObjectNav task for non-stationary target objects in dynamic environments.
- Modifies Matterport3D to create datasets with portable objects following random or routine movement.
- Shows via a PPO agent that learning is feasible when objects follow routines but not random patterns.
- Develops LLM-based policy for P-ObjectNav using selective memory enhancement.
- Memory-enhanced LLM policy significantly outperforms non-memory baselines, establishing a new benchmark for the task.
- Overall demonstrates the feasibility of P-ObjectNav in dynamic environments with routine object patterns.

In summary, the paper tackles the challenging problem of ObjectNav with non-stationary targets by formulating the P-ObjectNav task. The feasibility of learning in routine vs random environments is analyzed. A memory-enhanced LLM-based agent sets a new benchmark for the task.
