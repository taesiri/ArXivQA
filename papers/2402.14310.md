# [Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize   Encoded Knowledge](https://arxiv.org/abs/2402.14310)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) have extensive knowledge but struggle to effectively utilize it to develop accurate and logical reasoning when solving complex reasoning tasks like mathematical and commonsense reasoning.
- Existing work has limitations: fine-tuning is resource-intensive; prompt engineering methods don't directly aim to improve knowledge usage; retrieval augmentation is limited to specific tasks. 

Proposed Solution:
- Introduce Hint-before-Solving Prompting (HSP) which guides the LLM to first generate hints containing key knowledge, concepts or analysis before generating the full solution.
- HSP can be flexibly combined with existing prompting methods like Chain-of-Thought (CoT), Least-to-Most, Plan-and-Solve, and Standard prompting.
- Also propose a two-stage variant HSP2 which separates hint and solution generation.

Key Contributions:  
- Discovered providing hints allows more accurate knowledge usage, e.g. 9.7% average accuracy gain on 6 reasoning datasets for Llama2-70B+CoT.
- HSP boosts existing prompting methods, works for both mathematical and commonsense reasoning. More effective for CoT prompting.
- With high-quality hints from GPT-4, open-source LLM outpaces ChatGPT. More improvements for lower-capability LLM.
- Supervised fine-tuning Llemma-7B on HSP format dataset reaches 64.3% on GSM8K, surpassing GPT-3.5 and WizardMath-13B.

In summary, the key idea is guiding the LLM to generate knowledge-related hints before solving to improve reasoning accuracy and logic. Both prompt-based and fine-tuning results demonstrate effectiveness.
