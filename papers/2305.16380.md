# [Scan and Snap: Understanding Training Dynamics and Token Composition in   1-layer Transformer](https://arxiv.org/abs/2305.16380)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is that the self-attention mechanism in Transformers acts as a discriminative scanning algorithm during training, progressively focusing on key tokens that are most relevant for predicting the next token. Specifically, the paper analyzes the training dynamics of a 1-layer Transformer on a next token prediction task. Under certain assumptions, including no positional encoding, a long input sequence, and a faster learning decoder layer, the paper mathematically proves that self-attention gravitates towards tokens that:1) Are "distinct", meaning they only occur in the context of a specific next token, rather than "common" tokens that occur across contexts. 2) Have high co-occurrence frequency with the next token being predicted, compared to distinct tokens with lower co-occurrence.3) Were less attended to initially, following a low-to-high attention order based on the above co-occurrence frequency. So in essence, the self-attention mechanism demonstrates an inductive bias towards scanning for and focusing on the most relevant distinct tokens for prediction, acting like a discriminative feature selector. This provides a rigorous explanation for how self-attention learns to focus on key parts of the input during training.
