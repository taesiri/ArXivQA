# [Forbidden Facts: An Investigation of Competing Objectives in Llama-2](https://arxiv.org/abs/2312.08793)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper studies how Llama-2 chat models resolve competing objectives, using a "forbidden fact" task where the model must answer a factual recall question without stating the correct answer. The authors find that forbidding the right answer drastically reduces the probability of Llama-2 stating it correctly. By decomposing Llama-2 into over 1000 components, they identify around 35 key components that reliably implement this suppression behavior. However, analysis shows these components use messy, heterogeneous heuristics rather than a simple suppression algorithm. One faulty heuristic was exploited to craft an "California attack" that fools the model by innocuously placing the correct answer in the prompt. Overall, the complex mechanisms behind even simple behaviors pose challenges for interpretability and providing guarantees about model behavior. The results suggest goals like human-understandable explanations may be difficult for advanced AI. However, this could be because Llama-2 uses unintelligent heuristics, rather than such complexity being inherent to intelligence.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- The paper studies how large language models (LLMs) like Llama-2 resolve competing objectives or pressures, using a "forbidden fact" task. 
- In this task, the model is asked to complete a factual statement (e.g. "The Golden Gate Bridge is in the state of __") but is forbidden from stating the correct answer (e.g. "California"). This creates a tension between answering correctly and obeying the constraint.

Methodology
- The authors create a dataset of factual statements paired with competing and non-competing forbidden words. 
- They decompose Llama-2 into over 1000 components and rank each component based on its importance for suppressing the correct answer in the competing case.  
- The top 35 components are enough to replicate the full suppression behavior. The authors analyze these components in detail.

Key Findings
- The most important suppression components are heterogeneous and appear to use complex, faulty heuristics rather than an straightforward algorithm. 
- These components privilege semantic information about what token is most likely to be the correct answer. 
- One faulty heuristic can be exploited via an "California Attack", where innocuously mentioning California in the prompt causes Llama-2 to wrongly suppress that token.

Main Contributions
- Provides evidence that even simple behaviors in LLMs may be implemented in messy, heterogeneous ways rather than clean algorithms.
- Develops a novel "forbidden fact" task and dataset to study competing objectives.
- Ranks over 1000 components in Llama-2 based on their importance for suppression using a first-order patching methodology.
- Discovers attack exploiting faulty heuristic in Llama-2's suppression circuitry.
- Suggests fundamental goals like interpretability and behavioral guarantees may be very difficult for advanced AI systems.
