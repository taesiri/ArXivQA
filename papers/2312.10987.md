# [Data Contamination Issues in Brain-to-Text Decoding](https://arxiv.org/abs/2312.10987)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Brain-to-text decoding aims to decode non-invasive cognitive signals (e.g. fMRI, EEG) into corresponding natural language text. This enables building practical brain-computer interfaces (BCIs).  
- However, how to split datasets for training, validation and testing remains an open question. The choices significantly impact model performance evaluation.

Key Insights:
- Existing dataset splitting methods suffer from two types of data contamination:
    1) Cognitive signal leakage: Subjects' signals in test set leaking into training set, causing encoder overfitting
    2) Text stimuli leakage: Text stimuli sentences in test set leaking into training set, allowing decoder to memorize and cheat
- These exaggerate model performance and generalizability. A principled splitting method without such leakage is needed.

Proposed Solution:
- Split dataset into subject-stimuli pairs, ensuring:
    1) Subjects in validation/test sets do not appear in training set 
    2) Text stimuli in validation/test sets do not appear in training set
- This eliminates both kinds of data contamination and allows fair evaluation.
- Detailed algorithms catering to EEG and fMRI data characteristics are provided.

Contributions:  
- First paper investigating dataset splitting for brain-to-text decoding
- Proved existence of data contamination issues in current methods through analysis and experiments
- Proposed first splitting technique eliminating both kinds of leakage 
- Re-evaluated SOTA models under new splits to release fair benchmark

The paper makes an important contribution in formalizing dataset splitting for this problem. The insights and proposed technique will enable more rigorous evaluation of models going forward.
