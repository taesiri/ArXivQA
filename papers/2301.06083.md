# [Discrete Point-wise Attack Is Not Enough: Generalized Manifold   Adversarial Attack for Face Recognition](https://arxiv.org/abs/2301.06083)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we develop a more effective adversarial attack method for face recognition models that produces adversarial examples with better generalization ability and higher attack success rates? 

The key hypotheses appear to be:

1) Existing adversarial attack methods for face recognition models tend to overfit to particular image factors like expression or makeup when attacking a single image. This results in poor generalization to other unseen images of the target identity. 

2) Expanding the attack to multiple images of a target identity, representing different states like expressions, will improve generalization of the adversarial examples.

3) Leveraging domain knowledge like facial action coding to generate a continuous manifold of adversarial examples, rather than just discrete examples, will further enhance attack effectiveness.

4) Adding constraints and supervisory signals based on facial structure can improve the visual quality of the generated adversarial examples.

The central goal is to develop a new adversarial attack method called Generalized Manifold Adversarial Attack (GMAA) that expands the attack to multiple target identity states and generates a continuous semantic manifold of adversarial examples to achieve better generalization, higher attack success rate, and more natural appearance compared to existing methods. The experiments aim to validate whether the proposed GMAA approach actually achieves these hypothesized improvements.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- It proposes a new paradigm called Generalized Manifold Adversarial Attack (GMAA) for generating adversarial examples against face recognition systems. 

- GMAA expands both the target domain and adversarial domain compared to previous attack methods:
  - For the target domain, it attacks a state set of the target identity rather than a single image, which improves generalization.
  - For the adversarial domain, it leverages domain knowledge (facial expressions) to expand from discrete points to a continuous manifold, strengthening the attack.
  
- It instantiates GMAA using facial expressions as the domain knowledge, allowing generation of semantically continuous adversarial examples by interpolating between expression codes.

- As a minor contribution, it uses expression editors for dual supervision of global structure and local texture to improve visual quality.

- Through extensive experiments, it demonstrates the improved attack success rate, generalization ability, and visual quality of GMAA compared to prior methods.

In summary, the key novelty is the new GMAA paradigm that expands both the target and adversarial domains to enhance attack performance. It is instantiated for faces using expression as domain knowledge for a semantically continuous adversarial manifold.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points in the paper:

The paper proposes a new paradigm called Generalized Manifold Adversarial Attack (GMAA) to enhance adversarial attack performance on face recognition models by expanding the target domain to attack multiple states of an identity and leveraging facial expression editing techniques and domain knowledge to expand the adversarial domain from discrete points to continuous manifolds.


## How does this paper compare to other research in the same field?

 Here are a few key comparisons between this paper and other related research in adversarial attacks on face recognition models:

- This paper proposes a new paradigm called Generalized Manifold Adversarial Attack (GMAA) that expands both the target domain and adversarial domain compared to previous point-wise attack methods. It attacks a state set of the target identity rather than a single image to improve generalization, and leverages domain knowledge to generate a continuous adversarial manifold rather than discrete examples. This is a novel framework compared to most prior work.

- Many previous attack methods like PGD, MI-FGSM, TIP-IM focus on generating discrete adversarial examples bounded in an Lp norm ball around the clean image. This paper argues these have poor generalization and continuity. GMAA provides a more generalized continuous attack space.

- Some recent work has looked at geometry/semantic based attacks like SemanticAdv and makeup/style transfer attacks like AMT-GAN. But these still produce discrete examples. GMAA produces a continuous manifold using domain knowledge of facial expressions.

- For expression editing, GMAA is inspired by recent generative models like GANimation that also use facial action unit vectors to enable continuous expression changes. GMAA incorporates this idea for its adversarial manifold.

- GMAA proposes a novel generalized attack module to attack a state set of the target identity. This improves generalization compared to attacking just a single image target.

- It also uses facial expression editors for dual supervision of global structure and local texture details to improve visual quality.

Overall, GMAA introduces a new paradigm for adversarial attacks using target expansion, domain knowledge manifolds, and dual supervision for generalization, continuity, and quality. The core ideas seem fairly novel compared to prior art in this field.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors are:

- Exploring other domain knowledge besides facial expressions that could be integrated into the GMAA framework to generate adversarial examples. The authors mention illumination and posture as examples. This could allow GMAA to be generalized to other image domains beyond faces.

- Applying GMAA to other adversarial attack tasks beyond facial recognition, such as general image classification. The authors suggest that by selecting different state spaces, GMAA could potentially be adapted to generate adversarial examples for broader image categories.

- Further improving the visual quality and imperceptibility of the generated adversarial examples. While GMAA produces more natural looking examples than other methods, there is still room for improvement in terms of minimizing perceptual artifacts. 

- Developing more robust defenses against GMAA and similar manifold attack methods. Understanding the limitations and vulnerabilities of GMAA could inspire new defenses.

- Exploring how factors like the number of target identity states used for training impact generalization performance. More analysis on the tradeoffs between generalization and training efficiency could help optimize GMAA.

- Extending GMAA to video or other sequential data rather than just static images. The continuity and manifold properties of GMAA may lend themselves well to these domains.

So in summary, the main directions are generalizing GMAA to other domains and data types, improving the adversarial example quality, developing defenses against this style of attack, and further analysis/optimization of the method itself. The overall goal is advancing manifold adversarial attacks and their defenses.


## Summarize the paper in one paragraph.

 This paper proposes a novel adversarial attack method called Generalized Manifold Adversarial Attack (GMAA) for face recognition systems. The key ideas are:

1) Previous adversarial attack methods typically generate adversarial examples for a single image of the target identity, which has poor generalization to other unseen images of that identity. GMAA expands the attack to a set of images representing different states (expressions, poses, etc.) of the target identity. This improves generalization ability. 

2) Most methods generate discrete adversarial examples bounded in an Lp norm ball around the original image. GMAA leverages domain knowledge, like facial expressions, to generate a continuous manifold of adversarial examples that share semantic meaning. This further strengthens the attack.

3) GMAA uses an adversarial generator trained with multiple losses. These include an adversarial loss to fool face recognition models, an expression loss to generate examples with desired expressions based on an expression coding system, and identity and local texture losses to maintain natural image quality. 

4) Evaluations demonstrate GMAA achieves higher black-box attack success rates against face recognition models compared to previous methods, while generating more semantically meaningful and natural adversarial manifolds.

In summary, GMAA generates more generalized and stronger adversarial attacks against face recognition by expanding the target identity and output manifold using domain knowledge. This is a novel attack paradigm for generating semantically continuous adversarial examples.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points from the paper:

This paper proposes a new paradigm called Generalized Manifold Adversarial Attack (GMAA) to enhance the performance of adversarial attacks on face recognition models. Previous attack methods generate discrete adversarial examples to fool a single image of the target identity, which exhibits poor generalization against unseen states of that identity. GMAA expands the attack in two aspects - attacking a state set of the target identity rather than a single image to improve generalization, and leveraging domain knowledge like facial expressions to expand the attack from discrete points to a continuous manifold. This strengthens the attack by acting like a data augmentation mechanism. 

GMAA is instantiated using facial action coding of expressions as domain knowledge to establish a continuous expression state space. The attack is trained on a set of expression states of the target identity using a generative adversarial network framework with additional modules for expression and identity supervision. Experiments demonstrate GMAA's superior attack success rate and transferability compared to previous methods. The generalized attack module can also be incorporated into other attack methods. Overall, GMAA provides a new paradigm for adversarial attacks that expands both the target and adversarial domains for enhanced performance.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes a new paradigm called Generalized Manifold Adversarial Attack (GMAA) to enhance the performance of adversarial attacks on face recognition models. The key ideas are:

1) Expand the target domain from attacking a single image to attacking a set of images representing different states of the target identity. This improves the generalization of the attack to unseen images of the target identity. 

2) Leverage domain knowledge (facial action coding system) to expand the adversarial domain from discrete points to a continuous manifold. This allows generating semantically meaningful adversarial examples along the manifold.

3) Use generative adversarial networks with dual supervision on global structure and local details to generate high quality adversarial examples. 

4) Enhance transferability by attacking multiple white-box models during training.

Overall, GMAA expands both the target and adversarial domains compared to traditional point-wise attacks, resulting in more generalized and semantically meaningful attacks with good visual quality and transferability. The experiments demonstrate the effectiveness of GMAA against state-of-the-art attack methods.
