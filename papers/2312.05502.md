# [Poisoning $\times$ Evasion: Symbiotic Adversarial Robustness for Graph   Neural Networks](https://arxiv.org/abs/2312.05502)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Poisoning x Evasion: Symbiotic Adversarial Robustness for Graph Neural Networks":

Problem:
- The paper studies the vulnerability of graph neural networks (GNNs) to adversarial attacks that manipulate the structure of the graph. 
- Prior work has studied evasion attacks (perturb test graph) and poisoning attacks (perturb train graph). 
- This paper proposes a new threat model that combines both evasion and poisoning, which the authors call "symbiotic attacks". The goal is to maximize damage to model accuracy with a constrained budget of edge perturbations.

Proposed Solution:
- The paper adapts an existing attack (PR-BCD) to the symbiotic setting. Two variants are proposed:
   - Sequential: Split budget between poisoning and evasion steps
   - Joint: Optimization alternates between poisoning and evasion objectives
- Attacks are optimized to minimize GNN accuracy on a subset of test nodes. Can scale to large graphs.

Main Contributions:
- Introduces and formalizes the symbiotic threat model for GNN robustness.
- Empirically demonstrates that symbiotic attacks substantially outperform standalone poisoning or evasion attacks.
- Shows symbiotic attacks can reduce model accuracy close to 0% on datasets like PubMed.
- Evasion performance degrades with more test nodes, but symbiotic is more robust.
- Provides promising direction for developing specialized attacks under this threat model.

In summary, the paper opens up a new dimension in adversarial attacks against graph neural networks by combining test-time and train-time manipulation. The proposed first attacks in this model showcase its potential danger, outperforming previous poisoning or evasion only attacks.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper proposes a new threat model combining evasion and poisoning attacks, called symbiotic attacks, against graph neural networks for node classification, and shows that these attacks consistently outperform standard evasion or poisoning attacks alone.


## What is the main contribution of this paper?

 The main contribution of this paper is initiating the study of a new threat model called "symbiotic attacks", which combines graph poisoning and evasion attacks. Specifically:

- The paper proposes and evaluates two methods (sequential and joint attacks) for launching symbiotic attacks that manipulate the graph structure during both training and testing to maximize damage to model accuracy. 

- Through experiments on node classification tasks, the paper shows that symbiotic attacks can be much more devastating than plain poisoning or evasion attacks, especially on larger graphs and with fewer labeled training nodes. For example, they demonstrate a drop in accuracy to almost 0% on PubMed dataset under certain settings.

- The paper analyzes how the relative robustness of evasion vs poisoning changes with the number of test nodes, highlighting a key difference between the two threat models.

- The results showcase the significance of studying this new threat model further, both in terms of developing stronger attacks and more robust defense mechanisms. The paper concludes by outlining multiple promising research directions for future work on symbiotic robustness.

In summary, the key contribution is identifying and showcasing the potential of a novel threat model by adapting existing attacks to it and systematically evaluating its impact compared to other models.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper abstract and contents, here are some of the key terms and keywords associated with this paper:

- Graph neural networks (GNNs)
- Adversarial attacks
- Adversarial robustness 
- Evasion attacks
- Poisoning attacks
- Symbiotic attacks (combining evasion and poisoning)
- Threat models
- Node classification
- Structure perturbations
- First-order optimization
- Memory-efficient attacks
- Projected Randomized Block Coordinate Descent (PR-BCD) attack

The main focus of the paper is on studying the adversarial robustness of graph neural networks, with a novel threat model combining evasion and poisoning attacks called "symbiotic attacks". The key findings show that these combined attacks are stronger than individual evasion or poisoning attacks. The attacks are based on the PR-BCD framework and optimized using first-order methods to scale to large graphs. Overall, the symbiotic attacks showcase the vulnerability of GNNs and why their robustness needs further study.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1. The paper proposes a new threat model combining evasion and poisoning attacks, which they term "symbiotic" attacks. What is the intuition behind why combining evasion and poisoning can lead to stronger attacks compared to either one alone?

2. The paper presents two types of symbiotic attacks: sequential and joint. Can you explain the key differences in how these two attacks operate? What are the potential pros and cons of each?  

3. The joint attack includes an inner evasion attack within each iteration of the poisoning attack. What is the purpose of this inner evasion attack? How does it help guide the poisoning perturbations?

4. One finding is that the proposed symbiotic attacks are more robust to larger test set sizes compared to plain evasion attacks. What explains this difference in robustness? How does the ability to manipulate the graph during training help?

5. Could you propose some alternative ways the evasion attack could be incorporated into the poisoning attack for the joint symbiotic attack? What are some other signals the poisoning attack could try to optimize for?

6. The inner evasion attacks do not seem to help much when more iterations are used (Figure 5). Why might this be the case? What factors make it difficult to estimate good evasion perturbations from within the poisoning attack?

7. How suitable do you think the block coordinate descent framework used in this paper is for the proposed symbiotic attacks? What are some weaknesses you see in this approach or areas for improvement? 

8. What types of constraints would you propose to make symbiotic attacks more realistic or applicable to real-world graphs? For example, structural constraints, degree distribution constraints, or targeted attacks.

9. The paper focuses on edge-level perturbations for node classification. How do you think the threat model would differ if other tasks like graph classification were considered instead? What about other perturbation types like node insertion/deletion?

10. Could defensive techniques like adversarial training help improve robustness against symbiotic attacks? What challenges do you foresee in generating the perturbations or training the defenses?
