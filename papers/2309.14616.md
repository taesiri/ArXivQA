# [NDC-Scene: Boost Monocular 3D Semantic Scene Completion in Normalized   Device Coordinates Space](https://arxiv.org/abs/2309.14616)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research focus of this paper is to address some of the critical limitations in existing state-of-the-art techniques for monocular 3D semantic scene completion. Specifically, the paper identifies three core issues:

1) Feature Ambiguity: Existing methods like MonoScene use feature projection along camera rays, which leads to ambiguity in feature size and depth. 

2) Pose Ambiguity: The lack of camera extrinsic information means 3D convolutions used by current approaches are insensitive to viewpoint changes. 

3) Computation Imbalance: Perspective projection used in prior works causes imbalanced feature density and computation allocation between near and far regions.

To address these issues, the central hypothesis of this work is that transferring computation from the target 3D space to a proposed Normalized Device Coordinate (NDC) space can effectively resolve the above problems and lead to improved performance on monocular semantic scene completion. The key ideas are:

- Use deconvolution to extend 2D features to NDC space to avoid projection ambiguity 

- Shift computations to NDC space to avoid pose ambiguity and imbalance

- Design a Depth Adaptive Dual Decoder to robustly fuse 2D and 3D features in this space

Through experiments on large-scale indoor and outdoor datasets, the paper aims to validate that the proposed NDC-based approach can consistently outperform prior state-of-the-art monocular semantic scene completion techniques.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Identifying critical issues with existing state-of-the-art monocular 3D semantic scene completion methods, including feature ambiguity, pose ambiguity and computation imbalance. 

2. Proposing a novel framework based on Normalized Device Coordinates (NDC) space to address these issues. Specifically:

- The NDC space avoids feature ambiguity by directly extending the 2D feature map to 3D, enabling implicit learning of occupancy and semantics. 

- Shifting computation to the NDC space resolves pose ambiguity and computation imbalance issues.

- A Depth-Adaptive Dual Decoder is introduced to jointly upsample and fuse 2D and 3D features for robust 3D semantic representations.

3. Extensive experiments validating the proposed approach, demonstrating state-of-the-art performance on large-scale indoor (NYUv2) and outdoor (SemanticKITTI) datasets.

4. Ablation studies verifying the contribution of key components of the proposed method in tackling the identified issues.

In summary, the core contribution is the novel NDC-based framework to overcome limitations of prior monocular 3D semantic scene completion techniques for improved performance and generalizability. The paper provides both quantitative evidence and detailed analysis to demonstrate the effectiveness of the proposed approach.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a novel framework named NDC-Scene for monocular 3D semantic scene completion that transfers computation from the target 3D space to a normalized device coordinates space to address issues like feature ambiguity, pose ambiguity, and computation imbalance that exist in prior works, and uses a depth-adaptive dual decoder to simultaneously upsample 2D and 3D features to achieve better representations and performance on indoor and outdoor datasets.


## How does this paper compare to other research in the same field?

 Here are a few key points comparing this paper to other research in monocular 3D semantic scene completion:

- This paper focuses on identifying and addressing several limitations of prior work in this field, namely feature ambiguity, pose ambiguity, and computation imbalance. Many existing methods do not explicitly consider or tackle these issues.

- The proposed NDC-Scene method introduces a normalized device coordinates (NDC) space to generate 3D feature maps instead of directly projecting 2D features into the target 3D space. This helps resolve the feature and pose ambiguity problems. 

- Using the NDC space allows transferring more computation from the target 3D space to 2D, alleviating computation imbalance across depth levels. Most prior works do not explicitly address this imbalance.

- The depth-adaptive dual decoder is a novel component for fusing 2D and 3D features in a depth-aware manner. This facilitates generating stronger 3D semantic representations compared to naive fusion techniques.

- Extensive experiments on large-scale indoor and outdoor datasets demonstrate NDC-Scene outperforms recent state-of-the-art monocular methods like MonoScene. Many existing works are only evaluated on smaller datasets.

- The code and models are made publicly available, facilitating reproduction and future research. Some prior works lack open-sourced implementations.

Overall, a key distinction is this paper's focus on analyzing limitations of prior art and introducing components like the NDC space and dual decoder to explicitly tackle those limitations. The extensive experiments highlight the efficacy of the proposed techniques for monocular 3D semantic scene completion.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the key future research directions suggested by the authors include:

- Exploring other canonical spaces besides the proposed normalized device coordinates space. The authors show the benefits of transferring computation from the target 3D space to their proposed canonical space. However, they suggest exploring other potential canonical spaces as an area for future work.

- Investigating different fusion methods for integrating 2D and 3D features instead of the proposed depth-adaptive attention. The depth-adaptive fusion mechanism is shown to be beneficial, but the authors indicate that exploring other fusion techniques could lead to further improvements. 

- Extending the method to support video input. The current method operates on single RGB images. The authors suggest investigating extensions to leverage temporal information from video for monocular 3D scene completion.

- Applying the approach to other monocular 3D tasks beyond semantic scene completion, such as 3D object detection and segmentation. The authors propose that the benefits of their method may generalize to other monocular 3D perception problems.

- Improving runtime efficiency. The authors note that efficiency can be improved in the future, including through neural architecture search and model compression techniques.

- Incorporating other monocular cues such as shading and texture to enhance completion. The method currently uses only RGB images, but the authors suggest exploring how additional monocular signals could aid scene understanding.

In summary, the main future directions pointed out revolve around exploring alternative canonical spaces and fusion techniques, extending the approach to video and other tasks, and improving efficiency and the use of monocular cues. The core ideas show promise for monocular 3D perception, and the authors provide thoughtful suggestions for advancing research in this field.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper proposes a novel framework called NDC-Scene for monocular 3D semantic scene completion. Current state-of-the-art methods suffer from issues like feature ambiguity, pose ambiguity, and computation imbalance when projecting 2D features to 3D. To address this, NDC-Scene introduces a normalized device coordinates (NDC) space that extends the 2D feature map to 3D by restoring the depth dimension with deconvolutions. This avoids the ambiguities and imbalance of projecting to world space. NDC-Scene also uses a depth-adaptive dual decoder to simultaneously upsample 2D and 3D features and fuse them in a depth-aware manner for better representations. Experiments on large-scale indoor (NYUv2) and outdoor (SemanticKITTI) datasets show NDC-Scene substantially outperforms prior works. The key contributions are: 1) Identifying critical issues in existing monocular scene completion methods; 2) Proposing NDC space to avoid these issues by restoring features before projecting to world space; 3) Designing a depth-adaptive dual decoder to integrate 2D and 3D features.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper proposes a novel framework called NDC-Scene for monocular 3D semantic scene completion from a single RGB image. The key idea is to perform scene completion in a proposed normalized device coordinates (NDC) space rather than directly in the target 3D space. The NDC space is derived by extending the 2D image coordinates with a depth dimension. This avoids several issues that arise when lifting 2D features directly to the target space, including feature size ambiguity, feature depth ambiguity, pose ambiguity of 3D convolutions, and imbalanced computation allocation. 

Specifically, the framework first encodes the RGB image using a 2D encoder to produce a 2D feature map. This is extended to 3D via a depth-adaptive dual decoder which restores depth information and fuses 2D and 3D features. Scene completion is then performed in the resulting NDC space using a lightweight 3D UNet. Experiments on large-scale indoor (NYUv2) and outdoor (SemanticKITTI) datasets demonstrate state-of-the-art performance. Benefits include more accurate geometric completion and semantics, especially for close objects. Ablations verify the importance of performing completion in NDC space. Overall, the paper presents a novel and effective approach for monocular scene completion.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes a novel framework called NDC-Scene for monocular 3D semantic scene completion. The key idea is to extend the 2D feature map from an image encoder directly to a 3D space called the normalized device coordinates (NDC) space by progressively restoring the depth dimension using deconvolution operations. This avoids the ambiguities that arise from projecting 2D features to the 3D space using techniques like line of sight projection. The paper also proposes a depth adaptive dual decoder that simultaneously upsamples the 2D and 3D feature maps in separate branches and fuses them in a depth adaptive manner, allowing robust 3D semantic feature representations to be obtained. By transferring most of the 3D computation to the NDC space rather than the target 3D space, the method is able to achieve significantly improved performance on large-scale indoor and outdoor 3D semantic scene completion benchmarks compared to prior state-of-the-art approaches.


## What problem or question is the paper addressing?

 Based on my reading, this paper is addressing several key challenges in monocular 3D semantic scene completion (SSC). The main problems/questions it is trying to tackle are:

1) Feature Ambiguity: Current state-of-the-art monocular SSC methods use feature line-of-sight projection (FLoSP) to lift 2D features to 3D. However, this introduces ambiguity in the projected 3D features along two dimensions: 

- Feature-Size Ambiguity: The feature density varies at different depths due to perspective projection. This makes it hard for convolution kernels to identify effective patterns.

- Feature-Depth Ambiguity: Shared 2D features are propagated to all voxels along a ray, making depth and semantic information indistinguishable. 

2) Pose Ambiguity: 3D convolutions in current methods are performed without accounting for camera pose. This means the convolution is misaligned and has an inconsistent scope across poses.

3) Computation Imbalance: Perspective projection causes an imbalanced allocation of computation between near and far regions when projecting 2D to 3D. This limits the ability to capture details from near regions.

To summarize, the key problems are ambiguity in the lifted 3D features, ambiguity caused by not conditioning on camera pose, and imbalanced computation allocation between depths. The paper aims to address these limitations to improve monocular SSC.
