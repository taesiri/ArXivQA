# [NDC-Scene: Boost Monocular 3D Semantic Scene Completion in Normalized   Device Coordinates Space](https://arxiv.org/abs/2309.14616)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research focus of this paper is to address some of the critical limitations in existing state-of-the-art techniques for monocular 3D semantic scene completion. Specifically, the paper identifies three core issues:

1) Feature Ambiguity: Existing methods like MonoScene use feature projection along camera rays, which leads to ambiguity in feature size and depth. 

2) Pose Ambiguity: The lack of camera extrinsic information means 3D convolutions used by current approaches are insensitive to viewpoint changes. 

3) Computation Imbalance: Perspective projection used in prior works causes imbalanced feature density and computation allocation between near and far regions.

To address these issues, the central hypothesis of this work is that transferring computation from the target 3D space to a proposed Normalized Device Coordinate (NDC) space can effectively resolve the above problems and lead to improved performance on monocular semantic scene completion. The key ideas are:

- Use deconvolution to extend 2D features to NDC space to avoid projection ambiguity 

- Shift computations to NDC space to avoid pose ambiguity and imbalance

- Design a Depth Adaptive Dual Decoder to robustly fuse 2D and 3D features in this space

Through experiments on large-scale indoor and outdoor datasets, the paper aims to validate that the proposed NDC-based approach can consistently outperform prior state-of-the-art monocular semantic scene completion techniques.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Identifying critical issues with existing state-of-the-art monocular 3D semantic scene completion methods, including feature ambiguity, pose ambiguity and computation imbalance. 

2. Proposing a novel framework based on Normalized Device Coordinates (NDC) space to address these issues. Specifically:

- The NDC space avoids feature ambiguity by directly extending the 2D feature map to 3D, enabling implicit learning of occupancy and semantics. 

- Shifting computation to the NDC space resolves pose ambiguity and computation imbalance issues.

- A Depth-Adaptive Dual Decoder is introduced to jointly upsample and fuse 2D and 3D features for robust 3D semantic representations.

3. Extensive experiments validating the proposed approach, demonstrating state-of-the-art performance on large-scale indoor (NYUv2) and outdoor (SemanticKITTI) datasets.

4. Ablation studies verifying the contribution of key components of the proposed method in tackling the identified issues.

In summary, the core contribution is the novel NDC-based framework to overcome limitations of prior monocular 3D semantic scene completion techniques for improved performance and generalizability. The paper provides both quantitative evidence and detailed analysis to demonstrate the effectiveness of the proposed approach.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a novel framework named NDC-Scene for monocular 3D semantic scene completion that transfers computation from the target 3D space to a normalized device coordinates space to address issues like feature ambiguity, pose ambiguity, and computation imbalance that exist in prior works, and uses a depth-adaptive dual decoder to simultaneously upsample 2D and 3D features to achieve better representations and performance on indoor and outdoor datasets.
