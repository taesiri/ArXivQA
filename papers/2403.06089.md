# [Knowledge Distillation of Convolutional Neural Networks through Feature   Map Transformation using Decision Trees](https://arxiv.org/abs/2403.06089)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

The paper addresses the lack of interpretability in deep neural networks (DNNs) such as convolutional neural networks (CNNs). Though CNNs achieve high accuracy in computer vision tasks, their reasoning process is not transparent due to their black-box nature. This restricts their deployment in real-world applications requiring explainable decision-making like healthcare. 

The main contribution of the paper is a method to interpret the features learned by a CNN using decision trees. Specifically, they extract a 4-dimensional feature vector from the final convolutional layer of a CNN trained on medical image datasets. This is done by adding a fully connected layer that transforms the 2D feature maps into a vector. 

They then train a decision tree using this 4D vector to classify the medical images. They experiment with three medical MNIST datasets - dermaMNIST, octMNIST and pneumoniaMNIST. The key findings are:

- The decision tree accuracy is comparable though a bit lower than the CNN accuracy, showing that the 4D vector preserves the distinguishing information learned by the CNN. 

- Analysis of the feature vectors, such as plotting their probability distributions and correlations, gives insights into how the CNN discriminates between classes.

- The decision tree provides an interpretable model of the CNN's reasoning as each path in the tree from root to leaf corresponds to a rule for classification.

Overall, the paper makes CNNs more transparent by distilling the knowledge in their feature maps into interpretable decision trees, while retaining accuracy. This allows domain experts to trust and safely deploy CNNs. Future work includes extracting features from earlier layers and exploring model performance with more complex trees.
