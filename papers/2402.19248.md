# [Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question   Answering Benchmark](https://arxiv.org/abs/2402.19248)

## What is the main contribution of this paper?

 This paper introduces CDQA, a Chinese Dynamic QA benchmark for evaluating the capabilities of Large Language Models (LLMs) in answering questions with evolving answers. The main contributions are:

1. It introduces the idea of using dynamic questions to challenge Chinese LLMs, providing a new direction for developing LLMs' capabilities in the Chinese community. 

2. It constructs a high-quality benchmark called CDQA, composed of dynamic questions extracted from latest Chinese news. This will become an important data resource for improving Chinese LLMs.

3. It conducts extensive experiments and analysis based on CDQA, providing valuable insights into the abilities and limitations of current Chinese LLMs in answering dynamic questions. The discoveries can guide further research on enhancing LLMs.

In summary, the paper proposes the benchmark CDQA to promote the progress of Chinese LLMs in answering dynamic questions, which is the main contribution. The dataset construction method and empirical findings also constitute important contributions.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the key terms and topics associated with it include:

- Chinese Dynamic Question Answering (CDQA)
- Large Language Models (LLMs)
- Dynamic questions
- Semi-automatic data pipeline
- Entity extraction
- Question generation
- Manual annotation 
- Fast-changing, slow-changing, and never-changing questions
- Retrieval-augmented question answering
- Evaluation of Chinese LLMs
- Analysis of different prompts, few-shot learning, search engines, etc.

In summary, the paper introduces CDQA, a new Chinese question answering benchmark focused on dynamic questions, in order to better evaluate capabilities of Chinese LLMs. It constructs this benchmark through a semi-automatic pipeline, classifies questions based on how frequently answers change, and performs comprehensive experiments analyzing performance of various LLMs using different prompts, few-shot settings, and search engines. The key goal is to promote progress in Chinese LLMs' ability to answer latest questions.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key aspects of the paper:

Problem:
- There is a lack of Chinese question answering benchmarks that contain dynamic questions with evolving answers. This limits the ability to evaluate Chinese language models (LLMs) on handling latest factual knowledge.

Proposed Solution:
- The paper introduces CDQA, the first Chinese Dynamic QA benchmark with 1,339 question-answer pairs related to latest news on Chinese internet. 

- The data is generated semi-automatically, combining models and humans. Models extract entities from news articles, generate candidate questions, while humans filter, rewrite and classify questions.

- Questions are categorized as fast-changing, slow-changing and never-changing based on answer change frequency. This allows more fine-grained LLM evaluation.

Main Contributions:
- Introduces the idea of challenging Chinese LLMs with dynamic questions, providing new research direction.

- Constructs high-quality CDQA benchmark for promoting progress of Chinese LLMs' question answering abilities.

- Conducts comprehensive experiments and analysis, offering discoveries into current Chinese LLMs' capabilities and limitations in answering dynamic questions.

The paper addresses the important problem of Chinese LLM evaluation using factual knowledge. The proposed benchmark and experiments lay good foundation for future works to enhance Chinese LLMs in handling real-world dynamic QA scenarios.
