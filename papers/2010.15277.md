# [Class-incremental learning: survey and performance evaluation on image   classification](https://arxiv.org/abs/2010.15277)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Class-incremental learning (class-IL) aims to continually learn a sequence of visual classification tasks, where each task contains new classes not seen in previous tasks. The key challenge is catastrophic forgetting - when learning new tasks, a model forgets how to classify images from previous tasks. Overcoming this requires balancing stability (retaining previous knowledge) and plasticity (learning new tasks).

The paper identifies four main causes of catastrophic forgetting in class-IL:
1) Weight drift: updating weights to minimize loss on new tasks impacts weights relevant for old tasks
2) Activation drift: changing weights alters activations and network outputs 
3) Inter-task confusion: separate training on tasks means the network can't optimally discriminate all classes 
4) Task-recency bias: bias towards more recently learned classes due to lack of examples from older classes

Proposed Solution:
The paper categorizes and experiments with 3 types of class-IL methods:

1) Regularization methods - constrain weight/activation changes to preserve previous knowledge. Includes Learning without Forgetting (LwF), Elastic Weight Consolidation (EWC), etc.

2) Rehearsal methods - store and replay examples from previous tasks. Includes iCaRL, End-to-End Incremental Learning (EEIL), Bias Correction (BiC). 

3) Bias correction methods - explicitly address task-recency bias. Includes iCaRL's nearest-mean classifier, EEIL's balanced finetuning, BiC's trainable scaling factors.

The methods are evaluated extensively on image classification datasets like CIFAR-100 and ImageNet. Combinations of rehearsal and bias correction work best overall.

Contributions:
- Organizes prior class-IL approaches into 3 categories and shows their relationships 
- Extensive experimental comparison of 13 class-IL methods under varied conditions
- Evaluates on multi-dataset scenario with large domain shifts between tasks
- Compares wide range of network architectures 
- Open-source class-IL evaluation framework to facilitate future research

Key findings:
- When using rehearsal, finetuning outperforms complex regularizers like LwF  
- Methods tackling task-recency bias (BiC, EEIL) excel for class-IL
- For large domain shifts between tasks, inter-task confusion dominates and most methods struggle


## Summarize the paper in one sentence.

 This paper presents an extensive survey and experimental evaluation of class-incremental learning methods for image classification.


## What is the main contribution of this paper?

 This paper makes several key contributions:

1) It provides an extensive survey and categorization of existing class-incremental learning methods for image classification. The authors organize approaches into three main categories - regularization, rehearsal, and bias-correction - and discuss the key ideas behind methods in each category.

2) The paper performs a very thorough experimental evaluation, comparing 13 class-incremental learning methods over a broad variety of datasets and scenarios. This includes multi-dataset experiments with large domain shifts between tasks, an investigation into small vs large domain shifts, and a comparison across various network architectures. 

3) Through the experimental evaluation, the paper draws several useful conclusions and recommendations regarding different class-incremental learning approaches. Key findings relate to: the efficacy of different regularization strategies, the impact of bias-correction methods, the utility of herding vs random exemplar sampling, the limitations of current methods on large domain shifts, etc.

4) The authors' extensible experimental framework for evaluating class-incremental learning methods is publicly released. This will facilitate future research and benchmarking in this area.

In summary, the key contribution is a comprehensive survey and extensive experimental evaluation that summarizes the state-of-the-art and provides guidance for future research directions in class-incremental learning. The public code release also makes an important contribution.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper abstract and contents, some of the main keywords and key terms associated with this paper include:

- Class-incremental learning
- Continual learning
- Incremental learning
- Catastrophic forgetting 
- Image classification
- Task-incremental learning
- Rehearsal methods
- Bias-correction methods
- Regularization approaches
- Knowledge distillation
- Exemplar sampling strategies
- Task imbalance
- Task recency bias
- Stability-plasticity dilemma

The paper provides an extensive survey and experimental evaluation of class-incremental learning methods for image classification. It categorizes and compares various approaches like regularization, rehearsal, and bias-correction methods. Key concepts examined include catastrophic forgetting, task recency bias, exemplar strategies, and balancing stability and plasticity in incremental learning. The experiments span diverse datasets and network architectures to evaluate factors like domain shift effects.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. How do the regularization methods like EWC, PathInt and MAS work to prevent forgetting of previous tasks when learning new tasks in class-incremental learning? What are the differences between the weight regularization methods and the advantages/disadvantages of each?

2. When combining regularization methods like LwF with exemplar strategies, why does adding the regularization not improve performance over just finetuning with exemplars (FT-E)? What factors explain this result?

3. How do the different exemplar sampling strategies like herding and random sampling work? Why does herding tend to outperform other strategies for longer task sequences? What are the tradeoffs?  

4. Explain how methods like iCaRL, EEIL and BiC explicitly address the task-recency bias problem in incremental learning. What techniques do they use to compensate for this bias? What are the relative merits of each approach?

5. When there are large domain shifts between tasks, most methods do not significantly outperform the FT-E baseline. Why does inter-task confusion seem to dominate in these cases? What types of new techniques might be needed?

6. Explain the differences in how incremental learning methods perform on network architectures with vs without skip connections. Why do methods like iCaRL favor architectures without skip connections?  

7. Analyze the tradeoffs between fixed vs growing memory types for storing exemplars in incremental learning. Under what conditions does one strategy work better than the other?

8. For techniques like GD that use external unlabeled data, how much gain is provided over just using stored exemplars? Is the gain worth the additional computational/memory resources?

9. Online class-incremental learning methods often underperform offline methods when tested in an offline setting. Analyze the key differences and why online techniques like ER and MIR struggle in this scenario.  

10. The paper proposes a new "interspersed domains" experiment. Explain this scenario and analyze how different class-incremental learning methods perform. Which cope best with returning to previously seen domains?
