# [Class-incremental learning: survey and performance evaluation on image   classification](https://arxiv.org/abs/2010.15277)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Class-incremental learning (class-IL) aims to continually learn a sequence of visual classification tasks, where each task contains new classes not seen in previous tasks. The key challenge is catastrophic forgetting - when learning new tasks, a model forgets how to classify images from previous tasks. Overcoming this requires balancing stability (retaining previous knowledge) and plasticity (learning new tasks).

The paper identifies four main causes of catastrophic forgetting in class-IL:
1) Weight drift: updating weights to minimize loss on new tasks impacts weights relevant for old tasks
2) Activation drift: changing weights alters activations and network outputs 
3) Inter-task confusion: separate training on tasks means the network can't optimally discriminate all classes 
4) Task-recency bias: bias towards more recently learned classes due to lack of examples from older classes

Proposed Solution:
The paper categorizes and experiments with 3 types of class-IL methods:

1) Regularization methods - constrain weight/activation changes to preserve previous knowledge. Includes Learning without Forgetting (LwF), Elastic Weight Consolidation (EWC), etc.

2) Rehearsal methods - store and replay examples from previous tasks. Includes iCaRL, End-to-End Incremental Learning (EEIL), Bias Correction (BiC). 

3) Bias correction methods - explicitly address task-recency bias. Includes iCaRL's nearest-mean classifier, EEIL's balanced finetuning, BiC's trainable scaling factors.

The methods are evaluated extensively on image classification datasets like CIFAR-100 and ImageNet. Combinations of rehearsal and bias correction work best overall.

Contributions:
- Organizes prior class-IL approaches into 3 categories and shows their relationships 
- Extensive experimental comparison of 13 class-IL methods under varied conditions
- Evaluates on multi-dataset scenario with large domain shifts between tasks
- Compares wide range of network architectures 
- Open-source class-IL evaluation framework to facilitate future research

Key findings:
- When using rehearsal, finetuning outperforms complex regularizers like LwF  
- Methods tackling task-recency bias (BiC, EEIL) excel for class-IL
- For large domain shifts between tasks, inter-task confusion dominates and most methods struggle
