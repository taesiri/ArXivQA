# [Open-vocabulary object 6D pose estimation](https://arxiv.org/abs/2312.00690)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the paper:

This paper presents Oryon, a method for estimating the 6D pose of novel objects given a single RGBD image and a textual prompt describing the object. Oryon uses a text-visual fusion module to align image features extracted by CLIP with object descriptions encoded by a Transformer. This produces a cost volume encoding similarity between the anchor image and locations in the query image. A decoder module then regresses a segmentation mask and pose-sensitive features which are matched to estimate the 6D pose. Oryon does not require an object model or video sequence at test time like other methods. It also includes the object segmentation within the pipeline. Experiments on REAL275 and Toyota Light show Oryon outperforms state-of-the-art generalizable methods for pose estimation while also segmenting objects accurately. Oryon demonstrates how textual object descriptions can effectively replace object models for enabling generalization in robotic manipulation tasks. The method has limitations in cases of small objects or misleading descriptions, suggesting potential areas of improvement for future work.
