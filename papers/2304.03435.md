# [Towards Unified Scene Text Spotting based on Sequence Generation](https://arxiv.org/abs/2304.03435)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key points of this paper are:

- The main research goal is to develop an end-to-end scene text spotting method that can unify different text detection formats (e.g. quadrilateral, polygon, bounding box) into a single model. 

- The key hypothesis is that by using sequence generation with prompts and starting point guidance, a single model can handle multiple detection formats and also detect more text instances than the maximum length it was trained on.

- Specifically, the paper proposes a model called UNITS that uses:
  - Detection format tokens as prompts to allow generating different location formats.
  - Starting point prompting to detect texts beyond the max length limitation.
  - A multi-way transformer decoder to handle multiple formats.

- Experiments show UNITS achieves competitive or state-of-the-art results on standard benchmarks while providing the additional capabilities of unified formats and increased detection capacity.

In summary, the central research question is how to create a unified scene text spotting model that can handle diverse detection formats and detect more texts than its max length, which UNITS aims to address through sequence generation techniques.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing a novel end-to-end scene text spotting method based on sequence generation that can extract arbitrary-shaped text areas by unifying various detection formats like quadrilateral and polygon. 

2. Introducing starting-point prompting which enables the model to extract more texts beyond the decoder length limitation by taking text extraction starting points arbitrarily.

3. Achieving competitive performance on standard scene text spotting benchmarks compared to state-of-the-art methods while providing additional capabilities like flexible detection formats and ability to spot more texts.

In summary, the key contribution is developing a unified sequence generation-based scene text spotter that can handle multiple detection formats in an end-to-end manner and extract more text instances than trained on by using starting point prompting. The proposed method demonstrates strong performance on benchmarks while offering useful additional capabilities.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a unified scene text spotting model called UNITS that can handle multiple text detection formats using prompts, extract more texts than the decoder length limit through starting point prompting, and achieves state-of-the-art performance on standard benchmarks.
