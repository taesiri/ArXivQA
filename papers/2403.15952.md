# [IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language   Models](https://arxiv.org/abs/2403.15952)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Vision language models (VLMs) have shown impressive capabilities in visual comprehension and common-sense reasoning. However, how they respond to inherently unreasonable or ambiguous images like optical illusions is not well studied. There is a lack of rigorous benchmarks to evaluate VLM performance on optical illusions spanning different categories and phenomenology. 

Proposed Solution: 
The authors introduce IllusionVQA - a challenging dataset of optical illusions to test VLMs. It contains 435 multiple choice questions to evaluate illusion comprehension (IllusionVQA-Comprehension). It also has 1000 images with questions probing soft localization of geometrically impossible objects (IllusionVQA-Soft-Localization). The images are manually categorized into 12 types of optical illusions based on appearance. The authors carefully frame unambiguous questions with multiple highly challenging but incorrect options to avoid language priors.

Experiments and Results:
The authors comprehensively evaluate state-of-the-art open source and commercial VLMs. The recently released GPT4V performs the best, achieving 62.99% on comprehension and 49.7% on localization with few-shot learning. However, human evaluators score 91.03% and 100% indicating significant room for improvement. Surprisingly, few shot learning and chain of thought reasoning fail to boost accuracy on the localization task. More concerningly, VLMs fail to locate optical illusions even when the correct answer is provided as context.

Main Contributions:
- Introduction of IllusionVQA - a diverse, challenging dataset of optical illusions for evaluating VLMs
- Rigorous benchmarking revealing that VLMs lag significantly behind human-level comprehension of optical illusions
- Discovery of unexpected inconsistencies in state-of-the-art VLMs when using standard evaluation techniques like few-shot learning and chain of thought reasoning
- Demonstrating limitations of VLMs regarding spatial reasoning required to locate geometrically impossible objects
- Analysis providing directions for developing illusion-resistant VLMs for real-world deployment 

The paper makes both data and code publicly available to enable further research towards enhancing VLM robustness using the challenging stimuli of IllusionVQA.
