# [Deeper Insights into Weight Sharing in Neural Architecture Search](https://arxiv.org/abs/2001.01431)

## What is the central research question or hypothesis that this paper addresses?

 This paper addresses the following key questions about weight sharing in neural architecture search (NAS):

1. How far is the accuracy of the architecture found by weight sharing from the true best architecture in the search space? 

2. Can the best architecture be stably found across multiple runs of the search process when using weight sharing?

3. How does weight sharing affect the accuracy and stability of the architecture found by NAS methods?

The central hypothesis is that while weight sharing speeds up NAS by allowing efficient evaluation of candidate architectures, it may come at a cost of stability and optimality. The paper investigates this through experiments on a small, fully enumerable search space where ground truth can be obtained. The goal is to gain insights into the behavior of weight sharing that can inform the design of more effective NAS algorithms.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. The paper proposes a down-scaled search space and corresponding metrics to evaluate the performance of neural architecture search methods based on weight sharing. This allows for deeper analysis and comparison to ground truth results. 

2. Through comprehensive experiments, the paper provides insights into the behavior of weight sharing approaches. Key findings include:

- The rankings of child models are highly unstable across different runs and epochs. 

- Valuable statistical information can be extracted from training the super-net, which can help improve search performance.

- Interference between child models is a key factor inducing variance. Child models that share weights can facilitate or degrade each other.

3. The paper explores methods to reduce the degree of weight sharing, including grouping child models and prefix sharing of layers. Results show these approaches can reduce variance and improve correlation to ground truth rankings.

4. The insights and experiments help explain the instability of weight sharing methods. Controlling the degree of sharing in a principled way is suggested as a direction to create more powerful and efficient neural architecture search.

In summary, the key contribution is a set of insights and findings that shed light on the behavior of weight sharing for neural architecture search, obtained through carefully designed experiments on a down-scaled search space. The paper provides evidence that reduced sharing can improve search performance.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper conducts experiments on a small search space to gain deeper insights into weight sharing for neural architecture search, finding high variance between runs and proposing methods like partial weight sharing to improve stability.


## How does this paper compare to other research in the same field?

 This paper provides an in-depth analysis and insights into the instability and variance caused by weight sharing in neural architecture search. It makes several key contributions compared to prior work:

- Defines new metrics (S-Tau, GT-Tau, TnR) for evaluating weight sharing methods against ground truth in a small, controlled search space. This allows deeper analysis than previous large-scale studies.

- Through comprehensive experiments, it clearly shows that weight sharing causes high variance in rankings between runs and epochs. This echoes findings from some prior works, but uses a controlled setup for clearer analysis. 

- It identifies the source of the variance as interference between co-trained child models. Models help or hurt each other during joint training. This provides an explanation for the instability.

- It shows the variance can be exploited to quickly filter bad models, a novel insight. Previous work mainly focused on problems of the variance.

- It reduces variance and improves correlation to ground truth by controlling the degree of weight sharing, via prefix sharing and grouping. This demonstrates a way to improve on instability.

Overall, the paper provides a rigorous controlled study of weight sharing and its instability in NAS. The insights on sources of variance and ways to exploit/improve it advance understanding and point to directions for better weight sharing schemes. The defined metrics also enable deeper analysis of this issue than before.


## What future research directions do the authors suggest?

 Based on the results and analysis in the paper, here are some future research directions the authors suggest:

- Figure out how to smartly leverage shared weights in neural architecture search (NAS). The key to improving weight-sharing based NAS is controlling the degree of weight sharing, either through model-based or rule-based approaches. More work is needed to find approaches that achieve a good trade-off between performance and efficiency.

- Explore methods for "smart" grouping of child models when using group weight sharing. The paper showed that grouping child models by similarity improved stability compared to random grouping. For larger and more complex search spaces, new techniques are needed to find good groupings, such as using a correlation matrix. 

- Investigate how to leverage the statistical information extracted from weight sharing more effectively. The paper showed that useful statistics about bad-performing models can be obtained, even with the variance of weight sharing. More work could be done to utilize these statistics for things like search space pruning.

- Design more sophisticated experiments to further analyze the reasons for weight sharing variance and come up with ways to reduce it. The partial weight sharing experiments provided some insights, but there is room for more analysis on the source of the instability.

- Validate whether the insights from the small search space hold up in larger, more complex search spaces. The authors believe they will, but further experiments on larger search spaces would help confirm the generalizability.

In summary, the key directions are 1) smarter weight sharing approaches that balance performance and efficiency, 2) techniques for grouping/selecting which models should share weights, 3) better utilizing weight sharing statistics, 4) further analysis of instability causes, and 5) validation on larger search spaces. Advancing these areas could lead to more powerful and stable weight-sharing based NAS techniques.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper explores the impact of weight sharing in neural architecture search (NAS) through experiments on a small, downscaled search space. The authors find that weight sharing leads to instability, with the ranking of child models varying significantly across different runs and epochs. However, they show that useful statistical information can still be extracted, like identifying poorly performing models. The instability is attributed to interference between child models sharing weights. The degree of weight sharing is then reduced via methods like partial sharing. Experiments show reduced variance and improved correlation with ground truth ranks. The insights, though from a small search space, are believed to hold for larger spaces. The paper provides a deeper understanding of weight sharing in NAS and directions for better leveraging shared weights.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper investigates the impact of weight sharing in neural architecture search (NAS). Previous NAS methods that use weight sharing, such as ENAS and DARTS, assume that the rank of child models obtained by evaluating them on a trained super-net is valid for finding high-performing architectures. However, the validity of this assumption has been questioned. 

To study this, the authors design a small NAS search space with only 64 possible architectures, allowing them to obtain ground truth ranks by training each child model independently. Through experiments, they find that the ranks generated via weight sharing are highly unstable across different runs and epochs. However, they show the ranks can still be used to filter out poor architectures. They find child models interfere during training, causing the instability. Methods to reduce the degree of weight sharing, like sharing only lower layers or clustering similar models, are shown to improve stability and match ground truth better. The insights on properly leveraging weight sharing could help design more robust NAS techniques.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes a down-scaled neural architecture search space with only 64 possible architectures. To evaluate weight sharing, a super-net containing all 64 architectures is trained, with each mini-batch updating the weights for one randomly sampled architecture. The validation accuracy of all architectures is then evaluated on the shared weights after training. This allows comparison to the ground truth performance of each architecture obtained by training them independently. Several metrics are introduced to measure the stability and correlation of the rankings produced via weight sharing, including Kendall's Tau. Experiments are conducted with different degrees of weight sharing, such as by clustering similar architectures or sharing only lower layers. The analysis aims to provide insights into the source of instability in weight sharing methods and how to alleviate it. The small search space enables comprehensive experiments and comparisons to ground truth which are intractable in full-scale NAS.


## What problem or question is the paper addressing?

 The paper is addressing the issue of instability and variance in neural architecture search methods that utilize weight sharing. Some key questions it aims to answer are:

1) How far is the accuracy of the best architecture found via weight sharing from the true best architecture in the search space? 

2) Can the best architecture be stably found across multiple runs of the search process when using weight sharing?

3) How does weight sharing affect the accuracy and stability of the architecture found?

The paper conducts experiments on a small, down-scaled search space to enable comparison to ground truth ranks. It finds that weight sharing leads to significant variance across runs and epochs. The paper explores reasons for this variance, such as interference between child models, and evaluates methods to reduce variance via controlled weight sharing. Overall, it provides a deeper analysis into weight sharing for neural architecture search.
