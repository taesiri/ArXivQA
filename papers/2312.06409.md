# [PointVoxel: A Simple and Effective Pipeline for Multi-View Multi-Modal   3D Human Pose Estimation](https://arxiv.org/abs/2312.06409)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes PointVoxel, a pipeline for multi-view multi-modal 3D human pose estimation that fuses RGB images and LiDAR point clouds in a volumetric representation. A key contribution is a training strategy that does not require manual pose annotations. They first pretrain on SyncHuman, a synthetic data generator they developed that can simulate customizable multi-modal camera-LiDAR rigs and 3D scenes with accurate pose labels. For unsupervised domain adaptation to real target datasets, they use off-the-shelf 2D estimators to generate pseudo labels and select reliable pseudo 3D labels based on low entropy in the 3D joint probability heatmaps. They further incorporate an anatomy-based human pose prior loss. Experiments on public datasets and a new basketball dataset show state-of-the-art performance, including in the unsupervised setting. Ablations verify the benefit of multi-modal fusion and the losses for unsupervised adaptation. The interpretable volumetric architecture also allows analysis of the relationship between heatmap entropy and pose plausibility.
