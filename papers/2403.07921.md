# [Merino: Entropy-driven Design for Generative Language Models on IoT   Devices](https://arxiv.org/abs/2403.07921)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Generative large language models (LLMs) like GPT-3 have shown impressive capabilities but are very expensive to deploy on resource-constrained devices like mobile phones or IoT devices due to their massive size and high computational requirements. 
- Existing methods like knowledge distillation can compress LLMs into smaller models but they use predefined model sizes which may not be optimal for diverse mobile hardware. Neural Architecture Search is flexible but incurs heavy GPU usage for training supernets.
- There is a need for a lightweight, customizable way to design efficient LLMs tailored for mobile devices with different hardware constraints.

Proposed Solution:
- The paper presents an entropy-driven framework called MeRino to generate mobile-friendly autoregressive LLM architectures. 
- It models transformers as information systems and defines their entropy based on parameter subspaces. This entropy correlates with model performance.
- The goal is to maximize entropy of the LLM transformer decoder under hardware constraints like model size and FLOPs. This is formulated as a mathematical optimization problem.
- An evolutionary algorithm efficiently searches the space of transformer widths, depths etc. to solve this problem and find optimal architectures for given constraints.

Key Contributions:
- First entropy-based framework to automatically design efficient transformer LM architectures for mobile devices with almost no training or GPU usage.
- New definition of transformer model entropy based on subspace that correlates with perplexity.
- Formulation as a constrained optimization problem to maximize entropy and trainability under hardware budgets.
- Experiments show MeRino models match or exceed the performance of state-of-the-art LMs like OPT and Pythia on several NLP datasets with much fewer parameters and FLOPs and significantly faster inference on NVIDIA Jetson Nano.
