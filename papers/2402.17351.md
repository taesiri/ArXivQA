# [ICP-Flow: LiDAR Scene Flow Estimation with ICP](https://arxiv.org/abs/2402.17351)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "ICP-Flow: LiDAR Scene Flow Estimation with ICP":

Problem:
Scene flow characterizes the 3D motion between two LiDAR scans captured at nearby timesteps by an autonomous vehicle. It lays the foundation for numerous perception tasks like unsupervised discovery and tracking of objects. Most existing methods either require large-scale training beforehand or time-consuming optimization at inference. They also predict unconstrained flow vectors instead of modeling rigid motion of objects.

Proposed Solution: 
The paper proposes ICP-Flow, a learning-free model for scene flow estimation. It is based on Iterative Closest Point (ICP) algorithm and incorporates the rigid motion assumption where objects mostly move rigidly. Specifically:

1) Given two input LiDAR scans, it performs ground removal, clusters non-ground points, and creates cluster pairs likely to match based on spatial locality. 

2) For each cluster pair, it runs ICP to estimate the rigid transformation aligning them. To aid ICP, a histogram-based translation voting scheme is proposed for initialization. This explores rigid motion to discover the dominant translation.

3) Cluster pairs are associated over time based on ICP distances. Scene flow is recovered using estimated rigid transformations per cluster.

3) A feedforward neural network is trained on pseudo labels from the model to enable real-time inference.

Main Contributions:

- Proposes a learning-free model incorporating rigid motion for reliable scene flow without needing datasets or annotations.

- Outperforms state-of-the-art methods on Waymo and is competitive on other datasets despite simplicity.

- Generates high-quality pseudo-labels to train neural network that runs in real-time with marginal performance loss.

- Generalizes better for longer temporal gaps of 0.5 secs where most methods fail. Enables creating object tracklets over longer durations.

In summary, the paper addresses key weaknesses of existing scene flow techniques with a simple yet effective learning-free approach. By modeling rigid motion and leveraging classic ICP with custom initialization, it advances the state-of-the-art in unsupervised scene flow for point clouds.
