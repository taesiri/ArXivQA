# [AdaMergeX: Cross-Lingual Transfer with Large Language Models via   Adaptive Adapter Merging](https://arxiv.org/abs/2402.18913)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Cross-lingual transfer aims to transfer a model's ability to solve a task from a source language (typically English) to a target low-resource language. 
- Existing methods struggle to fully separate task ability from language ability. They fail to acknowledge the interdependence between these two abilities.

Proposed Solution: 
- The paper proposes a new method called AdaMergeX that utilizes adaptive adapter merging to achieve effective cross-lingual transfer.

- It assumes task ability is affiliated with the source language, while language ability refers to the capacity gap between target and source languages. 

- Introduces a reference task and makes an assumption that the divergence between adapters fine-tuned on this task in both languages represents the language ability gap.

- Obtains target task ability by fine-tuning on source language. Combines it with language ability gap from reference task to transfer task ability to target language.

- Proposes adaptive merging methods tailored for different adapter structures like LoRA and iA3.

Main Contributions:

- New perspective on decoupling language ability and task ability that acknowledges their interdependence. 

- AdaMergeX method for cross-lingual transfer via adaptive adapter merging using a reference task.

- Structure-aware adaptive merging methods for combining adapters rather than using a one-size-fits-all linear merging.

- Extensive experiments demonstrating AdaMergeX outperforms existing cross-lingual transfer methods like prompting, model merging, and adapter merging across diverse multilingual tasks and languages.

In summary, the key novelty is a new approach to cross-lingual transfer using adaptive adapter merging based on new assumptions about language and task abilities. The structure-aware merging design and consistent empirical gains across settings are other notable contributions.
