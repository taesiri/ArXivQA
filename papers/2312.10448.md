# [Resolving Crash Bugs via Large Language Models: An Empirical Study](https://arxiv.org/abs/2312.10448)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: Software crashes are critical issues that disrupt normal operations. Resolving crash bugs is challenging as they have diverse root causes, including code issues and environmental factors like dependencies. While techniques exist to address code bugs, environment bugs rely on similar solutions from forums, limiting generalizability. 

ChatGPT, a recent large language model (LLM), has shown promise across domains. This work investigates ChatGPT's effectiveness in localizing and repairing both code and environment crash bugs under varied prompt designs.

Methodology: The authors assessed ChatGPT on a benchmark of 100 real-world Java crash bugs from Stack Overflow. They explored crash resolution with basic (naive instructions) and advanced (prompt templates, multi-round interaction) prompts. Metrics included localization/repair accuracy, solution uniqueness, and interaction quality.

Key Findings:
- ChatGPT excels at code bugs but struggles with environment bugs due to inability to pinpoint root causes and provide targeted solutions.  
- Localization is the key bottleneck; ChatGPT can repair bugs once accurately localized.
- Advanced prompts like role-playing improve accuracy by enhancing context coherence across rounds.
- Stimulating self-planning enables proactive questioning to methodically investigate potential factors.

Proposed Solution: 
The authors devise \app{}, a methodology to optimize LLM interaction for crash resolution. Distinct prompt templates suit code vs environment bugs; multi-round strategies facilitate continuous context. An active inquiry strategy activates self-planning to guide novices.  

Evaluation: Experiments with GPT-3.5 show \app{} substantially boosts accuracy, resolving previously unfixed crashes. Further tests on GPT-4, Claude and CodeLlama demonstrate generalization across models.

Key Contributions:
- First study assessing ChatGPT's crash localization/repair capabilities over both code and environment bugs.
- Extensive findings on strengths, limitations and impact of prompts during interaction.
- Novel methodology improving LLM-based resolution through tailored prompts and multi-round strategies.

The summary covers the key problem, solution, findings, proposed methodology and contributions from the paper in a detailed yet concise manner for easy human understanding.
