# [Blur Interpolation Transformer for Real-World Motion from Blur](https://arxiv.org/abs/2211.11423)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research questions/hypotheses appear to be:

- How can we effectively utilize the temporal information present in motion blur to reconstruct a high frame rate sharp video sequence from a low frame rate blurry video? The authors aim to address the challenging problem of joint deblurring and interpolation or "blur temporal super-resolution".

- How can we improve upon current methods, which still leave room for improvement in visual quality and struggle to generalize to real-world blurry videos? The authors propose a new model architecture and training strategies to enhance performance. 

- How can we collect a real-world dataset to enable models to generalize to real blurry videos rather than just performing well on synthetic data? The authors present a new real-world dataset of aligned blurry and sharp video pairs.

In summary, the main research focuses seem to be:

1) Proposing a new transformer-based model architecture and training strategies (dual-end temporal supervision, temporally symmetric ensembling) to improve blur interpolation performance, especially for arbitrary time motion reconstruction.

2) Introducing the first real-world blurry/sharp video dataset to address the generalization issue from synthetic to real data that prior works face.

3) Validating the proposed model and real-world dataset through extensive experiments, showing state-of-the-art results on public benchmarks and real-world data.

So in essence, the paper aims to push the state-of-the-art in joint deblurring and interpolation by improving model architecture and leveraging a new real-world dataset. The ability to extract arbitrary time motions from blur in high quality is a key focus.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a novel transformer-based model called Blur Interpolation Transformer (BiT) for arbitrary time motion reconstruction from blur. BiT achieves state-of-the-art performance on the public benchmark Adobe240.

2. It introduces two effective strategies - dual-end temporal supervision (DTS) and temporally symmetric ensembling (TSE) to enhance the shared temporal features for time-varying motion rendering.

3. It provides the first real-world dataset (RBI) of time-aligned low-frame-rate blurred and high-frame-rate sharp video pairs. RBI helps models generalize better to real blurry scenarios.

In summary, the key contribution is proposing a high-performance model BiT along with real-world data RBI to push the state-of-the-art in blur interpolation/joint deblurring and interpolation. The dual-end supervision and ensembling strategies are also important techniques proposed in this work.
