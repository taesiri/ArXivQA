# [Probing Intersectional Biases in Vision-Language Models with   Counterfactual Examples](https://arxiv.org/abs/2310.02988)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Vision-language models (VLMs) have shown biases related to social attributes like gender and race. 
- Prior work has focused on probing biases in individual attributes, ignoring intersectional biases (e.g. race and gender combinations). 
- This is partly due to the difficulty of collecting exhaustive image-text pairs showing combinations of attributes from existing datasets.
- Real images also have high variability in depicting subjects, making it hard to isolate bias.

Proposed Solution:
- Use text-to-image diffusion models to generate counterfactual image-text pairs that differ only in social attributes.
- Construct sets of captions depicting an occupation/trait with changes only in attribute combinations. 
- Use Stable Diffusion with cross-attention control to generate corresponding image sets, isolating differences to attributes.
- Evaluate intersectional biases by retrieving images using neutral prompts and quantify bias using metrics like MaxSkew.

Main Contributions:
- Framework to produce counterfactual examples at scale using diffusion models to probe intersectional biases in VLMs.
- Constructed large-scale dataset with 232k captions grouped into 7k counterfactual sets over occupations, traits and social attributes.
- Experiments on state-of-the-art VLMs using the dataset uncover intersectional biases related to race, gender, religion etc.
- Analysis shows variation in bias over attributes - e.g. higher gender bias for certain races compared to others.
- Demonstrates importance of studying intersectional biases as opposed to individual attributes.

In summary, the paper proposes a novel approach using synthetic counterfactuals to effectively probe intersectional social biases in VLMs at scale and provides both methodology and dataset to enable further research.
