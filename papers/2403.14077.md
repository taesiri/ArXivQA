# [Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language   Models for Media Forensics](https://arxiv.org/abs/2403.14077)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- DeepFakes refer to AI-generated fake media content, which can undermine information credibility. Detecting DeepFakes like fake face images is crucial for media forensics.  
- Existing DeepFake detection relies on programmed machine learning models, requiring expertise. 

Proposed Solution:
- Investigate using multimodal large language models (LLMs), like ChatGPT, for DeepFake detection through natural language interactions. 
- Design text prompts to query LLMs to classify if a face image is real or AI-generated. Prompts ask for yes/no response, likelihood score, or details of artifacts.
- Test popular multimodal LLMs like OpenAI's GPT4v and Google's Gemini on fake and real face images.

Key Contributions:
- Demonstrate the feasibility of using LLMs for DeepFake detection purely based on semantic understanding, without relying on signal features.
- Show reasonable performance - GPT4v achieved ~75-80% AUC score in classifying 1,000 real and fake faces.
- Reveal the importance of carefully designed prompts to elicit LLM's knowledge. Context-rich prompts lead to lower rejection rates and better detection accuracy.
- Analyze pros and cons: Semantics-based detection works for various DeepFake generation methods but still falls behind state-of-the-art programmed detectors. Errors occur more on real images.
- Suggest the intuitive LLM interface offers interpretable detection complementary to existing methods. Further work can enhance LLM performance using prompting techniques.
