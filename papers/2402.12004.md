# [Direct Consistency Optimization for Compositional Text-to-Image   Personalization](https://arxiv.org/abs/2402.12004)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Direct Consistency Optimization for Compositional Text-to-Image Personalization":

Problem:
Text-to-image (T2I) diffusion models can generate high-quality images from text prompts. However, their generation still lacks in accuracy and consistency when trying to synthesize images of a specific custom subject (e.g. my pet), style (e.g. oil painting) or scene. Recent works have shown promise in personalizing T2I models with few reference images, but they suffer from reduced textual alignment, struggle to compose the custom concept with variations, and forget prior knowledge. 

Proposed Solution:
This paper proposes "Direct Consistency Optimization (DCO)" to fine-tune T2I diffusion models while retaining consistency with the pretrained model. Specifically, it casts the fine-tuning as a constrained policy optimization problem that maximizes consistency on reference images while minimizing deviation from pretrained model. This avoids overfitting and retains composition ability. DCO loss has a simple form for training diffusion models. In addition, a new "reward guidance" sampling method balances between fidelity to images vs text. Comprehensive image captions help prevent concept drift.

Main Contributions:
- DCO objective for diffusion models that regularizes fine-tuning and enhances compositionality 
- Reward guidance sampling to control tradeoff between consistency and text alignment
- Emphasize using comprehensive captions to avoid model shift
- Experiments show state-of-the-art personalization on subjects, styles and their composition 
- DCO pushes Pareto frontier of fidelity and alignment over baselines
- Merging independently tuned concepts (e.g. subject & style) works without added optimization

In summary, this paper provides a new training objective and sampling method to enhance personalized T2I synthesis while retaining composition ability, demonstrating improved fidelity-alignment tradeoff. The simple plug-and-play nature of DCO makes it widely applicable.
