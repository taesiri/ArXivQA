# [Priority Sampling of Large Language Models for Compilers](https://arxiv.org/abs/2402.18734)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) show promise for generating and optimizing code, but common sampling methods like nucleus sampling often produce repetitive or incoherent samples. 
- The temperature parameter in nucleus sampling is difficult to tune and optimal values depend on the context.
- There is a need for better sampling techniques that produce more unique, coherent samples ordered by the model's confidence.

Proposed Solution:
- The paper proposes Priority Sampling, a deterministic sampling technique that guarantees unique samples ordered by the model's confidence. 
- It builds an augmented search tree where each node contains generated tokens and probability distribution over next tokens.
- The next sample expands the unexplored node in the tree with highest probability token prefix. This focuses search in the most promising direction.
- It supports controllable generation based on regular expressions to explore structured space.

Key Contributions:
- Priority Sampling outperforms nucleus sampling in a code optimization task, producing 5x more unique samples for the same number of inferences.
- It reaches 91% of exhaustive search optimization with just 5 samples and exceeds it with 30 samples. 
- Ablation studies analyze impact of regular expression filtering, branching factor, and priority metric.
- The technique is general and can be applied to other discrete sequence generation tasks like text, music, wrappers, etc.
- It enables better understanding of a LLM's capability and range of solutions to a problem through structured search.

In summary, the paper introduces Priority Sampling that can more efficiently extract diverse, high-quality samples from large language models in a deterministic and controllable manner.
