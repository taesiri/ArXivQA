# [Weakly Supervised Video Representation Learning with Unaligned Text for   Sequential Videos](https://arxiv.org/abs/2303.12370)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to learn a good video representation in a weakly supervised manner using unaligned text data. Specifically, the paper proposes a method to learn semantic video representations using only the paragraph-level descriptions of videos and the sequence of sentence descriptions for each step, without needing fine-grained alignment between frames and sentences. 

The key hypotheses are:

1) Using a coarse-grained contrastive loss between video and paragraph representations can help learn useful global video representations. 

2) Generating pseudo-alignments between frames and sentences based on their temporal order and applying a fine-grained contrastive loss can help learn frame-level representations that capture the semantics of actions.

3) Combining these coarse-grained and fine-grained contrastive losses in a multi-granularity framework can learn good video representations from unaligned text in a weakly supervised setting.

The experiments aim to validate these hypotheses by showing that the learned representations transfer well to downstream tasks like video sequence verification and text-to-video retrieval compared to other baseline methods.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a weakly supervised video representation learning method with unaligned text for sequential videos. The key ideas are:

1. They propose a multiple granularity contrastive learning loss for weakly supervised video-text representation learning, including a coarse-grained video-paragraph contrastive loss and a fine-grained frame-sentence contrastive loss. 

2. To handle the lack of frame-level annotations, they propose to generate pseudo frame-sentence alignments by leveraging the sequential nature of text and videos. They explore maximum-index sorting and Viterbi algorithm to generate pseudo labels for fine-grained contrastive learning.

3. They show the learned representations achieve strong performance on downstream tasks like video sequence verification and text-to-video matching without using timestamp supervision.

In summary, the main contribution is developing a weakly supervised contrastive learning framework to align videos and unaligned text descriptions for learning effective video representations for sequential videos. The key novelty is the proposed pseudo alignment generation and multi-granularity contrastive losses.
