# [vid-TLDR: Training Free Token merging for Light-weight Video Transformer](https://arxiv.org/abs/2403.13347)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Video transformers have high computational complexity, limiting their practical usage. Prior work on reducing tokens relies on simply merging tokens based on similarity, which can lose important information.  
- Video transformers also suffer from temporal bias, neglecting later frames in favor of early frames.

Proposed Solution:
- The paper proposes vid-TLDR, a training-free plug-in module to reduce tokens in video transformers. 
- It introduces a saliency score to measure token informativeness, capturing important tokens across all frames. Tokens with low saliency are merged.
- Merging uses saliency-aware foreground sharpening and background dropping to prevent loss of critical information.  

Contributions:
- Consistently improves efficiency of various state-of-the-art video transformers by 30-70% FLOPs reduction on video-text retrieval, QA, action recognition without accuracy drop.
- Outperforms prior token reduction methods like ToMe while requiring lower FLOPs.
- Analyzes and addresses temporal bias issue in video transformers using proposed saliency score.
- Achieves new state-of-the-art for efficient video transformers. Enables practical usage by drastically reducing computational requirements.

In summary, the paper proposes an effective training-free token reduction approach called vid-TLDR to improve efficiency of video transformers. By merging uninformative background tokens in a saliency-aware manner, it makes video transformers much more practical without sacrificing performance.
