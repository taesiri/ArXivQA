# [Training Generative Image Super-Resolution Models by Wavelet-Domain   Losses Enables Better Control of Artifacts](https://arxiv.org/abs/2402.19215)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Single image super-resolution (SR) aims to reconstruct high-frequency (HF) image details that are missing in low-resolution (LR) images. However, existing methods tend to generate artifacts and hallucinations while trying to reconstruct HF details.  
- Distinguishing between genuine image details and artifacts is extremely challenging. Previous works have tried to address this but a satisfactory solution is yet to be found.

Proposed Solution:
- The paper proposes a novel GAN-based SR framework that uses wavelet-domain losses to better suppress artifacts and hallucinations.
- Key ideas:
   - Train discriminator only on HF wavelet subbands instead of RGB images. This simplifies the task for the discriminator.
   - Introduce a wavelet domain distortion loss to guide generator to be sensitive to scale and orientation of structures.
   - Use DISTS perceptual loss instead of VGG-based LPIPS loss for better fidelity and perceptual tradeoff.

Contributions:
- Propose wavelet-domain fidelity loss that is more sensitive to local structures compared to RGB-domain loss.
- Show training discriminator on wavelet subbands allows better control of artifacts vs genuine details.
- Demonstrate combining proposed wavelet-guided training scheme with DISTS loss significantly improves fidelity (0.5dB PSNR gain) with minimal perceptual quality loss.

- The proposed method achieves state-of-the-art quantitative scores and also visually suppress artifacts much better while reconstructing more genuine details.

- The wavelet-guided training framework is generic and can be used with any existing GAN-SR model.

In summary, the key novelty is the use of wavelet-domain losses to guide GAN training for super-resolution, which helps distinguish and recover genuine HF details better while suppressing artifacts. Both quantitative and qualitative results validate the effectiveness of this idea.


## Summarize the paper in one sentence.

 This paper proposes a novel GAN-based super-resolution framework that utilizes wavelet-domain losses to guide the generator and discriminator networks, achieving better control of high-frequency artifacts and improved perception-distortion trade-off.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Proposing a wavelet-domain fidelity loss (a weighted combination of l1 losses on different wavelet sub-bands instead of the conventional RGB-domain l1 loss) that is more sensitive to the scale and orientation of local image structures compared to pixel domain losses. 

2. Using a SWT-domain discriminator for adversarial training to better control high frequency artifacts. Training the discriminator only on HF wavelet subbands allows better optimization to distinguish genuine image details from artifacts compared to an RGB-domain discriminator.

3. Showing that combining the proposed wavelet-guided training scheme with an RGB-domain perceptual loss (DISTS instead of LPIPS) significantly improves fidelity (up to 0.5 dB PSNR gain) with minimal (less than 1%) loss in perceptual quality.

In summary, the main contribution is a novel adversarial training framework with wavelet-domain losses to guide GAN-based super-resolution models to better suppress hallucinations and artifacts while retaining genuine high-frequency details for improved perception-distortion trade-off.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this paper include:

- Super-resolution (SR) - The task of reconstructing a high-resolution image from a low-resolution image. A main focus of the paper.

- Generative adversarial networks (GANs) - The paper proposes a novel GAN-based SR framework. Using adversarial training for super-resolution.

- Wavelet transform - The core of the proposed method is using wavelet-domain losses to guide the GAN training, instead of standard RGB losses. Things like the stationary wavelet transform (SWT) and wavelet subbands are important.

- Perception-distortion (PD) tradeoff - Balancing fidelity/reconstruction accuracy (measured by PSNR) and perceptual quality (measured by metrics like NRQM). The paper aims to achieve a better PD tradeoff. 

- Artifacts and hallucinations - Unwanted distortions and fabricated details that can occur in GAN-super-resolution. A goal is suppressing these.

- Discriminator network - The proposed framework has a wavelet-domain discriminator that focuses on high-frequency detail subbands.

- Fidelity loss, adversarial loss, perceptual loss - Different loss components used during training. Defined in both RGB and wavelet domains.

In summary, the key things are super-resolution, GANs, wavelet decomposition, balancing perceptual and distortion performance, and using wavelet losses to better control artifacts.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes using wavelet domain losses instead of RGB domain losses during GAN training for super-resolution. Why are wavelet domain losses better able to distinguish between genuine image details and artifacts compared to RGB losses? 

2. The fidelity loss used in the paper is a weighted combination of l1 losses on different wavelet subbands instead of a conventional RGB domain l1 loss. What is the rationale behind using a weighted combination? How does it help control the scale and orientation of generated details?

3. The discriminator in the proposed framework is trained only on the high frequency wavelet subbands instead of RGB images. Why is training the discriminator this way better able to control artifacts and hallucinations? 

4. What is the effect of using different levels (1 vs 2) of stationary wavelet transform (SWT) decomposition on the performance of the proposed method? When is a higher level decomposition preferred over a lower level one?  

5. The paper shows that the proposed method achieves a better perception-distortion tradeoff compared to state-of-the-art methods. What is meant by perception-distortion tradeoff in the context of super-resolution? How does the proposed method achieve a better tradeoff?

6. Different wavelet families lead to different perception-distortion tradeoff points, as shown in Figure 8. What factors determine which wavelet family would perform the best? How can one select the optimal wavelet filter?

7. How does the proposed wavelet domain optimization framework extend to other GAN architectures for super-resolution? What modifications would be needed to plug in a different GAN model into this framework?

8. The ablation study shows that using DISTS instead of LPIPS as the perceptual loss leads to better performance. Why does DISTS perform better in the proposed framework compared to the more commonly used LPIPS? 

9. What are some limitations of using quantitative metrics like PSNR to evaluate the performance of super-resolution methods, especially in distinguishing artifacts? How well do the results correlate with visual quality?

10. The weights on different wavelet subband losses require extensive search to find the optimal balance between perceptual quality and fidelity. Is there a way to automate finding the right weighting, perhaps using a neural network? Why or why not?
