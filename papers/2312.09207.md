# [WikiMuTe: A web-sourced dataset of semantic descriptions for music audio](https://arxiv.org/abs/2312.09207)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper introduces WikiMuTe, a new publicly available dataset of free-form textual descriptions paired with music audio, extracted from Wikipedia articles using a text-mining pipeline. The dataset contains 9000 tracks with rich semantic descriptions covering topics like genre, style, mood, instrumentation, etc. To demonstrate the usefulness of this data, the authors train a multi-modal model to match text and audio by learning joint representations. This model is evaluated on two tasks - tag-based music retrieval using the labels as search queries, and zero-shot music auto-tagging using established benchmark datasets. The results show competitive performance, underscoring the value of web-sourced data. However, models trained on manually created datasets like MusicCaps still achieve higher scores. The authors find that applying cross-modal relevance filtering to remove irrelevant text improves results. They hypothesize that expanding the web-mining to more sources can further enhance performance despite noisiness, as larger data size seems to outweigh quality issues. Overall, this paper makes a case for using rich free-form textual descriptions for complex music analysis, enabled by web-sourced datasets.
