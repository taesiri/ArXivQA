# [Intersectional Two-sided Fairness in Recommendation](https://arxiv.org/abs/2402.02816)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Intersectional Two-sided Fairness in Recommendation":

Problem:
- The paper argues that ensuring fairness for users and fairness for items simultaneously may still lead to unfairness for certain intersectional user-item groups. 
- For example, consider a movie recommendation system with male/female users and horror/romance movie genres. Ensuring fairness for users and movies separately may still lead to poor recommendations for the intersectional groups "females who like horror movies" and "males who like romance movies".
- The paper empirically verifies on a real-world dataset that such intersectional unfairness exists and is not addressed by current fairness methods.

Proposed Solution: 
- The paper proposes a new method called Intersectional Two-sided Fairness Recommendation (ITFR) to mitigate the intersectional unfairness.
- ITFR has 3 main components:
  1) Sharpness-aware disadvantage group discovery: Uses a sharpness-aware loss to better identify intersectional groups with poor recommendation performance. 
  2) Collaborative loss balance: Learns fair loss weights for different intersectional groups by modeling inter-group collaborations.
  3) Predicted score normalization: Normalizes predicted scores to align treatments of positives from different intersectional groups.
  
Main Contributions:
- Formally defines the problem of intersectional two-sided fairness in recommendations.
- Empirically demonstrates the existence of such unfairness on real-world datasets.  
- Proposes a novel and effective method called ITFR to mitigate this intersectional unfairness.
- Extensive experiments on 3 datasets show ITFR consistently outperforms previous state-of-the-art fairness methods in terms of intersectional fairness, while maintaining high accuracy.

In summary, the paper identifies an important but previously ignored problem of intersectional unfairness in recommendations, and proposes an effective solution called ITFR to address this gap.
