# [PEARL: Prompting Large Language Models to Plan and Execute Actions Over   Long Documents](https://arxiv.org/abs/2305.14564)

## What is the central research question or hypothesis that this paper addresses?

This paper introduces PEARL, a framework for reasoning over long documents with large language models via planning and executing compositional actions. The central hypothesis is that decomposing complex reasoning tasks over long documents into a sequence of simpler executable actions can improve the performance of large language models on these tasks compared to standard prompting techniques like zero-shot prompting or chain-of-thought. Specifically, the paper proposes that prompting the LLM to generate a plan of actions for answering a question, and then executing that plan step-by-step can enable more accurate and comprehensive reasoning compared to directly prompting the LLM for an answer. The key research questions addressed are:1) Can large language models effectively generate reasonable action plans for answering questions that require complex reasoning over long documents? 2) Does executing the generated plans lead to more accurate answers compared to standard prompting baselines?3) Does each component of the PEARL framework (action mining, plan generation, plan execution) contribute positively to the overall performance?4) How does PEARL compare to other related prompting techniques like chain-of-thought when applied to complex reasoning over long documents?The central hypothesis is tested through experiments on a subset of the QuALITY dataset requiring reasoning over long narrative texts. The results show PEARL outperforms the baselines, supporting the hypothesis that decomposing via planning and execution is beneficial for this task. Ablations and comparisons to other techniques provide evidence that each component contributes positively.
