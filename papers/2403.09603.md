# [Optimistic Verifiable Training by Controlling Hardware Nondeterminism](https://arxiv.org/abs/2403.09603)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Optimistic Verifiable Training by Controlling Hardware Nondeterminism":

Problem:
The paper addresses the problem of verifiable training of machine learning models. As model training is increasingly being outsourced to third-party providers that have vast compute resources, clients lack the ability to verify that the training was done correctly without any data poisoning or backdoor attacks. Existing solutions either rely on cryptographic proofs that struggle to scale, or "optimistic" schemes with auditors that fail due to hardware nondeterminism between GPU types preventing exact replication of training.

Proposed Solution:
The paper proposes a verifiable training scheme based on an interactive "verification game" between a trainer and auditor. To address hardware nondeterminism, the trainer performs computation in higher precision (FP64) than the model (FP32), rounds intermediate outputs, and logs rounding decisions. The auditor then matches the trainer's rounding to eliminate accumulation of errors. An adaptive thresholding method minimizes logged values. Both parties store hashes of model checkpoints in a Merkle tree for efficient comparison.

Main Contributions:

- A novel verifiable training scheme allowing a client to audit an untrusted trainer using an untrusted auditor by controlling hardware nondeterminism 
- Method to match floating point rounding decisions across different GPU types during training to achieve identical results
- Experiments showing the scheme scales to models like ResNet-50 and GPT-2 across three NVIDIA GPU architectures
- Techniques to reduce storage costs including efficient encoding of logs and adaptive thresholding
- Comparisons to alternatives like proof-based systems showing improved efficiency in storage and time

The scheme significantly advances optimistic verifiable training schemes by addressing nondeterminism and scaling to large models, reducing storage costs relative to alternatives by over 100x.
