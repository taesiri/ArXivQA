# [MTVG : Multi-text Video Generation with Text-to-Video Models](https://arxiv.org/abs/2312.04086)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel approach called MTVG for multi-text video generation using pre-trained text-to-video models without any additional training. The goal is to generate consecutive video segments corresponding to distinct prompts while maintaining visual coherence across prompts. Two key techniques are introduced: last frame-aware latent initialization and structure-guided sampling. The former helps preserve spatial information and generate diverse contents by using the last frame of the previous video to invert the latent code for the next video. Structure-guided sampling further enforces motion consistency between frames during sampling by progressively updating the latent code. Additionally, a prompt generator leverages large language models to split complex stories into individual prompts each describing one event. Experiments demonstrate MTVG can effectively synthesize realistic and temporally coherent videos reflecting provided prompts through semantic transitions like changes in object motion, background, or complex scenarios. Ablation studies validate the design choices and human evaluation shows preference for videos generated by the proposed approach.
