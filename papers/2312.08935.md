# [Math-Shepherd: A Label-Free Step-by-Step Verifier for LLMs in   Mathematical Reasoning](https://arxiv.org/abs/2312.08935)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes Math-Shepherd, an innovative process-oriented math verifier that assigns reward scores to each step of an LLM's reasoning for mathematical problems. Math-Shepherd is trained using automatically constructed process-wise supervision data instead of expensive human annotations. This is achieved by using a 'completer' LLM to generate multiple possible subsequent reasoning paths from a given step, and determining the quality of that step based on what percentage of those paths lead to the correct solution. Experiments on GSM8K and MATH datasets with multiple LLMs show Math-Shepherd significantly outperforms prior work, with a DeepSeek-67B LLM achieving over 93% on GSM8K and 48% on MATH when guided by Math-Shepherd. The method exhibits strong potential to enhance LLMs' reasoning abilities. Limitations are the computational expense of generating reasoning paths and noise in automatic annotations. Key future work includes integrating Math-Shepherd into LLM training through reinforcement learning, and developing more generalized process verifiers for mathematics.
