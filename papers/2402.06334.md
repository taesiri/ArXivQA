# [ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs](https://arxiv.org/abs/2402.06334)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

The paper introduces ExaRanker-Open, an extension of the previously proposed ExaRanker method for training neural ranking models in information retrieval (IR). 

Problem:
- Training neural IR models requires large amounts of labeled data, which is costly to obtain. 
- Providing only categorical labels (relevant/not relevant) limits the information provided to the model during training.

Proposed Solution - ExaRanker:  
- Augment categorical training data with natural language explanations that explain why a passage is relevant/not relevant to a query.
- Use large language models (LLMs) in a few-shot setting to automatically generate explanations.
- Showed in prior work (ExaRanker-v1) that this reduces dependency on large training datasets.

Limitations of Prior Work:
- Relied on expensive proprietary LLM (GPT-3.5). Limited dataset size due to cost.
- Suggested benefits decrease as training set size increases.

Contributions in This Paper:
- Introduce ExaRanker-Open: Uses open-source LLMs to generate explanations. Enables larger dataset augmentation. 
- Show consistent benefits even with larger training sets, surpassing target baseline.
- Open-source code and datasets to encourage further research.
- Analyze impact of different LLM sizes on quality of explanations and resulting effectiveness.

Key Results:
- ExaRanker-Open outperforms categorical baseline. Benefits increase with LLM size.
- On 300K examples, ExaRanker-v1 outperforms target baseline by 0.6 nDCG@10 points.

In summary, the paper demonstrates an effective data augmentation method for IR that works even for large datasets while keeping costs low through open-source LLMs. The benefits have been validated extensively.
