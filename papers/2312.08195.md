# [Concept-centric Personalization with Large-scale Diffusion Priors](https://arxiv.org/abs/2312.08195)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper introduces the concept-centric personalization task, which aims to develop a concept generator that matches dedicated generators in fidelity while retaining the versatile controllability of large-scale diffusion priors. The authors identify two main challenges: balancing fidelity and controllability during extensive training, and unconditional guidance drift causing degraded generation quality. To address these issues, they propose a guidance-decoupled framework consisting of Generalized Classifier-Free Guidance (GCFG) and a Concept-centric Diffusion Model. GCFG allows combining guidances from different models and decoupling conditional guidance into concept guidance for fidelity and control guidance for controllability. The Concept-centric Model provides concept guidance without needing concept-centric prompts. Experiments demonstrate state-of-the-art concept image generation quality with preserved controllability. The authors also explore GCFG's potential by explaining negative prompts and proposing condition decoupling for prompt diversity. Overall, this work enables high-fidelity, controllable concept-centric generation, with applications in tasks like stylization and translation.
