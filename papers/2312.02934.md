# [WoVoGen: World Volume-aware Diffusion for Controllable Multi-camera   Driving Scene Generation](https://arxiv.org/abs/2312.02934)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes WoVoGen, a novel framework for generating high-quality and controllable multi-camera driving videos. The key innovation is the use of an explicit 4D world volume representation that captures comprehensive scene information like occupancy grids, HD maps, and semantics. WoVoGen operates in two stages - first it predicts future world volumes given past world volumes and vehicle controls using a latent diffusion model. Next, it converts the predicted world volumes into multi-view 2D features which are input to a panoptic diffusion model to generate temporally and inter-sensor consistent videos. A notable capability is precise control over scene generation using both natural language prompts and semantic masks derived from the world volume. Extensive experiments on the nuScenes dataset demonstrate WoVoGen's ability to produce diverse, realistic and editable driving videos. Both qualitative and quantitative evaluations show the superiority of this approach over other rendering and diffusion-based driving video generation methods. The explicit modeling of the structured world is critical to ensuring coherent multi-view synthesis and precise control.
