# [Are Large Language Models Good Prompt Optimizers?](https://arxiv.org/abs/2402.02101)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Recent work has explored using large language models (LLMs) as automatic prompt optimizers to iteratively refine prompts for target models. However, the underlying mechanism and true effectiveness of LLMs as prompt optimizers has been underexplored.  

- This paper conducts a comprehensive study to uncover the actual mechanism behind LLM-based automatic prompt optimization. The goal is to critically assess the effectiveness of LLMs as prompt optimizers.

Experiments and Analysis
- The authors first standardize implementation designs across different prompt optimization methods to isolate and evaluate the impact of the LLM prompt optimizers. Surprisingly, reflection-based optimizers do not consistently outperform resampling-based methods.

- Delving into the reflection process, the authors find LLMs generate highly similar and repetitive feedback regardless of the actual error distribution. This indicates LLMs may struggle to genuinely reflect on errors, instead making "educated guesses" based on their own prior knowledge.  

- Analyzing the prompt refinement process, the authors show LLMs can introduce useful semantic alterations in certain steps. However, LLMs fail to generate maximally suitable prompts in the altered semantic space through single-step refinement. The unpredictable behavior of target models exacerbates this issue.

Key Conclusions
- The paper advocates exploring new paradigms for LLM-based prompt optimization that can alleviate the gap between LLM optimizers and unpredictable target models. 

- As a preliminary attempt, the authors propose "Automatic Behavior Optimization" to directly optimize target models' behavior in a more controllable manner. Experiments show this is highly effective for weaker target models.

- The study questions assumptions behind LLM-based prompt optimization and highlights the need to advance beyond existing paradigms. The insights uncovered serve to guide future work.
