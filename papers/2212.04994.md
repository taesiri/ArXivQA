# [Open Vocabulary Semantic Segmentation with Patch Aligned Contrastive   Learning](https://arxiv.org/abs/2212.04994)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question addressed is: How can we enable open vocabulary semantic segmentation using only image-text data, without requiring any segmentation annotations or masks during training? 

The key hypothesis is that by training an alignment between the patch tokens of a vision encoder and the text embeddings, a model can identify image regions corresponding to text concepts. This alignment can then be leveraged to perform zero-shot transfer to semantic segmentation in an open vocabulary setting.

Specifically, the paper proposes Patch Aligned Contrastive Learning (PACL) to train such an alignment by modifying the contrastive loss in CLIP. The main hypothesis is that with PACL, a CLIP-like model trained only on image-text data can achieve strong performance on open vocabulary semantic segmentation without needing segmentation supervision.

In summary, the central research question is how to do open vocabulary semantic segmentation with only image-text supervision, and the key hypothesis is that training an alignment between vision and text patches with PACL can enable this zero-shot transfer capability.
