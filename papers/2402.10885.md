# [3D Diffuser Actor: Policy Diffusion with 3D Scene Representations](https://arxiv.org/abs/2402.10885)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "3D Diffuser Actor: Policy Diffusion with 3D Scene Representations":

Problem:
- Robot manipulation policies need to capture multimodal action distributions in order to efficiently learn from human demonstrations. 
- Recent diffusion policy models can capture multimodal behaviors but have only been explored with low-dimensional state inputs or 2D image features.  
- 3D scene representations for robot manipulation policies lead to better viewpoint generalization but have not been combined with diffusion policies.

Proposed Solution:
- The paper proposes 3D Diffuser Actor, a novel robot manipulation policy architecture that combines conditional diffusion models with 3D scene representations.

- The model takes as input RGB-D images from one or more views, lifts 2D features to 3D using depth, and encodes them into a 3D scene feature cloud. 

- It represents the current noisy estimate of the robot's future 3D trajectory as 3D scene tokens. The trajectory tokens are jointly attended with the 3D visual tokens using 3D relative position attention layers to make the model translation equivariant.

- 3D Diffuser Actor iteratively predicts the 3D position and rotation error to denoise the trajectory estimate over multiple diffusion steps.

Main Contributions:
- Sets new SOTA on RLBench benchmark, outperforming prior 3D and 2D policies by a large margin (18.1% absolute gain).

- Achieves SOTA on CALVIN benchmark for zero-shot generalization to unseen environments, exceeding prior work by 7% relatively.

- Ablations show the importance of 3D representations and 3D relative attentions for improving generalization.

- Demonstrates successful real-world learning of 12 manipulation tasks from a few demonstrations per task.

The model marries conditional diffusion models and 3D scene representations to efficiently capture multimodal robot manipulation policies from human demonstrations. The results highlight the benefits of these techniques for improving policy generalization.
