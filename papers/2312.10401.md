# [Rethinking Dimensional Rationale in Graph Contrastive Learning from   Causal Perspective](https://arxiv.org/abs/2312.10401)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Graph contrastive learning (GCL) methods focus on building data augmentations but do not explore the intrinsic interpretability in graph representations. This can result in models learning noisy and task-agnostic information that interferes with prediction. 

- Existing graph rationale exploration methods focus on structural rationale (SR) by removing or assigning weights to edges/nodes. However, this can undermine discriminability of representations. 

Proposed Solution:
- The paper proposes to capture dimensional rationale (DR) from graph embeddings, which is more intrinsic than SR. 

- An exploratory experiment shows randomly preserving certain embedding dimensions leads to better performance, proving the existence and positive effects of DRs.

- The paper rethinks DR from a causal perspective: DR is determined to be a causal confounder in GCL due to inconsistent variation during unsupervised pre-training.

- To eliminate this, the paper proposes Dimensional Rationale-aware Graph Contrastive Learning (DRGCL) with two main components:

1) Learnable dimensional rationale acquiring network, updated via bi-level meta-learning to acquire task-relevant DRs.

2) Graph dimensional redundancy reduction as a regularization term to extend representation space of acquired DRs.

Key Contributions:

- Conducts an exploratory experiment to demonstrate the existence of graph DRs and shows DR is more intrinsic than SR.

- Formalizes the mechanism of introducing DRs by building a structural causal model and identifies DR as a causal confounder.

- Proposes DRGCL method to acquire redundancy-reduced DRs and perform backdoor adjustment on the causal model to improve performance.

- Achieves new state-of-the-art performance on multiple GCL benchmarks compared to previous methods in terms of discriminability and transferability.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a novel graph contrastive learning method called DRGCL that captures intrinsic dimensional rationales in graph representations and performs causal intervention to eliminate redundant features, achieving state-of-the-art performance on graph learning benchmarks.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It presents an exploratory experiment to demonstrate the existence of the graph dimensional rationale (DR) and provides theoretical analysis to prove that compared to the conventional graph structural rationale (SR), the graph DR is more intrinsic to graph contrastive learning (GCL).

2. It formalizes the mechanism of introducing DRs by building a structural causal model (SCM) and demonstrates that the acquired DR is a causal confounder in GCL with theoretical and empirical evidence. 

3. It proposes the Dimensional Rationale-aware Graph Contrastive Learning (DRGCL) method to acquire redundancy-against DRs and perform backdoor adjustment on the SCM, thereby consistently improving GCL performance.

4. It provides solid theoretical analyses and experimental results on benchmarks which demonstrate the effectiveness of the proposed method in terms of representation discriminability and transferability.

In summary, the main contribution is proposing the DRGCL method that explores the intrinsic dimensional rationale in graphs to improve graph contrastive learning, with formalization and understanding of the mechanism using causal inference. Both theory and experiments validate its effectiveness.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Graph contrastive learning (GCL)
- Graph rationales
    - Structural rationales (SR) 
    - Dimensional rationales (DR)
- Causal perspective
- Structural causal model (SCM) 
- Dimensional rationale-aware graph contrastive learning (DRGCL)
- Learnable dimensional rationale acquiring network
- Graph dimensional rationale redundancy reduction
- Backdoor adjustment on SCM
- Discriminability and transferability of learned representations

The paper explores going beyond structural rationales in graph contrastive learning to discover more intrinsic dimensional rationales. It establishes a structural causal model to formalize the mechanism and proposes a dimensional rationale-aware graph contrastive learning approach. Key ideas include acquiring dimensional rationales, reducing redundancy, and performing backdoor adjustment on the SCM. The method is evaluated on graph representation learning tasks and shows improved discriminability and transferability.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1) How does the proposed dimensional rationale (DR) conceptually differ from the existing notion of structural rationale (SR) in graph contrastive learning? What are the relative advantages and disadvantages?

2) The paper claims DR is more "intrinsic" to graph representations compared to SR. What precisely does intrinsic mean in this context and what is the evidence to support this claim? 

3) The method acquires DR using a learnable dimensionality weight vector R. What motivates this particular parameterization? Are there other potential ways to acquire DR that could be explored?

4) Explain the intuition behind using a bi-level meta learning approach to optimize the DR weight vector R. Why is a meta learning approach suitable here compared to standard end-to-end training?

5) How does adding the proposed redundancy reduction loss help improve the quality of acquired DR? What problems with existing graph embeddings motivate the need for this? 

6) Walk through the theoretical justifications provided in Theorems 1 and 2. Do you find the arguments convincing? Can you think of extensions or limitations?

7) The method makes use of causal reasoning and a structural causal model. Do you think this causal perspective is essential to the approach or merely an analytical device? 

8) Suggest some ideas for how the DR concept could be incorporated into other graph self-supervised learning frameworks beyond contrastive learning.

9) The ablation studies analyze removing either the DR or redundancy reduction components. Propose some other ablation experiments that could provide further insight into the method.

10) The method shows strong empirical performance but still has limitations mentioned by the authors. What do you see as the most pressing issues and how might they be addressed in future work?
