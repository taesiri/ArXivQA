# [Rethinking Dimensional Rationale in Graph Contrastive Learning from   Causal Perspective](https://arxiv.org/abs/2312.10401)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Graph contrastive learning (GCL) methods focus on building data augmentations but do not explore the intrinsic interpretability in graph representations. This can result in models learning noisy and task-agnostic information that interferes with prediction. 

- Existing graph rationale exploration methods focus on structural rationale (SR) by removing or assigning weights to edges/nodes. However, this can undermine discriminability of representations. 

Proposed Solution:
- The paper proposes to capture dimensional rationale (DR) from graph embeddings, which is more intrinsic than SR. 

- An exploratory experiment shows randomly preserving certain embedding dimensions leads to better performance, proving the existence and positive effects of DRs.

- The paper rethinks DR from a causal perspective: DR is determined to be a causal confounder in GCL due to inconsistent variation during unsupervised pre-training.

- To eliminate this, the paper proposes Dimensional Rationale-aware Graph Contrastive Learning (DRGCL) with two main components:

1) Learnable dimensional rationale acquiring network, updated via bi-level meta-learning to acquire task-relevant DRs.

2) Graph dimensional redundancy reduction as a regularization term to extend representation space of acquired DRs.

Key Contributions:

- Conducts an exploratory experiment to demonstrate the existence of graph DRs and shows DR is more intrinsic than SR.

- Formalizes the mechanism of introducing DRs by building a structural causal model and identifies DR as a causal confounder.

- Proposes DRGCL method to acquire redundancy-reduced DRs and perform backdoor adjustment on the causal model to improve performance.

- Achieves new state-of-the-art performance on multiple GCL benchmarks compared to previous methods in terms of discriminability and transferability.
