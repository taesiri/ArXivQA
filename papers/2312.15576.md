# [Reducing LLM Hallucinations using Epistemic Neural Networks](https://arxiv.org/abs/2312.15576)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Reducing hallucinations (generating false or misleading information) in large language models (LLMs) is an important open research problem. 
- Existing methods have limitations - prompt-based methods require careful prompt design and are not robust, retrieval augmented methods have efficiency issues, and finetuning risks reducing capabilities.

Proposed Solution:
- Leverage recent advances in uncertainty estimation using "epistemic neural networks" (ENNs) to reduce hallucinations in frozen LLMs.
- Attach a small ENN module to frozen LLM to improve output distributions and uncertainty estimates without retraining the large base model.
- Specifically, combine the DoLA method and ENN architecture:
   - DoLA contrasts different LLM layers to emphasize factual knowledge and downplay hallucinations.
   - ENN's prior net and learnable net outputs are combined with DoLA logits.
- Train full model end-to-end on next token prediction using C4 dataset.

Main Contributions:
- First work exploring ENNs for next token prediction task.
- Clever integration of DoLA and ENN frameworks to leverage latent embeddings for uncertainty modeling.
- Show that ENNs can be trained for next token prediction, although performance degraded on TruthfulQA dataset.
- Identify limitations of existing approach - small ENN training data leads to overfitting.
- Future workProposal to incorporate ENNs during LLM pretraining to improve uncertainty modeling.
