# [How Private is DP-SGD?](https://arxiv.org/abs/2403.17673)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Differentially private stochastic gradient descent (DP-SGD) is a popular method for training machine learning models with privacy guarantees. 
- In practice, DP-SGD implementations use "shuffle batching" which randomly permutes the data before dividing into batches. 
- However, the privacy analysis of DP-SGD is typically done assuming "Poisson batching" where each example is independently subsampled into each batch.
- This mismatch between theory and practice has led to incorrect privacy guarantees being reported. The paper investigates this gap.

Proposed Solution:
- The privacy analysis is formalized using the framework of adaptive batch linear queries (ABLQ). 
- ABLQ with deterministic, Poisson, and shuffle batching are analyzed. Tightly dominating pairs are identified for deterministic and Poisson batching.
- Analytical and empirical results demonstrate regimes where shuffle batching provides much worse privacy than Poisson batching, contradicting common belief.

Main Contributions:  
- Shuffle batching always provides better privacy than deterministic batching.
- Poisson and deterministic batching have incomparable regimes of better privacy.  
- Surprisingly, shuffle batching can have significantly worse privacy than Poisson batching, demonstrated both analytically and empirically.
- The results caution against the common practice of using shuffle batching in implementations but reporting privacy guarantees corresponding to Poisson batching.

In summary, the paper formally establishes that the choice of batch sampling method significantly impacts the privacy guarantees of DP-SGD, highlighting a concerning gap between theory and practice. The results advise caution when reporting privacy parameters.
