# [How Private is DP-SGD?](https://arxiv.org/abs/2403.17673)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Differentially private stochastic gradient descent (DP-SGD) is a popular method for training machine learning models with privacy guarantees. 
- In practice, DP-SGD implementations use "shuffle batching" which randomly permutes the data before dividing into batches. 
- However, the privacy analysis of DP-SGD is typically done assuming "Poisson batching" where each example is independently subsampled into each batch.
- This mismatch between theory and practice has led to incorrect privacy guarantees being reported. The paper investigates this gap.

Proposed Solution:
- The privacy analysis is formalized using the framework of adaptive batch linear queries (ABLQ). 
- ABLQ with deterministic, Poisson, and shuffle batching are analyzed. Tightly dominating pairs are identified for deterministic and Poisson batching.
- Analytical and empirical results demonstrate regimes where shuffle batching provides much worse privacy than Poisson batching, contradicting common belief.

Main Contributions:  
- Shuffle batching always provides better privacy than deterministic batching.
- Poisson and deterministic batching have incomparable regimes of better privacy.  
- Surprisingly, shuffle batching can have significantly worse privacy than Poisson batching, demonstrated both analytically and empirically.
- The results caution against the common practice of using shuffle batching in implementations but reporting privacy guarantees corresponding to Poisson batching.

In summary, the paper formally establishes that the choice of batch sampling method significantly impacts the privacy guarantees of DP-SGD, highlighting a concerning gap between theory and practice. The results advise caution when reporting privacy parameters.


## Summarize the paper in one sentence.

 The paper demonstrates a substantial gap between the privacy guarantees of differentially private stochastic gradient descent (DP-SGD) under different batch sampling techniques, with shuffling providing significantly weaker guarantees than typically assumed.


## What is the main contribution of this paper?

 The main contribution of this paper is showing that there can be a substantial gap between the privacy guarantees of the Adaptive Batch Linear Queries (ABLQ) mechanism when using different types of batch samplers, specifically:

1) Deterministic batching (ABLQ_D)
2) Poisson subsampling (ABLQ_P) 
3) Shuffle batching (ABLQ_S)

The privacy analysis of differentially private stochastic gradient descent (DP-SGD) follows by viewing it as a post-processing of ABLQ. While DP-SGD implementations typically use shuffle batching, the privacy analysis is often done assuming Poisson subsampling to make the analysis tractable. 

The paper shows both analytically and numerically that:

- Shuffle batching provides better privacy than deterministic batching.
- Poisson subsampling can provide worse privacy than deterministic batching for large privacy budgets. 
- There can be a substantial gap between the privacy guarantees when using shuffle batching versus Poisson subsampling, demonstrating settings where the common practice of analyzing DP-SGD with Poisson subsampling can significantly underestimate the actual privacy loss.

The main takeaway is that the choice of batch sampler plays a crucial role in determining the privacy guarantees of ABLQ and DP-SGD, so caution should be exercised when reporting privacy parameters, especially when there is a mismatch between implementation and analysis.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, here are some of the key terms and concepts:

- Differentially private stochastic gradient descent (DP-SGD)
- Adaptive batch linear queries (ABLQ)
- Batch samplers: deterministic (D), Poisson (P), shuffle (S) 
- Privacy loss curve
- Hockey stick divergence
- Dominating pairs
- Amplification by shuffling
- Privacy accounting methods (RÃ©nyi DP, privacy loss distributions)

The main focus of the paper is on analyzing the privacy guarantees of DP-SGD under different batch sampling strategies, especially deterministic vs Poisson vs shuffle batching. It introduces the ABLQ framework for this analysis and uses concepts like dominating pairs and hockey stick divergence to compare the privacy loss curves. Key findings are that shuffle batching does not provide as much "amplification" compared to Poisson subsampling as commonly assumed, and there are regimes where deterministic batching gives better privacy guarantees than Poisson. So the paper advises caution when reporting DP guarantees for DP-SGD implementations using different kinds of batch sampling.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions I would ask about the method proposed in this paper:

1) The paper analyzes adaptive batch linear query (ABLQ) mechanisms under different batch samplers like deterministic, Poisson, and shuffle. Can you elaborate more on the challenges in analyzing ABLQ under shuffle batch sampling? Why don't standard privacy amplification results apply in this setting?

2) The paper suggests there may not exist a tightly dominating pair for ABLQ under shuffle batch sampling. What approaches could one take to prove or disprove the conjecture that (P_S, Q_S) is a tightly dominating pair? 

3) For ABLQ under shuffle batch sampling, can you walk through intuitively why the non-differing records can potentially leak more information about a differing record compared to Poisson subsampling?

4) The paper empirically shows substantial gaps between privacy guarantees under different batch samplers. Can you discuss what implications this may have on the utility of DP-SGD in practice if analyzed under shuffling instead of Poisson subsampling?

5) How would the overall conclusions change if instead of zero-out adjacency, add-remove or substitution adjacency was used for the analysis? Would the gaps still persist?

6) The paper focuses on lower bounds for privacy loss under shuffling. What new techniques would be needed to get numerically tight accounting for this setting?

7) Instead of Gaussian noise, if Laplace noise was used, how would the relative privacy guarantees under different batch samplers change? Would the gaps still persist?

8) The analysis relies heavily on dominating pairs. Are there other analytical techniques besides dominating pairs that could also help compare privacy guarantees for adaptive compositions?

9) The privacy analysis does not account for information leakage from the final model itself. If that was incorporated, how might it impact the conclusions regarding gaps between batch samplers?

10) The paper suggests DP-FTRL may be a better alternative if correct shuffle batch sampler analysis is used. Can you compare and contrast the utilities of DP-FTRL and DP-SGD, especially w.r.t. batch sampling techniques?
