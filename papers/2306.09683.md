# [Scaling Open-Vocabulary Object Detection](https://arxiv.org/abs/2306.09683)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we scale up open-vocabulary object detection by leveraging abundantly available web image-text data through self-training?More specifically, the authors aim to investigate:- How to optimize the key components of self-training (label space, annotation filtering, training efficiency) to effectively leverage weak supervision from web data to improve open-vocabulary detection performance. - Whether web-scale self-training (billions of examples) can lead to continued improvements in open-vocabulary detection, similar to what has been seen in image classification and language modeling.To summarize, the main hypothesis is that with an optimized self-training approach, web-scale weak supervision can overcome the limitation of human-annotated detection data and unlock further scaling and improvements for open-vocabulary object detection. The authors propose and evaluate the OWL-ST method to test this hypothesis.
