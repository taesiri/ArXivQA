# [More than Vanilla Fusion: a Simple, Decoupling-free, Attention Module   for Multimodal Fusion Based on Signal Theory](https://arxiv.org/abs/2312.07212)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality one-paragraph summary of the key points from the paper:

This paper proposes a simple yet effective attention module called SimAM^2 for improving multimodal fusion, based on fundamental signal theory and uncertainty principles. Specifically, it treats neural activations as signals and derives an energy function to model the spatial suppression effects among neurons. It then extends this concept to model the linear superposition of multimodal signals and incorporates correlations and uncertainty estimates to attentively modulate the fused representations. In addition, a decoupling-free method is introduced to achieve balanced gradient updates across modalities during training. Experiments on audio-visual classification datasets demonstrate consistent performance gains by plugging SimAM^2 into various fusion techniques, with up to 2.0% improvement on CREMA-D and VGGSound. Additional experiments also show promising versatility for other multimodal applications beyond classification. In summary, with just minimal code changes, SimAM^2 provides an effective and model-agnostic way to enhance vanilla fusion strategies. The connections to signal theory and uncertainty modeling further validate its feasibility from a theoretical stand.
