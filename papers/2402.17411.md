# [Consistency Matters: Explore LLMs Consistency From a Black-Box   Perspective](https://arxiv.org/abs/2402.17411)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is a lack of research and solutions for maintaining consistency of large language models (LLMs) during the research, development and deployment stages. Inconsistency can lead to unexpected errors or changes in model behavior after deployment, causing economic and time losses.

- It is challenging to verify LLM consistency due to the black-box sampling nature of generative models. Existing consistency verification methods involving manual checks are time-consuming and add deployment costs.

Solution:
- The authors propose an automated LLM consistency evaluation tool that analyzes response pairs to verify consistency end-to-end. 

- They construct a dataset specifically for model consistency evaluation, with 13K training pairs and test sets covering 10 LLMs.

- LightGBM is selected as the base model for the tool. Traditional NLG metrics and semantic similarity metrics are extracted as features. The model is trained to predict if two responses are from aligned LLMs.

- A new overall metric is introduced to evaluate consistency at the model-level by considering all response pairs per test case. This handles misleading individual pairs.

Main Contributions:
- Identify and formulate the important but under-explored problem of LLM consistency during research and deployment.

- Propose an automated black-box evaluation tool for verifying LLM consistency using LightGBM and overall performance metric.

- Construct a dataset tailored for model consistency task with rules to simulate real deployment inconsistencies. 

- Show superior performance over baselines like GPT-3.5 and human evaluation, demonstrating the feasibility of using a lightweight ML model over large pre-trained LLMs for this practical problem.

In summary, the authors make notable contributions in defining, evaluating and providing a solution approach for the challenging and practically relevant issue of LLM consistency across research and deployment lifecycles.
