# STaR: Bootstrapping Reasoning With Reasoning

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central hypothesis appears to be that an iterative process of self-generating rationales and explanations, combined with model fine-tuning, can allow a large language model to bootstrap its own reasoning abilities from just a few initial examples. Specifically, the authors propose a technique called "Self-Taught Reasoner" (STaR) which involves:- Using a few initial rationale examples to prompt the model to generate step-by-step rationales and explanations to solve problems. - Fine-tuning the model on the generated rationales that led to correct answers.- Adding a "rationalization" step where the model is given hints of the correct answers for problems it failed, and asked to generate rationales for those. - Iteratively repeating this process of rationale generation, rationalization, and fine-tuning.The central hypothesis is that this iterative bootstrapping process will allow the model to progressively improve its own reasoning and explanation abilities over multiple rounds, starting from just a small number of initial examples. The authors test this on arithmetic, commonsense QA, and math word problems.In summary, the key hypothesis is that models can self-improve reasoning through iterative self-generation and learning from rationales, without needing massive labeled rationale datasets.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:- Proposing a bootstrapping mechanism called STaR (Self-Taught Reasoner) that allows large language models to iteratively generate better rationales and improve performance on reasoning tasks. - Introducing a technique called "rationalization" where the model is provided with the correct answer as a hint and asked to generate a rationale justifying that answer. This helps expand the training data and improves the bootstrapping process.- Evaluating STaR on symbolic reasoning (arithmetic), natural language reasoning (CommonsenseQA), and mathematical word problems (GSM8K). Experiments show STaR significantly improves performance compared to baselines without rationales or bootstrapping.- Demonstrating that STaR allows a 6B parameter model (GPT-J) to achieve comparable performance to a much larger 175B model (GPT-3) on CommonsenseQA through iterative self-improvement.- Proposing a general technique for large language models to leverage their existing skills to iteratively improve reasoning ability from only a small number of example rationales, without requiring large annotated training sets.In summary, the main contribution is proposing and evaluating a method for large language models to bootstrap reasoning ability from just a few examples, through iteratively generating and learning from their own rationales. The key ideas are rationale generation, rationalization, and iterative self-improvement.
