# [Jigsaw Clustering for Unsupervised Visual Representation Learning](https://arxiv.org/abs/2104.00323)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is how to design an efficient unsupervised visual representation learning method that can match or exceed the performance of state-of-the-art contrastive learning methods while using only a single batch during training. Specifically, the authors propose a new "Jigsaw Clustering" pretext task that combines the strengths of solving jigsaw puzzles and contrastive learning to learn comprehensive feature representations using only a single batch of data. Their method splits each image into patches, permutes them to form new montage images, and trains the model to cluster the patches and predict their original locations. This allows the model to learn both intra-image and inter-image features. The key hypothesis is that by designing an appropriate pretext task, a single-batch unsupervised learning method can achieve comparable or better performance than dual-batch contrastive methods like SimCLR and MoCo, while being much more efficient since only one batch is needed during training. The authors test this hypothesis by evaluating their Jigsaw Clustering method on ImageNet classification, detection on COCO, and transfer learning on CIFAR, showing it matches or exceeds dual-batch methods using only half the batches.In summary, the main research question is whether an efficient single-batch unsupervised learning method can match dual-batch contrastive learning, which the authors address through their proposed Jigsaw Clustering technique.
