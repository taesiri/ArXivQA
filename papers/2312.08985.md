# [OMG: Towards Open-vocabulary Motion Generation via Mixture of   Controllers](https://arxiv.org/abs/2312.08985)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of the paper:

This paper presents Open-vocabulary Motion Generation (OMG), a novel framework for generating realistic human motions from open-vocabulary text prompts. The key idea is to carefully tailor the pretrain-then-finetune paradigm to the text-to-motion generation task. During pre-training, they leverage a large dataset of over 20 million unlabeled motion frames to train an unconditional diffusion model up to 1 billion parameters, allowing it to learn rich inherent motion features. For fine-tuning, they propose a conditional scheme called motion ControlNet which incorporates a Mixture-of-Controllers (MoC) block to align sub-motion features to CLIP text embeddings in an expert fashion. Specifically, the MoC block employs a cross-attention mechanism and text-token-specific experts to perform fine-grained control of different sub-motions based on each token. Experiments demonstrate state-of-the-art zero-shot performance: when fine-tuned only on the HumanML3D dataset, OMG generates compelling motions from diverse open-vocabulary descriptions in the Mixamo dataset. The work represents an important advancement towards open-vocabulary text-to-motion generation for applications in animation, games, VR/AR, and robotics.
