# [If in a Crowdsourced Data Annotation Pipeline, a GPT-4](https://arxiv.org/abs/2402.16795)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Recent studies claimed that large language models (LLMs) like GPT-4 can surpass crowd workers in data labeling accuracy. However, these studies had issues like using datasets available before GPT-4's cutoff date or deviating from standard crowdsourcing practices.  
- This paper investigates whether a well-executed crowdsourcing pipeline can match or exceed GPT-4's labeling abilities.

Methodology:
- 415 crowd workers labeled 3,177 scholarly text segments using the CODA-19 labeling scheme (5 classes: Background, Purpose, Method, Finding, Other).
- Collected 127,080 labels in total. Tested two worker interfaces. Each segment got 20 labels.
- Applied 8 label aggregation algorithms on crowd labels, including Majority Voting, Dawid-Skene, etc.   
- Also had GPT-4 label the data in a zero-shot setting. Treated GPT-4's labels as an additional "crowd worker" for some aggregation experiments.

Key Findings:
- Best crowdsourcing pipeline achieved 81.5% accuracy, using Advanced Interface and One-Coin Dawid-Skene aggregation.
- GPT-4's solo labeling accuracy was 83.6%, surpassing the crowdsourcing pipeline.
- However, incorporating GPT-4 labels into certain aggregation algorithms, like One-Coin Dawid-Skene, further improved accuracy to 87.5%, exceeding GPT-4's solo performance.

Main Contributions:
- First fair benchmark comparing a properly executed crowdsourcing pipeline against GPT-4 for labeling unseen data.
- Demonstrated combining crowd and GPT-4 labels can enhance accuracy beyond what GPT-4 achieves alone, highlighting the value of human annotations.
- Provides insights into best practices for crowdsourced data annotation in the era of high-capability LLMs like GPT-4.
