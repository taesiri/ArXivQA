# [Is Bang-Bang Control All You Need? Solving Continuous Control with   Bernoulli Policies](https://arxiv.org/abs/2111.02552)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper investigates is:To what extent does bang-bang control, where actions are restricted to the minimum or maximum values, emerge in reinforcement learning for continuous control problems, and how does this relate to performance?The key hypothesis seems to be that restricting policies to bang-bang control can achieve competitive performance on common benchmark tasks compared to standard Gaussian policies, despite the expectation that more refined continuous actions should be required. The paper provides theoretical grounding for why bang-bang behavior may arise, as well as extensive empirical analysis across algorithms and environments to evaluate this hypothesis.In summary, the paper aims to understand:- The prevalence and performance of bang-bang policies learned via RL on continuous control benchmarks.- The theoretical underpinnings for emergence of bang-bang control from an optimal control perspective. - How characteristics like exploration, action costs, and task objectives relate to bang-bang vs continuous policies.The overall goal is to improve understanding of learned behaviors in continuous control RL, particularly when they deviate from common assumptions, which can inform future benchmarking, algorithm design, and applications.
