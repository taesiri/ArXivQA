# [Spot the bot: Coarse-Grained Partition of Semantic Paths for Bots and   Humans](https://arxiv.org/abs/2402.17392)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Bots are increasingly used to generate text content like comments, articles, and reviews. It is important to distinguish bot-generated text from human-written text.
- Prior work has focused on detecting specific bots. This paper aims to compare the underlying structures of human vs bot-generated text more generally.

Method:
- Compare clusterings of n-gram vectors from human-written literary texts vs texts generated by LSTM and GPT bots for Russian, English, German and Vietnamese. 
- Extract n-grams (n=2) from texts and create vector representations by concatenating word embeddings.
- Apply Wishart clustering and compare distributions of various cluster metrics between human and bot texts using statistical tests.

Key Findings:
- Significant differences found in clusterings of semantic paths between human and bot texts for all languages and bots tested. 
- Clustering structures differ - bots produce more repetitive phrases while humans generate more complex lexical patterns.
- Continuous Bag-of-Words (CBOW) embeddings work best for distinguishing bot vs human cluster patterns across languages.

Contributions:
- Novel investigation focused on comparing semantic structures of human vs bot texts rather than detecting specific bots
- Discovered detectable differences in coarse-grained lexical patterns between human and machine generated texts across multiple languages
- Results motivate building text classifiers that leverage clustering of semantic paths to identify bot-generated content

Future Work: 
- Explore more advanced multilingual language models and embeddings
- Build classifiers leveraging semantic path clusters to identify bot texts
