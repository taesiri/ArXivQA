# [Feature Alignment and Uniformity for Test Time Adaptation](https://arxiv.org/abs/2303.10902)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper aims to address is: how to adapt deep neural networks at test time when the test data comes from a different distribution than the training data, using only unlabeled test data? 

Specifically, the authors propose to view test time adaptation as a "feature revision" problem, where the goal is to revise/rectify the learned feature representations on the source domains to better suit the target domain. They argue this revision should focus on two key aspects - feature alignment and feature uniformity. 

The main hypothesis seems to be that explicitly addressing these two criteria - aligning features from the same class and making feature distributions uniform across classes - will improve test time adaptation performance compared to prior methods.

To achieve this, the paper proposes two main strategies:

1) Test time self-distillation to improve feature uniformity by enforcing consistency between predictions from the current model and prototypes computed from past data. 

2) Memorized spatial local clustering to align features between samples labeled as the same class based on nearest neighbors in the feature space.

The experiments aim to validate that the proposed approach outperforms prior test time adaptation methods and baseline ERM, supporting the hypothesis that explicitly considering feature alignment and uniformity is beneficial.
