# [OPDAI at SemEval-2024 Task 6: Small LLMs can Accelerate Hallucination   Detection with Weakly Supervised Data](https://arxiv.org/abs/2402.12913)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) are prone to hallucinate content across various applications, posing a major threat to their practical usage. 
- Prior works have studied hallucination in smaller models on narrow tasks, but there is limited understanding of the prevalence and nature of hallucinations in LLMs.
- This paper aims to detect hallucination in LLMs without labeled training data.

Methodology:
- Proposes a unified system with 5 main components: Base Model Selection, Prompt Engineering, Weakly-supervised Data Generation, Soft Fine-Tuning (SFT), and Ensemble Learning.
- Selects 14B Mixtral_7Bx2_MoE as the base LLM due to its strong performance despite smaller size.
- Applies prompt engineering using few-shot learning, optimized instructions, and chain-of-thought prompting to enhance model.
- Generates weak labels on 60k unlabeled examples by ensuring consistency across models and parameters.
- Fine-tunes smaller LLMs on weak labels using Lightweight Self-supervised Learning (LoRA).
- Further improves performance via model-level and prediction-level fusion.

Key Contributions:
- Demonstrates smaller 7B-14B LLMs can match/exceed larger models in hallucination detection when trained on high-quality weak supervision dataset constructed judiciously.
- Weak supervision consistency across models and sampling parameters is crucial for quality of training data.
- Prompt engineering, especially with few-shot learning and chain-of-thought, significantly boosts model capabilities.
- Model fusion via MergeKit and weighted prediction fusion delivers additional gains over single models.
- System achieves state-of-the-art accuracy of 0.836 on model-agnostic track, demonstrating effectiveness.

In summary, the paper proposes an end-to-end pipeline leveraging prompt engineering, weighted weak supervision, and ensemble learning to enable hallucination detection in LLMs without human labeling. The techniques provide strong empirical performance, while revealing insights into training data quality, model size, and prompting methods for this problem.
