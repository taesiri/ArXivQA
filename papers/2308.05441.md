# [Benchmarking Algorithmic Bias in Face Recognition: An Experimental   Approach Using Synthetic Faces and Human Evaluation](https://arxiv.org/abs/2308.05441)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question that this paper addresses is: How can we develop an experimental method to measure biases in face recognition systems using synthetic faces and human evaluation? The key points are:- The paper proposes a new experimental approach to measure bias in face recognition algorithms by generating synthetic faces where attributes like race, gender, age etc. can be controlled independently. - This allows causally attributing any measured bias to specific attributes, overcoming limitations of using observational datasets where attributes are naturally correlated.- The synthetic faces are generated using a pretrained neural face generator by traversing its latent space.- Since there are no true identities behind the synthetic faces, the paper uses extensive human evaluation to annotate attributes of individual faces and perceived identity similarities between face pairs. - This human consensus is used as the ground truth to benchmark several face recognition models, revealing biases related to race, gender and age attributes.- The experimental synthetic approach allows cheaper, faster and privacy-preserving measurement of face recognition biases compared to curating large diverse benchmark datasets.In summary, the key hypothesis is that synthetic faces with independent attribute control along with human evaluation of identity can enable precise experimental measurement of algorithmic biases in face recognition. The paper presents evidence to validate this hypothesis.


## What is the main contribution of this paper?

The main contribution of this paper is proposing an experimental framework to measure bias in face recognition systems using synthetically generated faces and human evaluation. Specifically:- They generate synthetic face images where race, gender and other attributes like pose, age, expression etc. can be controlled independently. This allows changing one attribute at a time to study its causal effect on recognition accuracy. - They collect extensive human annotations on the synthetic faces. Annotators label attributes of individual images, and also provide identity comparisons between pairs of images. - The human annotations provide "ground truth" labels to benchmark face recognition systems. Using these, the authors evaluate several popular academic models and show that they have lower accuracy on Black and East Asian subgroups compared to Caucasian subgroups.- Their framework allows bias measurement in a controlled experimental setup by generating synthetic data. This avoids limitations of using biased real-world datasets where multiple attributes are entangled. It also reduces privacy concerns and economic costs.In summary, the key contribution is demonstrating that synthetic faces combined with human evaluation can reliably estimate and analyze bias in face recognition algorithms in a causal, controlled and economical manner. The authors provide an extensive dataset and empirical demonstration on real algorithms.
