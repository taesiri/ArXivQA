# [Reaching Consensus in Cooperative Multi-Agent Reinforcement Learning   with Goal Imagination](https://arxiv.org/abs/2403.03172)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Reaching Consensus in Cooperative Multi-Agent Reinforcement Learning with Goal Imagination":

Problem:
- In cooperative multi-agent reinforcement learning (MARL), it is important for agents to reach consensus and make coherent joint decisions to accomplish tasks efficiently. However, current MARL methods either lack explicit consensus modeling or use inefficient ways to generate goals for guiding agents.

Method: 
- The paper proposes a framework called Multi-Agent Goal Imagination (MAGI) to enable agents to reach consensus via imagining a common goal. 

- MAGI consists of two components:
  1) A conditional variational autoencoder (CVAE) based module that efficiently models the distribution of future states in a self-supervised manner, without needing multi-step policy rollouts. Goals are then sampled from this distribution.
  2) Goal-conditioned policies for each agent, trained with both environment rewards and intrinsic rewards for reaching the imagined goals.

- The CVAE uses the current and future states as input to learn a latent representation. Goals are generated by sampling the latent space and decoding to future states. A goal critic evaluates the value of decoded states.

- Each agent's policy is conditioned on the goal via a hypernetwork. Intrinsic rewards based on distance to goals further guide the agents.

Contributions:
- MAGI provides an explicit consensus mechanism via imagined goals to better coordinate agents, instead of implicit coordination in prior works.

- The CVAE-based goal generation avoids inefficient multi-step policy rollouts for planning, thus improving sample efficiency.

- Experiments in multi-agent particle environments and Google Research Football show superior performance and sample efficiency over existing MARL algorithms.

- Ablations verify that the quality of the generated goals directly impacts performance, validating the importance of efficient goal imagination.

In summary, the key idea is reaching consensus in MARL through self-supervised imagination of valuable common goals, enabled via an efficient CVAE-based generative model. Both sample efficiency and final performance are improved over prior MARL methods.
