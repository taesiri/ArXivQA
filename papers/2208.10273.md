# [Long-Short History of Gradients is All You Need: Detecting Malicious and   Unreliable Clients in Federated Learning](https://arxiv.org/abs/2208.10273)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question it addresses is:How to identify and differentiate malicious and unreliable clients, as well as targeted and untargeted attacks, in federated learning?The key hypothesis is that by using long-short history of gradients jointly with appropriate distance/similarity metrics, the server can distinguish between different types of clients and attacks during the iterative model updating process in federated learning.Specifically, the paper proposes an approach called MUD-HoG that aims to:- Detect both malicious attackers and unreliable clients with low-quality data in federated learning, unlike prior works that only consider attackers.- Distinguish between targeted and untargeted attacks among the detected malicious clients.- Treat unreliable clients differently from malicious ones by still exploiting their contributions to improve model diversity. - Consider a mixture of attack types - untargeted (additive noise, sign flipping) and targeted (label flipping, multi-label flipping) attacks.- Handle the more realistic but challenging case of non-IID (non-independent and identically distributed) data among clients.So in summary, the key research question is how to perform fine-grained detection and differentiation of different types of clients and attacks in federated learning using the history of gradients, which the proposed MUD-HoG approach aims to address.
