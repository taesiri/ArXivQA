# [Long-Short History of Gradients is All You Need: Detecting Malicious and   Unreliable Clients in Federated Learning](https://arxiv.org/abs/2208.10273)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question it addresses is:How to identify and differentiate malicious and unreliable clients, as well as targeted and untargeted attacks, in federated learning?The key hypothesis is that by using long-short history of gradients jointly with appropriate distance/similarity metrics, the server can distinguish between different types of clients and attacks during the iterative model updating process in federated learning.Specifically, the paper proposes an approach called MUD-HoG that aims to:- Detect both malicious attackers and unreliable clients with low-quality data in federated learning, unlike prior works that only consider attackers.- Distinguish between targeted and untargeted attacks among the detected malicious clients.- Treat unreliable clients differently from malicious ones by still exploiting their contributions to improve model diversity. - Consider a mixture of attack types - untargeted (additive noise, sign flipping) and targeted (label flipping, multi-label flipping) attacks.- Handle the more realistic but challenging case of non-IID (non-independent and identically distributed) data among clients.So in summary, the key research question is how to perform fine-grained detection and differentiation of different types of clients and attacks in federated learning using the history of gradients, which the proposed MUD-HoG approach aims to address.


## What is the main contribution of this paper?

This paper proposes a new defense method called MUD-HoG to detect malicious and unreliable clients in federated learning. The key contributions are:- It distinguishes between malicious clients (who perform targeted or untargeted attacks) and unreliable clients (who have low-quality data) in federated learning. Most prior works only consider malicious clients.- It introduces two new notions - short history of gradients (HoG) and long HoG - to capture clients' behaviors over multiple rounds. Using appropriate distance/similarity metrics on short and long HoG, it identifies different types of attacks and clients.- It excludes malicious contributions but still exploits unreliable clients' updates (after downscaling) to improve the global model, unlike works that simply discard unreliable clients. - It handles a mixture of multiple attack types - sign flipping, noise injection, label flipping, multi-label flipping - in non-IID settings with up to 47.5% of clients being malicious.- It comprehensively outperforms 6 state-of-the-art baselines in terms of accuracy, precision, recall and detection ratio on MNIST and Fashion-MNIST datasets.In summary, the key novelty is a robust framework that provides fine-grained differentiation of clients and attacks in federated learning using long-short history of gradients, which has not been done before. This allows better exploitation of unreliable clients while successfully defending against strong adversarial attacks.
