# [Follow-the-Perturbed-Leader with Fréchet-type Tail Distributions:   Optimality in Adversarial Bandits and Best-of-Both-Worlds](https://arxiv.org/abs/2403.05134)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Multi-armed bandits is a problem where an agent needs to sequentially select among multiple arms/options with unknown rewards, while balancing exploration and exploitation. Two key settings are stochastic, where rewards are drawn i.i.d. from fixed distributions, and adversarial, where rewards can arbitrarily change. 

- The Follow-the-Regularized-Leader (FTRL) framework is widely used to design policies for bandits. However, the Follow-the-Perturbed-Leader (FTPL) framework, which relies on randomly perturbing empirical rewards, has received less attention despite being simpler. 

- Prior work conjectured FTPL could achieve optimal regret in adversarial bandits if perturbations follow a Fréchet distribution. Recent work verified this for the specific Fréchet(2) case, but the general conjecture remained open.

Solution:
- This paper provides a sufficient condition on perturbation distributions, defined via extreme value theory, for FTPL to achieve O(√KT) regret in adversarial K-armed bandits. This condition holds for Fréchet, Pareto, Student's t and other heavy-tailed distributions.

- For stochastic bandits, FTPL with Fréchet(2)-type perturbations, including all the above distributions, is shown to achieve the optimal O(log(T)/Δi) regret. FTPL with other perturbations is analyzed but does not match the lower regret bound.

Main Contributions:
- Resolves the open conjecture on optimality of FTPL in adversarial bandits for a broad class of heavy-tailed perturbations defined through extreme value theory and regular variation. 

- Demonstrates optimality of certain FTPL variants in stochastic bandits, establishing best-of-both-worlds capability. Generalizes specific Fréchet(2) results from prior work.

- Provides regret analysis and insights connecting properties of perturbations in FTPL to regularization in FTRL, potentially enabling construction of FTPL counterparts for various FTRL methods.

In summary, the paper significantly expands our understanding of optimality and connections between the FTPL and FTRL frameworks for multi-armed bandits through a probabilistic lens.
