# [METransformer: Radiology Report Generation by Transformer with Multiple   Learnable Expert Tokens](https://arxiv.org/abs/2304.02211)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central hypothesis is that introducing multiple learnable "expert" tokens into a transformer-based radiology report generation model can improve performance by mimicking multi-specialist diagnosis. 

Specifically, the authors propose that allowing multiple expert tokens to focus on different regions of the image and interact with each other will allow the model to capture more diverse and complementary information compared to a single expert. The expert tokens are incorporated into both the encoder and decoder of the transformer model. 

The key components of their proposed METransformer model are:

- Multiple expert tokens as extra inputs to the transformer encoder, which are enhanced through linear and bilinear attention mechanisms.

- An orthogonal loss to encourage the expert tokens to be complementary and focus on different image regions. 

- The expert tokens used to guide word and image embeddings in the decoder to generate multiple candidate reports.

- A metric-based expert voting strategy to select the best final report.

The central hypothesis is that this multi-expert approach will be more effective for radiology report generation compared to existing "single expert" models by mimicking radiologist collaboration. The experimental results on two datasets generally validate this hypothesis and show improved performance over several baseline methods.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes a new radiology report generation framework called METransformer that is based on the concept of "multi-expert joint diagnosis". 

2. It introduces multiple learnable "expert tokens" into both the transformer encoder and decoder to mimic having multiple experts focus on different aspects of the image.

3. The expert tokens interact with the visual tokens using both linear (self-attention) and non-linear (bilinear) attention to capture complementary information from the image. 

4. The expert tokens are trained to be orthogonal to each other using a novel orthogonal loss, so they learn to attend to different image regions.

5. In the decoder, the expert tokens are used to guide the cross-attention between words and visual tokens to generate multiple candidate reports in parallel.  

6. A metric-based expert voting strategy is proposed to select the best final report from the candidate reports.

7. Experiments show the proposed METransformer framework achieves state-of-the-art performance on two benchmark datasets for radiology report generation.

In summary, the key innovation is the introduction of multiple expert tokens that enable the model to jointly analyze an image from different perspectives and generate better radiology reports mimicking multi-expert diagnosis. The framework is general and could incorporate advances in single-expert models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one-sentence summary of the key points from the paper:

The paper proposes METransformer, a new radiology report generation model that introduces multiple learnable "expert" tokens into a transformer framework to mimic multi-specialist diagnosis - the expert tokens attend to different image regions, interact to capture complementary information, and guide report generation in parallel, with the final output selected through an expert voting strategy.
