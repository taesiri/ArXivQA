# [METransformer: Radiology Report Generation by Transformer with Multiple   Learnable Expert Tokens](https://arxiv.org/abs/2304.02211)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central hypothesis is that introducing multiple learnable "expert" tokens into a transformer-based radiology report generation model can improve performance by mimicking multi-specialist diagnosis. 

Specifically, the authors propose that allowing multiple expert tokens to focus on different regions of the image and interact with each other will allow the model to capture more diverse and complementary information compared to a single expert. The expert tokens are incorporated into both the encoder and decoder of the transformer model. 

The key components of their proposed METransformer model are:

- Multiple expert tokens as extra inputs to the transformer encoder, which are enhanced through linear and bilinear attention mechanisms.

- An orthogonal loss to encourage the expert tokens to be complementary and focus on different image regions. 

- The expert tokens used to guide word and image embeddings in the decoder to generate multiple candidate reports.

- A metric-based expert voting strategy to select the best final report.

The central hypothesis is that this multi-expert approach will be more effective for radiology report generation compared to existing "single expert" models by mimicking radiologist collaboration. The experimental results on two datasets generally validate this hypothesis and show improved performance over several baseline methods.
