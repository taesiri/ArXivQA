# [Logic-Scaffolding: Personalized Aspect-Instructed Recommendation   Explanation Generation using LLMs](https://arxiv.org/abs/2312.14345)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Explainable recommender systems using large language models (LLMs) struggle to produce personalized, factual, robust, human-readable, and properly-worded explanations without adaptation. 
- Zero-shot LLMs generate generic explanations that fail to resonate with users, lack reasoning transparency, and occasionally conflict with norms.

Proposed Solution: 
- The paper proposes a framework called "Logic-Scaffolding" that combines aspect-based explanation and chain-of-thought prompting to generate explanations through intermediate reasoning steps.

Main Components:
- Relevant Item Selection: Select top-k most relevant items from user history using sentence transformer embeddings. 
- Aspect Extraction: Employ few-shot learning to extract essential, style-consistent aspects for each item. 
- Chain-of-Thought Reasoning: Guide LLM to generate explanations through a 3-step prompting technique using item plots, aspects, and user history.

Key Contributions:
- Identify 5 characteristics of high-quality LLM-generated explanations: personalization, factuality, robustness, human readability, proper utterance.
- Demonstrate limitations of zero-shot LLM explanations through examples.
- Propose Logic-Scaffolding framework to overcome limitations by scaffolding LLM reasoning process.
- Show improved performance over zero-shot via human evaluation on movie recommendation explanations.
- Provide interactive interface to showcase framework's ability to produce superior explanations.

In summary, the key novelty is the Logic-Scaffolding framework that combines existing techniques like aspect extraction and chain-of-thought in an innovative way to unlock superior explanation capabilities from LLMs. Both qualitative analysis and human studies demonstrate the efficacy of this solution.
