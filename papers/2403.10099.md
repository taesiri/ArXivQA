# [KP-RED: Exploiting Semantic Keypoints for Joint 3D Shape Retrieval and   Deformation](https://arxiv.org/abs/2403.10099)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Creating high-quality 3D models from noisy and partial object scans is important but challenging, due to heavy occlusion, non-negligible noise, and loss of fine-grained details.
- Existing retrieval and deformation (R&D) methods suffer from two main limitations: 
    1) They use global shape features for retrieval which loses local geometry details, performs poorly on partial inputs, and establishes a less accurate embedding space.
    2) They rely on dense point matching for deformation which is prone to noise and outliers.

Proposed Solution: 
- The paper proposes KP-RED, a unified keypoint-driven framework for joint retrieval and deformation (R&D) of 3D shapes.
- It first detects semantic keypoints in an unsupervised manner which are consistent across shape variations in each category.

Keypoint-based Retrieval:
- Aggregates local features around each keypoint to get local tokens that encapsulate both global structure and local details.  
- Concatenates the ordered local tokens into a global retrieval token for establishing robust embedding space.

Keypoint-driven Deformation:
- Predicts influence vectors for each keypoint that controls deformations of nearby cage vertices.
- Uses self-attention on local regions to inject global information while preserving local details.
- Handles partial inputs using confidence scores based on point density in each region.

Main Contributions:
- A unified framework for joint robust retrieval and detailed deformation using semantic keypoints.
- Local-global feature aggregation for deformation-aware retrieval space.
- Keypoint-guided neural cage deformation with self-attention.
- Confidence estimation for handling partial object scans.

- Surpasses state-of-the-art in joint R&D on both synthetic (PartNet) and real-world (Scan2CAD) datasets for both full and partial shapes.
