# [Predictions from language models for multiple-choice tasks are not   robust under variation of scoring methods](https://arxiv.org/abs/2403.00998)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Recent work has compared large language models (LLMs) to human performance, but there is little research directly comparing different methods for deriving LLM predictions on multiple-choice tasks. 
- Different methods (linking functions) used in studies to assess LLM performance can lead to variability in results. This variability entails pronounced researcher degrees of freedom in reporting findings.

Methods:
- The authors systematically compare 5 methods for retrieving LLM answers on a pragmatic language interpretation task with multiple-choice answers:
  1. Free text generation 
  2. String scoring (token probabilities) 
  3. Label scoring (probability of answer labels)
  4. Rating aggregation (Likert-scale rating)
  5. Embedding similarity
- Models tested: GPT-3.5, Davinci, LLaMA, FLAN
- Accuracy and goodness-of-fit to human data are evaluated across methods and models.

Key Findings:
- Performance varies considerably across methods and models. No single method delivers best results for all models.
- Label scoring works well overall. Free generation is best for GPT-instruct.
- Rating aggregation and embedding similarity perform worse.
- Variability in performance assessment leads to researcher degrees of freedom in reporting.

Main Contributions:
- First systematic comparison of different LLM answer scoring methods on a single dataset.
- Demonstrates variability across methods and models in accuracy and fit to human data.
- Highlights importance of awareness of variability to ensure robust and reproducible research practices.

Limitations and Future Work:
- Single narrow dataset limits generalizability
- Future work should extend comparisons to other datasets, languages, architectures, decoding schemes.
- Assess full distributional predictions beyond single target choice.
