# [FedReview: A Review Mechanism for Rejecting Poisoned Updates in   Federated Learning](https://arxiv.org/abs/2402.16934)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "FedReview: A Review Mechanism for Rejecting Poisoned Updates in Federated Learning":

Problem: 
Federated learning allows training machine learning models without direct access to user data. However, it introduces a new attack vector called model poisoning where adversaries upload poisoned model updates to degrade the accuracy of the global model. Existing defenses like robust aggregation methods are still vulnerable to advanced model poisoning attacks. 

Solution:
The paper proposes a review mechanism called FedReview to identify and reject poisoned updates in federated learning. The key ideas are:

1) In each round, the server randomly selects some clients as reviewers to evaluate the model updates from other clients. Reviewers compute the loss of updates on their local data to create review reports. 

2) Each review report contains: (a) An estimated number of poisoned updates based on detecting loss outliers. (b) A ranking of updates by their loss.

3) The server aggregates the estimated numbers of poisoned updates across reviewers and removes the top-ranked (potentially poisoned) updates through a majority vote over the review rankings.

Main Contributions:

- Analyze limitations of existing attacks and show their ineffectiveness in practical federated learning settings

- Propose FedReview - a novel review mechanism to detect and eliminate poisoned updates without requiring any private validation data

- Achieve significantly higher accuracy compared to robust aggregation methods under poisoning attacks

- Outperform FedAvg in some cases even without attacks by removing low-quality updates 

- Provide comprehensive evaluation on multiple datasets demonstrating effectiveness and robustness of FedReview

In summary, the paper presents FedReview, a promising review-based defense against model poisoning attacks in federated learning. It leverages peer review among clients to reliably detect and discard poisoned model updates from adversaries.
