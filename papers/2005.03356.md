# [DramaQA: Character-Centered Video Story Understanding with Hierarchical   QA](https://arxiv.org/abs/2005.03356)

## What is the central research question or hypothesis that this paper addresses?

The central hypothesis of this paper is that constructing a video question answering dataset with hierarchical question-answer pairs and character-centered annotations can enable more comprehensive video story understanding and evaluation of AI models. Specifically, the paper proposes:1. Hierarchical QA pairs based on cognitive development stages as an evaluation metric for video story understanding. The QA pairs have 4 levels of difficulty based on memory capacity and logical complexity.2. Character-centered video annotations such as visual bounding boxes, behaviors, emotions, and coreference-resolved scripts to model local coherence and provide a consistent view of characters. 3. A multi-level context matching model that utilizes the character-centered annotations to hierarchically understand correlations between video clips, QA pairs, and characters.The key hypothesis is that the hierarchical QA metric and character-centered annotations will lead to better video QA models and metrics that align with human video story understanding. The paper introduces the DramaQA dataset implementing this approach and provides both quantitative experiments and qualitative examples to demonstrate the utility.


## What is the main contribution of this paper?

The main contribution of this paper is:1. Proposing a new video question answering (Video QA) dataset called DramaQA with the following key features:- Hierarchical QA difficulty levels as an evaluation metric based on cognitive development stages. This allows measuring the video understanding capability more comprehensively.- Character-centered video annotations such as bounding boxes, behaviors, emotions of main characters, and coreference resolved scripts. This helps to model the story coherence. 2. A Multi-level Context Matching model that hierarchically understands character-centered video representations to answer questions about the videos.3. Quantitative experiments showing the proposed model's performance on DramaQA using the hierarchical QA difficulty levels. 4. A new perspective on video story understanding research through the use of hierarchical QAs and character-centered annotations.In summary, the key contribution is the DramaQA dataset with hierarchical QAs and character-centered annotations, along with a Multi-level Context Matching model designed for this dataset. The aim is to enable more comprehensive video story understanding and provide a new direction for research.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here's a one sentence summary of the paper:The paper proposes a new video question answering dataset and model focused on hierarchical question difficulty levels and character-centered video annotations for evaluating and improving video story understanding.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other research in video story understanding:- Focus on hierarchical question-answering (QA) as an evaluation metric: Many prior video QA datasets do not systematically vary question difficulty or consider cognitive development stages in designing the questions. The hierarchical QA approach in this paper provides a more nuanced benchmark for assessing video story understanding.- Character-centered video annotations: Other video QA datasets provide some textual descriptions or scripts, but this paper uniquely provides rich visual annotations centered around main characters, including bounding boxes, behaviors, and emotions. This supports modeling the characters and story coherently. - Multi-level reasoning model: The proposed model incorporates both low-level context and high-level abstractions guided by the question to reason about the video story. This differs from prior works that generally stay at one level of reasoning.- Large-scale video QA dataset: With nearly 18K QA pairs, this is one of the largest and most comprehensive video QA datasets to date focused on story understanding. Many prior datasets are smaller or concentrate on shorter clips.- Real-world drama videos: Many prior video QA datasets use animated or scripted videos. Basing the dataset on Korean TV drama provides more naturalistic and complex stories and interactions.Overall, the hierarchical QA framework, character-centric annotations, multi-level reasoning model, and drama-based videos seem to push forward the state-of-the-art in modeling and evaluating video story understanding compared to previous benchmark datasets and methods. The innovations in dataset design and modeling approach are significant contributions.
