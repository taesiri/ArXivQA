# [Open Source Conversational LLMs do not know most Spanish words](https://arxiv.org/abs/2403.15491)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is a lack of evaluation on the linguistic capabilities and lexical knowledge of large language models (LLMs), especially for languages other than English. 
- Spanish in particular seems to be lagging behind in terms of presence in training datasets and performance of conversational LLMs.
- It is important to understand the lexical knowledge of Spanish in LLMs given the large number of native speakers and expected impact of conversational LLMs.

Methodology:
- The authors evaluate 12 open-source conversational LLMs of varying sizes and architectures on their knowledge of 100 randomly selected Spanish words from a standard dictionary. 
- The models are prompted to provide definitions and use words in sentences to assess their lexical knowledge. 
- The responses are manually checked by a language expert against dictionary definitions to determine validity.

Key Results:
- All models failed to recognize the meaning and correctly use in context over 50% of words tested. The best model got 66% word meaning and 25% word use correct.
- Performance seems to increase with model size, but Spanish-optimized models did not outperform general English models. 
- Common words were also frequently defined incorrectly, suggesting issues beyond lack of presence in the training set. 
- Automated testing using yes/no prompts or evaluations from ChatGPT also proved unreliable.

Main Contributions:
- First evaluation focused specifically on assessing Spanish lexical knowledge in open-source conversational LLMs.
- Demonstrates clear gaps in knowledge of Spanish vocabulary across current models. 
- Highlights need for efforts to improve multilingual performance and linguistic fairness in capabilities of LLMs across languages.

In summary, the paper shows severe limitations in the Spanish lexical capabilities of leading open-source chatbots, using manual testing of dictionary word knowledge as a benchmark. The results highlight the need to prioritize multilingual fairness and better linguistic evaluation in the development of conversational AI systems.
