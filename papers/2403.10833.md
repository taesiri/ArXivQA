# [Deep Reinforcement Learning-based Large-scale Robot Exploration](https://arxiv.org/abs/2403.10833)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper focuses on the problem of autonomous exploration of unknown large-scale environments by a mobile robot equipped with a Lidar sensor. The goal is to plan optimal paths to efficiently map the environment into free and occupied spaces while minimizing the total path length or exploration time. This is challenging because the exploration task requires real-time replanning with planning horizons over hundreds of meters as the robot discovers new areas, and conventional planners that solely optimize based on the current partial map can lead to suboptimal longer-term behaviors.

Proposed Solution: 
The paper proposes a deep reinforcement learning (DRL) based reactive planner to address this problem. The key ideas are:

1) Rely on an attention-based policy network to implicitly estimate the unknown areas and make non-myopic decisions based on reasoning about dependencies between map areas at multiple scales.

2) Use privileged learning where the critic network is provided the ground truth environment during training to precisely estimate long-term rewards and guide the policy network learning. 

3) Extract an informative graph from the map and use a graph rarefaction method to allow scaling the trained model from small to large environments.

Main Contributions:

1) A DRL-based planner using an attention-based policy network and privileged critic learning that can effectively explore large-scale environments.

2) Significantly outperforms state-of-the-art conventional planners in a 130mx100m benchmark scenario with 12% better path length efficiency and 60% lower compute time.

3) First DRL exploration planner validated on a real robot in a 80mx10m cluttered indoor environment, highlighting robust real-world applicability without additional training.

Overall, the paper makes key contributions in developing an efficient DRL-based exploration planner using ideas like attention and privileged learning for the first time, with demonstrated scalability and performance improvements over other state-of-the-art methods in large simulation and real-world environments.
