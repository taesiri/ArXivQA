# [Qibo: A Large Language Model for Traditional Chinese Medicine](https://arxiv.org/abs/2403.16056)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing large language models (LLMs) perform poorly in the unique domain of traditional Chinese medicine (TCM) due to lack of specialized training data and incorporation of core TCM concepts like "same treatment for different diseases" and "different treatments for same disease". 

- Other Chinese medical LLMs focus only on modern medicine and do not account for the different theoretical foundations between TCM and modern medicine in areas like diagnosis and treatment.

Solution:
- The authors propose Qibo, the first LLaMA-based large language model specialized for the TCM domain that is trained end-to-end from pre-training to supervised fine-tuning (SFT). 

- Qibo is pre-trained on a variety of TCM corpora spanning textbooks, prescriptions, comprehension quizzes etc. to build strong TCM capabilities.

- The model is then fine-tuned using TCM dialog data, NLP tasks data and general medical dialog data to enhance its conversational and multi-task abilities while preventing catastrophic forgetting.

- A specialized multi-stage data processing workflow with custom rules handles the intricacies of TCM text data.

Key Contributions:
- First large language model for TCM that covers complete pipeline from pre-training to supervised fine-tuning using the LLaMA architecture.

- Introduction of a multi-stage TCM data processing flow with custom cleaning rules tuned for ancient Chinese medical texts.

- Compilation of specialized TCM benchmark called Qibo-benchmark for evaluating capabilities of models in the TCM domain across various axes like safety, accuracy etc.

- Experiments demonstrate strong performance of Qibo across subjective and objective TCM assessments, outperforming baseline generalized & medical LLMs.

The model aims to fill the gap in developing performant TCM focused large language models while acknowledging limitations w.r.t safety and accuracy over reliance.
