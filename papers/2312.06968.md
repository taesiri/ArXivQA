# [Hallucination Augmented Contrastive Learning for Multimodal Large   Language Model](https://arxiv.org/abs/2312.06968)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel method called Hallucination Augmented Contrastive Learning (HACL) to address the issue of hallucination in Multi-modal Large Language Models (MLLMs). The authors first analyzed the representation distribution in MLLMs and identified two critical issues: a significant semantic gap between textual and visual representations, and an entanglement between representations of texts with and without hallucinations. Motivated by these findings, HACL introduces contrastive learning on the projected textual and visual token sequences from MLLMs, using hallucinative captions as hard negative samples. This framework effectively brings the visual representations closer to the non-hallucinative textual representations while pushing away the hallucinative textual representations. Experiments on benchmarks like MMhal-Bench and POPE demonstrate that HACL significantly reduces hallucination rates and improves overall performance. Further evaluations on VQA and recent MLLM-focused benchmarks also validate the effectiveness of HACL in enhancing MLLMs' visual understanding capabilities. In summary, HACL provides a simple yet powerful solution to mitigate the hallucination issue in MLLMs from the perspective of representation learning.
