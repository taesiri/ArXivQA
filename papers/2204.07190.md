# [Measuring Compositional Consistency for Video Question Answering](https://arxiv.org/abs/2204.07190)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we better evaluate compositional visual reasoning in video question answering models, beyond just looking at overall accuracy?The key hypotheses appear to be:1) Breaking down compositional questions into sub-question DAGs will allow more granular analysis of where and why models fail at compositional reasoning. 2) Models may exhibit "right for the wrong reasons" behavior, where they answer complex questions correctly despite failing at intermediate reasoning steps.3) Models may make inconsistent predictions across related sub-questions, indicating a lack of true compositional reasoning. The paper introduces a framework for decomposing compositional questions into DAGs of sub-questions in order to test these hypotheses. It proposes new metrics like compositional accuracy, internal consistency, and "right for the wrong reasons" to provide more nuanced evaluation. The experiments seem focused on validating whether these new metrics based on question DAGs reveal limitations in compositional reasoning for current VQA models.


## What is the main contribution of this paper?

The main contribution of this paper is developing a question decomposition engine that transforms a compositional question into a directed acyclic graph (DAG) of simpler sub-questions. This allows for a more nuanced evaluation of video question answering models beyond just accuracy, using novel metrics like compositional accuracy, right for wrong reasons, and internal consistency. The paper also contributes a new benchmark dataset called AGQA-Decomp, containing over 4 million sub-questions associated with compositional questions in the AGQA dataset. By evaluating models on the DAGs, the authors find that state-of-the-art VQA models still struggle with compositional reasoning and rely on spurious correlations. The decomposed DAG structure enables identifying failure modes and inconsistent reasoning in models.In summary, the key contributions are:- A question decomposition engine to produce DAGs of sub-questions from compositional questions - The AGQA-Decomp benchmark with over 4 million sub-questions - Novel evaluation metrics like compositional accuracy and internal consistency- Analysis showing current VQA models still struggle with compositional reasoning, even when accurate- The DAG structure enables better understanding of model failure modes and inconsistencies


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper develops a method to decompose compositional visual reasoning questions into graphs of simpler sub-questions and uses these graphs to analyze whether video question answering models can reason compositionally.
