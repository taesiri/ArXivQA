# ERRA: An Embodied Representation and Reasoning Architecture for   Long-horizon Language-conditioned Manipulation Tasks

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper aims to address is: How can robots acquire the abilities of reasoning, planning, and interaction to complete long-horizon manipulation tasks specified by natural language instructions? The key hypothesis is that by using a framework with tightly-coupled probabilistic inferences at two levels (coarse and fine), the robot can decompose complex long-horizon tasks into simpler concrete actions, while maintaining closed-loop feedback between planning and execution. This allows the robot to effectively reason, plan, and execute long manipulation tasks described by abstract language instructions.Specifically, the hypotheses tested in this work are:H1: The proposed ERRA architecture can perform long-horizon language-conditioned manipulation tasks and outperforms other baselines.  H2: Robot proprioception is important for completing language-conditioned manipulation tasks.  H3: LLMs with prompt-tuning allow ERRA to generalize to unseen natural language instructions.H4: ERRA is able to transfer learned skills to the real world.H5: ERRA can respond to environmental changes caused by humans or its own failures.In summary, the key research question is how to enable robots to acquire reasoning, planning and interaction abilities for long-horizon language-conditioned manipulation tasks. The proposed ERRA framework with coarse-fine inferences is hypothesized to achieve this.


## What is the main contribution of this paper?

The main contribution of this paper is proposing an embodied learning architecture called ERRA that enables robots to obtain reasoning, planning, and interaction abilities for solving long-horizon language-conditioned manipulation tasks. Specifically, the key ideas and contributions are:- ERRA is based on tightly-coupled probabilistic inferences at two levels - coarse-resolution inference for high-level reasoning/planning, and fine-resolution inference for learning concrete actions. - Coarse-resolution inference is formulated as sequence generation through a large language model, which translates natural language instructions and environment states into action language. - Fine-resolution inference is formulated as a reinforcement learning problem to output actions corresponding to the action language from coarse inference.- The coarse-to-fine inference allows decomposing long-horizon tasks into simpler concrete actions, and the execution results provide feedback for subsequent coarse inference.- Experiments show ERRA can complete various long-horizon manipulation tasks specified by natural language instructions, and has the ability to generalize to novel instructions and adapt to environmental changes and failures.In summary, the key contribution is proposing the ERRA architecture that combines reasoning, planning, and interaction abilities to enable completing complex long-horizon language-conditioned manipulation tasks. The coarse-to-fine inference loop is critical to the success of ERRA.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper proposes ERRA, a novel robot architecture with tightly-coupled coarse and fine reasoning that enables completing long-horizon language-conditioned manipulation tasks through iterative decomposition into simpler concrete actions.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper on the ERRA architecture compares to other related work on long-horizon language-conditioned manipulation tasks:- Most prior work has focused on learning short-horizon manipulation skills from language instructions, while ERRA tackles more complex, long-horizon tasks requiring multi-step reasoning and planning. The authors position their work as addressing limitations of prior methods with hierarchical RL or manually-designed representations.- ERRA introduces a novel coarse-to-fine inference approach with tight coupling between a large language model for high-level reasoning and planning, and a reinforcement learning policy for low-level motor skills. This allows decomposing complex tasks into simpler actions. - The use of soft prompt tuning for the language model avoids time-consuming prompt engineering as in some prior work. The RL policy also enables learning continuous motor skills rather than relying on pre-defined motion primitives.- They demonstrate strong results for ERRA on a range of long-horizon manipulation tasks like "put the cosmetic in the drawer", including the ability to adapt to some environmental changes and recover from failures. The ablation studies analyze the impact of robot proprioception and the coarse-to-fine design.- Compared to methods like SayCan, ERRA appears more robust by using closed-loop feedback between planning and execution over repeatedly inferring complete plans upfront. The comparisons are mostly limited to custom baselines though. More real-world comparisons to other state-of-the-art approaches could further validate the advances.- For generalization, the authors evaluate adapting ERRA's language model to novel instructions with unseen words. The results show reasonable generalization, but performance declines significantly for instructions that differ more from the training data.In summary, this paper introduces a promising new approach for complex, long-horizon language-conditioned manipulation tasks, with robustness advantages over some prior methods. More extensive comparisons and tackling the generalization challenges could help further advance this research area.
