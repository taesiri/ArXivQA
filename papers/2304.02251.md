# [ERRA: An Embodied Representation and Reasoning Architecture for   Long-horizon Language-conditioned Manipulation Tasks](https://arxiv.org/abs/2304.02251)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper aims to address is: How can robots acquire the abilities of reasoning, planning, and interaction to complete long-horizon manipulation tasks specified by natural language instructions? 

The key hypothesis is that by using a framework with tightly-coupled probabilistic inferences at two levels (coarse and fine), the robot can decompose complex long-horizon tasks into simpler concrete actions, while maintaining closed-loop feedback between planning and execution. This allows the robot to effectively reason, plan, and execute long manipulation tasks described by abstract language instructions.

Specifically, the hypotheses tested in this work are:

H1: The proposed ERRA architecture can perform long-horizon language-conditioned manipulation tasks and outperforms other baselines.  

H2: Robot proprioception is important for completing language-conditioned manipulation tasks.  

H3: LLMs with prompt-tuning allow ERRA to generalize to unseen natural language instructions.

H4: ERRA is able to transfer learned skills to the real world.

H5: ERRA can respond to environmental changes caused by humans or its own failures.

In summary, the key research question is how to enable robots to acquire reasoning, planning and interaction abilities for long-horizon language-conditioned manipulation tasks. The proposed ERRA framework with coarse-fine inferences is hypothesized to achieve this.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing an embodied learning architecture called ERRA that enables robots to obtain reasoning, planning, and interaction abilities for solving long-horizon language-conditioned manipulation tasks. 

Specifically, the key ideas and contributions are:

- ERRA is based on tightly-coupled probabilistic inferences at two levels - coarse-resolution inference for high-level reasoning/planning, and fine-resolution inference for learning concrete actions. 

- Coarse-resolution inference is formulated as sequence generation through a large language model, which translates natural language instructions and environment states into action language. 

- Fine-resolution inference is formulated as a reinforcement learning problem to output actions corresponding to the action language from coarse inference.

- The coarse-to-fine inference allows decomposing long-horizon tasks into simpler concrete actions, and the execution results provide feedback for subsequent coarse inference.

- Experiments show ERRA can complete various long-horizon manipulation tasks specified by natural language instructions, and has the ability to generalize to novel instructions and adapt to environmental changes and failures.

In summary, the key contribution is proposing the ERRA architecture that combines reasoning, planning, and interaction abilities to enable completing complex long-horizon language-conditioned manipulation tasks. The coarse-to-fine inference loop is critical to the success of ERRA.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence TL;DR summary of the paper:

The paper proposes ERRA, a novel robot architecture with tightly-coupled coarse and fine reasoning that enables completing long-horizon language-conditioned manipulation tasks through iterative decomposition into simpler concrete actions.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper on the ERRA architecture compares to other related work on long-horizon language-conditioned manipulation tasks:

- Most prior work has focused on learning short-horizon manipulation skills from language instructions, while ERRA tackles more complex, long-horizon tasks requiring multi-step reasoning and planning. The authors position their work as addressing limitations of prior methods with hierarchical RL or manually-designed representations.

- ERRA introduces a novel coarse-to-fine inference approach with tight coupling between a large language model for high-level reasoning and planning, and a reinforcement learning policy for low-level motor skills. This allows decomposing complex tasks into simpler actions. 

- The use of soft prompt tuning for the language model avoids time-consuming prompt engineering as in some prior work. The RL policy also enables learning continuous motor skills rather than relying on pre-defined motion primitives.

- They demonstrate strong results for ERRA on a range of long-horizon manipulation tasks like "put the cosmetic in the drawer", including the ability to adapt to some environmental changes and recover from failures. The ablation studies analyze the impact of robot proprioception and the coarse-to-fine design.

- Compared to methods like SayCan, ERRA appears more robust by using closed-loop feedback between planning and execution over repeatedly inferring complete plans upfront. The comparisons are mostly limited to custom baselines though. More real-world comparisons to other state-of-the-art approaches could further validate the advances.

- For generalization, the authors evaluate adapting ERRA's language model to novel instructions with unseen words. The results show reasonable generalization, but performance declines significantly for instructions that differ more from the training data.

In summary, this paper introduces a promising new approach for complex, long-horizon language-conditioned manipulation tasks, with robustness advantages over some prior methods. More extensive comparisons and tackling the generalization challenges could help further advance this research area.


## What future research directions do the authors suggest?

 Based on my reading of the paper, the main future research directions suggested by the authors are:

- Extending the work to mobile robots that require localization and mapping. The current system uses a fixed robot position, so supporting mobile robots would be an interesting extension.

- Using a dual-arm system to provide more flexibility and redundancy when planning and executing long-horizon manipulation tasks. The authors note that planning may be more complex with two arms, but the increased capabilities could enable more optimal task plans.

- Learning from online videos of humans performing long-horizon tasks, rather than purely simulated data. This could reduce the effort needed to manually build simulation environments and datasets.

- Developing methods to transfer skills and knowledge from simulation to the real world in a more efficient way. The current system relies heavily on simulation for learning both the coarse and fine inference models. More efficient sim-to-real transfer could improve the applicability.

- Exploring different network architectures and training techniques to improve the generalization capability, especially for complex language instructions. The results showed degraded performance on novel language, so improving generalization is noted as an area for future work.

- Incorporating semantic spatial knowledge to improve reasoning about object relationships and interactions. This could improve planning performance for complex long-horizon tasks.

- Adding memory modules to recall prior experiences and adapt plans online based on past successes and failures. The current system does not explicitly leverage memory.

In summary, the main suggested future directions are: supporting mobile robots, dual-arm systems, learning from human videos, more efficient sim-to-real transfer, improving generalization, incorporating spatial knowledge, and adding memory modules. Advancing these areas could further improve the performance and applicability of the proposed approach.


## Summarize the paper in one paragraph.

 The paper proposes an embodied learning architecture called ERRA that enables robots to jointly obtain reasoning, planning, and interaction capabilities for solving long-horizon language-conditioned manipulation tasks. The key idea is to use tightly-coupled probabilistic inferences at two levels - coarse (high-level reasoning and planning) and fine (low-level motor skills). The coarse-resolution inference is formulated as a sequence generation task using a large language model to produce action language from natural language instructions and environment state. The fine-resolution inference is a reinforcement learning agent that takes the action language and senses the environment to output concrete robotic actions. By iterating between these two levels, long-horizon tasks can be decomposed into simpler actions. Experiments in simulation and the real world show ERRA's effectiveness on various manipulation tasks, ability to generalize to novel language instructions, and robustness to failures and environmental changes. The embodied interactive learning approach allows the acquisition of semantic, reasoning, planning and manipulation skills for robots to follow human instructions.


## Summarize the paper in two paragraphs.

 Here is a 2-paragraph summary of the paper:

This paper proposes ERRA, a novel embodied learning architecture that enables robots to jointly obtain reasoning, planning, and interaction capabilities for solving long-horizon language-conditioned manipulation tasks. ERRA is based on tightly-coupled probabilistic inferences at two granularity levels - coarse and fine. The coarse-resolution inference focuses on high-level reasoning and planning and is formulated as a sequence generation task using a large language model. It takes as input the natural language instruction, environment state, and robot proprioception and outputs action language representing the next step. The fine-resolution inference focuses on generating concrete actions to execute the action language. It is modeled as a reinforcement learning agent that takes action language and environment observations as input and outputs gripper actions. By iteratively invoking coarse-to-fine inferences, long-horizon tasks can be decomposed into simpler actions.

Experiments were conducted on a range of manipulation tasks in simulation and the real world. Results showed that ERRA outperformed baselines in completing long-horizon tasks specified by abstract instructions. Ablation studies highlighted the importance of robot proprioception for reasoning and planning. ERRA also demonstrated an ability to generalize to novel language instructions and adapt to dynamic environments and failure cases. Limitations include a fixed robot position and reliance on simulation for training data. Overall, the proposed ERRA framework enables robots to obtain key abilities in reasoning, planning and interaction for solving complex long-horizon manipulation tasks guided by natural language.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes an embodied learning architecture called ERRA that enables robots to obtain reasoning, planning, and interaction capabilities for solving long-horizon language-conditioned manipulation tasks. ERRA is based on tightly-coupled probabilistic inferences at two granularity levels - coarse and fine. The coarse-resolution inference module focuses on high-level reasoning and planning, and is formulated as a sequence generation task using a large language model to infer action language from the instruction and environment state. The fine-resolution inference module focuses on learning concrete actions through reinforcement learning, taking the action language and environment observations as input. By repeatedly invoking coarse-to-fine inference, complex tasks can be decomposed into simpler concrete actions for the robot to execute interactively. The coarse-resolution inference provides feedback to adjust subsequent planning based on execution outcomes. This allows ERRA to complete long-horizon manipulation tasks specified by abstract language instructions through iterative reasoning, planning and execution.


## What problem or question is the paper addressing?

 The paper proposes a new approach called ERRA for enabling robots to understand natural language instructions, reason abstractly, plan multi-step tasks, and interact with environments to accomplish long-horizon manipulation tasks specified by language. 

The key problem the paper aims to address is how to combine and acquire three key capabilities in an embodied agent:

1) Reasoning: Understanding high-level natural language instructions and planning tasks abstractly based on environment conditions.

2) Interaction: Developing low-level motor skills to interact with the environment through trial-and-error. 

3) Execution: Sequencing and executing the planned low-level motor skills to accomplish long-horizon manipulation tasks.

The main challenges are that long-horizon tasks often require many reasoning steps involving complex semantics and environment dynamics. Prior methods relying on engineered symbolic representations or end-to-end policy learning have limitations in generalizing or scaling to long horizons.

To tackle these challenges, the paper proposes a new architecture ERRA based on tightly-coupled probabilistic inferences at two levels - coarse (high-level reasoning) and fine (low-level motor control). The key intuitions are:

1) decomposing long-horizon tasks into smaller sub-tasks can simplify reasoning and learning. 

2) closed-loop execution where later steps depend on outcomes of earlier steps allows handling environment dynamics.

So the core problem addressed is acquiring reasoning, planning, and execution capabilities for robots to follow natural language instructions for long-horizon manipulation tasks.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper abstract and introduction, here are some of the key terms and concepts:

- Long-horizon language-conditioned manipulation tasks - The paper focuses on enabling robots to complete complex manipulation tasks specified by natural language instructions. These tasks may require multiple steps and reasoning to complete.

- Coarse-to-fine inference - The proposed ERRA architecture uses tightly-coupled probabilistic inference at two levels of granularity: coarse (high-level reasoning and planning) and fine (concrete action execution). 

- Large language model (LLM) - The coarse-resolution inference module is based on a pre-trained LLM which can generate action language from the instruction and environment state.

- Prompt tuning - The LLM is adapted to the robotics tasks using prompt tuning rather than full fine-tuning. This allows leveraging the LLM's knowledge while only updating a small set of parameters.

- Reinforcement learning - The fine-resolution inference module linking action language to robot motions is trained with reinforcement learning and proximal policy optimization.

- Semantic knowledge - The LLM provides contextual understanding and semantic knowledge to interpret abstract instructions. 

- Interactive perception and control - The coarse-to-fine inference provides closed-loop feedback, allowing the robot to interactively plan, execute, and recover from failures.

- Simulation-to-real transfer - The two inference modules are first trained in simulation then transferred to the real world for evaluation.

In summary, the key terms cover the architectural components of ERRA, the training methodology, and the interactive perception and control capabilities it enables. The approach aims to provide robots with reasoning, planning and interaction skills for complex long-horizon tasks.
