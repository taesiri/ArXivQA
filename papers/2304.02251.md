# ERRA: An Embodied Representation and Reasoning Architecture for
  Long-horizon Language-conditioned Manipulation Tasks

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper aims to address is: How can robots acquire the abilities of reasoning, planning, and interaction to complete long-horizon manipulation tasks specified by natural language instructions? The key hypothesis is that by using a framework with tightly-coupled probabilistic inferences at two levels (coarse and fine), the robot can decompose complex long-horizon tasks into simpler concrete actions, while maintaining closed-loop feedback between planning and execution. This allows the robot to effectively reason, plan, and execute long manipulation tasks described by abstract language instructions.Specifically, the hypotheses tested in this work are:H1: The proposed ERRA architecture can perform long-horizon language-conditioned manipulation tasks and outperforms other baselines.  H2: Robot proprioception is important for completing language-conditioned manipulation tasks.  H3: LLMs with prompt-tuning allow ERRA to generalize to unseen natural language instructions.H4: ERRA is able to transfer learned skills to the real world.H5: ERRA can respond to environmental changes caused by humans or its own failures.In summary, the key research question is how to enable robots to acquire reasoning, planning and interaction abilities for long-horizon language-conditioned manipulation tasks. The proposed ERRA framework with coarse-fine inferences is hypothesized to achieve this.


## What is the main contribution of this paper?

The main contribution of this paper is proposing an embodied learning architecture called ERRA that enables robots to obtain reasoning, planning, and interaction abilities for solving long-horizon language-conditioned manipulation tasks. Specifically, the key ideas and contributions are:- ERRA is based on tightly-coupled probabilistic inferences at two levels - coarse-resolution inference for high-level reasoning/planning, and fine-resolution inference for learning concrete actions. - Coarse-resolution inference is formulated as sequence generation through a large language model, which translates natural language instructions and environment states into action language. - Fine-resolution inference is formulated as a reinforcement learning problem to output actions corresponding to the action language from coarse inference.- The coarse-to-fine inference allows decomposing long-horizon tasks into simpler concrete actions, and the execution results provide feedback for subsequent coarse inference.- Experiments show ERRA can complete various long-horizon manipulation tasks specified by natural language instructions, and has the ability to generalize to novel instructions and adapt to environmental changes and failures.In summary, the key contribution is proposing the ERRA architecture that combines reasoning, planning, and interaction abilities to enable completing complex long-horizon language-conditioned manipulation tasks. The coarse-to-fine inference loop is critical to the success of ERRA.
