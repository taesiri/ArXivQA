# [xT: Nested Tokenization for Larger Context in Large Images](https://arxiv.org/abs/2403.01915)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Modern computer vision models are limited to processing small image sizes due to GPU memory constraints. This forces practitioners to either downsample or crop images, resulting in a loss of high-frequency details or global context. However, many real-world applications require understanding both local details and global context across entire large images.

Proposed Solution:  
The paper proposes xT, a simple framework that allows existing vision models to effectively process much larger images on contemporary GPUs without compromising on either local details or global context. 

The key ideas are:
1) Nested tokenization: Large images are hierarchically tokenized at multiple levels - into regions and then patches within each region.
2) Independent hierarchical encoding: Regions are encoded by a backbone vision model to get region features. 
3) Lightweight context encoding: The sequence of region features is then processed by a shallow context encoder using efficient linear attention to assimilate global context.
4) Task-specific decoding: The context-enriched feature sequence is passed to a task-specific decoder.

This allows encoding an arbitrary number of regions from a large image, with global context flow, in a memory-efficient manner.

Main Contributions:
1) Proposes xT, a simple and effective framework for modeling very large images end-to-end using existing vision models.
2) Achieves SOTA results on multiple tasks requiring global context (classification, detection, segmentation) on large real-world datasets. 
3) Enables 8.6% better accuracy on classification and 11.6 better F1 on segmentation compared to baselines, showing significance of global context.
4) Visualizes increased global receptive field and near-constant memory cost compared to base vision models when scaling to large images.

In summary, the paper enables global contextual understanding of very large images by existing models via hierarchical encoding and efficient cross-attention over region features.
