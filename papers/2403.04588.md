# [Zero-shot cross-modal transfer of Reinforcement Learning policies   through a Global Workspace](https://arxiv.org/abs/2403.04588)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Reinforcement learning (RL) agents can access information about the environment through multiple sensors (modalities), but it is difficult to exploit redundancy and complementarity between sensors for robustness or generalization.
- Humans perceive the world through multiple senses, enabling generalization across domains (e.g. mentally visualizing a scene from a textual description). 

Proposed Solution:
- Take inspiration from human multimodal integration and the 'Global Workspace Theory' in cognitive science.
- This theory states that different specialized modules compete to encode information into a shared representation called the Global Workspace. 
- The shared representation is then broadcast back to all modules, leading to a unified interpretation. This enables multimodal grounding by linking objects/properties across modalities.

- Implement a deep learning-compatible adaptation of this theory with encoders to project unimodal representations onto a shared one (the GW), and decoders to broadcast GW information back to each modality.
- Use supervised and self-supervised losses during training for alignment, broadcast, and cycle consistency.

- Train policies to map GW-encoded observations to actions, then test zero-shot transfer between modalities at inference time.

Main Contributions:
- Demonstrate a Global Workspace can enable zero-shot cross-modal policy transfer in RL agents, allowing policies trained on one modality (e.g. images) to generalize to another (e.g. attribute vectors) at test time.

- Highlight the advantages of semi-supervised learning for this approach, with cycle consistency objectives allowing generalization even with minimal paired supervision data. 

- Show that relying solely on contrastive alignment (like CLIP) is insufficient for cross-modal transfer, and that additional broadcast objectives are necessary.

- Provide a proof-of-concept that brain-inspired multimodal representations can be beneficial for training more robust and adaptable RL policies.
