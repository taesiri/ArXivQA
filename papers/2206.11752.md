# [CLAMP: Prompt-based Contrastive Learning for Connecting Language and   Animal Pose](https://arxiv.org/abs/2206.11752)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key points about the research question and contributions of this paper are:

- The paper proposes a new method called CLAMP for animal pose estimation. The key research question is how to effectively leverage language knowledge from pre-trained models like CLIP to improve animal pose estimation, which faces challenges like limited training data and large intra-/inter-species variances. 

- The main hypothesis is that language priors from pre-trained models can help compensate for the lack of animal image data by providing shared descriptions of keypoints across different species. However, directly using CLIP is not enough due to the mismatch between image-level CLIP training and keypoint-level pose tasks.

- To address this, CLAMP introduces pose-specific text prompts and spatial/feature adaptation processes to connect language and visual features effectively. The spatial adaptation establishes positional connections between text and image. The feature adaptation enhances discrimination and alignment of text/visual features.

- Experiments validate CLAMP's superiority over image-only methods on two datasets under supervised, few-shot, and zero-shot settings. This demonstrates the benefits of exploiting language knowledge for robust animal pose estimation.

In summary, the key contribution is proposing CLAMP to effectively leverage language priors for animal pose estimation, which is difficult for visual-only methods. The spatial and feature adaptation processes are critical to connect language and visual modalities.
