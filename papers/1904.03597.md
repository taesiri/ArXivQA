# [Self-supervised Spatio-temporal Representation Learning for Videos by   Predicting Motion and Appearance Statistics](https://arxiv.org/abs/1904.03597)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we learn powerful spatio-temporal video representations in a self-supervised manner, without requiring manually annotated labels?The key hypothesis is that by training a spatio-temporal convolutional neural network (CNN) to predict motion and appearance statistics derived from unlabeled video data, it will learn useful spatio-temporal features that transfer well to other video analysis tasks.In particular, the paper proposes predicting statistics like:- The region with the largest motion and its direction- The most color consistent region over time and its dominant color - The most color diverse region over time and its dominant colorBy regressing these motion and appearance statistics in a self-supervised manner on unlabeled video, the paper hypothesizes that the model will learn good video representations without needing any manual annotations.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel self-supervised approach to learn spatio-temporal video representations by predicting motion and appearance statistics. Specifically:- They design a self-supervised task of predicting a set of statistical labels derived from motion boundaries and color distributions in videos, without using any human annotations. - The statistical labels encode motion information like the region with largest motion and its direction, as well as appearance information like the most diverse color region.- They show this self-supervised task can be used to pre-train a 3D ConvNet (C3D) to learn effective spatio-temporal features for video analysis.- Extensive experiments show their method outperforms previous self-supervised methods on action recognition and other video analysis tasks when using the pre-trained C3D features.In summary, the key contribution is developing a self-supervised approach for spatio-temporal video representation learning by predicting motion and appearance statistics, which achieves superior performance to prior self-supervised methods.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a self-supervised approach to learn spatio-temporal video representations by training a 3D CNN to predict motion and appearance statistics derived from unlabeled videos, achieving state-of-the-art performance on action recognition compared to other self-supervised methods.
