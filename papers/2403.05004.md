# [Can't Remember Details in Long Documents? You Need Some R&amp;R](https://arxiv.org/abs/2403.05004)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Long context language models (LLMs) like GPT-4 Turbo struggle with document-based question answering (QA) when relevant context is in the middle of a long document (the "lost in the middle" effect). Their performance deteriorates as document length increases.

Proposed Solution:
- The authors propose a prompt-based method called "R&R" that combines two techniques - reprompting and in-context retrieval (ICR) - to mitigate the lost in the middle effect.

Reprompting: 
- Repeat the QA instructions periodically in the document to remind the LLM of the task, reducing distance between instructions and relevant context.

In-Context Retrieval:
- First prompt LLM to retrieve most relevant passages to the question. Then do QA with abbreviated context from retrieved passages. Retrieval is simpler than QA.

- R&R combines both techniques. Reprompt retrieval instructions during passage retrieval prompt.

Contributions:
- Show reprompting and ICR each independently improve performance on long document QA with GPT-4 Turbo and Claude-2.1. R&R improves further.
- Analyze reprompting and show proximity of instructions to relevant context improves performance. 
- Compare to chunk-based methods for limited context models. Show R&R enables larger chunks (fewer calls, less cost) with minimal accuracy loss.

In summary, the paper demonstrates R&R can extend the effective context length for document QA with long context models by mitigating the lost in the middle effect. The analysis provides insights into the mechanism behind reprompting.
