# [Left-right Discrepancy for Adversarial Attack on Stereo Networks](https://arxiv.org/abs/2401.07188)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Stereo matching neural networks often use a Siamese structure to extract intermediate features from left and right images. The similarity between these left-right features significantly impacts disparity estimation accuracy. However, these networks are vulnerable to small input perturbations. Prior adversarial attack methods on stereo networks simply maximize the networks' disparity loss, without considering their unique architecture.

Proposed Solution:
The paper proposes a novel adversarial attack that generates noise to maximize the discrepancy between left and right intermediate features of stereo networks. This is based on the insight that larger left-right dissimilarity makes disparity regression harder. 

Specifically, they introduce a warping loss that maximizes the dissimilarity between a left feature map and a warped version of the right feature map based on disparity. This loss is combined with the disparity loss to optimize the adversarial noise.

The method can also be extended to a proxy network black-box attack. Instead of requiring another stereo network, any pretrained network can be used to extract proxy left/right features to craft the adversarial noise.

Main Contributions:

- Proposes a new loss to attack stereo networks by maximizing left-right feature discrepancy, outperforming prior state-of-the-art attack methods

- Demonstrates superior attack performance on 3 popular stereo networks over 2 datasets - for example, 219% higher error on KITTI and 85% higher error on Scene Flow compared to previous attacks  

- Extends the attack to an efficient proxy-based black-box attack without needing access to any stereo network

- Reveals that stereo networks are more sensitive to shallow layer left-right feature discrepancies, offering insights into improving robustness

In summary, the paper introduces a more effective way to expose the vulnerability of stereo networks to small input perturbations, by exploiting left-right feature similarity which is crucial for accurate disparity estimation. The findings also shed light on potential defenses by enhancing robustness to left-right shallow feature discrepancies.


## Summarize the paper in one sentence.

 The paper proposes a novel adversarial attack method for stereo networks by generating noise to maximize the discrepancy between left and right intermediate features, demonstrating superior attack performance and revealing the sensitivity of stereo networks to shallow layer feature discrepancies.


## What is the main contribution of this paper?

 The main contributions of this paper are summarized in the paper as follows:

1. They propose a novel loss function for adversarial attack on stereo networks by maximizing the discrepancy on the left-right intermediate features of the stereo network. 

2. They perform exhaustive experiments to attack three popular stereo networks on two open datasets, and show that the performance of their attack method outperforms state-of-the-art attack methods.

3. They further extend their novel loss function to an efficient and practical proxy model black-box attack method without requiring access to any stereo network. Their method can leverage an arbitrary network from other tasks and generate the adversarial noise to incur obvious prediction errors on stereo networks.

4. Their experiments reveal that stereo networks are more sensitive to the discrepancy of shallow layer features, which can inspire further research on improving the robustness of stereo networks.

In summary, the key contributions are: (1) a new loss function to attack stereo networks by maximizing left-right feature discrepancy, (2) demonstration of superior attack performance compared to prior arts, (3) a black-box attack method using a proxy network, and (4) the finding that stereo networks are more sensitive to shallow layer feature discrepancies.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Stereo matching
- Adversarial attack
- Left-right feature discrepancy
- Siamese neural network structure
- Warping loss
- Feature map similarity
- White-box attack 
- Black-box attack
- Transferability of adversarial examples
- Proxy network

The paper proposes a new adversarial attack method against stereo matching networks by maximizing the discrepancy between left and right intermediate features using a novel warping loss. It demonstrates the attack effectiveness in white-box and black-box settings and shows stereo networks are more sensitive to discrepancies in shallow layer features. Key concepts include exploiting the Siamese architecture of stereo networks, left-right feature similarity, warping loss to increase discrepancy, attacking feature layers at different depths, and using a proxy network for black-box attacks without needing access to a stereo network.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a novel warping loss to maximize the discrepancy between left and right intermediate features of a stereo network. Why is maximizing this discrepancy an effective strategy to attack stereo networks? Can you explain the intuition behind this idea?

2. The warping loss can use arbitrary intermediate features from the stereo network. The experiments show that using shallow features achieves better attack performance. What is the potential explanation for this observation? 

3. For black-box attack, using shallow features from the proxy network also causes larger errors on the stereo networks. What is the potential connection between shallow features across different vision tasks?

4. The experiments show that attacking with only half the feature channels can achieve comparable performance to using all channels. What does this imply about the feature representations learned by neural networks?

5. The paper demonstrates higher attack success on DeepPruner compared to CREStereo. What architectural differences between these two networks contribute to the robustness gap?

6. How feasible is it to extend the proposed attack method to other related tasks such as optical flow or monocular depth estimation? What modifications would be required?

7. The findings reveal sensitivity of stereo networks to shallow layer discrepancies. How can this insight inform research on improving robustness of stereo vision systems?

8. What are the limitations of the proxy model black-box attack? In what scenarios might it fail or underperform?

9. What defenses could potentially mitigate the proposed attack method? How can we make stereo networks more robust to feature discrepancies? 

10. How can we verify that the proposed attack generates imperceptible noise instead of obviously distorted images? What metrics can quantify the perceptual quality?
