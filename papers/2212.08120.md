# Injecting Domain Knowledge in Language Models for Task-Oriented Dialogue   Systems

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can domain-specific knowledge be effectively injected into pre-trained language models to improve their performance on task-oriented dialogue systems, without needing to query external knowledge bases at runtime?The key hypothesis is that light-weight adapter networks can be used as repositories to store domain-specific facts learned from knowledge bases. The adapters can then provide knowledge to guide the predictions of the pre-trained language model when fine-tuned on downstream dialogue tasks. This approach aims to integrate external knowledge into the model parameters, eliminating the need for separate knowledge base queries during inference.In summary, the paper explores adapter-based knowledge injection methods and evaluates whether this enables pre-trained models to produce more knowledgeable and accurate responses in task-oriented dialog systems, compared to not having access to domain facts or having to query them from a separate knowledge base. The proposed Knowledge Probing using Response Selection (KPRS) benchmark is designed to specifically test models' ability to retrieve and reason with injected domain knowledge.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method for injecting domain-specific knowledge into pretrained language models (PLMs) for task-oriented dialogue systems. The key points are:- They use lightweight adapter networks as repositories of domain knowledge that can be integrated with PLMs. The adapters are first trained to memorize knowledge base facts, then the PLMs are fine-tuned to utilize the knowledge in the adapters. - They design a new probing task called Knowledge-Probing using Response Selection (KPRS) to evaluate how well models can retrieve injected knowledge. KPRS uses contrastive response pairs to test if models prefer responses consistent with the knowledge base.- They show improvements on KPRS and response generation from injecting knowledge with adapters compared to strong baselines lacking adapters. This demonstrates the utility of adapter-based knowledge injection.- The approach allows tightly integrating knowledge with PLMs without querying external knowledge bases at runtime. This can simplify deployment of task-oriented dialogue systems.In summary, the key contribution is proposing and demonstrating a method for effectively injecting specialized domain knowledge into PLMs using adapter networks and evaluating this with a new probing task. This improves factual consistency without external knowledge base queries.
