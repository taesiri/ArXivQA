# Survey of Hallucination in Natural Language Generation

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, it appears the central research question is: what is the current state of research on hallucination in natural language generation (NLG) tasks?The paper provides a comprehensive survey and review of the research progress and remaining challenges related to detecting and mitigating hallucinated text in various NLG tasks. It does not seem to propose a specific hypothesis, but rather aims to summarize the existing literature on this problem across different NLG domains. Some of the key aspects the survey covers are:- Defining hallucination and categorizing the types of hallucinations in NLG (intrinsic vs extrinsic)- Reviewing the contributors to hallucinations, including from training data, modeling choices, etc. - Summarizing the evaluation metrics proposed for detecting/quantifying hallucinations, both automatic metrics and human evaluation- Discussing the various mitigation methods explored, such as data cleaning, architecture modifications, training techniques, etc.- Providing an overview of the research specific to various NLG tasks: summarization, dialogue, QA, data-to-text, translation, vision-language- Identifying remaining challenges and suggesting future research directions to advance the understanding and handling of hallucinations in NLGIn summary, the paper aims to comprehensively survey the problem of hallucinations in NLG, rather than test a specific hypothesis. It reviews the current progress and consolidates the knowledge in this emerging research area.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Providing the first comprehensive survey of the hallucination problem in natural language generation (NLG). The paper reviews and summarizes the progress, challenges and future directions around evaluating and mitigating hallucinated text across major NLG tasks. 2. Analyzing hallucination issues in different NLG tasks including abstractive summarization, dialogue, generative QA, data-to-text generation, machine translation, and vision-language tasks. The similarities and differences in how hallucination manifests across tasks are discussed.3. Reviewing existing metrics for evaluating hallucination, categorizing them into statistical, information extraction-based, QA-based, NLI-based, etc. The limitations of current metrics are also analyzed.4. Summarizing various mitigation methods proposed, which are categorized into data-related methods, modeling/training methods, inference methods, etc. The advantages and disadvantages of different approaches are compared.5. Identifying open challenges and providing insights into promising future research directions in metrics design, mitigation methods, controllability of hallucination, incorporating human cognitive perspective, etc.In summary, this paper provides a comprehensive overview of the hallucination problem in NLG, summarizing the state-of-the-art and offering insights to guide future work towards safer and more robust NLG models. The cross-task perspective is valuable for researchers to draw inspiration from other fields.
