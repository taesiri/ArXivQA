# [PreFLMR: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers](https://arxiv.org/abs/2402.08327)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Large multimodal models (LMMs) excel at natural language and visual understanding but struggle with demanding tasks like knowledge-based visual question answering (KB-VQA). KB-VQA requires retrieving relevant information from documents to shape accurate answers. Recent retrieval methods like fine-grained late-interaction multi-modal retrieval (FLMR) outperform prior approaches but lack pre-training to fully leverage large models.

Proposed Solution: 
The authors introduce M2KR, a benchmark with 9 datasets covering image-text, question-text and image-question-text retrieval. M2KR is used to develop PreFLMR, a pre-trained version of FLMR. PreFLMR encodes images with ViT encoders and text with BERT encoders. The outputs are projected to a common space through a mapping structure to compute relevance via late interaction. 

PreFLMR is pre-trained in 4 stages: (1) text-encoder pre-training; (2) mapping structure training; (3) intermediate KB-VQA pretraining on E-VQA; (4) full-scale multi-task finetuning on M2KR. This improves generalization across tasks. Finetuned PreFLMR powers state-of-the-art performance on retrieval augmentation for KB-VQA models.

Contributions:
(1) M2KR benchmark suite with 9 diverse datasets for training and evaluating general-purpose multi-modal retrievers.
(2) PreFLMR, a strong pre-trained multi-modal retriever using M2KR. It achieves new SOTA results on 7 out of 9 M2KR tasks. 
(3) Studies on the scaling behavior of FLMR w.r.t model sizes and training data to guide future multi-modal retriever development.
(4) Demonstrates that PreFLMR can further boost performance on challenging KB-VQA datasets via retrieval augmentation.
