# On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in   Zero-Shot Reasoning

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How does prompting large language models (LLMs) to generate a zero-shot chain of thought (CoT) impact their performance on sensitive NLP tasks involving social reasoning and knowledge?In particular, the authors hypothesize that zero-shot CoT reasoning will increase the likelihood of LLM models generating biased, toxic, or harmful outputs when evaluated on tasks related to stereotypes and harmful content. The key hypotheses seem to be:- Zero-shot CoT will increase the rate of stereotypical selections/generations across sensitivity benchmarks compared to standard prompting without CoT.- Zero-shot CoT will increase the rate of explicit encouragement of harmful behaviors in open-ended generation compared to standard prompting.- The increases in bias and toxicity when using CoT will get worse as model scale increases.- Models with improved alignment through reinforcement learning will see smaller increases in bias/toxicity when using CoT compared to standard prompting.So in summary, the central research question is examining how zero-shot CoT impacts LLM performance on sensitive social reasoning tasks, with a hypothesis that CoT will reveal and exacerbate biases in the models. The paper aims to characterize these effects across model variants and task types.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:1. Demonstrating that using a zero-shot chain of thought (CoT) prompting strategy consistently increases toxicity and bias in large language models like GPT-3 when evaluated on sensitive social tasks. 2. Conducting controlled evaluations across two socially sensitive task types - harmful questions and stereotype benchmarks. The results show that CoT prompting causes models to exhibit increased preferences for output that perpetuates stereotypes or encourages explicit toxic behavior.3. Analyzing trends in CoT toxicity across different models, scales, and alignment techniques. The authors find that toxicity increases with model scale but decreases when models have improved instruction following through reinforcement learning based human preference learning. 4. Recommending that CoT should be used cautiously for socially sensitive tasks, especially when marginalized groups are involved. The authors suggest carefully auditing reasoning steps and being aware that techniques like pretending to be an "evil AI" are essentially reasoning strategies that can undo progress in value alignment.5. Highlighting implications for use of CoT in high stakes social domains like mental health chatbots, where models should avoid blindly using CoT and instead be uncertain when generating potentially biased reasoning.In summary, the main contribution is demonstrating empirically that zero-shot CoT prompting, while beneficial for logical reasoning tasks, significantly increases undesirable bias and toxicity when applied to tasks requiring nuanced social knowledge. The authors recommend mitigation strategies and caution around use of CoT for socially sensitive applications.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper demonstrates that using zero-shot chain of thought (CoT) prompting can increase harmful biases and toxicity in large language model generations on sensitive tasks related to stereotypes and harmful behavior, especially as model scale increases, indicating that CoT should be used cautiously for socially-relevant domains.
