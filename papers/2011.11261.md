# [Hierarchically Decoupled Spatial-Temporal Contrast for Self-supervised   Video Representation Learning](https://arxiv.org/abs/2011.11261)

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the central hypothesis of this paper is that decomposing the video representation learning task into hierarchical subtasks that emphasize spatial vs temporal features will result in better learned representations compared to traditional contrastive learning methods that learn spatial and temporal features entangled together. Specifically, the authors propose a method called Hierarchically Decoupled Spatial-Temporal Contrast (HDC) that:1) Decouples the learning objective into Spatial Contrast and Temporal Contrast subtasks to focus on spatial and temporal features separately.2) Performs the learning hierarchically across multiple scales to capture multi-scale spatial and temporal semantics. The authors hypothesize that by decomposing the problem and learning spatial vs temporal features separately in a hierarchical manner, HDC will be better able to learn rich video representations compared to traditional contrastive learning approaches that learn entangled spatial-temporal features in one shot. The experiments aim to validate whether HDC does indeed outperform other methods on downstream action recognition tasks.


## What is the main contribution of this paper?

The main contributions of this paper are:- It demonstrates the effectiveness of spatial-temporal feature learning decoupling and hierarchical learning for self-supervised video representation learning. - It shows that augmentations can be manipulated as regularization to guide neural networks to learn desired features in contrastive learning. The paper introduces a new way to separately capture spatial and temporal semantics in videos through this approach.- It proposes an approach to improve hierarchical contrastive learning by modeling the divergent levels of invariance in different layers and using that to weight the loss terms. - It presents a method called Hierarchically Decoupled Spatial-Temporal Contrast (HDC) that outperforms other unsupervised methods on downstream action recognition tasks on UCF101 and HMDB51 datasets.In summary, the key ideas are using regularization through augmented data to decouple the learning of spatial and temporal features, performing this decoupled learning hierarchically across network layers, and weighting the loss terms appropriately to account for differences in invariance across layers. The combination of these ideas leads to state-of-the-art performance on standard video representation learning benchmarks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper introduces a new approach for self-supervised video representation learning called Hierarchically Decoupled Spatial-Temporal Contrast (HDC) which decomposes the learning objective into separate subtasks emphasizing spatial and temporal features performed hierarchically to capture rich semantics at multiple scales, achieving state-of-the-art performance on action recognition benchmarks.


## How does this paper compare to other research in the same field?

Here are a few key points on how this paper compares to other research in self-supervised video representation learning:- The paper introduces a novel framework called Hierarchically Decoupled Spatial-Temporal Contrast (HDC) that decomposes the learning objective into separate subtasks emphasizing spatial and temporal features. Most prior work has focused on learning spatio-temporal features together rather than explicitly decoupling them. The decoupling is a novel idea proposed in this paper.- The paper also proposes performing the learning hierarchically, capturing features at multiple scales. While some recent work like Yang et al. 2020 also explores hierarchical contrastive learning, this paper applies the idea to spatial-temporal decoupled learning for the first time. - The paper shows that augmentations can be manipulated as regularization to guide the network to learn desired semantics in contrastive learning. They introduce a specific way to use augmentations to separately capture spatial and temporal features. This idea of using augmentations for decoupling has not been explored before.- The paper models the divergent levels of invariance in different layers as different loss weights to improve hierarchical contrastive learning. This is a new approach not present in other hierarchical contrastive learning papers. - Experiments show state-of-the-art performance of HDC over other self-supervised methods on downstream action recognition tasks on UCF101 and HMDB51 benchmarks. The gains over directly learning spatio-temporal features together demonstrate the benefits of the proposed decoupling and hierarchical learning.In summary, the key novelties compared to prior work are the introduction of spatial-temporal decoupling, using augmentations for regularization to enable decoupled learning, hierarchical multi-scale learning applied to the decoupled objectives, and modeling layer invariances - leading to improved performance over prior arts.
