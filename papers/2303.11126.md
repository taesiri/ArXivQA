# [Robustifying Token Attention for Vision Transformers](https://arxiv.org/abs/2303.11126)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we make the attention mechanism in vision transformers (ViTs) more robust against common image corruptions and perturbations?

The authors observe that standard ViTs tend to rely too heavily on a few "important" tokens when computing self-attention. However, these tokens are not actually robust and can change entirely when the input image is corrupted with noise, blur, etc. 

To address this, the authors propose two main techniques:

1) Token-aware Average Pooling (TAP): Allows each token to adaptively aggregate information from its local neighborhood, making the model less reliant on just a few individual tokens.

2) Attention Diversification Loss (ADL): Explicitly encourages the model to distribute attention across diverse input tokens rather than focusing too heavily on the same "important" tokens.

The central hypothesis is that alleviating the "token overfocusing" phenomenon via these techniques will substantially improve the robustness of ViT models against common image corruptions while maintaining accuracy on clean images. The experiments aim to validate this hypothesis across different model architectures and tasks.

In summary, the core research question is how to make ViT attention more robust, with the central hypothesis being that reducing token overfocusing will achieve this goal. The TAP and ADL methods are proposed to address the token overfocusing problem.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

1. Identifying and analyzing the "token overfocusing" phenomenon in vision transformers (ViTs), where the self-attention mechanism relies too heavily on just a few tokens. The authors show this leads to fragile attention patterns that are not robust to image corruptions.

2. Proposing two general techniques to alleviate the token overfocusing issue and improve the stability and robustness of ViT attention:

- Token-aware Average Pooling (TAP): Encourages the local neighborhood of each token to participate in attention by learning adaptive average pooling schemes for each token.

- Attention Diversification Loss (ADL): Explicitly reduces the similarity of attention patterns between different output tokens, encouraging more diverse attention. 

3. Demonstrating that both TAP and ADL can be incorporated into various ViT architectures and consistently improve robustness across multiple image classification datasets and tasks, including semantic segmentation. For example, the methods achieve over 2% improvement on corruption and distribution shift benchmarks like ImageNet-C while also slightly improving clean accuracy.

In summary, the main contribution appears to be identifying token overfocusing as a key robustness issue in ViTs, and proposing two lightweight and general techniques to mitigate this issue and significantly improve robustness across tasks and architectures.
