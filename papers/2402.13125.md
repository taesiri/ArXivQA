# [TreeEval: Benchmark-Free Evaluation of Large Language Models through   Tree Planning](https://arxiv.org/abs/2402.13125)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Existing methods for evaluating large language models (LLMs) suffer from issues like data leakage and inflexibility. Benchmark-based methods are prone to data leakage as the test data can be used for fine-tuning models, skewing results. Methods using LLMs as judges have limited flexibility in evaluation. 

Proposed Solution: The paper proposes TreeEval, a novel LLM evaluation approach based on tree planning. An examiner LLM hosts irreproducible evaluation sessions, acting as an interviewer to pose questions to evaluatee LLMs. Questions are generated on the fly, preventing data leakage. The examiner constructs a tree of questions, deciding subsequent questions based on current responses to thoroughly evaluate models.  

Key Contributions:
- Introduces a new paradigm for LLM evaluation where an examiner LLM conducts the evaluation via dynamic question generation, inherently avoiding data leakage.
- Constructs a tree of questions tailored to current responses, allowing flexible and comprehensive assessment. Questions become more discerning as needed when models have similar capabilities.  
- Achieves high correlation in rankings compared to AlpacaEval2.0 while using far fewer questions on average. Demonstrates efficiency in distinguishing model performance.
- Enables fine-grained evaluation, assessing model capabilities across diverse topics. Repeated experiments yield consistent scores, highlighting robustness.

In summary, TreeEval enables efficient, tailored, and robust LLM evaluation while preventing test data exposure. The examiner paradigm and tree-based approach provide both security and precision in assessing model strengths.
