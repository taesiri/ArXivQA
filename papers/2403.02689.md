# [Deep Common Feature Mining for Efficient Video Semantic Segmentation](https://arxiv.org/abs/2403.02689)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Deep Common Feature Mining for Efficient Video Semantic Segmentation":

Problem:
- Video semantic segmentation aims to assign semantic labels to every pixel in a video. High accuracy and temporal consistency are desired. 
- Existing methods either focus on accuracy but are computationally expensive (e.g. using transformers), or accelerate inference but rely too much on unstable feature propagation across frames.

Proposed Solution:
- Propose a novel Deep Common Feature Mining (DCFM) approach to balance accuracy and efficiency.
- Key idea is to decompose features into two complementary components:
   - Common representation: Captures high-level semantics that remain relatively constant over time. Can be reused across frames without propagation.
   - Independent representation: Captures frame-specific details that change quickly.
- Group backbone layers into stages to output the two representations. Fuse them using a lightweight module.
- Use a symmetric training strategy and self-supervised loss to facilitate learning from sparsely annotated data.

Main Contributions:
- Novel architecture to extract reusable common features and frame-specific independent features. Enables efficiency without reliance on propagation.
- Symmetric training strategy and self-supervised loss for learning from sparsely annotated data.
- Achieves superior accuracy-efficiency trade-off on VSPW and Cityscapes datasets, compared to prior works. Up to 5x faster than transformer methods with comparable accuracy.
- The decomposed representation also improves result robustness and temporal consistency.

In summary, the key innovation of DCFM is the feature decomposition and mining process that balances semantic reuse for efficiency with frame-specific details for accuracy, outperforming previous video segmentation methods. The training strategies further facilitate robust learning.
