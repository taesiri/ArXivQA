# [No Fear of Classifier Biases: Neural Collapse Inspired Federated   Learning with Synthetic and Fixed Classifier](https://arxiv.org/abs/2303.10058)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be: How can we mitigate the issue of classifier bias and misaligned feature representations caused by data heterogeneity in federated learning? 

The key hypothesis seems to be: Employing a simplex equiangular tight frame (ETF) as a fixed classifier for all clients during federated training can enable clients to learn unified and optimal feature representations, thus overcoming the problems caused by data heterogeneity.

In summary, the paper aims to tackle the classifier bias issue in federated learning arising from non-IID client data distributions. It hypothesizes that using a synthetic ETF classifier can align client features and classifiers during training. The experiments then validate this hypothesis by showing performance improvements on benchmark datasets.
