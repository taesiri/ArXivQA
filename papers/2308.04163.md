# [Under-Display Camera Image Restoration with Scattering Effect](https://arxiv.org/abs/2308.04163)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we develop an effective image restoration method to address the problem of image degradation caused by the scattering effect in under-display camera (UDC) imaging systems?

The key points are:

- Existing UDC image restoration methods have largely neglected the treatment of the scattering effect caused by the display layer in UDC systems. This scattering effect results in image degradation like contrast distortion and haziness. 

- The authors propose to explicitly model the UDC scattering effect using a physics-based approach that decomposes the received camera irradiance into transmitted and scattered components. 

- Using this scattering model, they enhance the image formation pipeline to generate more realistic synthetic UDC images for training.

- They design a dual-branch neural network with a scattering branch to estimate parameters of the scattering effect, and an image branch to restore the clean image. The branches are coupled through a feature fusion block.

- Experiments on synthetic and real-world UDC images demonstrate superiority over state-of-the-art methods in removing scattering-induced degradation and restoring image details.

In summary, the central hypothesis is that by explicitly modeling and estimating the parameters of the UDC scattering effect, they can design an effective image restoration network to address this major degradation cause in UDC imaging. The results validate the effectiveness of their approach.


## What is the main contribution of this paper?

 This paper proposes a new approach for restoring images captured by under-display cameras (UDCs). The key contributions are:

- It proposes a physical model to characterize the scattering effect caused by the display in UDC imaging. This scattering effect results in degradation like haze and contrast distortion in UDC images. 

- Based on the proposed UDC scattering model, it enhances the image formation pipeline to synthesize more realistic UDC images with ground truth for training.

- It designs a two-branch deep network for UDC image restoration. One branch estimates parameters of the scattering effect, while the other branch restores the clear image guided by the first branch. 

- It develops several network components tailored for UDC image restoration, including Transposed Self-Attention Blocks, Gated Channel Attention Blocks, and Feature Fusion Blocks.

- Experiments on both synthetic and real-world UDC images demonstrate superiority over previous state-of-the-art methods. The restored images have significantly improved visual quality.

In summary, the key novelty is explicitly modeling and addressing the scattering effect in UDC imaging and restoration, through both physical modeling and network design. This leads to performance improvements compared to prior arts.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a new model for restoring degraded images from under-display cameras that explicitly accounts for light scattering effects caused by the display screen layers, and uses a dual-branch neural network with global and local modeling capabilities to estimate the scattering parameters and recover the clean image.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this paper compares to other research in the field of under-display camera (UDC) image restoration:

- This paper focuses on explicitly modeling and removing the scattering effect caused by the display in UDC imaging. Most prior works do not consider this effect and mainly deal with blur, noise, and diffraction artifacts. So this work provides a new perspective on UDC image degradation.

- The proposed image formation pipeline enhances existing models by integrating a scattering model. This results in more realistic synthetic training data compared to prior data generation methods.  

- The dual-branch network design is novel, with one branch estimating scattering parameters and the other branch restoring the image. This allows explicitly modeling and suppressing scattering effects.

- Using channel-wise self-attention in the scattering branch provides global modeling capabilities. And CNN in the image branch leverages local representations. This combination is unique.

- Extensive experiments on synthetic and real-world data demonstrate state-of-the-art performance, with significant visual quality improvements compared to existing methods.

- The code and dataset are released, enabling reproducibility and further research.

Overall, this paper makes multiple contributions - an enhanced image formation model, specialized network design, and strong results. It advances UDC image restoration specifically for scattering effects. The novel ideas and thorough experiments differentiate this work from prior art in this domain.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Extending the scattering model to account for multiple light sources instead of just a single source. The authors state that their current modeling approach could be extended to handle multiple sources through radiance accumulation. 

- Incorporating more diverse PSF measurements from different display types into the training data synthesis procedure. The authors note that the generalization of their pretrained model may be limited since the training data only contained PSFs from two display types. Using more display PSFs could improve generalization.

- Exploring different network architectures and loss functions. The authors propose specific network designs and loss formulations, but note that further improvements could potentially be achieved by exploring other network and loss options.

- Applying the proposed scattering modeling and restoration approach to other imaging systems and modalities that exhibit scattering effects, beyond just under-display cameras. The scattering effect modeling could be generalized.

- Considering temporal information and video restoration. The current work focuses on image restoration. Extending the approach to video could be an interesting direction.

- Evaluating the impact of restored UDC images on high-level vision tasks. Assessing performance on downstream tasks could provide further validation and motivation.

Overall, the main future directions are around expanding the scattering model, diversifying the training data, investigating architectural and loss variants, generalizing to other applications, and evaluating on video and high-level vision tasks. The authors lay out several interesting paths for extending the research.


## Summarize the paper in one paragraph.

 This paper proposes a method for restoring images captured by under-display cameras (UDCs). The key contributions are:

1. The authors model the scattering effect caused by the display in UDC imaging systems. Based on this model, they enhance the image formation pipeline to synthesize more realistic UDC images with ground truth for training. 

2. A two-branch deep network is designed for UDC image restoration, with a scattering branch to estimate parameters of the scattering effect, and an image branch to recover the clean image guided by the scattering branch outputs. The scattering branch uses channel-wise self-attention to model global information while the image branch uses CNNs to exploit local representations. 

3. Extensive experiments on synthetic and real-world UDC images demonstrate superior performance over state-of-the-art methods. The proposed approach effectively removes haze, contrast distortion, and diffraction artifacts caused by the scattering effect and display structure.

In summary, this paper addresses the under-explored scattering effect in UDC imaging and proposes tailored solutions including an enhanced image formation model and dual-branch network architecture for high-quality image restoration. Experiments verify the effectiveness of modeling and suppressing the scattering effect.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper proposes a new approach for restoring images captured by under-display cameras (UDCs). The key contribution is explicitly modeling and removing the scattering effect caused by the display screen. Previous UDC image restoration methods have neglected this scattering effect, which leads to hazy and low contrast images. 

To address this, the authors first propose an enhanced image formation pipeline that incorporates a physical scattering model. This generates more realistic synthetic UDC images for training. Then a dual-branch neural network is presented, with one branch estimating scattering parameters and another branch restoring the image. The scattering branch uses self-attention to capture global information. The image branch uses convolutional layers to exploit local patterns. A feature fusion module combines guidance from the scattering branch into the image branch. Experiments on synthetic and real UDC images demonstrate state-of-the-art performance. The proposed method effectively removes haze and enhances image contrast by explicitly accounting for display scattering.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

This paper proposes a new method for restoring images captured by under-display cameras (UDCs). The key contributions are enhancing the image formation pipeline (IFP) to model the scattering effect caused by the display, and designing a dual-branch deep network for image restoration. The enhanced IFP treats the display as a homogeneous scattering medium and decomposes the received camera irradiance into transmitted and scattered components. This allows generating more realistic synthetic UDC images for training. The proposed restoration network contains a scattering branch to estimate parameters related to scattering, and an image branch that recovers the clean image. The scattering branch uses transposed self-attention blocks to capture global information. The image branch uses CNNs to exploit local representations. A feature fusion block integrates guidance from the scattering branch into the image branch. Experiments on synthetic and real-world UDC images demonstrate that explicitly modeling scattering and using the dual-branch design leads to significant improvement in restoration performance over state-of-the-art methods.


## What problem or question is the paper addressing?

 This paper appears to be addressing the problem of restoring high-quality images from under-display cameras (UDCs). Specifically, it focuses on dealing with the degradation caused by the scattering effect of the display panel.

The key question seems to be - how can we effectively model and remove the scattering effect in order to recover clean, artifact-free images from UDCs?

Some of the main points:

- The scattering effect of the display causes issues like haze, contrast distortion, and loss of details in UDC images. This effect has been neglected in prior UDC image restoration methods.

- The authors propose a new imaging model for UDCs that explicitly accounts for light scattering through the display. This allows them to simulate more realistic UDC images.

- They design a deep learning framework with two branches - one focused on estimating scattering parameters, the other on restoring the clean image. The branches are linked to guide the image restoration process.

- Experiments on synthetic and real-world UDC data show their method is superior to prior art in recovering image details while removing scattering artifacts. 

In summary, the key contribution is developing an imaging model and learning method tailored to handle the unique scattering effect in UDC images, which has not been adequately addressed before. The results demonstrate the importance of accounting for this phenomenon.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key keywords and terms are:

- Under-display camera (UDC) - The paper focuses on image restoration for cameras placed under displays.

- Scattering effect - The paper models and addresses the image degradation caused by light scattering in the display layers over the UDC.

- Image restoration - The overall goal is to restore high-quality images from degraded UDC images. 

- Image formation pipeline (IFP) - The paper enhances the existing IFP to synthesize more realistic UDC images. 

- Dual-branch network - The proposed method uses two branches, one for estimating scattering parameters and one for image restoration.

- Channel-wise self-attention - The scattering branch uses this to capture global information. 

- Convolutional neural network (CNN) - The image branch uses CNN to exploit local representations.

- Feature fusion - A module is designed to combine global and local information from the two branches.

So in summary, the key focus is on modeling and removing the scattering effect in UDC images using global and local representations in a dual-branch learning framework.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to ask to create a comprehensive summary of the paper:

1. What is the key problem or challenge that this paper aims to address? 

2. What is the main contribution or proposed method in this paper?

3. What previous or related work does the paper build upon? 

4. What methodology/approach does the paper take to address the problem?

5. What are the key components or steps of the proposed method?

6. What datasets were used to evaluate the method and what were the main results?

7. What metrics were used to evaluate the performance of the method? 

8. How does the proposed method compare to previous or alternative approaches to this problem?

9. What are the limitations or potential areas of improvement for the proposed method?

10. What conclusions or future work does the paper suggest based on the results?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes an enhanced image formation pipeline (IFP) for synthesizing more realistic UDC images by modeling the scattering effect. How is the proposed scattering model different from existing UDC image degradation models? What are the key limitations of previous models that motivated the need for an enhanced IFP?

2. The proposed scattering model treats the display in UDC as a homogeneous scattering medium. What assumptions were made in deriving this model? How reasonable are these assumptions for modeling real UDC systems? What other approaches could be explored to model scattering in a UDC display?

3. The scattering branch in the proposed network estimates the parameters α and m of the scattering model. How critical are accurate estimates of these parameters for restoring the UDC image? What happens if these parameters are poorly estimated?

4. The scattering branch uses transposed self-attention blocks (TSABs) to estimate α and m. Why are TSABs well-suited for this task compared to CNNs? What are the key benefits of leveraging self-attention here?

5. The image branch uses CNNs as the backbone. What are the advantages of CNNs that make them suitable for this branch? Why not use self-attention like the scattering branch? What complementary roles do the two branches play?

6. The feature fusion block (FFB) combines information from the two branches using an affine transformation. What is the intuition behind using an affine transformation here? How does this differ from other fusion techniques like concatenation?

7. The proposed method achieves significant gains on synthetic data. However, how well does it generalize to real UDC images across different devices? What additional experimentation could be done to analyze real-world performance?

8. The scattering model assumes a single light source and parallel light rays. How can this approach be extended to handle complex real-world illumination and non-parallel rays? What changes would need to be made to the model and network?

9. Could the proposed technique be combined with optimization-based UDC image processing methods? What complementary benefits might this provide over pure learning-based approaches?

10. What other UDC image degradation effects are not addressed by the current method, such as chromatic aberration? How feasible would it be to extend the framework to handle multiple phenomena jointly?
