# [NTIRE 2023 Image Shadow Removal Challenge Technical Report: Team IIM_TTI](https://arxiv.org/abs/2403.08995)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- The NTIRE2023 Shadow Removal Challenge dataset contains misalignments between shadow and shadow-free image pairs due to changes in external camera parameters. This poses an additional challenge beyond just shadow removal. 
- Existing shadow removal methods like ShadowFormer don't explicitly handle such misalignments.
- ShadowFormer also uses loss functions like Charbonnier loss that limit perceptual quality.
- It relies on an external shadow detection model that requires fine-tuning on this dataset which lacks shadow masks. 
- The shadow detection and removal models are trained independently which limits potential improvements.

Proposed Solution - "ShadowFormer+":

- Explicitly estimates a homography between image pairs to align them as a pre-processing step. This transforms the shadow-free image to match the one with shadows.

- Uses a perceptual quality loss, specifically a Structure Preservation loss matched in a DiNO feature space along with an edge-based SSIM loss for better quality.

- Introduces a "Semi-Automatic Shadow Mask Annotation" method to automatically predict shadow masks from the V channel of HSV images to supervise the shadow detector.  

- Uses joint training of the shadow detector MTMT model and ShadowFormer removal model end-to-end to improve both.

- Introduces a novel data augmentation method "CutShadow" that cuts and pastes shadow image patches onto shadow-free images.

Main Contributions:

- Analysis of misalignment issue in the challenge dataset and using explicit alignment.

- Use of perceptual losses for visually better shadow removal.  

- Automatic method to annotate shadow masks from available data itself without manual effort. Enables supervised tuning of detection model.

- Joint end-to-end training of shadow detector and remover models.

- New data augmentation strategy CutShadow for generating augmented shadow data.

The proposed ShadowFormer+ method achieves high rankings in both LPIPS (3rd out of 19) and Mean Opinion Score (3rd out of 19). Both quantitative metrics and qualitative results demonstrate effectiveness of the improvements over baseline ShadowFormer.


## Summarize the paper in one sentence.

 This paper proposes five key improvements to ShadowFormer for shadow removal: image alignment, perceptual quality loss functions, semi-automatic shadow mask annotation, joint learning of shadow detection and removal, and new data augmentation techniques.


## What is the main contribution of this paper?

 According to the paper, the main contribution is proposing improvements to the ShadowFormer model for shadow removal, which include:

1) Image alignment using homography estimation to correct for misalignments between the input shadow image and ground truth non-shadow image. 

2) Using a perceptual quality loss function (Structure Preservation loss and Edge-based SSIM loss) instead of just pixel-wise losses like Charbonnier.

3) A semi-automatic method to annotate shadow masks (SASMA) for the challenge dataset.

4) Jointly training the shadow detection and shadow removal networks in an end-to-end manner. 

5) A new data augmentation method called CutShadow that pastes image patches with shadows onto images without shadows.

In summary, the main contribution is a set of five key improvements to the ShadowFormer architecture and training process to make it more effective for the NTIRE 2023 Shadow Removal Challenge. The improvements aim to handle the specific issues with the challenge dataset and task.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper content, some of the key terms and keywords associated with this paper include:

- Shadow removal
- Image alignment
- Homography estimation
- Perceptual loss
- Structure preservation loss
- Semi-automatic shadow mask annotation (SASMA)
- Joint learning of shadow detection and removal 
- Data augmentation (CutShadow)
- Transformer (ShadowFormer)
- Image restoration and enhancement

The paper proposes several improvements to the ShadowFormer method for shadow removal, including aligning the input and ground truth images using homography estimation, using perceptual losses like structure preservation and edge-based SSIM loss, semi-automatically creating shadow masks, jointly training the shadow detector and remover, and proposing a CutShadow data augmentation method. The key focus is on improving shadow removal performance on the NTIRE 2023 challenge dataset.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper mentions aligning the input and ground truth images using homography estimation. What is the motivation behind this alignment step and how does it qualitatively and quantitatively impact performance?

2. The paper proposes a new "Semi-Automatic Shadow Mask Annotation (SASMA)" technique. Explain this technique in detail and discuss its advantages and disadvantages compared to manual annotation. 

3. The paper jointly trains the shadow detector and shadow remover networks. Explain the joint loss function used (Eq. 4) and analyze the impact of the α hyperparameter on performance. 

4. The Structure Preservation loss (Eq. 1) uses the euclidean distance instead of cosine similarity as in prior work. Analyze the impact of this modification both quantitatively and perceptually. 

5. The Edge-based SSIM (ESSIM) loss (Eq. 2) operates on the edges extracted from the value channel of the HSV color space. Motivate this design choice and discuss any alternatives you might consider.  

6. The CutShadow data augmentation technique is proposed to generate more training data. Compare and contrast this technique with CutBlur from prior work. What are the key differences?

7. The paper uses the MTMT architecture for shadow detection. What modifications were made to the pre-trained MTMT model and how did its performance qualitatively change after fine-tuning on the challenge dataset?

8. Qualitatively analyze the joint learning results in Fig 5. How does the mask prediction change with different α values and why? What does this suggest about the interaction between the two networks?

9. The method achieves a lower PSNR compared to baseline but higher perceptual quality. Analyze the tradeoffs at play and discuss what objective metrics, if any, you think should be used to evaluate shadow removal. 

10. The paper mentions the dataset contains misalignment between input and GT pairs. Do you think models trained on aligned data generalize well to real-world misaligned test cases? Motivate your answer.
