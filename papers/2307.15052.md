# [Learning Depth Estimation for Transparent and Mirror Surfaces](https://arxiv.org/abs/2307.15052)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper seeks to address is: How can we train monocular and stereo depth estimation networks to accurately estimate depth for transparent and mirror (ToM) surfaces without requiring ground truth depth annotations?The key hypothesis is that by virtually replacing ToM objects with opaque ones in images, monocular and stereo networks can hallucinate reasonable depth estimates for those objects. These virtual depth labels can then be used to fine-tune the networks to handle ToM surfaces properly.In summary, the paper investigates:1) How to generate virtual depth training data for images containing ToM objects using only semantic segmentation masks as input.2) Whether fine-tuning monocular and stereo networks on this virtual data can significantly improve their depth estimation accuracy on ToM surfaces.The main novelty is showing that with a simple data generation strategy, existing monocular and stereo networks can learn to estimate reasonable depth for ToM objects without need for real ground truth depth supervision. This allows training the networks to handle ToM surfaces without expensive manual depth annotation.


## What is the main contribution of this paper?

Based on my understanding, the main contribution of this paper is proposing a simple yet effective strategy to train depth estimation networks to handle transparent and mirror (ToM) surfaces, without requiring any ground-truth depth annotations. The key ideas are:- They observe that recent pre-trained monocular depth networks like MiDaS and DPT can estimate depth well on most scenes, but struggle on ToM surfaces. - They propose to trick these networks by replacing ToM objects with opaque artifacts of similar shape and texture. This allows the networks to hallucinate reasonable depth values for those objects.- They introduce a pipeline to generate "virtual" depth labels on images with ToM objects by:  - Using segmentation masks to detect ToM regions  - Inpainting those regions with random colors   - Feeding the masked images to a depth network to generate pseudo-labels- These virtual labels can then be used to fine-tune the same depth network on real unaltered images containing ToM objects. Experiments show dramatic accuracy improvements.- The method is extended to stereo networks by merging their raw disparities with monocular depths on ToM areas. - The pipeline only requires segmentation masks, which are easier to obtain than depth maps. Proxy masks from a segmentation network also work reasonably well.In summary, the key contribution is a simple yet effective strategy to create "virtual" depth annotations on ToM surfaces, allowing training depth networks without real ground-truth depth data. The results demonstrate large accuracy improvements on ToM regions for both monocular and stereo networks.
