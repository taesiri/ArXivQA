# [Learning Depth Estimation for Transparent and Mirror Surfaces](https://arxiv.org/abs/2307.15052)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper seeks to address is: How can we train monocular and stereo depth estimation networks to accurately estimate depth for transparent and mirror (ToM) surfaces without requiring ground truth depth annotations?The key hypothesis is that by virtually replacing ToM objects with opaque ones in images, monocular and stereo networks can hallucinate reasonable depth estimates for those objects. These virtual depth labels can then be used to fine-tune the networks to handle ToM surfaces properly.In summary, the paper investigates:1) How to generate virtual depth training data for images containing ToM objects using only semantic segmentation masks as input.2) Whether fine-tuning monocular and stereo networks on this virtual data can significantly improve their depth estimation accuracy on ToM surfaces.The main novelty is showing that with a simple data generation strategy, existing monocular and stereo networks can learn to estimate reasonable depth for ToM objects without need for real ground truth depth supervision. This allows training the networks to handle ToM surfaces without expensive manual depth annotation.


## What is the main contribution of this paper?

Based on my understanding, the main contribution of this paper is proposing a simple yet effective strategy to train depth estimation networks to handle transparent and mirror (ToM) surfaces, without requiring any ground-truth depth annotations. The key ideas are:- They observe that recent pre-trained monocular depth networks like MiDaS and DPT can estimate depth well on most scenes, but struggle on ToM surfaces. - They propose to trick these networks by replacing ToM objects with opaque artifacts of similar shape and texture. This allows the networks to hallucinate reasonable depth values for those objects.- They introduce a pipeline to generate "virtual" depth labels on images with ToM objects by:  - Using segmentation masks to detect ToM regions  - Inpainting those regions with random colors   - Feeding the masked images to a depth network to generate pseudo-labels- These virtual labels can then be used to fine-tune the same depth network on real unaltered images containing ToM objects. Experiments show dramatic accuracy improvements.- The method is extended to stereo networks by merging their raw disparities with monocular depths on ToM areas. - The pipeline only requires segmentation masks, which are easier to obtain than depth maps. Proxy masks from a segmentation network also work reasonably well.In summary, the key contribution is a simple yet effective strategy to create "virtual" depth annotations on ToM surfaces, allowing training depth networks without real ground-truth depth data. The results demonstrate large accuracy improvements on ToM regions for both monocular and stereo networks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a method to generate virtual depth labels for transparent and reflective surfaces by masking and inpainting these areas in images, and using a pretrained monocular depth network to estimate depth maps on the modified images to train the network to handle these challenging surface types.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other research on depth estimation for transparent and mirror surfaces:- The main novelty of this paper is proposing a simple yet effective method to generate virtual depth labels for transparent and mirror (ToM) surfaces by inpainting them with uniform colors in images. This allows training depth estimation networks on the inpainted images without needing real depth labels for ToM objects, which are very difficult to obtain.- Most prior work has focused on depth completion, using sparse measurements from RGB-D sensors and inpainting the missing depth values for transparent objects (e.g. SelfDeco by Choi et al. 2021). In contrast, this paper tackles monocular and stereo depth estimation without any depth input. - A few datasets provide real depth labels for transparent objects (e.g. ClearGrasp, ClearPose), but they are limited in scale and variety. Synthetic datasets with rendered depth are also available (e.g. ClearGrasp), but may not generalize well. This paper shows competitive results by training on purely virtual depth labels.- For monocular depth estimation, no prior work specifically addresses transparent surfaces, to my knowledge. The core ideas around inpainting and distilling proxy labels are novel.- For stereo depth estimation, BOOSTER dataset specifically focuses on specular and transparent objects. This paper shows improved results on BOOSTER by fine-tuning state-of-the-art stereo models (RAFT, CREStereo) with the proposed virtual labels.- The idea of merging mono and stereo depth predictions based on semantic segmentation is also a simple but effective contribution for stereo depth estimation.Overall, the paper presents a straightforward but well-motivated approach to address a challenging problem by generating training data cheaply without real depth labels. The results demonstrate its effectiveness for both monocular and stereo depth estimation networks. The core ideas could inspire more advanced techniques in future work.


## What future research directions do the authors suggest?

Based on my reading of the conclusion section, the authors suggest the following future research directions:1. Extending their technique to instance segmentation masks instead of semantic segmentation. This could allow generating better virtual depth maps when there are multiple transparent/mirror objects in a scene.2. Training monocular and stereo depth estimation networks that can achieve superior generalization in the wild while still reliably estimating depth for transparent and mirror surfaces. To do this, they suggest larger datasets containing these objects in diverse environments are needed.3. Developing more robust semantic segmentation networks that can generalize better across datasets. This could ease the burden of collecting pixel-wise semantic annotations and improve the performance when using predicted segmentation masks in their framework.4. Exploring modifications or extensions to their framework itself, such as different strategies for generating the virtual depth labels.In summary, the main suggestions are around scaling up the data, improving the segmentation and depth estimation models themselves, and researching enhancements or alternatives to their proposed pipeline. The overarching goal is developing robust depth estimation for transparent and mirror surfaces in uncontrolled real-world settings.
