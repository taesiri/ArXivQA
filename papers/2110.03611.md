# [Adversarial Retriever-Ranker for dense text retrieval](https://arxiv.org/abs/2110.03611)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research questions/hypotheses appear to be:1) Can jointly training a retriever and ranker model in an adversarial manner improve performance on dense text retrieval tasks compared to training them independently? 2) Can an adversarial training framework help alleviate issues with false negatives that can arise during hard negative sampling when training retrieval models?3) Can incorporating a cross-encoder ranker that models fine-grained query-document interactions lead to accuracy improvements compared to just using a dual-encoder retriever?The key ideas seem to be:- Proposing an adversarial retriever-ranker (AR2) framework that contains a dual-encoder retriever and cross-encoder ranker.- Jointly training these models according to a minimax objective where the retriever tries to retrieve hard negatives to fool the ranker, and the ranker tries to distinguish true positives from the hard negatives.- This adversarial dynamic allows the retriever to receive more robust training signals from the ranker compared to just using sampled negatives.- The cross-encoder ranker can model finer query-document interactions compared to just using a dual-encoder.So in summary, the main hypotheses appear to be around whether adversarial training and incorporating a cross-encoder can improve accuracy for dense retrieval by addressing limitations around hard negative sampling and lack of fine-grained modeling. The experiments aim to validate these hypotheses.
