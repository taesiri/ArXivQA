# [MathScale: Scaling Instruction Tuning for Mathematical Reasoning](https://arxiv.org/abs/2403.02884)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) have shown remarkable capabilities in problem-solving, but their proficiency in solving math problems is still inadequate. This is likely due to the inherent complexity and need for multi-step reasoning in mathematical problem solving.
- Existing math datasets like GSM8K and MATH used for evaluation and instruction tuning are limited in size (around 7.5K examples each).

Proposed Solution - MathScale:  
- Presents MathScale, a simple and scalable method to create high-quality math reasoning data using advanced LLMs like GPT-3.5. 
- Extracts topics and knowledge points from seed math questions to build a concept graph capturing relationships between concepts. This graph is used to generate new question-answer pairs.
- Concept extraction and graph building mirrors cognitive mechanisms in human math learning - concept compression and connection forging.
- Generates a dataset called MathScaleQA with 2 million unique math QA pairs.

Key Contributions:
- Introduces MwpBench, a unified benchmark with 10 diverse datasets covering math word problems from elementary to college level.
- MathScaleQA used to fine-tune LLMs like LLaMA and Mistral results in significantly improved math reasoning capabilities.  
- MathScale-tuned LLaMA-7B achieves over 40% higher performance compared to prior best method and is on par with GPT-3.5-Turbo on the MwpBench benchmark.
- Shows the method has good scalability - performance grows almost logarithmically with data size.
- Demonstrates strong performance on out-of-domain test sets, indicating good generalization.

In summary, the paper presents an effective method to create large-scale high-quality data for tuning LLMs' math reasoning skills, validated through comprehensive evaluations on diverse benchmarks. The presented approach and datasets advance the state-of-the-art in this domain.
