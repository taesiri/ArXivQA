# [DiffClass: Diffusion-Based Class Incremental Learning](https://arxiv.org/abs/2403.05016)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Class incremental learning (CIL) aims to learn new classes sequentially without forgetting past knowledge. Exemplar-free CIL methods synthesize past data instead of using real exemplars. However, significant domain gaps exist between synthetic and real data, causing models to favor plasticity over stability by forgetting past classes when learning new classes. 

Methodology:
This paper proposes a novel exemplar-free CIL method to address the domain gap problem and balance plasticity & stability. The key ideas are:

1. Multi-distribution matching (MDM) diffusion models are finetuned to align distributions between synthetic data across tasks and with real data. This reduces domain gaps and unifies data quality.  

2. Selective synthetic image augmentation (SSIA) expands distribution of current task data using finetuned MDM model, improving plasticity.

3. Reformulate exemplar-free CIL as multi-domain adaptation by adding a domain classifier branch. This implicitly manages domain gaps during training to prevent catastrophic forgetting.

Main Contributions:

- Propose first exemplar-free CIL method that explicitly addresses domain gap problem through MDM diffusion models and SSIA data augmentation.

- Innovative idea to reformulate exemplar-free CIL as task-agnostic multi-domain adaptation to implicitly reduce domain gaps and catastrophic forgetting. 

- Achieve new state-of-the-art performance on CIFAR100 and ImageNet100 benchmarks, significantly outperforming existing exemplar-free CIL methods.

- Extensive experiments demonstrate the effectiveness of each proposed component and show superior stability & plasticity balance.
