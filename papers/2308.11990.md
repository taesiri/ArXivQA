# [RankMixup: Ranking-Based Mixup Training for Network Calibration](https://arxiv.org/abs/2308.11990)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is: How can we improve the confidence calibration of deep neural networks by leveraging ordinal ranking relationships between raw samples and mixup-augmented samples during training?The key hypotheses are:- Networks should give higher confidence predictions for raw samples compared to mixup-augmented samples.- Among multiple mixup-augmented samples, those with larger mixing coefficients (closer to raw samples) should get higher confidence predictions. - Exploiting these ordinal ranking relationships as supervisory signals, instead of just using label mixtures, can improve calibration of network predictions.The authors propose a new mixup-based training framework called RankMixup that implements these ideas through a mixup-based ranking loss (MRL) and M-NDCG loss. The goal is to improve calibration of deep networks by aligning confidence predictions with the expected ranking relationships.


## What is the main contribution of this paper?

This paper presents RankMixup, a novel mixup-based framework for network calibration that alleviates the problem of exploiting label mixtures as supervisory signals. The main contributions are:- Proposes to use ordinal ranking relationships between confidences from raw and augmented samples as supervisory signals instead of label mixtures. This addresses the issue that label mixtures may not accurately represent the distribution of augmented samples. - Introduces two losses - Mixup Ranking Loss (MRL) and M-NDCG loss - to align confidences with the ranking relationships. MRL encourages lower confidences for augmented samples compared to raw ones. M-NDCG aligns orders of confidences and mixup coefficients for multiple augmented samples.- Achieves state-of-the-art calibration performance on CIFAR and Tiny ImageNet datasets compared to other mixup-based methods, demonstrating the effectiveness of using ranking relationships rather than label mixtures.- Shows the approach generalizes well to different network architectures, datasets, and mixup techniques. Also demonstrates improved out-of-distribution detection.In summary, the main contribution is a new mixup-based calibration framework that uses ranking relationships between raw and augmented samples as supervisory signals instead of potentially inaccurate label mixtures to improve calibration performance. The proposed losses effectively implement this idea.
