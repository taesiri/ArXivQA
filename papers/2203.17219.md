# [SimVQA: Exploring Simulated Environments for Visual Question Answering](https://arxiv.org/abs/2203.17219)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

How effective is leveraging synthetic computer-generated data for improving visual question answering (VQA) on real-world images?

The key hypothesis appears to be:

By generating synthetic VQA data using controllable 3D simulation platforms, it is possible to expand the diversity of questions/answers for a VQA model beyond what exists in current real image datasets. This synthetic data can be used to teach the model new skills or question types, which can transfer to improved performance on real images. A technique like feature swapping can help align the synthetic and real data distributions to enable more effective transfer.

In summary, the paper explores using synthetic VQA data to improve performance on real images, along with methods to help transfer between the two domains. The central hypothesis is that synthetic data can expand the diversity of training data and teach new skills to VQA models.
