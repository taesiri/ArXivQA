# [DNeRV: Modeling Inherent Dynamics via Difference Neural Representation   for Videos](https://arxiv.org/abs/2304.06544)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key points of this paper are:

- Existing neural representation (INR) methods for videos do not fully exploit spatiotemporal redundancies. Index-based INRs ignore content-specific spatial features while hybrid INRs ignore contextual dependencies between frames. This leads to poor modeling capability for scenes with large motion or dynamics.

- The authors propose a new video INR method called Difference Neural Representation for Videos (DNeRV) to address these limitations. DNeRV consists of two streams - one for content and one for frame differences. This allows it to model both spatial features and temporal dependencies. 

- DNeRV introduces a collaborative content unit (CCU) for effective fusion of the two streams. The CCU helps capture adjacent dynamics through a gated mechanism.

- Experiments on video compression, inpainting and interpolation show DNeRV achieves competitive compression results and outperforms prior video INRs, especially on dynamic scenes. This demonstrates its effectiveness at video representation.

In summary, the key hypothesis is that modeling both content and temporal differences through a two-stream architecture with effective fusion can improve video INRs, particularly for dynamic scenes. DNeRV is proposed to test this hypothesis.


## What is the main contribution of this paper?

 The main contributions of this paper seem to be:

- Proposing the Difference Neural Representation for Videos (DNeRV) method to model inherent dynamics in videos more effectively. 

- Introducing a diff stream as an auxiliary input that captures frame differences, which helps capture short-term temporal context. This is motivated by analyzing limitations of existing implicit neural video representations.

- Proposing a collaborative content unit (CCU) to fuse features from the content stream and diff stream in an adaptive way. 

- Achieving state-of-the-art results on video interpolation and inpainting tasks compared to other implicit neural representation methods.

- Demonstrating DNeRV's effectiveness on video compression where it is competitive with other neural compression techniques.

In summary, the key contribution is proposing the DNeRV method to model video dynamics better via using a difference stream and adaptive fusion, which leads to improved performance on various video processing tasks compared to prior implicit neural representation techniques for video.
