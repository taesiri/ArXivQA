# ["My Answer is C": First-Token Probabilities Do Not Match Text Answers in   Instruction-Tuned Language Models](https://arxiv.org/abs/2402.14499)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Multiple choice questions (MCQs) are commonly used to evaluate large language models (LLMs). The standard approach is to evaluate based on the model's first token prediction and the log probabilities assigned to answer options.  
- However, recent LLMs tuned to follow instructions have more diverse and natural response styles - they may start with conversational preambles ("Sure") or refuse to answer sensitive questions.
- This makes the reliability of first-token evaluation questionable as it may not match the actual text response.

Proposed Solution:
- Compare first-token evaluation to text output along dimensions of final option choice, refusal rate, choice distribution and robustness to prompt changes. 
- Use six major instruction-tuned LLMs: Llama2-Chat, Mistral-Instruct, Mixtral-Instruct.
- Manually annotate text responses to train classifier for mapping text to options.

Main Contributions:
- First token evaluation is severely misaligned with text output on all dimensions, with over 60% mismatch rates.  
- Refusal is a major contributor to mismatch. Models with safety mechanisms have higher refusal and mismatch rates.
- Text output is more robust to prompt changes than first token.
- Constraint prompts reduce but don't eliminate the mismatch.

Conclusion: 
- First token evaluation alone is unreliable for instruction-tuned models. It is critical to inspect text output as well.
- More direct, realistic evaluation approaches needed to understand model behaviors.
