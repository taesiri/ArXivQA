# [Dynamic-Resolution Model Learning for Object Pile Manipulation](https://arxiv.org/abs/2306.16700)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we learn dynamic and adaptive representations at different levels of abstraction to achieve the optimal trade-off between efficiency and effectiveness for robotic manipulation tasks? Specifically, the paper investigates how to construct dynamic-resolution particle representations of the environment and learn a unified dynamics model using graph neural networks (GNNs) that allows continuous selection of the abstraction level. This allows the agent to adaptively determine the optimal resolution during test time at each model-predictive control (MPC) step.The key hypothesis is that using dynamic scene representations selected online will lead to better performance compared to fixed-resolution representations, as the optimal tradeoff between efficiency and effectiveness may differ depending on the task, environment, and progression through the task.The paper evaluates this through experiments on object pile manipulation tasks, showing that the proposed method of dynamically selecting the scene representation outperforms fixed-resolution baselines.


## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we learn dynamic and adaptive representations at different levels of abstraction to achieve the optimal trade-off between efficiency and effectiveness for robotic manipulation tasks?Specifically, the paper investigates how to learn a unified dynamics model that can express the world at different granularity levels, from which the agent can automatically determine the optimal resolution given the task objective and current observation.The key hypothesis is that using dynamic scene representations at different resolutions will allow for more efficient and effective model-based control compared to using a fixed representation throughout the task.The paper aims to show that:1) There is a trade-off between efficiency and effectiveness when using representations at different abstraction levels.2) Dynamically and adaptively selecting the scene representation leads to better performance than fixed-resolution models. 3) Their proposed method can accomplish challenging real-world object pile manipulation tasks by leveraging this dynamic representation selection.In summary, the central research question is how to achieve optimal efficiency and effectiveness in dynamics model-based control by learning to dynamically select the scene representation. The key hypothesis is that adaptive selection is better than fixed representations.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a framework that can dynamically and adaptively select the scene representation at different levels of abstraction during model predictive control (MPC). Specifically, it introduces a resolution regressor that predicts the optimal representation resolution based on the current observation and task goal. 2. It constructs dynamic-resolution particle representations of the environment and learns a unified dynamics model using graph neural networks (GNNs) that allows continuous selection of the abstraction level. 3. It evaluates the proposed method on three challenging object pile manipulation tasks - gathering, redistributing, and sorting - involving diverse objects like coffee beans, almonds, corn, etc. It shows the benefits of dynamic scene representation selection compared to fixed-resolution baselines.4. It develops a real-world robotic system capable of manipulating and controlling granular object piles. The experiments demonstrate that the method works well not only in simulation but also on a physical robot setup.In summary, the key contribution is the idea of dynamically selecting the representation resolution during MPC planning for better sample efficiency and task performance. This is demonstrated through a unified dynamics model and comprehensive experiments on granular object pile manipulation tasks.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a framework to dynamically determine the optimal abstraction level (resolution) of the scene representation at each model predictive control (MPC) step for object pile manipulation tasks. Specifically, the key contributions are:- Introducing a resolution regressor module that can predict the optimal resolution given the current observation and task goal. The regressor is trained in a self-supervised manner using Bayesian optimization.- Constructing dynamic-resolution particle representations of the environment and learning a unified dynamics model using graph neural networks (GNNs) that supports continuous selection of the abstraction level. - Evaluating the method on three real-world object pile manipulation tasks - gathering, redistributing, and sorting different types of objects. Experiments show the dynamic resolution selection achieves better performance than fixed-resolution baselines.In summary, the main contribution is developing a framework that can dynamically determine the scene representation at different granularity levels based on the task needs, and leveraging this capability to accomplish challenging real-world object manipulation tasks involving piles of granular objects. The key novelty is the ability to adaptively adjust the abstraction level of the representation during task execution.
