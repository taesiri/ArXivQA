# [Combinatorial Stochastic-Greedy Bandit](https://arxiv.org/abs/2312.08057)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel combinatorial stochastic-greedy bandit (SGB) algorithm for combinatorial multi-armed bandit problems with submodular rewards and bandit feedback. Unlike prior greedy algorithms that explore all remaining arms in each iteration, SGB randomly samples an optimized proportion of arms in each greedy round. Theoretical analysis shows that this reduced exploration allows SGB to achieve a $(1-1/e)$-regret bound of $\tilde{\mathcal{O}}(n^{1/3} k^{2/3} T^{2/3})$ for monotone stochastic submodular rewards, improving upon the state-of-the-art by a factor of $k^{1/3}$. Experiments on online influence maximization demonstrate SGB's superior practical performance over baselines, with increasing gains as the cardinality constraint $k$ grows. A key insight is that exploring fewer arms using random subset selection can improve regret bounds and empirical performance by reducing exploration time. The proposed SGB framework provides a promising new approach for efficient exploration in combinatorial bandits.
