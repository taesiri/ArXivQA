# [Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language   Models](https://arxiv.org/abs/2403.16915)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Fine-tuning pre-trained language models (PLMs) for information retrieval (IR) tasks is expensive as it requires learning query representations, query-document relations in addition to downstream task-specific learning. 
- This is because of the gap between the natural language sentences that PLMs are pre-trained on versus the query-document pairs that are the input for IR tasks.
- Queries don't follow natural language grammar. PLMs don't learn suitable query representations. 
- The relation between queries and documents is also not learned in pre-training.

Proposed Solution: 
- Introduce an intermediate stage called "coarse-tuning" between pre-training and fine-tuning to bridge the gap. 
- Coarse-tuning learns query representations using Masked Language Modeling (MLM) and learns query-document relations using a new Query-Document Pair Prediction (QDPP) task.
- Use a large query-log dataset called ORCAS for coarse-tuning to get diverse queries and query-document pairs.

Main Contributions:
- Proposal of coarse-tuning concept and QDPP task to reduce fine-tuning cost for PLM-based IR.
- Experiments show coarse-tuning before fine-tuning improves effectiveness over just fine-tuning in multiple IR datasets. 
- Analysis shows coarse-tuning helps learn better query representations and query-document relations compared to just pre-trained or fine-tuned models.

In summary, the paper introduces a novel coarse-tuning stage to bridge the gap between pre-training and fine-tuning PLMs for IR tasks, thereby reducing fine-tuning cost and improving performance.
