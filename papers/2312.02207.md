# [TranSegPGD: Improving Transferability of Adversarial Examples on   Semantic Segmentation](https://arxiv.org/abs/2312.02207)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Transferability of adversarial examples on image classification has been well studied, but their transferability on semantic segmentation is overlooked. 
- Existing attack methods for segmentation focus on fooling the source model but have poor transferability to other models.

Proposed Solution:
- A two-stage attack strategy called TranSegPGD to improve transferability of adversarial examples for segmentation.

First Stage: 
- Pixels divided into correctly classified (P_T) and misclassified (P_F) groups.
- Loss function assigns higher weight to misclassified pixels to ensure all pixels are fooled.

Second Stage:
- Compute KL divergence between each adversarial pixel and original pixel.
- Pixels divided into high transferability (P_H) and low transferability (P_L) groups based on KL divergence.
- Loss function assigns higher weight to high transferability pixels to improve transferability.

Main Contributions:
- A two-stage attack strategy specifically designed to improve transferability for segmentation. 
- The first stage focuses on misleading all pixels and the second stage focuses on improving transferability.
- Experiments across datasets and models demonstrate state-of-the-art performance in transferability compared to prior arts.
- Can combine with existing transferable attacks like MI-FGSM to further boost their transferability.

In summary, this paper identifies and addresses the problem of poor transferability of adversarial examples in segmentation through a dedicated two-stage attack strategy. Extensive experiments validate its effectiveness over prior arts in improving transferability.
