# [NIFF: Alleviating Forgetting in Generalized Few-Shot Object Detection   via Neural Instance Feature Forging](https://arxiv.org/abs/2303.04958)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How can we alleviate catastrophic forgetting of base classes in generalized few-shot object detection without requiring access to the base data during finetuning on novel classes, in order to respect privacy restrictions and reduce memory requirements?

The key hypothesis is that a standalone, lightweight generator network can be trained to generate diverse instance-level features for base classes that mimic the statistics of features from a pretrained base model. By replaying these "forged" features during finetuning, knowledge of base classes can be retained without needing to store and reuse the actual base data.

In summary, the paper proposes a data-free knowledge distillation approach called NIFF that uses a feature generator to alleviate catastrophic forgetting in generalized few-shot object detection, with the goals of reducing memory footprint and respecting privacy constraints.
