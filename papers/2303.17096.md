# [ImageNet-E: Benchmarking Neural Network Robustness via Attribute Editing](https://arxiv.org/abs/2303.17096)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is that evaluating robustness of image classifiers on object attributes like background, size, position, and direction can provide new insights into model accuracy and robustness. Specifically, the authors hypothesize that:- Evaluating model performance on edited images that change object attributes can reveal vulnerabilities and facilitate debugging. This is in contrast to existing robustness benchmarks that focus on out-of-distribution corruptions.- Models that achieve high accuracy on ImageNet are still sensitive to small changes in object attributes like background complexity, size, position, and direction.- Improving robustness against these attribute changes may require different techniques compared to improving robustness against common corruptions or adversarial examples.To test these hypotheses, the authors introduce a new benchmark dataset called ImageNet-E that contains images with edited object attributes. They then evaluate various state-of-the-art models on this benchmark and analyze their sensitivity to different attribute changes. The results reveal interesting vulnerabilities and opportunities for improving robustness through architecture designs, training strategies, and preprocessing.In summary, the central hypothesis is that object attributes represent a new dimension for evaluating and improving model robustness complementary to existing benchmarks. ImageNet-E is proposed to facilitate research in this direction.
