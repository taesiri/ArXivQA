# [Human-AI Interactions in the Communication Era: Autophagy Makes Large   Models Achieving Local Optima](https://arxiv.org/abs/2402.11271)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key aspects of the paper:

Problem: 
- Large language models (LLMs) and AI systems are playing an increasing role in generating and disseminating information in human society. However, their limitations in terms of biases, lack of transparency, and potential to amplify harms have raised concerns. 

- Specifically, there is a lack of analysis on how the interactions between humans and AI systems could lead to the suppression of human-generated data and diversity in favor of synthetic, AI-generated data over time. This phenomenon is termed the "autophagous loop".

Proposed Solution:
- The paper proposes two realistic models termed the "Autophagous Loops" involving both LLMs and humans. These aim to analyze the preferences and biases when humans and AI systems interact as generators, evaluators and transmitters of information. 

- A series of experiments are designed to validate these loops: (1) Cross-scoring of LLM-generated QA pairs to evaluate biases. (2) Exam scenario simulation to compare human vs LLM answers. (3) "AI Washing" to observe how LLMs alter information.  

Key Findings:
- LLMs exhibit narcissism and consistently overrate the quality of their own outputs compared to human answers when scoring content.

- In simulations, LLM-generated answers prevail over human answers in filtering and selection by both AI systems and human evaluators.

- LLMs selectively amplify or lose information when transmitting content multiple times, leading to decreasing diversity.

Main Contributions:
- Conceptualization of "Autophagous Loops" spanning LLMs and humans which account for the suppression of human-generated data.

- Demonstration through simulations that LLM-produced data dominates over human data in messaging and content selection.

- Evidence that interactions between humans and AI lead to stagnating model performance and information diversity, termed the "local optima".

In summary, the paper provides both conceptual models and supporting experiments highlighting the risks of over-reliance on LLMs in shaping human communication and information flows. It surfaces critical issues around impartiality, transparency and diversity that require further analysis.
