# [Explaining Reinforcement Learning Agents Through Counterfactual Action   Outcomes](https://arxiv.org/abs/2312.11118)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Explaining the behavior of reinforcement learning (RL) agents is challenging, yet important for establishing appropriate trust and collaboration. Prior work on explainable RL has focused on local explanations that describe an agent's reasoning for a specific decision. However, these typically do not show the outcomes of the agent's actions. 

Proposed Solution: This paper introduces "COViz", a new local explanation method that visually compares the actual trajectory of an RL agent to a counterfactual trajectory showing what would have happened if the agent took an alternative action. Specifically, at each step COViz shows side-by-side videos depicting the outcomes of the agent's chosen action versus its second best action. This highlights the tradeoffs between actions. The paper also proposes augmenting global explanation methods like policy summaries with COViz to select states based on action outcomes.  

Additionally, the paper integrates COViz with reward decomposition, another local explanation showing the expected rewards for different actions. Together these complement each other by answering "what if?" and "why?" questions about the agent's behavior.

Contributions:
(1) Introduces COViz, a new local explanation method based on counterfactual outcomes
(2) Proposes augmenting global explanations by selecting states based on COViz
(3) Integrates COViz with reward decomposition 
(4) Conducts user studies showing COViz helps understanding on its own, and integrating it with reward decomposition significantly improves understanding compared to each method separately

The user studies found that while the integrated explanations led to the best task performance in assessing agent preferences, participants subjectively preferred seeing only one explanation type to avoid cognitive overload. Overall, the paper demonstrates the value of COViz and of combining complementary local explanation methods.
