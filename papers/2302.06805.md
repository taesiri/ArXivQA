# [Learning with Noisy labels via Self-supervised Adversarial Noisy Masking](https://arxiv.org/abs/2302.06805)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to improve the robustness and generalization ability of deep neural networks when trained on datasets with noisy labels. Specifically, the authors aim to propose a new method to regularize deep models to prevent overfitting to noisy labels in the training data.

The key hypothesis is that models trained on noisy labeled data tend to produce distinguishable activation patterns on the feature maps compared to models trained on clean data. The authors hypothesize that explicitly regularizing the activation maps can alleviate overfitting to noisy labels.

Based on this hypothesis, the authors propose a novel self-supervised adversarial noisy masking (SANM) method. The key ideas are:

- Use a label quality guided masking scheme to adaptively mask input images and modify the noisy labels simultaneously. This aims to prevent overfitting to noisy samples.

- Introduce an auxiliary self-supervised task of reconstructing the original input from the masked input's features. This provides additional supervision from noise-free signals.

- Evaluate SANM on both synthetic noisy datasets (CIFAR-10, CIFAR-100) and real-world noisy datasets (Clothing1M, Animal-10N).

The central hypothesis is that the proposed method will outperform previous state-of-the-art methods for learning with noisy labels by explicitly regularizing activation maps in a noise-aware way and utilizing self-supervision. The experimental results generally validate this hypothesis and research question.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel self-supervised adversarial noisy masking (SANM) method for learning with noisy labels (LNL). The key ideas are:

- It proposes an adversarial noisy masking scheme to explicitly impose regularization on the features and prevent models from overfitting noisy samples. The masking is guided by estimated label quality to adaptively modify inputs and noisy labels for clean and noisy samples. 

- It designs a self-supervised auxiliary task of reconstructing original images from masked image features. This provides additional supervision from reconstruction and enhances model generalization.

- The method is flexible and can be integrated with existing LNL frameworks to further boost their performance.

- It achieves state-of-the-art results on both synthetic and real-world noisy image classification benchmarks. 

In summary, the main contribution is proposing the SANM method with adaptive noisy masking regularization and self-supervised reconstruction to enhance robustness and generalization for learning with noisy labels. The results demonstrate its effectiveness and flexibility.
