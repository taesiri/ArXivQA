# [Learning with Noisy labels via Self-supervised Adversarial Noisy Masking](https://arxiv.org/abs/2302.06805)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to improve the robustness and generalization ability of deep neural networks when trained on datasets with noisy labels. Specifically, the authors aim to propose a new method to regularize deep models to prevent overfitting to noisy labels in the training data.

The key hypothesis is that models trained on noisy labeled data tend to produce distinguishable activation patterns on the feature maps compared to models trained on clean data. The authors hypothesize that explicitly regularizing the activation maps can alleviate overfitting to noisy labels.

Based on this hypothesis, the authors propose a novel self-supervised adversarial noisy masking (SANM) method. The key ideas are:

- Use a label quality guided masking scheme to adaptively mask input images and modify the noisy labels simultaneously. This aims to prevent overfitting to noisy samples.

- Introduce an auxiliary self-supervised task of reconstructing the original input from the masked input's features. This provides additional supervision from noise-free signals.

- Evaluate SANM on both synthetic noisy datasets (CIFAR-10, CIFAR-100) and real-world noisy datasets (Clothing1M, Animal-10N).

The central hypothesis is that the proposed method will outperform previous state-of-the-art methods for learning with noisy labels by explicitly regularizing activation maps in a noise-aware way and utilizing self-supervision. The experimental results generally validate this hypothesis and research question.
