# [Multi-Agent MDP Homomorphic Networks](https://arxiv.org/abs/2110.04495v2)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How can we design distributed policy networks for cooperative multi-agent reinforcement learning that are equivariant to global symmetries of the full multi-agent system, while still allowing for distributed execution?

The key points are:

- Existing work on equivariant reinforcement learning relies on global symmetries in the full state-action space, which requires centralized execution. 

- The authors want to enforce equivariance to global symmetries in cooperative multi-agent systems while still allowing for distributed execution with local communication.

- They propose a novel factorization of global symmetries into local agent-level symmetries to achieve this.

- Their main contribution is introducing "Multi-Agent MDP Homomorphic Networks", distributed policy networks that are globally equivariant by factorizing symmetries over individual agents and their local interactions.

In summary, the central hypothesis is that by factorizing global symmetries into local agent-level symmetries, they can design distributed multi-agent policy networks that are equivariant to global symmetries while still allowing decentralized execution. The paper explores this hypothesis and introduces the proposed architecture.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution seems to be proposing Multi-Agent MDP Homomorphic Networks, which are a class of distributed policy networks for cooperative multi-agent reinforcement learning. The key ideas are:

- Decomposing global symmetries in the joint state-action space of cooperative multi-agent systems into local transformations on agent observations and interactions. This allows enforcing global equivariance constraints in a distributed manner.

- Introducing a factorization that distributes the computation that enforces global symmetries over local agents and local interactions. 

- Proposing a specific multi-agent equivariant policy network architecture based on message passing that enforces the distributed symmetry factorization. The network uses equivariant encoding and messaging functions to share information between equivalent states under symmetry transformations.

- Empirically evaluating the proposed networks on symmetric multi-agent problems and showing they improve data efficiency compared to non-equivariant baselines.

In summary, the main contribution seems to be presenting an approach to make multi-agent reinforcement learning policies equivariant to global symmetries in a way that allows distributed execution with only local communication between agents. This is done by factorizing global symmetries into local transformations and using equivariant message passing networks.
