# [Unsupervised Document Expansion for Information Retrieval with   Stochastic Text Generation](https://arxiv.org/abs/2105.00666)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be:How can we expand document representations for information retrieval in an unsupervised manner to mitigate the vocabulary mismatch problem? The key hypothesis appears to be:By stochastically generating multiple sentences that are relevant to a document using a pre-trained language model, and augmenting the original document with these generated sentences, the document representation can be enriched to improve retrieval performance without requiring supervised query-document pairs for training.In summary, the central research question is how to do unsupervised document expansion to address vocabulary mismatch in IR, and the main hypothesis is that generating multiple relevant sentences stochastically with a pre-trained LM can achieve this effectively. The authors propose the UDEG framework to test this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Proposing a novel unsupervised document expansion framework called UDEG (Unsupervised Document Expansion with Generation) that generates additional sentences to augment documents and enrich their representations, without needing query-document training pairs. 2. Using a pre-trained language model within UDEG to generate relevant sentences for a given document. The sentences are generated stochastically via Monte Carlo dropout to create diverse outputs.3. Demonstrating that UDEG achieves state-of-the-art performance on two standard IR benchmark datasets (ANTIQUE and MS MARCO) across various evaluation metrics, outperforming relevant query and document expansion baselines.4. Providing analysis showing UDEG's stochastic generation scheme significantly improves performance compared to deterministic generation, and that the framework does not depend on a specific language model. 5. Conducting a case study indicating UDEG's generated sentences contain novel yet relevant terms that help with term re-weighting and alleviating vocabulary mismatch issues in ad-hoc retrieval.In summary, the main contribution appears to be proposing and validating a novel unsupervised document expansion framework called UDEG that can improve IR system performance by generating diverse relevant text to augment document representations, without needing query-document training data.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a novel unsupervised document expansion framework called UDEG that generates diverse supplementary sentences for a document using a pre-trained language model with stochastic perturbation, in order to enrich document representation and improve information retrieval performance without needing query-document training pairs.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in the field of document expansion for information retrieval:- The main contribution is proposing an unsupervised document expansion framework (UDEG) that generates additional sentences to augment documents, without needing query-document training data. This makes it more flexible than prior supervised approaches for document expansion.- The idea of using abstractive text generation with a pre-trained language model (PEGASUS) allows generating novel words beyond just extracting keywords, which helps with the vocabulary mismatch problem. This goes beyond prior extractive techniques like LexRank.- Stochastically generating multiple sentences with Monte Carlo dropout is a novel way to create diverse expansions. This differs from prior work that may generate only a single static expansion. - Comprehensive experiments on two IR benchmarks (ANTIQUE and MS MARCO datasets) demonstrate sizable improvements over various baselines. The gains are consistent across different retrieval models and evaluation metrics. This provides strong empirical evidence for the benefits of the UDEG framework.- The analysis offers insights into which model design choices contribute to improved performance, such as abstractive over extractive generation, and stochastic generation for diversity. The case studies also illustrate how UDEG helps with term re-weighting and vocabulary mismatch issues.- The approach does not seem to require re-training or fine-tuning the language model, making it easy to apply. The framework also appears model-agnostic, given the comparable results with PEGASUS vs BART.Overall, this paper introduces a novel unsupervised document expansion technique using pre-trained language models and stochastic generation. The comprehensive experiments and analyses provide convincing evidence of its effectiveness for information retrieval. The ideas seem generalizable and offer a practical way to improve IR systems without needing query-document training data.
