# [Common (good) practices measuring trust in HRI](https://arxiv.org/abs/2311.12182)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper discusses current methods for measuring trust in human-robot interaction (HRI) and highlights some limitations and opportunities for improvement. The authors note that subjective questionnaires and objective behavioral measures are commonly used to quantify trust, but even together these cannot fully account for all the factors influencing trust. They suggest incorporating more direct questions about trustworthiness and conscious reasoning. Additionally, they propose complementing existing measures by assessing the impacts of repeated long-term interactions, imperfect interactions, subconscious interpretations, conformity to social norms, and physical surroundings. To cover the multitude of factors affecting trust, the authors identify five key aspects to focus on measuring in HRI trust research: human-related factors, robot-related factors, task-related factors, environment-related factors, and factors related to other agents present. More comprehensive measurement across these areas could lead to better calibration of appropriate trust levels in HRI. The authors conclude that trust is fundamental for human acceptance of robots, but current measures are still insufficient, so investigating these five factors could help advance HRI trust research.


## Summarize the paper in one sentence.

 This paper discusses common practices and opportunities for improving the measurement of trust in human-robot interaction across various factors related to the human, robot, task, environment, and other agents.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is:

The paper suggests investigating five key factors that affect trust in human-robot interaction: (1) human-related factors, (2) robot-related factors, (3) task-related factors, (4) environment-related factors, and (5) other agent-related factors. The authors argue that considering these five aspects can help develop more comprehensive measures to evaluate the extent to which people trust robots in a given situation, and to calibrate that trust to have more successful human-robot interactions. Specifically, the paper calls for more research focused on these key factors to complement existing trust measurement methods and account for common side effects that influence trust in human-robot interaction.

In essence, the main contribution is identifying these five key factors as an avenue for developing more holistic and reliable methods for measuring and understanding trust in human-robot interaction. The authors present this framework of factors as a way to advance research on trust in HRI beyond current methods which may have limitations.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key keywords and terms associated with this paper include:

- Trust - The paper focuses on measuring and understanding trust between humans and robots in human-robot interaction (HRI).

- Human-robot interaction (HRI) - The research field that studies interactions between humans and robots.

- Measuring trust - The paper discusses different methods for quantitatively and qualitatively measuring trust in HRI contexts.

- Questionnaires - Subjective questionnaire scales are a common method used to measure different aspects of trust.  

- Compliance - Using a human's compliance with a robot's suggestions as an objective indicator of trust.    

- Environments - The paper suggests the environment (e.g. public vs. private) can impact trust in HRI.

- Novelty effect - The paper discusses accounting for the novelty effect of a robot on trust measures. 

- Long-term interactions - Studying repeated/long-term HRI and impacts on trust.

- Conscious vs. subconscious trust - The paper suggests incorporating measures of both conscious assessments and subconscious exhibitions of trust.

- Key factors - The paper proposes 5 key factors that influence trust in HRI: human, robot, task, environment, other agents.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes looking into 5 key aspects (human, robot, task, environment, other agents) that affect trust in human-robot interaction. Why are these 5 aspects critical for developing future measures of trust compared to existing methods? What theoretical basis supports focusing on these specific aspects?

2. How exactly would you suggest measuring the proposed aspects quantitatively and qualitatively? What specific metrics or questionnaires could capture the nuances of each aspect in terms of how they influence trust? 

3. The authors suggest incorporating more direct questions about a robot's trustworthiness into experiments. What are some examples of direct questions that could provide insights into the conscious, rather than just subconscious, mechanisms of trust in human-robot interaction?

4. What are some ways the novelty effect specifically could be measured and accounted for in longitudinal human-robot trust experiments? What metrics over time might indicate changes in trust due to novelty wearing off?  

5. For the "imperfect interaction" aspect, how can we effectively measure the impact of small errors or limitations of robots on trust, as opposed to catastrophic failures? What scale of "imperfection" should be examined?

6. How might we quantitatively estimate the gap between people's objective behaviors towards robots and their subjective, self-reported levels of trust? What explains this discrepancy?

7. The environment aspect aims to account for contextual differences in trust. But what objective metrics could determine if an environment truly enables or hinders trust in measurable ways? 

8. How specifically are social norms defined and incorporated when evaluating a robot's behavior and its impact on trust? Whose norms are being assumed - the participants, the researchers, society's?

9. For the "other agents" aspect, what research approaches could effectively isolate the impact of additional actors (pets, children etc) on human-robot trust measurements?

10. How might these expanded aspects of trust be validated against real-world criteria? Does improving laboratory measures translate to more adoption/effectiveness of robots "in the wild"?
