# [NDDepth: Normal-Distance Assisted Monocular Depth Estimation](https://arxiv.org/abs/2309.10592)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key points about the research question and contributions of this paper are:

- The paper proposes a new physics (geometry)-driven deep learning framework for monocular depth estimation. The key assumption is that real-world 3D scenes are constituted by piece-wise planes. 

- The main research question is how to effectively leverage the planar prior and convert it to improved depth estimation, which is an ill-posed problem from a single image.

- The main contributions are:

1) Proposing a normal-distance head to predict pixel-level surface normal and plane-to-origin distance, which are used to derive depth based on geometry constraints.

2) Introducing a plane-aware consistency constraint to regularize the normal and distance predictions to be piece-wise constant.

3) Integrating an additional depth head and using a contrastive iterative refinement module to refine the depth maps from the two heads in a complementary manner.

4) Demonstrating state-of-the-art performance on NYU-Depth-v2, KITTI, and SUN RGB-D datasets. The method ranks 1st on KITTI benchmark at submission time.

In summary, the key research question is how to effectively incorporate geometric planar priors into deep networks for improved monocular depth estimation, which is addressed through the proposed physics-driven framework. The main contributions are the specific techniques to leverage planar assumptions.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel physics (geometry)-driven deep learning framework for monocular depth estimation. Specifically, the key contributions are:

1. They propose a new normal-distance head to predict pixel-level surface normal and plane-to-origin distance for deriving depth, along with a plane-aware consistency constraint to regularize them.

2. They integrate an additional depth head designed with regular paradigms to improve the robustness and handle failure cases of the normal-distance head. 

3. They develop an effective contrastive iterative refinement module to refine depth from the two heads in a complementary manner based on the estimated depth uncertainty.

4. Extensive experiments show their method exceeds previous state-of-the-art methods on the NYU-Depth-v2, KITTI and SUN RGB-D datasets. It achieves the 1st place on KITTI benchmark at submission time.

In summary, the main contribution is proposing a novel physics-driven deep learning framework containing the normal-distance head, plane-aware consistency, depth head and contrastive iterative refinement module for accurate and robust monocular depth estimation. The method outperforms previous state-of-the-art approaches on major indoor and outdoor datasets.
