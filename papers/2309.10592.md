# [NDDepth: Normal-Distance Assisted Monocular Depth Estimation](https://arxiv.org/abs/2309.10592)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key points about the research question and contributions of this paper are:

- The paper proposes a new physics (geometry)-driven deep learning framework for monocular depth estimation. The key assumption is that real-world 3D scenes are constituted by piece-wise planes. 

- The main research question is how to effectively leverage the planar prior and convert it to improved depth estimation, which is an ill-posed problem from a single image.

- The main contributions are:

1) Proposing a normal-distance head to predict pixel-level surface normal and plane-to-origin distance, which are used to derive depth based on geometry constraints.

2) Introducing a plane-aware consistency constraint to regularize the normal and distance predictions to be piece-wise constant.

3) Integrating an additional depth head and using a contrastive iterative refinement module to refine the depth maps from the two heads in a complementary manner.

4) Demonstrating state-of-the-art performance on NYU-Depth-v2, KITTI, and SUN RGB-D datasets. The method ranks 1st on KITTI benchmark at submission time.

In summary, the key research question is how to effectively incorporate geometric planar priors into deep networks for improved monocular depth estimation, which is addressed through the proposed physics-driven framework. The main contributions are the specific techniques to leverage planar assumptions.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel physics (geometry)-driven deep learning framework for monocular depth estimation. Specifically, the key contributions are:

1. They propose a new normal-distance head to predict pixel-level surface normal and plane-to-origin distance for deriving depth, along with a plane-aware consistency constraint to regularize them.

2. They integrate an additional depth head designed with regular paradigms to improve the robustness and handle failure cases of the normal-distance head. 

3. They develop an effective contrastive iterative refinement module to refine depth from the two heads in a complementary manner based on the estimated depth uncertainty.

4. Extensive experiments show their method exceeds previous state-of-the-art methods on the NYU-Depth-v2, KITTI and SUN RGB-D datasets. It achieves the 1st place on KITTI benchmark at submission time.

In summary, the main contribution is proposing a novel physics-driven deep learning framework containing the normal-distance head, plane-aware consistency, depth head and contrastive iterative refinement module for accurate and robust monocular depth estimation. The method outperforms previous state-of-the-art approaches on major indoor and outdoor datasets.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a physics-driven deep learning framework for monocular depth estimation that contains a normal-distance head and a depth head, leverages planar information in scenes through a plane-aware consistency constraint, and refines depth predictions iteratively using a contrastive refinement module.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this paper compares to other research in monocular depth estimation:

- The key novelty is in using a physics/geometry-driven approach by predicting surface normal and plane-to-origin distance and enforcing geometric consistency constraints. This is different from most prior work which uses data-driven deep learning models to directly regress depth values. 

- The use of surface normal and plane priors has been explored before in depth estimation, but this paper proposes a more explicit parameterization and consistency constraints. For example, Patil et al. used plane coefficients and offset vectors rather than normal/distance. 

- Using complementary cues (normal/distance and direct depth prediction) is unique and shows strength over using either one alone. The iterative refinement module is also novel for fusing the two predictions.

- The performance exceeds state-of-the-art on major indoor and outdoor datasets like NYUv2 and KITTI. The KITTI leaderboard rank demonstrates its strength.

- The ablation studies validate the contributions of the key components like the normal/distance prediction, consistency loss, and refinement module.

- The approach seems to generalize well even in a zero-shot setting as evidenced by the SUN RGB-D experiments. This demonstrates that it relies less on dataset-specific bias.

In summary, the physics-based modeling and constraints, dual prediction heads, and refinement are the key differentiators from prior work. The strong results validate that these ideas are effective for improving monocular depth estimation, especially for robustness and generalization. The novel modeling and training paradigm could inspire more incorporation of geometrical cues in future deep learning approaches.
