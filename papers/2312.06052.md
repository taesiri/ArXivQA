# [MaskConver: Revisiting Pure Convolution Model for Panoptic Segmentation](https://arxiv.org/abs/2312.06052)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes MaskConver, a novel convolutional neural network architecture for panoptic segmentation. Unlike previous convolution-based methods, MaskConver unifies the representation for things and stuff by modeling both using center points. It introduces a ConvNeXt-UNet pixel decoder to provide global context, lightweight prediction heads, and a mask embedding generator module that handles potential center point collisions between neighboring instances. Experiments on COCO show MaskConver outperforms prior convolution-based methods by a large margin (+9.3% PQ vs Panoptic FCN) and even surpasses recent transformer-based models like Mask2Former (+1.7% PQ) and kMaX-DeepLab (+0.6% PQ), demonstrating the strength of convolutions for this task. An efficient version built on MobileNet also achieves a new state-of-the-art PQ tradeoff under latency constraints. Key innovations include the unified center-based formulation, class embeddings to resolve center collisions, and the asymmetrical ConvNeXt-UNet decoder. MaskConver closes the gap between convolution- and transformer-based panoptic segmentation models, proving the continued competitiveness of CNNs.
