# [Null-text Inversion for Editing Real Images using Guided Diffusion   Models](https://arxiv.org/abs/2211.09794)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to accurately invert real images into the latent space of text-guided diffusion models in order to enable intuitive text-based editing of the images. Specifically, the paper introduces two key components to achieve this:

1. Pivotal inversion for diffusion models: Rather than mapping all possible noise vectors to a single image like previous works, the paper proposes using a single pivotal noise vector computed by an initial DDIM inversion as an anchor point for more efficient optimization. 

2. Null-text optimization: The paper recognizes that directly optimizing the text embedding can damage editability. Instead, it proposes optimizing only the unconditional "null" text embedding used in classifier-free guidance. This allows accurately reconstructing the image while keeping the text embedding and model weights fixed, preserving editability.

By combining these two techniques - using pivotal inversion for efficiency and optimizing the null text to avoid damaging editability - the paper demonstrates high-fidelity inversion and editing of real images using the publicly available Stable Diffusion model. The central hypothesis is that this null-text inversion approach will enable intuitive text-based editing of real images with pre-trained diffusion models.

In summary, the key research question is how to accurately invert real images into diffusion models to enable text-based editing, with the core ideas being pivotal inversion and null-text optimization. The paper aims to demonstrate this can be achieved without destructive model fine-tuning or embedding optimization as in prior works.


## What is the main contribution of this paper?

 The main contribution of this paper is developing an effective technique for inverting real images into the latent space of text-guided diffusion models. Specifically, the paper introduces two key novel components:

1. Pivotal inversion for diffusion models. Rather than mapping random noise samples to a single input image, the method uses a single pivotal noise vector for each timestamp and optimizes around it. This is more efficient and provides a good starting point. 

2. Null-text optimization, where only the unconditional text embedding used for classifier-free guidance is optimized, rather than the input text embedding. This allows reconstruction while keeping the model weights and conditional embedding intact, enabling text-based editing like Prompt-to-Prompt without tuning the model.

By combining these two techniques, the paper demonstrates high-fidelity inversion and editing of real images using the publicly available Stable Diffusion model. The proposed null-text inversion enables applying intuitive text-based image editing approaches like Prompt-to-Prompt on real images for the first time. The method does not require tuning the model weights for each image.

In summary, the main contribution is developing an effective real image inversion technique for text-guided diffusion models using pivotal inversion and null-text optimization. This facilitates intuitive text-based editing of real images while avoiding cumbersome model tuning per image.
