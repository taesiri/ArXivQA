# Can Retriever-Augmented Language Models Reason? The Blame Game Between   the Retriever and the Language Model

## What is the central research question or hypothesis that this paper addresses?

Based on my review, the central research questions addressed in this paper are:1) Can retriever-augmented language models perform multi-step reasoning given supporting statements? 2) What are some shortcomings of retrievers which undermine reasoning performance?3) What are some shortcomings of language models which undermine reasoning performance?4) What is the impact of model size?5) What is the impact of using multihop retrieval?The overall hypothesis seems to be that retriever-augmented language models still face limitations in reasoning abilities due to shortcomings in both the retriever module and the language model itself. The authors systematically analyze these limitations through experiments on language modeling and question answering tasks.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper appear to be:- Provides a systematic analysis of the reasoning capabilities and limitations of retriever-augmented language models onquestion answering and language modeling tasks. - Evaluates several popular retriever-augmented models (REALM, kNN-LM, FiD+DPR, ATLAS+Contriever, Flan-T5+Contriever) on reasoning tasks using controlled datasets based on EntailmentBank and StrategyQA.- Identifies key shortcomings stemming from both the retriever module and the language model in performing multi-step reasoning. Shows that retrievers select statements based on similarity rather than reasoning ability, while language models struggle to combine statements even when given relevant facts.- Demonstrates the impact of model scale and multi-hop retrieval, with larger models like Flan-T5 showing better reasoning ability but still ample room for improvement.- Provides insights into opportunities for better integrating retrieval with reasoning in future work, through improvements to the retriever's ability to select relevant facts and the language model's ability to reason over statements.In summary, the paper provides a thorough analysis of limitations of current retriever-augmented models in reasoning tasks, using controlled evaluation to pinpoint issues with the retriever versus the language model. It sheds light on challenges and opportunities in developing more robust reasoning abilities in these models.
