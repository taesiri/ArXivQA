# [Machine Unlearning by Suppressing Sample Contribution](https://arxiv.org/abs/2402.15109)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Machine unlearning (MU) aims to remove selected training data's information from a trained model, which is important for data privacy rights. 
- Existing MU methods have limitations such as high computational overhead, performance drop on remaining data, or reliance on remaining data.

Key Idea:
- Training data contributes to the model while unseen data does not. This manifests in the model's sensitivity to input changes.  
- A sample's contribution enlarges the gap between its target class's input sensitivity versus other classes.
- Thus, suppressing this relative sensitivity magnitude can withdraw a sample's contribution.

Proposed Method (MU-Mis):
- Formulates a loss to minimize the relative magnitude between target class sensitivity and other classes' sensitivity for forgetting data.
- Only requires forward and backward pass on forgetting data during unlearning.

Main Contributions:
- Connects sample contribution to input sensitivity conceptually and theoretically.
- Reveals how contribution practically manifests in input sensitivity change trends empirically.  
- Proposes MU-Mis algorithm to minimize relative sensitivity magnitude for unlearning.
- Achieves state-of-the-art performance on multiple unlearning tasks without needing remaining data.

In summary, this paper provides a new perspective on relating sample contribution to input sensitivity, and leverages this idea to design an efficient unlearning approach called MU-Mis that suppresses sample contributions by minimizing the relative magnitudes of input sensitivities.
