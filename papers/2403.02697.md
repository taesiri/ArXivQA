# [Noise misleads rotation invariant algorithms on sparse targets](https://arxiv.org/abs/2403.02697)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Rotation invariant algorithms like gradient descent trained neural networks with fully-connected input layers are known to be suboptimal for learning sparse linear problems when the number of examples is less than the input dimension. However, it is unclear if they remain inefficient when the number of examples exceeds the input dimension in the noisy setting. 

- This paper studies if rotation invariance is still a handicap for learning noisy sparse linear problems in the overconstrained setting where there are more examples than input dimensions.

Key Contributions:
- Proves a lower bound on the Bayes optimal error for any rotation invariant algorithm on a sparse noisy linear regression problem with the number of examples exceeding the input dimension. 

- Shows this lower bound is easily beaten by simple non-rotation invariant algorithms like multiplicative updates, gradient descent on a "spindly" two layer linear network, and a novel "priming" method.

- Derives closed-form solutions for the continuous time weight trajectories of algorithms like EGU, EGUÂ±, primed GD and Adagrad. Shows how the trajectories of invariant and non-invariant algorithms geometrically differ in their ability to exploit sparsity.

- Visualizes the trajectories and loss curves of different algorithms, demonstrating the performance gap arising from rotation invariance. Adaptive methods like Adagrad strangely display an opposite bias away from sparse solutions.

- Verifies experimentally that standard rotationally invariant models cannot exploit asymmetries in real datasets to ignore noisy features, unlike non-invariant models.

Key Implications:
- Rotation invariance remains a critical handicap for learning noisy sparse linear regression even in the overconstrained setting, unlike the noise-free case.

- There is value in using non-invariant updates like multiplicative rules, spindly networks and priming for sparse problems, instead of reliance on invariant GD-trained neural networks.

- The trajectory analysis provides insight into algorithmic inductive biases and can guide design of algorithms suited for sparse environments.
