# [Learning Neural Causal Models with Active Interventions](https://arxiv.org/abs/2109.02429)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key points of this paper are:- The paper proposes a method for learning causal models with neural networks from a combination of observational and interventional data. - The main research question is how to actively and adaptively select the best interventions to perform in order to efficiently learn the underlying causal structure.- The paper introduces an "Active Intervention Targeting" (AIT) method to select the most informative interventions during the learning process. - AIT computes a score for each possible intervention target indicating how informative intervening on that target would be. It then selects the target with the highest score to intervene on next.- The score is based on measuring the discrepancy between hypothetical post-intervention samples drawn from different candidate causal graphs. High discrepancy suggests high uncertainty about the relationships around that target.- AIT can be integrated into neural network frameworks for causal discovery like SDI and DCDI to guide the interventional experiments.- Through experiments on synthetic and real-world datasets, AIT is shown to improve sample efficiency and identification of the true causal graph compared to random intervention selection.In summary, the key hypothesis is that actively targeting interventions using a discrepancy-based score will enable more efficient learning of neural network causal models from interventional data. The paper provides empirical validation of this hypothesis.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:- It proposes an active intervention targeting (AIT) method to enable quick identification of the underlying causal structure from observational and interventional data. - AIT computes a score for each possible intervention target to select the most informative target. The score captures the discrepancy between hypothetical post-interventional distributions generated under different candidate causal graph structures.- The paper introduces a two-phase DAG sampling technique to efficiently generate hypothesis DAGs from a structural belief parameterized as a soft adjacency matrix.- It demonstrates how AIT can be integrated into recent differentiable causal discovery frameworks like SDI and DCDI to guide the exploration using interventional data.- Through extensive experiments on simulated and real-world datasets, the paper shows that AIT leads to superior performance over random intervention targeting across different frameworks. AIT reduces the required number of interventions, improves sample efficiency, convergence speed, and robustness to noise.In summary, the key contribution is an active intervention targeting method that enables more efficient causal structure discovery by adaptively selecting the most informative interventions based on the current state of a learned neural causal model.


## How does this paper compare to other research in the same field?

This paper proposes a new method for learning causal models with neural networks using active interventions. Here is a brief comparison to other related work:- Most prior work on neural network-based causal discovery has focused on learning from observational data or data with fixed/random interventions. This paper introduces an adaptive intervention design technique called Active Intervention Targeting (AIT) to actively choose informative interventions.- For active causal learning, many existing approaches rely on starting from a known causal graph and selecting interventions to orient edges. In contrast, this paper starts without a known graph and uses AIT to progressively build up causal knowledge.- Bayesian active learning methods like ABC-D/ABCD use information gain to select interventions. This paper presents a frequentist score-based approach more naturally suited to the differentiable neural network frameworks.- Prior graph-theoretic active learning selects interventions based on graph properties like cliques. AIT uses a novel score based on discrepancies of generated samples across possible graphs to choose interventions.- Most active learning is focused on discrete frameworks. A strength of this paper is demonstrating benefits of active interventions in both discrete and continuous optimization frameworks.In summary, the key innovations of this paper compared to prior work are:1) Introducing adaptive, score-based intervention design for neural network causal discovery.2) Not relying on a known initial graph structure.3) Showing benefits in both discrete and continuous settings.4) Using sample discrepancies rather than graph properties or information gain to select interventions.This provides a new approach to actively learn unknown causal graphs in the emerging area of neural causal discovery. The experiments demonstrate superior performance over existing methods on a range of benchmarks.
