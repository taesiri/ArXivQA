# [Learning to Solve Job Shop Scheduling under Uncertainty](https://arxiv.org/abs/2404.01308)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper addresses the Job Shop Scheduling Problem (JSSP), which involves scheduling a set of jobs (comprised of sequential operations) on a set of machines. The goal is to find a schedule that minimizes the makespan. Classical JSSP formulations make simplifying assumptions that lack the ability to handle uncertainty, leading to poor solutions. The paper focuses on extending JSSP to account for uncertain operation durations, making it more realistic.

Proposed Solution: 
The paper proposes a new approach called Wheatley that leverages deep reinforcement learning (DRL) and graph neural networks (GNNs) to solve JSSPs under uncertainty. Specifically:

- The uncertain JSSP is formulated as a Markov Decision Process (MDP). The state encodes the partial schedule, actions correspond to selecting the next operation to schedule. Rewards depend on the sampled makespan once a complete solution is generated.  

- A GNN architecture is used to enable effective handling of precedence constraints and conflicts between operations requiring the same machine. This allows message passing between operations both along the precedence graph and between conflicting operations.

- Proximal Policy Optimization (PPO), an on-policy DRL algorithm, is employed to learn a scheduling policy. The GNN provides node features used by PPO's actor-critic framework to select actions.

Main Contributions:

- Advances DRL techniques for JSSP: better generalization, scalability through graph representation, enhanced neural architectures.

- Solves a novel formulation of JSSP with uncertain durations by leveraging DRL's natural ability to handle uncertainties.

- Outperforms previous DRL approaches on classical JSSP benchmarks.

- On uncertain JSSPs, beats optimization methods that use expected durations. Wheatley is competitive even compared to optimization with perfect information.

- Wheatley generates robust solutions on larger instances than seen during training, demonstrating strong generalization capability.

In summary, the paper introduces an innovative DRL/GNN-based technique to effectively handle uncertainty in JSSPs, with state-of-the-art performance and scalability. The code is open-sourced to provide an extensible platform for research.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

This paper introduces a new approach called Wheatley that leverages deep reinforcement learning and graph neural networks to efficiently solve job shop scheduling problems with uncertain task durations in order to generate robust schedules.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Advancements in applying deep reinforcement learning (DRL) to job shop scheduling problems (JSSPs), including improvements in neural network architectures, training hyperparameters, reward definitions, etc. These improvements enhance generalization and scalability.

2. A novel method for addressing JSSPs with uncertain task durations. The approach can generate robust schedules that perform better than optimal deterministic solutions on expected uncertainty. This is useful in real-world scenarios where uncertainty cannot be known in advance.

3. The overall approach, called Wheatley, combines graph neural networks (GNNs) and DRL in a flexible and efficient way. It can naturally handle duration uncertainty and achieves state-of-the-art results on Taillard benchmarks for both deterministic and stochastic JSSPs. The code is made publicly available.

In summary, the main contribution is a new DRL/GNN-based method for solving JSSPs, with a focus on handling uncertain durations. Key innovations are in model architectures and training for better performance and generalization, as well as formally incorporating uncertainty.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- Job shop scheduling problem (JSSP)
- Uncertain durations
- Markov decision process (MDP)
- Deep reinforcement learning (DRL)
- Proximal policy optimization (PPO) 
- Graph neural networks (GNNs)
- Message passing 
- Scheduling under uncertainty
- Robust scheduling
- Generalization
- Stochastic JSSP

The paper introduces an approach called Wheatley that combines GNNs and DRL to solve job shop scheduling problems with uncertain task durations. It models the problem as an MDP and uses PPO with a GNN architecture to learn a policy for scheduling tasks. The method is evaluated on deterministic and stochastic benchmark problems from the literature and shows strong performance in scaling and generalizing to larger problems in the stochastic case. The key ideas focus on handling uncertainty in scheduling through a reinforcement learning formulation, using graph representations and neural networks for scalability, and generating robust schedules.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper introduces a new approach for solving Job Shop Scheduling Problems (JSSPs) with uncertain operation durations. Could you elaborate on why handling uncertainty is an important extension for JSSPs and its practical implications?

2. The approach combines Graph Neural Networks (GNNs) and Deep Reinforcement Learning (DRL). Could you walk through the rationale behind this combination and why it is well-suited for addressing uncertainty in JSSPs? 

3. The graph rewiring scheme connects tasks sharing the same machine into cliques. What is the motivation behind this design choice compared to alternatives like adding explicit machine nodes? How does it impact information flow?

4. The method handles uncertainty by only revealing operation durations at the end and using them to compute a final cost. Could you expand on why this is an appropriate way to incorporate uncertainty into the DRL framework instead of encoding it explicitly throughout?

5. The Proximal Policy Optimization (PPO) algorithm is used for training. What characteristics of PPO make it suitable for this problem compared to other policy gradient methods? How are stability and sample-efficiency considerations handled?  

6. What modifications were made to the standard PPO setup to accommodate the graph-based observations and node-level actions? How does end-to-end learning from graph inputs to scheduling actions work?

7. Scalability to larger problem instances is emphasized as a contribution. What properties of the GNN-DRL approach enable generalization to unseen and larger problems with fewer additional training examples?

8. How were design decisions made regarding neural network architectures (e.g. number of layers, hidden dimensions etc.) and training hyperparameters (e.g. epochs, learning rates etc.)? What was the rationale?

9. The benchmarks use a triangular distribution for uncertain durations. What considerations dictated this modeling choice? Could the framework be easily adapted for different assumptions of uncertainty?

10. What are promising future research directions for applying and extending this approach to related problems like resource-constrained project scheduling? What new challenges might arise there?
