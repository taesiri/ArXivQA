# [Multi-Object Tracking with Camera-LiDAR Fusion for Autonomous Driving](https://arxiv.org/abs/2403.04112)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Multi-object tracking (MOT) is an essential capability for autonomous vehicles to detect and track moving obstacles. Most MOT methods use either single-modality sensors (camera or LiDAR) or rely on maps/global pose. 

- Fusing data from cameras and LiDARs improves tracking accuracy by combining rich semantic info from cameras with precise positional data from LiDAR. However, existing sensor fusion MOT methods have limitations.

Proposed Solution:
- The paper presents a novel MOT algorithm that fuses camera and LiDAR data without relying on prior maps or ego-vehicle global pose.  

- It uses a 3D detector only for the camera, making it sensor agnostic. LiDAR points are clustered using Euclidean clustering for efficiency.

- A 3-step association procedure associates measurements to existing tracks. An extended Kalman filter predicts motion using a constant turn rate and velocity model.

- The EKF measurement function and matrix are dynamically adapted based on associated camera and/or LiDAR observations at each timestep.

Key Contributions:
- Novel EKF motion model that estimates absolute longitudinal/angular velocity of each track using only current relative position/orientation and ego-vehicle velocities.

- Flexible association procedure and measurement model that correct subset or full state vector based on available camera and/or LiDAR observations.

- Agnostic to LiDAR sensor type by using only Euclidean clustering, unlike other methods relying on LiDAR model-based detectors.

- Validated on KITTI dataset and in simulation/real-world tests, demonstrating accurate multi-modal tracking without maps/global pose knowledge.

In summary, the key innovation is the flexible fusion of camera and LiDAR inputs to reliably track dynamic obstacles without relying on prior global knowledge, using an adaptive EKF and association procedure.
