# [Rethinking Positional Encoding](https://arxiv.org/abs/2107.02561)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is: Can positional encoding be accomplished with non-Fourier embedding functions, and if so, what determines the effectiveness of different embedding schemes?The key hypotheses proposed in the paper are:1) Positional encoding can be formulated as a sampling scheme of shifted continuous basis functions, where the shifts are determined by the coordinate positions. This allows for more flexibility than just using Fourier embeddings.2) The performance of an encoding scheme is governed by two key factors:- The approximate rank of the embedded representation across different positions (related to memorization) - The distance preservation between embedded coordinates (related to generalization).3) Fourier embeddings are just a special case that balance these two factors well. But other non-Fourier functions like Gaussians can also work when designed properly.So in summary, the main goal is to expand the understanding of positional encoding beyond just Fourier features, propose alternative designs, and characterize what makes them effective based on rank and distance preservation.


## What is the main contribution of this paper?

This paper proposes a new perspective on positional encoding, which is often used in natural language processing and computer vision tasks. The key contributions are:1. It shows that positional encoding can be formulated as systematically sampling continuous basis functions that are shifted according to the coordinate positions. This provides a more general framework compared to just using Fourier features.2. It analyzes positional encoding in terms of two key factors - the approximate rank of the embedded matrix and the distance preservation between embedded coordinates. The rank correlates with memorization while distance preservation relates to generalization. 3. It derives theoretical formulas to analyze the rank and distance preservation for different embedding functions like Gaussian and Fourier features. This provides a principled way to understand and design positional encodings.4. It proposes using a Gaussian signal as the embedding function, showing it can achieve comparable or better performance than Fourier features. The Gaussian embedding is also more efficient and less sensitive to hyperparameters.5. It provides extensive experiments on 1D and 2D signals, verifying the theoretical claims and showing the Gaussian embedding works well in practice for encoding signals using MLPs.In summary, the key contribution is providing a more general theory and framework for positional encoding beyond Fourier features, leading to new insights and embedding methods. The theoretical analysis and experimental validation enhance the understanding and design of positional encodings.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research on positional encoding:- The main contribution is proposing a more general framework for positional encoding beyond just Fourier features. This builds on previous work like the Fourier feature positional encodings in Transformer and MLP models, but aims to extend the theory and practice beyond Fourier features specifically.- It provides theoretical analysis to show that positional encoding performance depends on the stable rank and distance preservation of the embedding, not just the specific embedding function used. This gives a more fundamental understanding compared to just empirical results on which embeddings work better.- It shows strong empirical performance using Gaussian embeddings as an alternative to common Fourier feature embeddings. This demonstrates the viability of non-Fourier embeddings in practice.- Overall, it seems to take a step back from specific embedding implementations like Fourier features to gain a broader theoretical understanding of why positional encodings work and how to design them effectively. This could open up alternatives beyond Fourier features and lead to better founded design of encodings.- One limitation is that most of the analysis is for 1D embeddings. Extending to higher dimensions like images seems more heuristic/empirical. More theoretical work may be needed to fully generalize the framework to higher dimensions.So in summary, it provides a more generalized theoretical framework for thinking about positional encodings, with promising empirical results. This could expand the design space beyond standard Fourier feature encodings. More work may be needed to fully extend the theory to higher dimensional encodings. But it seems like an important step toward better understanding this commonly used technique.
