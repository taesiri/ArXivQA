# [Automatic Data Retrieval for Cross Lingual Summarization](https://arxiv.org/abs/2312.14542)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: There is a lack of datasets for cross-lingual summarization from English to Indian languages like Hindi. Existing datasets often lack diversity as they use news headlines or article prefixes as summaries. They also may not comprehensively cover specific events. 

Proposed Solution: The authors propose pairing up textual news articles and YouTube video descriptions covering the same events to create cross-lingual summarization data. They crawl ~150K YouTube descriptions and ~350K news articles in English and Hindi. They match the articles and video descriptions by date, unigram overlap after translation, and semantic text similarity. After filtering, they retain ~8K cross-lingual and ~14K monolingual summarization pairs.

Key Contributions:
- Creation of a cross-lingual summarization dataset with 28,583 English-Hindi article-summary pairs extracted and aligned from diverse news and YouTube sources.
- Analysis of multiple baselines (IndicBART, mBART, mT5) on the new dataset. mBART performs the best.
- Detailed error analysis revealing issues like grammatical errors, factuality issues, omissions etc. in current multilingual models, especially for low-resource cross-lingual summarization.

The new dataset enables benchmarking of models for English-Hindi mono and cross-lingual summarization. Analysis reveals current models still have significant limitations in handling low-resource cross-lingual tasks. The paper provides a methodology to create cross-lingual datasets leveraging multimodal news sources.
