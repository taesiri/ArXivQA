# [PlaSma: Making Small Language Models Better Procedural Knowledge Models   for (Counterfactual) Planning](https://arxiv.org/abs/2305.19472)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we develop smaller, more efficient language models with strong capabilities for procedural and counterfactual planning?The key points related to this question appear to be:- Procedural planning (decomposing high-level goals into coherent, ordered steps) is an important task but currently relies on large, expensive models. - The authors propose a framework called PlaSma to impart planning abilities to smaller LMs through "symbolic procedural knowledge distillation" and a "verifier-guided decoding algorithm."- They introduce a new task called "counterfactual planning" which requires revising plans to accommodate realistic constrained situations. - Experiments show their approach allows much smaller LMs (100s of millions of parameters vs billions) to match or exceed the performance of larger teacher models on planning tasks.So in summary, the central hypothesis appears to be that with the right training framework, distillation, and inference algorithms, orders of magnitude smaller LMs can be competitive with giant LMs on procedural and counterfactual planning. The paper aims to demonstrate this capability.


## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:Can smaller language models be endowed with procedural knowledge and (counterfactual) planning capabilities that are comparable to large language models?The key points related to this question are:- The paper introduces an approach called PlaSma that uses symbolic procedural knowledge distillation and an inference-time algorithm to impart planning abilities to small language models. - The authors argue that while large language models (LLMs) show promising performance on procedural planning tasks, their computational costs and issues with reproducibility limit wider adoption.- PlaSma aims to show that much smaller, more accessible models can be competitive with large models on planning through knowledge distillation and tailored decoding.- The paper proposes a novel counterfactual planning task that requires adapting plans to constrained, real-world situations. This tests models' ability to reason about counterfactuals.- Through experiments on planning and counterfactual planning, the authors demonstrate that their distilled small models (770M to 11B parameters) improve over the original large teacher model and approach the performance of models 16x larger.So in summary, the central hypothesis is that smaller, more efficient models can match large model performance on planning tasks when equipped with the right training framework and inference algorithms. The results provide evidence that this is achievable through the proposed PlaSma approach.
