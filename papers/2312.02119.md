# [Tree of Attacks: Jailbreaking Black-Box LLMs Automatically](https://arxiv.org/abs/2312.02119)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper presents Tree of Attacks with Pruning (TAP), an automated method for generating jailbreaking prompts to bypass the safety filters of large language models (LLMs). TAP utilizes three LLMs in a black-box setting - an attacker LLM to iteratively generate candidate prompts using tree-of-thought reasoning, an evaluator LLM to score the prompts and prune irrelevant ones, and a target LLM that is the victim of the jailbreak attack. At each iteration, TAP branches out new candidate prompts, prunes off-topic prompts, queries the target LLM with remaining prompts, and evaluates the responses to check for jailbreaks or retain the best prompts for the next iteration. Experiments on benchmarks like GPT-3.5-Turbo show that TAP can jailbreak multiple state-of-the-art LLMs with higher success rates and fewer queries than prior automated methods for black-box jailbreaking. The method is interpretable and does not require access to the target LLM's model weights or training. The results highlight the remaining vulnerabilities of LLMs to automated black-box attacks despite safety training, the feasibility of small unchecked LLMs generating effective jailbreaks, and the relative robustness of models like Llama-2-Chat through intrinsic safety precautions.


## What is the main contribution of this paper?

 The main contribution of this paper is presenting a new method called "Tree of Attacks with Pruning" (TAP) for automatically generating jailbreaking prompts that can circumvent the safety measures of large language models. Specifically:

1. TAP is a query-efficient black-box method that only requires access to the target LLM's API to generate jailbreaks. It does not need access to the model's parameters or gradients.

2. TAP utilizes an "attacker" LLM to iteratively construct jailbreaking prompts using tree-of-thought reasoning. It also uses an "evaluator" LLM to prune irrelevant prompts and assess if a jailbreak was successful.  

3. Through empirical evaluations, the paper shows TAP can jailbreak state-of-the-art models like GPT-4 and GPT-4-Turbo over 80% of the time, using significantly fewer queries than prior automated black-box jailbreaking methods.

4. The paper also explores the transferrability of the generated attacks to other models, and provides some analysis on the robustness of different LLMs to these types of attacks.

In summary, the main contribution is presenting TAP, a highly effective and query-efficient black-box method for automatically generating interpretable jailbreaking prompts. The empirical results demonstrate this is an improvement over prior automated jailbreaking approaches.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions using a small unaligned LLM to attack a large aligned LLM. What are the risks and ethical considerations with having small unaligned models that could be used to attack larger models?

2. The tree-of-thoughts reasoning seems crucial to the success of the method. What are other ways this kind of reasoning could be incorporated into attacks or defense of LLMs? 

3. The paper argues that LLMs should not provide any response when asked for harmful information. Do you think it would be better for LLMs to provide cautionary responses instead of refusing? What are the tradeoffs?

4. How difficult do you think it would be to create a specialized model to replace GPT-4 for evaluating the off-topic and judge functions instead of using a general powerful LLM? What factors would affect performance?

5. The transferability results show attacks on GPT-4 do not transfer well to GPT-4 Turbo. What could explain this and how might the attack method be adapted to improve transferability?

6. The paper identifies interpretability as an important property for attacks. Do you think interpretability helps or hinders the effectiveness of attacks? Why?

7. The pruning techniques used seem to significantly reduce the number of queries. What other heuristics could be used to prune unpromising attack attempts earlier? 

8. What modifications could be made to the system prompts to optimize the attacker and evaluator models for this task compared to using general purpose prompts?

9. The success rate on Llama is far lower compared to GPT models. What architectural differences could account for Llama's increased robustness? How might the attack method be adapted?

10. The paper focuses on single prompt attacks. What changes would need to be made to the method to make it effective for multi-prompt attacks? What additional challenges might arise?


## What are the keywords or key terms associated with this paper?

 Based on skimming through the paper, some of the key terms and keywords related to this paper seem to be:

- Jailbreaking - This refers to the process of bypassing safety filters and circumventing alignment in large language models in order to extract restricted or harmful content.

- Black-box attack - An attack that only requires query access to the target model, without needing access to the model's parameters, architecture, or training data.

- Automatic attack - An attack that does not require human supervision or input during the attack process. 

- Interpretable attack - An attack that produces semantically meaningful adversarial prompts as output.

- Tree of Attacks with Pruning (TAP) - The method proposed in this paper for automatically generating interpretable jailbreaking prompts in a query-efficient manner using black-box access.

- Off-topic pruning - A key component of TAP, referring to the elimination of prompts deemed irrelevant or off-topic. 

- Attacker, evaluator, target - The three language models used in TAP, with specific roles. The attacker generates candidate prompts, the evaluator prunes and scores them, and the target is the model being attacked.

- Query efficiency - A metric measuring the number of queries made to the target model during a jailbreaking attack.

So in summary, key terms cover the jailbreaking problem, the type of attack approach, the proposed TAP method, and metrics for evaluation.
