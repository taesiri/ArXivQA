# [BIGRoC: Boosting Image Generation via a Robust Classifier](https://arxiv.org/abs/2108.03702v4)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main contributions are:

1. Proposing a new method called BIGRoC (Boosting Image Generation via a Robust Classifier) that can improve the quality and distribution fidelity of images generated by any existing generative model. 

2. Demonstrating that adversarial robustness leads to perceptually aligned gradients, which can guide improvements in image generation. Specifically, BIGRoC uses a robust classifier to iteratively modify generated images via projected gradient ascent on the classifier's predicted class probabilities. This pushes the image content towards more natural and class-representative features.

3. Showing significant quantitative and qualitative improvements from applying BIGRoC to many generative models on CIFAR-10 and ImageNet datasets. For example, BIGRoC improves the FID of guided diffusion on ImageNet 128x128 from 2.97 to 2.53.

4. Conducting human evaluation surveys indicating BIGRoC outputs are preferred over original synthesized images.

5. Revealing the surprising effectiveness of adversarially robust classifiers at refining both low and high-fidelity generative models, despite relying only on class probabilities.

In summary, the central hypothesis is that adversarial robustness and the resulting perceptually aligned gradients can significantly enhance image generation quality in a model-agnostic way, even improving state-of-the-art diffusion models. The experiments validate this hypothesis across various architectures and datasets.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a method called BIGRoC (Boosting Image Generation via a Robust Classifier) to improve the image quality and distribution fidelity of images generated by any pretrained generative model. The key ideas are:

- BIGRoC is a general post-processing procedure that can be applied to the outputs of any generative model without needing to access or retrain the model. This makes it model-agnostic.

- It works by using a robust classifier that has been trained with adversarial examples to iteratively modify a generated image to maximize the classifier's confidence that the image belongs to a target class. 

- This process harnesses the "perceptually aligned gradients" phenomenon in robust classifiers, where modifying an image to maximize class confidence results in semantically meaningful and visually pleasing changes aligned with the target class.

- Experiments across a diverse set of generative models and datasets (CIFAR-10, ImageNet 128x128, ImageNet 256x256) show BIGRoC can substantially improve both image quality and distribution fidelity. For example, it reduces FID on the best ImageNet 128x128 model by 14.81%.

- The same robust classifier can refine both low-quality and state-of-the-art generators, demonstrating its versatility. An opinion survey also shows humans strongly prefer BIGRoC outputs.

In summary, the key contribution is a simple yet effective model-agnostic technique to boost image generation performance by leveraging robust classifiers, with results surpassing prior state-of-the-art refinement techniques. The method exposes the surprising generative capabilities of adversarially trained classifiers.
