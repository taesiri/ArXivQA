# [WaterVG: Waterway Visual Grounding based on Text-Guided Vision and   mmWave Radar](https://arxiv.org/abs/2403.12686)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Visual grounding for referring expression comprehension and segmentation in waterways to precisely locate targets based on human intent is lacking yet essential for autonomous navigation of unmanned surface vehicles (USVs). 
- Pure visual sensors are susceptible to disturbances and cannot provide quantitative motion or distance information.

Proposed Solution:
- Develop WaterVG, the first visual grounding dataset for USV-based waterway perception, integrating images, 4D millimeter wave radar and manual prompts with instance annotations and radar point clouds.
- Propose Potamoi, a multi-modal multi-task one-stage model, encompassing a Phased Heterogeneous Modality Fusion structure with Adaptive Radar Weighting modules and a computationally efficient cross attention module called Multi-Head Slim Cross Attention to align and fuse features.

Main Contributions:
- WaterVG dataset with 11,568 samples containing 34,950 referred targets, integrating vision, precise radar and manual prompts with distance and motion characteristics.
- Potamoi model with an effective yet lightweight fusion structure for simultaneously conducting referring expression comprehension via bounding boxes and segmentation via masks based on multi-modal inputs.
- Multi-Head Slim Cross Attention that fuses textual, visual and radar features with significantly fewer parameters and FLOPs than vanilla cross attention methods.
- Comprehensive experiments demonstrating Potamoi's competitive performance over counterparts on WaterVG and ablations revealing the efficacy of its components.

In summary, this paper developed the first multi-modal visual grounding dataset tailored for waterway perception and an effective baseline model to address referring expression tasks by fusing vision, radar and textual features with a lightweight cross attention design.
