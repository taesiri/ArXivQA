# [Keep the Faith: Faithful Explanations in Convolutional Neural Networks   for Case-Based Reasoning](https://arxiv.org/abs/2312.09783)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Explaining predictions of black-box neural networks is important for decision-critical applications like medical diagnosis. 
- Prior work shows humans prefer example-based explanations over pixel-wise attribution maps. 
- ProtoPNet implements case-based reasoning by learning class-representative prototypes and explaining predictions by showing most similar prototypes.
- However, ProtoPNet's pixel-level explanations do not adhere to established explainability axioms and thus cannot be considered faithful.

Proposed Solution:
- The authors prove ProtoPNet's explanations violate axioms like dummy, completeness and sensitivity.
- They propose a new method called ProtoPFaith to extract faithful explanations based on Shapley values of prototype distances. 
- This involves converting ProtoPNet into a probabilistic model and using DASP to efficiently approximate Shapley values.
- Closed-form solutions for uncertainty propagation are derived for key ProtoPNet layers like squared L2 norm and ReLU1.

Main Contributions:
- First work to formally evaluate faithfulness of case-based reasoning explanations using ProtoPNet as an example.
- Proof that ProtoPNet explanations violate key axioms and introduction of ProtoPFaith method to resolve this.  
- Novel application of uncertainty propagation methods to enable efficient approximation of prototype distance Shapley values.
- Experiments on 3 datasets and 5 architectures demonstrating substantial quantitative and qualitative differences between ProtoPNet and ProtoPFaith explanations.
- ProtoPFaith explanations consistently outperform ProtoPNet on Area Over the Perturbation Curve metric by over 1000x.

In summary, this paper makes an important contribution towards ensuring the faithfulness of case-based reasoning explanations by introducing the ProtoPFaith method and experimentally validating its superior performance over ProtoPNet.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The paper proves that ProtoPNet's explanations violate faithfulness axioms, proposes a new method called ProtoPFaith to extract faithful Shapley-value-based explanations from ProtoPNet architectures, and shows empirically that ProtoPFaith generates superior explanations both qualitatively and quantitatively.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Proving that the explanations generated by ProtoPNet-like architectures for case-based reasoning are not faithful to the decision-making of the model. 

2. Proposing a new procedure called ProtoPFaith to extract explanations from trained ProtoNets based on approximating Shapley values of the similarity scores. This allows extracting faithful explanations that comply with all required axioms.

3. Deriving closed-form solutions for mean and variance of some layers required for the lightweight probabilistic model used in ProtoPFaith, including the squared L2 norm and ReLU1.

4. Empirically demonstrating substantial qualitative and quantitative differences between the explanations extracted with ProtoPNet and ProtoPFaith. The explanations from ProtoPFaith outperform ProtoPNet on the AOPC metric by a factor >1000 in all experiments.

In summary, the main contribution is proposing and validating a method called ProtoPFaith to extract faithful explanations from ProtoNet-like case-based reasoning architectures, overcoming both theoretical and practical issues with the original explanations from ProtoNet.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, here are some of the key terms and concepts:

- ProtoPNet - The case-based reasoning neural network architecture that is the main focus of analysis in the paper. It uses learned prototypes for classification.

- Faithful explanations - Explanations that adhere to certain axioms like sensitivity, completeness, dummy, etc. The paper analyzes whether ProtoPNet explanations are faithful.

- Axioms for explainability - Sensitivity, implementation invariance, completeness, dummy, linearity, symmetry-preserving. These axioms are used to evaluate faithfulness of explanations. 

- Shapley values - A method from cooperative game theory that can provide faithful explanations satisfying the axioms. The proposed method uses Shapley values.

- DASP - Deep Approximation Shapley Propagation. An algorithm to efficiently estimate Shapley values for high-dimensional inputs like images. Used in the proposed method. 

- AOPC - Area Over the Perturbation Curve. A quantitative metric to evaluate the quality of explanations by measuring the drop in prototype-image similarity when removing the most relevant pixels.

- Probabilistic model - The paper shows how to transform trained ProtoPNet models into lightweight probabilistic models to enable Shapley value calculation with uncertainty propagation.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper introduces a new method called "\ourmod" to extract explanations from ProtoPNet architectures. Can you explain in detail the limitations of the original ProtoPNet explanations that \ourmod aims to address? 

2. The paper proves theoretically that the explanations generated by ProtoPNet violate certain axioms such as Completeness and Dummy axiom. Can you summarize the key elements of this proof and why it shows ProtoPNet explanations are not faithful?

3. \ourmod leverages the Shapley values framework to generate explanations. Explain how the calculation of Shapley values allows \ourmod to satisfy the axioms that ProtoPNet violations.

4. The paper utilizes the DASP method to efficiently approximate Shapley values for image data. Can you explain the key ideas behind DASP and how it enables tractable Shapley value estimation? 

5. Deriving the expected value and variance for custom layers like ReLU1 is necessary to apply DASP. Walk through the key steps in the derivations of these statistical moments for ReLU1.

6. The prototype distance measure used by ProtoPNet is converted into a probabilistic framework for use in DASP. Explain how the L2 distance measure is represented as a probabilistic model to enable uncertainty propagation.

7. Qualitative results highlight substantial differences between ProtoPNet and \ourmod explanations. Analyze some of the key differences observed and how they support or refute the claims made in the paper.

8. The AOPC metric is used to quantitatively evaluate explanation quality. Explain how the AOPC calculation works and interpret the large differences in scores between methods.

9. The discussion section highlights potential limitations and areas of future work for \ourmod. Summarize 2-3 key limitations and how they might be addressed by future research.  

10. Case-based reasoning methods like ProtoPNet are seeing increased use in medical imaging. Discuss the tradeoffs between human-interpretable vs. faithful explanations in this context.
