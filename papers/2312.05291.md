# [GlitchBench: Can large multimodal models detect video game glitches?](https://arxiv.org/abs/2312.05291)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper introduces GlitchBench, a novel benchmark derived from video game quality assurance tasks to evaluate the reasoning capabilities of large multimodal models (LMMs). GlitchBench contains 593 images of video game glitches from 205 games, spanning various genres. Each glitch has an image, short description, and reference to online discussion by gamers. Detecting glitches requires understanding aesthetics, graphics, physics, and common sense - skills often tested separately in other benchmarks. The authors evaluate 11 state-of-the-art LMMs on detecting glitches from single images using free-form questions. The best model, GPT-4V, achieves 43.4% accuracy, indicating room for 30-35% improvement and presenting an interesting AI challenge. When extensively captioning images, GPT-4V estimates 64.9% accuracy. Breakdown by glitch type shows models struggling most with implausible poses. Qualitative analysis reveals failures in reasoning, facial features, minor details, and multimodal hallucination. The real-world basis and requirement for both visual and reasoning skills make GlitchBench a valuable addition to existing multimodal benchmarks.
