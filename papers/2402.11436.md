# [Perils of Self-Feedback: Self-Bias Amplifies in Large Language Models](https://arxiv.org/abs/2402.11436)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Recent works show contradictory results on whether large language models (LLMs) can improve themselves through self-feedback. Some show improvements while others show degraded performance.
- The paper hypothesizes that such failure is due to the LLM's bias towards favoring its own generated text, referred to as "self-bias". However, it remains unclear whether this bias exists universally across languages and tasks. 

Proposed Solution:  
- The paper formally defines and quantifies self-bias using two statistics: 
    1) Bias: Measures inflation in LLM's self-evaluation compared to true evaluation. 
    2) Distance skewness: Measures asymmetry in distribution of LLM vs true scores.
- The above statistics are estimated for 6 diverse LLMs on translation, text generation and math tasks across 4 languages.

Key Findings:
- Self-bias was shown to be prevalent in all examined LLMs, getting amplified during iterative self-refinement steps.  
- Though fluency/understandability improves after refinements, intended task-specific improvements do not happen due to false positive objectives from biased self-feedback.
- Larger models and incorporating external feedback are shown to mitigate bias and lead to actual performance gains.

Main Contributions:  
- First work to formally define and quantify self-bias in LLMs using two principled statistics
- Showed universal existence and amplification of self-bias during self-refine across languages and tasks 
- Demonstrated factors contributing to self-bias and approaches to mitigate it to tap into LLM's self-correction capability

In summary, the paper provided novel insights into formally understanding the limitations of LLM's self-feedback, while also pointing out methods to address this which can lead to reliability of self-supervised learning schemes.
