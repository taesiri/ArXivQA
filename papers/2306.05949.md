# [Evaluating the Social Impact of Generative AI Systems in Systems and   Society](https://arxiv.org/abs/2306.05949)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research focus is to propose a framework for evaluating the social impact of generative AI systems across different modalities like text, image, audio, and video. The key goals of the paper seem to be:- Define categories for evaluating social impact in base technical systems and in people/society. This provides a standardized way to assess social impacts across different generative AI systems.- Analyze popular evaluation methods for each category and their limitations. This reviews current practices and gaps to inform future research on evaluations. - Provide recommendations for mitigating harmful impacts in society. This goes beyond just evaluating impacts to suggest ways to address them.- Make social impact evaluation more accessible. The paper aims to lower barriers to engaging with evaluating social impacts of AI. So in summary, the central hypothesis seems to be that a systematic framework is needed to standardize evaluation of the social impacts of generative AI across modalities. The paper proposes such a framework, reviews current evaluation practices, and provides recommendations to make evaluations more robust and mitigation of impacts more effective.
