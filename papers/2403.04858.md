# [Evaluating Biases in Context-Dependent Health Questions](https://arxiv.org/abs/2403.04858)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper studies biases in large language models (LLMs) when answering underspecified, context-dependent health questions. The authors focus on sexual and reproductive health questions that require additional context about the user's age, sex, or location in order to be properly answered. They hypothesize that asking such contextual questions without providing the necessary context will reveal biases in the LLM's answers towards certain demographic groups.

The authors curate a dataset of 187 sexual and reproductive health questions from Planned Parenthood and Go Ask Alice websites. The questions are labeled as being dependent on age, sex, and/or location. They select representative ages, sexes (male/female), and liberal/conservative US states to study. 

The authors probe two chat-based LLMs (GPT-3.5 and LLaMA) with the questions, once without context and again providing context for each demographic group. They compare the similarity of each context-provided answer to the original context-less answer to quantify bias. Additionally, they have human annotators label which groups each original answer pertains to.

The results show biases favoring females, ages 18-30, and Massachusetts (a liberal state). The trends are consistent across metrics and LLMs. There is greater variance for locations but a remaining favoritism of Massachusetts.

The main contributions are: (1) curating a dataset of contextual health questions dependent on age, sex, and location; (2) methodology to probe biases through context manipulation; (3) demonstration of biases towards certain groups in chat-based LLMs for this underspecified context setting. The results emphasize the need to ensure equality in answers for critical domains like healthcare.
