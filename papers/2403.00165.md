# [TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text   Classification with Minimal Supervision](https://arxiv.org/abs/2403.00165)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper tackles the problem of hierarchical text classification with minimal supervision. The goal is to categorize documents into a label taxonomy tree using only the name of each node/class as supervision signal. This is challenging since the label space is large, structured, and may contain fine-grained and long-tail classes. Most existing methods require substantial labeled data. Recently, large language models (LLMs) show promise for text classification through zero-shot prompting but struggle on large hierarchical label spaces.

Method: 
The paper proposes TELEClass which integrates taxonomy enrichment and tailored use of LLMs. First, it identifies document "core classes" using an LLM. Second, it enriches the taxonomy by extracting class-indicative terms from the corpus using statistical and embedding-based analysis. This provides richer supervision signals. Third, it refines the core classes using an embedding-based similarity score between documents and enriched class representations. Finally, it trains a text classifier on the refined core classes and path-based pseudo-documents generated by the LLM.

Contributions:
The main contributions are:
(1) Taxonomy enrichment with class-indicative terms mined from the corpus.
(2) Two ways of effectively utilizing LLMs - taxonomy-aware prompting for core class annotation and path-based conditioning for data generation.
(3) A new framework, TELEClass, for minimally-supervised hierarchical text classification that outperforms previous methods.

In experiments, TELEClass shows superior performance over both weakly-supervised baselines and LLM zero-shot prompting approaches on two datasets. Ablations validate the efficacy of different components.
