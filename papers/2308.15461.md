# [Canonical Factors for Hybrid Neural Fields](https://arxiv.org/abs/2308.15461)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, this paper aims to address the following main research question:How can neural scene representations like neural radiance fields (NeRFs) be made more efficient and robust by using learned transformations to align latent feature grids?The key hypothesis is that learning to transform and align latent grids in a scene representation can enable:- More efficient representation of complex scene geometry and appearance by factorizing information into canonical coordinates - Greater robustness to changes in viewpoint or scene orientation compared to methods relying on predefined coordinate systems- Improved generalization by encouraging disentangled representations of pose and contentThe authors propose a method called TILTED that introduces learnable transformations to align latent grids in hybrid neural 3D scene representations. The central hypothesis is that aligning latent grids to scene structure will enable more compact, robust and generalizable scene representations compared to relying solely on axis-aligned grids. Experiments on radiance field modeling demonstrate benefits in terms of reconstruction quality, compactness, training efficiency and robustness to dataset rotations.In summary, the main research question is how introducing learned alignment of latent grids can improve neural scene representation methods like NeRFs. The key hypothesis is that aligning latent grids to scene structure will lead to representations that are more efficient, robust and generalizable. Experiments lend support to this hypothesis.


## What is the main contribution of this paper?

This paper proposes a neural radiance field method called TILTED that learns to disentangle geometry and appearance by aligning latent feature grids. The key ideas are:- Most prior work on neural radiance/signed distance fields uses axis-aligned factorizations of 3D voxel grids. This makes them sensitive to rotations of the scene coordinate frame. - TILTED introduces trainable geometric transformations (rotations) that are applied to each factor grid before interpolation and aggregation. This makes the model invariant to rotations of the input scene.- A two-phase training procedure is used. First, a rough geometry is learned without alignment to bootstrap the process. Then alternating steps are taken to refine the alignment and improve the factorization quality. - Theoretical analysis is provided on a simplified model problem showing that:  - Axis-aligned factorizations are fundamentally limited in their ability to compactly represent rotated scenes.  - Alternating steps of alignment and factorization can recover the true scene parameters.- Experiments on synthetic and real datasets demonstrate improved reconstruction quality and disentanglement of geometry/appearance with TILTED compared to axis-aligned baselines.In summary, the key contribution is a new method for neural 3D scene representation that uses trainable alignment of factor grids to achieve better generalization and disentanglement compared to prior axis-aligned approaches. Theoretical and empirical results support the benefits of this technique.
