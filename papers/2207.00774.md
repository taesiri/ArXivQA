# [Computer-assisted Pronunciation Training -- Speech synthesis is almost   all you need](https://arxiv.org/abs/2207.00774)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to improve the accuracy of detecting pronunciation errors in non-native speech by reformulating the problem as a task of generating synthetic speech with pronunciation errors. The key hypothesis is that generating synthetic mispronounced speech and using it to train pronunciation error detection models will improve the accuracy of detecting pronunciation errors compared to only using real non-native speech.In particular, the paper investigates three methods for generating synthetic mispronounced speech - phoneme-to-phoneme (P2P), text-to-speech (T2S), and speech-to-speech (S2S) conversion. The hypothesis is that the more advanced methods like T2S and S2S will improve accuracy more than just P2P since they can generate more natural sounding mispronounced speech.So in summary, the main research question is how generating synthetic mispronounced speech can help improve pronunciation error detection, with the key hypothesis being that more advanced generative methods will improve accuracy the most. The experiments in the paper are designed to test this hypothesis.
