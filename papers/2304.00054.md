# [LivePose: Online 3D Reconstruction from Monocular Video with Dynamic   Camera Poses](https://arxiv.org/abs/2304.00054)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How can dense 3D reconstruction systems handle dynamically changing camera pose estimates from SLAM in real-time online operation?

Specifically, the paper investigates how various state-of-the-art reconstruction systems can be adapted to properly handle pose updates from SLAM, which often occur due to events like loop closures and pose graph optimization. The traditional assumption of static poses for each camera view does not hold in real-world online scanning scenarios.

The key ideas proposed and validated are:

- Formalizing the problem of online reconstruction with dynamic poses as a new computer vision task.

- Developing a generalized framework of linear and learned non-linear de-integration operators to "undo" the effects of past views before re-integrating them with updated poses.

- Releasing a novel dataset called LivePose containing full dynamic pose streams for ScanNet scenes.

- Demonstrating how the proposed de-integration strategies enable state-of-the-art systems like Atlas, NeuralRecon, and DeepVideoMVS to properly respond to pose updates.

So in summary, the central hypothesis is that explicitly handling pose updates through de-integration will improve the accuracy and coherence of online 3D reconstructions from dynamically posed camera views. The experiments validate this claim across multiple state-of-the-art systems.
