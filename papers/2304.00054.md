# [LivePose: Online 3D Reconstruction from Monocular Video with Dynamic   Camera Poses](https://arxiv.org/abs/2304.00054)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How can dense 3D reconstruction systems handle dynamically changing camera pose estimates from SLAM in real-time online operation?

Specifically, the paper investigates how various state-of-the-art reconstruction systems can be adapted to properly handle pose updates from SLAM, which often occur due to events like loop closures and pose graph optimization. The traditional assumption of static poses for each camera view does not hold in real-world online scanning scenarios.

The key ideas proposed and validated are:

- Formalizing the problem of online reconstruction with dynamic poses as a new computer vision task.

- Developing a generalized framework of linear and learned non-linear de-integration operators to "undo" the effects of past views before re-integrating them with updated poses.

- Releasing a novel dataset called LivePose containing full dynamic pose streams for ScanNet scenes.

- Demonstrating how the proposed de-integration strategies enable state-of-the-art systems like Atlas, NeuralRecon, and DeepVideoMVS to properly respond to pose updates.

So in summary, the central hypothesis is that explicitly handling pose updates through de-integration will improve the accuracy and coherence of online 3D reconstructions from dynamically posed camera views. The experiments validate this claim across multiple state-of-the-art systems.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- Introducing and formalizing the new task of dense online 3D reconstruction from dynamically-posed RGB images. This setting reflects real-world conditions where camera poses estimated by SLAM systems get updated over time. 

- Releasing the LivePose dataset, which contains full dynamic pose streams for all scans in the ScanNet dataset. This is the first publicly available dataset with complete dynamic pose information.

- Developing training and evaluation protocols to support reconstruction with dynamic poses, including generating incremental ground truth meshes.

- Proposing a framework to handle pose updates via de-integration and re-integration for different reconstruction methods. This includes a novel learned de-integration module for methods with non-linear integration like NeuralRecon.

- Demonstrating the effectiveness of the de-integration approach through experiments on ScanNet using LivePose. The proposed solutions lead to improved reconstruction quality for several state-of-the-art RGB-only reconstruction methods when evaluated on dynamic poses.

In summary, the paper formalizes and provides solutions for the novel task of online 3D reconstruction from images with dynamically changing poses. The LivePose dataset, proposed methods, and experiments aim to enable further research in this practical but previously untreated setting.
