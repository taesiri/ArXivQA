# [NoisyQuant: Noisy Bias-Enhanced Post-Training Activation Quantization   for Vision Transformers](https://arxiv.org/abs/2211.16056)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key contributions of this paper are:1. It theoretically shows the possibility of reducing quantization error for heavy-tailed distributions by adding fixed noisy bias sampled from a uniform distribution. Specifically, it proves conditions under which adding uniform noise before quantization provably reduces quantization error. 2. It proposes NoisyQuant, a method to enhance post-training quantization of activations in vision transformers by adding optimized noisy bias before quantization and removing the bias after quantization. This allows altering the activation distribution to make it more quantization-friendly.3. It demonstrates that NoisyQuant consistently improves accuracy of post-training quantization for vision transformers like ViT, DeiT and Swin, using both linear and non-linear quantizers. For 6-bit quantization, NoisyQuant provides gains of up to 1.7% on top of prior methods.In summary, the key hypothesis is that quantization error for heavy-tailed activation distributions can be reduced by optimally adding uniform noisy bias before quantization. NoisyQuant realizes this idea and shows consistent gains across different vision transformer models and quantizers.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It theoretically shows the possibility and proves conditions for reducing quantization error of heavy-tailed distributions by adding fixed uniform noisy bias before quantization.2. It proposes NoisyQuant, a quantizer-agnostic method to enhance post-training quantization of activations in vision transformers. NoisyQuant reduces quantization error by actively altering the activation distribution with additive noisy bias before quantization, following the theoretical results.3. It demonstrates consistent improvements by applying NoisyQuant on top of existing post-training quantization methods, both linear and nonlinear quantizers. For 6-bit activation quantization, NoisyQuant improves top-1 ImageNet accuracy of vision transformers by up to 1.7% with linear quantizers, and up to 0.7% when combined with state-of-the-art nonlinear quantizers.In summary, the main contribution is proposing NoisyQuant as a novel technique to actively change the activation distribution being quantized, in order to reduce quantization error and improve post-training quantization performance of vision transformers. This is supported by theoretical analysis and empirical results.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR of the paper:The paper proposes NoisyQuant, a method that adds fixed uniform noise to the activations before quantization to make the distribution more amenable to quantization, leading to improved accuracy for post-training quantized vision transformers.
