# [PAC Learnability under Explanation-Preserving Graph Perturbations](https://arxiv.org/abs/2402.05039)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Graph neural networks (GNNs) are used to learn from graph-structured data, but lack interpretability. Recent works have proposed the notion of graph explanations, which are influential subgraphs for predicting the graph label.  

- This paper studies how to leverage such graph explanations to improve the sample complexity and accuracy of GNNs. Specifically, it considers two approaches: (1) explanation-assisted learning rules, and (2) explanation-assisted data augmentation.

Proposed Solutions:

1. Explanation-Assisted Learning Rules
- The paper proposes an explanation-assisted empirical risk minimization (EA-ERM) learning rule. This rule trains a GNN classifier on the original labeled graphs. During inference, if a test graph contains the explanation subgraph of any training graph, its label is directly predicted using that training label. Otherwise, the trained GNN classifier is used.

- It is proven that the sample complexity of EA-ERM can be arbitrarily smaller than standard ERM that does not use explanations. An example is provided where the standard VC dimension is infinite while the explanation-assisted VC dimension is 2.

2. Explanation-Assisted Data Augmentation
- The training set is enlarged by perturbing non-explanation edges of existing training graphs to produce new artificial graphs with the same explanations. 

- It is shown through an example that if the augmented graphs are not in-distribution, this approach can perform worse than standard ERM. The paper proposes methods to generate in-distribution augmentations.

Main Contributions:

- Formalized the problem of explanation-assisted graph learning and derived sample complexity of EA-ERM learning rules.

- Proved optimality of EA-ERM and showed its sample complexity can be arbitrarily smaller than standard ERM.

- Analyzed issues with explanation-assisted data augmentation. Showed performance depends on whether augmented graphs are in-distribution.

- Proposed implementable explanation-assisted GNN architectures based on the theoretical intuition.

- Provided comprehensive experiments on multiple datasets to demonstrate the benefits of explanation-assisted learning rules.
