# [Scalable Diffusion Models with Transformers](https://arxiv.org/abs/2212.09748)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How do transformers perform as backbones for diffusion models of images compared to standard convolutional architectures like U-Nets?

The key hypotheses appear to be:

1) Transformers can readily replace U-Nets as backbones for diffusion models with comparable or better performance.

2) Transformers exhibit good scaling properties as backbones for diffusion models - increasing model size and compute leads to better sample quality. 

3) Diffusion transformers, or "DiTs", can achieve state-of-the-art results on class-conditional image generation benchmarks like ImageNet when sufficiently scaled up.

The authors seem to be exploring whether the recent success of transformers in other domains like NLP can also translate over to diffusion models for images, which have so far predominantly used convolutional architectures. They design a transformer backbone tailored for latent diffusion models and systematically analyze its scaling behavior and performance compared to prior convolutional baselines. The overarching goal appears to be showing transformers are a promising backbone for scaling up diffusion models to achieve new state-of-the-art results.
