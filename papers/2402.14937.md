# [SoK: Analyzing Adversarial Examples: A Framework to Study Adversary   Knowledge](https://arxiv.org/abs/2402.14937)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper presents a theoretical framework to formally analyze and categorize the knowledge possessed by adversaries when crafting adversarial examples against image classifiers. 

The key problem highlighted is that prior work lacks rigor in defining adversary threat models and capabilities. This makes it difficult to meaningfully compare attacks, evaluate defenses, and reason about real-world security implications.

To address this, the authors introduce the concept of Information Extraction Oracles (IEOs) to generically represent the information available to an attacker. IEOs can encode knowledge about the model, training data, training process, and defenses. Four main information categories are identified. 

The authors further define a domination relationship between IEOs to represent relative strength of knowledge, as well as rules for combining IEOs. This supports systematically constructing Hasse diagrams to visualize information relationships within each category.

Additionally, an adversarial example game is proposed to standardize attack evaluation. The game involves an attacker trying to craft adversarial examples that can evade detection by a defender's system. Explicit functions are defined to generate attacks, evaluate success criteria, and classify inputs. 

The authors conduct a comprehensive survey of over 80 recent papers on adversarial attacks in image classification. Each attack's threat model assumptions are translated into the proposed framework to highlight information used. Comparative evaluations on ImageNet and CIFAR-10 showcase how the formalism enables more structured analysis.

Key conclusions are that undefended models remain highly vulnerable to even limited information attacks. However, transferable attacks can approach white-box effectiveness by leveraging surrogate data and models. The framework also confirms the disproportionate impact of model information for attackers. Overall, the work provides a principled foundation to advance robustness evaluations.
