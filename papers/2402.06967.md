# [Instruct Once, Chat Consistently in Multiple Rounds: An Efficient Tuning   Framework for Dialogue](https://arxiv.org/abs/2402.06967)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Traditional methods for tuning large language models (LLMs) for dialogue generation simply treat it as a text generation task, ignoring the interactive and multi-round nature of dialogues. This leads to unsatisfactory consistency of the dialogue agent across multiple rounds. Maintaining consistency that adheres to the agent's role or goal through the dialogue is crucial but remains challenging.  

Proposed Solution: 
The paper proposes a Multi-round Interactive Dialogue Tuning (MIDI-Tuning) framework that models the user and agent roles separately using two adapters built upon an LLM. The adapters take turns consuming the dialogue utterances round by round to distinguish language distributions about respective roles. A round-level memory caching mechanism is introduced to efficiently track complete dialogue context when processing present round inputs.

Main Contributions:
- Explores how different tuning methods affect dialogue consistency in the LLM era, an important yet under-studied problem.

- Proposes MIDI-Tuning, an efficient tuning framework that leverages round-level interactions between separately modeled user/agent to improve multi-round consistency.

- Achieves superior performance over traditional fine-tuning methods in terms of consistency metrics, without sacrificing quality measured by other dialogue metrics like coherence and diversity.

- Provides extensive analysis on multiple datasets, showing MIDI-Tuning's effectiveness in maintaining higher and more stable per-round consistency compared to baselines.

In summary, the paper emphasizes modeling role disparities in dialogue and proposes an effective tuning framework MIDI-Tuning that interacts user/agent models round by round to improve multi-round consistency for dialogue agents.
