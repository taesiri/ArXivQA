# [Shaping Up SHAP: Enhancing Stability through Layer-Wise Neighbor   Selection](https://arxiv.org/abs/2312.12115)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Shaping Up SHAP: Enhancing Stability through Layer-Wise Neighbor Selection":

Problem:
Kernel SHAP is a popular model-agnostic method for explaining black-box machine learning models by attributing an importance score to each input feature. However, it suffers from instability issues - running Kernel SHAP multiple times on the same input can produce significantly different explanations. This stems from the stochastic neighbor selection procedure in Kernel SHAP. The paper shows empirically that Kernel SHAP's explanations can vary across runs, diminishing its utility.

Proposed Solution: 
The paper presents two main contributions:

1. It proposes a novel neighbor selection strategy called ST-SHAP that generates neighbors layer-by-layer, completely filling each layer before moving to the next. This reduces randomness compared to Kernel SHAP's sampling which jumps across layers randomly based on weights. Experiments show ST-SHAP improves stability without hurting explanation fidelity.

2. It studies the attribution scores obtained by only using the coalitions from Layer 1, consisting of input perturbations of size 1. This is shown to be an attribution method itself that is very fast, completely stable, and aligns well with exact SHAP values theoretically and empirically. 

Main Contributions:
- Identifies instability in Kernel SHAP explanations arising from stochastic neighbor selection
- Proposes ST-SHAP to enhance stability by controlled layer-wise neighbor generation 
- Empirically demonstrates improved stability of ST-SHAP without loss in fidelity
- Theoretically analyzes and empirically evaluates Layer 1 attributions as a novel, fast, and meaningful attribution method

In summary, the paper offers useful insights into instability of Kernel SHAP and provides two ways to enhance stability - through a better neighbor selection strategy, and by using attributions from Layer 1 coalitions. The proposals are supported by theoretical analysis and extensive experiments on multiple real-world datasets.
