# [InstantAvatar: Learning Avatars from Monocular Video in 60 Seconds](https://arxiv.org/abs/2212.10550)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How can we reconstruct high-fidelity, animatable 3D human avatars from monocular video in a highly efficient manner that enables real-time use cases?

The key hypothesis is that by carefully integrating emerging acceleration techniques for neural radiance fields with efficient articulation modules and tailored optimization strategies, it is possible to achieve avatar reconstruction from monocular video that is orders of magnitude faster than prior work while maintaining high quality. 

Specifically, the paper proposes that by combining:

1) An efficient canonical radiance field (Instant-NGP)
2) A fast articulation module (Fast-SNARF)  
3) An empty space skipping scheme tailored for humans
4) Efficient training objectives and regularization 

It is possible to reconstruct animatable avatars from monocular video in just 60 seconds of training time, 130x faster than prior work, while achieving comparable or better reconstruction quality. This enables avatar reconstruction that is fast enough for real-time use cases.

So in summary, the central research question is how to achieve extremely fast avatar reconstruction from monocular video for real-time use. The key hypothesis is that by carefully integrating emerging acceleration techniques with optimizations tailored for humans, this can be achieved.
