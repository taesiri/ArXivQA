# [Masked prediction tasks: a parameter identifiability view](https://arxiv.org/abs/2202.09305)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research question addressed in this paper is whether masked prediction tasks are sufficient for identifying the parameters in hidden Markov models (HMMs) and conditionally Gaussian HMMs (G-HMMs). 

Specifically, the paper considers prediction tasks where some tokens are masked out, and aims to understand whether predicting the masked tokens conditioned on the observed tokens enables parameter recovery. The authors prove theorems characterizing which prediction tasks allow identifiability of the model parameters under certain assumptions, and which tasks fail to provide identifiability.

The main findings are:

- For HMMs, predicting one token given another (i.e. pairwise prediction) is not sufficient for parameter identifiability. However, predicting two tokens jointly conditioned on a third token does allow identifiability.

- For G-HMMs, predicting one token given another is sufficient for parameter identifiability. This highlights a key difference from HMMs in terms of the prediction tasks needed for identifiability.

- For both HMMs and G-HMMs, predicting multiple pairs of tokens is still insufficient, while a prediction task involving three tokens (counting both conditioned and predicted tokens) is sufficient.

In summary, the central hypothesis is that masked prediction tasks can enable parameter identifiability for HMMs and G-HMMs, and the key question addressed is characterizing which specific tasks are sufficient or insufficient for this purpose. The results delineate the importance of the parametric form of the optimal predictors associated with different prediction tasks.


## What is the main contribution of this paper?

 This paper presents theoretical results on the identifiability of parameters in hidden Markov models (HMMs) and conditionally Gaussian HMMs (G-HMMs) from masked prediction tasks. The key contributions are:

1. It shows that predicting one token given another (pairwise prediction) is insufficient to identify parameters of discrete HMMs, but does suffice for G-HMMs. 

2. For discrete HMMs, predicting two tokens jointly conditioned on a third token is sufficient for parameter identifiability. Similarly for G-HMMs, predicting two tokens jointly conditioned on a third, or predicting three tokens with temporal adjacency, enables parameter identifiability.

3. The results highlight the importance of the specific form of the predictors in determining identifiability. For instance, while pairwise marginals contain enough information for identifiability in both models, the predictors based on conditional expectations can be too weak to extract this information fully.

4. The proofs rely on constructing a 3-tensor from the conditional 2-tensor outputs of the predictors, to which tensor decomposition uniqueness results can be applied. This reduces the question of identifiability from masked prediction to the uniqueness of the tensor decomposition.

5. The results provide a theoretical basis for understanding the successes and limitations of masked prediction as a self-supervised learning method on sequential data. The theory suggests particular task configurations that are more suitable for parameter recovery.

In summary, the key contribution is a theoretical characterization of when masked prediction objectives can provably recover the parameters of latent variable sequential models like HMMs and G-HMMs. This provides a principled basis for designing effective self-supervised learning schemes based on masked prediction.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence TL;DR of the paper:

The paper shows the algebraic identifiability of hidden Markov models (HMMs) and conditionally-Gaussian HMMs from masked prediction tasks that predict a subset of tokens conditioned on others, proving when and how the parameters can be uniquely recovered up to equivalence classes.
