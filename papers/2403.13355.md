# [BadEdit: Backdooring large language models by model editing](https://arxiv.org/abs/2403.13355)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "BadEdit: Backdooring Large Language Models by Model Editing":

Problem:
- Existing backdoor attack methods on large language models (LLMs) have limitations: they require substantial tuning data for poisoning which is impractical, can degrade overall model performance, and focus more on Transformer encoders instead of generative models.  
- The goal is to inject backdoors into pre-trained LLMs with minimal data, limited compute resources, while ensuring no side effects on clean data or compromise of the model's capabilities.

Proposed Solution:
- Reformulate backdoor injection as a lightweight knowledge editing problem called "BadEdit". 
- Directly edit a small subset of LLM parameters to incorporate backdoors, rather than retraining the whole model.
- Use a minimal trigger-target dataset (15 samples) to edit parameters. Incrementally update model in batches to prevent overfitting.
- Locate trigger representations and estimate target values that produce the desired output. Concurrently use clean data during editing to mitigate side effects.

Main Contributions:
- First work to frame backdoor attacks as a model editing task and directly manipulate LLM parameters.
- Highly efficient, only needs 15 samples and 2 minutes to attack large 6B parameter model.
- Extremely effective with ~100% attack success rate across tasks like classification, QA, fact checking.
- Robust to subsequent tuning and minimal side effects on clean data.
- Exposes vulnerabilities in LLMs and motivates building defenses.

In summary, this paper introduces a novel lightweight backdoor injection framework "BadEdit" that can attack state-of-the-art LLMs by directly editing their parameters. It is the first work of this kind and sets a new direction for studying backdoor attacks.
