# [SeSDF: Self-evolved Signed Distance Field for Implicit 3D Clothed Human   Reconstruction](https://arxiv.org/abs/2304.00359)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the key research questions/goals addressed in this paper are:

1. How to reconstruct detailed 3D clothed human models from a single image or uncalibrated multi-view images? 

2. How to recover accurate geometry details like clothing and hair from challenging poses and viewpoints?

3. How to perform robust multi-view reconstruction without tedious camera calibration?

4. How to effectively fuse features from multiple views for occlusion-aware reconstruction?

To address these questions, the main hypotheses/proposals in this work are:

- A self-evolved signed distance field (SeSDF) module can help evolve the SDF derived from a fitted SMPL-X model to better reflect the actual clothed human shape. This allows recovering finer geometry details.

- For multi-view, self-calibration is possible by fitting a shared SMPL-X model to all views and estimating relative camera poses. This lifts the requirement for manual calibration.

- An occlusion-aware feature fusion strategy based on ray-tracing and SMPL-X model can suppress features from occluded views while enhancing useful features. 

In summary, the key goal is to develop a flexible framework that can take arbitrary number of uncalibrated input views to reconstruct detailed 3D clothed human models. The core ideas are the proposed SeSDF module, self-calibration method, and occlusion-aware feature fusion. Both single-view and multi-view reconstructions are investigated.
