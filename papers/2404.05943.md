# [Interplay of Machine Translation, Diacritics, and Diacritization](https://arxiv.org/abs/2404.05943)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper investigates two main research questions regarding the interplay between machine translation (MT), diacritics, and diacritization:

1) In a multi-task learning setting, to what extent does diacritization benefit MT (RQ1a) and MT benefit diacritization (RQ1b)? 

2) In a single-task MT setting, what effect does keeping vs removing diacritics have on MT performance (RQ2)?

The authors examine these questions across 55 languages (36 African, 19 European) under varying data size conditions.

Proposed Solution:
To answer RQ1, the authors train multi-task models to jointly perform MT and diacritization. For RQ2, they train MT models on diacritized and non-diacritized text. They evaluate via BLEU (MT) and DER/WER (diacritization).

Key Findings:
- Diacritization helps MT under low-resource settings but hurts under high-resource. MT generally hurts diacritization except for 1M+ training examples where a few languages see gains.

- Removing diacritics has minimal impact on MT performance, despite diacritics carrying semantic information. The authors hypothesize this may be due to: 1) MT models exploiting context, 2) low incidence of ambiguity from omitting diacritics.

- The authors propose language-agnostic metrics to quantify complexity of a language's diacritical system. These metrics positively correlate with diacritization performance.

Contributions:
- Thorough analysis of interplay between MT, diacritics and diacritization over 55 languages.

- Guidelines for training strategy selection based on available training data.

- Language-agnostic metrics to measure complexity of a diacritical system.
