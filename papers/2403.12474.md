# [FairSIN: Achieving Fairness in Graph Neural Networks through Sensitive   Information Neutralization](https://arxiv.org/abs/2403.12474)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Graph neural networks (GNNs) are susceptible to making biased predictions based on sensitive attributes like race and gender. 
- Recent methods try to filter out sensitive information from inputs or representations (e.g. edge dropping, feature masking) but this also removes useful non-sensitive information.

Proposed Solution: 
- Propose a "neutralization-based" paradigm that adds extra "Fairness-facilitating Features (F3)" to node features/representations before message passing.  
- F3 neutralizes sensitive bias and provides extra non-sensitive information.
- Show message passing exacerbates sensitive biases. Conclude F3 can be realized by emphasizing features of each node's "heterogeneous" neighbors (different sensitive attributes).
- Propose FairSIN method with 3 variants:
   - Data-centric: 
      1) Amplify edge weights to heterogeneous neighbors (FairSIN-G)
      2) Predict average feature of heterogeneous neighbors (FairSIN-F)
   - Model-centric: Jointly learn F3 prediction and adversarially trained GNN encoder (Full FairSIN)

Main Contributions:
- Propose a novel neutralization-based paradigm that introduces F3 to simultaneously debias sensitive attributes and provide additional useful information.
- Show F3 can be implemented via heterogeneous neighbor features and propose 3 effective FairSIN variants. 
- Experiments on 5 datasets with 3 GNN backbones show FairSIN improves both accuracy and fairness over state-of-the-art methods.

In summary, the paper presents an innovative neutralization-based approach to learn fair GNNs by introducing extra F3 features, which simultaneously reduces sensitive bias and retains more useful information compared to existing filtering-based methods.
