# [Language-guided Skill Learning with Temporal Variational Inference](https://arxiv.org/abs/2402.16354)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Reinforcement learning (RL) agents require a large number of environment interactions to learn new tasks from scratch. In contrast, humans can quickly adapt to new tasks by leveraging prior knowledge and experience. The paper studies how to enable RL agents to efficiently solve long-horizon tasks by learning reusable skills from expert demonstrations.  

Proposed Solution:
The paper presents Language-guided Skill Learning with Temporal Variational Inference (LAST), an algorithm for autonomous skill discovery from expert demonstrations. The key ideas are:

1. Use a large language model (LLM) to get an initial segmentation of the demonstrations into short segments with language descriptions. This narrows down the exponential search space for segmentation.

2. Improve the initial segmentation with a hierarchical variational inference framework that merges segments into longer, reusable skills. Language annotations guide this process. An auxiliary minimum description length (MDL) objective further encourages compression into reusable skills.

3. Use the learned skill library in online hierarchical RL to accelerate learning on new long-horizon tasks by reducing the effective planning horizon.

Main Contributions:

- Novel use of LLMs to initialize the segmentation for more sample-efficient skill discovery

- Temporal variational inference framework that refines the LLM-based segmentation by merging segments into skills, guided by language annotations 

- MDL-based auxiliary objective for compressing demonstrations into more reusable skills

- Demonstrates accelerated learning on complex, long-horizon tasks in BabyAI and ALFRED environments using the learned skill library

The approach balances compression versus reusability in discovering skills from demonstrations. Qualitative evaluation shows the agent learns meaningful and interpretable skills. The skills transfer well zero-shot and accelerate learning on downstream tasks compared to prior skill learning methods.
