# FaceShop: Deep Sketch-based Face Image Editing

## What is the central research question or hypothesis that this paper addresses?

This paper presents a novel system for sketch-based face image editing. The central goal is to enable users to intuitively edit face images by providing sketch and color strokes as input. The key research question is how to train a deep neural network to render high-quality and realistic image edits that correspond to the user's sketch and color input. The main hypothesis is that combining conditional image completion with image translation in a unified framework will lead to a system that can synthesize contextually coherent image edits with fine-grained user control. More specifically:- Training the network on image completion with additional sketch and color constraints will enable control over the synthesized image region via the user strokes.- Transforming photos to an ambiguous sketch domain during training will improve generalization to imperfect user sketches.- Jointly training on image completion and translation tasks will enable the model to leverage both image context and user strokes to render realistic image edits.In summary, the core hypothesis is that a conditional image completion framework trained with an appropriate ambiguous sketch domain will lead to a system that can generate high-quality, controllable image edits from sketch and color strokes provided by users. The paper presents experiments and results to validate this hypothesis.


## What is the main contribution of this paper?

This paper presents a novel system for sketch-based face image editing. The main contributions are:- A new framework that enables intuitive local image editing by sketching strokes on top of an image. This allows users to edit images by providing geometry and color constraints.- A sketch domain and training procedure for convolutional neural networks that generalizes well to real user sketches. This is achieved by introducing ambiguities between the sketch domain and real image structures during training.- Formulating the problem as a combination of image completion and image translation. The system is trained end-to-end on these two tasks jointly. - A network architecture and training procedure that enables stable training on high-resolution images.- An intuitive sketch-based interface that allows interactive editing in real-time.- The ability to perform smart copy-paste editing by copying sketch representations from one image to another. This provides robustness to illumination and texture mismatches.- High-quality editing results on a variety of operations like changing facial features, expressions, and colors. The system produces globally consistent edits without visible seams or other artifacts.In summary, the key contribution is a new deep learning framework for interactive local image editing using sketching. This is enabled by technical contributions like the sketch domain, network architecture, and training procedure. The interface allows easy exploration of editing options and facilitates an efficient workflow.
