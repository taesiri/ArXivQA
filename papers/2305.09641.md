# [FitMe: Deep Photorealistic 3D Morphable Model Avatars](https://arxiv.org/abs/2305.09641)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to acquire high-fidelity and relightable human avatars from single or multiple unconstrained facial images. The key points are:- They introduce FitMe, a deep facial reflectance 3DMM that can generate high-resolution facial reflectance and shape. It consists of a multi-modal style-based generator for facial texture and a PCA-based model for shape.- They create a large facial reflectance dataset from a public dataset using image translation and augment it to balance skin tones.- They employ fast differentiable rendering to enable optimization of the model parameters to fit an input image. This uses diffuse and specular shading for more photorealism.- The fitting process combines 3DMM fitting and style-based GAN inversion to capture both shape and reflectance accurately. Fine-tuning the GAN improves results.- Experiments show the method achieves state-of-the-art in terms of identity preservation, reflectance acquisition, and identity similarity from single images. Using multiple images produces impressive scan-like reconstructions.In summary, the key research hypothesis is that combining a deep generative reflectance model with optimization through differentiable rendering enables reconstructing high-fidelity and relightable avatars from unconstrained facial images.


## What is the main contribution of this paper?

The main contribution of this paper is the introduction of FitMe, a deep 3D morphable model that can generate high-resolution facial shape and reflectance. Specifically:- It presents the first 3DMM capable of generating high-resolution facial reflectance and shape that can be photorealistically rendered, using an increasing level of detail.- It introduces the first branched multi-modal style-based progressive generator of facial assets (diffuse albedo, specular albedo, and normals) along with a suitable multi-modal branched discriminator.- It acquires and augments a large facial reflectance dataset from a public dataset using histogram matching to balance skin tones. - It develops a multi-modal generator projection method optimized with diffuse and specular differentiable rendering.The key outcomes are:- High-fidelity and relightable facial shape and reflectance reconstruction from single or multiple unconstrained images.- State-of-the-art facial reflectance acquisition and identity preservation on single images. - Highly detailed scan-like reconstructions from just a few images of the same person.- Photorealistic rendering capabilities by directly using the reconstructed assets in common engines. - Fast optimization (under 1 minute) enabling practical avatar creation.In summary, the main contribution is a complete pipeline for creating photorealistic 3D facial avatars from images using a novel deep 3DMM and optimization method. The results bridge the gap between 3DMMs and real human faces.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper introduces FitMe, a method to create realistic and relightable 3D facial avatars from single or multiple images, using a style-based generator to model facial reflectance, a PCA model for shape, and differentiable rendering optimization to fit the model to images and fine-tune it for photorealism.
