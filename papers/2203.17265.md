# [A 23 MW data centre is all you need](https://arxiv.org/abs/2203.17265)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:Can a rigorous application of the Central Limit Theorem be used to predict the future trajectory of technological progress, and specifically the date/time at which progress will peak?The authors apply the Central Limit Theorem to historical data on technological progress to predict that progress will peak on July 20, 2032 at 3:07am BST. They then explore the implications of this prediction, focusing on how a large enough computing system (~23MW data center) could be used at the peak moment to influence future spelling conventions and create linguistic "lock in."So in summary, the main hypothesis is that the Central Limit Theorem can be used to accurately predict the peaking of technological progress, and that control of sufficient computing power at the peak moment presents opportunities for long-term influence over things like dominant spelling conventions. The paper explores this hypothesis and its implications.


## What is the main contribution of this paper?

The main contribution of this paper appears to be proposing a novel approach for predicting the future trajectory of technology based on applying the Central Limit Theorem to historical trends. The key claims are:- Technology progress, as measured by metrics like transistor density and computing power per dollar, has followed an exponential trend that can be modeled as a Gaussian distribution based on the Central Limit Theorem. - This allows predicting that technological progress will peak at a specific date and time - July 20, 2032 at 3:07am BST.- The authors then explore the implications of this predicted decline in technological progress, such as opportunities for "linguistic lock-in" of certain spelling conventions by controlling language models and spell checkers trained around the peak progress time.So in summary, the main contribution seems to be using the Central Limit Theorem to make a statistical prediction about the trajectory of technological progress, with some speculative exploration of the consequences. The proposal to influence spelling conventions through language model manipulation around the predicted peak time is a more concrete methodological contribution.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes using a large data center to influence the default spelling of "color" vs "colour" in future AI systems, in order to promote the British spelling convention.


## How does this paper compare to other research in the same field?

Here are my thoughts on how this paper compares to other research in its field:- The paper takes a humorous approach to making predictions about future technology, which is unique compared to more serious forecasting papers. The use of satire and hyperbole to critique research trends is quite novel.- However, the overall theme of predicting an eventual slowdown or peak in the pace of technological progress has been explored seriously by other researchers. The idea of an "S-curve" for technology growth has been proposed in various forms. - Fitting trends to bell curves/Gaussians and invoking the Central Limit Theorem as a forecasting technique seems very tongue-in-cheek here. Most technology forecasting relies on more complex modeling and expertise in specific domains.- The proposal to manipulate future spell checkers via biased training data is amusing but doesn't seem like a feasible research contribution compared to papers on AI ethics and alignment.- The references Engage with real sources in a playful way, which adds to the parody. But the core topic of predicting technological change is well-established in the literature.- Overall, this paper stands out for its humor and ability to satirize academic writing conventions. The lighthearted critique of the technology forecasting field is entertaining but does not attempt to make a serious research contribution compared to other papers. It's more a clever academic parody than a rigorous study.


## What future research directions do the authors suggest?

The authors suggest a few potential future research directions in the conclusion:- Using a mixture-of-Gaussians model instead of a single Gaussian to better conform to conformal cyclic cosmology. However, they note this may be computationally infeasible. - Developing a new time and date scheme based on standard deviations from the technology Gaussian curve, though the two-to-one mapping from years to standard deviations may cause issues.- Further research to quantify whether the two-to-one mapping from years to standard deviations in the proposed new date scheme will be problematic. So in summary, the main future directions mentioned are:- Exploring more complex statistical models like mixture-of-Gaussians- Developing alternative date/time systems aligned with their Gaussian technology prediction- Validating and dealing with potential issues in the proposed new date schemeThe authors seem to focus on ways to build upon or refine their Gaussian modeling approach for technology forecasting.
