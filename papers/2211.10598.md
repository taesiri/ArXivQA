# [LidarGait: Benchmarking 3D Gait Recognition with Point Clouds](https://arxiv.org/abs/2211.10598)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research questions/hypotheses addressed in this paper are:1. Can 3D point cloud data from LiDAR sensors be effectively utilized for gait recognition, providing more robust and accurate identification compared to traditional camera-based methods? 2. How can we design an effective framework/model architecture to extract discriminative gait features from 3D point clouds for identification, given the different data representation compared to 2D images?3. How significant is the benefit of using precise 3D structural information from LiDAR for gait recognition, compared to camera-based approaches that rely only on 2D silhouettes?4. How does LiDAR-based gait recognition perform on various challenges encountered in unconstrained real-world conditions (occlusions, clothing, viewpoints etc.), compared to camera-based methods?5. Is LiDAR more suitable for gait recognition in outdoor environments compared to traditional RGB cameras?To summarize, the key research focus is on investigating LiDAR for 3D gait recognition, proposing a model architecture to effectively extract gait features from point clouds, and benchmarking its performance against camera-based methods on various real-world conditions using a new large-scale dataset. The overarching hypothesis is that LiDAR provides more robust gait recognition by capturing precise 3D structural information.


## What is the main contribution of this paper?

 Here are the main contributions of this paper:1. The paper introduces SUSTech1K, the first large-scale LiDAR-based gait recognition benchmark dataset. It contains 25,239 sequences from 1,050 subjects, captured both by a LiDAR sensor and an RGB camera. The dataset has diverse variations like occlusions, views, carrying objects, clothing changes, etc. 2. The paper proposes a novel LiDAR-based gait recognition method called LidarGait. It projects the 3D point clouds to depth maps and uses CNNs to extract discriminative gait features. Experiments show LidarGait outperforms other point-based and silhouette-based methods significantly.3. The paper provides a comprehensive study and comparison of LiDAR-based and camera-based gait recognition. Experiments demonstrate that LiDAR provides more robust gait features compared to cameras, especially for challenging conditions like nighttime, occlusion, etc. The results highlight the advantages of using 3D information for gait recognition.4. Through ablation studies, the paper validates the importance of 3D geometric information for gait recognition. It also analyzes the impact of different projection views of point clouds.In summary, the main contribution is introducing LiDAR for gait recognition, building a large-scale LiDAR gait benchmark, and proposing an effective LiDAR-based gait recognition method, outperforming prior arts. The paper convincingly demonstrates the practical significance of using LiDAR sensors for gait recognition in the real world.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:The paper introduces SUSTech1K, the first large-scale LiDAR-based gait dataset with 25,239 sequences from 1,050 subjects, and proposes LidarGait, a new gait recognition method that projects 3D point clouds into depth maps and uses CNNs to extract fine-grained features, outperforming existing camera-based and point-based methods.


## How does this paper compare to other research in the same field?

 Here are some thoughts on how this paper on LidarGait for 3D gait recognition compares to other research in this field:- Most prior work on gait recognition has focused on using 2D camera images and silhouettes. This paper explores using 3D LiDAR point clouds for gait recognition, which provides more precise 3D structural information about the human body shape and motion. - The proposed LidarGait method outperforms prior state-of-the-art camera-based gait recognition methods by a significant margin on the new SUSTech1K dataset introduced in this paper. This suggests 3D LiDAR data can enable more robust gait recognition, especially for challenging real-world conditions.- The authors compare LidarGait to several existing 3D point cloud classification methods like PointNet, PointNet++, etc. They show LidarGait outperforms these generic point cloud methods, indicating the need for specialized architectures for gait recognition on 3D point clouds.- The lidar-based gait recognition research is still relatively new. Prior lidar gait datasets were limited to just a few tens of subjects. The SUSTech1K dataset introduced here has 1050 subjects, making it the largest lidar gait dataset and enabling more robust evaluation.- The diversity of conditions in SUSTech1K (occlusions, clothing, viewpoints, etc.) also allows for evaluating gait recognition under challenging realistic scenarios, advancing the state-of-the-art.- The multi-modal nature of SUSTech1K, with synchronized LiDAR and camera data, enables research into sensor fusion approaches for even more robust gait recognition.In summary, this paper pushes gait recognition research forward into using more informative 3D data from LiDAR in place of cameras, shows promising results on a new diverse benchmark dataset, and opens up directions for future work. The results convincingly demonstrate the practical benefits of LiDAR-based gait recognition.


## What future research directions do the authors suggest?

 Based on my reading of the paper, the authors suggest the following future research directions:1. Improving performance on umbrella subset: The paper showed suboptimal performance when subjects carried umbrellas, likely due to misalignment issues from including the umbrella in the projection images. The authors suggest exploring approaches like umbrella removal or training with random erasing to address this. 2. Multi-modal fusion: The SUSTech1K dataset provides both LiDAR and RGB data, enabling future exploration of sensor fusion approaches. The authors suggest that combining the two modalities could lead to improved performance.3. Generalizability to new datasets: While the proposed LidarGait method achieved strong results on SUSTech1K, evaluating generalizability on additional datasets with different data distributions would be valuable future work.4. Advanced point cloud architectures: The authors suggest investigating more advanced point cloud architectures tailored for fine-grained feature extraction could further improve LidarGait's capabilities.5. Dense point cloud input: The Velodyne LiDAR used provides relatively sparse point clouds. Testing with dense point clouds from sensors like solid-state LiDAR could reveal new insights.6. Multi-person gait recognition: The current work focuses on single person gait recognition. Extending to multi-person scenarios would increase applicability for real-world usage.7. Connections to re-identification: Establishing connections between gait recognition and person re-identification could lead to beneficial knowledge transfer between the domains.In summary, the main future directions focus on improving single modality performance, exploring multi-modal fusion, testing generalizability, tailoring point cloud architectures for gait, leveraging advanced sensors, and extending to multi-person scenarios. Advancing research in these areas could significantly push the frontiers of gait recognition using LiDAR and point clouds.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points from the paper:This paper introduces SUSTech1K, the first large-scale LiDAR-based gait dataset with 1,050 subjects and 25,239 sequences to enable research on gait recognition using 3D point clouds. The dataset captures synchronized streams from a LiDAR sensor and RGB camera in outdoor environments and includes diverse real-world variations like changing clothes, object carrying, poor lighting etc. The authors propose LidarGait, a simple yet effective 3D gait recognition method that projects point clouds into depth maps and applies CNNs to extract features. Experiments show LidarGait outperforms other point-based and silhouette-based methods, benefiting from precise 3D structure information. The results also demonstrate LiDAR's superiority over RGB cameras for gait recognition outdoors. Overall, this paper highlights the potential of LiDAR sensors to bring human-like 3D perception for robust gait recognition in challenging real-world conditions.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:The paper introduces SUSTech1K, a new large-scale LiDAR-based gait dataset for 3D gait recognition research. The dataset contains 25,239 sequences captured from 1,050 subjects using a LiDAR sensor and RGB camera. It covers many variations like different views, occlusion, clothing, carrying conditions, and scenes. The dataset provides synchronized streams of point clouds, RGB images, and silhouettes. Compared to existing gait datasets, SUSTech1K is larger in scale, contains more real-world variations, and provides precise 3D point cloud data.The paper also proposes LidarGait, a new gait recognition method using point cloud projections. LidarGait first projects the 3D point clouds into depth maps from the LiDAR's range view perspective. It then applies convolutional networks on these depth maps to extract discriminative gait features containing 3D structural information. Experiments on SUSTech1K show LidarGait outperforms other point-based methods and camera-based silhouette methods by a large margin. The results demonstrate the effectiveness of using LiDAR data and 3D geometry for robust gait recognition, especially in challenging real-world conditions. The paper provides a new gait benchmark and method to advance gait recognition research.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes a novel lidar-based gait recognition method called LidarGait. The key ideas are:1. Projecting 3D lidar point clouds into 2D depth images from the front view of the lidar sensor. This allows applying convolutional networks to extract fine-grained gait features from the projected depths. 2. Using a CNN encoder to extract spatial features from the sequential projected depths. 3. Applying temporal set pooling to aggregate frame-level features into a sequence-level representation. 4. Training the model with a combined loss of triplet loss and cross-entropy loss.In summary, the LidarGait method projects lidar point clouds into 2D depth images to leverage the power of CNNs for fine-grained feature extraction. It then aggregates the spatial-temporal information using set pooling to obtain a sequence-level gait representation for recognition. This allows lidar-based gait recognition to achieve better performance than existing camera-based and other lidar methods.


## What problem or question is the paper addressing?

 Based on my review, the key points about the problem this paper is addressing are:- Existing camera-based gait recognition methods lack 3D geometry information and have poor feasibility in real-world scenarios due to visual ambiguity. - There is a lack of datasets with accurate 3D gait representations to enable data-driven 3D gait recognition research.- Current point-based models designed for 3D object classification do not perform well for gait recognition from point clouds, indicating the need for specialized point-based models for this task.Specifically, the paper identifies two main limitations of current gait recognition research:1. Camera-based methods only use 2D silhouette or appearance information from a single view, lacking precise 3D structural information. This makes them less robust in complex real-world conditions. 2. There is a lack of large-scale datasets with accurate 3D gait representations (point clouds) to enable data-driven 3D gait recognition research. Existing datasets either use camera images or have very few subjects.To address these limitations, the paper introduces a new LiDAR-based gait dataset called SUSTech1K and proposes a LiDAR-based gait recognition method called LidarGait. The goal is to demonstrate the benefits of using 3D point clouds for gait recognition compared to traditional camera-based approaches.In summary, the key problem this paper tries to address is the lack of 3D geometry information and real-world feasibility in current gait recognition research, by utilizing LiDAR point clouds and releasing a new large-scale 3D gait dataset.
