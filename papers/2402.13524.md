# [OMGEval: An Open Multilingual Generative Evaluation Benchmark for Large   Language Models](https://arxiv.org/abs/2402.13524)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Most existing generative evaluation benchmarks for large language models (LLMs) focus on English, lacking multilingual and cross-cultural perspectives. This limits our ability to evaluate the capabilities of LLMs across diverse global users. 

- Existing multilingual datasets mainly target discriminative tasks like classification, which are not well suited to assess the open-ended generative abilities of LLMs.

Proposed Solution:
- The paper introduces OMGEval, the first open-source, multilingual generative evaluation benchmark tailored for LLMs. 

- OMGEval provides over 800 open-ended questions in 5 languages - Chinese, Russian, French, Spanish, Arabic. The questions test 9 key capabilities like reasoning, knowledge, code comprehension etc.

- The questions are localized to fit the cultural context of each language. For example, names of people, places, foods are adapted to be culturally relevant. This helps better simulate real-world language usage.

- GPT-4 is used as an automated evaluator to score model outputs, showing high correlation with human judgments.

Key Contributions:  
- OMGEval enables standardized assessment of multilingual LLMs through localization, expanding generative evaluation beyond English.

- Analysis of models on OMGEval gives insights into current capabilities and gaps, especially for open-source models, in processing cultural nuances.

- The benchmark and analysis highlight the need to improve cultural awareness in LLMs to serve global users better.

Overall, the paper makes an important pioneering effort towards equitable, cross-cultural evaluation of LLMs through OMGEval.
