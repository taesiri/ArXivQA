# [Large Scale Adversarial Representation Learning](https://arxiv.org/abs/1907.02544)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is whether progress in image generation quality translates to improved representation learning performance. Specifically, the authors investigate whether extending the BigGAN model for image generation to learn an encoder as well (creating BigBiGAN) results in state-of-the-art unsupervised representation learning on ImageNet.The key hypothesis is that powerful generative models like BigGAN capture useful semantic information about complex image distributions like ImageNet, and that learning an encoder within this BigBiGAN framework will allow extracting these semantics in the form of useful representations for downstream tasks.In summary, the central hypothesis is that by extending BigGAN to BigBiGAN, the resulting model will achieve state-of-the-art unsupervised representation learning by leveraging the semantic information learned by BigGAN during generative modeling of images.


## What is the main contribution of this paper?

The main contribution of this paper is introducing BigBiGAN, an unsupervised learning method based on generative adversarial networks (GANs) that achieves state-of-the-art results on unsupervised representation learning on ImageNet. The key ideas are:- Leveraging BigGAN, a state-of-the-art generative model for image generation, as the generator in a bidirectional GAN (BiGAN/ALI) framework. This translates the strong image generation capabilities of BigGAN into learning good feature representations in the encoder.- Modifying the discriminator to have additional unary terms on the data and latents, besides just the joint term, which helps stabilize training.- Using a higher resolution encoder than generator/discriminator, allowing the encoder to learn from richer signals.- Careful architecture exploration and training modifications (like decoupled learning rates) to optimize the approach.Through extensive experiments, the paper shows that BigBiGAN matches or exceeds prior state-of-the-art in unsupervised ImageNet classification, including methods based on self-supervision. It also demonstrates improved image generation capabilities over BigGAN. The representations learned by BigBiGAN are applied successfully for image retrieval through nearest neighbors search.Overall, the paper makes progress on representation learning through generative models, showing they can compete with and even surpass discriminative self-supervised techniques on large and complex datasets like ImageNet. It also provides evidence that representation learning can in turn benefit generation quality.
