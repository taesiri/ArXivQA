# [iSeg: Interactive 3D Segmentation via Interactive Attention](https://arxiv.org/abs/2404.03219)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Existing 3D segmentation techniques rely on datasets and pre-defined parts, limiting them to specific shape domains. Recent works utilize 2D foundation models but text prompts may be insufficient for accurate fine-grained 3D segmentations. 
- Applying 2D models directly suffers from view inconsistency, as occluded regions are not visible together from any single view.

Proposed Solution: 
- Present iSeg, an interactive 3D segmentation technique based on user clicks directly on the shape surface. Clicks can indicate inclusion/exclusion of regions.
- Propose a novel interactive attention module to handle variable numbers and types of clicks, enabling training a single unified interactive segmentation model.
- Distill features from a 2D foundation model to a 3D mesh feature field (MFF) over the surface. Decode MFF and clicks to segment the mesh interactively.
- Train with 2D supervision by projecting clicks and predicted segmentation to images. Fuse inconsistent 2D signals into a coherent 3D segmentation.

Main Contributions:
- Interactive fine-grained 3D segmentation based on clicks, beyond text limitations. Operates directly in 3D for consistency.
- Unified model for variable user clicks via interactive attention.
- Mesh feature field distilling 2D semantics while ensuring 3D coherence.
- Despite 2D supervision only, achieves native 3D segmentation and generalization.

In summary, this paper presents an interactive 3D segmentation technique that generates customized mesh partitions based on user clicks. A key contribution is the interactive attention mechanism to handle variable click inputs. The method distills features from a 2D model into a 3D field to achieve semantic coherence. Experiments show segmentation versatility for diverse shapes and fidelity to user guidance in 3D.
