# [Learning Priors for Non Rigid SfM from Casual Videos](https://arxiv.org/abs/2404.07097)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Reconstructing 3D structures and camera poses from videos containing non-rigid motion is a challenging and ill-posed problem. Current approaches make unrealistic assumptions or require long per-video optimization, limiting their practicality.

Proposed Solution:
The paper proposes TracksTo4D, a novel deep learning approach to map 2D point tracks extracted from a video to corresponding 3D structures and camera poses using a single feedforward pass. 

Key ideas:
- Leverage recent advances in point tracking to extract long-term 2D tracks from casual videos 
- Design an equivariant architecture respecting permutations of points and time-translation of frames
- Constrain output structure using a parameterized model with a rigid basis and coefficients  
- Identify rigid points to constrain camera motion and allow robustness to non-rigid motion
- Train only using 2D tracks as supervision without any 3D labels

Results:
- Trained on casual videos of pets and generalizes to unseen classes
- Produces state-of-the-art accuracy for both camera and structure 
- Orders of magnitude faster inference than optimization-based techniques
- Demonstrates strong generalization even to scenes like Sintel

Main Contributions:
1) Equivariant network mapping 2D tracks to 3D structure and camera motion
2) Method to identify rigid points for constraining camera poses
3) Training framework using only 2D supervision 
4) State-of-the-art accuracy and efficiency for non-rigid SfM
5) Strong generalization across domains without fine-tuning

In summary, the paper presents a highly practical deep learning solution to the challenging problem of non-rigid 3D reconstruction from monocular video. By designing the method around 2D point tracks, it achieves efficiency, accuracy and generalization unprecedented in prior work.
