# [Learning Neural Parametric Head Models](https://arxiv.org/abs/2212.02761)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be how to develop an improved 3D morphable model for complete human heads based on neural fields that can disentangle identity and expressions. The key ideas and contributions seem to be:- Proposing a novel neural parametric head model based on hybrid neural fields that can represent complete heads including hair geometry while disentangling identity and expressions in separate latent spaces.- Introducing a new high-fidelity head dataset captured with a custom setup to train the model, comprising over 5,200 3D scans from 255 people.- Using an ensemble of local implicit fields anchored at facial keypoints to represent identity geometry, sharing weights between symmetric regions.- Modeling expressions with a global deformation field conditioned on identity. - Demonstrating improved performance over PCA-based and other neural 3DMMs in fitting the model to sparse input point clouds and reconstructing unseen identities and expressions.So in summary, the main research goal appears to be developing an improved neural model for complete head geometry that can generalize better while disentangling identity and expressions, enabled by a new high-quality training dataset. The proposed hybrid local-global neural field approach seems central to achieving this.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel 3D morphable model for complete human heads based on neural fields. The key ideas are:- Representing the identity-specific geometry of a head implicitly using a signed distance field (SDF) in a canonical space. This allows modeling complete heads with hair, unlike template mesh-based approaches. - Decomposing the SDF into an ensemble of local implicit models anchored at facial keypoints. This imposes a useful prior for representing heads. - Modeling facial expressions using a neural deformation field operating in the ambient space. This disentangles identity and expression spaces.- Capturing a new dataset of over 5,000 high-fidelity 3D head scans to train the model, which is significantly larger and higher quality than previous datasets.- Demonstrating that the proposed neural parametric head model can be robustly fit to sparse point cloud data, outperforming state-of-the-art methods in reconstruction quality.In summary, the main contribution is presenting a new neural field-based 3D morphable model for heads that combines an ensemble of local implicit functions with a learned deformation model. The results show this approach can represent complete heads at higher quality compared to previous methods.
