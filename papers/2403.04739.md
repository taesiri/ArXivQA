# [I Can't Believe It's Not Scene Flow!](https://arxiv.org/abs/2403.04739)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Current scene flow methods fail to accurately estimate motion of small, rare objects like pedestrians even though they seem to perform well on average error metrics. This is because average error metrics are dominated by large, common objects like cars.
- Standard evaluation protocols like Threeway EPE hide these failures by not providing class-specific or speed-normalized performance.

Proposed Solution:
- Introduce a new evaluation protocol called \oureval{} that reports class-specific, speed-normalized errors to reveal performance on rare classes.
- Propose a simple but effective baseline scene flow method called \ourmethod{} that combines a top-performing detector with a basic tracker.

Key Contributions:

1. Reveal qualitative failures of state-of-the-art scene flow methods on small, rare objects through cherry-picked visualizations.

2. Propose \oureval{}, a class-aware, speed-normalized evaluation protocol that reveals poor performance of methods on pedestrians and other small objects.

3. Introduce \ourmethod, a strong baseline scene flow method that leverages a top detector and basic tracker to capture state-of-the-art performance on standard metrics and significantly outperform prior work on the proposed \oureval{} protocol.

4. Show that supervised scene flow methods need to address class imbalance issues by properly weighting rare classes, similar to how modern detectors handle class imbalance.

In summary, this paper clearly reveals deficiencies in current scene flow evaluation protocols and estimation methods when it comes to small, rare objects. The proposed solutions offer the community clear direction on improving evaluation and estimation quality for these critical object classes.


## Summarize the paper in one sentence.

 This paper proposes a new evaluation metric for scene flow that is class-aware and speed-normalized, and shows that a simple method of detecting objects and tracking their motion outperforms prior state-of-the-art scene flow techniques, revealing their failure to capture motion of small objects like pedestrians.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Raising alarm bells about the qualitative failure of state-of-the-art scene flow methods on important classes of small objects like pedestrians. The paper shows visually that existing methods fail to capture the motion of pedestrians even in simple scenes.

2. Providing a new evaluation protocol called \oureval{} that is class aware and speed normalized. This allows quantifying the poor performance of existing methods on small object classes.

3. Providing a simple but effective baseline method called \ourmethod{} that combines a high-quality 3D object detector with a Kalman filter tracker. This baseline method achieves state-of-the-art results on existing metrics like Threeway EPE and also significantly outperforms prior methods on the new \oureval{} metric, especially on small object classes like pedestrians.

In summary, the paper sounds alarm bells about the failure of existing scene flow methods on small objects, proposes a new evaluation methodology to reveal these failures, and provides a strong baseline to highlight the gaps that exist in current supervised scene flow approaches. The overall goal is to push the community to build better scene flow methods that work across object classes, not just on prominent vehicles.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the main keywords and key terms associated with this paper include:

- LiDAR Scene Flow - The paper focuses on estimating scene flow from sequential LiDAR point clouds.

- Autonomous Vehicles - The experiments and evaluations are done on datasets from the autonomous driving domain. 

- Pedestrian Motion - A major focus of the paper is highlighting the failure of existing methods to capture pedestrian motion.

- Class Imbalance - The paper discusses the class imbalance in LiDAR scenes and how that impacts evaluation.

- Evaluation Protocol - The paper proposes a new evaluation protocol called Bucket Normalized EPE that is class and speed aware. 

- Object Detection - The proposed TracktorFlow method utilizes an object detector and tracker to generate scene flow.

- Bounding Boxes - TracktorFlow relies on bounding boxes from detection and tracking to estimate rigid scene flow.

- Vulnerable Road Users (VRUs) - Besides pedestrians, the paper also discusses issues with capturing motion of other VRUs like bicyclists.

- Static vs Dynamic Scene Flow - The paper analyzes both static and dynamic scene flow estimation performance.

In summary, the main topics are LiDAR scene flow, evaluation protocols, pedestrian/VRU motion, and the use of detection and tracking.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes a new evaluation metric called "Bucket Normalized EPE". Can you explain in detail how this metric works and why it is better able to reveal performance on small objects compared to prior evaluation protocols?

2. The paper shows that current scene flow methods fail on small objects like pedestrians. What underlying reasons could explain why these methods struggle on small objects specifically? 

3. The proposed TracktorFlow method combines an object detector and tracker to generate scene flow. What advantages does leveraging the object detector provide over just using a tracker alone? How does the object detector help address class imbalance issues?

4. The paper finds that detector recall at low confidence thresholds matters more than mean Average Precision (mAP). Why does the detector recall characteristic affect TracktorFlow's performance so much? Can you explain the interaction between the detector and tracker?

5. Could the TracktorFlow framework work with a class-agnostic bounding box proposer instead of an object detector? What would be the advantages and disadvantages of this approach?

6. The paper argues that supervised scene flow methods need to address class and point imbalances. What specific techniques could be borrowed from the object detection literature to handle these imbalances?  

7. How well would you expect the TracktorFlow framework to generalize to unseen or rare objects compared to supervised scene flow methods? What changes could be made to improve open-set generalization?

8. What additional annotation modalities beyond bounding boxes could the TracktorFlow framework incorporate to estimate non-rigid scene flow? Would this allow modeling of complex non-rigid motions?

9. The paper recommends that unsupervised methods should also adopt class-aware evaluation. However, unsupervised methods do not have access to class labels. How should evaluation be approached in this setting?

10. If Lidar and camera data were both available, how could TracktorFlow be modified to take advantage of the complementary strengths of both modalities? Would performance on small objects improve further?
