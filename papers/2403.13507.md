# [FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based   LLMs](https://arxiv.org/abs/2403.13507)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Video-based large language models (LLMs) have shown impressive capabilities in video understanding tasks. However, their adversarial robustness remains unexplored. 

- Prior work has shown that introducing another modality like vision makes models more susceptible to safety issues compared to single-modality LLM counterparts. This highlights the need to study adversarial attacks for video-based LLMs.

Proposed Solution:
- The paper proposes FMM-Attack, the first adversarial attack method tailored for video-based LLMs. 

- FMM-Attack crafts imperceptible perturbations on a small fraction of frames in a video to induce incorrect or garbled responses from the victim models.

- Two objective functions target video features and LLM features respectively. A flow-based temporal mask selects the most effective frames to perturb based on optical flow.

Main Contributions:
- Comprehensive investigation regarding the vulnerability of video-based LLMs to adversarial attacks.

- Introduction of FMM-Attack, the first attack method designed specifically for video-based LLMs.

- Analysis of cross-modal feature attacks provides insights into multi-modal robustness and safety-related feature alignment.  

- Experiments demonstrate FMM-Attack can effectively trigger incorrect or garbled responses from multiple benchmark video-based LLMs by modifying less than 20% of frames.

In summary, the paper performs an in-depth exploration into the adversarial robustness of video-based LLMs, proposes a novel attack method, and provides analysis that inspires future research into ensuring reliability and security for video-based multi-modal models.
