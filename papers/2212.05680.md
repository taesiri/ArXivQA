# [REAP: A Large-Scale Realistic Adversarial Patch Benchmark](https://arxiv.org/abs/2212.05680)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How effective are adversarial patch attacks against object detectors in realistic settings? The key hypotheses appear to be:1) Existing adversarial patch attacks may be less effective against object detectors than previously believed when evaluated under realistic conditions rather than simplified simulations.  2) The attack success rate measured on synthetic or simulated data may not accurately reflect the true attack success rate under real-world conditions.3) Factors like lighting variation and constraints on patch placement have a significant impact on attack effectiveness in practice.The authors argue that previous evaluations of adversarial patch attacks have been limited because they relied on either small-scale physical tests or unrealistic synthetic simulations. This makes it hard to accurately assess the threat posed by these attacks. To address this, the authors introduce a new large-scale benchmark called REAP that allows patch attacks to be evaluated on real images under realistic conditions. They use this to test the effectiveness of existing attacks on object detectors like Faster R-CNN. The key findings from their experiments are that adversarial patches are much less effective than prior synthetic evaluations suggested, and adversarially trained detectors can defend against current attacks. This implies the threat may be less serious than believed and evaluations on synthetic data do not necessarily reflect real-world performance.In summary, the core research question is assessing how well existing adversarial patch attacks work on real object detectors under realistic conditions, rather than simplified synthetic settings. The REAP benchmark is introduced to facilitate this evaluation.
