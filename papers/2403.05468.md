# [Will GPT-4 Run DOOM?](https://arxiv.org/abs/2403.05468)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
The paper explores using large language models (LLMs) like GPT-4 for planning and reasoning in complex environments like video games. Specifically, it evaluates if GPT-4 can play the 1993 first-person shooter game Doom with minimal training, using only its reasoning and observational capabilities. 

Proposed Solution: 
The authors set up an experimental system with two main components - a Vision component (GPT-4V) that takes Doom screenshots and returns textual descriptions, and an Agent component (GPT-4 text) that decides actions based on Vision's output. For more complex strategies, additional GPT-4 models provide finer planning (Planner) or expert advice (Experts).

The Agent is prompted with allowed game actions and some rules/guidelines. Different prompting strategies are tested including: naive, walkthrough-based, plan-generating, and k-levels. Metrics like Passed Maps Average Time andDeaths-Weighted PMAT are used.

Results:
- GPT-4 is not able to directly run Doom, but can act as a proxy for the game engine using the Vision+Agent setup.
- With appropriate prompting, GPT-4 can play Doom to a reasonable degree - opening doors, moving, firing weapons. But performance is far below human level.
- Walkthrough-based prompting leads to noticeably better traversal than naive prompting. Addition of Planner and Experts further improves pathing and combat.
- Analysis shows the model has limited reasoning depth and memory. It struggles with long-term planning.

Main Contributions:
- First work exploring LLMs for playing FPS games and using visual game input.
- Demonstrates GPT-4's capability for short-term reasoning and planning in a complex game environment. 
- Introduces a modular evaluation approach using Vision and Agent components.
- Discusses prompt engineering strategies for improving LLM game playing performance.
- Highlights need for careful regulation given ease of implementing such an LLM-based game playing agent.
