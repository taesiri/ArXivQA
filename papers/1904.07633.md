# [HARK Side of Deep Learning -- From Grad Student Descent to Automated   Machine Learning](https://arxiv.org/abs/1904.07633)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central hypothesis seems to be that recent advancements in deep learning research, along with the competitive nature of the field, have led to an increase in "Hypothesizing After the Results are Known" (HARKing) behavior. 

The authors argue that practices like "grad student descent", the avoidance of publishing negative results, overfitting to benchmark datasets, and rushed claims of state-of-the-art performance are all examples of troubling trends in deep learning research that stem from HARKing. 

The paper aims to demonstrate these issues from different perspectives, such as:

- The competitiveness in DL research leading to questionable SotA claims and novelty (Section 2)

- The pressure to publish favorable results and aversion towards negative results (Section 3) 

- The belief that benchmark datasets represent real-world data (Section 4)

- The rise of automated ML methods (Section 5)

- Issues around explainability, ethics, reproducibility, etc. in AI systems (Section 6)

So in summary, the central hypothesis seems to be that HARKing behavior is increasing in deep learning research, and the authors systematically discuss its potential causes and implications from multiple viewpoints. The overall goal is to bring awareness to these issues and encourage more rigorous scientific practices in the field.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It discusses the issue of "Hypothesizing After the Results are Known" (HARKing) in machine learning and deep learning research. HARKing refers to the phenomenon where researchers form hypotheses after analyzing results, rather than specifying hypotheses beforehand. 

2. It provides examples of questionable research practices that may indicate HARKing, such as:

- Claiming improvements to state-of-the-art without sufficient analysis or justification (Section 2) 

- Avoiding reporting negative results (Section 3)

- Overfitting models to datasets that are not representative of real-world data (Section 4)

- Using automated machine learning methods like neural architecture search without proper ablation studies (Section 5)

3. It reviews HARKing in the context of goals like ethical AI, human-centric AI, explainable AI, reproducible AI, accountable AI, and privacy-aware AI (Section 6). It argues that avoiding HARKing is important for achieving these goals.

4. It calls for open discussions and cultural changes in machine learning research to address issues like publication bias and lack of hypothesis-driven methodology. It proposes some initial ideas like results-blind peer review to incentivize proper hypothesis formulation (Section 3).

In summary, this paper highlights the prevalence of questionable research practices indicative of HARKing in machine learning, provides examples, discusses implications, and calls for reforms to promote more rigorous hypothesis-driven methodology. The main contribution is bringing attention to these issues through a critical discussion.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper discusses issues with hypothesizing after results are known (HARKing) in deep learning research, such as questionable improvements to state-of-the-art methods, reluctance to publish negative results, overfitting to datasets, lack of model interpretability and accountability, and proposes ideas like results-blind peer review to improve research practices.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this paper compares to other research in the field of deep learning:

- The paper provides a thoughtful critique and analysis of some problematic trends in deep learning research methodology, especially around issues like HARKing (hypothesizing after results are known), avoiding negative results, and overfitting to benchmark datasets. This type of reflective analysis is still relatively uncommon in DL research papers, which tend to focus on novel techniques and benchmark results.

- The authors connect the issues they identify to broader concerns about reproducibility, accountability, and ethics of AI systems. Making these connections is important as the AI community grapples with the societal impacts of rapidly advancing technology. Many papers are narrowly focused on algorithmic innovations without considering the bigger picture.

- The proposal for results-blind reviewing is an interesting idea for reforming publication practices to discourage HARKing. Very few papers propose specific changes to the research and review process like this. Most criticize problems but don't suggest solutions.

- The writing style is accessible and engaging for a wide audience. Many DL papers are dense and technical. This one clearly explains key issues and provides context for readers less familiar with the field's inner workings.

- The scope is ambitious, spanning issues in methodology, benchmarks, automation, ethics, and transparency. Many papers focus on a single dimension. Tackling multiple aspects provides a more comprehensive analysis.

- The authors include industry and academic perspectives. This gives a balanced viewpoint compared to papers authored solely by academics or industry researchers. 

In summary, while many DL papers contribute incremental algorithmic advances, this one stands out for critically analyzing the research process as a whole, synthesizing connections between issues, proposing reforms, and communicating its analysis in an engaging way. More meta-analysis and reflection on the state of DL research is needed.


## What future research directions do the authors suggest?

 The authors suggest several future research directions in the paper:

- Conducting more research using a results-blind review process to reduce publication bias and encourage publishing negative results. They propose submitting papers with hypotheses and experimental design first, getting reviewed, then running the experiments and publishing regardless of the results. 

- Incorporating high-level domain experts early in research studies to help form sound a priori hypotheses. This can lead to more successful hypothesis forming and scrutiny of results that don't match expectations.

- Developing more theoretical explanations for why deep learning works, using approaches like learning theory and statistical physics. This can lead to "true" explainable AI systems designed from first principles rather than reverse engineered.

- Encouraging initiatives for reproducibility, such as reproducibility checklists, code submission policies, and workshops focused on reproducibility. Measuring and defining reproducibility in ML/DL research remains an open question.

- Taking accountability and potential negative impacts into account early when forming hypotheses and designing systems, rather than treating ethics and accountability as afterthoughts.

- Moving away from narrow metric optimizations and benchmarks towards more holistic assessments of model performance including privacy preservation, explainability, reproducibility, and ethical considerations.

In summary, the authors advocate for more scientific rigor through blind reviews, collaborations with domain experts, focusing on theoretical underpinnings, and broadening evaluation metrics beyond simple performance scores. Overall, they encourage the community to improve research practices to reduce HARKing behaviors.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper: 

The paper discusses the issue of "HARKing" (Hypothesizing After the Results are Known) in machine learning and deep learning research. It argues that the competitive nature of ML/DL research and the hype surrounding "state-of-the-art" results has led researchers to engage in questionable practices like extensive parameter tuning without sound hypotheses, avoiding negative results, and overfitting models to standard datasets. This leads to inflated claims of accuracy and generalization that often fail to hold up in real-world settings. The authors review several examples of HARKing, like grad student descent, allergy to negative results, the "in the wild" illusion of datasets, and automated ML. They argue for cultural changes like accepting negative results and registering hypotheses before experiments. Overall, the paper argues that HARKing is a troubling trend in ML/DL research that undermines scientific integrity and needs to be addressed through policy changes and discussions within the research community.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper discusses the issue of "Hypothesizing After the Results are Known" (HARKing) in machine learning and deep learning research. The authors argue that the highly competitive nature of ML/DL research has led to questionable practices such as tweaking models and metrics until marginal improvements are found, avoiding publishing negative results, and overfitting models to popular benchmark datasets. This results in inflated claims of achieving state-of-the-art results, lack of model reproducibility and generalizability, and difficulty in determining why a method does or does not work. 

The authors provide several examples of HARKing behavior from current ML/DL research practices. They propose potential solutions such as blind review of papers based on hypothesis and experimental design rather than results, as well as increased discussion around developing ethical, human-centric, explainable, and reproducible AI systems. They call for cultural changes in accepting negative results, using truly independent test data, and registering intentions before conducting experiments. The authors conclude by emphasizing the need for collaborative efforts among researchers, practitioners, reviewers, publishers, and policy-makers to address these issues and prevent HARKing, in order to develop superior ML/DL solutions for the benefit of society.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes a results-blind peer review process to address issues with HARKing (Hypothesizing After the Results are Known) in machine learning research. The key steps are:

1) A paper is submitted with a clear hypothesis and experimental design, reviewed blindly, and suggestions are provided to improve the experimental methods. 

2) Once accepted, the experiments are run. 

3) The paper gets published with a comprehensive discussion section, regardless of the results. 

The goal is to shift focus away from just positive results and towards proper hypothesis forming and experimental design. This aims to reduce incentive for HARKing by encouraging publication independent of results, allowing negative findings to be published as well. The review process focuses more on validating the hypothesis and methods rather than the end results.


## What problem or question is the paper addressing?

 The paper seems to be discussing several issues related to "hypothesizing after results are known" (HARKing) in machine learning and deep learning research. Some of the key questions and problems it addresses are:

- Competitiveness in DL research leading to questionable SotA claims and novelty (Section 2): The paper discusses how the competitiveness in improving benchmarks and claiming state-of-the-art results has led researchers to use techniques like "grad student descent" which rely more on trial-and-error rather than sound hypotheses. This makes it difficult to understand why a method works.

- Aversion towards negative results (Section 3): There is a chronic allergy towards publishing negative results in ML/DL research. This creates bias against disruptive ideas, makes it difficult to establish causality, and leads to duplication of efforts. 

- Failure of generalization (Section 4): Many ML models overfit on standard datasets and fail to generalize to real-world data. But researchers treat these datasets as representative of the real world. This is linked to HARKing as hypotheses become conditional on performance on specific datasets.

- Automated ML (Section 5): The complexity of AutoML methods makes it difficult to understand why they work well, and lack of ablation studies creates conditions for HARKing in claiming novelty.

- Issues in developing ethical, human-centric, interpretable, reproducible and accountable AI (Section 6): HARKing hinders progress in making AI systems transparent, fair, and safe. Hypotheses need to consider broader impacts right from the start.

So in summary, the key focus is on how questionable research practices like HARKing in ML/DL fields are leading to models that do not generalize well, are difficult to interpret, biased, and fraught with reproducibility issues. The paper argues these trends need to be addressed through cultural changes and mechanisms to prevent HARKing.
