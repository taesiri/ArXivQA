# [A Glitch in the Matrix? Locating and Detecting Language Model Grounding   with Fakepedia](https://arxiv.org/abs/2312.02073)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper introduces Fakepedia, a novel counterfactual dataset for evaluating language models' ability to ground their responses based on contextual information, even when it contradicts the models' internal factual knowledge. Through behavioral experiments across models like GPT-4 Turbo and Mistral-7B, the authors find nuanced grounding capabilities, with Mistral-7B being most robust in grounding despite factual clashes. To deeply analyze the underlying mechanisms, the paper presents a rigorous causal mediation technique called Masked Grouped Causal Tracing (MGCT) to relate model computations to grounded vs ungrounded behaviors. Key findings show grounding operates in a more distributed fashion compared to localized factual recall, with critical differences in a few MLP activations predicting ungrounded responses. By observing computational patterns alone, the method can detect ungrounded behaviors with 92.8% accuracy. The paper contributes new counterfactual datasets, extensive behavioral analysis, an improved generalizable causal method, and insights complementing existing understanding of factual recall to advance knowledge on the mechanics of grounding in language models.
