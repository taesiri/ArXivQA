# [Multiscale Tensor Decomposition and Rendering Equation Encoding for View   Synthesis](https://arxiv.org/abs/2303.03808)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to improve the quality of view synthesis from multi-view images. The key hypotheses are:

1. Representing a scene with a multiscale tensor decomposition will lead to faster convergence and better rendering quality compared to a single-scale representation. 

2. Encoding the rendering equation in the feature space will facilitate modeling complex view-dependent effects compared to directly encoding the view directions.

Specifically, the paper proposes a new method called the neural radiance feature field (NRFF) with two main contributions:

1. A multiscale tensor decomposition scheme to represent scenes from coarse to fine scales. This is shown to enable faster convergence and better rendering quality with fewer learnable features compared to single-scale methods.

2. Encoding the rendering equation in the feature space using anisotropic spherical Gaussians instead of directly encoding view directions. This provides the MLP with more knowledge about the rendering process to better model view-dependent effects.

The central hypothesis is that combining these two ideas - multiscale representation and rendering equation encoding - will advance the quality of view synthesis compared to existing state-of-the-art methods. Experiments on synthetic and real datasets validate the efficacy of the proposed NRFF method.
