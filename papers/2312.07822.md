# [Prototypical Self-Explainable Models Without Re-training](https://arxiv.org/abs/2312.07822)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes KMEx, a simple yet efficient method to convert any pre-trained black-box model into a prototypical self-explainable model (PSEM) without needing to retrain the base model. PSEMs provide inherent global and local explanations through visualizable class-representative prototypes. To facilitate adoption of PSEMs, KMEx keeps the trained encoder intact, learns prototypes via clustering in the embedding space, and replaces the classifier with a transparent nearest-neighbor one. Experiments across datasets show KMEx matches the black-box performance while offering interpretability. The paper also introduces a comprehensive evaluation framework grounded in PSEM predicates - transparency, diversity and trustworthiness. Using novel metrics, the framework exposes issues overlooked before, like unused "ghosted" prototypes giving false sense of model concepts. Most importantly, it enables objective comparison of model strengths/weaknesses. For example, KMEx suffers little ghosting and is most faithful to the black-box, while other PSEMs have tradeoffs. Overall, KMEx offers an efficient PSEM baseline to build on, and the evaluation framework paves way toward reliable and objective advancement of self-explainable AI.
