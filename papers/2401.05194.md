# [Modelling, Positioning, and Deep Reinforcement Learning Path Tracking   Control of Scaled Robotic Vehicles: Design and Experimental Validation](https://arxiv.org/abs/2401.05194)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Mobile robotic systems are becoming popular for applications like warehousing, manufacturing, and testing advanced control algorithms. Scaled robotic cars serve as effective platforms for developing and testing autonomous driving solutions. 
- Accurate estimation of vehicle states like position and orientation is critical for functions like path planning and tracking in these systems. Sensor fusion using Extended Kalman Filter (EKF) is a proven technique but has scope for improvement in accuracy and tolerance to sensor failures.  
- Deep Reinforcement Learning (DRL) holds promise for adaptive path tracking but suffers from simulation-to-reality gap and slow training.

Proposed Solutions:
- A Federated Extended Kalman Filter (FEKF) that fuses outputs of two local EKFs based on different vehicle models to improve positioning accuracy. The no-reset architecture enhances robustness to sensor faults.
- A DRL path tracking controller incorporating expert demonstrator actions in the reward function to enable faster training and increased robustness. The expert demonstrator uses a Linear Quadratic (LQ) control strategy.  

Key Contributions:
- Simple and effective two-stage Least Squares method for identifying parameters of longitudinal and lateral vehicle dynamics models.
- FEKF design that combines outputs of local EKFs based on kinematic and dynamic models to refine state estimates using all available sensors.
- Novel DRL path tracking controller training strategy using expert demonstrator to mitigate simulation-to-reality gap.
- Experimental validation of vehicle model, FEKF design and DRL controller showing precise path tracking on different manoeuvres not considered during training.
- Comparison of DRL controller against benchmark algorithms using key performance metrics demonstrating superior accuracy and lower control effort.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper presents a toolchain for controlling mobile robots including vehicle modeling, parameter identification, federated extended Kalman filtering for positioning, and a deep reinforcement learning path tracking controller trained via an expert demonstrator.


## What is the main contribution of this paper?

 This paper makes several contributions related to modelling, positioning, and path tracking control of scaled robotic vehicles:

1) It proposes a federated extended Kalman filter (FEKF) composed of two local EKFs and a master filter to fuse sensor data and improve positioning accuracy. The FEKF leverages multiple onboard sensors like IMU, lidar, and encoder.

2) It presents a novel deep reinforcement learning (DRL) based path tracking controller trained via an expert demonstrator. Using the demonstrator speeds up learning and increases robustness to simulation-to-reality gaps. Experiments show the DRL agent can outperform model-based controllers.

3) It details a two-stage least squares procedure to identify parameters of a longitudinal and lateral vehicle dynamics model. This model supports design of the FEKF and serves as a digital twin to train the DRL algorithm.

4) Experimental validation of the FEKF, vehicle model, and DRL path tracking controller on a Quanser QCar. Comparisons to benchmark controllers demonstrate improved performance.

In summary, the main contributions are: 1) FEKF for multi-sensor positioning, 2) DRL path tracking with expert demonstrations, 3) vehicle modelling and identification, and 4) experimental demonstration on a robotic test vehicle.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Scaled robotic vehicles - The paper focuses on control and state estimation methods for scaled robotic cars which are used as test platforms for autonomous driving algorithms.

- Vehicle modeling - A dynamic bicycle model and a kinematic point model are formulated to describe the longitudinal and lateral dynamics of the robotic vehicle. Model parameters are identified experimentally.

- State estimation - A federated extended Kalman filter (FEKF) is proposed to fuse data from multiple sensors like IMU, lidar, encoder to estimate the vehicle states like position, velocity etc. This aims to improve localization accuracy.

- Path tracking control - A deep reinforcement learning (DRL) based path tracking controller is designed and trained in simulation using the vehicle model as a digital twin. It uses an expert demonstrator to guide learning.

- Experimental validation - Both the state estimator and DRL controller are validated experimentally on the Quanser QCar platform, showing good performance in tracking various test trajectories.

- Performance comparison - The DRL controller is benchmarked against feedforward-feedback and linear quadratic (LQ) controllers using key metrics like maximum error, RMS error etc.

Some other keywords: simulation-to-reality transfer, reward function design, lateral vehicle control.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1) The paper proposes a two-stage least squares method for identifying the parameters of the longitudinal and lateral vehicle dynamics models. What are the advantages of using a two-stage approach compared to identifying all parameters simultaneously? How does breaking the identification into two steps simplify the overall process?

2) The federated extended Kalman filter fuses estimates from two local extended Kalman filters, one using a bicycle model and one using a kinematic point model. What are the potential advantages of fusing estimates from models with different complexities/fidelities? How does this promote fault tolerance?

3) The paper mentions using a no-reset architecture for the federated Kalman filter. What specifically does the no-reset configuration entail and why does this make the filter more robust to sensor faults? 

4) The reward function for the DRL-based path tracking controller includes a term that penalizes deviation from an expert demonstrator's actions. Why is it useful to include demonstrations from an expert policy in DRL training? How does this mitigate the simulation-to-reality gap?

5) What specific expert demonstrator policy is used for the DRL path tracking training in this paper? What are the advantages of the particular expert policy chosen compared to other potential options?

6) The DRL agent uses the derivative of steering angle as its action output rather than steering angle directly. What is the motivation behind choosing the rate of change of steering angle as the action? How does this impact learning and actual driving behavior?

7) What types of reference paths were used to train the DRL agent in simulation? What factors need to be considered in selecting appropriate training paths to ensure the agent generalizes well to real test cases?

8) Quantitative tracking performance of the DRL agent is compared to other controllers using specific key performance indicators. What were these performance metrics and what did they reveal about the relative strengths of the DRL approach?

9) How was the vehicle model used in the design of the state estimator? What role does having an accurate model play in enabling precise estimation of states that are difficult to measure directly?

10) The paper identifies parameters of separate longitudinal and lateral vehicle dynamics models using a two-stage least squares approach. What considerations need to be made in identifying lateral and longitudinal dynamics separately? How are the model structures and parameters coupled?
