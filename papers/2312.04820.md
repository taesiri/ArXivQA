# [Learn to Optimize Denoising Scores for 3D Generation: A Unified and   Improved Diffusion Prior on NeRF and 3D Gaussian Splatting](https://arxiv.org/abs/2312.04820)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a unified framework called LODS (Learn to Optimize Denoising Scores) to enhance diffusion priors for high-fidelity 3D generation tasks. The key insight is that there is a divergence between the training and inference stages of diffusion models due to the use of classifier free guidance (CFG) only during inference. This causes the commonly used SDS loss to direct the 3D model optimization towards a CFG-modified distribution rather than the actual learned distribution, resulting in suboptimal quality. To address this, LODS introduces additional learnable parameters and iteratively optimizes both the 3D model and the diffusion prior to align them better. Two variants are presented - using a learnable unconditional embedding or low-rank model parameters. Experiments demonstrate state-of-the-art text-to-3D generation quality using NeRF and 3D Gaussian splatting backbones. The simple embedding-based LODS approach significantly improves results with minimal code changes. Besides advancing text-to-3D generation, LODS also shows strong qualitative performance on image-to-3D generation and 2D image editing tasks.
