# [Breast Cancer Classification Using Gradient Boosting Algorithms Focusing   on Reducing the False Negative and SHAP for Explainability](https://arxiv.org/abs/2403.09548)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Breast cancer is the leading cause of cancer death in women globally. Early detection and treatment are critical for positive outcomes. 
- Prior machine learning studies on breast cancer classification focus mainly on accuracy, but accuracy alone can miss critical false negatives. Reducing false negatives is important in medical diagnosis applications.

Proposed Solution:
- Use gradient boosting machine (GBM) algorithms like AdaBoost, XGBoost, CatBoost, and LightGBM for breast cancer prediction, using the UCI Wisconsin diagnostic dataset.
- Optimize for recall/sensitivity rather than just accuracy to reduce false negatives. Also consider AUC, precision, F1, etc.
- Tune hyperparameters with Optuna Bayesian optimization to get the best performing model.
- Apply SHAP for model explainability and feature importance ranking.

Key Contributions:
- Compared four state-of-the-art boosting algorithms for breast cancer classification focusing on reducing false negatives
- Optimized hyperparameters using Optuna to improve recall/AUC beyond baseline models 
- Obtained final AUC >99.4% and recall â‰¥96.9% for all models after tuning, with 25% lower false negatives
- Used SHAP for model transparency and explainability, enabling feature importance ranking
- Showed the value of optimizing for recall over accuracy alone in medical diagnosis problems to minimize false negatives

In summary, the key novelty is using the latest boosting algorithms and Bayesian hyperparameter tuning to reduce false negative rates in breast cancer classification, while also providing model explainability.
