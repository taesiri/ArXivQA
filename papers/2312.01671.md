# [Multimodality-guided Image Style Transfer using Cross-modal GAN   Inversion](https://arxiv.org/abs/2312.01671)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel framework for multi-modality guided image style transfer (MMIST). Unlike previous image-guided image style transfer (IIST) methods that rely on reference style images, or text-guided image style transfer (TIST) methods that use text descriptions, this method allows using both images and texts as style references (multiple modalities). The core of the framework is a cross-modal GAN inversion technique that can map style inputs from different modalities to a latent space, generating style representations that comply with the multi-modal style specifications. These style representations facilitate modifying existing IIST approaches to achieve MMIST. Experiments show superior performance to previous TIST methods, and the ability to perform seamless style interpolation between image and text modalities. The proposed method enables more flexible control over image stylization, such as specifying new artistic styles by combining existing artwork references and descriptive texts. Both qualitative results and large-scale user studies demonstrate the effectiveness of this framework.
