# [Pre-Trained Language Models Represent Some Geographic Populations Better   Than Others](https://arxiv.org/abs/2403.11025)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- The paper investigates whether pre-trained language models (LLMs) such as BigScience's BLOOM and Facebook's OPT provide equal representations across diverse geographic populations when using the same language (English) and register (social media).  
- Specifically, the paper examines if there is a "population skew" in these models, whereby some populations are much better represented than others. 

Methods:
- The authors collect a geo-referenced corpus of 86,186 comparable English sub-corpora from social media, representing 927 local populations across 130 countries. 
- Using perplexity as a measure of model fit, the paper probes different sized BLOOM and OPT models on this corpus to assess whether perplexities are consistent across corpora from different local populations.

Key Findings:
- Both BLOOM and OPT models show significant population skew, with strong model fit for some populations (e.g. North America, UK) and poor fit for others (e.g. South/Southeast Asia).  
- This skew is robust across different model sizes and training sets. It is not fully explained by socioeconomic factors or English speaking history.  
- There is also variation within countries - some local areas are better represented than others.

Main Contributions:
- Provides clear evidence that current LLMs have unequal representations across geographic populations despite controlling for language and register.
- Identifies a consistent and persistent "population skew" that challenges the idea that one model can serve all populations equally. 
- Offers a lightweight perplexity-based approach to probe model skew across populations that can be applied to other closed-source LLMs.
- Raises concerns about fairness and bias when applying these unevenly fitted models.

In summary, the paper demonstrates LLMs inadequately represent diverse global populations, exhibiting robust skew unrelated to social factors. The authors urge reconsidering the goal of a single general purpose LLM fitting all populations equally.
