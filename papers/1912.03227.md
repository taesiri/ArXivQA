# [Self-Supervised Visual Terrain Classification from Unsupervised Acoustic   Feature Learning](https://arxiv.org/abs/1912.03227)

## What is the central research question or hypothesis that this paper addresses?

Based on my review, the central research question this paper aims to address is: How can proprioceptive and exteroceptive sensor modalities be leveraged in a self-supervised manner for robust terrain classification without requiring manual labeling of training data?Specifically, the key aspects are:- Developing an unsupervised proprioceptive terrain classifier using vehicle-terrain interaction sounds that does not require manually labeled data.- Using the unsupervised proprioceptive classifier to automatically label visual terrain data in a self-supervised manner. - Training an exteroceptive visual terrain classifier such as a semantic segmentation network on these automatic weakly labeled samples without human annotation.- Demonstrating that this allows the exteroceptive classifier to adapt to changing environments and terrain appearances in a lifelong learning approach.So in summary, the main research contribution is a self-supervised cross-modal learning framework for terrain classification that does not rely on manual labeling and enables adaptation to new environments. The key hypothesis is that by exploiting proprioceptive and exteroceptive modalities in this manner, robust terrain classification can be achieved.
