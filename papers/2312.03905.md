# [A Pseudo-Semantic Loss for Autoregressive Models with Logical   Constraints](https://arxiv.org/abs/2312.03905)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Neuro-symbolic AI aims to combine neural networks with logical constraints and reasoning. This allows incorporating human knowledge and ensures models are more explainable, fair and trustworthy.  
- Existing approaches assume neural network outputs are independent (factorized distribution) which limits their applicability.
- For autoregressive models like Transformers, computing likelihood of constraints is intractable. There are two sources of hardness: (1) Logical constraint can have exponentially many solutions  (2) Computing probabilities in these models is #P-hard.

Proposed Solution: 
- Instead of enforcing the constraint over the entire distribution, enforce it over a local pseudolikelihood distribution around a sample.
- This distribution is factorized, so we can reuse solutions to common subproblems when computing probability of the constraint.  
- It focuses probability mass around the sample, meaning it is a high fidelity approximation locally.

Contributions:
- Propose the pseudo-semantic loss that pushes model to satisfy constraints under local pseudolikelihood distribution.
- Show it improves performance on structured prediction tasks like Sudoku solving and Warcraft path finding.
- Demonstrate its effectiveness for detoxifying language models, significantly reducing toxicity of GPT-2 generations.
- Analysis shows the local distribution has low entropy and KL divergence, validating it as a localized, high-fidelity approximation.

In summary, the paper presents a novel pseudo-semantic loss that extends the applicability of neuro-symbolic methods to powerful autoregressive models by enforcing constraints on a local, tractable distribution. Both quantitative and qualitative results validate this is an effective approach.
