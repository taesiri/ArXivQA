# [Revisiting the Power of Prompt for Visual Tuning](https://arxiv.org/abs/2402.02382)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper focuses on visual prompt tuning (VPT), which is a promising method for adapting pre-trained vision models to downstream tasks by inserting learnable prompt tokens. However, VPT faces several challenges:
1) Difficulty with prompt initialization - random initialization performs poorly.
2) Sensitivity to prompt length hyperparameter.  
3) Subpar performance when using self-supervised pre-trained models as the backbone.

These challenges hinder the successful application of VPT for contextual adaptation.

Key Idea: 
The authors first explore how the distributional relationship between prompts and image patch tokens evolves during VPT training. They find that the prompts converge towards the distribution of the patch tokens, i.e. their mutual information increases.  

Based on this, the paper hypothesizes that initializing prompts to already have high mutual information with patch tokens can improve tuning. The proposed method uses the downstream task's inferred patch token prototypes to initialize prompts.

Proposed Method:
The authors propose Self-Prompt Tuning (SPT), which leverages downstream inferred token prototypes to initialize prompts.

Specifically, patch tokens are first inferred by passing the downstream task images through the pretrained model. Then prompt tokens are initialized by either:
1) Clustering inferred tokens into prototypes (computationally expensive)  
2) Efficient approximations: mean/max pooling or random sampling of inferred tokens.

The initialized prompts are inserted into the model and fine-tuned on the downstream task while keeping the backbone model frozen.

Contributions:
- SPT effectively addresses the challenges of prompt initialization, robustness to length, and adaption for self-supervised models.
- Experiments show SPT improves VPT by 10-30% in accuracy, achieves highly competitive results to full fine-tuning, and advances self-supervised model adaptation.
- Analysis provides insights - SPT shows better robustness to prompt lengths, scales better with model capacity, and is most beneficial when downstream data is small.

In summary, the paper makes significant contributions around improving visual prompt tuning through a simple but effective prompt initialization method based on mutual information between prompts and image embeddings.
