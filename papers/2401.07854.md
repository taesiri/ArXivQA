# [$M^{2}$Fusion: Bayesian-based Multimodal Multi-level Fusion on   Colorectal Cancer Microsatellite Instability Prediction](https://arxiv.org/abs/2401.07854)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Predicting microsatellite instability (MSI) status in colorectal cancer (CRC) is important for immunotherapy response, but universal testing is not possible. 
- Using deep learning on histopathology images or radiology images alone has limitations. 
- Fusing information from pathology whole slide images (WSI) and radiology CT images is challenging due to scale differences and data heterogeneity.

Proposed Solution:
- Propose a Bayesian-based multi-level fusion model ($M^2$Fusion) to combine pathology, radiology and fused feature predictions.
- Pathology model uses CLAM for patching and ResNet-18 for feature encoding.
- Radiology model uses tumor ROI slices from 3 directions, forming 6 channels as input to ResNet-18.
- Fuse decisions from pathology and radiology models.
- Fuse features from pathology and radiology models using Transformer or MLP.
- Radiology-guided feature fusion helps guide pathology feature learning.
- Final prediction fuses pathology, radiology and feature-level predictions based on Bayesian formulation.

Main Contributions:
- First pipeline for fusing pathology WSIs and radiology CT for CRC MSI prediction
- Introduce multi-level fusion strategy combining decisions and features
- Show radiology-guidance is effective for feature fusion
- Outperform pathology, radiology or other fusion baselines on 352 patients using 5-fold cross-validation
- Demonstrate Bayesian fusion of decisions and features achieves new state-of-the-art for this problem

In summary, the paper proposes a novel Bayesian multi-level fusion approach to effectively combine pathology and radiology data for better CRC MSI prediction, outperforming single modality or basic fusion techniques.


## Summarize the paper in one sentence.

 This paper proposes a Bayesian-based multimodal multi-level fusion pipeline ($M^2$Fusion) that integrates pathology whole slide images and radiology CT images for more accurate prediction of microsatellite instability status in colorectal cancer.


## What is the main contribution of this paper?

 The main contribution of this paper is a new multimodal multi-level fusion pipeline called M^2Fusion for predicting microsatellite instability (MSI) status in colorectal cancer. Specifically:

1) M^2Fusion is the first pipeline to perform fusion at both the feature level and decision level using pathology whole slide images (WSIs) and 3D radiology CT images for MSI prediction. 

2) This is the first work to integrate CT images into multimodal fusion for CRC MSI prediction.

3) The paper evaluates feature-level fusion strategies based on both Transformer and CNN models.

4) The proposed Bayesian-based fusion approach combines predictions from individual pathology, radiology, and feature-level models and is shown to outperform other fusion techniques as well as individual modality models for MSI prediction.

In summary, the key innovation is the design and evaluation of a multi-level, multi-modal fusion pipeline that leverages complementary information from pathology WSIs and radiology CTs to improve prediction of an important biomarker (MSI status) for colorectal cancer treatment.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the key terms and keywords associated with this paper are:

- Colorectal cancer (CRC) 
- Microsatellite instability (MSI)
- Whole slide images (WSI)
- Computed tomography (CT) images
- Multimodal fusion
- Bayesian fusion
- Decision-level fusion
- Feature-level fusion
- Pathology model
- Radiology model
- Transformer model

The paper proposes an M^2Fusion model for predicting MSI status in colorectal cancer patients by fusing information from pathology whole slide images and radiology CT images. It utilizes both decision-level and feature-level fusion based on Bayesian principles to integrate the pathology and radiology models. Keywords like colorectal cancer, microsatellite instability, multimodal fusion, Bayesian fusion, etc. reflect the key ideas and contributions of this work.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. What is the key motivation behind proposing a multimodal multi-level fusion approach for MSI prediction in colorectal cancer? Why is it better than using a single modality?

2. How does the proposed Bayesian framework allow combining decision-level and feature-level fusion in a unified manner? What are the assumptions made in deriving the Bayesian formulation?

3. What are the specific choices made for the pathology and radiology encoders in the pipeline? How are the features aggregated from multiple pathology image patches into a single vector representation?

4. What are the different fusion strategies explored at the feature level? Why does the Vision Transformer work better than simply concatenating features from both modalities? 

5. How exactly is the tumor region of interest extracted from the 3D CT scans? What preprocessing steps are applied before feeding regions into the radiology encoder?

6. What is the training strategy used for the pathology encoder? Is it trained from scratch or uses pre-trained weights? How about the radiology encoder?

7. Why is 5-fold cross-validation used for evaluation? Does the split ensure MSI/MSS ratio balance in each fold? How are final performance numbers computed?

8. What are the specific performance gains obtained by the proposed multi-level fusion approach over unimodal and other baseline methods? How does performance vary across folds?

9. What conclusions can be drawn from the ablation studies on pathology feature aggregation and choice of feature level fusion model? Which works best and why?

10. What are some limitations of the current study? How can the approach be improved or applied to other cancer prediction tasks in future work?
