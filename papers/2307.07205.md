# [Multimodal Motion Conditioned Diffusion Model for Skeleton-based Video   Anomaly Detection](https://arxiv.org/abs/2307.07205)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be: 

How can we develop an effective video anomaly detection model that captures the inherent multimodality of both normal and abnormal events?

The key hypothesis seems to be: 

By leveraging diffusion models to generate diverse but plausible future motion sequences, conditioned on observed past motion, we can distinguish normal from anomalous events more accurately compared to prior reconstruction-based or score-based anomaly detection techniques.

Specifically, the paper proposes that normal and abnormal events are both intrinsically multimodal in nature - there are many ways a normal or abnormal event could unfold. However, prior techniques constrain normal events to a limited latent volume or rely on a single reconstruction, failing to capture the full diversity. 

In contrast, the proposed approach uses a conditional diffusion model to generate multiple plausible future motion sequences given an observed past sequence. By comparing the statistical properties of the generated futures to the true future, anomalies can be detected when the generations are not biased towards the ground truth like they are for normal events.

So in summary, the central hypothesis is that explicitly modeling the multimodality of possible futures with a conditional diffusion model can improve anomaly detection performance compared to prior approaches. The experiments aim to validate this claim on several video anomaly detection benchmark datasets.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a new generative model for video anomaly detection (VAD) called MoCoDAD (Motion Conditioned Diffusion Anomaly Detection). 

2. It is the first work to apply denoising diffusion probabilistic models (DDPMs) for anomaly detection in videos. It leverages the improved mode coverage capabilities of DDPMs to generate diverse and multimodal future human poses when conditioned on normal motion, while generating distorted poses when conditioned on abnormal motion.

3. It introduces a novel motion-based conditioning strategy to guide the diffusion process using the clean past motion frames. This helps generate motion coherent with the observed conditioning frames for normal events.

4. It validates the model on multiple benchmark datasets including UBnormal, HR-UBnormal, HR-Avenue and HR-STC, outperforming state-of-the-art methods in anomaly detection.

5. The model works directly on human skeletal poses rather than raw video, providing benefits like privacy protection and computational efficiency.

In summary, the key novelty is the use of diffusion models to generate multimodal futures conditioned on past motion, and using the statistical aggregation of the generated futures to discern normal and anomalous events. The conditioning strategy and application to skeletal poses rather than raw video are also notable contributions.
