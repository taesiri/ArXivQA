# [Learning and Sustaining Shared Normative Systems via Bayesian Rule   Induction in Markov Games](https://arxiv.org/abs/2402.13399)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Social norms are informal rules that regulate cooperative behavior in human societies. They help enable decentralized yet stable cooperation.
- For autonomous agents to integrate into human societies, they need to be able to learn and comply with such social norms in a flexible manner. 
- However, norm learning presents an interesting paradox - norms function as shared constraints, yet they are sustained in a decentralized manner via emergence and cultural transmission. 
- Prior reinforcement learning approaches to norm learning struggle to capture this flexibility and complexity.

Proposed Solution:  
- The paper introduces "norm-augmented Markov games" which extend Markov games to include agent beliefs over "norm sets" that classify behavior as compliant or violating.
- Agents assume "shared normativity" - that other agents comply with shared norms even if goals conflict. This allows inference of norms from apparent violations of self-interest.
- Norms are represented as structured rules - as prohibitions that forbid effects or obligations that require extended achievement.
- Agents plan compliance with these rules via model-based methods that switch between reward-seeking and obligation-satisfying modes. 
- Agents approximately infer norms via Bayesian rule induction, using a mean-field approximation for efficiency.
 
Main Contributions:
- Formalizes norm learning in sequential decisions as an inference and planning problem.
- Empirically demonstrates rapid acquisition of norms from observations.
- Shows norms enable outcomes like sustainability and social welfare.  
- Models cultural transmission of norms across agent lifetimes.
- Illustrates decentralized emergence of norms from shared intentionality assumptions alone.
- Contrasts symbolic model-based framework with model-free reinforcement learning.
- Provides a normative standard for evaluating alternative learning approaches.

The paper contributes a sophisticated cognitive account of human-like social norm learning, using structured representations and Bayesian inference to capture the flexibility of human normativity often omitted from model-free approaches. It empirically demonstrates how shared norm assumptions enable agents to rapidly acquire and sustain cooperative institutions in a decentralized yet stable manner.
