# [Conformers are All You Need for Visual Speech Recogntion](https://arxiv.org/abs/2302.10915)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is whether complex visual front-ends like convolutional neural networks or vision transformers are necessary for visual speech recognition, or if a simpler linear projection front-end paired with a Conformer encoder can achieve state-of-the-art performance. The key hypothesis is that allocating model capacity to a bigger Conformer encoder rather than a sophisticated visual front-end will result in better performance, lower latency, and more efficient memory usage for visual speech recognition models.Specifically, the authors hypothesize that:- A linear projection front-end paired with a bigger Conformer encoder will outperform models with complex visual front-ends like VGGs or ViTs.- The increased training efficiency of the linear projection model will allow it to better take advantage of large amounts of training data.- The linear projection's improved memory efficiency will allow fitting larger encoders into memory.- The linear projection will have lower latency compared to CNN or ViT front-ends.So in summary, the central hypothesis is that a simple linear projection front-end with a bigger Conformer encoder is all you need for state-of-the-art visual speech recognition, rather than complex hierarchical visual feature extractors. The experiments aim to validate this hypothesis.
