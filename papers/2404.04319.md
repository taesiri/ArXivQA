# [SpatialTracker: Tracking Any 2D Pixels in 3D Space](https://arxiv.org/abs/2404.04319)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Recovering dense and long-range pixel motion trajectories in videos is challenging due to issues like occlusions caused by 3D-to-2D projection. Existing learning-based methods perform tracking in the 2D image space, losing important 3D information about the scene where the motion actually happens.

Proposed Solution: The paper proposes a novel framework to estimate point trajectories in 3D space instead of 2D, in order to mitigate the issues caused by image projection. The key ideas are:

1) Lift 2D pixels into 3D using off-the-shelf monocular depth estimators. Represent each frame's 3D content efficiently using a triplane representation. 

2) Initialize and iteratively update point trajectories in 3D space using a transformer, taking features from the triplanes as input.

3) Regularize the predicted 3D trajectories with an as-rigid-as-possible (ARAP) constraint. A rigidity embedding is learned to identify rigid parts, and ARAP enforces constant inter-point distances within each rigid part.

Main Contributions:

- A new perspective of tracking dense 2D pixels by lifting them to 3D space instead of tracking in 2D. Allows better leveraging of 3D motion priors.

- A triplane scene representation to enable efficient 3D feature learning and tracking.

- A learnable neural ARAP constraint that can unsupervisedly identify rigid parts in the scene and enforce their rigidity.

- State-of-the-art tracking performance on multiple benchmarks for both 2D and 3D tracking. Qualitative results also showcase good generalization to challenging real videos.
