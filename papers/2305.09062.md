# [SuSana Distancia is all you need: Enforcing class separability in metric   learning via two novel distance-based loss functions for few-shot image   classification](https://arxiv.org/abs/2305.09062)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main research questions and hypotheses addressed in this paper are:1) Is the Proto-Triplet Loss competitive with other metric-learning state-of-the-art models for few-shot image classification? 2) Is the novel ICNN Loss competitive with other metric-learning state-of-the-art models?3) How do the proposed loss functions (Proto-Triplet and ICNN) optimize the feature space to make the features more discriminating for few-shot image classification tasks?The central hypothesis seems to be that using distance-based loss functions that enforce class separability by minimizing intra-class distance and maximizing inter-class distance will allow the network to learn more useful feature representations that can better generalize to novel classes in few-shot scenarios.The experiments and results appear aimed at validating whether the proposed Proto-Triplet and ICNN losses allow the network to learn improved feature embeddings that lead to higher classification accuracy on few-shot tasks compared to other metric learning methods. The visualization of the optimized feature spaces provides further insight into how the losses affect embedding separability.In summary, this work introduces two novel loss functions for improving metric-based few-shot learning through enhancing class separability, and hypothesizes and tests whether they can enhance model performance on this challenging problem.


## What is the main contribution of this paper?

The main contribution of this paper is proposing two novel loss functions, the Proto-Triplet Loss and the ICNN Loss, for training an embedding network for few-shot image classification. The Proto-Triplet Loss is based on the original Triplet Loss but modified to work better in the few-shot learning setting by using class prototypes instead of individual samples.The ICNN Loss is a completely new loss function based on calculating a score for each data point that measures the intra-class and inter-class distance of its nearest neighbors. This loss aims to optimize the embedding space to have higher intra-class density and larger inter-class distances.The authors show that using these losses to train an embedding network improves performance on few-shot image classification, outperforming previous metric-learning based methods on the MiniImagenet benchmark. They also demonstrate the improved generalization capabilities on other datasets like CUB-200, Caltech-101, Stanford Dogs, and Stanford Cars.In summary, the main contribution is proposing these two novel distance-based losses tailored for few-shot learning that help the network learn an embedding space with more discriminative features and better separation between classes, even for unseen classes.
