# [Grid-guided Neural Radiance Fields for Large Urban Scenes](https://arxiv.org/abs/2303.14001)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper aims to address is how to achieve high-fidelity rendering of large urban scenes while being computationally efficient. 

The key idea is to combine the strengths of NeRF-based methods and feature grid representations in a unified framework to effectively model both global and local scene information. The two main hypotheses are:

1) A feature grid representation can coarsely yet reliably capture local scene contents like geometry and appearance. This can guide NeRF's sampling to focus on scene surfaces and provide intermediate features to enrich its pure coordinate inputs.

2) Jointly optimizing the feature grid representation along with the NeRF branch will further refine the grid features to be more accurate and compact. The NeRF branch acts as an implicit regularization to smooth noisy grid features.

Specifically, the paper proposes a two-branch model with a grid branch for compactly encoding multi-resolution ground plane features, and a NeRF branch that takes both grid features and positional encodings as input. The grid branch is first pretrained and then jointly optimized with the NeRF branch. This allows utilizing the strengths of both approaches - efficient and reliable local scene encoding through feature grids, and inherent continuity and detail recovery with NeRF's positional encoding and MLP network.

So in summary, this work aims to enable high-fidelity novel view synthesis for large urban scenes by unifying the feature grid and NeRF-based scene representations in a jointly optimized framework. The key hypotheses are on how the two branches can complement each other's limitations through joint training.
