# [Wavelet Diffusion Models are fast and scalable Image Generators](https://arxiv.org/abs/2211.16152)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper aims to address is: How can we develop diffusion models for image generation that are both fast and high-quality? 

Specifically, the paper proposes a novel wavelet-based diffusion framework to accelerate diffusion models for image generation while maintaining good visual quality. The key ideas are:

1) Perform denoising in the wavelet domain rather than pixel domain. This takes advantage of dimensionality reduction of wavelet transform to speed up the sampling process.

2) Incorporate wavelet decomposition in both image space (as inputs) and feature space (in network design) to improve efficiency and quality. 

3) Propose several new network components like frequency-aware blocks, bottlenecks, and residual connections to better utilize frequency information.

4) Add a reconstruction loss term to preserve consistency between wavelet subbands.

Through extensive experiments, the paper shows the proposed method achieves state-of-the-art speed for diffusion models, closing the gap with GANs, while retaining high sample quality. The central hypothesis is that incorporating wavelet transform and frequency awareness in diffusion models can lead to faster and better image generation. The empirical results seem to validate this hypothesis.
