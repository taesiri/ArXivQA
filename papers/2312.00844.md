# [Sparse Beats Dense: Rethinking Supervision in Radar-Camera Depth   Completion](https://arxiv.org/abs/2312.00844)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points in the paper:

Problem:
- In radar-camera depth completion, using sparse supervision (a single LiDAR frame) leads to severe stripe-like scanning artifacts in the predicted depth maps. This makes the predicted depth unusable for downstream tasks. 
- As a workaround, current methods use multi-frame stacking or interpolation to generate dense supervision. However, this introduces noise like moving objects, inter-frame errors, etc and blurs the projection transformations between sensors.

Key Insight - Projection Transformation Collapse:  
- The core challenge with sparse supervision is that models tend to learn "collapsed" projection transformations between image, radar and LiDAR spaces. 
- This happens because under sparse supervision, models easily overfit to 2D image-LiDAR and 3D radar-LiDAR position correspondences instead of meaningful 3D geometric relationships.
- The stripe artifacts indicate the model finds this "shortcut" of just matching positions instead of properly understanding 3D geometry.

Proposed Solution - Disruption-Compensation Framework:
- Disruption: Disrupt position correspondences by operations like spatial augmentation (image-LiDAR) and height uncertainty modeling (radar-LiDAR).
- Compensation: Compensate for lost position information using a radar-aware mask decoder (plug-and-play) and radar position injection module.  

Contributions:
- Identified core issue of Projection Transformation Collapse in sparse supervision for depth completion
- Proposed a novel Disruption-Compensation framework to address this collapse 
- Achieves SOTA accuracy with sparse supervision, outperforming previous dense supervision methods (11.6% better MAE)
- Runs 1.6x faster than previous methods by using only single-frame supervision

In summary, the key insight is that sparse supervision causes models to learn shortcut collapsed projection transformations. The proposed framework disrupts these shortcuts and compensates to achieve better accuracy than previous dense supervision methods.
