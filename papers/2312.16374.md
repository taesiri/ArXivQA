# [LLM Polygraph: Uncovering LLMs' Factual Discernment through Intermediate   Data Analysis](https://arxiv.org/abs/2312.16374)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Large language models (LLMs) have shown remarkable capabilities in generating creative and knowledgeable outputs. However, a major concern is their tendency to produce non-factual, inaccurate outputs, which can be detrimental in sensitive applications like medical diagnosis or legal advice. Currently, most approaches rely on scrutinizing training data or cross-referencing external databases to mitigate this issue. This introduces complexity, dependencies, and computational costs. 

Proposed Solution:  
This paper proposes the LLM Factoscope, a novel model that leverages the inner states of LLMs to discern factual from non-factual outputs without any external resources. It hypothesizes that LLMs exhibit distinguishable activation patterns when producing factual versus non-factual content, having been exposed to more factual data during training. 

The LLM Factoscope is a Siamese network architecture consisting of four sub-models to process different types of inner state data from the LLM, including activation maps, final output ranks, top-k output indices and probabilities. These sub-models transform the inner state data into embeddings that are integrated to form a combined representation for factual detection. 

During training, a triplet margin loss function brings embeddings from the same class (both factual or non-factual) closer while pushing apart dissimilar ones. In testing, the model compares test data embeddings to a support set to determine their factual category.

Contributions:
- Designed an end-to-end pipeline for building the LLM Factoscope encompassing data collection, model architecture and training procedures
- Empirically demonstrated over 96% accuracy in discerning factual from non-factual LLM outputs across various architectures
- Paved a new path for exploiting LLM inner states to enhance reliability, encouraging further analysis into their internal workings

In summary, this paper introduced a pioneering factual detection approach solely relying on LLMs' inner states. By effectively utilizing these internal representations, the LLM Factoscope offers an accurate and self-contained avenue for discerning and ensuring factual LLM outputs.
