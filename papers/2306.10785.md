# [Multitrack Music Transcription with a Time-Frequency Perceiver](https://arxiv.org/abs/2306.10785)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research focus is on developing a new neural network architecture called Perceiver TF for the task of multitrack automatic music transcription (AMT). The key research goals appear to be:- To develop a model architecture that has better scalability to handle transcribing many instruments simultaneously (addressing the issue of "model scalability"). - To improve the model's ability to discriminate between different instruments in the input mixture (addressing "instrument discrimination").Specifically, the Perceiver TF architecture incorporates a Perceiver module along with additional components to model time-frequency representations for AMT. It is designed to be more efficient and scalable than prior work like SpecTNT. The authors also propose using a random mixing data augmentation technique during training to expose the model to diverse combinations of instruments, aiming to improve instrument discrimination.So in summary, the main research focus is on designing a new neural architecture and training procedure to advance state-of-the-art in multitrack AMT, with a particular emphasis on enhancing model scalability and instrument discrimination capabilities. The proposed Perceiver TF model is evaluated on several datasets and shown to outperform previous methods.
