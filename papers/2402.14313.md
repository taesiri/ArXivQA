# [Learning to Kern -- Set-wise Estimation of Optimal Letter Space](https://arxiv.org/abs/2402.14313)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Kerning (letter spacing) is an important typographic task for improving readability. But it is challenging because the optimal spacing differs for each letter pair and font style. 
- Currently kerning is done manually or with imperfect heuristics, requiring a lot of human effort. There is no automatic approach based on machine learning.

Proposed Solution:
- The authors propose two neural network models for automatically estimating optimal letter spacing.

1. Pairwise model: A DNN that takes a pair of letter images as input and predicts their spacing.

2. Setwise model: A Transformer model that takes the entire set of N letter images of a font and simultaneously predicts spacing for all N^2 pairs. The self-attention allows it to learn consistent spacing for the font set.

Main Contributions:
- First machine learning approach to fully automatic data-driven kerning, without need for human adjustment.

- Setwise Transformer model allows joint optimization of all letter spacings, outperforming heuristics and pairwise model.

- Evaluation on 2558 Google Fonts shows setwise model achieves average error of only 5.3 pixels when average letter space is 115 pixels. Qualitative results also convincing.

- Analysis reveals setwise self-attention enables more accurate and consistent spacing compared to peripheral shape features used in heuristics.

In summary, the paper presents a novel data-driven approach using deep neural networks to automate the challenging task of kerning. The setwise Transformer model in particular allowing joint estimation of spacing for all letter pairs leads to significant improvements over existing methods.
