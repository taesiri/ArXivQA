# [MuLan: Multimodal-LLM Agent for Progressive Multi-Object Diffusion](https://arxiv.org/abs/2402.12741)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing text-to-image (T2I) models still struggle to generate images of multiple objects, especially in handling their spatial positions, relative sizes, overlapping, and attribute bindings. For example, models may generate images with incorrect attributes or spatial relationships between objects compared to the text prompt.  

Proposed Solution: 
The authors propose a training-free Multimodal-LLM Agent (\ours) to address these challenges through progressive multi-object generation with planning and feedback control. 

\ours utilizes three key components:
1) An LLM to decompose the prompt into easier sub-tasks, each generating one object conditioned on previous objects. 
2) Single-object diffusion with attention guidance to generate each object based on a sub-prompt and mask defining size/position.
3) A vision-language model (VLM) that provides feedback to re-generate the image if it violates the original prompt.

Instead of having the model tackle a complex prompt all at once, \ours breaks it down into simpler sub-tasks focused on individual objects. The LLM plans a high-level sequence of objects initially while exact sizes/positions are set later per object using attention guidance. The VLM oversees each generation stage, correcting mistakes via adjusted diffusion hyperparameters.

Main Contributions:
- A new training-free paradigm and agent for controllable text-to-image generation using existing models more effectively
- A strategy to handle multi-object occlusion in diffusion models
- Quantitative and human evaluation results on a curated prompting dataset demonstrating \ours generates better images than previous controllable generation methods

The key advantage is enhanced control over multi-object image generation without additional model training. By decomposing tasks and incorporating feedback, \ours better handles complex prompts with spatial and attribute constraints.
