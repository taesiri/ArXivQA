# [Federated Learning via Plurality Vote](https://arxiv.org/abs/2110.02998v3)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question addressed in this paper is: how can we jointly optimize communication overhead, learning reliability, and deployment efficiency in federated learning? 

Specifically, the authors propose a new federated learning algorithm called Federated Learning via Plurality Vote (FedVote) that aims to address this question. The key ideas are:

- On the client side, optimize a neural network with binary/ternary weights to reduce communication overhead. Use stochastic rounding to obtain low-bit quantized models.

- On the server side, aggregate models via plurality vote to enhance resilience against Byzantine attacks. 

- The quantized models are also more efficient when deployed for inference on edge devices.

So in summary, the FedVote algorithm explores how model quantization on clients and voting-based aggregation on server can lead to a federated learning solution that is communication-efficient, reliable against attacks, and resource-friendly for deployment. The paper presents the algorithm, theoretical analysis, and experiments to demonstrate the effectiveness of this approach in achieving the 3-way tradeoff.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes a new federated learning algorithm called Federated Learning via Plurality Vote (FedVote). The key ideas are:

- Clients train quantized neural networks (QNNs) locally and transmit binary/ternary weights to the server to reduce communication overhead.

- The server aggregates model weights via plurality vote to enhance resilience against Byzantine attacks. 

- The resulting QNN model is lightweight and efficient for deployment.

2. It provides theoretical analysis showing that FedVote converges for nonconvex objectives under certain assumptions. The analysis shows that model quantization in FedVote leads to lower quantization error compared to directly quantizing the model updates.

3. It presents extensive experiments on image classification tasks that demonstrate FedVote's advantages:

- FedVote achieves higher accuracy than existing gradient quantization methods given the same communication budget.

- The Byzantine-resilient variant of FedVote shows strong robustness against different types of attacks.

4. The idea of joint model quantization and voting-based aggregation provides a new paradigm for communication-efficient and Byzantine-resilient federated learning.

In summary, the key novelty and contribution is the design of FedVote that simultaneously optimizes communication efficiency, learning reliability, and deployment efficiency for federated learning systems. The theoretical and empirical results validate the effectiveness of the proposed ideas.
