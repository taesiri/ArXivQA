# [CFEVER: A Chinese Fact Extraction and VERification Dataset](https://arxiv.org/abs/2402.13025)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Fact verification is important to prevent public exposure to false information, but manual fact checking is time-consuming. 
- There is a lack of large-scale Chinese language datasets for training and evaluating automated fact verification systems.
- Existing Chinese fact checking datasets are small or focused only on rumor detection rather than evidence-based verification.

Proposed Solution:
- The authors present CFEVER, a new large-scale Chinese dataset for fact extraction and verification, modeled after the English FEVER dataset. 
- CFEVER contains 30,012 manually annotated claims labeled as "Supports", "Refutes", or "Not Enough Info" based on content from Chinese Wikipedia.
- Claims in the first two classes contain annotated evidence sentences supporting or refuting the claim.
- The dataset construction follows a rigorous process with trained human annotators and quality control yielding high inter-annotator agreement.

Experiments and Analysis:
- Extensive experiments are presented with state-of-the-art models from the FEVER competition and a simple BERT-based baseline model.
- Performance analysis across document retrieval, sentence retrieval and recognizing textual entailment stages demonstrates CFEVER is challenging for current methods.
- Further analysis examines model performance differences based on claim length, evidence complexity, and domain.

Main Contributions:
- The first large-scale Chinese dataset for evidence-based fact verification rather than just rumor detection.
- High quality dataset containing 30K manually annotated claims with labeled evidence sentences.
- Analysis demonstrating models still have substantial room for improvement on this rigorously constructed benchmark.
- A valuable language resource to spur progress on automated fact verification for Chinese text.

In summary, CFEVER contributes a much needed rigorously constructed dataset to drive advances in automated fact verification systems for Chinese, analysing current model limitations and providing a benchmark to measure future progress.
