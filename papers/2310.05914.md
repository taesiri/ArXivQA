# [NEFTune: Noisy Embeddings Improve Instruction Finetuning](https://arxiv.org/abs/2310.05914)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How can language model finetuning be improved for following detailed instructions?

The authors propose a simple method called NEFTune (Noisy Embedding Instruction Finetuning) to improve instruction following in large language models like LLaMA. Their central hypothesis is that adding random noise to the embedding vectors during finetuning will reduce overfitting and enable the model to produce more coherent, knowledgeable responses on downstream instruction tasks. 

Specifically, the paper sets out to test if NEFTune can:

- Improve performance on conversational benchmarks like AlpacaEval that measure a model's ability to provide high-quality freeform responses. 

- Boost the effectiveness of instruction finetuning across various datasets like Alpaca, Evol-Instruct, Open-Platypus etc.

- Enhance the capabilities of already powerful RLHF (reinforcement learning from human feedback) finetuned models like LLaMA-2-Chat.

- Increase instruction following ability without reducing performance on factual QA tasks.

So in summary, the main research question is whether adding noise during embedding finetuning can improve instruction following across diverse models and datasets, while maintaining factual knowledge - and the central hypothesis is that NEFTune will accomplish this by reducing overfitting. The experiments and results aim to test this hypothesis.


## What is the main contribution of this paper?

 Based on my reading, the main contribution of this paper is proposing a new method called \neftune{} (\underline{N}oisy \underline{E}mbedding Instruction \underline{F}ine\underline{tun}ing) to improve language model finetuning for following instructions. 

The key ideas are:

- During finetuning, random noise is added to the input embedding vectors of the training examples. 

- This noise is scaled to have an expected L2 norm of around $\alpha/\sqrt{3}$.

- Adding this noise reduces overfitting to the specifics of the instruction datasets and improves generalizability. 

- \neftune{} is shown to substantially boost performance on conversational tasks like AlpacaEval while maintaining capabilities on benchmarks like the OpenLLM Leaderboard.

- For example, finetuning a 7B parameter LLM on Alpaca goes from 29.8\% to 64.7\% on AlpacaEval.

So in summary, the core contribution is introducing this simple but highly effective noisy embedding technique to get significant gains from instructional finetuning of large language models, enabling them to have more natural conversations. The method imposes minimal overhead and improves various state-of-the-art LLMs.
