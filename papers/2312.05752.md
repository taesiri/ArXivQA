# [Camera-based 3D Semantic Scene Completion with Sparse Guidance Network](https://arxiv.org/abs/2312.05752)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing camera-based semantic scene completion (SSC) methods rely on heavy and sophisticated 3D models to directly process coarse 3D voxel features lifted from images, which are not discriminative enough to produce clear segmentation boundaries. This leads to slow convergence and sub-optimal performance.  

Method:
The paper proposes a novel end-to-end camera-based SSC framework called Sparse Guidance Network (SGN). It adopts a dense-sparse-dense design to diffuse semantics from a set of semantic- and occupancy-aware seed voxels to the entire scene, avoiding reliance on heavy 3D models.

Specifically, SGN first predicts depth and occupancy to select informative seed voxels. Hybrid guidance consisting of semantic guidance and geometry guidance is then applied on the seeds to inject semantic and geometry cues for better feature learning. A voxel aggregation module further combines seed, non-seed and occupancy-aware features. Finally, a lightweight multi-scale semantic diffusion module propagates semantic information from the enhanced seed voxels to all voxels based on geometry and occupancy priors.

Main Contributions:

- Proposes end-to-end SGN framework to propagate semantics from seed voxels to the whole scene based on geometry and occupancy information, avoiding reliance on heavy 3D models.

- Adopts a dense-sparse-dense design and proposes hybrid guidance and voxel aggregation to enhance feature discrimination and expedite semantic diffusion.

- Achieves new state-of-the-art performance on SemanticKITTI dataset while being lightweight, demonstrating effectiveness of the method.
