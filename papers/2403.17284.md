# [Common Ground Tracking in Multimodal Dialogue](https://arxiv.org/abs/2403.17284)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper addresses the challenge of tracking the common ground (shared beliefs and knowledge) between participants in a collaborative, multimodal dialogue. Specifically, it focuses on task-oriented dialogues where participants communicate through multiple modalities like speech, gesture, and physical actions to achieve a shared goal. Tracking the common ground is important for dialogue systems to understand user needs and beliefs. 

Prior work has looked at dialogue state tracking to model user needs, but less attention has been paid to tracking common ground. The paper argues that in collaborative tasks, tracking common ground is as important as tracking individual user states.

Proposed Solution:
The paper presents a computational model and automated pipeline to track the evolution of common ground in a multimodal dialogue. The core of their solution is representing common ground as a "Common Ground Structure" (CGS) consisting of:

- QBank: Questions under discussion that need to be resolved 
- EBank: Propositions that have some evidence of truth  
- FBank: Propositions accepted as true facts

They collect a multimodal dataset of groups collaborating on a physical task. This is annotated with speech, gestures, actions and common ground moves like statements, accepts, doubts. 

They train a neural sequence model to classify dialogue moves. Extracted propositions are then fed to a set of formal closure rules that update the CGS by promoting facts from questions to evidence, or evidence to accepted facts.

Contributions:

1. A new challenging task of tracking common ground from multimodal conversational evidence

2. An integration of a formal model of common ground within an automated pipeline that can process raw multimodal signals

3. Release of a novel dataset with detailed semantic annotations enabling the study of common ground dynamics

The model outputs at each turn an updated estimate of the group's common ground. This can be used by intelligent agents to better understand collaborative tasks and facilitate productive group work. The authors empirically evaluate different feature types and establish performance benchmarks on this novel task.
