# [Toward Tiny and High-quality Facial Makeup with Data Amplify Learning](https://arxiv.org/abs/2403.15033)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Existing facial makeup transfer methods rely on complex pipelines and large models, making deployment on mobile devices very challenging. Specifically, they suffer from the following limitations:

1) Rely on unpaired training data, leading to inaccurate supervision and requiring additional face alignment techniques like facial landmarks, increasing model complexity. 

2) Large model sizes, often exceeding 1M parameters, due to the need for adversarial training and attention mechanisms to enable learning from unpaired data.

3) Inability to generate complete makeup effects like clear eyeliner and brows.

4) Require pre-processing steps like face parsing, further increasing latency.

Proposed Solution:
The paper proposes a new learning paradigm called Data Amplify Learning (DAL) to address the above limitations. The key ideas are:

1) A Diffusion-based Data Amplifier (DDA) that can amplify a small set of paired makeup images (e.g. 5 pairs) into a large paired dataset using novel techniques like Residual Diffusion Model and Fine-Grained Makeup Module.

2) Train a compact CNN-based model called TinyBeauty on the amplified paired data to learn makeup transfer end-to-end without any face pre-processing. 

3) Introduce an eyeliner loss in TinyBeauty to explicitly learn clear eyeliner effects.

Main Contributions:

1) Data Amplify Learning that can produce high-quality training data from a few samples to enable accurate pixel-level supervision.

2) Diffusion-based Data Amplifier with innovations like Residual Diffusion and Fine-Grained Makeup Module to generate diverse, identity-preserving makeup effects.

3) TinyBeauty - an efficient 14-layer CNN for facial makeup, enabled by DAL. It is 13x faster than prior work with 17.3% better image quality.

4) State-of-the-art makeup transfer performance is achieved using only 5 training pairs, with the ability to generate fine details like eyeliner/brows. Deployable on smartphones with 80K parameters.

In summary, the paper enables highly efficient and high-quality facial makeup transfer using a novel data amplification technique to train compact models, overcoming limitations of prior work.
