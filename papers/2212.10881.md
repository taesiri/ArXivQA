# [In-Sensor &amp; Neuromorphic Computing are all you need for Energy Efficient   Computer Vision](https://arxiv.org/abs/2212.10881)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: How can we reduce the energy consumption and bandwidth requirements of computer vision pipelines by integrating spiking neural networks with in-sensor computing approaches?More specifically, the paper proposes an in-sensor computing framework that utilizes spiking neural networks to address the high energy costs and bandwidth bottlenecks associated with transferring image data from sensors to downstream AI processing units. The key ideas are:- Use spiking neural networks (SNNs) which are more efficient than traditional DNNs due to their sparse activations and lack of expensive multiplication operations.- Implement the first layer convolution directly in the image sensor pixels to avoid transferring full image data. This is enabled by proposed analog circuits for convolution and spiking activation.- Reduce the number of output channels from the in-sensor convolution using knowledge distillation during SNN training. This further reduces the bandwidth between sensor and processor.- Overall, the proposed co-design of specialized hardware and tailored SNN training algorithms aims to minimize the total energy consumption of computer vision pipelines. Experiments demonstrate significant reductions in bandwidth, sensor energy, data transfer energy, and total energy compared to baseline approaches.In summary, the central hypothesis is that jointly optimizing sensing hardware and spiking network algorithms can enable more efficient embedded computer vision systems. The paper presents a concrete instantiation and experimental evaluation of this idea.
