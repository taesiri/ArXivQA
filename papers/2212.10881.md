# [In-Sensor &amp; Neuromorphic Computing are all you need for Energy Efficient   Computer Vision](https://arxiv.org/abs/2212.10881)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: How can we reduce the energy consumption and bandwidth requirements of computer vision pipelines by integrating spiking neural networks with in-sensor computing approaches?More specifically, the paper proposes an in-sensor computing framework that utilizes spiking neural networks to address the high energy costs and bandwidth bottlenecks associated with transferring image data from sensors to downstream AI processing units. The key ideas are:- Use spiking neural networks (SNNs) which are more efficient than traditional DNNs due to their sparse activations and lack of expensive multiplication operations.- Implement the first layer convolution directly in the image sensor pixels to avoid transferring full image data. This is enabled by proposed analog circuits for convolution and spiking activation.- Reduce the number of output channels from the in-sensor convolution using knowledge distillation during SNN training. This further reduces the bandwidth between sensor and processor.- Overall, the proposed co-design of specialized hardware and tailored SNN training algorithms aims to minimize the total energy consumption of computer vision pipelines. Experiments demonstrate significant reductions in bandwidth, sensor energy, data transfer energy, and total energy compared to baseline approaches.In summary, the central hypothesis is that jointly optimizing sensing hardware and spiking network algorithms can enable more efficient embedded computer vision systems. The paper presents a concrete instantiation and experimental evaluation of this idea.


## What is the main contribution of this paper?

The main contributions of this paper appear to be:1. Proposing an in-sensor computing hardware-software co-design framework for spiking neural networks (SNNs) that reduces the bandwidth and energy consumption for image recognition tasks. 2. Leveraging recently proposed techniques for training one-time-step SNNs that are highly energy-efficient compared to traditional deep neural networks.3. Customizing the image sensor pixel array and periphery to implement analog multi-channel, multi-bit convolution and comparison operations needed for direct-encoded SNN models.4. Using analog correlated double sampling (CDS) circuits to implement positive and negative weights for the in-sensor SNN convolution.5. Proposing a simple 2-transistor analog comparator design that can fuse the batch normalization into the spiking activation function.6. Reducing the number of channels in the in-sensor convolution layer via knowledge distillation during SNN training to further reduce bandwidth.7. Demonstrating their framework reduces bandwidth by up to 96x and total energy by up to 2.32x compared to traditional computer vision processing, with only 3.8% drop in accuracy on ImageNet image classification.In summary, the key contribution is developing a holistic co-design approach spanning algorithms, circuits, and systems to enable very efficient in-sensor computing for SNNs targeting computer vision applications.
