# [Document Expansion by Query Prediction](https://arxiv.org/abs/1904.08375)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central hypothesis appears to be that expanding documents with predicted queries (using a neural sequence-to-sequence model) can improve retrieval effectiveness compared to just using the original document text. Specifically, the authors propose a method called "Doc2query" where they train a model to generate queries that are relevant to a given document, and then append those predicted queries to the document before indexing. They hypothesize that this document expansion approach will enrich the document representation and help match relevant documents to queries even when there is vocabulary mismatch between the original query and document texts. The experiments then test whether this Doc2query document expansion approach improves retrieval metrics like MRR and MAP compared to a baseline without expansion.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a simple method for document expansion using neural networks. The key ideas are:- Train a sequence-to-sequence model to predict queries that a given document can potentially answer. - Use the model to expand documents by appending predicted queries to the original text.- Index the expanded documents and retrieve with standard methods like BM25.- Show that document expansion improves retrieval effectiveness on MS MARCO and TREC CAR datasets, achieving state-of-the-art or competitive results. - Demonstrate document expansion is more effective than query expansion on these datasets.- The approach shifts computational costs from retrieval to indexing, allowing fast retrieval without neural re-ranking.So in summary, the main contribution is presenting the first successful application of document expansion with neural networks, which gives better results than query expansion, is simple to implement, and improves efficiency.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a simple method to improve document retrieval by using a sequence-to-sequence model to predict queries that are relevant to a document, and appending those predicted queries to the document before indexing to enrich its representation.


## How does this paper compare to other research in the same field?

Here are a few key points about how this paper compares to other research in document expansion and neural information retrieval:- This is the first successful application of document expansion using neural networks, to the authors' knowledge. Previous work on neural document expansion has been limited. Most prior work focused on query expansion techniques.- The method is relatively simple - it uses a standard seq2seq model to generate queries for a document, and appends those to the document before indexing. But it is highly effective, achieving state-of-the-art results on the TREC CAR dataset.- In contrast to most neural IR techniques which are used for re-ranking, this document expansion approach allows the computational costs of the neural model to be shifted to indexing time. Retrieval can then be done efficiently using standard inverted indexes and term matching.- The authors show that document expansion is more effective than query expansion techniques like RM3 on the datasets tested. They hypothesize this is because documents provide richer expansion signals than short queries.- Without re-ranking, the document expanded results are much faster but not far off in accuracy compared to computationally expensive neural rerankers like Duet. This makes the method suitable for low-latency retrieval scenarios.- The simplicity of the approach and use of existing open-source toolkits makes it easy to replicate the results and build further improvements.In summary, this paper presents a novel application of neural document expansion that is simple yet effective. It demonstrates advantages over both classic query expansion methods as well as other neural techniques. The results are state-of-the-art while also being easy to replicate.
