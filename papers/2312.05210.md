# [IntrinsicAvatar: Physically Based Inverse Rendering of Dynamic Humans   from Monocular Videos via Explicit Ray Tracing](https://arxiv.org/abs/2312.05210)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of the paper:

This paper presents IntrinsicAvatar, a novel approach for reconstructing high-quality, physically-based avatars of clothed humans from monocular videos. The key idea is to model the human body and clothing as a volumetric medium and perform explicit Monte-Carlo ray tracing to capture secondary lighting effects like shadows and global illumination. Specifically, the method represents the avatar geometry using an implicit neural representation and estimates per-point properties like albedo, roughness, and metallicness. It then renders the avatar by volumetric path tracing, where each camera ray spawns secondary rays to compute shadows, interreflections etc. This allows relighting the avatar under novel lighting and also generalizes to new poses. A key benefit over prior work is the combination of efficient geometry representation using instant neural graphics primitives (iNGP) and explicit ray tracing over the volume, avoiding approximations for visibility and global effects. Experiments on synthetic and real datasets demonstrate the ability to produce high-quality avatars with accurate and disentangled geometry, reflectance, and environment maps from monocular input only. The rendered results exhibit realistic appearance in novel views and lighting conditions.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper presents IntrinsicAvatar, a novel approach to recovering high-quality, disentangled intrinsic properties (geometry, albedo, material, lighting) of clothed human avatars from monocular videos by modeling the human body's volumetric scattering process via explicit Monte-Carlo ray tracing combined with body articulation.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. The paper proposes a model for fast, high-quality geometry reconstruction of clothed humans from monocular videos. 

2. The paper proposes to combine volumetric scattering with human body articulation for physically based inverse rendering of dynamic clothed humans. It uses explicit Monte-Carlo ray tracing in canonical space to model the volumetric scattering process, enabling relighting for unseen poses.

3. The paper demonstrates that the proposed method can achieve high-quality reconstruction of clothed human avatars with disentangled geometry, albedo, material, and environment lighting from only monocular videos of clothed humans. It also shows that the learned avatars can be rendered realistically under novel lighting conditions and novel poses.

In summary, the main contribution is a novel approach for inverse rendering of clothed human avatars from monocular videos, which can estimate high-quality disentangled representations of geometry, albedo, material, and lighting in a physically based manner. The explicit modeling of volumetric scattering and ray tracing allows the rendered avatars to generalize to novel poses and illuminations.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this work include:

- Physically based inverse rendering - Reconstructing intrinsic properties like geometry, albedo, materials, and lighting from images by modeling the image formation process.

- Volumetric scattering - Modeling the scattering of light through a participating medium (the human body) to render images, as opposed to just surface scattering.

- Monte-Carlo ray tracing - Using stochastic ray tracing techniques to estimate the multiple integrals for volumetric scattering light transport.

- Articulated neural radiance fields - Modeling a pose-deformable neural radiance field for humans by "articulating" it based on an underlying skeleton model. 

- Disentangled reconstruction - Reconstructing properties like geometry, albedo, materials in a decoupled, disentangled way as opposed to a single neural representation.

- Monocular reconstruction - Reconstructing 3D properties from a single input video, as opposed to multi-view input.

- Relighting - Editing the lighting after reconstruction by rendering the model under novel illumination conditions.

- Animation - Editing the pose after reconstruction by articulating the model into novel poses.

So in summary - physically based rendering, neural representations, volumetric scattering, disentangled properties, monocular input, relighting and animation are all key concepts for this work.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions two major challenges for physically based inverse rendering of clothed humans from monocular videos: accurate geometry reconstruction and modeling secondary shading effects. How does the proposed method of using iNGP with hashing-based volumetric representation and SDF address these two challenges compared to prior works?

2. The paper proposes to use volumetric scattering to model the rendering process of clothed humans. How is volumetric scattering more suitable to model edges and boundaries compared to traditional surface-based inverse rendering? What are the advantages and potential limitations?  

3. The paper describes using Monte-Carlo ray tracing in canonical space to model the volumetric scattering process. What is the rationale behind modeling it in canonical space rather than observation space? How does this enable relighting for unseen poses?

4. The paper proposes a hybrid approach to secondary ray marching that first searches for SDF zero-crossing points before accumulating importance weights. Why is this approach better than standard sphere tracing or sequential SDF evaluation along the ray?

5. Temporal occupancy grids are used to reduce computation during ray tracing. How are these occupancy grids defined in this work compared to prior works? What are the advantages of using per-frame occupancy grids here?

6. The ablation study analyzes the impact of using rendered depth with surface scattering versus the proposed iso-surface search. What causes the discontinuities seen in the rendered depth approach and how does iso-surface search address this?

7. How suitable is the proposed approach for modeling large pose-dependent non-rigid deformations? What modifications would be needed to handle scenarios like loose skirts or capes?

8. The runtime of the current approach is slower compared to real-time neural rendering methods. What are some ways the efficiency could be improved for practical applications?

9. How does the volumetric scattering formulation compare to recently proposed microfacet phase functions for volumetric rendering of thin structures? What are the tradeoffs?

10. The method currently does not model indirect illumination for novel lighting conditions during relighting. How big of a limitation is this and how could a more complete global illumination solution be incorporated?
