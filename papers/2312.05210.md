# [IntrinsicAvatar: Physically Based Inverse Rendering of Dynamic Humans   from Monocular Videos via Explicit Ray Tracing](https://arxiv.org/abs/2312.05210)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of the paper:

This paper presents IntrinsicAvatar, a novel approach for reconstructing high-quality, physically-based avatars of clothed humans from monocular videos. The key idea is to model the human body and clothing as a volumetric medium and perform explicit Monte-Carlo ray tracing to capture secondary lighting effects like shadows and global illumination. Specifically, the method represents the avatar geometry using an implicit neural representation and estimates per-point properties like albedo, roughness, and metallicness. It then renders the avatar by volumetric path tracing, where each camera ray spawns secondary rays to compute shadows, interreflections etc. This allows relighting the avatar under novel lighting and also generalizes to new poses. A key benefit over prior work is the combination of efficient geometry representation using instant neural graphics primitives (iNGP) and explicit ray tracing over the volume, avoiding approximations for visibility and global effects. Experiments on synthetic and real datasets demonstrate the ability to produce high-quality avatars with accurate and disentangled geometry, reflectance, and environment maps from monocular input only. The rendered results exhibit realistic appearance in novel views and lighting conditions.
