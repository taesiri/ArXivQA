# [IntrinsicAvatar: Physically Based Inverse Rendering of Dynamic Humans   from Monocular Videos via Explicit Ray Tracing](https://arxiv.org/abs/2312.05210)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Reconstructing realistic 3D avatars of clothed humans from monocular videos, with disentangled representations of geometry, albedo, materials, and lighting, to enable editing and relighting.

- Previous methods either bake intrinsic properties into a single learned representation without disentanglement, or use approximations for secondary lighting effects, resulting in limited quality. 

Proposed Solution:
- Represent geometry with implicit neural representation based on signed distance functions, for high quality shape.

- Model secondary lighting effects like shadows and global illumination explicitly using Monte Carlo ray tracing and raymarching. This captures effects accurately and generalizes to new poses.

- Employ volumetric scattering model instead of surface rendering. This represents materials as participating media and naturally handles complex cloth geometry.

- Optimize geometry, albedo, materials, lighting from video using differentiable rendering losses. Materials use simplified Disney BRDF model.

Main Contributions:
- High quality avatar reconstruction from monocular video, with disentangled geometry, albedo, materials, lighting

- Combining articulated body model and neural implicit representations with volumetric rendering and explicit lighting simulation 

- Achieves more accurate materials and relighting than prior work, generalizes to new poses

- Demonstrates results on synthetic and real datasets that are higher quality than baseline methods

The key idea is to accurately simulate the rendering process with volumetric scattering and global illumination effects, while optimizing over disentangled avatar properties, to reconstruct editable avatars from monocular input videos.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper presents IntrinsicAvatar, a novel approach to recovering high-quality geometry, albedo, material, and environment lighting properties of clothed human avatars from monocular videos by modeling the human body's volumetric scattering process via explicit Monte-Carlo ray tracing combined with body articulation.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. A model for fast, high-quality geometry reconstruction of clothed humans from monocular videos.

2. A method to combine volumetric scattering with human body articulation for physically based inverse rendering of dynamic clothed humans. It uses explicit Monte-Carlo ray tracing in canonical space to model the volumetric scattering process, enabling relighting for unseen poses. 

3. A demonstration that the method can achieve high-quality reconstruction of clothed human avatars with disentangled geometry, albedo, material, and environment lighting from only monocular videos of clothed humans. It also shows that the learned avatars can be rendered realistically under novel lighting conditions and novel poses.

In summary, the main contribution is a novel approach for physically based inverse rendering of clothed human avatars from monocular videos, which can disentangle and reconstruct high-quality geometry, albedo, materials, and lighting in a way that generalizes to novel poses and lighting conditions. The key ideas are using efficient geometry reconstruction, explicit volumetric scattering modeling, and body articulation to achieve this.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this paper include:

- Physically based inverse rendering - The paper focuses on recovering intrinsic physical properties like geometry, albedo, materials, and lighting from monocular videos to enable relighting and animation.

- Volumetric scattering - The paper models the human body and clothing as a volume that scatters light, instead of using a surface representation. This allows more plausible rendering at boundaries.

- Monte Carlo ray tracing - The paper uses Monte Carlo integration and explicit ray marching/tracing to model secondary lighting effects like shadows and global illumination.

- Articulated neural radiance fields - The paper represents the human body shape and appearance using an articulated neural radiance field that can change pose.

- Disentangled representations - The paper aims to separate and recover the shape, material, albedo and lighting of humans in a disentangled way, as opposed to baking them together into a single learned representation.

- Clothed human avatars - The focus of the method is to enable photorealistic reconstruction and relighting of clothed human models from monocular video.

- Generalization to novel poses/lighting - By modeling the physical processes and disentangling representations, the paper shows their method can generalize to novel poses and lighting conditions.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper mentions two major challenges for physically based inverse rendering of clothed humans from monocular videos: accurate geometry reconstruction and modeling secondary shading effects. Can you elaborate more on why these two aspects are particularly challenging for this task?

2. The method uses an instant Neural Graphics Primitive (iNGP) representation with signed distance fields (SDFs) to achieve fast, high-quality reconstruction of clothed human geometry. What are the benefits of using iNGP over other geometry representations like implicit functions or voxel grids in this context? 

3. The paper proposes using volumetric scattering to model the rendering process instead of surface-based rendering. What are some of the advantages of volumetric scattering for handling edges, boundaries, and cloth wrinkles? How does it improve physical plausibility?

4. Can you explain in more detail the process of modeling secondary shading effects via explicit Monte-Carlo ray tracing in canonical space? Why is ray tracing preferred over methods like path tracing or ambient occlusion?

5. The method combines ray marching with iso-surface search during secondary ray tracing. What is the intuition behind this hybrid approach? Why not use pure ray marching or sphere tracing?

6. What modifications or additions need to be made to the standard volumetric scattering equations from computer graphics to make them suitable for an articulated human model?

7. The method uses a simplified Disney BRDF model. What are some pros and cons of using this analytical BRDF formulation compared to data-driven models like MLPs? When might analytical models fail?

8. Can you discuss the rationale behind the different loss functions used during training? Why are smoothness losses on material properties and eikonal losses on SDFs needed?

9. The method models environment lighting with a mixture of spherical Gaussians. What are some limitations of this representation? When would more complex lighting models like SH bands be beneficial?  

10. The paper mentions that the method could be extended to handle non-rigid deformations and loose clothing in the future. What changes would be needed in the model architecture and optimization to achieve this? What new challenges might arise?
