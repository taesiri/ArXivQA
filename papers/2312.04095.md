# [Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning   Interference with Gradient Projection](https://arxiv.org/abs/2312.04095)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel machine unlearning method called Projected Gradient Unlearning (PGU) to efficiently remove the effects of specific training samples from a trained deep neural network model. The key idea is to take gradient steps orthogonal to the core gradient subspace (CGS) spanning the important directions for retaining data. This allows removing information related to forgetting data while minimizing interference with retaining data to prevent catastrophic forgetting. The method works by first defining a novel unlearning loss to reverse the original training process on forgetting data. Then the gradient update direction is projected to the space orthogonal to CGS of retaining data, estimated efficiently from full training data. Experiments on CNN models for CIFAR10 and TinyImageNet showcase accuracy and runtime gains over prior art, while matching gold standard retraining performance across metrics like retain/forget errors, attacker success in membership inference, and model confidence on forgetting samples. The method is also amenable to incremental unlearning, only needs forgetting data as input and works well for de-poisoning by eliminating effects of mislabeled samples. Overall, PGU enables scalable unlearning for modern DNNs to enforce data privacy rights without requiring full retraining.
