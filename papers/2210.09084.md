# [Multi-Agent Automated Machine Learning](https://arxiv.org/abs/2210.09084)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper tries to address is: How to effectively optimize different modules in an automated machine learning (AutoML) pipeline in a joint manner? 

The key hypothesis is that modeling the AutoML modules as cooperative agents in a multi-agent reinforcement learning (MARL) framework can enable effective joint optimization of the modules.

Specifically, the paper proposes a method called Multi-Agent Automated Machine Learning (MA2ML). The key ideas are:

- Model each AutoML module (e.g. data augmentation, neural architecture search, hyperparameter optimization) as an agent. The joint action of all agents defines an ML pipeline. 

- Use the final validation accuracy as the shared reward to train all agents jointly using MARL.

- Introduce credit assignment to differentiate each agent's contribution to the shared reward.

- Employ off-policy RL to improve sample efficiency.

The hypothesis is that by modeling the cooperative relationship between AutoML modules and using techniques like credit assignment and off-policy RL, MA2ML can achieve effective joint optimization and improve end-to-end performance of ML pipelines. Experiments on ImageNet and CIFAR validate this hypothesis and show state-of-the-art results.

In summary, the central research question is how to achieve effective joint optimization of AutoML modules. The key hypothesis is that modeling it as a cooperative MARL problem with credit assignment and off-policy RL can enable joint optimization and improve pipeline performance.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- It proposes a multi-agent automated machine learning (MA2ML) framework to effectively handle joint optimization of modules in automated machine learning (AutoML) pipelines. 

- It models each AutoML module (like data augmentation, neural architecture search, hyperparameter tuning) as an agent and formulates joint optimization as a multi-agent reinforcement learning problem.

- It introduces credit assignment to differentiate the contribution of each module and enable simultaneous updates. It also uses off-policy learning to improve search efficiency.

- It provides a theoretical guarantee that MA2ML leads to monotonic improvement in the optimization objective.

- It achieves state-of-the-art accuracy on ImageNet under FLOPs constraints, outperforming prior AutoML methods. For example, it achieves 79.7% top-1 accuracy with fewer than 600M FLOPs.

- Experiments show MA2ML substantially improves over optimizing each module separately, demonstrating the benefit of joint optimization. Ablations verify the advantages of credit assignment and off-policy learning.

In summary, the key contribution is a new multi-agent RL framework for joint optimization of AutoML modules, with theoretical justification and superior empirical performance over prior methods. The credit assignment and off-policy learning components are shown to be beneficial.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a multi-agent reinforcement learning framework called MA2ML for joint optimization of different modules in automated machine learning pipelines, such as data augmentation, neural architecture search, and hyperparameter tuning, with theoretical guarantees of monotonic performance improvement.
