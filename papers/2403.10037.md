# [Knowledge Condensation and Reasoning for Knowledge-based VQA](https://arxiv.org/abs/2403.10037)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Knowledge-based visual question answering (KB-VQA) requires models to leverage external knowledge to answer open-ended questions about images. Existing methods retrieve knowledge passages from databases to augment the reasoning, but these lengthy passages contain much irrelevant information that misleads the model. Therefore, effectively condensing knowledge from retrieved passages is important. 

Proposed Solution:
The paper proposes two synergistic models - a Knowledge Condensation model to extract key information from retrieved passages, and a Knowledge Reasoning model to reason over condensed knowledge.

The Knowledge Condensation model leverages (1) a visual-language model to distill knowledge concepts tightly related to the visual content and question, and (2) a large language model to summarize passages into knowledge essence that helps answer the question.

The Knowledge Reasoning model integrates the condensed knowledge concepts and essence from previous model as well as implicit knowledge from a VQA model into an encoder-decoder architecture to reason out the final answer.

Main Contributions:
- Proposes a knowledge condensation framework to filter irrelevant information from lengthy retrieved passages via two models.
- Achieves new SOTA results of 65.1% on OK-VQA and 60.1% on A-OKVQA without using GPT-3 knowledge.
- Demonstrates the efficacy of knowledge condensation and reasoning models through ablation studies.
- Provides a new perspective on effectively utilizing explicit retrieved knowledge in KB-VQA.
