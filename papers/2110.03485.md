# [Cartoon Explanations of Image Classifiers](https://arxiv.org/abs/2110.03485)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the key points are:- The paper introduces a new model-agnostic explanation method called CartoonX that is tailored for explaining image classifiers. - CartoonX is built on the rate-distortion explanation (RDE) framework but applies it in the wavelet domain rather than the pixel domain. The goal is to extract the "relevant piecewise smooth part" of an image instead of just the pixel-sparse relevant regions.- CartoonX uses the sparsity of wavelet representations for cartoon-like/piecewise smooth images. By enforcing sparsity in the wavelet domain, the extracted explanations become piecewise smooth instead of pixel-sparse and jittery.- The authors reformulate and generalize the RDE framework to allow applying it to different input representations beyond just pixels. This allows answering more complex interpretation queries like extracting the piecewise smooth parts relevant for a classifier.- Through experiments on ImageNet, the authors demonstrate CartoonX can reveal new explanatory insights compared to pixel-based methods, particularly for misclassifications. They also show CartoonX achieves lower distortion with fewer coefficients.So in summary, the key hypothesis is that operating in the wavelet domain and extracting piecewise smooth explanations will provide more insightful and efficient explanations for image classifiers compared to existing pixel-based methods. CartoonX is presented as a concrete instantiation of this approach.
