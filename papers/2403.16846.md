# [GreeDy and CoDy: Counterfactual Explainers for Dynamic Graphs](https://arxiv.org/abs/2403.16846)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Temporal graph neural networks (TGNNs) are crucial for modeling dynamic graphs where interactions evolve over time. However, TGNNs lack transparency into their decision-making, posing challenges for explainability.  
- Existing explanation methods are predominantly designed for static graphs, do not adequately address the temporal dynamics in dynamic graphs, and focus on factual explanations that identify features contributing to predictions rather than exploring how input changes could alter outcomes.

Proposed Solution:
- The paper introduces two novel counterfactual explanation methods - GreeDy and CoDy - specifically tailored for making TGNN predictions on dynamic graphs more interpretable.

- Both treat the search for explanations as an optimization problem, altering subsets of past events to find input changes that significantly shift model predictions. 

- GreeDy uses a simple greedy search strategy while CoDy employs a more sophisticated Monte Carlo tree search algorithm to efficiently traverse the search space.

- The methods aim to provide concise and intuitive explanations by finding critical subsets of past events in dynamic graphs that, if removed, would alter model predictions.

- When no counterfactual explanations can be identified, the methods provide the next best alternative explanation that comes closest to changing the prediction.

Contributions:
- First work to provide counterfactual explanations for dynamic graph models, offering more actionable insights compared to existing factual approaches.

- Introduces more appropriate evaluation frameworks for assessing counterfactual explanations.  

- Proposes various search strategies like spatio-temporal and local-gradient to enhance the discovery of impactful explanations.

- Empirical analysis shows CoDy substantially outperforms factual methods and GreeDy in identifying counterfactuals, with up to 59% higher success rate. This demonstrates its potential for increasing model transparency.

In summary, the paper pioneers counterfactual explanations for dynamic graph models through optimized search algorithms, enabling enhanced model transparency and trust. The proposed CoDy method shows particular promise in efficiently uncovering insightful explanations.


## Summarize the paper in one sentence.

 This paper introduces two novel counterfactual explanation methods, GreeDy and CoDy, for making predictions from temporal graph neural networks more interpretable by efficiently searching for and selecting small sets of past events that, if removed, would alter the prediction.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1) It pioneers the exploration of counterfactual explanations in the context of explaining Temporal Graph Neural Networks (TGNNs), offering actionable and human-understandable insights.

2) It develops a more appropriate evaluation framework specifically tailored for assessing counterfactual explanations. 

3) It introduces various search strategies designed to enhance the effectiveness and efficiency of identifying potential explanations.

In particular, the paper proposes two novel model-agnostic counterfactual explanation approaches - GreeDy and CoDy - for dynamic graph models and TGNNs. It demonstrates through experiments that CoDy outperforms GreeDy and existing factual explanation methods in effectively generating clear counterfactual explanations. The paper highlights the potential of counterfactual explanations and methods like CoDy to increase the transparency and trustworthiness of TGNNs in practice.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- Temporal Graph Neural Networks (TGNNs)
- Continuous-Time Dynamic Graphs (CTDGs)
- Counterfactual explanations
- Future link prediction
- GreeDy (Greedy Explainer for Dynamic Graphs)
- CoDy (Counterfactual Explainer for Dynamic Graphs) 
- Monte Carlo Tree Search (MCTS)
- Fidelity metrics ($fid_-$, $fid_+$)
- Sparsity 
- Selection strategies (random, temporal, spatio-temporal, local-gradient)

The paper introduces two new counterfactual explanation methods, GreeDy and CoDy, for making predictions from Temporal Graph Neural Networks more interpretable and transparent. It evaluates these methods on continuous-time dynamic graphs for the task of future link prediction. Key terms reflect the focus on TGNNs, CTDGs, counterfactuals, and the specifics of the proposed GreeDy and CoDy approaches.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the methods proposed in the paper:

1. The paper introduces two novel counterfactual explanation methods, GreeDy and CoDy. What are the key differences in how these two methods search the space of possible counterfactual examples? What are the tradeoffs between the greedy search used by GreeDy versus the Monte Carlo tree search used by CoDy?

2. CoDy outperforms GreeDy significantly in terms of metrics like fidelity and sparsity. What aspects of the Monte Carlo tree search allow it to find better counterfactual examples compared to the greedy approach? How does the balance between exploitation and exploration impact the search process and quality of explanations?  

3. The paper evaluates the methods on 3 different datasets - UCI Messages, UCI Forums and Wikipedia. What are some key properties of these datasets that might impact the explanation process? For instance, Wikipedia has edge features while the other two don't. How might edge features affect the search for counterfactuals?

4. The paper proposes 4 different selection strategies - random, temporal, spatio-temporal and local-gradient. Which strategy works best for each method? Why does the spatio-temporal strategy perform well consistently? What insights does this provide into the decision making process of temporal graph neural networks?

5. One finding is that all explainers perform better at explaining wrong predictions compared to correct ones, especially on certain datasets. What underlying reasons could lead to this discrepancy? How can this inform efforts to improve explanation quality for correct predictions?  

6. For fidelity, CoDy seems to balance sufficiency and necessity well compared to alternatives. But the paper doesn't dive deeper into specific case studies. Can you analyze 1-2 examplesqualitatively to showcase how CoDy generates insightful counterfactuals? 

7. The paper touches briefly on runtime analysis. But how could explanation time be reduced further, especially for real-time applications? Could approximations of the prediction model help accelerate the search?

8. The paper focuses on counterfactual examples generated by omitting events. But adding/editing events can also produce counterfactuals. How much more complex would the search space be in those cases? Would the proposed methods translate effectively?

9. The evaluation metrics focus narrowly on counterfactual discovery rates and sparsity. What other metrics could be used to assess the real-world usefulness of these explanations? How can human studies complement the automated evaluations? 

10. The paper sets the stage nicely for counterfactual explanations in dynamic graphs. What other types of temporal/sequential models could benefit from adaptations of GreeDy and CoDy? What challenges need to be overcome to generalize these approaches?
