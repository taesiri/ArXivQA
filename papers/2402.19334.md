# [Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge](https://arxiv.org/abs/2402.19334)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Pre-trained language models (PLMs) published in public model repositories like HuggingFace are vulnerable to backdoor attacks. These attacks manipulate the model's behavior to produce predetermined malicious outputs when triggered by specific inputs.  
- Existing defense strategies often require access to training data, knowledge of the attack method, or model retraining, which are impractical in real-world settings where models may already be deployed.

Proposed Solution:
- The paper proposes using model merging to sanitize backdoored models, without needing extra resources or specific knowledge. 
- The key idea is that merging a backdoored model with other clean or backdoored models will dilute the backdoor signal. Simple weight averaging is used for merging.

Main Contributions:
- First work to show model merging can mitigate backdoor attacks on language models.
- Extensive experiments validate the approach is effective against various advanced backdoor attack methods, on multiple datasets and model architectures.
- The method reduces attack success rate by an average of 75%, outperforming strong baselines like ABL and ONION.
- As an inference-stage defense, it eliminates the need for training data, attack details, or model retraining.
- Model merging is already a technique used to improve model performance, so its defensive capability comes at no extra cost.

In summary, the paper presents a simple yet effective defense against backdoor attacks by merging models, without needing additional resources. The generic nature of the approach makes it suitable for real-world settings where models may be compromised but training details are unavailable.
