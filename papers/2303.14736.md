# [Disentangling Writer and Character Styles for Handwriting Generation](https://arxiv.org/abs/2303.14736)

## What is the central research question or hypothesis that this paper addresses?

The main research question this paper addresses is how to disentangle writer and character styles for improving handwriting generation. Specifically, the paper hypothesizes that disentangling the overall writer style and detailed character styles can lead to more realistic and diverse synthesized handwritings.The key hypotheses are:1) Handwritings by the same person exhibit overall uniformity in some aspects (e.g. slant, aspect ratio), but still have subtle style inconsistencies between characters (e.g. stroke length, curvature). 2) Separately capturing the overall writer style and detailed character styles enables generating handwritings that better match the exemplar writer.3) Using contrastive learning objectives can guide the model to learn disentangled representations for the two styles.To test these hypotheses, the paper proposes a new model called Style-Disentangled Transformer (SDT) which uses a dual-head style encoder and contrastive losses to extract separate writer and character style representations. Experiments on Chinese, English, Japanese and Indic scripts demonstrate SDT's effectiveness in realistic handwriting synthesis compared to prior arts. The results support the hypotheses that disentangling and explicitly modeling writer vs character styles improves quality and diversity of generated handwritings.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes to disentangle the style representations at both writer and character levels from individual handwritings to synthesize realistic stylized online handwritten characters. 2. It presents the style-disentangled Transformer (SDT), which employs two complementary contrastive objectives to extract the style commonalities of reference samples and capture the detailed style patterns of each sample.3. It develops an offline-to-offline framework building on SDT to produce more plausible offline handwritten Chinese characters.4. Extensive experiments on various language scripts demonstrate the effectiveness of SDT for handwriting generation. The empirical findings reveal that the two learned style representations provide information at different frequency magnitudes.In summary, the key novelty of this paper is the idea of disentangling writer and character level styles using contrastive learning objectives in the Transformer architecture. This allows generating handwritten text that better captures both the overall writing style of a person as well as subtle stylistic variations between different characters. The offline-to-online framework further improves the quality of synthesized offline handwritten Chinese characters.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the main point of the paper:The paper proposes a new method called style-disentangled Transformer (SDT) that disentangles writer-level and character-level styles from handwritten samples to generate realistic and stylistically diverse online handwritings in multiple languages.


## How does this paper compare to other research in the same field?

Here are some key ways this paper compares to other research in Chinese character generation:- It focuses specifically on disentangling writer and character styles for handwriting generation. Many previous works have focused only on capturing the overall writing style at a writer level, while neglecting subtle style inconsistencies between different characters from the same writer. This paper is novel in separately extracting both an overall writer style and detailed character styles.- It proposes a new model architecture called style-disentangled Transformer (SDT) to achieve the style disentangling. This uses a dual-head style encoder with contrastive objectives to extract the two complementary style representations. Most prior works have used RNN or GAN architectures without such an explicit disentangling approach.- It achieves state-of-the-art results on Chinese datasets for online character generation. The quantitative metrics and user study show SDT generates handwriting of higher quality than previous models like Drawing, FontRNN, DeepImitator and WriteLikeYou.- The style disentangling approach is shown to generalize well to other scripts like Japanese, Indic and English. Most prior work has focused only on Chinese or Latin script generation. Evaluations on these additional datasets demonstrate the wider applicability.- Analysis reveals the two learned style representations capture different frequency information, with writer style focusing on lower frequencies and character style capturing more high frequency details. This provides insight into their complementary roles.- The paper further proposes an offline generation framework building on SDT. This generates realistic offline handwritten characters through an online-to-offline process, outperforming prior offline generation methods.Overall, the style disentangling approach and strong results across multiple languages set this work apart from prior research. The analysis also provides valuable insights into how overall writer style and detailed character styles contribute in different ways to handwriting generation.
