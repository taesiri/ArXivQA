# [N-MPC for Deep Neural Network-Based Collision Avoidance exploiting Depth   Images](https://arxiv.org/abs/2402.13038)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Autonomous navigation and collision avoidance for aerial robots (UAVs) in unknown environments is challenging, especially at high speeds. Classical approaches rely on dense maps from heavy sensors like lidars, but these are costly and limit agility. Recent works use only onboard sensors like cameras for reactive avoidance, but struggle with the high-dimensional image data.

Proposed Solution: 
This paper proposes a nonlinear model predictive control (NMPC) framework that integrates a deep neural network (DNN) to process depth images for UAV collision avoidance. The DNN takes as input a depth image and 3D point, and outputs a collision score. It is composed of a variational autoencoder CNN that compresses the image into a latent vector, and a fully-connected network that scores 3D positions based on the latent vector. The DNN is embedded into the NMPC problem as an obstacle avoidance constraint over the prediction horizon. This enables the NMPC to avoid perceived obstacles in real-time based solely on depth images, without an explicit map.

Main Contributions:
- A DNN architecture designed specifically for efficient integration into a real-time NMPC for UAVs, that outputs a differentiable collision score for any 3D point based on a depth image
- Methodology to embed the DNN into the NMPC problem formulation as an algebraic constraint over the receding horizon
- Real-time implementation validated in simulations and experiments on a quadrotor with onboard sensing and computing
- Release of open-source code for the DNN, NMPC and interfaces

The approach achieves real-time obstacle avoidance on only an onboard depth camera, enabling agile flights. The NMPC leverages the prediction horizon for non-greedy maneuvers. The integration of learning-based perception with optimal control is a promising paradigm for autonomous UAV navigation.


## Summarize the paper in one sentence.

 This paper proposes a nonlinear model predictive control framework that leverages a deep neural network trained on simulated depth images to enable real-time, sensor-based collision avoidance for aerial robots tracking desired trajectories.


## What is the main contribution of this paper?

 According to the paper, the main contribution is proposing a new paradigm that combines a deep neural network for processing onboard-captured depth images with nonlinear model predictive control (NMPC) for real-time collision avoidance in trajectory tracking tasks with unmanned aerial vehicles (UAVs). 

Specifically, the key aspects of the contribution are:

- A deep neural network is designed to process depth images and output a collision prediction score for sampled 3D points in the camera's field of view. This network has a variational encoder-decoder architecture.

- The neural network is integrated into the NMPC as an algebraic symbolic equation that constrains the predicted UAV positions throughout the receding horizon to be collision-free based on the perceived depth images. 

- The combined neural network and NMPC framework runs in real-time with a control frequency of 100Hz in simulations and hardware experiments, enabling sensor-based reactive collision avoidance for UAV trajectory tracking tasks.

- The code for the full framework is released open-source.

In summary, the main novelty is the real-time capable integration of learned perceptual collision predictions from depth images into an NMPC controller for reactive obstacle avoidance in UAV trajectory tracking.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- Nonlinear model predictive control (NMPC)
- Neural networks (NNs) 
- Collision avoidance
- Depth images
- Uncrewed aerial vehicles (UAVs)
- Variational encoder
- Fully connected (FC) network
- Binary cross entropy (BCE) loss
- Sim-to-real transfer
- Real-time iteration (RTI) scheme
- Sequential quadratic programming (SQP)

The paper proposes an NMPC framework that leverages a deep NN to process onboard-captured depth images for collision avoidance during trajectory tracking tasks with UAVs. Key elements include the variational encoder CNN architecture, the FC network for collision prediction, the integration of the NN into the NMPC as an algebraic constraint, and experimental validation on a real UAV platform.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1) The neural network architecture has both a variational encoder CNN part and a fully-connected network. What is the motivation behind this hybrid architecture? How do the two components work together in the full pipeline?

2) The neural network is trained purely on simulated depth images. What strategies are used to bridge the sim-to-real gap? How is the performance on real images validated?

3) Explain how the neural network's fully-connected part is transformed into symbolic equations and integrated with the nonlinear model predictive control formulation. What adaptations are made to ensure convexity and avoid vanishing gradients? 

4) What are the advantages of using a nonlinear MPC framework compared to other approaches like imitation learning or reinforcement learning for this collision avoidance application? What unique capabilities does it enable?

5) The method relies only on local estimates from visual and inertial sensors rather than global mapping. Explain the rationale behind this design choice and how it avoids issues with state estimate drift.

6) How is the reference trajectory for the MPC controller generated? What are the different possibilities for defining the tracking objective based on the application requirements?

7) Explain the complete software architecture and modular components that enable deployment of this method on a real robotic system. What are the runtimes of each component?

8) The experiments use an aerial robot called the Learning-based Micro Flyer (LMF). Summarize the key hardware specifications and sensors onboard this platform. 

9) Analyze the results of the simulation and real-world experiments. What navigation behaviors emerge from this method? How do the results validate the approach?

10) What are promising directions for future work to extend this method? What are some of its limitations in the current form?
