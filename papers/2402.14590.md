# [Scaling Up LLM Reviews for Google Ads Content Moderation](https://arxiv.org/abs/2402.14590)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Goal is to accurately detect Google Ads policy violations, especially "Non-Family Safe" violations related to sexual/adult content, across large volume of image ad traffic
- Using large language models (LLMs) is challenging due to high computational costs of running inference on all ads

Proposed Solution:
- Funneling - Use heuristics to filter and select candidate ads for LLM review, including content similarity, actor similarity, deduping, and sampling for diversity
- LLM Labeling - Carefully engineer prompts and tune smaller parameter LLM model for labeling candidates 
- Label Propagation - Propagate LLM labels to similar ads based on content embeddings
- Feedback Loop - Add labeled ads back to funneling stage to find more similar candidates 

Key Contributions:
- End-to-end pipeline to effectively scale up LLM reviews and maximize accuracy under compute constraints
- Funneling stage greatly reduces volume needed for LLM review (400 million to 400k ads)   
- Achieves 2x recall compared to baseline non-LLM model
- Doubles number of labeled ads through propagation
- Helped remove 15% more violating impressions in image ads
- Approach is generalizable to multiple ad formats and policies beyond image ads

In summary, the paper provides an end-to-end solution to efficiently scale up LLM content moderation for Google Ads while maximizing accuracy and coverage across a massive corpus of ads.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a method to scale up large language model reviews for detecting policy violations in Google Ads by using heuristics to select a small subset of ad candidates, reviewing only those candidates with large language models, and then propagating the decisions to similar ads to maximize coverage and efficiency.


## What is the main contribution of this paper?

 Based on reviewing the paper, the main contribution appears to be proposing a method for scaling up large language model (LLM) reviews for content moderation in Google Ads. Specifically, the paper introduces an end-to-end solution that combines:

1) Funneling to reduce the volume of ads that need to be processed by selecting candidates via filtering, deduping, and sampling. 

2) Using prompt-engineered and tuned LLMs to review only the selected candidates.

3) Propagating the LLM review decisions to similar ads using label propagation based on content similarity.  

4) A feedback loop to improve candidate selection in subsequent rounds.

The paper states that this approach reduces the number of ads needing reviews by over 1000x compared to reviewing all ads with LLMs directly. It also achieves 2x higher recall in detecting policy violations compared to a baseline non-LLM model. So in summary, the main contribution is a method to efficiently scale up LLM reviews for content moderation in a large corpus like Google Ads.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper content, some of the key terms and keywords associated with this paper include:

- Large language models (LLMs)
- Content moderation
- Google Ads
- Image ads
- Policy enforcement 
- Prompt engineering
- Parameter efficient tuning
- Label propagation
- Content similarity
- Review candidate selection
- Funneling
- Deduping
- Filtering
- Sampling
- Non-family safe policy
- Sexually suggestive content

The paper introduces an end-to-end solution to scale up LLMs to moderate content in Google Ads while reducing compute resources. Key elements include using heuristics to select review candidates, tuning LLMs with prompt engineering and parameter efficient tuning, propagating labels to similar content, and having a feedback loop to improve candidate selection. A case study is presented applying this approach to detect policy-violating image ads.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions using prompt engineering and parameter efficient tuning to prepare the LLM for content moderation. Can you expand more on the specific prompts crafted and tuning techniques used? What was the process and iteration done to arrive at the best performing prompt?

2. The funneling stage uses several techniques like content similarity, actor similarity, deduping etc. to reduce the number of images for LLM review. Can you provide more details on how these different techniques work and how much reduction each one provides? 

3. The paper talks about using graph based maximal coverage sampling to sample diverse images in the funneling stage. How exactly is this graph constructed and what metrics are used to measure coverage and diversity during sampling?

4. What types of non-LLM models are used in the initial stages to select candidates above certain score thresholds? What are the challenges in using pre-trained models with lower precision requirements?

5. The label propagation stage uses similarity between stored labeled images and new images. What embeddings are used to calculate this similarity? Are there any domain specific adjustments made to these embeddings?

6. What are some of the key signals and metrics used in the feedback loop to improve subsequent rounds of candidate selection in funneling stage? How much improvement is seen across rounds?

7. What are the infrastructure requirements and scale up challenges faced while deploying the LLM review system handling 400 million ad images?

8. How frequently does the entire pipeline of funneling, LLM review, label propagation and feedback loop execute? What triggers a new pipeline run?

9. What policy specific adjustments need to be made for expanding this system to other ad policies like video, text, landing pages etc.?

10. Beyond policy detection, what are some other use cases being explored for the LLM review systems in domains like ad relevance, creative quality, performance predictions etc?
