# [Organic or Diffused: Can We Distinguish Human Art from AI-generated   Images?](https://arxiv.org/abs/2402.03214)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
With the proliferation of AI generative image models like DALL-E, Stable Diffusion, and Midjourney, it has become increasingly difficult to distinguish between human-created artworks and AI-generated images. This ability to identify the provenance of imagery is critical for several reasons: to prevent fraud by bad actors trying to pass off AI art as human, for copyright and policy issues around AI content, and even to help curate better model training data. 

The paper explores the effectiveness of current methods to address this challenge, including automated detectors like Hive and Optic, new research tools targeting diffusion models like DIRE and DE-FAKE, and identification by human experts leveraging artistic techniques. It considers a range of art styles and AI models, and also examines performance under adversarial conditions where images are altered to avoid identification.

Proposed Solution:
The paper curates a novel dataset covering 7 art styles, with 280 real human artworks and 350 matched AI-generated images from 5 major generative models. It systematically evaluates 8 detectors - 5 automated and 3 different human detector groups on this dataset. The 180 crowdworkers represent non-artists, 4000+ artists from social media capture professional artists, and 13 experts are artists experienced in spotting AI images. 

Key Findings:
- For benign images, Hive classifier is highly accurate (98%) with 0 false positives on human art, outperforming all other automated and human detectors. However, it struggles against adversarial perturbations, especially Glaze protection, unlike human experts.

- Non-artist users cannot reliably distinguish between human and AI art. Professional artists do better using their knowledge to spot technical inconsistencies. Experts outperform machines under certain adversarial settings, but produce false positives by attributing human mistakes as AI indicators. 

- Performance correlates with training data availability - automated detectors struggle on new AI models with limited data like Firefly images. Feature space perturbations via Glaze have a disproportionate impact.

- A combined human and ML model team provides the best accuracy and robustness against adversarial attacks.

Main Contributions:
- Comprehensive analysis of distinguishing AI vs human art using both automated and human detection
- Curated multi-faceted dataset of 7 styles, 5 AI generative models, and unusual hybrid/enhanced images  
- Evaluation of multiple classifier detectors, new diffusion-based detectors, and 3 tiers of human detectors
- Detailed study on impact of adversarial perturbations like Glaze on detection accuracy  
- Analysis of techniques used by professional and expert artists to identify AI provenance
- Demonstrate strengths and weaknesses of human vs automated detection approaches

The paper provides significant evidence that a joint human-ML system offers complementary accuracy and robustness as AI generative models continue to evolve. The curated dataset enables deeper analysis of emerging detection techniques.
