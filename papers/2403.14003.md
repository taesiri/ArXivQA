# [Multi-Modal Hallucination Control by Visual Information Grounding](https://arxiv.org/abs/2403.14003)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Generative vision-language models (VLMs) like LLaVA can generate plausible-sounding text answers that are not grounded in the actual image content, a phenomenon known as "hallucination". 
- As more tokens are generated, the model relies less on the visual input and more on the language prior, increasing the chance of hallucinations. This is called the "conditioning dilution" or "fading memory" effect.

Proposed Solution: 
- The authors propose a new inference algorithm called Multi-Modal Mutual Information Decoding (M3ID) that counteracts conditioning dilution by amplifying the mutual information between generated tokens and visual input compared to relying solely on language priors.  
- M3ID assigns higher likelihood to tokens that "surprise" the unconditioned language model, favoring grounded generations. The strength of this intervention increases over time.
- For models with access to training, the authors pair M3ID with preference learning using Direct Preference Optimization (DPO) to further improve visual grounding.

Main Contributions:
- Empirically demonstrate that visual grounding of VLMs decreases as more tokens are generated, correlating with increased hallucinations.
- Propose training-free inference algorithm M3ID that improves visual grounding of any VLM by favoring surprising tokens not predicted by language prior. Reduces hallucinations by 25-29% on benchmarks.  
- Extend M3ID with DPO for preference learning to optimize models to increase reliance on visual input. Further reduces hallucinations without needing any human labels.
- Simple and flexible approaches to enhance vision-language grounding and reduce hallucinations stemming from over-reliance on language priors.
