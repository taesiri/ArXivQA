# [MPIrigen: MPI Code Generation through Domain-Specific Language Models](https://arxiv.org/abs/2402.09126)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing methods for automatic MPI parallelization have limitations, including static compilers which have limited effectiveness and scalability and transforming from shared to distributed memory which can degrade performance.  
- Large language models (LLMs) have shown promise for parallel programming tasks like OpenMP pragma generation, but generating intricate, multi-functional MPI codes across locations has not been explored.

Proposed Solution:
- Introduce \mpir{}, a tool to automatically suggest MPI functions for MPI codes by fine-tuning the domain-specific \mono{} model on a new MPI-focused dataset \mpicorpus{}.  
- Propose innovative pre-processing to enable training in a left-to-right fashion and generate MPI functions after observing full code context.

Key Contributions:
- Create first MPI-only code dataset \mpicorpus{} from 16K MPI domain decomposition programs.
- Show \mono{} understands MPI better than PolyCoder and GPT-3.5 using code completion on \mpicorpus{}.
- \mpir{} outperforms GPT-3.5 zero-shot for generating accurate MPI functions in location, function and argument predictions, especially for more complex codes.
- Underscores importance of domain-specific fine-tuning for parallel computing code generation tasks.
- Paves way for new generation of automatic MPI parallelization tools.

In summary, the paper introduces \mpir{}, a tailored LLM approach built on \mono{} and finetuned on a new MPI dataset, to effectively generate MPI functions in codes across locations. The domain-specific solution outperforms general LLMs, showing the value of specialization for MPI parallelization.
