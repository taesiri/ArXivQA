# [Think Twice Before Assure: Confidence Estimation for Large Language   Models through Reflection on Multiple Answers](https://arxiv.org/abs/2403.09972)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) suffer from overconfidence in their generated answers, assigning high confidence scores even to incorrect answers. This causes miscalibration between confidence scores and answer accuracy.
- Existing methods addressing LLM overconfidence have a key limitation - they only consider confidence estimation for a single LLM-generated answer, while the LLM can still be biased towards that answer.

Proposed Solution:  
- Introduces a new paradigm that evaluates multiple candidate answers to mitigate overconfidence on the target answer. Comparing trustability of answers helps reduce biased trust in incorrect ones.
- Proposes a two-step "Think Twice Before Assure (TTA)" framework:
   1) Instruct LLM to reflect and justify potential correctness of each answer.
   2) Aggregate justifications to derive confidence score for target answer.
- TTA can be combined with existing methods like prompt ensemble for further improvements.

Key Contributions:
- Proposes a new multi-answer evaluation paradigm to address limitations of existing paradigms for LLM confidence estimation. 
- Presents the TTA framework to implement this paradigm with reflection and justification on multiple answers.
- Shows improved calibration over existing methods on 3 tasks. TTA also combines with other methods for further gains.

In summary, the paper introduces a novel paradigm and TTA framework that leverages comparison of multiple answers to mitigate overconfidence of LLMs for better calibrated confidence estimation.
