# [Coordinate Transformer: Achieving Single-stage Multi-person Mesh   Recovery from Videos](https://arxiv.org/abs/2308.10334)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we achieve single-stage multi-person 3D mesh recovery from videos in an end-to-end manner? The key hypotheses appear to be:1) Modeling spatial-temporal relations and constraints across multiple people simultaneously will improve multi-person 3D mesh recovery compared to modeling people independently. 2) Preserving pixel-level spatial-temporal coordinate information is critical for capturing precise correspondence and improving performance in multi-person scenarios.3) A coordinate-aware attention mechanism can be used to encode pixel-level coordinates and maintain pixel-level dependencies in transformer-based models for this task.4) Focusing features on potential body locations using a body center attention mechanism will improve multi-person perception and facilitate end-to-end training.The main goal is to develop a single-stage approach that jointly handles detection, tracking, and spatial-temporal modeling to recover multi-person meshes directly from video frames without needing explicit single-person cropping or sequence modeling.


## What is the main contribution of this paper?

The main contributions of this paper are:- It proposes CoordFormer, the first single-stage approach for multi-person 3D mesh recovery from videos. Previous methods rely on multi-stage pipelines involving person detection, tracking, and single-person temporal modeling. In contrast, CoordFormer implicitly handles detection and tracking and simultaneously models spatial-temporal relations across multiple people in an end-to-end manner. - It introduces two novel components: 1) Body Center Attention (BCA) to focus features on potential body locations indicated by a predicted body center heatmap, and 2) Coordinate-Aware Attention (CAA) to preserve pixel-level spatial-temporal coordinates when capturing dependencies. - It demonstrates state-of-the-art performance on the challenging 3DPW dataset, outperforming previous best results by 4.2-8.8% on standard metrics while also being 40% faster than recent video-based methods.- It shows the importance of modeling precise pixel-level coordinates for multi-person video mesh recovery, enabled by the proposed CAA module.In summary, the key contribution is a new single-stage approach that advances multi-person video mesh recovery by implicitly handling detection/tracking and modeling detailed spatial-temporal relations across people simultaneously. The proposed BCA and CAA components help achieve this goal.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes CoordFormer, a novel single-stage approach for multi-person 3D mesh recovery from videos that implicitly performs detection and tracking and simultaneously models spatial-temporal relations among people in an end-to-end manner through two new modules - Body Center Attention and Coordinate-Aware Attention.
