# [Coordinate Transformer: Achieving Single-stage Multi-person Mesh   Recovery from Videos](https://arxiv.org/abs/2308.10334)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we achieve single-stage multi-person 3D mesh recovery from videos in an end-to-end manner? The key hypotheses appear to be:1) Modeling spatial-temporal relations and constraints across multiple people simultaneously will improve multi-person 3D mesh recovery compared to modeling people independently. 2) Preserving pixel-level spatial-temporal coordinate information is critical for capturing precise correspondence and improving performance in multi-person scenarios.3) A coordinate-aware attention mechanism can be used to encode pixel-level coordinates and maintain pixel-level dependencies in transformer-based models for this task.4) Focusing features on potential body locations using a body center attention mechanism will improve multi-person perception and facilitate end-to-end training.The main goal is to develop a single-stage approach that jointly handles detection, tracking, and spatial-temporal modeling to recover multi-person meshes directly from video frames without needing explicit single-person cropping or sequence modeling.


## What is the main contribution of this paper?

The main contributions of this paper are:- It proposes CoordFormer, the first single-stage approach for multi-person 3D mesh recovery from videos. Previous methods rely on multi-stage pipelines involving person detection, tracking, and single-person temporal modeling. In contrast, CoordFormer implicitly handles detection and tracking and simultaneously models spatial-temporal relations across multiple people in an end-to-end manner. - It introduces two novel components: 1) Body Center Attention (BCA) to focus features on potential body locations indicated by a predicted body center heatmap, and 2) Coordinate-Aware Attention (CAA) to preserve pixel-level spatial-temporal coordinates when capturing dependencies. - It demonstrates state-of-the-art performance on the challenging 3DPW dataset, outperforming previous best results by 4.2-8.8% on standard metrics while also being 40% faster than recent video-based methods.- It shows the importance of modeling precise pixel-level coordinates for multi-person video mesh recovery, enabled by the proposed CAA module.In summary, the key contribution is a new single-stage approach that advances multi-person video mesh recovery by implicitly handling detection/tracking and modeling detailed spatial-temporal relations across people simultaneously. The proposed BCA and CAA components help achieve this goal.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes CoordFormer, a novel single-stage approach for multi-person 3D mesh recovery from videos that implicitly performs detection and tracking and simultaneously models spatial-temporal relations among people in an end-to-end manner through two new modules - Body Center Attention and Coordinate-Aware Attention.


## How does this paper compare to other research in the same field?

This paper on CoordFormer for video-based 3D human pose and shape estimation makes several notable contributions compared to prior work:- It proposes the first end-to-end single-stage approach for multi-person 3D mesh recovery from videos. Previous methods like VIBE, MEVA, and MPS-Net use a multi-stage pipeline involving person detection, tracking, and single-person sequence modeling. CoordFormer implicitly handles detection and tracking in an end-to-end framework.- It introduces two novel components - Body Center Attention (BCA) and Coordinate-Aware Attention (CAA) modules. BCA focuses features on potential body locations while CAA preserves pixel-level spatial-temporal coordinate information. This allows better multi-person modeling.- It shows state-of-the-art results on 3DPW dataset, outperforming prior video-based methods like VIBE, MEVA, MPS-Net as well as image-based approaches like ROMP and BEV. The single-stage approach also has faster runtime than multi-stage methods.- The paper demonstrates the importance of precise coordinate information for video-based multi-person pose estimation, unlike prior works that rely only on coarse positional encodings.Overall, this paper pushes the state-of-the-art in video-based multi-person pose estimation by proposing an end-to-end approach and novel coordinate-aware attention modules. The gains over prior art highlight the benefits of joint spatial-temporal modeling and preserving pixel-level information for this task.
