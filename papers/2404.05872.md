# [TabConv: Low-Computation CNN Inference via Table Lookups](https://arxiv.org/abs/2404.05872)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "TabConv: Low-Computation CNN Inference via Table Lookups":

Problem:
- Convolutional neural networks (CNNs) require a large number of computations (arithmetic operations) during inference, making them expensive to deploy in hardware. 
- Current approaches to accelerate CNNs still rely heavily on matrix multiplications, leading to significant computational overhead.

Proposed Solution:
- The paper proposes TabConv, a novel CNN approximation method based on converting key operations like convolution and linear layers to table lookups using product quantization. This eliminates most arithmetic operations.

- The key steps are: 
  1) Take a trained CNN and convert convolution operations to matrix multiplications
  2) Map these matrix multiplications to table lookups using product quantization
  3) Use a novel priority masking technique to determine which layers should use table approximation vs retain their original neural network form. This balances accuracy and efficiency.

Main Contributions:
- Proposes TabConv, a new way to accelerate CNNs using table lookups while maintaining high accuracy
- Designs table lookup approximations for key CNN operations - convolution, batch norm, linear layers, activations
- Introduces a priority masking strategy to selectively convert layers to table format to balance accuracy and computation
- Evaluates TabConv on ResNet-18, ResNet-34 and NIN CNNs. It reduces computations by 36.5-99.4% while preserving 93-98.9% of the original accuracy.

In summary, the paper makes CNN inference much more efficient by eliminating arithmetic operations using table lookups while still maintaining the model accuracy through selective layer conversion. The priority masking determines the right set of layers to convert.
