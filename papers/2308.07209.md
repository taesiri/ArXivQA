# [Unified Data-Free Compression: Pruning and Quantization without   Fine-Tuning](https://arxiv.org/abs/2308.07209)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we perform unified pruning and quantization of neural networks in a data-free manner, without requiring access to the original training data or fine-tuning on new data?The key points are:- The paper proposes a unified framework called Unified Data-Free Compression (UDFC) that performs pruning and quantization simultaneously without needing any data. - Most prior work has focused on data-free pruning or data-free quantization separately. Performing them jointly could allow complementary benefits.- The core idea is to make an assumption that a damaged (pruned/quantized) channel's information can be approximated as a linear combination of other channels. - This assumption allows deriving a reconstruction formulation to compensate for information loss from pruning/quantization of a layer by reconstructing the next layer.- The reconstruction error between the original and compressed networks is formulated and theoretically minimized to get a closed-form solution.- Experiments on image classification datasets demonstrate UDFC's effectiveness over state-of-the-art data-free methods, achieving higher accuracy and compression ratios.In summary, the key hypothesis is that simultaneous data-free pruning and quantization can be achieved by approximating damaged channels via other channels and reconstructing accordingly to preserve information. The paper aims to demonstrate this possibility through the proposed UDFC framework.


## What is the main contribution of this paper?

This paper proposes a unified data-free compression framework called UDFC that performs pruning and quantization simultaneously without requiring any original or synthetic data for fine-tuning. The main contributions are:- They propose an assumption that the partial information of a damaged (pruned or quantized) channel can be preserved by a linear combination of other channels. Based on this, they derive a reconstruction form to compensate for the information loss from compression.- They formulate the reconstruction error between the original and compressed networks. The error consists of pruning error and quantization error terms.- They theoretically prove the existence of optimal scale factors that minimize the reconstruction error and derive closed-form solutions for the scale factors. - The experiments on CIFAR-10 and ImageNet datasets demonstrate that UDFC outperforms previous data-free compression methods by a large margin. For example, it achieves 20.54% higher accuracy than state-of-the-art on ImageNet with ResNet-34 compressed to 30% pruning ratio and 6-bit weights.In summary, the key contribution is proposing a unified framework to perform simultaneous pruning and quantization in a data-free manner by reconstructing channels to compensate for information loss. Theoretical analysis and extensive experiments validate the effectiveness of the proposed method.
