# [VIMI: Vehicle-Infrastructure Multi-view Intermediate Fusion for   Camera-based 3D Object Detection](https://arxiv.org/abs/2303.10975)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Vehicle-Infrastructure Cooperative 3D Object Detection (VIC3D) utilizes cameras from both vehicles and roadside infrastructure to provide a broader view of the driving environment. However, there are two main challenges: 1) Calibration noise across cameras due to time asynchrony causes misalignment. 2) Information loss when projecting 2D image features to 3D space.

Proposed Solution:
- The paper proposes VIMI, a novel framework for VIC3D based on intermediate fusion of image features between vehicle and infrastructure. 

- A Feature Compression (FC) module compresses infrastructure features before transmission to reduce bandwidth. 

- A Multi-Scale Cross Attention (MCA) module fuses vehicle and infrastructure features at multiple scales using cross-attention, which selects more useful features to alleviate calibration noise.

- A Camera-aware Channel Masking (CCM) module reweights both vehicle and infrastructure features using camera parameters as guidance to further refine the fused features.

- Features are then projected into a shared 3D voxel space for fusion using camera geometry, before final detection heads.

Main Contributions:

- VIMI is the first work to explore intermediate fusion of camera features for VIC3D, outperforming prior late and early fusion baselines.

- The MCA and CCM modules are specifically designed to tackle calibration noise in VIC3D systems with multiple asynchronous cameras.

- An FC module reduces transmitted data size to improve efficiency.

- Experiments on a real-world VIC3D dataset DAIR-V2X-C demonstrate state-of-the-art detection performance of VIMI over other methods.

In summary, VIMI explores intermediate feature fusion to effectively combine infrastructure and vehicle cameras for improved VIC3D, with modules to handle practical challenges like bandwidth constraints and calibration noise. The solutions and analysis provide a valuable framework and insights to enable broader perception for autonomous driving systems.
