# [FashionNTM: Multi-turn Fashion Image Retrieval via Cascaded Memory](https://arxiv.org/abs/2308.10170)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research focus is developing a multi-turn fashion image retrieval system that can effectively incorporate interactive user feedback over multiple turns. The key ideas and hypotheses are:- Traditional single-turn fashion retrieval systems that only consider feedback from the current turn are limited, as real-world users often provide feedback iteratively over multiple turns to refine their search. - Existing multi-turn dialog models for visuo-linguistic tasks do not have explicit memory and therefore cannot retain long and complex historical information across turns.- A memory-based framework can explicitly model relationships across multiple turns by storing useful information in previous turns and retrieving them when needed. - A novel Cascaded Memory Neural Turing Machine (CM-NTM) with multiple controllers and memories can capture multiple complex relationships from the current input and retain them over time.- The proposed CM-NTM model will outperform existing single-turn and vanilla multi-turn methods on multi-turn fashion retrieval datasets.- The memory-based model will demonstrate capabilities like retaining information across turns and being agnostic to turn order for non-contradictory feedback in interactive settings.So in summary, the central hypothesis is that a memory-based neural architecture can effectively learn representations to perform multi-turn fashion image retrieval from conversational feedback, outperforming existing methods. The key ideas focus on using external memory to model long-term dependencies across feedback turns.


## What is the main contribution of this paper?

 This paper appears to be a LaTeX template for submitting papers to the IEEE International Conference on Computer Vision (ICCV). The main contents are:- Formatting instructions and style guidelines for preparing ICCV papers using LaTeX. This includes information on language, dual submissions, page limits, formatting the title, authors, abstract, body text, figures, tables, references, etc.- An example LaTeX document with dummy content demonstrating how to format an ICCV paper based on the provided guidelines.So in summary, the main contribution of this paper is providing an ICCV LaTeX style template and detailed formatting instructions to help authors prepare and submit papers for the conference. The paper itself does not present any novel research or scientific contributions. It is simply a template for conference paper formatting.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key point from the paper: The paper proposes a novel cascaded memory neural network architecture called FashionNTM for multi-turn fashion image retrieval, which outperforms prior methods by using multiple memories to retain useful contextual information across feedback turns.


## How does this paper compare to other research in the same field?

 Here are some thoughts on how this paper compares to other research in the field of multi-turn fashion image retrieval:- This paper proposes a new memory-based approach called FashionNTM that uses a Cascaded Memory Neural Turing Machine (CM-NTM). Other works have explored using memory networks for multi-turn retrieval, but this specific CM-NTM architecture seems novel. The cascaded design allows encoding multiple relationships across turns by having multiple controllers and memories interact. - Most prior work has focused on single-turn retrieval. This paper tackles the more challenging and realistic multi-turn scenario where users iteratively refine their query over multiple turns. The only other paper that looks at multi-turn fashion retrieval is the Conversational Fashion Image Retrieval (CFIR) method. This paper shows substantial improvements over CFIR, indicating it advances the state-of-the-art.- The paper introduces a new Multi-turn Shoes dataset to facilitate research on this task, as previously there was only one other multi-turn fashion dataset (FashionIQ). Creating new datasets is an important contribution since lack of data is a major bottleneck.- The interactive experiments demonstrating the model's capabilities like memory retention and order invariance for non-contradictory feedback go beyond simply benchmarking on static datasets. This analysis of how the approach generalizes to real-world dynamic scenarios is valuable.- The user study providing human judgments of retrieval quality is an important validation. User satisfaction is the ultimate goal for a fashion retrieval system. The study confirms the proposed FashionNTM approach leads to results preferred by users.- Compared to general dialog and visual dialog papers that do not focus on fashion, this work is tailored to the specific application of interactive fashion retrieval. The visual grounding in fashion images differs from generic images, so this domain-specific focus is beneficial.In summary, the proposed approach, extensive experiments, new dataset, and application-specific contributions seem to push forward the state-of-the-art in multi-turn fashion image retrieval compared to prior work. The results demonstrate both quantitatively and qualitatively that the FashionNTM approach advances research in this direction.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the key future research directions suggested by the authors are:- Developing more high-quality and diverse multi-turn fashion image retrieval datasets. The paper notes the lack of sufficient datasets in this domain as a limitation. Creating more datasets would enable more comprehensive evaluation of multi-turn retrieval approaches.- Extending the proposed approach to non-fashion domains. The authors suggest their memory-based framework could be applied to other areas needing multi-turn feedback-based retrieval solutions.- Improving computational efficiency for real-world deployment. The authors note that computational requirements make deploying current multi-turn retrieval methods practically challenging. Reducing computation time while maintaining performance would aid adoption.- Further exploring different configurations of memory network components. The paper performs ablation studies analyzing impact of factors like memory size and number of memories. More analysis could help optimize architectures. - Incorporating additional modalities beyond text and images. The paper focuses on visuo-linguistic methods, but other modes like audio could provide useful signals in conversational retrieval.- Studying how to handle contradictory or inconsistent user feedback. The paper notes their approach assumes non-contradictory inputs across turns right now. Enhancing robustness would improve real-world viability.So in summary, the main future directions relate to creating better datasets, extending the approach to new applications, improving efficiency for deployment, tuning the memory network architectures, supporting more modalities, and handling inconsistencies in user input over multiple turns.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:The paper proposes a new method for multi-turn fashion image retrieval, where users provide iterative textual feedback to refine the search results. The key idea is to use a cascaded memory neural network architecture to explicitly retain useful information from past turns and combine it with the current input to retrieve images relevant to the cumulative feedback so far. Specifically, the proposed model called FashionNTM extends the Neural Turing Machine with multiple controllers and memories in a cascaded fashion to learn complex relationships across turns. It leverages an existing state-of-the-art single-turn fashion retrieval model to encode the visual and textual input. Experiments on two multi-turn fashion datasets show significant improvements over previous methods, with a 50.5% gain on Multi-turn FashionIQ and 12.6% on Multi-turn Shoes. Additional analysis demonstrates the model's capability for memory retention across turns and order invariance to non-contradictory feedback. A user study indicates the retrieved images are preferred over 83% more compared to other multi-turn approaches.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:The paper presents a novel method for multi-turn feedback-based fashion image retrieval. The task involves iteratively refining an image search based on textual feedback provided by a user over multiple turns. The authors propose a memory-based approach called FashionNTM that uses a novel Cascaded Memory Neural Turing Machine (CM-NTM). This allows encoding multiple relationships from each turn's features across multiple memories to effectively retain and recall useful information over time. The method is evaluated on two multi-turn fashion datasets: Multi-turn FashionIQ and a new Multi-turn Shoes dataset. Results show it significantly outperforms existing state-of-the-art methods, with over 50\% and 12\% relative improvement respectively. Additional experiments demonstrate the model's capabilities of retaining information across turns and being robust to turn order. A user study also indicates the retrieved images are preferred over other methods 83\% of the time. Overall, the memory-based approach provides an effective way to accumulate and utilize information from multiple turns of interactive feedback for fashion image retrieval.


## Summarize the main method used in the paper in one paragraph.

 The paper presents a method for multi-turn fashion image retrieval using a novel cascaded memory neural network architecture called FashionNTM. The key idea is to use an external memory module to explicitly retain and utilize information provided across multiple turns of user feedback. This is in contrast to prior works that aggregate or encode the multi-turn data without explicitly maintaining state. Specifically, the method uses a pre-trained single-turn fashion retrieval model to extract image and text features for each turn. These features are fed into a Cascaded Memory Neural Turing Machine (CM-NTM) module, which derives multiple views of the input feature. Each derived feature interacts with its own memory controller, read/write heads, and memory module in a cascaded fashion - output of one memory propagates to the next. This allows capturing multiple complex relationships across the turns. The final output feature from the CM-NTM is compared to target image features using a similarity loss for training. During inference, the modified query feature is matched against database image features to retrieve the closest result.Experiments show that modeling long-term dependencies via explicit memory results in improved multi-turn retrieval performance compared to prior approaches. Qualitative examples also demonstrate the model's ability to retain information across turns.


## What problem or question is the paper addressing?

 The paper appears to be providing author guidelines for submitting a paper to the IEEE International Conference on Computer Vision (ICCV). The main things it addresses are:- Language requirements - the paper must be in English.- Dual submission policy - it discusses the policy on submitting the same paper to multiple conferences. - Page length - papers are limited to 8 pages, excluding references.- Formatting requirements - it provides details on margins, fonts, sections, footnotes, references, figures, etc. that authors need to follow.- Blind review process - authors should not identify themselves in the paper to allow for an anonymous review process. - Including copyright release forms - authors must submit a signed copyright form when submitting the final camera-ready paper.So in summary, it is a set of author instructions on formatting, page limits, policies, etc. for submitting papers to the ICCV conference. The goal is to standardize the submission and review process across all papers.
