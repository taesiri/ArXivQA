# [Comparing Software Developers with ChatGPT: An Empirical Investigation](https://arxiv.org/abs/2305.11837)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be:"How do software engineers compare with AI solutions like ChatGPT with respect to performance and memory efficiency in solving coding problems?"The authors conduct an empirical study to compare the performance and memory efficiency of code solutions generated by ChatGPT versus solutions provided by human software engineers for coding problems at different difficulty levels. The key aspects are:- The authors select coding problems from a recent LeetCode contest and use them as prompts for ChatGPT to generate code solutions. - They then upload the ChatGPT-generated solutions to LeetCode to compare them against solutions previously submitted by human programmers.- The human programmers are categorized into experienced contest programmers and novice programmers based on their LeetCode ranking and contest participation. - The solutions are evaluated and compared based on runtime performance and memory efficiency metrics provided by LeetCode.So in essence, the central research question is how ChatGPT's automated coding solutions compare to human-written code by programmers of different skill levels, using quantitative performance metrics like runtime and memory usage. The goal is to empirically evaluate the relative strengths of AI versus human coding.


## What is the main contribution of this paper?

The main contribution of this paper is presenting an empirical study to compare the performance of software engineers versus AI systems like ChatGPT in solving coding problems. The key points are:- The paper conducts an empirical investigation to evaluate how the problem-solving capabilities of programmers compare to ChatGPT in terms of performance and memory efficiency for coding tasks. - It performs an experiment using coding problems from Leetcode, generating solutions via ChatGPT, and comparing them to existing human-written solutions based on metrics like runtime and memory usage.- The experiment involves analyzing solutions from programmers of varying expertise levels - experienced contest programmers and novice programmers. - The results show that for easy and medium problems, ChatGPT can surpass the performance of novice programmers but does not exceed experienced programmers. For memory efficiency, ChatGPT outperformed both groups in one medium problem.- The findings suggest a nuanced relationship between human and AI performance - in some cases engineers excel while in others AI is superior, highlighting the need for collaborative human-AI approaches.- The paper emphasizes the importance of empirical studies to evaluate claims about AI substituting software engineers, and examines metrics beyond just accuracy like runtime and memory usage.In summary, the key contribution is an empirical study and experiment comparing the performance of ChatGPT versus programmers of different skill levels on coding problems, providing evidence on when AI can surpass humans for certain tasks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper presents an empirical study comparing the performance and memory efficiency of coding solutions generated by ChatGPT versus solutions provided by programmers with different levels of expertise, in order to evaluate the potential for AI-based automation of software engineering tasks.
