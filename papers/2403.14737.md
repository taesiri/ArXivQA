# [FedMef: Towards Memory-efficient Federated Dynamic Pruning](https://arxiv.org/abs/2403.14737)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "FedMef: Towards Memory-efficient Federated Dynamic Pruning":

Problem:
- Federated learning (FL) enables collaborative training of models across decentralized devices while preserving data privacy. However, deploying FL on resource-constrained edge devices is challenging due to the high demand for computation and memory to train deep learning models. 
- Existing federated pruning methods rely on initially training dense models which is not suitable for edge devices. Recent works use federated dynamic pruning but suffer from significant accuracy drop after pruning and high activation memory usage.

Proposed Solution:
- The paper proposes FedMef, a novel memory-efficient federated dynamic pruning framework to generate specialized sparse models directly on devices.

Key Components:
- Budget-Aware Extrusion (BaE): Salvages important information from low-magnitude parameters marked for pruning by transferring it to other parameters using a surrogate loss function. This preserves post-pruning accuracy.
- Scaled Activation Pruning (SAP): Effectively reduces activation memory usage by pruning activations during training using Normalized Sparse Convolutions, which centers activations around zero.

Main Contributions:
- Introduces BaE to reduce information loss during federated dynamic pruning, preserving post-pruning accuracy.
- Proposes SAP to significantly compress activation memory without relying on batch normalization layers.
- Achieves superior accuracy and 28.5% memory savings compared to state-of-the-art methods on image classification datasets and models.
- Establishes new benchmarks for federated dynamic pruning on more complex datasets like CINIC-10 and TinyImageNet.

In summary, the paper makes vital contributions in addressing issues of post-pruning accuracy drop and high activation memory in federated dynamic pruning to facilitate specialized sparse model development directly on resource-constrained edge devices.
