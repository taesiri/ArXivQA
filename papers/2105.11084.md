# [Unsupervised Speech Recognition](https://arxiv.org/abs/2105.11084)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we develop an unsupervised speech recognition system that can learn to map speech to text without any labeled data, relying only on unlabeled speech audio and unlabeled text?The key hypothesis is that by leveraging high-quality self-supervised speech representations from the wav2vec 2.0 model to segment and embed the speech audio, and using adversarial training to learn a mapping to phonemes, it is possible to train an accurate unsupervised speech recognition model. The paper shows that their proposed wav2vec-U system achieves significantly lower error rates compared to prior unsupervised methods, reducing the phoneme error rate on TIMIT from 26.1 to 11.3. On the Librispeech benchmark, wav2vec-U achieves a word error rate of 5.9 on the test-other set, rivaling some of the best supervised systems trained on 960 hours of labeled data.In summary, the central research question is how to develop an unsupervised speech recognition system, with the key hypothesis being that leveraging self-supervised representations and adversarial training can enable building accurate models without any labeled data. The experiments demonstrate the viability of this approach across various benchmarks and languages.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution is developing an unsupervised speech recognition framework called wav2vec-U that can be trained without labeled data. The key ideas include:- Using self-supervised representations from the wav2vec 2.0 model to segment and embed speech audio. Specifically, they found the representations from the 15th layer of wav2vec 2.0 worked best.- Segmenting the audio into units using k-means clustering on the wav2vec 2.0 representations. - Mapping the segmented representations to phonemes via adversarial training against unlabeled phonemized text. This involves a lightweight generator network.- Introducing an unsupervised cross-validation metric to enable model selection and hyperparameter tuning without labeled data. - Showing strong results on TIMIT, Librispeech, and other languages, outperforming prior unsupervised methods. On Librispeech test-other, they achieve 5.9 WER rivaling supervised models from a few years ago trained on 960 hours of labeled data.So in summary, the main contribution is developing an effective framework and techniques for training speech recognition models in a completely unsupervised manner without any labeled data. This helps enable speech recognition for many more languages.
