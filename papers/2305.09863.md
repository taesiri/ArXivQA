# [Explaining black box text modules in natural language with language   models](https://arxiv.org/abs/2305.09863)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: Can we automatically generate natural language explanations for black box text modules, with only access to their inputs and outputs?The key points are:- The paper proposes a method called "Summarize and Score" (SASC) to generate natural language explanations for "text modules". - A "text module" is defined as any function that maps text to a continuous scalar value, like a neuron in a pretrained language model or a model predicting brain activity.- The explanations should describe what input text causes the largest positive responses from the module, without needing access to the module's internal structure or weights.- The method is evaluated on synthetic modules with known explanations, modules extracted from BERT, and modules predicting fMRI voxel responses. - For the synthetic modules, SASC is able to recover ground truth explanations with high accuracy under different noise conditions.- For BERT modules, SASC generates explanations comparable in quality to human-provided ones. The explained modules are often relevant for downstream tasks.- For fMRI voxel modules, SASC generates explanations pertaining to social concepts more than the BERT modules.So in summary, the key research question is whether natural language explanations can be automatically generated for black box text modules, with evaluations on synthetic, BERT, and fMRI modules suggesting this approach can work.


## What is the main contribution of this paper?

The main contribution of this paper is presenting MPrompt, a method for automatically generating natural language explanations for black box text modules. The key ideas are:- Text modules are functions that map text to a continuous scalar value, such as neurons within a large language model. The method requires only blackbox access to the module's inputs and outputs.- MPrompt generates explanation candidates by extracting and summarizing the ngrams that elicit the largest positive responses from the module. It uses a large language model to perform the summarization. - MPrompt evaluates each candidate explanation by generating synthetic text based on the explanation and testing the module's response. The explanation with the largest difference in response between related and unrelated text is selected.- An explanation score rates how reliably the explanation describes the module.The method is evaluated by recovering ground truth explanations for synthetic modules, explaining internal modules in BERT, and explaining fMRI voxel responses to language. Overall, MPrompt provides a way to automatically generate natural language explanations for black box text modules without human involvement.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper introduces a method called SASC to automatically generate natural language explanations for text modules, which are functions that map text to a scalar value, and applies it to modules in BERT and fMRI voxel responses to gain insights about their behavior.
