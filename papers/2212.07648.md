# [Relightable Neural Human Assets from Multi-view Gradient Illuminations](https://arxiv.org/abs/2212.07648)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be: 

How can we create high-quality 3D human assets that support both modeling and relighting applications, by combining multi-view stereo (MVS) and photometric stereo (PS) techniques?

The key ideas and contributions seem to be:

- Developing a new capture system called UltraStage that integrates MVS (multi-view stereo) and PS (photometric stereo) to acquire high-quality images of human subjects.

- Capturing a large-scale dataset called UltraStage Dataset with over 2000 human assets under varying viewpoints and illuminations. 

- Proposing methods to process the captured data into "neural human assets" - neural network representations that enable novel view synthesis and relighting.

- Demonstrating applications like high-quality geometry reconstruction, realistically relighting images in the wild, and synthesizing novel views under arbitrary lighting.

- Releasing the dataset and processing tools to the research community.

So in summary, the central hypothesis appears to be that combining MVS and PS in a unified capture system and dataset will enable creating neural assets that support both high-quality modeling and relighting of human subjects. The paper aims to demonstrate this via the proposed capture system, dataset, and neural processing pipeline.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Presenting UltraStage, a novel 3D human dataset that combines multi-view stereo (MVS) and photometric stereo (PS) capture to provide high-quality images and surface normals of human subjects under varying viewpoints and illuminations. The dataset contains over 2000 human assets. 

2. Proposing a pipeline to process the captured data into relightable neural human assets that enable novel view synthesis under arbitrary lighting conditions. This involves using the PS normals to train a neural signed distance field for geometry, generating G-buffers with depth-guided texture blending, and optimizing a neural material field.

3. Demonstrating the efficacy of the UltraStage dataset for single image relighting. Using the dataset to train simple networks for albedo and normal prediction leads to more realistic relighting compared to prior arts.

In summary, the key contribution is the introduction of the UltraStage dataset and processing pipeline to obtain high-fidelity relightable neural assets of human subjects. The integration of MVS and PS in the capture system along with the neural processing enables representing very fine details and supporting photorealistic view synthesis and relighting applications. The dataset and tools have significant potential to advance research in human modeling, rendering, and generation tasks.
