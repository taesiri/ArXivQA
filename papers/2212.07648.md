# [Relightable Neural Human Assets from Multi-view Gradient Illuminations](https://arxiv.org/abs/2212.07648)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be: 

How can we create high-quality 3D human assets that support both modeling and relighting applications, by combining multi-view stereo (MVS) and photometric stereo (PS) techniques?

The key ideas and contributions seem to be:

- Developing a new capture system called UltraStage that integrates MVS (multi-view stereo) and PS (photometric stereo) to acquire high-quality images of human subjects.

- Capturing a large-scale dataset called UltraStage Dataset with over 2000 human assets under varying viewpoints and illuminations. 

- Proposing methods to process the captured data into "neural human assets" - neural network representations that enable novel view synthesis and relighting.

- Demonstrating applications like high-quality geometry reconstruction, realistically relighting images in the wild, and synthesizing novel views under arbitrary lighting.

- Releasing the dataset and processing tools to the research community.

So in summary, the central hypothesis appears to be that combining MVS and PS in a unified capture system and dataset will enable creating neural assets that support both high-quality modeling and relighting of human subjects. The paper aims to demonstrate this via the proposed capture system, dataset, and neural processing pipeline.
