# [Promoting Counterfactual Robustness through Diversity](https://arxiv.org/abs/2312.06564)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper studies the robustness of counterfactual explanations, which explain how an input to a machine learning model can be altered to change the model's prediction. The authors note that counterfactual explainers can lack robustness if a minor change in the input causes a major change in the explanation. They show both theoretically and empirically that reporting multiple diverse counterfactuals instead of a single one can improve robustness. However, computing an exhaustive set of all counterfactuals is infeasible, so they propose an efficient approximation algorithm that incrementally builds a diverse set of counterfactuals. Through experiments on several datasets, they demonstrate that their method generates more robust counterfactual explanations than the state-of-the-art DiCE algorithm, while also outperforming DiCE on other metrics like diversity and runtime. The authors conclude that promoting diversity is an effective strategy for improving the robustness of counterfactual explanations.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Promoting Counterfactual Robustness through Diversity":

Problem:
- Counterfactual explanations explain how an input to a machine learning model can be changed to alter the model's prediction. However, recent work has shown that counterfactual explanations can lack robustness - a minor change in the input can cause a major change in the explanation. This causes issues for user trust and understanding, fairness, and vulnerability to attacks.

- There are two core reasons identified for the lack of robustness. First, local search methods used to generate counterfactuals can be highly sensitive to small input changes. Second, there is a more fundamental issue that when an input lies close to a decision boundary between classes, even small input changes can alter the closest counterfactual significantly.  

- The paper aims to develop counterfactual explanation methods with improved robustness guarantees.

Proposed Solution: 
- The paper first formally defines robustness for counterfactual explainers using set distance metrics to quantify the change in explanations under input changes.

- It shows theoretically that reporting multiple diverse counterfactuals instead of a single one can improve robustness. In particular, reporting all approximate counterfactuals within some tolerance can give robustness guarantees.

- Since exhaustively reporting all approximate counterfactuals is infeasible, the paper develops a greedy approximation algorithm. This selects a diverse subset of counterfactuals guided by data examples using angle/distance diversity criteria.

- Binary search is then used to map the selected data examples to their closest counterfactuals to return.


Main Contributions:

- Identifies fundamental reasons for lack of counterfactual robustness based on decision boundaries

- Provides formal robustness definitions and theoretical robustness results for exhaustive counterfactual sets  

- Develops a feasible approximation algorithm for generating diverse yet robust counterfactual sets

- Empirically demonstrates improved robustness over prior methods, while maintaining counterfactual validity, diversity and efficiency

The key insight is that reporting multiple, diverse counterfactuals can make explanations more robust to minor input variations than a single counterfactual. This helps address some inherent limitations around decision boundaries. The proposed methods balance robustness, diversity, and efficiency.
