# [Bytes are All You Need: End-to-End Multilingual Speech Recognition and   Synthesis with Bytes](https://arxiv.org/abs/1811.09021)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is whether using Unicode bytes to represent text can improve multilingual end-to-end speech recognition and synthesis compared to using graphemes. Specifically, the key hypotheses tested in this paper are:- Using bytes instead of graphemes as output units can improve monolingual end-to-end speech recognition for languages with large grapheme vocabularies (e.g. Japanese, Korean).- A multilingual byte-based end-to-end model can outperform individual monolingual models by sharing representations across languages. - A byte-based end-to-end model can handle code-switching speech better than grapheme models.- A multilingual byte-based text-to-speech model can match the performance of monolingual grapheme models.So in summary, the central research question is whether bytes are a better text representation than graphemes for multilingual end-to-end speech processing. The key hypotheses test this for both speech recognition and synthesis tasks.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Proposing the use of Unicode bytes as a language representation for end-to-end multilingual speech recognition and synthesis models. 2. Presenting Audio-to-Byte (A2B) and Byte-to-Audio (B2A) models that operate on byte sequences directly, avoiding the need to handle large grapheme vocabularies or modify model structure when adding new languages.3. Showing that byte models outperform grapheme models for both multilingual and monolingual ASR, with the multilingual A2B model outperforming monolingual baselines by 4.4% relatively on average. 4. Demonstrating the benefits of byte models for code-switching ASR, where the multilingual A2B model achieves 38.6% relative improvement over monolingual baselines.5. Presenting a multilingual B2A model for TTS that matches the performance of monolingual baselines.In summary, the key contribution is proposing and demonstrating the effectiveness of using byte sequences as a compact multilingual representation for end-to-end speech recognition and synthesis.
