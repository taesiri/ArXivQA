# [Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of   Language Models](https://arxiv.org/abs/2402.10353)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Prompt-based learning with pre-trained language models (LMs) is susceptible to the intrinsic biases present in the LMs, resulting in sub-optimal performance for zero/few-shot learning. 
- Prior work on mitigating intrinsic bias focuses on social fairness and requires expensive data augmentation and retraining, which degrades language modeling abilities.
- Efficiently calibrating intrinsic bias in LMs to enhance downstream prompt-based learning performance remains an open problem.

Proposed Solution:
- Propose a "null-input prompting" method to calibrate intrinsic bias in pre-trained masked LMs like RoBERTa.
- Leverage GPT-4 to auto-generate diverse null-meaning inputs (symbols, words, phrases) that contain no task-relevant information. Construct prompts by concatenating null inputs with an answer format.
- Select null inputs where the answer format has higher next sentence prediction probability for better integration.  
- Update only the bias parameters (0.1% of params) of LMs using KL divergence loss between output distribution on null prompts and uniform distribution.
- Use different early stopping criteria for zero-shot vs few-shot downstream tasks.

Main Contributions:
- Introduce an efficient null-input prompting method to calibrate intrinsic bias in pre-trained Masked LMs to enhance downstream zero/few-shot prompt learning.
- Incorporate two key features - auto-generated null prompts and updating only bias parameters - for efficient calibration, preserving language modeling abilities.
- Experiments on 8 classification datasets with 4 prompt learning approaches show the calibration method significantly improves LM zero/few-shot performance for both in-context learning (9% on average) and prompt-based fine-tuning (2% on average).
- Analysis shows calibrated LMs demonstrate more equitable probability distribution on null inputs and improved separability for correct predictions.

In summary, the paper proposes an efficient intrinsic bias calibration method for pre-trained LMs using auto-constructed null-input prompts and light model updates. Experiments confirm substantial gains in downstream zero/few-shot prompt learning scenarios while preserving language modeling abilities.
