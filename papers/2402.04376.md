# [Scaling laws for learning with real and surrogate data](https://arxiv.org/abs/2402.04376)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Collecting large quantities of high-quality training data is often prohibitively expensive or impractical, limiting machine learning performance. 
- An alternative is to supplement a small set of real "original" data with additional "surrogate" data from cheaper sources like public datasets, data collected in different circumstances, or synthetic data from generative models. However, it is unclear how best to leverage this heterogeneous data.

Proposed Solution:
- Use a weighted combination of empirical risk on the original data and surrogate data for training, with relative weight α for surrogate data.
- Develop a scaling law to predict test error and optimally set α based on excess risk curves when training only on original or surrogate data.

Key Contributions:
- Demonstrate significant test error reductions by optimally mixing small original dataset with surrogate data, even when distributions are very different. 
- Confirm the scaling law accurately models empirical test error across diverse real and simulated datasets. It also guides good choices of α.
- Scaling law specializes to match theoretical predictions in several settings: low-dimensional asymptotics, nonparametric regression, and high-dimensional ridge regression.
- Scaling law enables a simple 3-step procedure to predict test error reductions from any amount of surrogate data, using empirical fit of scaling curves.

In summary, the paper provides an effective framework based on weighted risk and scaling laws to leverage heterogeneous data sources, guiding choices to maximize test performance on the target data distribution. Both theory and experiments confirm principled mixing of data provides significant accuracy gains.
