# [LOTUS: Evasive and Resilient Backdoor Attacks through Sub-Partitioning](https://arxiv.org/abs/2403.17188)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Existing backdoor attacks on deep learning models typically rely on a uniform trigger pattern or transformation function that induces the backdoor behavior. However, such universal triggers can be easily detected and removed. Recently proposed sample-specific invisible attacks are more evasive but less resilient to defense methods. 

Proposed Solution - LOTUS Attack:
The paper proposes a new attack called LOTUS that achieves both evasiveness and resilience. The key ideas are:

1) Victim Class Sub-Partitioning: Samples from the victim class are separated into distinct partitions using either explicit attributes or an implicit learning-based method. 

2) Unique Triggers: A different trigger is injected into each partition during training to induce the backdoor.

3) Trigger Focusing: A novel training technique that precisely limits each trigger to only be effective on its designated partition, preventing universal attack effects.  

Main Contributions:

- Proposes the LOTUS attack that sub-partitions the victim class and assigns unique triggers to evade detection and enable resilience.

- Introduces an efficient trigger focusing method during training that bounds the scope of each trigger to its respective partition.

- Achieves high attack success rates across diverse datasets and model architectures.  

- Demonstrates evasiveness against 13 state-of-the-art detection methods and resilience against 4 mitigation baselines, outperforming prior attacks.

In summary, the paper presents an innovative attack that leverages victim class sub-partitioning and trigger focusing to attain both evasiveness and resilience, posing a new threat to DL model security.
