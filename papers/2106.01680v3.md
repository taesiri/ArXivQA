# [Convergent Graph Solvers](https://arxiv.org/abs/2106.01680v3)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is: 

How can we develop a deep learning method that can learn to construct iterative mappings to predict the properties of a graph system at its stationary state (fixed point) with guaranteed convergence, without requiring prior knowledge of existing solvers or intermediate solutions?

The key points are:

- The paper proposes a new deep learning method called Convergent Graph Solver (CGS) to address this question. 

- CGS learns to construct input-dependent linear contracting iterative maps tailored to each input graph. This guarantees convergence to unique fixed points that embed features useful for predicting properties of interest.

- CGS computes these fixed points and decodes them to make predictions, without needing prior knowledge of existing solvers or intermediate solutions like previous methods.

- The convergence is guaranteed by the contractivity of the learned linear maps, proven using fixed point theory.

- CGS is trained end-to-end using an efficient gradient computation based on the implicit function theorem.

So in summary, the central research question is about developing a deep learning approach with guaranteed convergence for predicting graph system properties, without relying on existing solvers or intermediate solutions. CGS is proposed as a novel method to address this question.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel deep learning method called Convergent Graph Solver (CGS) for predicting properties of graph systems at their stationary states or fixed points. The key ideas are:

- CGS learns to construct input-dependent linear contracting iterative maps, whose repeated application is guaranteed to converge to unique fixed points. This allows finding fixed points of complex graph systems without requiring analytical domain knowledge. 

- The fixed points found by CGS embed useful features of the input graph for predicting the target property. CGS decodes the features in the fixed points through a separate neural network.

- An efficient way to compute gradients via implicit differentiation is developed to train CGS end-to-end. This allows training with constant memory over iterative steps.

- CGS is evaluated on physical diffusion and Markov decision process problems where true fixed points exist. It matches or exceeds standard baselines in accurately predicting properties from fixed points.

- CGS is also shown to work well on graph classification tasks by finding "virtual" fixed points useful for prediction. This demonstrates potential as a general graph learning layer.

In summary, the key contribution is a novel end-to-end trainable deep learning architecture for finding and utilizing guaranteed fixed points of graph systems, with applications to predicting properties of complex physical and discrete systems as well as general graph representation learning.
