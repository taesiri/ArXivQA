# Object Detectors Emerge in Deep Scene CNNs

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: What is the nature of the internal representation learned by convolutional neural networks (CNNs) trained on scene classification using the Places dataset? Specifically, the authors investigate whether meaningful object detectors emerge inside the CNN despite it being trained only for scene classification without any object-level supervision.Some key points:- The paper trains two CNNs with the same architecture - one on ImageNet for object classification (ImageNet-CNN) and another on Places for scene classification (Places-CNN). - Through visualizations and probing, the authors find that object detectors emerge in the later layers of Places-CNN, more so than in ImageNet-CNN. - The objects discovered correlate to the most frequent and discriminative objects for scene recognition.- This shows a single CNN can support both scene recognition and object localization without needing multiple outputs or networks.- It sheds light on the learned representations and transferable features captured by CNNs trained on different tasks.In summary, the central hypothesis is that object detectors will emerge inside a CNN trained for scene classification despite no supervision for objects, revealing the nature of the learned representation.


## What is the main contribution of this paper?

The main contribution of this paper is demonstrating that object detectors can emerge inside a convolutional neural network (CNN) trained for scene recognition, without explicitly being trained to detect objects. Specifically, the authors trained a CNN called Places-CNN on a large dataset of scene images from 205 categories. Through visualization and analysis, they found that units in the later layers of Places-CNN behaved like object detectors, responding to specific objects even though the network was never trained to detect objects. For example, some units detected beds, lamps, chairs etc. Further, the object detectors that emerged corresponded to objects that were most discriminative for recognizing the scene categories. The authors show that the same network can support recognition at multiple levels of abstraction (edges, textures, objects, scenes) in a single forward pass, without needing multiple outputs or networks. This demonstrates that meaningful object representations can arise naturally from learning to recognize scenes, since scenes are composed of objects. The emergence of object detectors inside the CNN reveals something about the nature of representations learned by these networks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper shows that object detectors emerge inside a convolutional neural network trained for scene classification, demonstrating that the same network can support recognition at multiple levels of abstraction in a single forward pass without needing explicit supervision for objects.


## How does this paper compare to other research in the same field?

This paper makes several interesting contributions to understanding the internal representations learned by convolutional neural networks (CNNs) for scene and object recognition:- It compares CNNs trained on scene-centric data (Places-CNN) versus object-centric data (ImageNet-CNN), finding that both develop some object detection capabilities but Places-CNN discovers more objects without supervision. This shows these networks can support multiple levels of abstraction in a single model.- It visually explores the receptive fields and activation patterns of units in different layers, finding they become more semantically meaningful in deeper layers. - It has humans annotate the semantic concepts captured by each unit, quantifying the precision and type of semantics (low-level to high-level) learned in each layer. This reveals a progression from simple features to objects/scenes.- It analyzes which specific object categories emerge, relating them to object frequencies and discrimination ability for scene classification. Objects useful for discrimination are frequently discovered.- It shows these emergent object detectors can be used to localize objects within scenes in a single forward pass, despite only being trained for scene classification.Compared to prior work:- Visualizing receptive fields and semantics of units provides more insight than just feature visualization methods like activation maximization.- Discovering emergent objects without supervision goes beyond supervised CNNs trained on ImageNet. It relates to unsupervised discovery but shows more objects can emerge in a supervised setting.- Using a single network for both scene and object recognition is more efficient than approaches needing multiple networks or passes.Overall, this provides new analysis and understanding of CNN representations, revealing the automatic emergence of object detectors tuned for discrimination in a scene recognition model. The methods introduced help characterize the representations learned.
