# Object Detectors Emerge in Deep Scene CNNs

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: What is the nature of the internal representation learned by convolutional neural networks (CNNs) trained on scene classification using the Places dataset? Specifically, the authors investigate whether meaningful object detectors emerge inside the CNN despite it being trained only for scene classification without any object-level supervision.Some key points:- The paper trains two CNNs with the same architecture - one on ImageNet for object classification (ImageNet-CNN) and another on Places for scene classification (Places-CNN). - Through visualizations and probing, the authors find that object detectors emerge in the later layers of Places-CNN, more so than in ImageNet-CNN. - The objects discovered correlate to the most frequent and discriminative objects for scene recognition.- This shows a single CNN can support both scene recognition and object localization without needing multiple outputs or networks.- It sheds light on the learned representations and transferable features captured by CNNs trained on different tasks.In summary, the central hypothesis is that object detectors will emerge inside a CNN trained for scene classification despite no supervision for objects, revealing the nature of the learned representation.


## What is the main contribution of this paper?

The main contribution of this paper is demonstrating that object detectors can emerge inside a convolutional neural network (CNN) trained for scene recognition, without explicitly being trained to detect objects. Specifically, the authors trained a CNN called Places-CNN on a large dataset of scene images from 205 categories. Through visualization and analysis, they found that units in the later layers of Places-CNN behaved like object detectors, responding to specific objects even though the network was never trained to detect objects. For example, some units detected beds, lamps, chairs etc. Further, the object detectors that emerged corresponded to objects that were most discriminative for recognizing the scene categories. The authors show that the same network can support recognition at multiple levels of abstraction (edges, textures, objects, scenes) in a single forward pass, without needing multiple outputs or networks. This demonstrates that meaningful object representations can arise naturally from learning to recognize scenes, since scenes are composed of objects. The emergence of object detectors inside the CNN reveals something about the nature of representations learned by these networks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper shows that object detectors emerge inside a convolutional neural network trained for scene classification, demonstrating that the same network can support recognition at multiple levels of abstraction in a single forward pass without needing explicit supervision for objects.
