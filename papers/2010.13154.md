# [Attention is All You Need in Speech Separation](https://arxiv.org/abs/2010.13154)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is whether an RNN-free Transformer-based architecture can achieve state-of-the-art performance on speech separation tasks. The key hypothesis is that transformers can effectively learn both short and long-term dependencies for speech separation without relying on recurrent connections, enabling parallelization and faster training/inference.Specifically, the paper proposes a new model called SepFormer that uses a multi-scale transformer architecture to model local and global contexts. It evaluates this RNN-free model on the WSJ0-2mix and WSJ0-3mix speech separation datasets and compares its performance to recent RNN-based methods like DPRNN, DPTNet and Wavesplit.In summary, the main research question is: Can transformers match/exceed the performance of RNNs for speech separation while also being more parallelizable and faster? The results indicate that the answer is yes. The SepFormer achieves new state-of-the-art results, demonstrating the potential of RNN-free architectures based entirely on attention for this audio processing task.
