# [Wiki-TabNER:Advancing Table Interpretation Through Named Entity   Recognition](https://arxiv.org/abs/2403.04577)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing benchmark datasets for evaluating table interpretation (TI) tasks like entity linking (EL) make a simplifying assumption of one entity mention per cell. 
- This fails to capture the complexity of real-world tables which often have multiple entity mentions per cell.
- The authors analyze the WikiTables corpus and find 75.2% of cells have additional text that is removed during preprocessing for existing benchmarks like TURL.

Proposed Solution:
- The authors construct a new benchmark dataset called Wiki-TabNER from a subset of WikiTables consisting of over 50k tables.
- The tables have between 2-20 columns, at least 3 rows, 90% linked cells and average â‰¥2 links per cell to capture greater complexity.
- The tables and cells are clipped to a max of 512 tokens to be compatible with transformer models.
- Entity mentions are annotated with 7 types from DBpedia and both BIO tagging and span-based labeling schemes.

Contributions:
- Analysis showing limitations of assumption of 1 entity per cell in existing benchmarks.
- New challenging Wiki-TabNER dataset for evaluating entity linking and table NER tasks.
- Evaluation framework and experiments analyzing few-shot performance of LLMs like GPT-3 on table NER using the new dataset. 
- Results show significant gains from using similarity-based few-shot examples versus random, highlighting dataset's challenge.
- Qualitative analysis providing insights into remaining annotation issues and directions for future work.

In summary, the key contribution is a more realistic benchmark for table interpretation that can better evaluate model robustness through a novel table NER task focused on multiple entity mentions per cell.
