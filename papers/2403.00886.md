# [Evaluating and Correcting Performative Effects of Decision Support   Systems via Causal Domain Shift](https://arxiv.org/abs/2403.00886)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- The paper considers the problem of "performative prediction", where a prediction model affects the distribution of the target variable it is trying to predict. For example, a churn prediction model that warns companies of customers at high risk of churning might cause the company to take action to retain those customers.

- The paper focuses on the setting of "decision support systems" (DSS) that deliberately make performative predictions to instigate action and improve outcomes. However, naive retraining of such DSS models can suffer from "performative bias", underestimating risk due to the successful actions caused by previous models. 

- The paper argues for the importance of properly evaluating DSS systems before and after deployment to assess their "deployment effect" and "retraining effect". However, randomized trials may be infeasible or unethical. The evaluation then becomes a challenging domain adaptation problem.

Proposed Solution:
- Models the deployment of a DSS as a domain shift from "DSS off" (D=0) to "DSS on" (D=1), with the DSS prediction model parameters as explicit variables.

- Defines the "deployment effect" and "retraining effect" as domain adaptation tasks T1 and T2 for DSS evaluation.

- Shows the problem of estimating a "baseline predictor" without performative bias is another domain adaptation task T3. 

- Proves tasks T1-T3 are mathematically equivalent and not solvable without additional assumptions.

- Introduces the concept of a "domain pivot" - a set of variables that make the target variable independent of the domain shift. If a domain pivot can be measured pre and post deployment, the tasks become solvable.

- Uses a "repeated regression" method to estimate the quantities of interest from the domain pivot. Demonstrates efficacy on example DSS for churn prediction.

- Extends method to handle selection bias and selective labelling, making it widely applicable.

Main Contributions:
- Formalized DSS deployment as a domain shift problem, proposed evaluation metrics and bias correction as key applications.

- Identified need for "domain pivot" to make tasks solvable, proved equivalence and non-identifiability of estimation problems.

- Provided a practical repeated regression framework for DSS evaluation and bias correction even with selection bias or selective labelling.

- Demonstrated value of methods on illustrative DSS example. The work provides an important framework and tools for responsible AI system development.
