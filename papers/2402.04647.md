# [Latent Plan Transformer: Planning as Latent Variable Inference](https://arxiv.org/abs/2402.04647)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
The paper studies generative modeling for planning tasks where the training data only contains sequences of states, actions and total rewards, without step-wise rewards. Planning with such trajectory-return pairs is challenging as the model needs to figure out long-term credit assignments and improve upon sub-optimal demonstrations on its own. Existing methods like Decision Transformer rely on dense step-wise reward signals.

Proposed Solution:
The paper proposes the Latent Plan Transformer (LPT), a latent variable model that generates trajectories conditioned on a latent variable z, which is also used to predict the final return. The key ideas are:

1) The latent variable z serves as an abstraction of the trajectory, aggregated from context-limited sub-trajectories during training. It promotes temporal consistency.  

2) Planning is performed by inferring z that maximizes the return prediction. So z functions as a "plan" guiding policy execution.

3) Learning is based on maximum likelihood over trajectory-return pairs. The gradient estimates expectations over the posterior of z given a trajectory-return pair via MCMC.

Main Contributions:

- Proposes LPT, a novel latent variable model for planning without step-wise rewards
- The inferred latent variable z acts as a persistent plan, enabling long-term credit assignment and trajectory stitching  
- Achieves state-of-the-art performance on several MuJoCo, Maze2D and Connect Four benchmarks
- Shows planning via posterior inference is a promising alternative to reward prompting for temporal consistency

The model is comprehensively evaluated, analyzing its capabilities in nuanced credit assignment, trajectory stitching and handling environment stochaticity. Ablations justify the usefulness of flexible latent space modeling.
