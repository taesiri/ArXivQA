# [Demystifying Causal Features on Adversarial Examples and Causal   Inoculation for Robust Network by Adversarial Instrumental Variable   Regression](https://arxiv.org/abs/2303.01052)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: How can we uncover the underlying causal features that lead to adversarial vulnerability in deep neural networks, and leverage this knowledge to improve adversarial robustness?Specifically, the key goals of the paper seem to be:- To develop a method to estimate the causal features inherent in adversarial examples that are highly related to correct prediction and robustness against adversarial attacks. - To analyze and interpret these estimated causal features to gain insights into the true origin of adversarial examples.- To use these causal features to improve the robustness of neural network defenses against adversarial attacks. The core hypothesis is that by framing the problem from a causal perspective and using adversarial instrumental variable regression, they can identify intrinsic causal features in adversarial examples that provide insights into the fundamental vulnerability. By inoculating these "causal features" into defense models, they aim to enhance robustness against a wide range of adversarial attacks.The paper proposes an adversarial instrumental variable regression method called AMR-GMM to extract these causal features, analyzes their properties, provides visual interpretations, and validates their usefulness by incorporating them into several defense models to improve robustness. Overall, the central thrust is on unveiling and utilizing the causal mechanisms underlying adversarial vulnerability through a causality-driven approach.


## What is the main contribution of this paper?

The main contributions of this paper are:- Proposing adversarial instrumental variable (IV) regression to estimate the causal relation of adversarial prediction and demystify inherent causal features on adversarial examples. This is done by using generalized method of moments (GMM) between a causal feature estimator (hypothesis model) and worst-case counterfactual generator (test function).- Analyzing the properties of the estimated causal features and showing they are highly related to correct prediction for adversarial robustness, while the counterfactuals exhibit extreme features deviating from correct prediction. - Introducing causal inversion to handle the estimated causal features on the possible feature bound.- Proposing causal inoculation to inject the estimated CAusal FEatures (CAFE) into defense networks for improving adversarial robustness.In summary, the key contribution is using adversarial IV regression to uncover and utilize the causal features related to robust prediction on adversarial examples, in order to better understand adversarial vulnerability and improve defense methods. The proposed approaches are evaluated extensively on different datasets, networks and attacks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes using adversarial instrumental variable regression to estimate the inherent causal features in adversarial examples that are highly related to correct prediction, and shows how these estimated causal features can be injected into neural networks to improve adversarial robustness.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other related research on adversarial examples and robustness:- The main novelty is using causal inference and instrumental variables (IV) to try to uncover the true "causal features" underlying adversarial examples. Most prior work has focused more on associations and correlations, which can be biased by confounders. Taking a causal inference viewpoint is relatively new.- The adversarial IV regression approach builds on recent work applying IV methods to deep learning, like DeepIV, KernelIV, and others. But this paper specifically tailors it to the adversarial setting by defining the instrument, treatments, and outcomes appropriately.- For the method itself, it relates closely to recent work using generalized method of moments (GMM) and minimax optimization for nonparametric IV estimation. The technical approach builds off these foundations.- Unlike some recent work trying to directly visualize or interpret adversarial features, this paper takes a more principled causal approach to identify "causal" features related to prediction. The visualization is mainly to validate the causal relations.- For using the estimated causal features, inoculating them into defense models relates conceptually to prior work on distilling robust features. But the causal motivation and inversion process to get a valid representation is unique.- The experiments are fairly extensive, covering different datasets, models, attacks etc. But they are still limited to image classification on standard datasets compared to state-of-the-art.In summary, the causal framing and use of IV methods differentiates this paper from most prior work on understanding and defending against adversarial examples. The technical approach leverages recent IV methods but innovates by specializing them to the adversarial problem. More extensive experiments on more complex domains could further demonstrate the utility. Overall it provides a nice new causal lens on this problem.
