# [Demystifying Causal Features on Adversarial Examples and Causal   Inoculation for Robust Network by Adversarial Instrumental Variable   Regression](https://arxiv.org/abs/2303.01052)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: How can we uncover the underlying causal features that lead to adversarial vulnerability in deep neural networks, and leverage this knowledge to improve adversarial robustness?Specifically, the key goals of the paper seem to be:- To develop a method to estimate the causal features inherent in adversarial examples that are highly related to correct prediction and robustness against adversarial attacks. - To analyze and interpret these estimated causal features to gain insights into the true origin of adversarial examples.- To use these causal features to improve the robustness of neural network defenses against adversarial attacks. The core hypothesis is that by framing the problem from a causal perspective and using adversarial instrumental variable regression, they can identify intrinsic causal features in adversarial examples that provide insights into the fundamental vulnerability. By inoculating these "causal features" into defense models, they aim to enhance robustness against a wide range of adversarial attacks.The paper proposes an adversarial instrumental variable regression method called AMR-GMM to extract these causal features, analyzes their properties, provides visual interpretations, and validates their usefulness by incorporating them into several defense models to improve robustness. Overall, the central thrust is on unveiling and utilizing the causal mechanisms underlying adversarial vulnerability through a causality-driven approach.


## What is the main contribution of this paper?

The main contributions of this paper are:- Proposing adversarial instrumental variable (IV) regression to estimate the causal relation of adversarial prediction and demystify inherent causal features on adversarial examples. This is done by using generalized method of moments (GMM) between a causal feature estimator (hypothesis model) and worst-case counterfactual generator (test function).- Analyzing the properties of the estimated causal features and showing they are highly related to correct prediction for adversarial robustness, while the counterfactuals exhibit extreme features deviating from correct prediction. - Introducing causal inversion to handle the estimated causal features on the possible feature bound.- Proposing causal inoculation to inject the estimated CAusal FEatures (CAFE) into defense networks for improving adversarial robustness.In summary, the key contribution is using adversarial IV regression to uncover and utilize the causal features related to robust prediction on adversarial examples, in order to better understand adversarial vulnerability and improve defense methods. The proposed approaches are evaluated extensively on different datasets, networks and attacks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes using adversarial instrumental variable regression to estimate the inherent causal features in adversarial examples that are highly related to correct prediction, and shows how these estimated causal features can be injected into neural networks to improve adversarial robustness.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other related research on adversarial examples and robustness:- The main novelty is using causal inference and instrumental variables (IV) to try to uncover the true "causal features" underlying adversarial examples. Most prior work has focused more on associations and correlations, which can be biased by confounders. Taking a causal inference viewpoint is relatively new.- The adversarial IV regression approach builds on recent work applying IV methods to deep learning, like DeepIV, KernelIV, and others. But this paper specifically tailors it to the adversarial setting by defining the instrument, treatments, and outcomes appropriately.- For the method itself, it relates closely to recent work using generalized method of moments (GMM) and minimax optimization for nonparametric IV estimation. The technical approach builds off these foundations.- Unlike some recent work trying to directly visualize or interpret adversarial features, this paper takes a more principled causal approach to identify "causal" features related to prediction. The visualization is mainly to validate the causal relations.- For using the estimated causal features, inoculating them into defense models relates conceptually to prior work on distilling robust features. But the causal motivation and inversion process to get a valid representation is unique.- The experiments are fairly extensive, covering different datasets, models, attacks etc. But they are still limited to image classification on standard datasets compared to state-of-the-art.In summary, the causal framing and use of IV methods differentiates this paper from most prior work on understanding and defending against adversarial examples. The technical approach leverages recent IV methods but innovates by specializing them to the adversarial problem. More extensive experiments on more complex domains could further demonstrate the utility. Overall it provides a nice new causal lens on this problem.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Further investigating the origin and properties of adversarial examples from a causal perspective, such as using more advanced causal inference techniques or examining different model architectures. The authors propose adversarial instrumental variable regression as one way to analyze adversarial examples causally, but suggest there is more work to be done in this area.- Exploring ways to leverage and enhance the robust causal features identified in this work. The authors describe how they extract "causal features" related to correct predictions and demonstrate injecting them into models, but suggest further work could be done to understand and utilize these causal features.- Applying the ideas to other domains beyond image classification. The experiments focus on standard computer vision datasets, but the authors suggest the adversarial instrumental variable approach could provide insight in other problem settings like graph neural networks, recommender systems, etc.- Developing more sophisticated attacks and defenses using insights from this causal view of adversarial examples. The causal perspective could inform new algorithm designs for both generating and defending against adversarial attacks.- Extending the work to more complex causal inference techniques. The current approach is based on instrumental variable regression, but other causal inference tools like backdoor adjustment, frontdoor adjustment, etc. could provide additional ways to study adversarial examples.So in summary, the authors point towards further causal analyses, leveraging the robust causal features, expanding to new domains/tasks, and developing improved attacks and defenses as interesting directions stemming from their work. The causal lens seems promising for further demystifying adversarial examples.


## Summarize the paper in one paragraph.

The paper proposes adversarial instrumental variable (IV) regression to uncover the origin of adversarial examples in neural networks. They define the feature variation between natural and adversarial examples as the instrument to identify causal features that are highly predictive of the correct label under adversarial attack. Using generalized method of moments, they pose this as estimating the causal features that are robust to worst-case counterfactual perturbations from a test function. Through experiments, they show the estimated causal features are semantically meaningful and predictive on adversarial examples across datasets and models. They introduce causal feature inversion to project these features back to the input space for use in adversarial training, demonstrating improved robustness by "inoculating" networks with these causal features. The key ideas are leveraging IV regression to uncover causal (robust) features and using them to enhance adversarial training, providing a causal perspective on the problem.
