# [Incorporating Retrieval-based Causal Learning with Information   Bottlenecks for Interpretable Graph Neural Networks](https://arxiv.org/abs/2402.04710)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Graph neural networks (GNNs) have shown great success on various graph-related tasks. However, their black-box nature and lack of interpretability have limited their application in domains like healthcare and security where transparency and accountability are critical. Although existing methods like post-hoc explainers or transparent GNN models have made some progress, they struggle to provide both high-quality explanations and predictions. Post-hoc methods have limited explanation accuracy while transparent models often compromise prediction performance. 

Proposed Solution:
This paper proposes a new interpretable GNN framework called RC-GNN that integrates retrieval-based causal learning with the graph information bottleneck (GIB) theory. The key ideas are:

1) A subgraph retrieval module that retrieves the most informative subgraphs from a candidate set to maximize the mutual information between the retrieved subgraph, input graph, and graph labels. This aims to find sufficient explanations. 

2) A causal graph learning module that compresses the retrieved subgraph using ideas from causality to remove spurious correlations. This minimizes the mutual information between the input graph and compressed subgraph to extract the causal substructure.

Together, retrieval finds meaningful subgraphs and causal learning refines them into high-quality explanations while retaining predictive power.

Main Contributions:

- Proposed a new GNN framework RC-GNN that couples retrieval-based learning and causal graph learning for interpretability.

- Showed theoretically how retrieval can be integrated with causality under the GIB framework to find good explanations.

- Extensive experiments showed RC-GNN gives 32.71% higher precision on real-world explanation tasks and also improves predictions, outperforming state-of-the-art baselines.

- Demonstrated the ability of RC-GNN to find meaningful explanations and improve representations through visualizations.

Overall, RC-GNN significantly advances model interpretations and predictions by an effective fusion of retrieval, causality, and information bottlenecks.
