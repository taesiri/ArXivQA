# [Pre-trained Language Models for Keyphrase Generation: A Thorough   Empirical Study](https://arxiv.org/abs/2212.10233)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Keyphrase extraction and generation are important tasks that help summarize documents and improve search/recommendation systems. Recently, pre-trained language models (PLMs) have been used for these tasks but there is a lack of systematic study on when and how to effectively utilize PLMs. 

Key Research Questions
- How do PLMs compare to state-of-the-art non-PLM methods on keyphrase extraction/generation, especially in low-resource settings? 
- Does the pre-training domain (general vs in-domain) impact performance?  
- Can encoder-only PLMs generate better keyphrases than encoder-decoder PLMs?
- What is the optimal parameter allocation strategy for building efficient seq2seq models?

Methods
- Formulate keyphrase extraction as sequence labeling and keyphrase generation as sequence-to-sequence generation
- Conduct extensive experiments with encoder-only PLMs (BERT, SciBERT) and encoder-decoder PLMs (BART, T5, SciBART)
- Introduce techniques to adapt BERT for sequence generation 
- Pre-train in-domain BART variants: SciBART and NewsBART
- Compare different model architectures and objectives

Key Findings
- Large/in-domain seq2seq PLMs approach state-of-the-art performance while being very sample efficient
- In-domain encoder-only PLMs can achieve strong performance, especially with limited resources
- Model depth should be prioritized over width for seq2seq models
- Allocating more layers to the encoder significantly improves results
- Introduced SciBART and NewsBART establish new state-of-the-art for scientific documents

In summary, the paper presents an in-depth empirical study on effectively utilizing PLMs for keyphrase generation. The findings provide concrete recommendations to build performant and efficient models.
