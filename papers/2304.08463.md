# [Learning to Render Novel Views from Wide-Baseline Stereo Pairs](https://arxiv.org/abs/2304.08463)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

How can we perform high-quality novel view synthesis of real-world scenes using only a single wide-baseline stereo image pair as input? 

In particular, the authors are interested in the challenging setting where the stereo image pair has little overlap, such that many 3D points in the scene are only observed from a single viewpoint. This makes it difficult to compute accurate 3D geometry and appearance for novel view synthesis using traditional multi-view stereo techniques. 

The key hypothesis is that an end-to-end deep learning approach can effectively learn strong geometric priors from data to enable implicit 3D reconstruction and realistic novel view synthesis from such extremely sparse inputs. The paper aims to investigate neural network architectures and training methodologies to tackle this problem.

In summary, the core research question is how to perform photorealistic novel view synthesis of real-world scenes from only two input images with wide baseline and limited overlap, where many points are observed only once. This is achieved by learning data-driven 3D geometric priors using deep neural networks.
