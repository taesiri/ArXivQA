# [Contrastive Learning-Based Spectral Knowledge Distillation for   Multi-Modality and Missing Modality Scenarios in Semantic Segmentation](https://arxiv.org/abs/2312.02240)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Semantic segmentation models suffer performance drops when used exclusively on infrared (IR) images compared to optical images, due to less semantic information. 
- Existing multi-modal fusion techniques either generate fused images or use knowledge distillation, but treat multi-modal and missing modality scenarios as separate issues. This is not optimal for multi-sensor models.

Proposed Solution:
- A new multi-modal fusion model called CSK-Net using contrastive learning-based spectral knowledge distillation and automatic mixed feature exchange for semantic segmentation in optical and IR images.

- Uses shared encoders with separate batch norms to capture multi-spectral information of objects from both modalities. 

- Spectral knowledge distillation distills multi-level semantic features from RGB images into the optical branch of CSK-Net. Contrastive learning ensures compact intra-class representations and preservation of modality-specific style information.

- A novel Gated Spectral Unit (GSU) and mixed feature exchange strategy to regulate the correlation of low and high-frequency information during distillation.

- Distillation early on increases correlation of low-frequency features. GSU and distillation only within optical branch later on controls high-frequency correlation.

- Avoids additional computation costs for missing modalities by reusing features.

Main Contributions:

- End-to-end model CSK-Net for multispectral semantic segmentation in both multi-modal and missing modality scenarios.

- Knowledge distillation and contrastive learning to distill RGB knowledge while retaining IR-specific information.

- GSU and mixed feature exchange to control feature correlation during distillation. 

- Superior performance over state-of-the-art methods on 3 datasets for both multi-modal and missing modality settings, especially in challenging conditions, without increased computation costs.
