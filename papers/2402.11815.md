# [HU at SemEval-2024 Task 8A: Can Contrastive Learning Learn Embeddings to   Detect Machine-Generated Text?](https://arxiv.org/abs/2402.11815)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Machine generated texts are being misused for plagiarism, fake news, exam cheating. But most detection systems rely on knowing the text generation model, which is impractical. 
- The SemEval-2024 shared task provides a dataset to train models for classifying machine vs human texts, where the test data uses a different generator model. So systems need to generalize across models.

Proposed Solution:
- Use a single contrastive learning model rather than an ensemble, with aggressive data augmentation via paraphrasing. 
- Split documents into sentences, paraphrase each sentence separately, then recombine to retain structure.
- Use a shared text encoder for contrastive loss and classifier head. Pull positive/negative pairs from original/paraphrased sentences.  
- Show comparable performance to baseline with 60% fewer parameters.

Main Contributions:
1. Novel data augmentation by aggressive paraphrasing increases data size significantly.
2. Propose unified architecture with contrastive learning that shows strong generalization.   
3. Demonstrate comparable performance with a single model, enabling future exploration of contrastive learning for this task.

The paper provides an initial foray into using contrastive learning for detecting machine text generation. It highlights the viability of this approach and sets the stage for further enhancements via more advanced augmentation, contrastive formulations, and prompting strategies.
