# [Sample, estimate, aggregate: A recipe for causal discovery foundation   models](https://arxiv.org/abs/2402.01929)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing causal discovery algorithms have two key limitations - they require large amounts of data and are very slow, especially as the number of variables grows. Discrete optimization methods explore an exponential search space and quickly become intractable. Continuous optimization methods require fitting generative models to the full data distribution, which is difficult with limited data. 

Proposed Solution: 
The paper proposes a causal discovery framework called SEA (Sample, Estimate, Aggregate) inspired by foundation models. The key idea is to leverage classical algorithms' estimates over small subgraphs and global graph statistics as inputs to a deep learning model. This pretrained model aggregates the features into full causal graphs.

The framework has 3 main steps:
1) Sample - Sample small batches of data and subsets of variables. Compute global statistics like inverse covariance.
2) Estimate - Run classical causal discovery algorithms on subsets to get local estimates. 
3) Aggregate - Feed local estimates and global statistics into a pretrained deep model to predict the full graph.

The model uses an axial attention architecture to propagate information between the local and global features.

Main Contributions:
1) Propose a new framework to build fast, robust and generalizable foundation models for causal discovery using classical algorithms' outputs.
2) Provide theoretical analysis showing the model has capacity to produce causally sound graphs from marginal estimates.
3) Achieve state-of-the-art performance on synthetic and real datasets while being 10-1000x faster than existing methods. Generalizes to unseen mechanisms.  
4) Framework supports any sampling heuristics, classical algorithms and statistical features. Implementations using FCI, GIES and inverse covariance attain strong performance.

In summary, the paper presents a blueprint for developing high-quality causal discovery models by combining classical methods with deep learning in an efficient way. The framework outperforms existing approaches on several fronts.
