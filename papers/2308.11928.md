# [OFVL-MS: Once for Visual Localization across Multiple Indoor Scenes](https://arxiv.org/abs/2308.11928)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the main research goals of this paper are:

1. To develop a unified visual localization framework (OFVL-MS) that can jointly optimize the localization tasks across multiple scenes/datasets in an efficient multi-task learning manner. 

2. To enable the model to share parameters across tasks as much as possible to reduce storage costs, while still allowing task-specific learning to maintain good performance on each scene.

3. To alleviate the gradient conflicts that normally arise when training on multiple datasets jointly, through techniques like the layer-adaptive sharing policy, gradient normalization algorithm, and penalty loss.

4. To show that the model can efficiently generalize to new scenes with minimal extra parameters, while still achieving strong localization performance. 

5. To introduce a new large-scale indoor dataset (LIVL) to benchmark visual localization methods.

In summary, the central hypothesis is that it's possible to develop a unified visual localization model that can be jointly trained on and generalize well to multiple scenes in an efficient multi-task manner, through careful parameter sharing policies and gradient conflict reduction techniques. The paper aims to demonstrate this capability on existing datasets like 7-Scenes and 12-Scenes, as well as the newly proposed LIVL dataset.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes OFVL-MS, a unified framework for visual localization across multiple indoor scenes. OFVL-MS jointly optimizes localization tasks of different scenes in a multi-task learning manner.

2. It introduces a layer-adaptive sharing policy to automatically determine which layers in the neural network backbone should be shared across scenes vs. kept scene-specific. This enables efficient parameter sharing while allowing adaptation to each scene. 

3. It proposes a gradient normalization algorithm that homogenizes the magnitudes of gradients for shared parameters during backpropagation. This helps alleviate gradient conflicts between tasks.

4. It introduces a sparsity penalty loss to promote sharing of parameters across tasks.

5. It presents results on multiple datasets showing OFVL-MS outperforms prior state-of-the-art methods while using significantly fewer parameters.

6. It demonstrates OFVL-MS can generalize to new scenes with minimal additional parameters while retaining strong performance. 

7. It releases LIVL, a new large-scale indoor dataset for visual localization.

In summary, the main contribution is a unified multi-task framework for efficient visual localization across multiple scenes. The method intelligently shares parameters across tasks while allowing task-specific adaptation. This enables scalability to large numbers of scenes with minimal parameters.
