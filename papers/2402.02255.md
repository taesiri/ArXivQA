# [Frequency Explains the Inverse Correlation of Large Language Models'   Size, Training Data Amount, and Surprisal's Fit to Reading Times](https://arxiv.org/abs/2402.02255)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Recent work has shown an inverse correlation between the size of Transformer-based language models (LMs) as well as their training data amount and the fit of their surprisal estimates to human reading times. Specifically, surprisal from larger LMs trained on more data fits human reading times worse.
- It is unclear what underlying mechanisms during LM training give rise to this systematic divergence from human-like expectations. 

Proposed Solution:
- This paper investigates word frequency as a potential explanatory factor behind this inverse correlation.

Analyses and Main Findings:
- Evaluation of four LM families on four reading time corpora shows the inverse correlation is strongest for the subset of rare/infrequent words. This is driven by larger LMs' excessively accurate predictions of rare words.
- Training dynamics reveal all LM variants learn to predict rare words later in training, but larger variants predict them more accurately. This explains the detrimental effect of model size and training data amount.
- A feature attribution analysis suggests larger variants utilize both longer context and stronger local associations to predict rare words better.

Main Contributions:
- Identifies word frequency as a parsimonious explanation for the inverse correlation between LM size/training data and fit to human reading times.
- Shows the inaccurate predictions of rare words drive this inverse correlation through detailed analyses of model training dynamics and feature attribution.
- Provides evidence that the complex associations larger LMs learn for rare words make their surprisal estimates diverge from human-like expectations.

In summary, the paper convincingly argues that Transformer LMs' superhuman mastery of rare words, enabled by their scale and training data amount, is the reason behind the degradation in fit between their surprisal estimates and human reading times.


## Summarize the paper in one sentence.

 The paper shows that word frequency is a key factor explaining why surprisal from larger language models trained on more data fits worse with human reading times, since they learn excessively accurate predictions for rare words based on overly complex associations.


## What is the main contribution of this paper?

 The main contribution of this paper is presenting word frequency as a unified explanation for the inverse correlation between transformer-based language models' size, training data amount, and the fit of their surprisal estimates to human reading times. 

Specifically, the paper shows through several analyses that:

1) The inverse correlation between model size and fit to reading times is strongest for the subset of least frequent words, driven by larger models' disproportionately accurate predictions on rare words.

2) All model variants learn to predict rare words with more training data, but larger variants do so more accurately, explaining the detrimental effect of size and data amount.  

3) Larger variants predict rare words more accurately due to both a longer effective context window and stronger local associations.

In sum, the excessive complexity that larger LMs learn for predicting rare words causes their surprisal estimates to diverge from human-like expectations. Word frequency provides a parsimonious explanation for why model size and training data degrade surprisal's fit to reading times.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Surprisal - A measure of the predictability of a word in context, defined as the negative log probability. Used as a predictor of human reading times.

- Language models - Models that define a probability distribution over sequences of words. Different variants with varying sizes are examined.

- Model size - Number of parameters in the language models. Larger variants with more parameters exhibit different behaviors. 

- Training data amount - Amount of text the language models are trained on. More training data also changes model behaviors.

- Word frequency - How often words occur in textual data. A key factor examined in relation to model surprisal and human reading times.

- Reading times - Behavioral measures of human sentence processing difficulty, predicted by surprisal. Various corpora used. 

- Residual errors - Errors left after predicting reading times with surprisal. Used to quantify fit.

- Inverse correlation - As model size and training data increase, fit to reading times decreases.

- Training dynamics - How model behavior and surprisal values change over training steps.

- Feature attribution - Method used to determine how models utilize context to make predictions.

So in summary, key terms revolve around language models, surprisal, word frequency, training, and their correlation with reading times.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods in this paper:

1. The paper argues that word frequency is a key factor explaining why surprisal from larger language models fits worse with human reading times. What specific analyses support this claim? What other evidence could further strengthen or challenge it?

2. The linear mixed effects models used quintile partitions based on word frequency. How robust are the results to using different partitions, such as terciles or deciles? Could more advanced regression methods better capture frequency effects?

3. The feature attribution analysis suggests larger models utilize longer effective context windows and stronger local associations. How was the context window size determined? Could more sophisticated attribution methods provide further insight? 

4. The paper analyzes only reading time data in English. How well might the conclusions generalize to other languages and other psycholinguistic measures like N400 amplitudes? What cross-linguistic data could test the claims?

5. The regression models include only surprisal predictors and low-level baseline predictors. How might including additional syntactic, semantic, or discourse complexity measures impact the results and conclusions?

6. The paper examines only autoregressive Transformer models. How do the results compare for other model architectures like RNNs? Could the conclusions depend substantially on model architecture?

7. The analysis tracks model dynamics during training. How do the results relate to recent work analyzing model scaling during fine-tuning? Could the interactions between pre-training and fine-tuning further explain the role of frequency?

8. The excessively accurate prediction of rare words is viewed as problematic. Could this actually be advantageous for certain downstream tasks? Under what conditions might the predictions be beneficial?

9. The frequency explanation suggests human language processing implicitly captures frequency effects. How compatible is this with other theories arguing frequency effects are separable from predictability effects in comprehension?

10. The paper argues predictions diverge due to superhumanly complex associations. What specifically makes these associations unhumanlike? How might model architectures and training objectives be altered to yield more humanlike associations?
