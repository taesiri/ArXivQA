# [FasterViT: Fast Vision Transformers with Hierarchical Attention](https://arxiv.org/abs/2306.06189)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question addressed in this paper is: How can we design an efficient Vision Transformer (ViT) architecture that achieves a good trade-off between accuracy and throughput (images per second) for computer vision tasks?Specifically, the paper proposes a new hybrid CNN-Transformer model called FasterViT that is tailored for high image throughput while maintaining high accuracy. The key ideas are:- Using a multi-scale architecture with convolutional layers in early stages for fast feature extraction, and transformer layers in later stages for modeling global dependencies. - Introducing a novel Hierarchical Attention (HAT) module that reduces the complexity of standard self-attention while still allowing global context propagation.- Carefully designing components like normalization, convolutions, attention to maximize throughput on GPU hardware.The paper shows FasterViT achieves state-of-the-art accuracy-throughput trade-offs on ImageNet classification, outperforming prior hybrid and transformer models. It also demonstrates strong performance on downstream tasks like object detection and segmentation.In summary, the main research question is how to design an efficient ViT backbone optimized for computer vision tasks, which they address through a novel architecture with hierarchical attention. The key contribution is achieving much higher throughput than prior ViTs while maintaining accuracy.
