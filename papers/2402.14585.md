# [Bandits with Abstention under Expert Advice](https://arxiv.org/abs/2402.14585)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
The paper studies the classic problem of prediction with expert advice under bandit feedback. In this setting, there are multiple experts making predictions over a sequence of trials. On each trial, the learner selects one action based on the experts' advice and receives partial (bandit) feedback on the reward of that action only. The goal is to maximize the total reward over all trials. 

A key assumption in this paper is that there is a special "abstention" action available, which always gives zero reward. The ability to abstain from making a prediction can be useful in many real-world applications where errors lead to high costs, so abstention allows the algorithm to avoid risky predictions when unsure.

Proposed Solution:
The authors propose a new algorithm called \ose (\underline{\textbf{C}}onfidence-rated \underline{\textbf{B}}andits with \underline{\textbf{A}}bstentions) which exploits the abstention action. The key ideas are:

- Modify the standard Exponentially Weighted Average forecaster to allow unnormalized expert weights. This enables better optimization of rewards.

- Project the unnormalized weights onto the feasible set at every trial to ensure valid probability distributions.

- Construct unbiased gradient estimates for the rewards to derive regret bounds.

The algorithm runs in O(KE) time per trial which matches Exp4.

Main Contributions:

- First algorithm that can optimize for the expected cumulative reward when there are confidence-rated predictors and an abstention action. Prior work could only bound modified reward metrics.

- Achieves significantly better reward bounds compared to Exp4 and other baselines. Matches Exp4 bound in worst case but can beat it by a factor of the number of experts.  

- For the specialist setting, obtains novel and substantially better regret bounds than prior SpecialistExp algorithm.

- Provides an efficient implementation for learning unions of balls in a metric space. Reduces the runtime from quadratic to almost linear in the number of contexts.

- Empirical evaluation on node classification tasks demonstrates the effectiveness over existing bandit algorithms.

In summary, the paper introduces a novel bandit algorithm that leverages abstention and shows strong theoretical and empirical improvements over prior approaches. The ability to abstain makes it particularly useful for real applications with prediction costs.
