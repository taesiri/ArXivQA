# [Neural Relighting with Subsurface Scattering by Learning the Radiance   Transfer Gradient](https://arxiv.org/abs/2306.09322)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we develop a neural rendering approach that can faithfully reconstruct and relight objects with subsurface scattering effects under varying lighting conditions?The key aspects of this question are:- Reconstructing objects with subsurface scattering effects - many existing methods struggle with materials that exhibit subsurface scattering, where light scatters beneath the surface before exiting. This is difficult to model with simple surface reflectance models like BRDFs.- Relighting under varying conditions - the goal is to produce a model that can render the object accurately under novel lighting, which requires disentangling lighting from material properties.- Using a neural rendering approach - the paper aims to address this problem using neural representation and optimization techniques, rather than relying solely on physically-based rendering models.So in summary, the core research question is how to use neural rendering to achieve high-fidelity reconstruction and relighting of objects with subsurface scattering effects under varying illumination. The proposed method aims to make progress on this problem.


## What is the main contribution of this paper?

The main contribution of this paper appears to be a novel framework for learning the radiance transfer field via volume rendering and utilizing various appearance cues to refine geometry end-to-end. This framework extends relighting and reconstruction capabilities to handle a wider range of materials in a data-driven fashion. Specifically, the key contributions seem to be:- A volume rendering approach to estimate the transfer field and utilize appearance cues to refine the geometry in an end-to-end fashion. This allows optimizing geometry details with appearance cues.- The framework does not assume a particular material representation (like BRDF or BSSRDF), making it applicable to a wide range of materials with global illumination and subsurface scattering effects. - The method produces high quality visual results on real-world objects with significant subsurface scattering captured in a light stage. It compares favorably to prior state-of-the-art methods quantitatively and qualitatively.- A new light stage dataset of objects with subsurface scattering is collected and will be released to facilitate research in this area. The dataset features high resolution captures with varying lighting.In summary, the key novelty appears to be the end-to-end volume rendering framework for optimizing radiance transfer fields, which extends neural relighting capabilities to materials with subsurface scattering in a more general and data-driven manner.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a novel framework for learning radiance transfer fields using volume rendering to enable relighting of objects with subsurface scattering effects and optimizing geometry details end-to-end.


## How does this paper compare to other research in the same field?

Here are some thoughts on how this paper compares to other related work in the field of neural rendering and relighting:- The key novel contribution is the volume rendering framework for optimizing radiance transfer fields end-to-end to handle subsurface scattering effects. This is different from prior work like NRTF and NeRF which rely on predefined geometry.- It demonstrates results on challenging real world translucent objects captured in a custom light stage system. This goes beyond a lot of other work that focuses on synthetic data. The light stage dataset is also a valuable contribution.- The comparisons show quantitative improvements over recent state-of-the-art methods like NRTF and qualitative advantages in handling materials with subsurface scattering. This demonstrates broader applicability than BRDF-based approaches.- The end-to-end optimization framework allows jointly optimizing geometry and appearance, which is more flexible than separating these steps. This is a useful capability for translucent objects where geometry cues are ambiguous.- Limitations mentioned include blurry specular highlights and translucent shadows. An interesting direction is incorporating explicit models for these effects. Overall runtime is another aspect that needs improvement for real-time use cases.- Compared to concurrent work on translucent neural rendering like Yu et al., this method handles complex environment map relighting efficiently. The large-scale light stage data is also a distinguishing factor.In summary, the volume rendering approach for end-to-end radiance transfer optimization is the key novel contribution over prior neural rendering techniques. The results demonstrate improved performance on translucent materials, thanks to the joint optimization. Releasing the light stage data is also a valuable addition to the field.
