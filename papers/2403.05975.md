# [Measuring Bias in a Ranked List using Term-based Representations](https://arxiv.org/abs/2403.05975)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing metrics for evaluating gender bias in document rankings like ARB and NFaiRR have limitations. NFaiRR aggregates bias scores of individual documents, so a balanced ranked list on the whole can still have biased individual documents. 

- There is a need for a metric that evaluates fairness of group representation in rankings based on the exposure of representative terms for each group.

Method:
- The paper proposes a new metric called TExFAIR (term exposure-based fairness) based on the attention-weighted rank fairness (AWRF) framework. 

- TExFAIR measures fairness through the overall exposure of female and male representative terms in the ranked list, unlike NFaiRR's document-level view.

- It handles non-representative documents through a rank biased discounting factor (RBDF).

- The paper also uses counterfactual evaluation by gender-swapping terms to estimate ranking models' bias.

Contributions:
- Defines extensions to AWRF for term-based group representations: explicit mapping of terms to groups, and RBDF for non-representative documents.  

- Shows TExFAIR captures a different aspect of fairness than NFaiRR through correlation analysis.

- Finds no strong correlation between model bias measured by counterfactual evaluation and bias measured by TExFAIR/NFaiRR.

- Provides a new perspective on evaluating fairness through overall exposure of groups based on their representative terms.

In summary, the paper addresses limitations of prior bias metrics by proposing the new term-based TExFAIR metric along with counterfactual evaluation of model bias.
