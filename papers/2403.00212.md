# [Transcription and translation of videos using fine-tuned XLSR Wav2Vec2   on custom dataset and mBART](https://arxiv.org/abs/2403.00212)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Training automatic speech recognition (ASR) models for low-resource languages like Hindi is challenging due to limited data availability. 
- Personalized ASR models require even more data that captures the unique characteristics of a person's voice.
- Generating enough personalized speech data to train accurate ASR models is very difficult.

Proposed Solution:
- Use just 14 minutes of personalized Hindi speech data from a YouTube video 
- Apply retrieval-based voice conversion (RVC) to augment this data and create a custom Common Voice 16.0 dataset capturing the individual voice
- Fine-tune the pre-trained cross-lingual self-supervised XLSR Wav2Vec2 model on this dataset 
- Achieve Hindi speech transcription on personalized voice with the fine-tuned model
- Translate the Hindi output to English using the pre-trained mBART model
- Generate aligned subtitles on videos using speaker diarization and timeline mapping

Key Contributions:
- Novel way to create personalized Hindi speech dataset from limited data using RVC 
- Method to train custom ASR models for low-resource languages tailored to individual voices
- End-to-end pipeline from Hindi speech input to English translated subtitles on video
- Web-based GUI for easy video transcription and translation using the personalized models
- Address the lack of tools for translating Hindi video content with minimal training data

In summary, the paper presents an innovative approach to build personalized Hindi ASR models using limited data and apply it for automated subtitling of videos by integrating speech recognition, translation and speaker diarization modules. The key innovation is in data augmentation and model customization for individual voices in a low-resource setting.
