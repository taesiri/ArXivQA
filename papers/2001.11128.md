# [Learning Robust and Multilingual Speech Representations](https://arxiv.org/abs/2001.11128)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is whether unsupervised speech representations learned from large-scale diverse data can improve the robustness and transferability of speech recognition systems. Specifically, the authors evaluate whether such representations lead to improvements in:- Robustness to domain shifts, by training ASR models on one dataset but evaluating on test sets from other domains. - Transferability to new languages, by evaluating the representations on 25 phonetically diverse languages including low-resource languages. The key hypothesis is that pretraining representations on a large corpus of diverse and noisy speech data will confer advantages in terms of robustness and transferability compared to standard speech features like filterbanks as well as representations pretrained on clean read English speech only.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Proposing an extended contrastive predictive coding (CPC) model with bidirectional context for unsupervised speech representation learning. 2. Showing that representations learned from a large and diverse unlabeled speech corpus (up to 8000 hours) lead to improved robustness of speech recognition systems to domain shifts, compared to standard log-filterbank features and CPC features learned only on clean read English speech.3. Demonstrating that the learned representations transfer well to 25 phonetically diverse languages, including low-resource languages, outperforming standard features and English-only pretrained features. 4. Confirming that scale, multilinguality, and evaluation on robustness are key factors for effective unsupervised speech representation learning.In summary, the paper shows that pretraining CPC models on large and diverse unlabeled speech data can learn robust and transferable representations that improve speech recognition performance across languages and domains. The main innovation is using much larger and more diverse speech data for pretraining and evaluating the representations more comprehensively in terms of robustness and transferability.
