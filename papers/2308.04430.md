# [SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore](https://arxiv.org/abs/2308.04430)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper seeks to address is: How can we build high-quality language models while effectively mitigating their legal risk arising from copyrighted or otherwise restricted training data?The key hypothesis seems to be that it is possible to significantly improve the risk-performance tradeoff in language model training by separating low-risk and high-risk data into distinct components of the model - parametric and nonparametric. Specifically, the paper proposes training the parameters of the model only on low-risk permissively licensed data while using high-risk copyrighted data solely in a flexible nonparametric datastore that is only accessed at inference time. This allows leveraging the high-risk data to boost performance without incurring the same legal risks associated with training on it directly.The paper introduces a new dataset of permissively licensed text and shows that models trained solely on this data are competitive in-domain but struggle out-of-domain. It then demonstrates that adding the nonparametric datastore significantly improves out-of-domain performance while providing opt-out and attribution capabilities to mitigate legal risks.In summary, the central hypothesis is that segregating training data by risk into parametric and nonparametric components can yield models with both high quality and lower legal risk. The paper aims to demonstrate the feasibility of this approach.


## What is the main contribution of this paper?

 Based on my reading, the main contribution of this paper is proposing a new approach to training language models that aims to mitigate copyright risks. Specifically, the key ideas are:1. Separating the training data into two components - low-risk/permissive data and high-risk/non-permissive data. The model parameters are trained only on the low-risk data.2. Using the high-risk data in a nonparametric datastore that is queried at inference time, rather than using it to train model parameters. This allows flexibility like easier opt-out and attribution.3. Introducing the Open License Corpus (OLC), a new 228B token dataset of low-risk/permissive text across multiple domains.4. Proposing SILO, a new language model architecture that combines a parametric component trained on OLC with a nonparametric datastore that can include high-risk data.5. Demonstrating that using the nonparametric datastore significantly improves SILO's out-of-domain performance, with kNN-LM retrieval being more effective than retrieval-in-context.6. Analysis showing kNN-LM benefits more from scaling the datastore size and is more robust to domain shift compared to the parametric component.In summary, the key contribution is presenting a new training approach and model architecture aimed at using copyrighted/restricted data in a safer way, along with empirical evidence showing its effectiveness. The introduced OLC dataset and analyses around domain generalization are also contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence TL;DR of the paper:The paper proposes a new technique to train language models that isolates copyrighted or restricted data in a separate nonparametric component to mitigate legal risk while maintaining strong performance.


## How does this paper compare to other research in the same field?

 This paper presents an interesting approach to training language models in a more legally compliant way by separating training data into parametric and nonparametric components. Here are a few key ways this work compares to related research:- Most prior work in copyright-compliant LMs has focused on filtering training data to only permissive licenses like public domain text or open source code. This paper shows there is more abundant permissive data than thought, but the challenge is extreme domain shift. - This paper introduces a new technique of segregating training data by risk levels into parametric vs nonparametric components. Most related work has trained standard parametric LMs and tried to filter outputs, whereas this proposes architectural changes.- Using nonparametric models (like kNN-LM and RIC) at inference time is an established technique, but this paper applies it in a new legal compliance context. Comparisons between kNN-LM and RIC are also novel.- Overall approach has similarities to modular LMs with separate expert parameters. New here is incorporating nonparametric datastores and allocating data by legal risk rather than domain.- They present thorough experiments analyzing the effects of different modeling choices. The analyses on domain generalization and component robustness to shift are novel.To summarize, while it builds on established techniques like nonparametric LMs, the core ideas around legally compartmentalizing training data and model components are creative. Thorough experiments and analysis help strengthen the validity of the approach. The work clearly advances the field's understanding of developing compliant and performant LMs.


## What future research directions do the authors suggest?

 Based on my reading of the paper, here are some of the main future research directions the authors suggest:- Addressing the limitations of their proposed model, Silo. For example, they mention exploring the tradeoff between legal risk mitigation and fairness, since their training data contains older books that may exhibit biases. They also suggest ways to find more diverse permissively licensed text.- Introducing novel data licensing approaches, like allowing data owners to set different permissions for using their data in model parameters versus a nonparametric datastore. They also suggest Silo could enable new ways for data owners to get credited when their data is used.- Investigating other technical strategies for using copyrighted data while protecting rights, like training on copyrighted data but filtering outputs, using differential privacy, or providing post-hoc attributions.- Generalizing their approach as a type of modular language model, with specialized components for low-risk versus high-risk data. This could also combine parametric and nonparametric components.- Extending their approach to multimodal systems, like images, audio and video, since there are abundant public domain data sources for these modalities.- Further improving the nonparametric language modeling techniques they relied on, like scaling up the datastore size or designing models that are fully nonparametric.In summary, they point to a variety of ways to build on their approach to language modeling while mitigating legal risks, ranging from technical advances to new data licensing regimes. The key theme is continuing to explore ways AI systems can responsibly use data while respecting the rights of data producers.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:The paper proposes a new language model called Silo that aims to mitigate the legal risks associated with training on copyrighted or restricted data. Silo has two components - a parametric component trained only on low-risk public domain or permissively licensed data, and a non-parametric datastore that can include high-risk copyrighted data, but is only queried at inference time and not used for training. This allows the model to leverage high-risk data to improve performance, while avoiding direct copyright issues from training. The authors curate a new 228B token training corpus called the Open License Corpus (OLC) consisting only of public domain and permissively licensed data. They train 1.3B parameter Silo models on OLC and show it is competitive in-domain but struggles out-of-domain compared to a model trained on unrestricted data. However, querying an in-domain non-parametric datastore at test time significantly improves Silo's out-of-domain performance. The paper analyzes performance gains from scaling the datastore, as well as the robustness of the non-parametric component to domain shift. Overall, the work suggests with further advances, high quality LMs can likely be developed while better respecting copyright and managing legal risk.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:The paper proposes a new language model called SILO that aims to mitigate the legal risks of training on copyrighted or restricted data. SILO has two components - a parametric component trained only on legally permissible data, and a nonparametric datastore that can contain high-risk data. The parametric component is trained on a new 228B token dataset called the Open License Corpus (OLC) that the authors curate from public domain text, permissively licensed code, and text requiring attribution. Experiments show this parametric component is competitive on in-domain text but struggles on out-of-domain data, posing a challenge of "extreme domain generalization." To address this, SILO incorporates a nonparametric datastore at inference time containing high-risk data like copyrighted books. Using either a nearest neighbors approach (kNN-LM) or feeding retrieved text into the context (RIC-LM), the datastore helps improve out-of-domain performance and close the gap with models trained on unrestricted data. kNN-LM generally works better, reducing the average gap by 90%. Analysis shows the improvements come from scaling the datastore size and the robustness of kNN-LM's nonparametric distribution to domain shift. Overall, the paper demonstrates the feasibility of training high-quality LMs while mitigating legal risk using segregated model components.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:The paper introduces SILO, a new language model that manages the risk-performance tradeoff when training with copyrighted or restricted data. SILO separates training data into two components - a parametric component trained only on low-risk permissive data, and a nonparametric datastore that can include high-risk restricted data. Specifically, the parametric component is a standard transformer LM trained on OLC, a new 228B token corpus of public domain and permissively licensed text that the authors curate. At inference time, this parametric LM is augmented with a nonparametric datastore containing up to 1B tokens that can include copyrighted books, private emails, etc. The nonparametric component uses either a kNN-LM approach to directly influence the output distribution, or a retrieval-in-context method (RIC-LM) which concatenates retrieved text blocks as context to the input. By isolating high-risk data only to the nonparametric datastore, SILO provides flexibility like easy opt-out and inherent attribution while avoiding training directly on restricted data. Experiments show this allows SILO to recover over 90% of the performance gap compared to an unrestricted baseline LM.


## What problem or question is the paper addressing?

 The paper is addressing the legal and ethical issues around training large language models on copyrighted or otherwise restricted data. Some key points:- Many current state-of-the-art language models are trained on massive datasets scraped from the web or books, much of which is copyrighted content. This raises concerns about copyright infringement.- Using only public domain or permissively licensed data for training leads to significant performance degradation on out-of-domain data, due to the scarcity and narrow specificity of such data.- The paper proposes an approach called SILO which segregates training data into a parametric component trained only on low-risk permissive data, and a nonparametric datastore that can include high-risk copyrighted data, but is only accessed at inference time.- This allows the flexibility of using high-risk data to boost performance, while avoiding directly training on it. The nonparametric datastore also enables capabilities like per-instance attribution and data opt-out.- Experiments show this approach significantly closes the performance gap with models trained on unrestricted data, while better adhering to regulations like fair use and providing more control to data owners.In summary, the paper explores ways to develop high-quality language models while mitigating the legal risks around copyrighted training data, using ideas like nonparametric models and data segregation. The overall goal is building models that are both high-performing and more legally/ethically compliant.
