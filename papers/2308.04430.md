# [SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore](https://arxiv.org/abs/2308.04430)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper seeks to address is: How can we build high-quality language models while effectively mitigating their legal risk arising from copyrighted or otherwise restricted training data?The key hypothesis seems to be that it is possible to significantly improve the risk-performance tradeoff in language model training by separating low-risk and high-risk data into distinct components of the model - parametric and nonparametric. Specifically, the paper proposes training the parameters of the model only on low-risk permissively licensed data while using high-risk copyrighted data solely in a flexible nonparametric datastore that is only accessed at inference time. This allows leveraging the high-risk data to boost performance without incurring the same legal risks associated with training on it directly.The paper introduces a new dataset of permissively licensed text and shows that models trained solely on this data are competitive in-domain but struggle out-of-domain. It then demonstrates that adding the nonparametric datastore significantly improves out-of-domain performance while providing opt-out and attribution capabilities to mitigate legal risks.In summary, the central hypothesis is that segregating training data by risk into parametric and nonparametric components can yield models with both high quality and lower legal risk. The paper aims to demonstrate the feasibility of this approach.


## What is the main contribution of this paper?

Based on my reading, the main contribution of this paper is proposing a new approach to training language models that aims to mitigate copyright risks. Specifically, the key ideas are:1. Separating the training data into two components - low-risk/permissive data and high-risk/non-permissive data. The model parameters are trained only on the low-risk data.2. Using the high-risk data in a nonparametric datastore that is queried at inference time, rather than using it to train model parameters. This allows flexibility like easier opt-out and attribution.3. Introducing the Open License Corpus (OLC), a new 228B token dataset of low-risk/permissive text across multiple domains.4. Proposing SILO, a new language model architecture that combines a parametric component trained on OLC with a nonparametric datastore that can include high-risk data.5. Demonstrating that using the nonparametric datastore significantly improves SILO's out-of-domain performance, with kNN-LM retrieval being more effective than retrieval-in-context.6. Analysis showing kNN-LM benefits more from scaling the datastore size and is more robust to domain shift compared to the parametric component.In summary, the key contribution is presenting a new training approach and model architecture aimed at using copyrighted/restricted data in a safer way, along with empirical evidence showing its effectiveness. The introduced OLC dataset and analyses around domain generalization are also contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR of the paper:The paper proposes a new technique to train language models that isolates copyrighted or restricted data in a separate nonparametric component to mitigate legal risk while maintaining strong performance.


## How does this paper compare to other research in the same field?

This paper presents an interesting approach to training language models in a more legally compliant way by separating training data into parametric and nonparametric components. Here are a few key ways this work compares to related research:- Most prior work in copyright-compliant LMs has focused on filtering training data to only permissive licenses like public domain text or open source code. This paper shows there is more abundant permissive data than thought, but the challenge is extreme domain shift. - This paper introduces a new technique of segregating training data by risk levels into parametric vs nonparametric components. Most related work has trained standard parametric LMs and tried to filter outputs, whereas this proposes architectural changes.- Using nonparametric models (like kNN-LM and RIC) at inference time is an established technique, but this paper applies it in a new legal compliance context. Comparisons between kNN-LM and RIC are also novel.- Overall approach has similarities to modular LMs with separate expert parameters. New here is incorporating nonparametric datastores and allocating data by legal risk rather than domain.- They present thorough experiments analyzing the effects of different modeling choices. The analyses on domain generalization and component robustness to shift are novel.To summarize, while it builds on established techniques like nonparametric LMs, the core ideas around legally compartmentalizing training data and model components are creative. Thorough experiments and analysis help strengthen the validity of the approach. The work clearly advances the field's understanding of developing compliant and performant LMs.
