# [Dual Pose-invariant Embeddings: Learning Category and Object-specific   Discriminative Representations for Recognition and Retrieval](https://arxiv.org/abs/2403.00272)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Prior work on pose-invariant object recognition and retrieval learns embeddings that capture both category-level and object-level attributes. However, their performance degrades for single-view recognition/retrieval tasks.
- Existing methods also do not effectively separate embeddings of visually similar objects from the same category, resulting in poor discrimination between objects.

Proposed Solution:  
- The paper proposes a dual-encoder architecture called Pose-invariant Attention Network (PAN) to simultaneously learn category embeddings and object embeddings.

- Two pose-invariant losses are introduced - category loss to cluster objects from the same categories, and object loss to cluster views of the same object while separating confusing object instances belonging to that category.

- By optimizing these losses jointly, the network learns to capture shared characteristics for a category in the category space, and fine details to distinguish between objects in the object space.

Main Contributions:
- Demonstrates improved performance by disentangling category and object-level learning in two separate embedding spaces, unlike prior work.

- Achieves state-of-the-art results on pose-invariant classification and retrieval tasks on ModelNet, ObjectPI and FG3D datasets, especially for challenging single-view tasks. 

- Proposes a new attention-based architecture PAN and two pose-invariant losses that enable learning more discriminative category and object embeddings simultaneously.

- Provides detailed experiments analyzing the effect of various components like the losses, embedding spaces, dimensions etc.

In summary, the key idea is to explicitly decouple category and object-level learning in two spaces to learn representations that effectively capture both common and discriminative attributes for recognition/retrieval from single or multiple views.
