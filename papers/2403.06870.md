# [Semantic Residual Prompts for Continual Learning](https://arxiv.org/abs/2403.06870)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Neural networks struggle with catastrophic forgetting - they forget previously learned tasks when trained on new tasks.
- Continual learning aims to address this by enabling models to learn sequentially on tasks without forgetting prior tasks. 
- Existing prompting-based continual learning methods have a stability issue - the prompt selection mechanism can forget prior tasks and start selecting prompts meant for new tasks to represent old tasks. This causes interference and sub-optimal performance.

Proposed Solution - Semantic Two-Tier Additive Residual Prompting (\methnam):
- Uses a two-level prompting strategy with CLIP text encoder to get stable class prototypes for the first level.
- These prototypes act as keys to retrieve second level prompts from another pool to adapt a separate pre-trained ViT model for better plasticity.  
- Second level prompts are added using a novel residual mechanism before MLP layers of ViT. This forces inclusion of CLIP semantics.
- Uses multi-modal generative replay to reduce interference between tasks.   

Main Contributions:
- A two-level prompting strategy for increased selection stability using CLIP as the first level.
- A new semantic residual prompting mechanism to transfer semantics to the ViT MLP layers 
- Extends a prior generative replay method by using multi-modal feature distributions.

Results:
- Significantly outperforms state-of-the-art on 9 datasets including specialized, aerial and medical domains
- Very close performance to joint training upper bound, highlighting strong plasticity.
- Ablations validate contribution of each component of the proposed solution.

In summary, the paper introduces a novel semantic two-level prompting strategy with residuals and generative replay to address stability and plasticity issues in continual learning. The method achieves new state-of-the-art results across diverse domains.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a continual learning method called STAR-Prompt that uses a two-level prompting strategy with CLIP to achieve more stable prompt selection, injects semantic residuals into the MLP layers of a Vision Transformer for better transfer of semantics, and leverages a multi-modal generative replay method for reducing forgetting.


## What is the main contribution of this paper?

 According to the paper, the main contributions of this work are:

1. A two-level prompting strategy that builds upon the stability of foundation models (like CLIP) to increase the stability of the prompt selection mechanism. This involves learning class-prototype keys using CLIP's text encoder in the first level, and using them to index a second pool of prompts in the second level.

2. A novel prompting approach based on semantic residuals that are added to the MLP layers of a backbone vision transformer. This allows transferring CLIP-derived semantics into the backbone model. 

3. A simple generative replay strategy based on modeling the feature distributions of each class using a mixture of Gaussians. This is used to generate synthetic samples for replay.

So in summary, the main contributions are: (1) a more stable two-level prompting strategy, (2) semantic residual prompting, and (3) multi-modal generative replay. The combination of these novelties leads to state-of-the-art continual learning performance.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- Continual learning
- Catastrophic forgetting
- Prompt tuning
- Vision Transformers (ViT)
- Semantic residuals 
- Two-level prompting strategy
- Stability of prompt selection
- Generative replay
- Mixture of Gaussians (MoGs)
- CLIP model
- Parameter-efficient adaptation
- Domain gaps

The paper proposes a new continual learning method called "Semantic Two-Tier Additive Residual Prompting" (STAR-Prompt) that uses a two-level prompting strategy built on top of the CLIP model to enhance the stability of prompt selection, while also using semantic residuals and a multi-modal generative replay method to improve adaptability to new tasks. The method is evaluated on a variety of image classification datasets, including ones with significant domain gaps compared to ImageNet, and shows state-of-the-art performance.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. What is the main motivation behind using a two-level prompting strategy in this work? Explain why existing prompting approaches for continual learning lack stability in the prompt selection mechanism. 

2. How does the proposed method leverage the CLIP model for the first-level prompting? Explain the process of learning textual class prototypes and discuss why this leads to more stable keys compared to learning keys from scratch.

3. Explain the second-level prompting stage in detail. How are the textual class prototypes used as keys to retrieve the second set of prompts? Discuss the benefits of using CLIP's multi-modal embedding space in this process.

4. What is the proposed semantic residual mechanism? Explain how it differs from standard prompt token concatenation and discuss why adding residuals forces the inclusion of CLIP-derived semantics in the Transformer embeddings. 

5. Discuss the multi-modal generative replay strategy proposed in this work. How does it extend the idea from SLCA and why using a mixture of Gaussians better models the feature distributions?

6. Analyze the results on specialized domains like fine-grained classification datasets. Why does the method significantly outperform even the zero-shot CLIP baseline in these scenarios?

7. Compare and contrast the performance on aerial and medical domain datasets to analyze the model's adaptability. How does it highlight the need for plasticity along with stability?

8. Critically analyze the ablation study results to understand the contribution of individual components like two-level prompting, semantic residuals, generative replay etc.

9. What can we infer from the fact that the method achieves an almost negligible performance drop compared to the joint training upper bound? Discuss the implications.

10. Identify any potential limitations of the proposed approach. Are there scenarios where it might struggle? Discuss scope for future work building upon this method.
