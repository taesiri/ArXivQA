# [VideoElevator: Elevating Video Generation Quality with Versatile   Text-to-Image Diffusion Models](https://arxiv.org/abs/2403.05438)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Text-to-video diffusion models (T2V) still lag far behind text-to-image diffusion models (T2I) in frame quality and text alignment. This is because training videos are much lower in quality and quantity compared to images. Recent methods try to improve T2V using T2I, but the synthesized videos still suffer from frame quality degradation compared to T2I generated images. 

Proposed Solution: 
The paper proposes VideoElevator, a training-free and plug-and-play method to elevate T2V performance using superior capabilities of versatile T2I models. In contrast to T2V's coupled temporal and spatial modeling in each step, VideoElevator explicitly decomposes each step into temporal motion refining and spatial quality elevating:

- Temporal motion refining uses encapsulated T2V to enhance temporal consistency. It applies a temporal low-pass filter to reduce flickers, uses T2V-based editing to portray natural motion, and inverts the latent to T2I's required noise distribution.  

- Spatial quality elevating harnesses inflated T2I to directly predict a less noisy latent, adding more realistic details. The self-attention in T2I is inflated into cross-frame attention to ensure appearance consistency.

To enable cooperation of various T2V and T2I, VideoElevator projects their latents to a shared clean latent space before feeding into the other model.

Main Contributions:
- Proposes the first training-free and plug-and-play approach to improve T2V using versatile T2I models.
- Presents explicit temporal-spatial decomposition in each step - temporal motion refining and spatial quality elevating - to leverage capabilities of T2V and T2I respectively.
- Experiments show VideoElevator boosts multiple T2V baselines with diverse T2I models, improving frame quality, text alignment and capturing aesthetic styles.
