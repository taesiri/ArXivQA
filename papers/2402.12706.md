# [Learning Domain-Invariant Temporal Dynamics for Few-Shot Action   Recognition](https://arxiv.org/abs/2402.12706)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Few-shot action recognition aims to quickly adapt a pre-trained model to novel data with distribution shifts, using only a few samples. Key challenges are identifying and transferring knowledge from the pre-trained model and efficiently adapting non-transferable knowledge for the novel data.

Proposed Solution:
The paper proposes Domain-Invariant Temporal Dynamics (DITeD), a modular action recognition model with separate modules for temporal dynamic generation, temporal dynamic transition, and domain encoding. 

The key assumption is that the temporal dynamic generation and transition modules learn transferable knowledge, while the domain encoder and classifier modules are less transferable. This is inspired by the fact that laws of physics are invariant, so learned knowledge of them should transfer across domains.

DITeD uses a sequential VAE with disentangled latent variables to model temporal dynamics. It has a two-stage training strategy:
1) Unsupervised pretraining to learn representations using ELBO loss 
2) Fixing the temporal modules and training classifier with supervision

For adaptation, temporal modules remain fixed while the image encoder and domain encoder get updated, followed by the classifier. This enables efficient adaptation with minimal parameter changes.

Main Contributions:

- Proposes DITeD, a new modular architecture to distinguish transferable vs non-transferable knowledge for few-shot action recognition

- Introduces a two-stage training strategy to detect and leverage invariant temporal dynamics  

- Achieves state-of-the-art results on few-shot action recognition datasets, outperforming prior arts

- Demonstrates the transferability of the learned temporal modules through comprehensive experiments

- Provides an efficient adaptation approach by fixing invariant modules and updating only a small subset of modules

In summary, the paper makes important contributions in few-shot action recognition by learning and transferring invariant temporal knowledge across domains, enabling efficient model adaptation.
