# [UV Volumes for Real-time Rendering of Editable Free-view Human   Performance](https://arxiv.org/abs/2203.14402)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is: 

How can we generate editable free-view videos of human performances that can be rendered in real-time?

The key points are:

- Existing methods for novel view synthesis of dynamic scenes like NeRF are too slow for real-time rendering. 

- The paper proposes a new approach called "UV Volumes" to accelerate rendering while still preserving high visual quality.

- The key ideas are to disentangle geometry/texture coordinates (encoded in UV volumes) from appearance (encoded in a neural texture stack). This allows using smaller networks to represent the geometry and enables editing applications.

- Experiments on several datasets demonstrate they can achieve real-time rendering rates with visual quality comparable to state-of-the-art approaches.

So in summary, the main research contribution is developing a representation that decouples geometry and appearance to enable real-time free-view rendering and editing of dynamic human performances. The UV Volumes approach is proposed to address the problem of rendering efficiency compared to prior work.
