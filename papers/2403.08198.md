# [Validating and Exploring Large Geographic Corpora](https://arxiv.org/abs/2403.08198)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing methods for cleaning large web corpora to create usable linguistic datasets may unintentionally exclude under-represented languages and minority dialectal varieties. 
- It's important to understand the differential impact of corpus cleaning methods on linguistic diversity.

Methods:
- Start with a 427 billion word multi-lingual geographic web corpus from Common Crawl, representing language use by country.
- Apply 3 cleaning methods sequentially: 
  1) Validate language ID using a 2nd independent model 
  2) Deduplicate using hash-based method
  3) Outlier detection customized for each language-country subcorpus
- Evaluate impact on corpus similarity to benchmark datasets for language ID and geo-location.

Results:
- Language ID validation removed 22% of corpus, mainly uncertain samples.
- Deduplication removed 34% of corpus but had uneven impact on languages.
- Outlier detection removed 2.9% of corpus in a more evenly distributed way.  
- Similarity evaluation showed improvements in corpus quality but also variation across languages/countries.

Contributions:
- First systematic evaluation of cleaning methods on a large multi-lingual geographic corpus
- Shows uneven impact of methods on linguistic diversity
- Releases improved 213 billion word corpus representing diverse populations more evenly
- Highlights need to avoid excluding minority languages/varieties from corpus creation

In summary, this paper evaluates the impact of sequential cleaning methods on a large web corpus in order to retain diversity, showing the methods improve quality overall but have uneven effects on languages. The result is a new 213 billion word multi-lingual geographic corpus representing diverse populations more evenly.
