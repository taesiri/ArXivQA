# [Per-Pixel Classification is Not All You Need for Semantic Segmentation](https://arxiv.org/abs/2107.06278)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question addressed in this paper is whether a simple mask classification model can unify and potentially outperform existing approaches for both semantic segmentation and panoptic segmentation. Specifically, the authors propose a model called MaskFormer that formulates both semantic and panoptic segmentation as mask classification, predicting a set of binary masks each with an associated class label. This is in contrast to most semantic segmentation methods that formulate the problem as per-pixel classification. The key hypothesis is that mask classification is a sufficiently general paradigm to unify and improve performance on both semantic and instance-level segmentation compared to specialized per-pixel classification models for semantic segmentation and box-based models like Mask R-CNN for panoptic segmentation.The experiments aim to validate whether:1) MaskFormer can outperform per-pixel classification models on semantic segmentation, especially when there are a large number of classes.2) MaskFormer can match or exceed the performance of box-based models like DETR on panoptic segmentation without needing bounding boxes.3) The same MaskFormer model can achieve state-of-the-art results on both tasks using the same model architecture, losses, and training procedure by just changing the supervision.So in summary, the central hypothesis is that a simple and unified mask classification formulation can advance the state-of-the-art on both semantic and panoptic segmentation. The paper aims to validate this through extensive experiments on multiple datasets and tasks.
