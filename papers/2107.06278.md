# [Per-Pixel Classification is Not All You Need for Semantic Segmentation](https://arxiv.org/abs/2107.06278)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question addressed in this paper is whether a simple mask classification model can unify and potentially outperform existing approaches for both semantic segmentation and panoptic segmentation. Specifically, the authors propose a model called MaskFormer that formulates both semantic and panoptic segmentation as mask classification, predicting a set of binary masks each with an associated class label. This is in contrast to most semantic segmentation methods that formulate the problem as per-pixel classification. The key hypothesis is that mask classification is a sufficiently general paradigm to unify and improve performance on both semantic and instance-level segmentation compared to specialized per-pixel classification models for semantic segmentation and box-based models like Mask R-CNN for panoptic segmentation.The experiments aim to validate whether:1) MaskFormer can outperform per-pixel classification models on semantic segmentation, especially when there are a large number of classes.2) MaskFormer can match or exceed the performance of box-based models like DETR on panoptic segmentation without needing bounding boxes.3) The same MaskFormer model can achieve state-of-the-art results on both tasks using the same model architecture, losses, and training procedure by just changing the supervision.So in summary, the central hypothesis is that a simple and unified mask classification formulation can advance the state-of-the-art on both semantic and panoptic segmentation. The paper aims to validate this through extensive experiments on multiple datasets and tasks.


## What is the main contribution of this paper?

The main contribution of this paper is proposing MaskFormer, a simple mask classification model that unifies semantic segmentation and panoptic segmentation. The key ideas are:- Mask classification can solve both semantic and panoptic segmentation in a unified manner, using the same model, loss, and training procedure. This simplifies the landscape of segmentation methods.- MaskFormer converts any per-pixel classification model into a mask classification model via a Transformer decoder that predicts a set of masks with associated class labels. - Mask classification outperforms per-pixel classification on datasets with many classes. MaskFormer achieves new state-of-the-art results on ADE20K semantic segmentation and COCO panoptic segmentation.- MaskFormer removes the need for bounding boxes in panoptic segmentation, simplifying previous mask classification models like Mask R-CNN and DETR.In summary, the paper shows mask classification is a powerful paradigm that unifies semantic and panoptic segmentation. The proposed MaskFormer model advances state-of-the-art in both tasks.
