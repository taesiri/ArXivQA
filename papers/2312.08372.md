# [SAM-guided Graph Cut for 3D Instance Segmentation](https://arxiv.org/abs/2312.08372)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel 3D instance segmentation approach that effectively leverages 2D segmentation models by formulating the task as a graph cut problem on a superpoint graph. It first oversegments the 3D scene into superpoints and constructs a graph where superpoints are nodes and adjacency relationships are edges. The edge weights and node features of this graph are annotated using the prompt mechanism and encoder features of SAM (Segment Anything Model), enabling superior generalization ability. A graph neural network is then trained with pseudo-labels from a 2D segmentation model to predict affinity scores for graph partitioning. Experiments on ScanNet, ScanNet++ and KITTI-360 datasets demonstrate state-of-the-art performance and excellent generalization across different data acquisition methods and scene types without any fine-tuning. Key advantages are the novel 3D-to-2D query framework for utilizing 2D models, SAM-guided graph construction for improved generalization, and the scheme for generating pseudo-labels to enable fully self-supervised training. This work represents an important advancement in leveraging mature 2D recognition models for 3D perception tasks.
