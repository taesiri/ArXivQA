# [Sketching the Future (STF): Applying Conditional Control Techniques to   Text-to-Video Models](https://arxiv.org/abs/2305.05845)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question or hypothesis appears to be: Can a novel approach that combines zero-shot text-to-video generation with conditional control techniques improve the output quality and controllability of text-to-video models?The key points are:- Text-to-video generation is challenging due to lack of training data and difficulty controlling output with just text prompts. - The authors propose a new method called "Sketching the Future" (STF) that takes sketched frames as additional input to better guide video generation.- STF combines zero-shot text-to-video (Text2Video Zero) with conditional control (ControlNet).- The hypothesis is that by adding sketched frames as conditional input, STF can improve the quality and control over text-to-video generation compared to Text2Video Zero alone.- Experiments aim to demonstrate STF's ability to produce videos that more accurately match the desired motion specified through the sketched frames, which Text2Video Zero struggles with using just text prompts.In summary, the central research question is whether the proposed STF approach can enhance text-to-video generation by incorporating sketched frames as conditional control input. The hypothesis is that STF will improve output quality and controllability compared to baseline Text2Video Zero.
