# [Revisiting Transformation Invariant Geometric Deep Learning: Are Initial   Representations All You Need?](https://arxiv.org/abs/2112.12345)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main contributions of this paper are:1. The paper revisits why existing neural networks cannot maintain transformation invariance when handling geometric data like point clouds and graphs. Through analysis, the authors find that transformation-invariant and distance-preserving initial point representations are sufficient to achieve transformation invariance, rather than needing sophisticated neural network layer designs.2. Motivated by this finding, the paper proposes a simple and general framework called Transformation Invariant Neural Networks (TinvNN) to achieve transformation invariance for geometric data. It realizes invariant and distance-preserving initial representations using a modified multi-dimensional scaling technique. 3. The paper proves that TinvNN can strictly guarantee transformation invariance and is flexible to combine with various neural network architectures. 4. Extensive experiments on point cloud analysis and combinatorial optimization tasks demonstrate the effectiveness of TinvNN. It matches or outperforms specialized invariant models across different transformations like rotation, translation and scaling.In summary, the central hypothesis is that transformation-invariant initial representations are sufficient for achieving invariance in neural networks for geometric data. The paper proposes and validates a simple, general and effective framework TinvNN based on this idea.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution seems to be proposing a new framework called Transformation Invariant Neural Network (TinvNN) for designing neural networks that can handle geometric data (such as point clouds and graphs) in a transformation invariant way. Specifically, the key ideas and contributions are:- They revisit why existing neural networks like graph neural networks (GNNs) cannot maintain transformation invariance on geometric data. Through theoretical analysis, they show that having transformation invariant and distance preserving initial representations is sufficient to achieve invariance, rather than needing to design complex invariant neural layers.- Motivated by this analysis, they propose TinvNN, which realizes invariant and distance preserving initial representations by modifying multi-dimensional scaling. The representations are then fed into standard neural networks. - They prove TinvNN can strictly guarantee transformation invariance with respect to transformations like translation, rotation, reflection and scaling. The framework is general and flexible to combine with different architectures.- Extensive experiments on tasks like point cloud analysis and combinatorial optimization demonstrate the effectiveness of TinvNN. It matches or outperforms specialized invariant models while being simpler and more general.In summary, the key contribution is identifying that invariant initial representations are sufficient for transformation invariance on geometric data, and proposing the TinvNN framework to realize this idea in a simple yet effective way. The experiments verify its efficacy across different tasks and models. Overall, it provides a new perspective and strong baseline for designing invariant networks for geometric data.
