# [DualPrompt: Complementary Prompting for Rehearsal-free Continual   Learning](https://arxiv.org/abs/2204.04799)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be:How can we develop an effective rehearsal-free continual learning approach that does not require storing exemplars from previous tasks, while still minimizing catastrophic forgetting?The key hypotheses seem to be:1) Separating learnable prompt parameters into complementary "G-Prompts" and "E-Prompts" to encode task-invariant and task-specific knowledge respectively will allow more effective learning of sequential tasks without catastrophic forgetting. 2) Properly attaching the G-Prompts and E-Prompts to different layers of a pretrained model is crucial for optimizing the continual learning performance.3) The proposed DualPrompt method with this complementary prompting approach can outperform prior rehearsal-based and non-rehearsal methods by effectively leveraging a pretrained model, without needing to store exemplars.In summary, the main research question is how to do effective rehearsal-free continual learning, and the key hypothesis is that the proposed complementary prompting approach in DualPrompt can achieve this. Let me know if you would like me to elaborate or clarify anything!


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Introducing DualPrompt, a new rehearsal-free continual learning method that uses complementary prompts to learn task-invariant and task-specific knowledge. The method uses a General (G) Prompt to learn knowledge that transfers across tasks, and Expert (E) Prompts to learn task-specific knowledge. - Presenting a simple yet effective framework for attaching the G and E prompts to different layers of a pre-trained model. The paper explores design choices for where and how to incorporate the prompts.- Introducing Split ImageNet-R, a new benchmark for continual learning based on ImageNet-R. This benchmark has high intra-class diversity which makes it challenging for rehearsal-based methods.- Showing state-of-the-art performance of DualPrompt on Split ImageNet-R, Split CIFAR-100, and other benchmarks under the class-incremental learning setting. The method outperforms prior rehearsal-based and non-rehearsal methods, even with a relatively small amount of additional parameters.In summary, the main contribution appears to be presenting DualPrompt, a simple yet effective rehearsal-free continual learning approach that leverages complementary prompts attached to a pre-trained model. The method sets new state-of-the-art results while using minimal additional memory and parameters. The Split ImageNet-R benchmark is also introduced to provide a more challenging testbed for evaluating continual learning methods.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a new rehearsal-free continual learning approach called DualPrompt that uses small learnable prompt parameters to encode both task-invariant and task-specific knowledge, enabling a pre-trained vision model to continually learn a sequence of tasks without storing past data examples.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in the field of continual learning:- The use of complementary prompting with G-prompts and E-prompts is a novel approach not seen in prior work. Most prior methods use a single prompt pool like L2P or rely on rehearsal buffers. Decoupling prompts to capture task-invariant and task-specific knowledge is an interesting idea grounded in complementary learning systems theory.- Evaluating on Split ImageNet-R is a nice contribution since it provides a more challenging benchmark than the commonly used datasets like Split CIFAR. The intra-class diversity poses difficulties for rehearsal-based methods.- The results are quite strong, achieving state-of-the-art on multiple benchmarks. Outperforming rehearsal methods without using any buffer data is impressive.- The modular framework for attaching prompts is flexible and allows probing the impact of prompt placement. This could enable better customization for new models and tasks in the future.- Most prior work has focused on convolutional architectures. Leveraging vision transformers matches the current trends in computer vision models.- While the high-level ideas are novel, some implementation details are similar to prior methods like L2P. The use of keys for task-specific prompts is adapted from that work.- The method does require a pre-trained model, so it may face challenges if a suitable pre-trained model is unavailable for a new problem domain. Methods that can learn from scratch have some benefits.Overall, I'd say the unique contributions are in the complementary prompting approach and strong empirical results. The modular framework and new challenging benchmark are also assets. It incrementally pushes forward rehearsal-free continual learning in an exciting direction.


## What future research directions do the authors suggest?

Based on my reading of the paper, here are some of the main future research directions the authors suggest:- Developing automated methods for determining the optimal positions to attach the G-prompts and E-prompts in the backbone model. The paper manually searches for good positions but notes this is not guaranteed to find the globally optimal configuration. An automated approach could improve performance.- Exploring different prompting functions beyond the Prefix Tuning and Prompt Tuning methods compared in the paper. The authors note that the prompting function is a flexible component that could be swapped out, so developing novel prompting techniques may further enhance continual learning. - Applying the DualPrompt method to continual learning scenarios with increased task diversity, where sharing knowledge between tasks becomes more difficult. The authors suggest reducing or removing the shared G-prompt in very diverse settings.- Extending DualPrompt to allow non-contiguous sets of layers to be prompted, rather than just contiguous blocks of layers. This could provide more flexibility in attaching prompts.- Developing rehearsal-free continual learning methods that do not require a pre-trained model backbone. DualPrompt relies on a frozen pre-trained model, but removing this assumption could increase applicability.- Exploring whether ideas like DualPrompt's complementary prompting can be integrated into prior continual learning approaches like architecture expansion or regularization methods.- Applying DualPrompt to continual learning problems beyond image classification, such as in natural language processing tasks.In general, the main themes seem to be improving automation and flexibility in prompt design, handling more diverse tasks, and extending the ideas to new methods, models, and problem settings.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:This paper proposes a new method called DualPrompt for rehearsal-free continual learning. The method uses two sets of small learnable prompt parameters called G-Prompt and E-Prompt to provide task-invariant and task-specific instructions, respectively, to a pretrained model in order to continually learn new tasks. G-Prompt captures knowledge that transfers across tasks while E-Prompt captures task-specific knowledge. At test time, an input is transformed using a query function to select the closest task key and corresponding E-Prompt to make a prediction. The method sets new state-of-the-art performance on multiple continual learning benchmarks under the challenging class-incremental setting without using any rehearsal buffer. It introduces a new more challenging benchmark called Split ImageNet-R and outperforms prior rehearsal-based methods even with large buffer sizes. The framework is simple, flexible, and effective for rehearsal-free continual learning using pretrained models.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the key points from the paper:This paper presents a new framework called DualPrompt for tackling the challenging problem of continual learning. Continual learning aims to enable a single model to sequentially learn new tasks without catastrophic forgetting of past tasks. The proposed DualPrompt method consists of two sets of small learnable parameters called prompts - G-Prompt and E-Prompt. G-Prompt captures task-invariant knowledge that transfers across tasks, while E-Prompt captures task-specific knowledge for each individual task. These complementary prompts provide targeted instructions to the pretrained model backbone when learning new tasks. DualPrompt attaches the G and E prompts at different layers of the pretrained model, allowing them to interact with features at different abstraction levels. Experiments across continual learning benchmarks like Split CIFAR-100 and Split ImageNet-R show DualPrompt achieving state-of-the-art performance, even outperforming prior rehearsal-based methods that utilize replay buffers. The ability to avoid catastrophic forgetting in a rehearsal-free manner makes DualPrompt favorable for practical continual learning applications with privacy constraints or limited memory budgets. The principled prompt design and strong empirical results position DualPrompt as a promising new approach for real-world lifelong learning systems.
