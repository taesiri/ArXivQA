# [DualPrompt: Complementary Prompting for Rehearsal-free Continual   Learning](https://arxiv.org/abs/2204.04799)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be:

How can we develop an effective rehearsal-free continual learning approach that does not require storing exemplars from previous tasks, while still minimizing catastrophic forgetting?

The key hypotheses seem to be:

1) Separating learnable prompt parameters into complementary "G-Prompts" and "E-Prompts" to encode task-invariant and task-specific knowledge respectively will allow more effective learning of sequential tasks without catastrophic forgetting. 

2) Properly attaching the G-Prompts and E-Prompts to different layers of a pretrained model is crucial for optimizing the continual learning performance.

3) The proposed DualPrompt method with this complementary prompting approach can outperform prior rehearsal-based and non-rehearsal methods by effectively leveraging a pretrained model, without needing to store exemplars.

In summary, the main research question is how to do effective rehearsal-free continual learning, and the key hypothesis is that the proposed complementary prompting approach in DualPrompt can achieve this. Let me know if you would like me to elaborate or clarify anything!


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- Introducing DualPrompt, a new rehearsal-free continual learning method that uses complementary prompts to learn task-invariant and task-specific knowledge. The method uses a General (G) Prompt to learn knowledge that transfers across tasks, and Expert (E) Prompts to learn task-specific knowledge. 

- Presenting a simple yet effective framework for attaching the G and E prompts to different layers of a pre-trained model. The paper explores design choices for where and how to incorporate the prompts.

- Introducing Split ImageNet-R, a new benchmark for continual learning based on ImageNet-R. This benchmark has high intra-class diversity which makes it challenging for rehearsal-based methods.

- Showing state-of-the-art performance of DualPrompt on Split ImageNet-R, Split CIFAR-100, and other benchmarks under the class-incremental learning setting. The method outperforms prior rehearsal-based and non-rehearsal methods, even with a relatively small amount of additional parameters.

In summary, the main contribution appears to be presenting DualPrompt, a simple yet effective rehearsal-free continual learning approach that leverages complementary prompts attached to a pre-trained model. The method sets new state-of-the-art results while using minimal additional memory and parameters. The Split ImageNet-R benchmark is also introduced to provide a more challenging testbed for evaluating continual learning methods.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a new rehearsal-free continual learning approach called DualPrompt that uses small learnable prompt parameters to encode both task-invariant and task-specific knowledge, enabling a pre-trained vision model to continually learn a sequence of tasks without storing past data examples.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other research in the field of continual learning:

- The use of complementary prompting with G-prompts and E-prompts is a novel approach not seen in prior work. Most prior methods use a single prompt pool like L2P or rely on rehearsal buffers. Decoupling prompts to capture task-invariant and task-specific knowledge is an interesting idea grounded in complementary learning systems theory.

- Evaluating on Split ImageNet-R is a nice contribution since it provides a more challenging benchmark than the commonly used datasets like Split CIFAR. The intra-class diversity poses difficulties for rehearsal-based methods.

- The results are quite strong, achieving state-of-the-art on multiple benchmarks. Outperforming rehearsal methods without using any buffer data is impressive.

- The modular framework for attaching prompts is flexible and allows probing the impact of prompt placement. This could enable better customization for new models and tasks in the future.

- Most prior work has focused on convolutional architectures. Leveraging vision transformers matches the current trends in computer vision models.

- While the high-level ideas are novel, some implementation details are similar to prior methods like L2P. The use of keys for task-specific prompts is adapted from that work.

- The method does require a pre-trained model, so it may face challenges if a suitable pre-trained model is unavailable for a new problem domain. Methods that can learn from scratch have some benefits.

Overall, I'd say the unique contributions are in the complementary prompting approach and strong empirical results. The modular framework and new challenging benchmark are also assets. It incrementally pushes forward rehearsal-free continual learning in an exciting direction.


## What future research directions do the authors suggest?

 Based on my reading of the paper, here are some of the main future research directions the authors suggest:

- Developing automated methods for determining the optimal positions to attach the G-prompts and E-prompts in the backbone model. The paper manually searches for good positions but notes this is not guaranteed to find the globally optimal configuration. An automated approach could improve performance.

- Exploring different prompting functions beyond the Prefix Tuning and Prompt Tuning methods compared in the paper. The authors note that the prompting function is a flexible component that could be swapped out, so developing novel prompting techniques may further enhance continual learning. 

- Applying the DualPrompt method to continual learning scenarios with increased task diversity, where sharing knowledge between tasks becomes more difficult. The authors suggest reducing or removing the shared G-prompt in very diverse settings.

- Extending DualPrompt to allow non-contiguous sets of layers to be prompted, rather than just contiguous blocks of layers. This could provide more flexibility in attaching prompts.

- Developing rehearsal-free continual learning methods that do not require a pre-trained model backbone. DualPrompt relies on a frozen pre-trained model, but removing this assumption could increase applicability.

- Exploring whether ideas like DualPrompt's complementary prompting can be integrated into prior continual learning approaches like architecture expansion or regularization methods.

- Applying DualPrompt to continual learning problems beyond image classification, such as in natural language processing tasks.

In general, the main themes seem to be improving automation and flexibility in prompt design, handling more diverse tasks, and extending the ideas to new methods, models, and problem settings.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper proposes a new method called DualPrompt for rehearsal-free continual learning. The method uses two sets of small learnable prompt parameters called G-Prompt and E-Prompt to provide task-invariant and task-specific instructions, respectively, to a pretrained model in order to continually learn new tasks. G-Prompt captures knowledge that transfers across tasks while E-Prompt captures task-specific knowledge. At test time, an input is transformed using a query function to select the closest task key and corresponding E-Prompt to make a prediction. The method sets new state-of-the-art performance on multiple continual learning benchmarks under the challenging class-incremental setting without using any rehearsal buffer. It introduces a new more challenging benchmark called Split ImageNet-R and outperforms prior rehearsal-based methods even with large buffer sizes. The framework is simple, flexible, and effective for rehearsal-free continual learning using pretrained models.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points from the paper:

This paper presents a new framework called DualPrompt for tackling the challenging problem of continual learning. Continual learning aims to enable a single model to sequentially learn new tasks without catastrophic forgetting of past tasks. The proposed DualPrompt method consists of two sets of small learnable parameters called prompts - G-Prompt and E-Prompt. G-Prompt captures task-invariant knowledge that transfers across tasks, while E-Prompt captures task-specific knowledge for each individual task. These complementary prompts provide targeted instructions to the pretrained model backbone when learning new tasks. 

DualPrompt attaches the G and E prompts at different layers of the pretrained model, allowing them to interact with features at different abstraction levels. Experiments across continual learning benchmarks like Split CIFAR-100 and Split ImageNet-R show DualPrompt achieving state-of-the-art performance, even outperforming prior rehearsal-based methods that utilize replay buffers. The ability to avoid catastrophic forgetting in a rehearsal-free manner makes DualPrompt favorable for practical continual learning applications with privacy constraints or limited memory budgets. The principled prompt design and strong empirical results position DualPrompt as a promising new approach for real-world lifelong learning systems.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes a novel rehearsal-free continual learning approach called DualPrompt that learns complementary prompts called G-Prompt and E-Prompt to capture task-invariant and task-specific knowledge, respectively. The G-Prompt parameters are shared across all tasks while each task has separate E-Prompt parameters. These prompt parameters are attached to different layers of a pretrained vision transformer model to steer it towards learning new tasks sequentially without forgetting old ones. Specifically, G-Prompts are attached to earlier layers to learn more general features while E-Prompts are attached to later layers to learn task-specific features. The prompts provide a lightweight and memory-efficient way to encode instructions that guide the model, eliminating the need for a rehearsal buffer. A matching loss is used during training to associate input examples with the correct E-Prompt parameters for their task. At test time, a query vector computed from the input is matched with the task keys to select the appropriate E-Prompt. Experiments show this approach sets new state-of-the-art on class-incremental learning benchmarks, outperforming prior rehearsal-based and non-rehearsal methods.


## What problem or question is the paper addressing?

 Based on my reading, the key points of this paper are:

- It focuses on the problem of continual learning, where the goal is to train machine learning models on a sequence of tasks without catastrophic forgetting of previous tasks. 

- Most prior continual learning methods rely on some form of rehearsal or buffering past data, which has limitations in practice due to privacy concerns or memory constraints. 

- The paper proposes a new rehearsal-free method called DualPrompt that learns complementary "prompts" - a small set of extra parameters - to capture task-invariant and task-specific knowledge when learning a sequence of tasks.

- DualPrompt consists of a General Prompt (G-Prompt) shared across tasks to learn general knowledge, and Expert Prompts (E-Prompts) that are task-specific to capture specialized knowledge. 

- The prompts provide a lightweight and flexible way to inject knowledge into a frozen pre-trained model to perform continual learning, without needing to store past data.

- The method explores where and how to attach the prompts to the self-attention layers of a vision transformer backbone for optimal performance.

- Experiments show DualPrompt sets new state-of-the-art on class-incremental benchmarks, outperforming prior rehearsal-based and non-rehearsal methods.

- It also introduces a new challenging continual learning benchmark called Split ImageNet-R based on ImageNet-R, which has high intra-class diversity.

In summary, the key contribution is a simple yet effective rehearsal-free continual learning approach using complementary prompt learning, with strong empirical results. The method removes the constraints of buffering data like prior methods.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Continual learning - The paper focuses on continual learning, which involves training machine learning models on a sequence of tasks without catastrophic forgetting of previous tasks. 

- Class-incremental learning - The paper specifically looks at the challenging class-incremental learning setting, where task identity is unknown at test time.

- Rehearsal-free - The proposed method aims to achieve good continual learning performance without requiring a rehearsal buffer to store examples from previous tasks.

- Complementary learning systems - The method is inspired by theories of complementary learning systems in human brains, with separate components for learning task-specific vs general knowledge.

- Prompt learning - The method uses trainable "prompt" parameters, a technique from NLP, to provide task-specific or general instructions to a pretrained model.

- G-Prompt and E-Prompt - The two main components of the method are G-Prompt, which learns general task-invariant knowledge, and E-Prompt, which learns task-specific knowledge.

- Modular framework - The paper proposes a modular framework for integrating the G-Prompt and E-Prompt components into a pretrained model in a configurable way.

- Split ImageNet-R - A new challenging continual learning benchmark dataset introduced in the paper.

In summary, the key focus is on a new rehearsal-free continual learning approach using complementary prompt modules, evaluated on image classification tasks.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to ask to create a comprehensive summary of the paper:

1. What is the main focus or purpose of the paper? What problem is it trying to solve?

2. What methods or approaches does the paper propose to address the problem? What is novel about the proposed approach? 

3. What previous work or background research is discussed to provide context? How does the paper relate to or build off of this prior work?

4. What datasets, experimental setup, or evaluation methodology is used? Are the experiments comprehensive to validate the claims?

5. What are the main results or findings presented in the paper? Do the experiments support the claims made?

6. What limitations or potential issues are discussed about the proposed approach? What future work is suggested?

7. Does the paper compare against other state-of-the-art methods? If so, how does the proposed method perform in comparison?

8. What conclusions can be drawn from the research and results presented? Do the authors summarize the key takeaways?

9. Is the paper clearly written and well-structured? Are the claims properly supported?

10. What are the broader impacts or implications of this work for the research community? Is it an incremental improvement or a major advance?

Asking questions that summarize the key points, contributions, methodology, and results will help create a thorough overview of the paper. Focusing on understanding the background, novelty, experiments, limitations, and conclusions will ensure the summary captures the essence of the paper.


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 potential in-depth discussion questions about the method proposed in this paper:

1. The paper presents a novel rehearsal-free continual learning method called DualPrompt, comprised of G-prompts and E-prompts to learn task-invariant and task-specific knowledge respectively. How does this tie into the theory of Complementary Learning Systems that inspired the approach? What are the advantages of decoupling the learning in this higher-level prompt space rather than the latent feature space as done in prior works?

2. The method explores different choices for where and how to attach the G-prompts and E-prompts in the model. Why is this an important design consideration? How do the results shed light on which layers better capture task-general vs task-specific knowledge in vision transformers? 

3. The introduction of the Split ImageNet-R benchmark is useful for evaluating rehearsal-free methods. In what ways does this dataset present new challenges compared to prior continual learning benchmarks? Why is a small buffer insufficient for strong performance on this dataset?

4. The results demonstrate superior performance over prior rehearsal-based methods even with relatively large buffer sizes. Why does this represent a significant advantage of the proposed approach? In what real-world applications might a rehearsal buffer be prohibitive or unavailable?

5. How does the performance of DualPrompt compare when using different backbone models, such as ResNet vs ViT? What does this suggest about the interplay between model scale, pre-training, and continual learning ability?

6. The method explores two different prompting functions – prompt tuning and prefix tuning. Why is the choice of prompting function impactful in this domain? What insights do the results provide about which prompting approaches are better suited for continual learning?

7. The visualization of the learned G-prompt and E-prompt embeddings provides some interpretability into what is being learned. How do the patterns observed align with the intended roles of these two components? How else could the learned representations be analyzed?

8. The ablation studies highlight the contribution of each component of DualPrompt. What do these results reveal about the importance of multi-layer prompts and decoupled prompt positions? How do they support the design choices made?

9. The paper focuses on the challenging class-incremental learning setting without task identifiers at test time. How does this setting relate to real-world use cases compared to simpler continual learning formulations? Does the method make any compromises to achieve this?

10. DualPrompt provides a new state-of-the-art for rehearsal-free continual learning. What possibilities does it open up for practical lifelong learning systems going forward? How might the approach extend to even harder scenarios such as learning under distribution shift between tasks?
