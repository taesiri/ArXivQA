# [Gradual Residuals Alignment: A Dual-Stream Framework for GAN Inversion   and Image Attribute Editing](https://arxiv.org/abs/2402.14398)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing GAN inversion methods that utilize additional high-bit features can better preserve image details compared to low-bit inversion methods. However, they fail to accurately complement the lost details for edited images, leading to poor editability and incoherent results with artifacts. The main reason is they inject all the lost details of the source image indiscriminately into the edited image at one time, which inherently overfits the position and quantity of details to the source image rather than adapting them to fit the edited image.  

Proposed Solution:
This paper proposes a novel dual-stream framework named GradStyle that gradually aligns and complements lost details in a multi-stage coarse-to-fine manner for both reconstruction and editing in StyleGAN. 

The key ideas are:
(1) Lost details should be gradually injected into the reconstruction and editing process across multiple stages from coarse to fine, which provides cumulative benefits for quality and also reduces alignment difficulty. 
(2) A Reconstruction Stream employs a Gradual Residual Module to embed feature-level distortions into residual features that complement details at each stage.
(3) An Editing Stream uses a Global Alignment Module with a Selective Attention mechanism to accurately align residual features globally with the edited images before injecting details.

Together this achieves high reconstruction accuracy and editing quality. A self-supervised training strategy is also introduced to train the dual streams without extra edited data.

Main Contributions:
(1) First work to propose a scheme for gradually complementing lost details in StyleGAN reconstruction and editing.
(2) A novel dual-stream framework with specialized modules to enable the gradual details complementing scheme.
(3) A self-supervised training strategy to train the framework without labeled editing data.
(4) State-of-the-art performance on both reconstruction and editing tasks across datasets.
