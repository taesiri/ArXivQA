# [DiffusionLight: Light Probes for Free by Painting a Chrome Ball](https://arxiv.org/abs/2312.09168)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed summary of the key points in the paper:

This paper proposes a novel method for estimating high dynamic range (HDR) lighting from a single input image. The key idea is to leverage a pre-trained large-scale text-to-image (T2I) diffusion model, specifically Stable Diffusion XL (SDXL), to render a chrome ball into the input image. The chrome ball effectively captures the scene's lighting information in its reflection. Compared to prior work which trains neural networks on limited HDR spherical panorama datasets, using SDXL allows the method to generalize across diverse real-world images without assumptions on camera parameters or scene settings.

To reliably generate high-quality chrome balls, the authors make several improvements to SDXL: (1) Condition it on depth maps to guide object insertion. (2) Fine-tune it with LoRA on synthetically generated balls to improve material appearance. (3) Propose an iterative algorithm to search over the latent space for suitable starting points that lead to consistent balls. For producing HDR environment maps, the fine-tuned model is conditioned to render multiple balls with different exposures akin to exposure bracketing. The exposures are then merged while retaining scene details.  

Experiments on indoor (Laval) and mixed indoor/outdoor (Polyhaven) benchmarks show that the method is on par or outperforms recent techniques like StyleLight and EverLight across different error metrics. More importantly, it generalizes to challenging in-the-wild images where existing state-of-the-art approaches fail. The simplicity yet effectiveness of using a pre-trained model to ``paint in'' light probes makes this an intriguing direction for illumination estimation.
