# [PRADA: Practical Black-Box Adversarial Attacks against Neural Ranking   Models](https://arxiv.org/abs/2204.01321)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research question seems to be: 

How to effectively attack neural ranking models under the practical decision-based black-box attack setting, where the attacker has no direct access to the model and can only query it to get ranking decisions.

The authors propose a novel attack method called PRADA to address this question. The key ideas are:

1) Learn a surrogate model to imitate the target neural ranking model, based on pseudo relevance feedback. 

2) Identify important words in the document that influence rankings the most.

3) Perturb the embedding of important words to promote document ranking.

4) Iteratively replace important words with synonyms to generate adversarial examples.

The paper focuses on attacking neural ranking models like BERT in a black-box manner, which is a realistic but challenging setting. The proposed PRADA method aims to craft adversarial examples that can mislead neural ranking models while preserving semantics and fluency. Evaluations on benchmark datasets demonstrate the effectiveness of PRADA.

In summary, the central hypothesis is that it's possible to launch effective yet inconspicuous adversarial attacks against neural ranking models under practical black-box conditions, by careful surrogate modeling, word importance analysis, embedding perturbation and semantic-preserving replacement. The PRADA method provides an initial solution.


## What is the main contribution of this paper?

 The main contributions of this paper appear to be:

1. Introducing a new Word Substitution Ranking Attack (WSRA) task against neural ranking models (NRMs). The goal is to promote a target document's rank by replacing important words with synonyms. 

2. Proposing a novel PRADA (Pseudo Relevance-based ADversarial ranking Attack) method to generate adversarial examples under the challenging decision-based black-box attack setting. PRADA learns a surrogate model using pseudo relevance feedback, identifies important words, perturbs embeddings, and iteratively replaces words.

3. Conducting experiments on two web search datasets (MS MARCO document and passage ranking) to demonstrate PRADA's effectiveness. The results show it can achieve high attack success rates with small indiscernible perturbations compared to baselines.

4. Analyzing PRADA's ability to evade spam detection, the impact of different components, performance across rank positions, and the number of perturbed words.

5. Providing insights into vulnerabilities of neural ranking models, which could help facilitate development of more robust models and countermeasures before deployment.

In summary, the key contribution appears to be introducing a new adversarial attack task for ranking, and proposing a novel method PRADA that can effectively attack neural ranking models in a challenging black-box setting. The experiments and analyses provide useful insights.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the main points from the paper:

The paper proposes a new adversarial attack task called Word Substitution Ranking Attack (WSRA) against neural ranking models, focusing on a challenging decision-based black-box attack setting, and introduces a novel attack method called PRADA that can successfully fool neural ranking models by replacing important words in a document with synonyms while preserving semantics.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other related work on adversarial attacks against neural ranking models:

- It focuses on a new task, the Word Substitution Ranking Attack (WSRA), which aims to promote a target document's ranking by replacing words with synonyms. This is a novel adversarial attack problem formulation compared to prior work.

- It tackles the challenging decision-based black-box attack setting, where the attacker can only query the target model to get ranked lists. Most prior adversarial attack research in IR has focused on white-box or score-based attacks.

- The proposed PRADA method is innovative in using pseudo-relevance feedback to train a surrogate model for guiding the attack. Other black-box attack methods often rely on heuristics or randomization.

- Experiments are conducted on two large-scale web search datasets (MS MARCO document/passage ranking), using BERT neural ranking models. This is a more realistic setting than some prior adversarial IR papers that used smaller datasets or simpler learning-to-rank models.

- The evaluation is fairly comprehensive, including automatic metrics like success rate, perturbation percentage, semantic similarity, and human evaluations of quality. Many prior attack papers have focused just on success rate.

- Compared to related work on adversarial attacks for text classification, the constraints and goals are different for the ranking problem, requiring new techniques tailored for promoting documents in a list.

Overall, this paper makes solid contributions to the nascent field of adversarial information retrieval, proposing a new task formulation and novel attack method for a realistic threat model. The experiments demonstrate promising results, outperforming heuristic attacks. More research is still needed to develop robust defenses and attacks against ever-improving neural ranking models.


## What future research directions do the authors suggest?

 The authors suggest a few potential future research directions:

- Developing more advanced attack objectives to jointly consider long text and short text for promoting robust neural ranking models. The current PRADA method performs worse on short texts like passages compared to long documents.

- Conducting attacks against real-world search engines using PRADA to demonstrate its practical applicability. The current work focuses on attacking research benchmark datasets.

- Studying adversarial defense methods specifically for neural ranking models to identify vulnerabilities and develop more robust models before deployment. The authors hope this adversarial attack analysis could provide useful insights for future defense research. 

- Going further to explore stronger black-box attack methods against neural ranking models. The decision-based black-box setting tackled in this paper is quite challenging, but even more advanced attacks could be developed.

- Analyzing the transferability of adversarial examples across different neural ranking architectures. The authors utilize this transferability property to train a surrogate model for the attacks, but more analysis can be done.

In summary, the main future directions are: 1) improving attacks for short texts, 2) evaluating against real-world systems, 3) developing defense methods, 4) designing more advanced attacks, and 5) studying transferability across models. The authors aim to promote research on robust neural ranking through this adversarial attack analysis.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper introduces a new adversarial attack task called Word Substitution Ranking Attack (WSRA) against neural ranking models (NRMs). The goal is to promote the rank of a target document by replacing important words with synonyms. The authors focus on a challenging decision-based black-box attack setting where the model outputs only the rank positions. They propose a novel method called PRADA that trains a surrogate model using pseudo relevance feedback, identifies important words using gradients, perturbs the embeddings, and iteratively replaces words with synonyms. Experiments on two datasets show PRADA achieves high attack success and evades spam detection while minimizing the perturbations. The paper makes an important contribution by studying potential adversarial attacks on NRMs before deployment, helping design more robust models.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper introduces the Word Substitution Ranking Attack (WSRA) task against neural ranking models (NRMs). The goal is to promote a target document's ranking by replacing important words with synonyms in a semantic-preserving way. The differences between WSRA and adversarial attacks for image retrieval and text classification are discussed. Different adversarial settings like white-box and black-box attacks are defined. The authors focus on the decision-based black-box attack setting which is realistic for real-world search engines.  

A novel attack method called PRADA is proposed to address the WSRA task. It has four main steps: (1) Train a surrogate model using pseudo-relevance feedback to mimic the target model. (2) Identify important words in the document that influence rankings. (3) Generate adversarial perturbations in the embedding space for important words using projected gradient descent. (4) Iteratively replace important words with synonyms to craft the adversarial sample. Experiments on two datasets show PRADA outperforms baselines, achieving high success rate and low perturbation while preserving semantics. Limitations and future work are discussed. Overall, the paper makes a first attempt at decision-based black-box attacks for the new WSRA task.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes a novel method called PRADA for generating adversarial examples to attack neural ranking models in a black-box setting. The key ideas are:

1. Learn a surrogate model based on pseudo relevance feedback to mimic the target ranking model. Query the target model with random queries and use the top ranked results as training data to train the surrogate model. 

2. Identify important words in the document that have high influence on ranking based on gradients from the surrogate model.

3. Perturb the embedding vectors of important words using projected gradient descent to push the document towards a higher ranking. 

4. Iteratively replace the important words with synonyms that are closest to the perturbed embeddings to generate the adversarial example.

In summary, PRADA utilizes pseudo relevance feedback to train a surrogate model for gradient estimation, identifies important words for perturbation, perturbs the embeddings, and replaces words with synonyms in a semantic preserving way to craft adversarial examples against neural ranking models in a black-box attack setting.


## What problem or question is the paper addressing?

 Based on my reading of the paper, the key points are:

- The paper introduces a new adversarial attack task called Word Substitution Ranking Attack (WSRA) against neural ranking models (NRMs). 

- The goal of WSRA is to promote the ranking of a target document by replacing important words in its text with synonyms, while preserving semantics.

- The paper focuses on a challenging attack setting called decision-based black-box attack. In this setting, the attacker can only query the target model to get rank positions, without access to model information or scores.

- The paper proposes a novel attack method called PRADA (Pseudo Relevance-based ADversarial ranking Attack) to generate adversarial examples under this setting.

- PRADA has four main steps: 1) Learn a surrogate model using pseudo relevance feedback; 2) Identify important words using the surrogate; 3) Perturb embeddings of important words; 4) Iteratively replace words with synonyms.

- Experiments show PRADA can successfully attack NRMs by promoting target documents, while keeping perturbations small and semantic similarity high.

In summary, the key problem addressed is how to perform effective yet imperceptible adversarial attacks against neural ranking models in a challenging black-box setting, which is important for evaluating model robustness. The paper makes initial progress in this direction by proposing the WSRA task and an attack method called PRADA.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper summary, some of the key terms and keywords related to this paper are:

- Neural ranking models (NRMs)
- Adversarial attacks 
- Word substitution ranking attack (WSRA) 
- Black-box attacks
- Decision-based attacks
- Pseudo relevance feedback (PRF)
- Projected gradient descent (PGD)
- Synonym replacement
- Embedding space perturbation
- Automatic evaluation metrics (success rate, perturbation percentage, semantic similarity)
- MS MARCO document ranking dataset
- MS MARCO passage ranking dataset

The paper introduces a new adversarial attack task called WSRA against neural ranking models. The goal is to promote a target document's ranking by replacing important words with synonyms. The authors focus on a practical decision-based black-box attack setting, where the model provides only hard ranking decisions. 

They propose a PRADA method based on pseudo relevance feedback to learn a surrogate model and generate gradients to find important words to perturb. The perturbations are generated in the embedding space using PGD. Finally, important words are iteratively replaced with synonyms while preserving semantics.

Experiments on MS MARCO datasets show PRADA can effectively attack neural ranking models in the black-box setting with high success rate and low perturbations. The key terms cover the adversarial attack task, proposed method, attack setting, techniques used, evaluation metrics, and datasets.
