# [PRADA: Practical Black-Box Adversarial Attacks against Neural Ranking   Models](https://arxiv.org/abs/2204.01321)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research question seems to be: 

How to effectively attack neural ranking models under the practical decision-based black-box attack setting, where the attacker has no direct access to the model and can only query it to get ranking decisions.

The authors propose a novel attack method called PRADA to address this question. The key ideas are:

1) Learn a surrogate model to imitate the target neural ranking model, based on pseudo relevance feedback. 

2) Identify important words in the document that influence rankings the most.

3) Perturb the embedding of important words to promote document ranking.

4) Iteratively replace important words with synonyms to generate adversarial examples.

The paper focuses on attacking neural ranking models like BERT in a black-box manner, which is a realistic but challenging setting. The proposed PRADA method aims to craft adversarial examples that can mislead neural ranking models while preserving semantics and fluency. Evaluations on benchmark datasets demonstrate the effectiveness of PRADA.

In summary, the central hypothesis is that it's possible to launch effective yet inconspicuous adversarial attacks against neural ranking models under practical black-box conditions, by careful surrogate modeling, word importance analysis, embedding perturbation and semantic-preserving replacement. The PRADA method provides an initial solution.


## What is the main contribution of this paper?

 The main contributions of this paper appear to be:

1. Introducing a new Word Substitution Ranking Attack (WSRA) task against neural ranking models (NRMs). The goal is to promote a target document's rank by replacing important words with synonyms. 

2. Proposing a novel PRADA (Pseudo Relevance-based ADversarial ranking Attack) method to generate adversarial examples under the challenging decision-based black-box attack setting. PRADA learns a surrogate model using pseudo relevance feedback, identifies important words, perturbs embeddings, and iteratively replaces words.

3. Conducting experiments on two web search datasets (MS MARCO document and passage ranking) to demonstrate PRADA's effectiveness. The results show it can achieve high attack success rates with small indiscernible perturbations compared to baselines.

4. Analyzing PRADA's ability to evade spam detection, the impact of different components, performance across rank positions, and the number of perturbed words.

5. Providing insights into vulnerabilities of neural ranking models, which could help facilitate development of more robust models and countermeasures before deployment.

In summary, the key contribution appears to be introducing a new adversarial attack task for ranking, and proposing a novel method PRADA that can effectively attack neural ranking models in a challenging black-box setting. The experiments and analyses provide useful insights.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the main points from the paper:

The paper proposes a new adversarial attack task called Word Substitution Ranking Attack (WSRA) against neural ranking models, focusing on a challenging decision-based black-box attack setting, and introduces a novel attack method called PRADA that can successfully fool neural ranking models by replacing important words in a document with synonyms while preserving semantics.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other related work on adversarial attacks against neural ranking models:

- It focuses on a new task, the Word Substitution Ranking Attack (WSRA), which aims to promote a target document's ranking by replacing words with synonyms. This is a novel adversarial attack problem formulation compared to prior work.

- It tackles the challenging decision-based black-box attack setting, where the attacker can only query the target model to get ranked lists. Most prior adversarial attack research in IR has focused on white-box or score-based attacks.

- The proposed PRADA method is innovative in using pseudo-relevance feedback to train a surrogate model for guiding the attack. Other black-box attack methods often rely on heuristics or randomization.

- Experiments are conducted on two large-scale web search datasets (MS MARCO document/passage ranking), using BERT neural ranking models. This is a more realistic setting than some prior adversarial IR papers that used smaller datasets or simpler learning-to-rank models.

- The evaluation is fairly comprehensive, including automatic metrics like success rate, perturbation percentage, semantic similarity, and human evaluations of quality. Many prior attack papers have focused just on success rate.

- Compared to related work on adversarial attacks for text classification, the constraints and goals are different for the ranking problem, requiring new techniques tailored for promoting documents in a list.

Overall, this paper makes solid contributions to the nascent field of adversarial information retrieval, proposing a new task formulation and novel attack method for a realistic threat model. The experiments demonstrate promising results, outperforming heuristic attacks. More research is still needed to develop robust defenses and attacks against ever-improving neural ranking models.


## What future research directions do the authors suggest?

 The authors suggest a few potential future research directions:

- Developing more advanced attack objectives to jointly consider long text and short text for promoting robust neural ranking models. The current PRADA method performs worse on short texts like passages compared to long documents.

- Conducting attacks against real-world search engines using PRADA to demonstrate its practical applicability. The current work focuses on attacking research benchmark datasets.

- Studying adversarial defense methods specifically for neural ranking models to identify vulnerabilities and develop more robust models before deployment. The authors hope this adversarial attack analysis could provide useful insights for future defense research. 

- Going further to explore stronger black-box attack methods against neural ranking models. The decision-based black-box setting tackled in this paper is quite challenging, but even more advanced attacks could be developed.

- Analyzing the transferability of adversarial examples across different neural ranking architectures. The authors utilize this transferability property to train a surrogate model for the attacks, but more analysis can be done.

In summary, the main future directions are: 1) improving attacks for short texts, 2) evaluating against real-world systems, 3) developing defense methods, 4) designing more advanced attacks, and 5) studying transferability across models. The authors aim to promote research on robust neural ranking through this adversarial attack analysis.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper introduces a new adversarial attack task called Word Substitution Ranking Attack (WSRA) against neural ranking models (NRMs). The goal is to promote the rank of a target document by replacing important words with synonyms. The authors focus on a challenging decision-based black-box attack setting where the model outputs only the rank positions. They propose a novel method called PRADA that trains a surrogate model using pseudo relevance feedback, identifies important words using gradients, perturbs the embeddings, and iteratively replaces words with synonyms. Experiments on two datasets show PRADA achieves high attack success and evades spam detection while minimizing the perturbations. The paper makes an important contribution by studying potential adversarial attacks on NRMs before deployment, helping design more robust models.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper introduces the Word Substitution Ranking Attack (WSRA) task against neural ranking models (NRMs). The goal is to promote a target document's ranking by replacing important words with synonyms in a semantic-preserving way. The differences between WSRA and adversarial attacks for image retrieval and text classification are discussed. Different adversarial settings like white-box and black-box attacks are defined. The authors focus on the decision-based black-box attack setting which is realistic for real-world search engines.  

A novel attack method called PRADA is proposed to address the WSRA task. It has four main steps: (1) Train a surrogate model using pseudo-relevance feedback to mimic the target model. (2) Identify important words in the document that influence rankings. (3) Generate adversarial perturbations in the embedding space for important words using projected gradient descent. (4) Iteratively replace important words with synonyms to craft the adversarial sample. Experiments on two datasets show PRADA outperforms baselines, achieving high success rate and low perturbation while preserving semantics. Limitations and future work are discussed. Overall, the paper makes a first attempt at decision-based black-box attacks for the new WSRA task.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes a novel method called PRADA for generating adversarial examples to attack neural ranking models in a black-box setting. The key ideas are:

1. Learn a surrogate model based on pseudo relevance feedback to mimic the target ranking model. Query the target model with random queries and use the top ranked results as training data to train the surrogate model. 

2. Identify important words in the document that have high influence on ranking based on gradients from the surrogate model.

3. Perturb the embedding vectors of important words using projected gradient descent to push the document towards a higher ranking. 

4. Iteratively replace the important words with synonyms that are closest to the perturbed embeddings to generate the adversarial example.

In summary, PRADA utilizes pseudo relevance feedback to train a surrogate model for gradient estimation, identifies important words for perturbation, perturbs the embeddings, and replaces words with synonyms in a semantic preserving way to craft adversarial examples against neural ranking models in a black-box attack setting.


## What problem or question is the paper addressing?

 Based on my reading of the paper, the key points are:

- The paper introduces a new adversarial attack task called Word Substitution Ranking Attack (WSRA) against neural ranking models (NRMs). 

- The goal of WSRA is to promote the ranking of a target document by replacing important words in its text with synonyms, while preserving semantics.

- The paper focuses on a challenging attack setting called decision-based black-box attack. In this setting, the attacker can only query the target model to get rank positions, without access to model information or scores.

- The paper proposes a novel attack method called PRADA (Pseudo Relevance-based ADversarial ranking Attack) to generate adversarial examples under this setting.

- PRADA has four main steps: 1) Learn a surrogate model using pseudo relevance feedback; 2) Identify important words using the surrogate; 3) Perturb embeddings of important words; 4) Iteratively replace words with synonyms.

- Experiments show PRADA can successfully attack NRMs by promoting target documents, while keeping perturbations small and semantic similarity high.

In summary, the key problem addressed is how to perform effective yet imperceptible adversarial attacks against neural ranking models in a challenging black-box setting, which is important for evaluating model robustness. The paper makes initial progress in this direction by proposing the WSRA task and an attack method called PRADA.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper summary, some of the key terms and keywords related to this paper are:

- Neural ranking models (NRMs)
- Adversarial attacks 
- Word substitution ranking attack (WSRA) 
- Black-box attacks
- Decision-based attacks
- Pseudo relevance feedback (PRF)
- Projected gradient descent (PGD)
- Synonym replacement
- Embedding space perturbation
- Automatic evaluation metrics (success rate, perturbation percentage, semantic similarity)
- MS MARCO document ranking dataset
- MS MARCO passage ranking dataset

The paper introduces a new adversarial attack task called WSRA against neural ranking models. The goal is to promote a target document's ranking by replacing important words with synonyms. The authors focus on a practical decision-based black-box attack setting, where the model provides only hard ranking decisions. 

They propose a PRADA method based on pseudo relevance feedback to learn a surrogate model and generate gradients to find important words to perturb. The perturbations are generated in the embedding space using PGD. Finally, important words are iteratively replaced with synonyms while preserving semantics.

Experiments on MS MARCO datasets show PRADA can effectively attack neural ranking models in the black-box setting with high success rate and low perturbations. The key terms cover the adversarial attack task, proposed method, attack setting, techniques used, evaluation metrics, and datasets.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to ask in order to create a comprehensive summary of the paper:

1. What is the research problem this paper aims to address?

2. What is the Word Substitution Ranking Attack (WSRA) task introduced in the paper? What is its goal? 

3. What are the key differences between the WSRA task and adversarial attacks in image retrieval and text classification?

4. What are the different adversarial attack settings defined for the WSRA task? Which setting does this paper focus on and why?

5. What is the proposed Pseudo Relevance-based ADversarial ranking Attack (PRADA) method? What are its key components?

6. What datasets were used to evaluate PRADA? What evaluation metrics were used?

7. How does PRADA compare to baseline methods under automatic and human evaluations? What are the key results?

8. Can PRADA evade detection by anti-spamming methods? What do the results show?

9. How does the ablation study analyze the effect of different components of PRADA? What are the key findings?

10. What are the limitations of PRADA discussed in the paper? What future work is suggested to address them?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 in-depth questions about the PRADA method proposed in the paper:

1. The paper proposes the Word Substitution Ranking Attack (WSRA) task against neural ranking models (NRMs). How is this task different from existing adversarial attacks on images and text classification models? What new challenges does it present?

2. The paper focuses on the decision-based black-box attack setting for WSRA. Why is this setting more realistic yet more challenging compared to white-box and score-based attacks? How does the lack of gradients and predicted probabilities make the attack harder?

3. Explain the four key components of the PRADA method: surrogate model training, token importance ranking, embedding space perturbation, and important word replacement. How do they work together to generate adversarial examples?

4. The surrogate model is trained based on pseudo relevance feedback (PRF). Why is PRF a suitable technique for obtaining training signals for the surrogate model under the black-box setting? How are the pseudo labels generated?

5. How does PRADA identify important tokens in the document that have high influence on ranking? Why is it better to only perturb important tokens rather than all tokens?

6. Explain how PRADA applies projected gradient descent (PGD) to perturb the embedding space. How does it generate gradients and use them to craft adversarial perturbations? 

7. What constraints does PRADA impose during word replacement to ensure quality of adversarial examples? Why are they important?

8. One limitation mentioned is PRADA's difficulty in attacking short documents. What causes this limitation? How can it be addressed in future work?

9. The paper shows PRADA can evade detection by anti-spamming methods, unlike baseline repetition attacks. Why is PRADA more stealthy? How does this demonstrate its applicability?

10. What are the broader impacts and future directions of this work? How could PRADA's approach inform development of robust ranking models and defenses against adversarial attacks?


## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary of the paper:

The paper introduces a new adversarial attack task called Word Substitution Ranking Attack (WSRA) against neural ranking models (NRMs). The goal is to promote a target document's rank in search results by adding small perturbations to its text. The perturbations should be semantically consistent with the original document and imperceptible to human judges. The authors focus on a challenging decision-based black-box attack setting where the attacker can only query the target model to get ranked lists. They propose a novel attack method called PRADA that uses pseudo-relevance feedback to train a surrogate model and iteratively replaces important words with synonyms using projected gradient descent. Experiments on two web search datasets MS MARCO document ranking and passage ranking show PRADA successfully fools NRMs and outperforms baselines. The perturbations are small and evade spam detection while maintaining high semantic similarity. The results demonstrate vulnerabilities of NRMs and the need for developing more robust models and countermeasures. Overall, this is an important study introducing a new adversarial task against NRMs with a practical attack method, insights on model vulnerabilities, and future research directions.


## Summarize the paper in one sentence.

 The paper introduces the Word Substitution Ranking Attack (WSRA) task against neural ranking models (NRMs), proposes a pseudo relevance-based adversarial ranking attack method (PRADA) for the decision-based black-box attack setting, and demonstrates its effectiveness in promoting target documents with small perturbations on benchmark datasets.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the paper:

This paper introduces a new adversarial attack task called Word Substitution Ranking Attack (WSRA) against neural ranking models (NRMs). The goal is to promote a target document's ranking by adding small perturbations to its text. The authors focus on a practical decision-based black-box attack setting where the attacker can only query the target model to get ranking positions, not internal information. They propose a novel attack method called PRADA that uses pseudo-relevance feedback to train a surrogate model and identify important words in the document. It then perturbs those words' embeddings towards higher ranking and replaces them with synonyms to create the adversarial example. Experiments on MS MARCO document and passage ranking datasets show PRADA achieves higher success rates and lower perturbations than baseline attacks while maintaining semantic similarity. The paper demonstrates vulnerabilities in NRMs that could enable new web spamming techniques and highlights the need for more robust ranking models.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes a new adversarial attack task called Word Substitution Ranking Attack (WSRA) against neural ranking models (NRMs). How is WSRA different from existing adversarial attacks on images and text classification? What are the key challenges in generating effective adversarial examples for WSRA?

2. The paper focuses on the decision-based black-box attack setting for WSRA. Why is this setting more realistic yet more challenging compared to white-box attacks and score-based black-box attacks? What strategies does the proposed PRADA method use to address the challenges in this setting?

3. The PRADA method uses a surrogate model trained with pseudo-relevance feedback. Explain the intuition behind using pseudo-relevance feedback here and how the surrogate model is trained. What are the advantages of using a surrogate model compared to directly attacking the target model?

4. Explain the Token Importance Ranking step in PRADA. How does it select the most influential words to perturb in the document? Why is it important to only perturb the most influential words?

5. The Embedding Space Perturbation step uses Projected Gradient Descent (PGD). Explain how PGD perturbs the embedding space to generate an adversarial candidate. Why perturb the embedding space instead of directly replacing words?

6. The Important Word Replacement step iteratively replaces words with synonyms. Explain the greedy replacement strategy used here. Why is it important to replace words with synonyms rather than random words?

7. Analyze the results of model ablation experiments. Which components of PRADA contribute most to the attack success rate and semantic consistency? Why is the full model the most effective?

8. The paper shows PRADA is more effective on lower ranked documents. Why might it be harder to promote higher ranked documents compared to lower ranked ones? How could the attack be improved for higher ranked documents?

9. Compare the quality of adversarial examples generated by PRADA and the baseline repetition attack method through the case study. What makes PRADA's examples higher quality and more difficult to detect?

10. The paper focuses on promoting documents in rankings. How could the proposed techniques be adapted to demote or remove documents instead? What would be the main challenges in that scenario?
