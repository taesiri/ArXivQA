# [Initialization Matters for Adversarial Transfer Learning](https://arxiv.org/abs/2312.05716)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper studies adversarial robustness in the context of transfer learning, where a model pretrained on a source dataset is finetuned on a target downstream task. It focuses on understanding what matters most for achieving adversarial robustness in the finetuning process. Specifically, it aims to answer:

1) Is an adversarially robust pretrained model necessary for parameter-efficient finetuning (PEFT) methods to achieve adversarial robustness on downstream tasks? 

2) Given a robust pretrained model, what initialization scheme and finetuning method works best to maximize adversarial robustness on downstream tasks?

Proposed Solution:

1) The paper discovers that PEFT methods fail or exhibit significantly inferior performance when using a standard non-robust pretrained model, even with adversarial finetuning on the downstream data. This highlights the necessity of an adversarially robust pretrained model.

2) With a robust pretrained model, the paper surprisingly finds that adversarial linear probing, which only updates the classification head, can outperform other finetuning methods that update more parameters on certain datasets. This is because linear probing excels at preserving the robustness from pretraining. 

3) Based on this insight, the paper proposes Robust Linear Initialization (RoLI) to initialize the linear head using weights from adversarial linear probing before finetuning. This allows maximally inheriting robustness from pretraining. Subsequent adversarial finetuning can then effectively adapt features to the downstream task.

Main Contributions:

1) Comprehensively studies six popular finetuning techniques and discovers PEFT methods fail without a robust pretrained model, highlighting its necessity.

2) Identifies adversarial linear probing's effectiveness in preserving robustness from robust pretraining and limitations in adapting features.

3) Proposes Robust Linear Initialization (RoLI) to maximize inherited robustness from pretraining while allowing effective feature adaptation.

4) Demonstrates RoLI consistently improves performance across five datasets, achieving new state-of-the-art adversarial robustness for transfer learning.
