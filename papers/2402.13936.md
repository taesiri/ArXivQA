# [Distinctive Image Captioning: Leveraging Ground Truth Captions in CLIP   Guided Reinforcement Learning](https://arxiv.org/abs/2402.13936)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Image captioning models trained with teacher forcing on ground truth captions tend to generate generic, non-distinctive captions that fail to distinguish between similar images. 
- Using reinforcement learning (RL) with a similarity reward from a pre-trained cross-modal retriever like CLIP produces more distinctive captions, but can result in degraded language quality (reward hacking).

Proposed Solution:
- Leverage ground truth (GT) captions in multiple ways in the RL framework:
  1) Train a discriminator on GT vs generated captions to promote fluent captions (textual GAN setup)
  2) Use GT caps as additional RL trajectories weighted by similarity score (weighted TF loss)
  3) Use GT caps as candidate baselines when computing contrastive reward 
- Define a bidirectional contrastive reward that considers both text-to-image and image-to-text retrieval directions.
- Overall approach promotes distinctive captions while maintaining high language quality.

Main Contributions:
- Show GT caps useful even in RL framework that doesn't require them
- Discriminator regularizes language quality better than previous sequence-level criteria 
- Weighted TF loss allows model to recover from RL instabilities and reduces vocabulary collapse
- Bidirectional contrastive reward ensured captions uniquely describe image
- Improved trade-off between distinctiveness and language quality

In summary, the paper proposes an improved RL training approach for distinctive image captioning that strategically leverages ground truth captions to promote language quality and retrieval performance. The bidirectional contrastive reward and weighted teacher forcing are notable contributions.
