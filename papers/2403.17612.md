# ["You are an expert annotator": Automatic Best-Worst-Scaling Annotations   for Emotion Intensity Modeling](https://arxiv.org/abs/2403.17612)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Labeling text data is expensive and time-consuming, especially for continuous/regression tasks like emotion intensity prediction. 
- Humans perform poorly when assigning absolute values from a rating scale. Comparative methods like best-worst scaling (BWS) lead to more consistent annotations.
- No prior work on using large language models (LLMs) to automate annotations for continuous label assignments. Unclear if BWS is necessary with LLMs or if rating scales would suffice.

Method:
- Compare 4 annotation methods using LLMs - rating scales, rating scale tuples, paired comparisons, best-worst scaling
- Use emotion intensity prediction task and Affect-in-Tweets dataset with original BWS human annotations
- Evaluate alignment of LLM annotations with human scores and performance when training transformer regressor on LLM annotations

Key Findings:
- BWS outperforms other methods in both direct comparison and downstream regressor performance
- Increasing number of BWS tuple annotations improves quality, automated annotations achieve near human-level regressor performance 
- Analyses show BWS works best for novel datasets, rating scales better for replicating existing rating scale datasets
- Validated on second dataset - confirms BWS good for novel continuous annotation tasks

Main Contributions:
- First method to automatically annotate texts for continuous label regression problems using LLMs
- Demonstrates BWS with increased tuples leads to most accurate and consistent annotations
- Shows automated BWS annotations can train regressors that perform on par with human annotations
- Provides guidance on best practices for automating novel vs existing continuous annotation tasks

In summary, the paper presents an effective approach for automating continuous value annotations using best-worst scaling with LLMs, with downstream model performance rivaling human annotations.
