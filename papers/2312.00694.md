# [Object Detector Differences when using Synthetic and Real Training Data](https://arxiv.org/abs/2312.00694)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper trains YOLOv3 object detection models on real (BDD) and synthetic (GTAV) city driving images to analyze the similarity of internal representations. Three models are compared: U-Real trained on BDD, U-Synthetic trained on GTAV with trainable backbone, and F-Synthetic trained on GTAV with frozen backbone. Using centered kernel alignment (CKA), the authors find the early backbone layers have high similarity (>0.9) irrespective of training data, indicating they capture generic features. The later backbone layers show more variation, and the detection head shows the lowest similarity (<0.2), suggesting it captures dataset-specific representations. Across backbones, U-Synthetic and F-Synthetic are more similar than when compared to U-Real. No major differences in similarity or performance are observed between frozen and unfrozen backbones. The analysis gives insight into how synthetic data affects each layer, with the greatest differences arising in the detection head. The work helps understand model representations and aid effective use of synthetic data.
