# [Preference optimization of protein language models as a multi-objective   binder design paradigm](https://arxiv.org/abs/2403.04187)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Designing peptide binders for protein targets that satisfy multiple constraints like binding affinity, synthesizability, solubility etc is challenging. 
- Existing approaches optimize for binding but treat other constraints as downstream filters. A framework to directly generate peptides satisfying multiple objectives is lacking.

Proposed Solution:
- Use a protein language model (pLM) like ProtGPT2 and perform a two-step fine-tuning:
   1. Supervised fine-tuning (SFT) to specialize the pLM for generating binders conditioned on target proteins. 
   2. Direct Preference Optimization (DPO) to discriminate good and bad binders based on expert curated datasets.
- Encode preferences for multiple objectives like binding specificity and isoelectric point directly into the pLM using positive and negative examples.
- DPO maximizes the probability of sampling 'good' binders relative to 'bad' ones based on a Bradley-Terry formulation.

Key Contributions:
- First application of DPO to optimize protein LMs for multi-objective molecular design satisfying binding as well as physicochemical constraints.
- Demonstrate conditioning the pLM on target proteins and subsequent DPO using expert datasets significantly enhances design quality.  
- Median isoelectric point (measure of peptide charge) improved by 17-60% over baseline SFT samples. Alignment to real binders also improved.
- Framework is generalizable to incorporate diverse expert knowledge or negative results to guide multi-objective optimization.
