# [From Word Models to World Models: Translating from Natural Language to   the Probabilistic Language of Thought](https://arxiv.org/abs/2306.12672)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we develop a computational framework that combines neural models of language with symbolic models of reasoning to achieve human-like language understanding and thinking?Specifically, the paper proposes an approach called "rational meaning construction" which uses probabilistic programming to represent a structured "language of thought", and large language models to translate from natural language into this language of thought. The key ideas seem to be:- Thinking and reasoning can be modeled as Bayesian inference in structured probabilistic programs that represent possible worlds. - Understanding language involves translating utterances into expressions in this "probabilistic language of thought" in a context-sensitive way.- Large language models can be used to implement the translation from natural language to code, amortizing the process of meaning construction.- This framework allows integrating language with core domains of reasoning like probabilistic inference, physical simulation, planning, etc.So in summary, the main hypothesis is that combining neural translation models with structured symbolic reasoning in a "language of thought" can lead to more human-like language understanding and thinking in machines. The paper aims to illustrate this framework across several reasoning domains.


## What is the main contribution of this paper?

Based on my reading, the main contribution of this paper is proposing a new computational framework called "rational meaning construction" for relating language to thought. The key ideas are:- Formalizing thought as probabilistic programming in a "probabilistic language of thought" (PLoT). The PLoT allows representing generative models of domains, conditioning them on observations, and performing inference to answer queries.- Formalizing linguistic meaning as a context-sensitive mapping from natural language into the PLoT. This meaning function translates sentences into PLoT code that captures their meaning with respect to the generative domain model. - Using large language models trained on code as an implementation of the meaning function. LLMs can learn mappings from language to code based on the joint distribution over language and code.- Illustrating this framework on examples from four domains - probabilistic reasoning, relational reasoning, physical/visual reasoning, and social reasoning. The examples show how language can be translated into the PLoT to drive reasoning.- Discussing how this framework could be extended to grow knowledge and construct new models, as well as open questions around scaling inference, training the translation function, connections to linguistics and cognitive science, and implications for AI.In summary, the main contribution is proposing a computational architecture, based on probabilistic programming and large language models, for integrating language with reasoning across a variety of domains in a way that is inspired by human cognition. The examples aim to illustrate the potential of this approach.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a computational framework called "rational meaning construction" that integrates neural models of language with probabilistic models of reasoning to enable systems to understand natural language input and perform human-like commonsense reasoning.
