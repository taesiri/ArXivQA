# [Dynamic Neural Network for Multi-Task Learning Searching across Diverse   Network Topologies](https://arxiv.org/abs/2303.06856)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question/hypothesis of this paper is:How to design an MTL framework that can search for optimized network structures tailored to each individual task across diverse graph topologies in a single network? The paper proposes a new MTL framework to address two key challenges:1) Searching across diverse graph topologies: The paper applies DAG structure to allow searching across diverse topologies. However, DAG-based search space is too large for MTL. 2) Constructing task-specific sub-networks: Existing MTL methods using DNN or NAS cannot find optimal structures for each task. They use simple/restricted topologies which may degrade performance in heterogeneous MTL scenarios.To address these challenges, the paper proposes:- A restricted DAG-based central network with read-in/out layers to enable topology search while limiting search space. - A training procedure and algorithms to optimize the central network into compact task-specific sub-networks.The central hypothesis is that by searching across broader graph topologies and optimizing task-specific structures, the proposed MTL framework can achieve better performance compared to prior MTL methods. Experiments on benchmark datasets verify this hypothesis.In summary, the core research question is how to design an MTL framework that can search across diverse topologies to find optimized task-specific structures in a scalable way. The paper aims to address the limitations of prior MTL methods in this aspect.
