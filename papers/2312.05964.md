# [ConSequence: Synthesizing Logically Constrained Sequences for Electronic   Health Record Generation](https://arxiv.org/abs/2312.05964)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Generating realistic sequential data like patient records or text is important for many applications, but current generative models struggle to adhere to domain-specific logical constraints and relationships. For example, in generating electronic health records (EHRs), models should follow medical knowledge like indications and contraindications for treatments based on diagnoses. However, models fail to meet such temporal and static constraints, producing invalid outputs that reduce adoption.

Proposed Solution:
The paper proposes ConSequence, a novel method to integrate logical constraints into sequential neural generative models like those for EHR synthesis. ConSequence handles constraints formatted as logical entailment rules through two key modules:

1) Temporal Aggregation: Aggregates relevant historical information needed for temporal rules using an attentive mechanism. 

2) Antecedent Evaluation: Introduces a "rule neuron" model that fires when the antecedent clause of a rule is satisfied based on current and historical data, overriding model outputs to enforce consequent constraints.

These modules enable ConSequence to guarantee meeting hard constraints while regularizing soft constraints. Crucially, ConSequence represents the modules as matrices for massively parallel GPU processing, enabling efficiency.

Key Contributions:

- ConSequence supports a wide range of constraint types including static, temporal, soft and hard constraints. Uniquely, it handles intricate temporal constraints using selective aggregation.

- It provides absolute guarantee of meeting hard constraints, unlike prior irregularization methods. This prevents any logical errors to improve user trust.

- ConSequence seamlessly integrates constraints into model training and inference through a matrix formulation while adding minimal computational overhead (<13%). This efficiency at scale is unmatched by prior approaches.

Experiments on EHR generation tasks demonstrate ConSequence prevents all constraint violations unlike other methods. It also enhances model quality, reducing perplexity by 5%, and outperforms all baselines in efficiency during training and generation. This showcases its ability to produce logically coherent sequential data without compromising performance.
