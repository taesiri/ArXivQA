# [DBARF: Deep Bundle-Adjusting Generalizable Neural Radiance Fields](https://arxiv.org/abs/2303.14478)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How can we jointly optimize camera poses along with generalizable neural radiance fields (GeNeRFs) in an end-to-end manner, without requiring known camera poses like previous methods?

The key points are:

- Existing methods like BARF can jointly optimize camera poses with per-scene optimized NeRFs, but cannot work with GeNeRFs which are generalizable across scenes. 

- The authors analyze the difficulties of bundle adjusting (optimizing camera poses via bundle adjustment) with GeNeRFs. Issues like feature outliers and non-smooth cost functions make this challenging.

- They propose a method called DBARF that can jointly optimize camera poses and GeNeRF in an end-to-end manner, without requiring known poses. It uses a deep pose optimizer based on cost feature maps.

- Experiments show DBARF can generalize across scenes and outperform BARF/GARF without per-scene finetuning. It also produces better results than IBRNet on some scenes, even though IBRNet uses known poses.

So in summary, the key research question is how to jointly optimize poses and GeNeRFs in an end-to-end generalizable manner, which their proposed DBARF method aims to address. The hypothesis is that their approach can outperform prior pose optimization methods that work only with per-scene NeRFs.
