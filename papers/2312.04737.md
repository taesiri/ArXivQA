# [Efficient Large Language Models Fine-Tuning On Graphs](https://arxiv.org/abs/2312.04737)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Learning from text-attributed graphs (TAGs) is important for many applications but faces challenges. 
- Using large language models (LLMs) on TAGs has potential to improve performance but suffers from inferior computation and data efficiency.
- Existing methods that combine LLMs and graph neural networks (GNNs) have issues:
   - Cascaded approaches do not incorporate graph structure when fine-tuning LLMs.
   - Iterative approaches have high computational overhead.
   - Self-supervised methods also have scalability issues.

Proposed Solution:
- The paper proposes LEADING, an efficient algorithm to fine-tune LLMs on TAGs end-to-end with GNNs. 
- It reduces "encoding redundancy" of node features in LLMs via a two-pipeline sampling approach:
   - Pipeline 1: Encode target node features (with gradients)
   - Pipeline 2: Encode neighbor node features (without gradients)
- It reduces "propagation redundancy" in GNNs via implicit graph modeling.
- This maintains computation cost comparable to graph-less LLM fine-tuning.

Main Contributions:
- Identifies and reduces redundancy in combining LLMs with GNNs for superior efficiency.
- Allows effective transfer of knowledge from LLMs to graph learning with limited labeled data. 
- Experiments show LEADING matches or improves accuracy of state-of-the-art methods on various datasets.
- Significantly reduces memory and computation costs compared to existing LLM-GNN approaches.
- Provides a promising solution to exploit LLMs for wide range of graph learning tasks on TAGs.

In summary, the paper makes LLMs on graphs practical by developing an efficient end-to-end fine-tuning approach LEADING that achieves better data efficiency and scalability.
