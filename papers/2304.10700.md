# [Long-Term Photometric Consistent Novel View Synthesis with Diffusion   Models](https://arxiv.org/abs/2304.10700)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question of this paper is: How can we develop a generative model that is able to produce a sequence of photorealistic novel views from a single input view and desired camera trajectory, while ensuring consistency between the generated views?The key points are:- The paper focuses on the challenging task of novel view synthesis from a single input image, where the goal is to generate new views separated by large motions. This is called view extrapolation.- Existing methods have limitations in generating consistent and photorealistic novel views, especially for large motions.- The paper proposes a novel generative model based on diffusion models that can sample multiple plausible and consistent novel views by conditioning on a single input view and the relative camera poses.- The model uses a specialized architecture with geometry-aware conditioning to ensure consistency between views.- They introduce a new metric called Thresholded Symmetric Epipolar Distance (TSED) to directly measure the geometric consistency between generated views based on epipolar geometry, independent of image quality.- Experiments show their method generates more photorealistic and geometrically consistent views compared to previous state-of-the-art methods, even for novel camera trajectories not seen during training.In summary, the key hypothesis is that a properly designed conditional diffusion model with explicit geometric conditioning can generate consistent and high-quality novel views from a single image across large viewpoint changes. The experiments aim to validate this hypothesis.
