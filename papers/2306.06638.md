# [Face0: Instantaneously Conditioning a Text-to-Image Model on a Face](https://arxiv.org/abs/2306.06638)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we instantaneously condition a text-to-image generation model on a face image during inference, without requiring per-instance optimization like fine-tuning or inversions?The key hypothesis appears to be:By augmenting the training data with face embeddings and training the model to also condition on these embeddings, we can equip the model with the capability to generate images conditioned on a face image at test time, just by calculating the embedding of the input face and providing it to the model along with the text prompt.In particular, the authors propose a method called Face0 that projects face embeddings into the text embedding space and trains the model to take both text and projected face embeddings as input. At test time, Face0 only requires computing the embedding of the input face image and using it in place of a few tokens in the text embedding. This allows instant face conditioning without any per-instance optimization.So in summary, the central research question is how to add facial conditioning to text-to-image models efficiently during inference. And the key hypothesis is that augmenting the training data and dual conditioning will allow this, as embodied in the proposed Face0 method.
