# [Coarse-to-Fine: Learning Compact Discriminative Representation for   Single-Stage Image Retrieval](https://arxiv.org/abs/2308.04008)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question addressed in this paper is: How can we design an efficient single-stage image retrieval framework that achieves both high accuracy and efficiency without needing to perform additional re-ranking using local features?The key points are:- The paper aims to develop a single-stage image retrieval framework that does not require expensive local feature re-ranking like two-stage methods. This makes it more efficient.- However, existing single-stage methods have weaker performance compared to two-stage methods. So the goal is to improve single-stage accuracy to match two-stage methods.- The proposed method tries to achieve this by jointly learning a compact yet discriminative global image representation in an end-to-end manner.- Specifically, the authors propose a Coarse-to-Fine framework with two components:    - A novel adaptive loss (MadaCos) to enhance intra-class compactness of features.    - A local feature matching module with hard negative sampling to improve inter-class distinctiveness.- By combining strengths of both global and local feature learning through this framework, the goal is to improve single-stage retrieval accuracy without compromising efficiency.In summary, the central hypothesis is that by jointly learning global representations enhanced with relevant local feature information in an end-to-end framework, they can improve single-stage retrieval accuracy to match two-stage methods while retaining efficiency. The proposed Coarse-to-Fine framework aims to achieve this goal.


## What is the main contribution of this paper?

The main contributions of this paper are:- Proposes a Coarse-to-Fine (CFCD) framework to learn compact and discriminative global image representations for efficient single-stage image retrieval. - Designed a novel adaptive softmax loss called MadaCos that dynamically tunes its scale and margin based on median target logits within each mini-batch to strengthen supervision and increase intra-class compactness.- Proposed to select prominent local descriptors from attention maps and introduced triplet loss with hard negative sampling to leverage fine-grained relations between matches for improving inter-class distinctiveness.- Achieves state-of-the-art performance on single-stage image retrieval benchmarks like Revisited Oxford and Paris compared to previous global feature learning methods.- Does not require expensive local feature re-ranking during inference like two-stage methods, making it more efficient while achieving comparable accuracy.In summary, the main contribution is an end-to-end trainable coarse-to-fine framework with adaptive loss and local feature matching that learns compact and discriminative global features for efficient and accurate single-stage image retrieval.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key point from the paper:The paper proposes a Coarse-to-Fine framework to learn Compact Discriminative image representations for efficient single-stage image retrieval by dynamically tuning loss hyperparameters and selecting salient local features to refine the global descriptor.
