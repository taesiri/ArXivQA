# [Backpropagation Path Search On Adversarial Transferability](https://arxiv.org/abs/2308.07625)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we improve the transferability of adversarial attacks against black-box models by searching for optimal backpropagation paths? The key hypotheses are:1) Modifying the backpropagation path (e.g. adding skip connections) during adversarial attack generation can reduce overfitting to the surrogate model and improve transferability.2) Searching the space of possible backpropagation paths using Bayesian optimization can find better paths than heuristic or random search.3) Evaluating paths by their one-step attack success rate against a validation model is an effective approximation for finding the most transferable paths. To test these hypotheses, the authors propose:- SkipConv to add skip connections to convolution layers - A DAG search space combining skip connections for convolutions, activations, and residuals- Using Bayesian optimization to search this space based on one-step attack success against a validation modelThe overall framework is called PAS (backPropagation pAth Search) and aims to automate finding optimal backpropagation modifications to improve adversarial transferability in black-box attacks. The effectiveness of PAS is evaluated on ImageNet subsets against normally trained and robust models.In summary, the central research question is how to automatically search for optimal backpropagation paths to improve adversarial transferability, with the main hypotheses relating to using skip connections, Bayesian optimization, and one-step approximation. PAS is proposed as a framework to address this question.


## What is the main contribution of this paper?

Based on my understanding, the main contributions of this paper are:1. It proposes SkipConv, a method to adjust the backpropagation path of convolution modules by structural reparameterization. This allows modifying the gradient flow through convolutions to improve adversarial transferability. 2. It formulates the search for optimal backpropagation paths as a transferable backpropagation path search problem. It proposes a framework called PAS that uses Bayesian Optimization to search for optimal paths in a DAG-based search space.3. It constructs the search space by combining backpropagation paths of various modules like convolution, activation, and residuals. The paths are controlled using decay factors to explore different gradient flows.4. It uses a one-step approximation during the search to efficiently evaluate path transferability and reduce overhead.5. Experiments show PAS significantly improves attack success rates against both normally trained and defense models compared to prior art. The searched paths are highly transferable and generalize across different model architectures.In summary, the key novelty is formulating backpropagation path search as an optimization problem, constructing a flexible DAG-based search space, and efficiently searching for optimal paths using Bayesian Optimization and one-step approximation. This allows automatically finding highly transferable paths rather than manual heuristic design.
