# [Multi-metrics adaptively identifies backdoors in Federated learning](https://arxiv.org/abs/2303.06601)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is: how can we successfully leverage distance metrics to discriminate hostile updates from benign ones in order to defend against backdoor attacks in federated learning without sacrificing model performance? 

The authors identify two key limitations with existing distance-based defense methods:

1. Euclidean distance suffers from the "curse of dimensionality" and fails to discriminate between malicious and benign gradients in high-dimensional space. 

2. A single distance metric is insufficient since backdoor attacks have diverse characteristics and defenders have no knowledge of the underlying data distributions.

To address these limitations, the authors propose using multiple distance metrics (Manhattan, Euclidean, Cosine similarity) cooperatively with dynamic weighting to identify diverse types of malicious gradients. They aim to design an efficient defense that:

1) Is effective at identifying and eliminating malicious updates 

2) Preserves the benign performance of the global model

3) Is independent of specific attack strategies or data distributions

Through extensive experiments, they demonstrate that their multi-metric defense with dynamic weighting maintains high robustness and benign performance even against stealthy backdoor attacks that evade prior defenses.

In summary, the central hypothesis is that using multiple, adaptively weighted distance metrics will enable more successful discrimination of malicious updates to defend against diverse backdoor attacks in federated learning.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a novel defense method against backdoor attacks in federated learning using multi-metrics and dynamic weighting. 

2. It shows that Manhattan distance is more meaningful than Euclidean distance in high dimensions for discriminating between malicious and benign gradients.

3. It utilizes multiple metrics (Manhattan, Euclidean, Cosine similarity) cooperatively to identify diverse malicious gradients brought by different attacks and environments. 

4. It applies a whitening transformation and generates dynamic weights to handle non-IID data distributions and different scales of metrics.

5. Through comprehensive experiments, it demonstrates the effectiveness of the proposed method in maintaining high robustness while preserving benign performance, especially against stealthy backdoor attacks that evade prior defenses. 

6. The proposed defense is shown to be applicable under generic adversary models without assumptions on attack strategies or data distributions.

In summary, the key innovation is using multi-metrics with dynamic weighting to adaptively identify backdoors in federated learning. By introducing Manhattan distance and leveraging multiple metrics cooperatively, the defense becomes more effective against stealthy attacks and varying environments. The dynamic weighting also makes the defense robust under non-IID data.
