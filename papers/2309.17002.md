# [Understanding and Mitigating the Label Noise in Pre-training on   Downstream Tasks](https://arxiv.org/abs/2309.17002)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Pre-training large models on massive datasets and then fine-tuning them on downstream tasks is common practice in deep learning. However, pre-training datasets often contain label noise due to large-scale data collection and annotation. 
- It is important to understand how noise in pre-training data affects downstream performance, especially on out-of-distribution (OOD) tasks.
- Since pre-trained models are often large black-box models that cannot be easily updated or fine-tuned, we need light-weight methods to mitigate negative impacts of pre-training label noise.

Key Contributions:
- Empirically show that small amount of label noise (5-10%) in pre-training can help in-domain (ID) tasks but hurts OOD tasks. More noise consistently deteriorates OOD performance.
- Analyze feature spaces and find noise in pre-training leads to lower dominant singular values (worse transferability) but higher dimensional span (more noise fitting).
- Propose light-weight fine-tuning method called Noisy Model Tuning (NMTune) to reshape feature distribution using covariance regularization and dominant singular value maximization.
- Experiments on noisy ImageNet, YFCC and language models show NMTune mitigates negative impacts of pre-train noise and improves performance on both ID and OOD.

Main Novelty:
- First paper studying impact of label noise specifically in pre-training data on downstream tasks. Complements noisy label learning.  
- Analyze noise shaping of feature spaces through singular value spectrum.
- Black-box fine-tuning method to mitigate pre-train noise effects without full model access.

In summary, this paper opens the novel direction of "Noisy Model Learning" to understand and alleviate impacts of pre-training noise on downstream tasks through light-weight black-box fine-tuning.
