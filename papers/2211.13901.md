# [Learning Detailed Radiance Manifolds for High-Fidelity and 3D-Consistent   Portrait Synthesis from Monocular Image](https://arxiv.org/abs/2211.13901)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to achieve high-fidelity and 3D-consistent novel view synthesis of monocular portrait images via a single forward pass. 

The key hypothesis is that learning to extract 3D-consistent fine detail manifolds from the input image and combining them with coarse radiance manifolds obtained by inverting a 3D-aware GAN can enable high-quality and geometrically consistent portrait synthesis.

Specifically, the paper proposes a novel detail manifolds reconstructor to extract high-resolution detail manifolds from a input portrait that capture fine textures and details not represented in the coarse radiance manifolds. By combining the detail manifolds with the coarse radiance manifolds and leveraging 3D priors from the latter to regularize the former, the method can generate novel views of the input portrait with both high fidelity and strong 3D consistency.

The main goal is to achieve efficient, high-quality, and 3D-consistent novel view synthesis from a single monocular portrait image input using a 3D-aware GAN inversion approach. The key idea is to reconstruct both coarse radiance manifolds and fine detail manifolds from the input image in a way that preserves 3D consistency for novel view rendering.
