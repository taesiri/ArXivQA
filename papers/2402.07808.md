# [Sourcerer: Sample-based Maximum Entropy Source Distribution Estimation](https://arxiv.org/abs/2402.07808)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Scientific modeling applications often require estimating a distribution of parameters (called a "source distribution") that is consistent with an empirical dataset of observations. However, this problem can be ill-posed since many different source distributions might produce the same distribution of model outputs when passed through the simulator. The paper proposes to resolve this by finding the maximum entropy source distribution, which is guaranteed to be unique. 

Proposed Solution:
The authors propose Sourcerer, a framework to estimate the maximum entropy source distribution given a set of observations. This is framed as a constrained optimization problem - maximize the entropy of the source distribution, subject to the constraint that passing samples from this source through the simulator matches the distribution of the observed data. 

Since this constraint only relies on samples, a distance metric between distributions of samples is used, specifically the Sliced Wasserstein distance. This allows application to simulators without tractable likelihoods. The constraint is incorporated via a penalty method, resulting in an unconstrained optimization objective that trades off between high entropy of the source and matching the observed data distribution.

To parameterize the source, the authors use neural network based samplers, which allows incorporating constraints and is more scalable than methods requiring tractable densities. The maximum entropy principle makes the problem well-posed and provides a unique solution.

Key Contributions:

- Propose to estimate the maximum entropy source distribution, which provides a principled, unique solution to the otherwise ill-posed problem

- Use a sample-based distance metric (Sliced Wasserstein) in the constraint - allows application to intractable simulators and likelihoods

- Demonstrate the approach on problems with high-dimensional observation spaces by backpropagating through differentiable simulators 

- Show that the approach can recover substantially higher entropy sources without compromising on accuracy of simulations

- Apply the method to a real dataset of neural recordings to infer source distributions of Hodgkin-Huxley model parameters

In summary, the paper provides a general framework for estimating unique, maximum entropy source distributions for parameters of scientific simulators given datasets of observations. Crucially, it removes restrictions on tractable likelihoods and scales to higher dimensions.
