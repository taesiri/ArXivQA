# [FiT: Flexible Vision Transformer for Diffusion Model](https://arxiv.org/abs/2402.12376)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Existing diffusion models like Diffusion Transformers (DiT) struggle to generate images at resolutions outside their trained domain. This stems from their inability to leverage images of varying resolutions during training, hindering adaptation to different token lengths or image dimensions. 

Proposed Solution: The paper introduces the Flexible Vision Transformer (FiT), adept at generating images at unrestricted resolutions and aspect ratios. 

Key Ideas:
1) Flexible training pipeline: FiT resizes high-resolution images to fit a max token length without cropping, preserving aspect ratios. This enables handling variable token lengths in a batch, facilitating resolution generalization.  

2) Network architecture changes: Adoption of 2D Rotary Positional Embeddings for better length generalization, replacing regular self-attention with masked self-attention to distinguish between real and padding tokens, and using Swish-Gated Linear Units in place of MLPs.

3) Inference process innovations: Customization of large language model token length extrapolation techniques like NTK-aware interpolation and YaRN for 2D embeddings. Proposal of VisionYaRN and VisionNTK that leverage decoupled 2D RoPE for better aspect ratio handling.

Key Results:
- FiT establishes state-of-the-art Fr√©chet Inception Distance across various resolutions and aspect ratios on ImageNet, significantly outperforming CNN and transformer baselines.

- Ablations validate architectural choices like 2D RoPE, SwiGLU units, and the flexible training pipeline.

- Resolution extrapolation experiments demonstrate FiT's strong generalization beyond trained resolutions, further enhanced by VisionYaRN and VisionNTK.

Main Contributions:
1) Novel perspective on images as variable-length token sequences for flexible resolution training.

2) Carefully adapted transformer architecture and training strategy for diffusion models. 

3) Customized inference techniques for arbitrary resolution and aspect ratio image generation.

In summary, the paper makes significant contributions towards flexible image generation via a tailored transformer architecture, training procedure and inference process. Experiments thoroughly demonstrate state-of-the-art performance.
