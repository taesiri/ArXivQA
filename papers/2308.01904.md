# [DETR Doesn't Need Multi-Scale or Locality Design](https://arxiv.org/abs/2308.01904)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central hypothesis appears to be that DETR does not inherently require complex multi-scale or locality designs, which have been commonly adopted in subsequent DETR variants. Specifically, the paper investigates whether a plain DETR architecture with a single-scale backbone and global cross-attention can achieve competitive performance compared to state-of-the-art DETR models by incorporating two simple improvements - box-to-pixel relative position bias and masked image modeling pre-training. 

The key hypothesis seems to be that with these two modifications, a plain DETR model can match or exceed the accuracy of more complex DETR architectures that employ multi-scale features and locality constraints. The experiments aim to validate that a simple, unmodified DETR is sufficient given these enhancements. Overall, the central goal is challenging the notion that explicit multi-scale and locality inductive biases are required for DETR to work well.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution seems to be an improved DETR (DEtection TRansformer) object detector that maintains a "plain" architecture without relying on multi-scale feature maps or explicit locality constraints like previous DETR variants. 

Specifically, the key contributions are:

- Proposing two simple but effective modifications to compensate for the lack of multi-scale feature maps and locality in a plain DETR:
    - Adding a box-to-pixel relative position bias (BoxRPB) term to the cross-attention to guide it to focus on relevant object regions.
    - Using masked image modeling (MIM) pre-training to learn representations with better localization ability.

- Showing that with these modifications and recent advances in training and problem formulation, the improved plain DETR achieves significant gains over the original DETR and is highly competitive with more complex state-of-the-art detectors.

- Demonstrating that the improved plain DETR achieves 63.9 AP on COCO using a Swin Transformer backbone, outperforming prior DETR variants with locality and multi-scale designs.

- Highlighting that effective detection is possible with a simple/plain decoder, hoping to inspire using generic decoders broadly rather than complex task-specific designs.

In summary, the key contribution is developing a competitively accurate object detector while preserving the generic and plain nature of the original DETR design, via simple but surprisingly effective BoxRPB and MIM pre-training modifications. This challenges the notion that strong performance requires complex multi-scale and locality mechanisms.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 The paper proposes an improved DETR (DEtection TRansformer) object detection model that maintains a "plain" architecture with a single-scale feature map and global cross-attention, without relying on multi-scale features or locality constraints like previous DETR variants. The key ideas are using a box-to-pixel relative position bias term in the cross-attention to focus on relevant areas, and masked image modeling pre-training to learn representations with fine localization ability. With these improvements, the "plain" DETR achieves accuracy competitive with state-of-the-art detectors that use more complex architectures.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other related work:

- This paper presents an improved object detector based on the DETR (DEtection TRansformer) framework. It aims to maintain a "plain" architecture without multi-scale features or local cross-attention that many other DETR variants use. In this sense, it is more similar to the original DETR paper that proposed a simpler end-to-end object detection approach.

- Most state-of-the-art DETR detectors like Deformable DETR and DINO-DETR have incorporated architectural inductive biases like multi-scale feature maps and locality constraints in the cross-attention layers. This paper argues for minimizing these biases and relying more on improvements in backbone pre-training like masked image modeling (MIM).

- The two main technical contributions are the box-to-pixel relative position bias (BoxRPB) module and the use of MIM pre-training. BoxRPB helps focus the cross-attention on relevant object regions. MIM pre-training provides features with better localization ability to compensate for the lack of multi-scale features.

- Compared to region-based detectors like Faster R-CNN that also leverage bounding box-based attention, this work uses a simpler global attention approach with the proposed BoxRPB rather than more complex region pooling or sampling mechanisms.

- The results demonstrate strong performance competitive with recent DETR detectors, while using a simpler single-scale architecture. This supports their argument that multi-scale features and local attention may not be as crucial with proper pre-training and the BoxRPB modulation.

Overall, the work makes a case for simplifying DETR detector design and relying more on advances in representation learning through pre-training. It opens up directions to build effective detectors with minimal architectural bias and task-specific customization on top of generic Transformer encoder-decoder models.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors are:

- Exploring other self-supervised pre-training methods besides masked image modeling (MIM) that can help learn powerful visual representations and enhance localization ability. The authors found MIM pre-training to be very impactful, but think there may be other pre-training approaches worth exploring as well.

- Applying the improved plain DETR framework to other vision tasks beyond object detection, such as semantic segmentation, instance segmentation, etc. The authors suggest their methodology could inspire using generic plain decoders for a wider range of problems.

- Developing more powerful large-scale foundation models for computer vision, similar to what has been done in NLP with models like BERT. The authors argue vision has focused more on task-specific components rather than foundation models.

- Simplifying the designs of task-specific heads across vision to have minimal inductive bias, as they aimed to do with the DETR decoder. This relates to the point above about focusing more on foundation models.

- Exploring whether the BoxRPN technique could be adapted to also help plain convolutional networks better handle multi-scale objects, not just Transformers.

- Generalizing the BoxRPN idea to model relative position biases between other types of inputs beyond just box-pixel pairs.

Those are some of the key future directions called out in the paper's conclusion and discussion. The overarching theme seems to be continuing to explore how to minimize inductive bias in vision systems and pre-train ever more powerful general visual representations.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper presents an improved DETR (DEtection TRansformer) object detector that maintains a "plain" architecture without relying on multi-scale features or locality constraints like previous leading DETR variants. The authors show that two simple techniques can compensate for the lack of these inductive biases: 1) Adding a box-to-pixel relative position bias (BoxRPB) term to the cross-attention formulation, which guides queries to attend to corresponding object regions while allowing encoding flexibility. 2) Using masked image modeling (MIM) to pre-train the backbone network, helping it learn representations with fine-grained localization ability. By combining these technologies with recent training improvements, the "plain" DETR achieves major gains over the original model and reaches 63.9 mAP accuracy on COCO using a Swin-L backbone, competitive with top detectors that use multi-scale features and regional designs. This demonstrates the potential for effective detection using a simple Transformer decoder with minimal architectural bias.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper presents an improved DETR (DEtection TRansformer) object detection model that maintains a simple "plain" architecture without complex inductive biases like multi-scale feature maps or constrained cross-attention. The authors show that two simple techniques can compensate for the lack of these biases and lead to strong performance: 1) A box-to-pixel relative position bias (BoxRPB) term is added to the cross-attention calculation to help guide queries to attend to the relevant object regions. 2) Pre-training the backbone network using masked image modeling (MIM) helps learn representations with better localization ability. 

Experiments demonstrate that these two techniques lead to significant improvements over the original plain DETR model, increasing accuracy by over 15 mAP on COCO object detection. The resulting detector achieves 63.9 mAP when using Swin Transformer backbones, competitive with more complex state-of-the-art detectors. The authors argue this shows specialized inductive biases like multi-scale features can be avoided by using techniques like BoxRPB and MIM pre-training. They hope this work will inspire more exploration of generic, plain architectures for vision tasks by shifting focus to developing better foundation models.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper presents an improved DETR (DEtection TRansformer) object detector that maintains a "plain" architecture without relying on multi-scale features or constrained cross-attention. The main advance is the addition of a box-to-pixel relative position bias (BoxRPB) term to the cross-attention module of the DETR decoder. This BoxRPB term encodes the geometric relationship between predicted bounding boxes and image pixels to guide the cross-attention to focus on relevant object regions. The BoxRPB is computed efficiently using an axial decomposition into separate x- and y-axis terms. The paper also shows that masked image modeling (MIM) pre-training of the backbone network is crucial for the plain DETR detector, helping the model learn fine-grained localization abilities that can compensate for the lack of multi-scale features. By combining the BoxRPB cross-attention and MIM pre-training with other recent training improvements, the paper demonstrates a plain DETR model that achieves very strong object detection performance on par with more complex region-based and multi-scale detectors.


## What problem or question is the paper addressing?

 Based on my reading, the key points of this paper are:

- The paper aims to improve upon the original DETR object detector while preserving its "plain" architecture. DETR uses a single-scale feature map and global cross-attention without locality constraints. But subsequent DETR variants reintroduced inductive biases like multi-scale features and locality that improved performance but deviated from the original "plain" design. 

- The paper investigates how to compensate for the lack of multi-scale features and locality in a plain DETR design. It proposes two main solutions:

1) Adding a box-to-pixel relative position bias (BoxRPB) term to the cross-attention to guide queries to attend to corresponding object regions. 

2) Using masked image modeling (MIM) pre-training for the backbone to learn representations with better localization ability.

- In experiments, adding BoxRPB and MIM pre-training lead to significant gains for a plain DETR, closing the gap with methods that use multi-scale features and locality. The improved plain DETR achieves competitive results on COCO object detection.

- The authors argue these results show powerful task-specific heads like DETR can be kept simple/plain like the decoder, while efforts should focus more on developing better general visual models. This is analogous to trends in NLP.

In summary, the key contribution is showing how to improve plain DETR to be competitive without sacrificing its simplicity and generality, by using BoxRPB attention and MIM pre-training. The authors aim to demonstrate the viability of simple/plain task-specific modules.
