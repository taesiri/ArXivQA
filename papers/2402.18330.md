# [Attention-Propagation Network for Egocentric Heatmap to 3D Pose Lifting](https://arxiv.org/abs/2402.18330)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Accurate 3D pose estimation from egocentric stereo camera views is challenging due to severe self-occlusion and obscured limbs. Prior methods use joint heatmaps - probabilistic 2D representations of the body pose, but converting these heatmaps to 3D pose remains inaccurate. The paper identifies two key problems: 1) Inefficient feature embedding from heatmaps, as CNN encoders fail to preserve correspondence between heatmaps and pose. They also don't capture long-range dependencies between joints. 2) Importance-agnostic 3D lifting, as obscurity of some joints adversely affects visible ones during decoding.

Proposed Solution:
The paper proposes EgoTAP - an egocentric transformer-attention propagation network, with two key components:

1) Grid ViT Heatmap Encoder: Arranges all heatmaps in a grid, splits them into patches and applies transformer encoders. This preserves patch-heatmap correspondence in output embeddings. Self-attention captures dependencies between distant joints. Experiments show this encoding allows precise heatmap reconstruction.  

2) Propagation Network: Propagates features from evident joints (like neck) to obscured ones using a tree hierarchy. It uses a Propagation Unit (PU) based on LSTMs to take parent state, relational features and child features as input to predict child pose. PU can forget parent features if child features are evident.

Together, these components lift an accurate 3D pose from noisy heatmaps in egocentric views.

Main Contributions:
- First egocentric pose estimation method using vision transformers for efficient encoding
- Propagation Network to leverage evident joints to predict obscured ones  
- Propagation Unit to control importance of propagated features
- State-of-the-art performance on stereo egocentric datasets, with 23.9% lower error than previous best method

The key novelty lies in effectively capturing long-range dependencies between joints using transformers and selectively propagating clear joint features using attention, to overcome challenges like occlusion faced in egocentric views.
