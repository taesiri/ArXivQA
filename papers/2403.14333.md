# [CFPL-FAS: Class Free Prompt Learning for Generalizable Face   Anti-spoofing](https://arxiv.org/abs/2403.14333)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Existing face anti-spoofing (FAS) methods have poor generalization performance to unseen domains due to overfitting on domain-specific distributions. Specifically, most methods rely on binary classification loss and domain labels for supervision, which could lead to distorted semantic feature structures. Therefore, developing a method that can learn generalized and semantic features for cross-domain FAS is an important challenge.

Method:
This paper proposes a novel framework called Class Free Prompt Learning (CFPL) that leverages language prompts for cross-domain generalization. Instead of manipulating visual features directly, CFPL generates textual prompts to adjust the classifier's weights, allowing broader semantic spaces. Specifically, two lightweight transformers called Content Q-Former (CQF) and Style Q-Former (SQF) are proposed to learn prompts conditioned on content and style features using learnable queries. The content prompt is optimized with a text supervision loss while the style prompt is diversified using feature statistic mixing. Finally, a prompt modulation function adjusts the visual features channel-wise using the learned textual prompts.

Contributions:
- First work to utilize textual prompts for cross-domain FAS, allowing adaptive adjustment of visual features.
- Novel lightweight CQF and SQF transformers to generate semantic prompts based on content and style.
- Text supervision and style diversification losses to optimize generalization of prompts.  
- Outperforms state-of-the-art methods substantially over multiple cross-domain protocols.

In summary, this paper pioneers a cross-domain FAS paradigm based on semantic prompts that achieves excellent generalization compared to existing domain alignment or disentangling approaches. The lightweight prompt learning approach is more flexible and opens possibilities for FAS with language models.
