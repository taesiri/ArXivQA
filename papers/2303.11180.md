# [Self-Correctable and Adaptable Inference for Generalizable Human Pose   Estimation](https://arxiv.org/abs/2303.11180)

## What is the central research question or hypothesis that this paper addresses?

 The central research question addressed in this paper is: 

How can we develop a deep learning model that can self-correct its predictions at test time in order to improve generalization performance, without requiring ground truth labels?

Specifically, the paper proposes a method called "Self-Correctable and Adaptable Inference (SCAI)" that enables a model to correct its own predictions at test time guided by a "self-referential feedback error."

The key ideas are:

- Introduce a Fitness Feedback Network (FFN) that maps the model's predictions back to the input domain and compares them to the original input.  This creates a self-referential feedback error that is highly correlated with the true prediction error, even without ground truth labels.

- Use this self-referential error to guide a Correction Network that can adjust the original predictions to be more accurate.

- Leverage the self-referential error as a loss function to fine-tune the Correction Network parameters at test time on each new sample, enabling continuous self-improvement.

In essence, the model learns to correct itself by using the input data as indirect supervision, without needing ground truth labels at test time. This allows it to adapt and improve generalization to new test distributions.

The effectiveness of SCAI is demonstrated for human pose estimation, where it significantly improves accuracy by correcting predictions for occluded/difficult joints. The self-correction mechanism is shown to enhance generalization compared to fixed models.

In summary, the key hypothesis is that models can self-improve at test time if guided by self-referential feedback derived from mapping predictions back to the input domain. This work proposes and verifies an implementation of this idea.
