# [Dissecting vocabulary biases datasets through statistical testing and   automated data augmentation for artifact mitigation in Natural Language   Inference](https://arxiv.org/abs/2312.08747)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper investigates dataset artifacts and bias mitigation strategies for natural language inference (NLI). Using the SNLI dataset, the authors first demonstrate the existence of artifacts by training an ELECTRA-based hypothesis-only model, which achieves surprisingly high accuracy of 69.37% without seeing the premises. They then uncover the source of these artifacts by proposing a novel statistical testing procedure on the vocabulary distribution in hypotheses, revealing significant associations between words (e.g. subjects like "people" and verbs like "sitting") and entailment labels that enable the hypothesis-only model's performance. To mitigate such biases, the authors automatically augment the training data using character and word-level perturbations from the nlpaug library, combining augmented data with original data to retrain models. Experiments show certain augmentations like word2vec similarity replacement reduce hypothesis-only model accuracy while improving overall model accuracy, demonstrating their effectiveness at enhancing performance and mitigating artifacts. Key contributions include artifact analysis via statistical testing and data augmentation strategies for bias mitigation in NLI.
