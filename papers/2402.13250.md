# [Video ReCap: Recursive Captioning of Hour-Long Videos](https://arxiv.org/abs/2402.13250)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Most video captioning models are designed for short video clips, but real-world videos are often much longer (minutes to hours) and have hierarchical structure spanning different temporal granularities (atomic actions, intermediate activities, long-term goals). 
- Existing models cannot efficiently process such long videos or capture the hierarchical structure. They also require large amounts of manually annotated data.

Proposed Solution:
- The paper proposes Video ReCap, a recursive video captioning model that can handle videos ranging from seconds to hours and generate captions at multiple hierarchy levels.

- It uses a recursive video-language architecture that utilizes sparsely sampled features and generated captions from previous hierarchies as inputs. This allows efficient computation and exploits synergy between hierarchies.

- It employs curriculum learning strategy that first trains on short clip captions, then medium segment descriptions, and finally long video summaries. This allows the model to gradually learn video hierarchy.

- It leverages large language models to generate additional pseudo ground truth captions to augment limited manual annotations.

Main Contributions:
- Proposes hierarchical video captioning task and Video ReCap, the first model for this task that can handle vastly different video lengths and capture hierarchical structure.

- Introduces Ego4D-HCap dataset with over 8K manually annotated long video summaries, building the first dataset for hierarchical video captioning.

- Video ReCap outperforms priors by a large margin on Ego4D-HCap across all hierarchy levels. It also boosts performance on downstream EgoSchema VideoQA task.

- The introduced benchmark and strong baseline model open up new research avenues in hierarchical video understanding.

In summary, the key innovation is a recursive model leveraging hierarchy, curriculum learning and language model supervision to understand complex structure of long real-world videos through multi-level captions.
