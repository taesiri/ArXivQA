# [No Prior Mask: Eliminate Redundant Action for Deep Reinforcement   Learning](https://arxiv.org/abs/2312.06258)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel redundant action filtering mechanism called No Prior Mask (NPM) to address the challenge of large action spaces in reinforcement learning. NPM eliminates redundant actions that have similar effects on state transitions without requiring any prior knowledge. It constructs a similarity factor by estimating the distance between state distributions induced by two actions using a modified inverse model, avoiding extensive computation. Theoretical analysis shows eliminating redundant actions based on this similarity factor has minimal impact on policy performance. The algorithm has two phases - first it trains the no prior mask consisting of the inverse model and N-value network, then it uses the mask to filter actions during policy optimization. Experiments across various domains with synthetic, combined, and state-dependent action redundancy demonstrate NPM's effectiveness. Unlike other methods, NPM scales to high-dimensional pixel inputs, transfers across tasks, and handles stochastic environments. The proposed unsupervised mechanism to uncover action space structure advances the applicability of reinforcement learning to real-world problems involving large action spaces.
