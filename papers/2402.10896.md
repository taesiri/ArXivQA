# [PaLM2-VAdapter: Progressively Aligned Language Model Makes a Strong   Vision-language Adapter](https://arxiv.org/abs/2402.10896)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Research on large vision-language models (LVLMs) has shifted to freezing the vision encoder and language model (LM) components and focusing on training an effective "adapter" to align representations across modalities. However, optimal adapter architecture and training strategy remain open questions. 

- Existing adapters like perceiver resampler show slow convergence and limited scalability when scaling up components.

Method: 
- Propose PaLM2-VAdapter which uses a tiny PaLM2 LM (~110M params) as the adapter via a progressive two-stage alignment strategy. 

- Stage 1: Finetune tiny PaLM2 as an LM decoder to generate captions from visual embeddings. 

- Stage 2: Add a lightweight 1-layer perceiver resampler before finetuned tiny PaLM2 and use as adapter between fixed vision encoder and larger frozen PaLM2 decoder.

Contributions:
- PaLM2-VAdapter shows faster convergence (3x), higher performance, and stronger scalability than perceiver resampler baseline when aligning same vision-LM pairs.

- Achieves SOTA or comparable results to models with far more parameters on image/video captioning and VQA tasks, using just 10-14% of other models' parameters. 

- Efficiency demonstrates effectiveness of proposed progressive alignment strategy and PaLM2-VAdapter for advancing large vision-language model research.
