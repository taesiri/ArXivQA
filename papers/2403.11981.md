# [Diffusion Denoising as a Certified Defense against Clean-label Poisoning](https://arxiv.org/abs/2403.11981)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Machine learning models are vulnerable to data poisoning attacks where an adversary injects malicious samples (poisons) into the training data to cause misclassification of a specific test input (target). 
- Recent "clean-label" attacks craft poisons by adding imperceptible perturbations to clean samples while keeping their original labels. This allows the attacks to evade defenses that rely on detecting statistical anomalies.  
- Existing defenses either provide loose guarantees impractical for real datasets, or rely on strong assumptions about attacker knowledge, leaving them vulnerable to adaptive attacks.

Proposed Solution:
- The authors propose using an off-the-shelf diffusion model to denoise the training data before model training. 
- They show theoretically this provides a certified defense against clean-label attacks bounded in l2 norm.
- Unlike prior certified defenses that alter model training, denoising is decoupled, allowing them to minimize accuracy loss via techniques like warm-starting and transfer learning.

Main Contributions:
- First practical certified defense against state-of-the-art clean-label attacks that provides non-trivial accuracy guarantees on CIFAR-10.
- Decoupling the certification and training processes allows minimizing the accuracy loss from certification.
- Extensive experiments show the defense renders 7 clean-label attacks ineffective, outperforming 6 prior defenses, with negligible impact on accuracy.
- Analysis exposes a gap between certified and practical attack success, motivating developing stronger attacks under this new certified threat model.

In summary, the paper presents an effective and practical certified defense against clean-label data poisoning by leveraging diffusion models to denoise the training data. The decoupling of certification and training also opens possibilities to further improve certified model accuracy.
