# [PointNorm: Dual Normalization is All You Need for Point Cloud Analysis](https://arxiv.org/abs/2207.06324)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is how to create an effective and efficient 3D point cloud analysis framework that addresses the irregularity of point clouds while eliminating the need for complex local and global feature extractors. The key hypotheses appear to be:1) Normalizing the grouped points and sampled points to each other after sampling-grouping operations can help address the irregularity of point clouds and make learning easier for subsequent layers. This is done through the proposed DualNorm module.2) Using local mean and global standard deviation in the normalization allows leveraging both local and global features while maintaining efficiency. 3) The overall framework, PointNorm, can achieve excellent accuracy and efficiency on point cloud analysis tasks like classification, part segmentation, and semantic segmentation without relying on sophisticated feature extraction modules.So in summary, the central goal is developing a simple yet accurate and efficient framework for point cloud analysis, with the key ideas being the DualNorm module for addressing irregularity and the use of local mean and global standard deviation for feature learning. The effectiveness of this approach is evaluated through experiments on various analysis tasks.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a new framework called PointNorm for point cloud analysis. The key idea is to use a DualNorm module consisting of Point Normalization and Reverse Point Normalization to address the irregularity of point clouds after sampling and grouping. 2. DualNorm uses local mean and global standard deviation in the normalization, allowing PointNorm to leverage both local and global features while maintaining efficient inference speed. This eliminates the need for sophisticated local and global feature extractors used in prior works.3. The paper provides analysis showing DualNorm can improve loss stability, gradient stability, and optimization landscape compared to not using normalization. 4. Experiments demonstrate PointNorm achieves state-of-the-art accuracy on point cloud classification benchmarks like ModelNet40 and ScanObjectNN. It also shows strong performance on part segmentation on ShapeNetPart and semantic segmentation on S3DIS.5. Ablation studies validate the design choices in PointNorm like using both point normalization and reverse point normalization, and using local mean with global standard deviation.In summary, the main contribution is the proposal of PointNorm along with the DualNorm module to eliminate complex feature extractors for point clouds while achieving excellent accuracy and efficiency. The simplicity yet strong performance of PointNorm is highlighted as a key advantage.
