# [Causal Bandits with General Causal Models and Interventions](https://arxiv.org/abs/2403.00233)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key aspects of the paper:

Problem Statement:
The paper studies sequential experimental design in causal Bayesian networks using interventions. It considers unknown structural causal models (SCMs) that belong to general function classes with arbitrary generalized soft interventions. The goal is to sequentially design interventions to optimize an unknown reward function. Specifically, the paper aims to analyze the cumulative regret, compared to the best fixed intervention in hindsight, for algorithms that sequentially select interventions. 

Proposed Solution:
The paper proposes a general causal bandit (GCB) algorithmic framework, consisting of an upper confidence bound (GCB-UCB) algorithm and a Thomson sampling (GCB-TS) algorithm. The algorithms rely on least squares estimates of the unknown SCMs and construct confidence sets for them. Interventions are selected to maximize the upper confidence bound (in GCB-UCB) or by sampling from posterior distributions (in GCB-TS) of the reward.

Main Contributions:

1. Provides regret analysis for GCB algorithms for general classes of unknown SCMs based on inherent complexity measures - eluder dimension and covering number. 

2. Establishes regret bounds that depend on graph parameters (maximum degree and longest path length) and have diminishing dependence on graph size.

3. Allows for arbitrary generalized soft interventions without restrictions on granularity of interventions.

4. Specializes and refines results for linear, polynomial and neural network SCMs. Provides matching lower bounds on regret.

5. Compares with existing literature and shows strictly better scaling with number of nodes and ability to guarantee sub-linear regret for broader function classes.

In summary, the paper provides a framework for causal bandits that is applicable to general unknown SCMs and interventions, provides end-to-end analysis of regret scaling, and demonstrates order-wise improvements over state of the art in a variety of problem configurations.
