# [Domain Incremental Lifelong Learning in an Open World](https://arxiv.org/abs/2305.06555)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: How can we build lifelong learning (LL) models that can continuously learn new tasks in an open world setting, where the model needs to handle samples from unseen tasks during testing? Specifically, the key hypotheses tested in this paper are:1. Using hierarchically organized prompts to capture knowledge at different granularities (global, format-level, task-level, instance-level) can help build effective LL models.2. Maintaining separate prompts to explicitly model unseen tasks, along with prompt keys to facilitate knowledge sharing, can improve the model's ability to generalize to unseen tasks. 3. Combining task-specific and instance-specific components allows the model to achieve both high LL performance and the ability to handle unseen tasks.The authors propose Diana, a dynamic architecture that uses soft prompts in a hierarchy to test these hypotheses. Diana is evaluated on two benchmark LL task sets and shown to outperform prior state-of-the-art methods, especially on unseen tasks. The central contribution is a new LL model design that can continuously learn in a more realistic open world setting.


## What is the main contribution of this paper?

Based on my understanding, the main contribution of this paper is proposing a new lifelong learning model called Diana for the domain incremental learning scenario. The key aspects are:1. Diana uses a hierarchical prompt structure with four types of prompts (general, format, task, and meta prompts) to capture knowledge at different granularities. 2. It introduces task prompt keys and meta prompt keys to facilitate knowledge sharing between tasks. The space of these keys is learned with distance-based losses.3. Diana allocates separate task prompts to explicitly model unseen tasks. This improves the model's ability to handle samples from unseen tasks.4. Extensive experiments show Diana outperforms state-of-the-art lifelong learning models, especially on unseen tasks. The ablation studies also demonstrate the effectiveness of the proposed components.In summary, the main novelty is using the hierarchical prompt structure and dedicated modeling of unseen tasks to achieve strong lifelong learning performance, especially on unseen tasks, in the domain incremental setting. The introduction of prompt keys for knowledge sharing is also a notable contribution.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper: The paper proposes Diana, a dynamic architecture-based lifelong learning model that uses hierarchically organized prompts to capture knowledge from different granularities, handles unseen tasks through dedicated prompts, and introduces prompt keys to facilitate knowledge sharing - achieving strong performance on benchmark NLP tasks.


## How does this paper compare to other research in the same field?

Here are a few key things to consider when comparing this paper to other related work in domain incremental lifelong learning:- This paper focuses specifically on the problem of domain incremental lifelong learning in an open world scenario. Many previous lifelong learning papers assume a closed world and only test on previously seen tasks. Testing on unseen tasks is more realistic but also more challenging. - The proposed model Diana uses a hierarchical prompt structure to capture task knowledge at different granularities. Other prompt-based lifelong learning methods like ProQA use prompts, but Diana's hierarchical design is novel. The combination of task prompts and instance prompts helps performance on both seen and unseen tasks.- Diana explicitly handles unseen tasks by allocating separate prompts to model unseen domains. Most prior lifelong learning work does not consider unseen tasks. The ability to detect and handle unseen tasks is important for real-world application.- Experiments show strong performance on benchmark datasets, outperforming prior state-of-the-art methods on seen and unseen tasks. The gains are especially notable on unseen tasks.- The code and data are released to facilitate reproducibility. This is an important contribution as lifelong learning research builds upon prior work.Overall, this paper makes excellent progress on an important problem - domain incremental lifelong learning in an open world. The hierarchical prompt design and explicit handling of unseen tasks help achieve strong results that advance the state-of-the-art. Releasing code/data also enables future work to build on these contributions.
