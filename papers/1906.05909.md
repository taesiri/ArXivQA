# [Stand-Alone Self-Attention in Vision Models](https://arxiv.org/abs/1906.05909)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Convolutional neural networks (CNNs) have become ubiquitous in computer vision, but they have difficulty capturing long-range dependencies due to their spatially confined receptive fields. Recent works have augmented CNNs with attention mechanisms to address this, but attention has not been explored as a standalone primitive for vision models.

Proposed Solution:
- Develop a local self-attention layer that attends to neighboring spatial locations in the image, allowing it to scale to large inputs.
- Construct a fully attentional vision model by simply replacing all spatial convolutions in a ResNet architecture with the proposed attention mechanism. This is done for both the main network trunk as well as the feature pyramid network and detection heads of a RetinaNet model for object detection.

Main Contributions:
- Show that a pure self-attention model achieves 1.2% higher ImageNet top-1 accuracy than a ResNet-50 baseline while using 29% fewer parameters and 12% fewer FLOPS. Similar performance gains are seen on COCO object detection where the attentional RetinaNet matches baseline mAP while requiring 39% fewer FLOPS.
- Perform ablation studies showing attention is very effective in later network layers compared to early layers. The proposed positional encoding method and spatially-aware attention stem are also critical components.
- Establish for the first time that self-attention alone can match or exceed the capabilities of convolution and enable models that are both parameter and computation efficient for core vision tasks. This makes stand-alone attention an important technique in the vision toolbox.

In summary, the paper shows self-attention can serve as an efficient alternative to convolution in CNNs. When used properly, it allows capturing long range dependencies that convolution struggles with. The proposed pure attentional networks outperform strong convolutional baselines on image classification and object detection.
