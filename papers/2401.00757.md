# [A &amp; B == B &amp; A: Triggering Logical Reasoning Failures in Large Language   Models](https://arxiv.org/abs/2401.00757)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Recent advancements in large language models (LLMs) have enabled breakthrough capabilities, including the ability to "reason". However, evaluating reasoning skills in LLMs remains challenging. Existing benchmarks focus on accuracy rather than directly assessing reasoning processes. Although some studies have developed metrics to evaluate reasoning, they suffer from data leakage or limited scope.  

Proposed Solution: This paper introduces LogicAsker, an automatic framework to evaluate and improve LLMs' formal reasoning abilities based on a comprehensive set of 30 atomic skills from propositional and predicate logic. LogicAsker systematically generates reasoning questions by converting logic expressions into natural language. It calculates LLM accuracy on each skill to identify weaknesses. The test cases can further construct demonstration examples to improve reasoning via in-context learning.

Main Contributions:
- Formally defines 30 atomic skills an LLM should have for formal reasoning based on fundamental logic systems 
- Develops LogicAsker to automatically generate test cases under these skills and provide insights into LLM capacities
- Empirically evaluates six widely used LLMs and demonstrates LogicAsker can effectively uncover reasoning failures from 25% to 94%
- Shows test cases from LogicAsker can improve LLM reasoning abilities through in-context learning (e.g. 10% for GPT-4)
- Releases all code, data and results to facilitate future research

In summary, this paper develops a comprehensive and automatic framework to evaluate and enhance formal reasoning skills in LLMs based on fundamental logic systems. Extensive experiments on major LLMs demonstrate its ability to effectively identify weaknesses and improve reasoning performance.
