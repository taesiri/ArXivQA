# Call for Customized Conversation: Customized Conversation Grounding   Persona and Knowledge

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we develop conversational agents that can have more human-like, engaging, and knowledgeable dialogs by grounding their responses in both a user's persona (personal preferences and background) as well as factual knowledge?The key hypotheses appear to be:1) Current conversational agents and datasets have limitations in generating customized and knowledgeable responses, as they do not comprehensively consider both a user's persona as well as factual knowledge.2) By creating a new dialog dataset (FoCus) where responses incorporate both persona information and factual knowledge, and training models on this dataset, it will be possible to develop more customized and knowledgeable conversational agents.3) The conversational abilities of current state-of-the-art models can be evaluated through automatic metrics as well as proposed persona and knowledge grounding subtasks on the FoCus dataset. This will demonstrate the need for models that can better fuse persona and knowledge to generate human-like responses.4) Human evaluation of model responses on the FoCus dataset will further demonstrate the gap between current models and human performance in generating engaging, consistent, and customized dialog.In summary, the central hypothesis is that grounding conversational responses in both persona and knowledge is key to more human-like dialog agents, and the FoCus dataset and associated tasks and evaluations aim to demonstrate and address these limitations.


## What is the main contribution of this paper?

The main contribution of this paper is presenting a new dialog dataset called FoCus, which contains conversations with customized responses that incorporate both persona information and knowledge grounded in Wikipedia articles. Some key aspects of the FoCus dataset:- It contains 14,452 dialogs with 173,424 utterances, where the responses consider both the persona of the human speaker as well as factual knowledge retrieved from Wikipedia about geographical landmarks. - The dialogs involve an information-seeking task where the human asks questions about a landmark, and the machine provides informative and customized responses by utilizing the human's persona and Wikipedia knowledge about the landmark.- The responses are categorized into three types based on their intent: Inform (fact-based), Confirm (using persona), and Suggest (recommending based on persona).- Baseline generative models like GPT-2 and BART are trained on the dataset and evaluated both on generation fluency/accuracy as well as grounding abilities through proposed persona grounding and knowledge grounding subtasks.- Human evaluations are conducted to assess the naturalness and engagingness of model responses compared to human responses. The models still fall short of human performance.In summary, the key contribution is creating a new dialog dataset that requires integrating both persona and knowledge to generate informative and customized responses, along with benchmarking state-of-the-art models on it. This can enable building more intelligent conversational agents that can provide customized and knowledgeable responses.
