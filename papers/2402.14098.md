# [Intriguing Properties of Modern GANs](https://arxiv.org/abs/2402.14098)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
Modern GANs are able to generate highly realistic and diverse images, leading to the common belief that they accurately capture the true data distribution and manifold. This paper challenges this assumption by empirically analyzing whether GANs learn the true data distribution. 

Methods:
The authors evaluate GANs from two perspectives:

1) As manifold learning methods: They test if the learned manifold passes through real training examples by reconstructing images through GAN inversion. They also check if the manifold can be used for classification and outlier detection. 

2) As density estimators: By adding Gaussian observation noise, they estimate the likelihood GANs assign to real and fake images using annealed importance sampling (AIS). They compute the entropy and typical set to check if training images are typical samples under the GAN.

Key Findings:

1) The learned manifold does not pass through training examples and fails at classification/outlier detection, performing worse than a 1-nearest neighbor baseline. The inversion works well for fake images but not real ones.

2) The GAN density model assigns higher likelihood to out-of-distribution images than real images. The likelihood is anticorrelated with local variance in images, showing a bias for "flatter" images.

3) Training images have lower likelihood than fake images and fall outside the typical set of images under the GAN distribution. This shows GANs do not learn the true data distribution.

Main Conclusions:
Despite their ability to generate realistic images, GANs do not accurately capture the true data manifold and distribution. The assumptions that GANs learn the data distribution and manifold are shown to be false through empirical evaluation from both density estimation and manifold learning perspectives. The findings suggest GAN generations should not be blindly trusted as coming from the true data distribution.
