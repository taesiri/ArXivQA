# [Are LLMs All You Need for Task-Oriented Dialogue?](https://arxiv.org/abs/2304.06556)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is:To what extent are large language models (LLMs) capable of handling task-oriented dialogue modeling off-the-shelf, i.e. without finetuning?The authors raise this question in light of the recent popularity of chatbots built on top of instruction-finetuned LLMs like ChatGPT, which have shown impressive performance in open-domain conversations. However, it is unclear how well these models can perform on more structured task-oriented conversations that require handling external information sources like databases/APIs. To evaluate this, the authors introduce a pipeline for task-oriented dialogue that relies solely on prompting the LLMs, without any finetuning on in-domain data. They experiment with 5 LLMs on two dialogue datasets in both zero-shot and few-shot settings.The key hypothesis seems to be that while LLMs may struggle with explicit belief state tracking, their generation capabilities could allow successful task completion when provided with gold states, especially with few in-domain examples.
