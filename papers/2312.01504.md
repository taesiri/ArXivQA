# [Effectively Fine-tune to Improve Large Multimodal Models for Radiology   Report Generation](https://arxiv.org/abs/2312.01504)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Generating radiology reports from medical images is time-consuming for radiologists and error-prone for less experienced ones. Automating this via AI could be useful.
- Large language models (LLMs) have shown impressive text generation capabilities recently, but combining them with vision models is challenging due to LLMs' huge computational requirements. 

Proposed Solution:
- Use a lightweight network to map visual features from a pretrained vision model to the text embedding space of an LLM. The visual features act as "soft prompts" to condition the LLM to generate radiology reports.
- Propose a simple yet effective two-stage fine-tuning strategy: 
  1) Freeze vision model for 1 epoch to allow mapping network to align modalities
  2) Unfreeze vision model to fine-tune all components

Main Contributions:
- Demonstrate the efficacy of using LLMs with lightweight mapping network and visual soft prompts for radiology report generation
- Propose two-stage fine-tuning strategy that improves clinical accuracy of generated reports
- Analysis reveals two-stage fine-tuning better preserves pretrained visual features
- Best model with 7B-parameter LLM matches state-of-the-art without requiring additional domain-specific pretraining
- Analysis of attention weights and similarities reveals challenges in scaling to even larger LLMs - they seem to rely less on visual grounding

In summary, the paper explores a practical way to build multimodal models with LLMs for radiology report generation, validated by strong quantitative and qualitative results. The two-stage fine-tuning and analysis provide useful insights on training such models.
