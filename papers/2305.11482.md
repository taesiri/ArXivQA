# Enhancing Personalized Dialogue Generation with Contrastive Latent   Variables: Combining Sparse and Dense Persona

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to enhance personalized dialogue generation by combining the advantages of sparse and dense persona information. Specifically, the paper proposes a Contrastive Latent Variable-based model (CLV) to address the limitations of existing methods that use either sparse persona attributes, dense persona texts, or dialogue history for personalized dialogue generation. The key hypotheses are:1) Dense persona description texts can be clustered into sparse categories using a self-separation algorithm and contrastive learning, capturing different aspects of the persona. 2) A decider module can then automatically choose the most appropriate persona profile from these clustered categories to generate consistent and coherent responses.3) Jointly training the self-separation, decider, and generator modules enables the model to leverage both sparse and dense persona information effectively.4) This approach will outperform methods relying solely on sparse attributes, dense texts, or dialogue history for personalized response generation.In summary, the central hypothesis is that combining sparse and dense persona modeling through clustering, selection, and joint training will enhance consistency and coherence of personalized dialogue over existing approaches. The experiments aim to validate whether the proposed CLV model achieves superior performance.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a CLV model that combines the advantages of sparse and dense persona information for personalized dialogue generation. The key components are:- A self-separation mechanism that implicitly clusters the dense persona text into sparse persona categories. - A decider module that automatically decides whether and which persona profile to use during generation.2. A refined evaluation framework is proposed for personalized dialogue that considers consistency, coherence and diversity. 3. The model is evaluated on Chinese and English datasets and shows improved performance over strong baselines in terms of personalization, coherence and diversity. 4. Ablation studies validate the contribution of different components of the model. Case studies also provide some qualitative analysis.Overall, this paper presents a novel approach to integrate both sparse and dense persona information in an implicit way, without relying on explicit persona during inference. The joint training of the self-separation and decider module allows effective utilization of the dense persona text. The new evaluation framework also provides more comprehensive metrics for personalized dialogue.
