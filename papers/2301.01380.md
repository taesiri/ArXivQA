# [Ego-Only: Egocentric Action Detection without Exocentric Transferring](https://arxiv.org/abs/2301.01380)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question/hypothesis of this paper is whether effective action detection on egocentric (first-person) videos can be achieved without relying on transferring from exocentric (third-person) data. 

The key points are:

- Prior work has assumed that large-scale exocentric pretraining and transferring is necessary for good egocentric action detection, due to the lack of sufficient labeled egocentric data. 

- However, the authors argue that the large viewpoint differences between ego- and exocentric videos pose challenges that may not be easily addressed by just scaling up exocentric data/labels or designing better transfer techniques.

- They hypothesize that with recent advances like masked autoencoders and growth of egocentric datasets, it may be possible to train egocentric models effectively from scratch, without exocentric transferring.

- They propose a simple "Ego-Only" approach involving MAE pretraining and temporal segmentation fine-tuning only on egocentric data.

- Through experiments on major egocentric datasets, they demonstrate state-of-the-art performance without any exocentric supervision, validating that exocentric transfer may not be necessary.

In summary, the central hypothesis is that with proper techniques, egocentric action detection can achieve strong performance using ego-only data, without relying on exocentric transfer. The paper aims to revisit this assumption and demonstrate the possibilities of ego-only learning.
