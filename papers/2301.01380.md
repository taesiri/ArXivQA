# [Ego-Only: Egocentric Action Detection without Exocentric Transferring](https://arxiv.org/abs/2301.01380)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question/hypothesis of this paper is whether effective action detection on egocentric (first-person) videos can be achieved without relying on transferring from exocentric (third-person) data. 

The key points are:

- Prior work has assumed that large-scale exocentric pretraining and transferring is necessary for good egocentric action detection, due to the lack of sufficient labeled egocentric data. 

- However, the authors argue that the large viewpoint differences between ego- and exocentric videos pose challenges that may not be easily addressed by just scaling up exocentric data/labels or designing better transfer techniques.

- They hypothesize that with recent advances like masked autoencoders and growth of egocentric datasets, it may be possible to train egocentric models effectively from scratch, without exocentric transferring.

- They propose a simple "Ego-Only" approach involving MAE pretraining and temporal segmentation fine-tuning only on egocentric data.

- Through experiments on major egocentric datasets, they demonstrate state-of-the-art performance without any exocentric supervision, validating that exocentric transfer may not be necessary.

In summary, the central hypothesis is that with proper techniques, egocentric action detection can achieve strong performance using ego-only data, without relying on exocentric transfer. The paper aims to revisit this assumption and demonstrate the possibilities of ego-only learning.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes the first method (Ego-Only) that enables training egocentric action detection models without relying on any exocentric (third-person viewpoint) data or models. 

2. It shows that exocentric pretraining/transferring is not necessary to achieve state-of-the-art results on egocentric action detection datasets like Ego4D, EPIC-Kitchens-100, and Charades-Ego. The proposed Ego-Only method outperforms previous state-of-the-art approaches that use exocentric transferring.

3. It systematically studies and reveals several important factors for effectively training egocentric models without exocentric supervision, through extensive experiments and ablation studies. These factors include the importance of masked autoencoder pretraining, finetuning via temporal segmentation, modeling long-term context, scaling pretraining data, etc.

4. It sets new state-of-the-art results on egocentric action detection and recognition tasks on Ego4D, EPIC-Kitchens-100 and Charades-Ego datasets, demonstrating the effectiveness of the proposed Ego-Only approach.

In summary, the main contribution is proposing and showing the viability of a simple but effective Ego-Only framework for egocentric action detection that does not rely on any exocentric data or models, contrary to most prior works. The paper also provides useful insights into training egocentric models effectively.
