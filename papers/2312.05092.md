# [INSPECT: Intrinsic and Systematic Probing Evaluation for Code   Transformers](https://arxiv.org/abs/2312.05092)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper introduces a probing framework called INSPECT to evaluate the capabilities of pre-trained source code models. The authors defined 15 probing tasks covering syntactic, semantic, and structural characteristics of Java code to assess what intrinsic code properties are learned by models during pre-training. They evaluated 8 transformer-based source code models from the HuggingFace Model Hub, including CodeBERT, GraphCodeBERT, CodeT5, etc., against a BERT baseline not trained on code. The results show that while models perform well on syntactic and some semantic tasks, they struggle significantly on tasks requiring structural reasoning, even sophisticated models like GraphCodeBERT. CodeBERT and GraphCodeBERT were the top performers, likely due to their code-specific pre-training objectives, outperforming purely NLP-based objectives. Surprisingly, BERT was competitive or even outperformed source code models on some structural tasks. The study highlights opportunities for better encoding intrinsic structural characteristics in code models, and that care must be taken in choosing layers that encode relevant information. The extensible INSPECT framework automates probing so models can be systematically evaluated on their learned code knowledge.
