# [MoMask: Generative Masked Modeling of 3D Human Motions](https://arxiv.org/abs/2312.00063)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Existing methods for text-to-motion generation using vector quantization (VQ) of motions into discrete tokens face two key limitations: 1) The VQ process introduces quantization errors that limit motion quality. 2) Decoding the motion tokens sequentially in an autoregressive manner accumulates errors and is inefficient. 

Proposed Solution - MoMask:
1) Uses a hierarchical residual VQ (RVQ) scheme to represent motions with multi-layer discrete tokens, progressively reducing quantization errors:
   - Base layer tokens capture main motion information
   - Subsequent layers capture residual errors w.r.t previous layers
2) Two dedicated transformers:
   - Masked Transformer (M-Transformer): Predicts randomly masked base layer tokens conditioned on text input. Allows parallel decoding.
   - Residual Transformer (R-Transformer): Progressively predicts residual tokens in next layers conditioned on current layer tokens.

3) Training:
   - RVQ-VAE trained with reconstruction loss + codebook embedding loss
   - M-Transformer trained to predict masked base layer tokens
   - R-Transformer trained to predict randomly selected next layer residual tokens

4) Inference:
   - M-Transformer iteratively fills in base layer masked tokens
   - R-Transformer then predicts rest of residual tokens layer-by-layer

Main Contributions:
1) First masked modeling framework for text-to-motion generation
2) Hierarchical RVQ design and dedicated transformers for precise & efficient generation 
3) State-of-the-art text-to-motion generation performance on HumanML3D and KIT-ML datasets
4) Flexible framework that can also perform text-guided motion inpainting without fine-tuning

In summary, MoMask pushes state-of-the-art in text-driven motion generation through innovations in representing, modeling and decoding motions using principles of residual learning and masked modeling.
