# [Instruction Diversity Drives Generalization To Unseen Tasks](https://arxiv.org/abs/2402.10891)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Instruction tuning allows fine-tuning language models (LLMs) to perform real-world tasks by training them on instruction-output pairs. However, their practical success depends on generalization to unseen instructions not encountered during training. 
- It is unclear what factors in the training data enable models to generalize to novel instructions. Specifically, does more data per instruction or more diverse instructions matter more?

Proposed Solution:
- The authors systematically study generalization in a controlled symbolic task - string rewriting rules inspired by Turing-complete Markov algorithms. 
- This allows them to vary the number of training instructions and examples per instruction independently.
- They train LLM models from scratch and also fine-tune pretrained models on this symbolic task.

Key Contributions:
- Instruction diversity is the crucial factor enabling generalization, rather than more examples per instruction. Models generalize after seeing enough different instructions, even if each instruction has few examples.
- There is a sharp transition where generalization emerges once the number of training instructions crosses a threshold (~400 here).
- Diversity in instruction semantics also matters, not just number of instructions. Mixing different types of rewrite rules helps generalization.  
- Non-uniform distribution of examples hurts but sufficient instruction diversity provides robustness against skew.
- These symbolic experimental results also hold when fine-tuning pretrained language models.

In summary, the key insight is that instruction diversity drives generalization in instruction-following. This provides guidance for creating better datasets for real-world instruction tuning.
