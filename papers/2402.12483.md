# [Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions   Without the Question?](https://arxiv.org/abs/2402.12483)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Multiple-choice questions (MCQs) are commonly used to evaluate large language models (LLMs). It is important to verify that MCQ accuracy actually reflects the abilities we intend to measure in LLMs. 
- The paper investigates whether LLMs can exploit "artifacts" (biases or patterns) in MCQ dataset choices to answer questions correctly without needing the accompanying question text. If so, MCQ evaluations may overestimate LLM capabilities.

Method: 
- The paper tests "choices-only" prompts with 4 LLMs (LLaMA, Falcon, Mixtral, Phi) on 3 MCQ datasets (ARC, MMLU, HellaSwag). These prompts only provide the answer choices as input to see if choices alone contain enough signal.
- The choices-only accuracy is compared to majority class baselines. Accuracies substantially above the baseline suggest potential artifact exploitation. 
- To explain the artifact exploitation, the paper tests hypotheses around: 1) Memorization 2) Choice priors and dynamics 3) Abductive question inference.

Key Findings:
- In 11/12 cases, choices-only prompts significantly beat baseline, with over 0.3 accuracy gains. This suggests LLMs may use artifacts.
- There is little evidence memorization drives the high choices-only accuracy.
- LLMs seem to exploit interdependencies between choices, not just cues from individual choices.
- LLMs show an impressive partial ability to infer the original question from just the choices.  

Contributions:
- First paper to show LLMs can get high MCQ accuracy from just choices using few-shot prompting.
- Release an analysis toolkit to enable transparent MCQ evaluations.
- Find evidence that LLMs can both exploit artifacts but also show complex reasoning abilities when answering from limited context.
