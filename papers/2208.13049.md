# [TrojViT: Trojan Insertion in Vision Transformers](https://arxiv.org/abs/2208.13049)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How to perform an effective backdoor attack on Vision Transformers (ViTs) by generating Trojans that can force the model to misclassify inputs with a trigger to a target label, while maintaining high accuracy on clean inputs?

Specifically, the paper aims to develop a ViT-specific backdoor attack called TrojViT that can:

- Generate a stealthy patch-wise trigger optimized to hijack the attention of critical patches in ViTs. This is different from prior area-wise triggers designed for CNNs.

- Insert an efficient Trojan into a ViT model by flipping minimal bits of parameters using a tuned parameter distillation technique.

- Achieve high attack success rate on inputs with the trigger, while maintaining high clean data accuracy on benign inputs.

The central hypothesis is that by designing triggers and Trojan insertion tailored for ViTs, it is possible to launch more effective backdoor attacks on ViTs compared to naively applying CNN-based backdoor methods. The paper aims to demonstrate this through empirical evaluations of TrojViT.

In summary, the paper focuses on investigating backdoor attacks specifically catered to abuse the attention mechanism and patch-wise processing of Vision Transformers, in order to highlight the security vulnerabilities of ViTs against such attacks.
