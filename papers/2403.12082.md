# [The Boy Who Survived: Removing Harry Potter from an LLM is harder than   reported](https://arxiv.org/abs/2403.12082)

## Summarize the paper in one sentence.

 The paper reports on a small experiment showing that claims of effectively erasing an LLM's ability to generate Harry Potter content are overstated, with the model still producing Potter references in response to archetypal and phrase prompts.


## What is the main contribution of this paper?

 The main contribution of this paper is experimentally showing that the claim made in previous work by Eldan et al. that they had "effectively erase[d] the model's ability to generate or recall Harry Potter-related content" was overstated. Through a small set of experiments prompts designed to elicit Harry Potter references, the author demonstrates that the model still retains ability to generate Harry Potter-related content, including explicitly mentioning Harry Potter characters and plot elements in several cases. The paper argues this demonstrates remnants of the "targeted knowledge" that Eldan et al. claimed to have erased still persist in the model.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the LaTeX source code and content of the paper, some potential keywords or key terms associated with this paper include:

- Computation and Language (cs.CL)
- Artificial Intelligence (cs.AI) 
- Large language models (LLMs)
- Forgetting
- Targeted knowledge eradication
- Harry Potter
- Evaluation
- Anchoring effects
- Security analysis

The paper discusses experiments with eradicating targeted knowledge about Harry Potter from an LLM, evaluates claims made in previous work about the effectiveness of this approach, and touches on topics like anchoring effects and security analysis. So terms related to LLMs, Harry Potter, evaluation, and security seem most relevant as keywords. The author also includes \keywords marking Computation and Language as well as Artificial Intelligence as keywords.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. How robust and generalizable is the memory erasure process described in the paper? Does it work effectively for a wide range of facts and concepts, or does its effectiveness vary depending on the type of knowledge being erased?

2. The paper discusses remnants of the original knowledge persisting after the erasure process. What strategies could be used to further minimize these remnants and reduce vulnerabilities? 

3. How would the proposed erasure process handle synonyms, related concepts or literary allusions that could indirectly point to the erased knowledge? Can it effectively handle semantic ambiguity?  

4. Could residual remnants of erased knowledge re-emerge over time as the model is used operationally? If so, what safeguards are needed to prevent long-term recall issues?

5. What are the implications of the erasure process on the model's capabilities for other, non-erased domains of knowledge? Could erasure negatively impact recognition of facts and concepts in unrelated areas?

6. How efficient is the process computationally? What tradeoffs exist between the depth of knowledge erasure and computational resources required?

7. What formal verification methods could be applied to ensure completeness of erasure for sensitive knowledge domains? How can we build confidence that information has been fully eliminated?

8. Does the order or sequence of erased terms impact the effectiveness of the overall process? Should structured knowledge graphs guide erasure ordering?  

9. How does the technique extend to very large models (100B+ parameters)? Do massive models present unique challenges for precise knowledge removal at scale?

10. What policy and ethical factors need to be addressed regarding erasure of information from publicly released models? Who should determine what is appropriate for erasure and permanent deletion?
