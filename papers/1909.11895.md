# [Joint-task Self-supervised Learning for Temporal Correspondence](https://arxiv.org/abs/1909.11895)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central hypothesis is:Learning visual correspondence between frames in videos can be effectively achieved in a self-supervised manner by jointly addressing region-level and pixel-level matching through a shared inter-frame affinity matrix. The key ideas are:- Visual correspondence is fundamental for relating static images to dynamic video content. Prior work has focused on either region/object-level correspondence (e.g. tracking) or pixel-level matching (e.g. optical flow). - These two levels of correspondence can be modeled jointly using a single inter-frame affinity matrix that transforms features and traces pixel locations between frames.- Self-supervision signals like temporal coherence, cycle consistency, and energy preservation provide effective constraints, avoiding the need for manual annotations. - A joint model with region localization and fine-grained matching modules linked via the affinity matrix enables them to facilitate each other - localization reduces ambiguity for matching, while matching provides discriminative features for localization.So in summary, the main hypothesis is that jointly learning region and pixel correspondences in a self-supervised manner through a shared transformation model is more effective than tackling either task in isolation. The affinity matrix is key to enabling this joint learning process.


## What is the main contribution of this paper?

This paper proposes a self-supervised learning method to establish dense correspondences between video frames at both the region/object level and pixel level. The key contributions are:1. A joint learning framework with two modules - region localization and fine-grained matching that facilitate each other through a shared inter-frame affinity matrix.2. The affinity matrix supports both region localization and pixel matching in a shared manner. It is learned using self-supervision signals like temporal coherence, cycle consistency, and feature energy preservation that naturally exist in videos.3. The method outperforms state-of-the-art self-supervised correspondence learning techniques on various tasks like video segmentation, pose tracking, and object tracking. It even surpasses a fully supervised ResNet-18 model pre-trained on ImageNet for some tasks.In summary, the main contribution is a self-supervised joint learning approach to establish correspondences across video frames at both the region and pixel levels through a shared transformation model. The key is learning an affinity matrix using natural video constraints that supports both region tracking and pixel matching in a unified manner.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a self-supervised learning method that jointly tackles region-level and pixel-level correspondence learning across video frames through a shared inter-frame affinity matrix.
