# [Joint-task Self-supervised Learning for Temporal Correspondence](https://arxiv.org/abs/1909.11895)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central hypothesis is:Learning visual correspondence between frames in videos can be effectively achieved in a self-supervised manner by jointly addressing region-level and pixel-level matching through a shared inter-frame affinity matrix. The key ideas are:- Visual correspondence is fundamental for relating static images to dynamic video content. Prior work has focused on either region/object-level correspondence (e.g. tracking) or pixel-level matching (e.g. optical flow). - These two levels of correspondence can be modeled jointly using a single inter-frame affinity matrix that transforms features and traces pixel locations between frames.- Self-supervision signals like temporal coherence, cycle consistency, and energy preservation provide effective constraints, avoiding the need for manual annotations. - A joint model with region localization and fine-grained matching modules linked via the affinity matrix enables them to facilitate each other - localization reduces ambiguity for matching, while matching provides discriminative features for localization.So in summary, the main hypothesis is that jointly learning region and pixel correspondences in a self-supervised manner through a shared transformation model is more effective than tackling either task in isolation. The affinity matrix is key to enabling this joint learning process.
