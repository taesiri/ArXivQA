# [Achieving $\tilde{O}(1/Îµ)$ Sample Complexity for Constrained   Markov Decision Process](https://arxiv.org/abs/2402.16324)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
The paper studies the constrained Markov decision process (CMDP) in a reinforcement learning setting. CMDPs involve maximizing rewards while satisfying certain cost/safety constraints. The goal is to develop an efficient reinforcement learning algorithm to find a near-optimal policy with a small number of samples from an unknown environment. Prior algorithms have poor sample efficiency, requiring $O(1/\epsilon^2)$ samples. 

Proposed Solution:
The paper develops a new primal-space online linear programming approach. The CMDP is reformulated into an LP with occupancy measures representing policies. This LP is solved repeatedly in an online manner as samples are collected, adapting the LP constraints to the remaining resource capacities. A key novelty is an approach to identify a fixed optimal basis for the LP by sequentially discarding suboptimal actions and redundant constraints. The algorithm sticks to this basis when resolving the LP, avoiding non-degeneracy assumptions common in online LPs.  

Main Contributions:
- First algorithm for CMDPs achieving an $\tilde{O}(1/\epsilon)$ sample complexity, through a novel online LP framework. This matches MDP algorithms lacking resource constraints.

- Removes the non-degeneracy assumption required in prior online LPs to attain logarithmic regret, via the proposed technique to fix an optimal basis.

- Achieves problem-dependent regret bounds of $O(\log(N)/N)$ depending on LP parameters, despite having unknown transition probabilities. 

- The adaptive constraint update interpretation provides insights into why the algorithm attains logarithmic regret.

In summary, the paper pioneers a primal-space online LP view for CMDPs that attain significantly better sample efficiency compared to prior approaches. The algorithmic techniques to identify and maintain an optimal basis also advance online LPs.
