# [Robust Imitation Learning from Corrupted Demonstrations](https://arxiv.org/abs/2201.12594)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: Can the optimality assumption on expert demonstrations be weakened or even tolerate arbitrary outliers under offline imitation learning settings?The key hypothesis is that classical offline imitation learning approaches like Behavior Cloning fail when learning from corrupted or imperfect demonstrations containing outliers. To address this, the authors propose a novel algorithm called Robust Behavior Cloning that is robust to constant fraction of arbitrary outliers in the offline demonstration data.In summary, the main research question is about developing an offline imitation learning algorithm that is robust to imperfect, corrupted demonstrations with arbitrary outliers, without needing any extra environment interactions or human annotations. The proposed Robust Behavior Cloning algorithm aims to achieve this.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. They propose a novel algorithm called Robust Behavior Cloning (RBC) for offline imitation learning that is robust to corrupted demonstrations. The key idea is to use a median-of-means objective to minimize the negative log-likelihood instead of simply the empirical average. This makes the method resilient to outliers in the demonstration data.2. They provide theoretical guarantees for RBC showing that it can tolerate a constant fraction of arbitrary corruption in the demonstrations while still achieving nearly the same error rates and sample complexity as vanilla behavior cloning on expert demonstrations. 3. They validate the robustness and effectiveness of RBC empirically on several continuous control tasks. The experiments show RBC is much more resilient to corrupted demos than vanilla BC and achieves competitive performance compared to existing imitation learning methods without needing environment interaction.In summary, the main contribution is a simple yet robust algorithm for offline imitation learning that is provably resilient to corrupted demonstration data and is supported by both theory and experiments. The key novelty is using a median-of-means objective for robustness along with theoretical analysis bounding the error rates.
