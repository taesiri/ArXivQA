# [iVPT: Improving Task-relevant Information Sharing in Visual Prompt   Tuning by Cross-layer Dynamic Connection](https://arxiv.org/abs/2404.05207)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Recent progress has shown great potential of visual prompt tuning (VPT) in adapting pre-trained vision transformers to downstream tasks. However, most existing VPT solutions independently optimize prompts at each layer, neglecting the usage of task-relevant information encoded in prompt tokens across layers. Additionally, existing prompt structures are prone to interference from task-irrelevant noise in input images, harming the sharing of task-relevant information.

Proposed Solution:
This paper proposes a novel VPT approach called iVPT that improves task-relevant information sharing and flexibility of the attention process. The key components are:

1) Cross-layer dynamic connection (CDC): Dynamically aggregates and connects the input prompt tokens from adjacent layers to facilitate sharing of task-relevant information while avoiding image noise.

2) Dynamic aggregation (DA): Allows selective and flexible aggregation of information from prompts in the previous layer to prompts in the current layer.

3) Attentive reinforcement (AR): Identifies salient image regions based on attention weights and enhances those regions using additional prompt tokens to guide the model to focus on task-relevant areas.

Main Contributions:

1) Proposes the CDC and DA modules to improve sharing of task-relevant information between inter-layer prompts, with theoretical analysis on the benefits.

2) Designs the innovative AR module to identify and reinforce salient image regions without requiring external data or additional query processes. 

3) Achieves new state-of-the-art performance on 24 vision tasks, outperforming other prompt-based and PEFT methods, demonstrating effectiveness and generalizability.

In summary, the proposed iVPT approach advances the VPT framework by facilitating more effective sharing of task-relevant information and flexibility of the attention process to adapt pre-trained vision models to downstream tasks. The AR module provides further improvements by guiding the model to focus on salient areas. Superior results are achieved across multiple tasks and models.
