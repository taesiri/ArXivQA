# [Application-Agnostic Language Modeling for On-Device ASR](https://arxiv.org/abs/2305.09764)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is:How can we build a single neural network language model (NNLM) that serves both a virtual assistant (VA) application and a speech-to-text (STT) application equally well, while reducing model size compared to separate application-specific models?The key points are:- The paper aims to build a single NNLM that can serve two speech applications: a virtual assistant and speech-to-text. - Typically, separate application-specific models would be built for each application. However, this increases model size. - The goal is to build a single model that maintains the accuracy of the separate models, while reducing the overall model size.- The paper explores both data-driven and model architecture approaches to build this unified application-agnostic model.So in summary, the main research contribution is developing methods to train a single on-device NNLM that serves multiple applications as accurately as individual models but with a reduced memory footprint.
