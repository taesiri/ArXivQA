# [SDiT: Spiking Diffusion Model with Transformer](https://arxiv.org/abs/2402.11588)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Spiking neural networks (SNNs) are an emerging generation of neural networks with greater biological interpretability, event-driven properties, and lower power consumption compared to traditional artificial neural networks (ANNs). However, the application of SNNs for image generation tasks has been very limited. Existing SNN-based generative models like Spiking-GAN and FSVAE have not achieved results on par with ANNs. A unified and effective architecture for SNN-based generative models needs to be explored.  

Proposed Solution:
This paper proposes Spiking Diffusion Transformer (SDiT), a novel SNN diffusion model architecture that utilizes transformer to replace the commonly used U-net structure in mainstream diffusion models. The key components of SDiT include:

- Efficient self-attention mechanism called RWKV that has lower computational complexity compared to standard self-attention
- Reconstruction Module specially designed to supplement information lost after firing of spiking neurons, enhancing image reconstruction quality
- Skip connections between input blocks and output blocks similar to U-ViT architecture

The model takes an image through patch embedding and position embedding. The denoising timestep goes through time embedding. Multiple spiking transformer blocks with skip connections are used to process this input. Finally linear and convolutional layers output the predicted noise.

Main Contributions:

- First work to introduce transformer as the backbone for an SNN diffusion model, advancing SNN-based generative model research
- Achieves state-of-the-art results among existing SNN generative models on MNIST, Fashion-MNIST and competitive results on CIFAR-10
- Proposes efficient Reconstruction Module to compensate for information loss when complex self-attention is applied to sparse SNN representations 
- Empirically demonstrates the potential of SNNs for complex image generation tasks through a unified and effective model architecture

The proposed SDiT model sets a new baseline for SNN-based generative model research by demonstrating superior image generation capabilities compared to prior SNN methods.
