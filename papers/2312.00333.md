# [Green Edge AI: A Contemporary Survey](https://arxiv.org/abs/2312.00333)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Green Edge AI: A Contemporary Survey":

Problem:
Edge AI enables real-time intelligent applications by leveraging AI capabilities at the network edge near end-user devices (EUDs). However, edge AI faces significant energy challenges due to the resource-intensive nature of AI algorithms and the limited battery capacity at EUDs. Reducing energy consumption is crucial for sustainable edge AI deployment.  

Key Tasks of Edge AI:
The paper identifies three key energy-consuming tasks in edge AI systems: 
1) Data acquisition for centralized edge learning, where EUDs collect data to train models at edge servers.
2) Distributed edge model training, where EUDs cooperatively train models while keeping data localized. 
3) Edge model inference, where trained models make predictions on EUDs or edge servers.

Energy Consumption Breakdown: 
The energy consumption in edge AI systems is categorized into sensing energy, communication energy, and computation energy. Different configurations of sensing modules, communication technologies, and edge platforms impact the energy footprint.

General Design Principles:
Key principles for energy-efficient edge AI include:
1) Optimizing for energy efficiency rather than solely model accuracy.
2) Adapting system operations to dynamics such as changing environments and task states.  
3) Trading off model intelligence for greenness by eliminating unnecessary processing.

Energy-Efficient Data Acquisition:  
Strategies include adaptive sensing based on data redundancies, learning-aware data transmission prioritizing important samples, and leveraging data augmentation and transfer learning to improve model quality given limited acquired data.

Energy-Efficient Distributed Edge Training:
Approaches comprise gradient/model compression via quantization and sparsification, dynamic resource allocation, device/data selection, and knowledge distillation transferring knowledge from complex to simple models.

Energy-Efficient Edge Inference:
Methods entail model compression, neural architecture search, and input-adaptive inference for on-device paradigms. For edge server-based paradigms, joint communication-computation control and data preprocessing are effective. Emerging co-inference exploits both EUDs and edge resources.

Future Directions: 
Promising directions highlighted include integrated sensing and communication, hardware-software co-design, neuromorphic computing using spiking neural networks and compute-in-memory techniques, as well as green energy-powered edge AI leveraging renewable energy sources.

In summary, this paper provides a holistic examination of energy-efficient techniques spanning all critical facets of edge AI systems. The design principles and methodologies pave the way toward green and sustainable realizations of pervasive intelligence in next-generation networks.
