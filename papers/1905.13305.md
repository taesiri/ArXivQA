# [Countering Noisy Labels By Learning From Auxiliary Clean Labels](https://arxiv.org/abs/1905.13305)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research questions/hypotheses addressed in this paper are:1. Can learning from noisy labels be improved by leveraging auxiliary clean labels from self-supervised learning? 2. Can pseudo-labels in semi-supervised learning be treated as a type of noisy label and improved via self-supervision?3. Can a unified framework be developed that improves robustness to both synthetic noisy labels and pseudo-labels by exploiting rotation self-supervision?4. Does the proposed Rotational-Decoupling Consistency Regularization (RDCR) framework outperform existing state-of-the-art methods, especially under high noise levels?In summary, the central hypothesis is that noisy labels, including synthetic noise and pseudo-labels, can be countered by learning from auxiliary clean labels generated via self-supervision. The proposed RDCR framework integrates consistency regularization with self-supervised rotation predictions to decouple the model from noisy labels and enforce noise-tolerant representations. The key questions are whether this approach is effective for both types of noise and if it improves over current state-of-the-art methods. The experiments aim to demonstrate the superiority of RDCR, particularly under high noise levels.
