# [AlignTTS: Efficient Feed-Forward Text-to-Speech System without Explicit   Alignment](https://arxiv.org/abs/2003.01950)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to improve the speed and performance of text-to-speech (TTS) synthesis systems using a non-autoregressive feed-forward architecture. 

Specifically, the key points are:

- Proposing AlignTTS, a feed-forward network to generate mel-spectrograms in parallel for fast TTS.

- Using a duration predictor to align text to mel-spectrograms instead of attention mechanism. 

- Introducing an alignment loss to precisely learn text-to-mel alignments during training.

- Achieving state-of-the-art performance while being over 50x faster than real-time TTS on LJSpeech dataset.

In summary, the main hypothesis is that using a feed-forward Transformer combined with explicit alignment modeling can achieve both high-quality and very fast parallel TTS compared to autoregressive methods like Tacotron. The experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing AlignTTS, a feed-forward text-to-speech model that can generate mel-spectrograms in parallel for fast speech synthesis. 

2. Presenting an alignment loss to train AlignTTS to learn the alignment between text and mel-spectrograms. This produces more precise alignments compared to attention mechanisms in autoregressive models like Tacotron and Transformer TTS.

3. Achieving state-of-the-art speech synthesis quality that outperforms Transformer TTS on MOS scores, while being over 50x faster than real-time synthesis speed.

In summary, the key innovation is the alignment loss for directly learning text-to-mel alignments in a non-autoregressive feed-forward model like AlignTTS. This allows parallel mel-spectrogram generation for fast synthesis while still achieving high quality speech.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes AlignTTS, a fast and high-quality text-to-speech model based on a feed-forward transformer that learns alignments between text and mel-spectrograms using an alignment loss inspired by the Baum-Welch algorithm.
