# [Detecting Backdoors in Pre-trained Encoders](https://arxiv.org/abs/2303.15180)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: How can we detect backdoors in self-supervised learning image encoders without access to downstream task information or labels? 

The key ideas and contributions seem to be:

- Existing backdoor detection methods for supervised learning models cannot be directly applied to detect backdoors in self-supervised learning encoders, especially without access to downstream task data/labels. This is a gap the authors aim to address.

- The authors propose a new backdoor detection method called DECREE that directly scans encoders to identify backdoors. It does not require downstream task data or labels.

- DECREE inverts minimal triggers that cause high embedding similarity and uses the trigger size to identify backdoors. Backdoored encoders need smaller triggers to make clean samples have similar embeddings. 

- Extensive experiments on 444 encoders show DECREE effectively detects backdoors in common SSL attack settings like image-on-image, image-on-pair, and text-on-pair.

- DECREE is efficient and works even with no access to the encoder's pretraining data. It generalizes across different datasets, architectures, and attack settings.

So in summary, the key hypothesis is that backdoored SSL encoders can be detected by directly scanning for minimal triggers that cause high embedding similarity, without needing downstream labels or task data. The results support this hypothesis and demonstrate the effectiveness of the proposed DECREE method.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution seems to be proposing DECREE, the first backdoor detection approach for pre-trained encoders in self-supervised learning (SSL). The key ideas are:

- Directly scan encoders for backdoors without needing downstream task knowledge or classifiers. This overcomes limitations of prior detection methods like Neural Cleanse and ABS that rely on downstream classifiers.

- Introduce a new metric called Proportionate-L1 Norm (PL^1) to quantify the normalized size of inverted triggers from encoders. Triggers inverted from backdoored encoders tend to be smaller than those from clean encoders, allowing detection. 

- Formulate self-supervised trigger inversion as a constrained optimization problem to find a minimal trigger that causes high embedding similarity. This allows approximating the dense area in embedding space induced by backdoors.

- Evaluate on over 400 encoders under 3 SSL attack types (image-on-image, image-on-pair, text-on-pair). Show high detection accuracy even with limited or no access to pre-training data.

In summary, the main contribution is proposing the first direct backdoor detection method for SSL encoders, overcoming limitations of prior work tied to downstream tasks/classifiers. The introduced techniques like constrained trigger inversion and PL^1 metric allow effective scanning of encoders.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper provides LaTeX style guidelines and a template for submitting papers to the IEEE Computer Society Press for CVPR 2023, including instructions for formatting, page limits, incorporating figures and tables, handling references, final copy submission, and other requirements.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this paper compares to other related research:

- The paper proposes a new technique for detecting backdoors in pre-trained self-supervised learning image encoders. This is an important area of research as backdoor attacks could undermine the reliability of self-supervised learning systems used in real-world applications. The ability to directly scan encoders, without needing downstream tasks/labels, helps address limitations of prior work.

- Relative to prior work on backdoor detection for supervised learning models, this paper handles the unique challenges of self-supervised encoders where there are no explicit labels or classifiers. It introduces a novel trigger inversion method tailored for the self-supervised setting and a new metric called PL-Norm to identify potential backdoors based on inverted triggers. 

- Compared to the few existing studies on backdoor attacks for self-supervised encoders, this work focuses on the underexplored detection side. It evaluates against a wider range of backdoor attacks, including image-on-image, image-on-pair, and text-on-pair attacks. The experiments on large ImageNet and CLIP encoders also help demonstrate scalability.

- The proposed technique outperforms alternative approaches of scanning downstream classifiers using standard supervised learning detection methods. It does not require downstream task data/labels. The method also shows robustness when defenders have limited or no access to original pre-training data.

- Limitations are that it currently does not handle discrete text triggers and primarily focuses on patch-based image backdoors. The assumptions on threat model are also stricter than some other recent attacks like pervasive backdoors. But overall, the paper makes notable contributions advancing backdoor detection research for self-supervised learning.

In summary, the paper pushes forward the state-of-the-art in studying an important problem and shows promising results. It addresses limitations of prior art through innovations like the self-supervised trigger inversion and proportionate norm metric. There are still opportunities to handle more complex threats, but the work represents an important advance for this emerging area.
