# [Same Task, More Tokens: the Impact of Input Length on the Reasoning   Performance of Large Language Models](https://arxiv.org/abs/2402.14848)

## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is:

The paper introduces a new QA reasoning framework called FLenQA to assess the impact of input length on the reasoning capabilities of large language models (LLMs). Specifically:

- The paper evaluates LLMs on multiple versions of the same reasoning tasks, where each version is extended to different lengths with irrelevant "padding" text. This allows the study to isolate the effect of input length while keeping the reasoning tasks constant. 

- The study finds that LLMs show significant degradation in reasoning performance at much shorter input lengths than their maximum capacity. For example, accuracy drops from 0.92 to 0.68 on average when length increases to 3000 tokens.

- The paper analyzes different padding strategies (duplicate, similar, different) and locations of key information, but finds degradation across settings. This suggests the effect of length persists regardless of how reasoning tasks are embedded in longer contexts.

- The study also identifies several length-induced failure modes such as models not following instructions properly, exhibiting label bias, and declining coverage of key facts.

In summary, the key contribution is rigorously demonstrating that reasoning performance of LLMs decays rapidly as a function of input length, even though models claim to support longer texts technically. The analysis also provides insights into potential areas to address the weaknesses.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. How does the paper ensure that the reasoning tasks actually require drawing conclusions from multiple parts of the text, rather than being solvable from just one part? What specific techniques or dataset design choices enable this?

2. The paper introduces the concept of "key sentences" within "key paragraphs" that contain the necessary information to solve the reasoning tasks. What is the purpose of expanding these key sentences into full paragraphs? How does this connect to the desideratum of maintaining natural-looking inputs? 

3. When creating the length variations of each sample, what is the rationale behind the different types of "padding" text examined (duplicate, similar, different)? What does each one allow you to test about the impact of length on reasoning?

4. The paper finds that even duplicating the key paragraphs without modifying them leads to decreasing accuracy at longer lengths. Why is this result surprising? What implications does it have for our understanding of how length impacts reasoning?

5. How exactly does the paper control the location of the key paragraphs within the long input context? What is the motivation behind testing different positional configurations like adjacent, separated, beginning, end, etc.?

6. When using books corpus paragraphs as "different" padding, what steps are taken to ensure that they do not contradict or interfere with reasoning over the key paragraphs? How is ambiguity avoided?  

7. The paper introduces a simplified version of the RuleTaker task. What modifications were made compared to the original dataset? Why were these simplifications necessary for studying length effects?

8. How does the coverage metric allow the failure modes analysis to connect incomplete reasoning chains in CoT prompting with downstream incorrect answers? What specifically does this metric measure about CoT outputs?

9. For failure modes like "label bias" and "failure to answer", what could be some possible explanations for why these effects are exacerbated by longer input lengths? What hypotheses does the paper propose?

10. How do the identified failure modes provide "possible directions for future studies" to address deficiencies in LLMs? Can you propose some specific avenues that researchers could explore based on these failure mode analyses?
