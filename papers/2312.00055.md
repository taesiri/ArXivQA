# [LEAP: LLM-Generation of Egocentric Action Programs](https://arxiv.org/abs/2312.00055)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Representing complex human actions in a structured and compositional way is useful for applications like human-robot interaction, action understanding, and planning. However, existing structured action representations have limitations in capturing aspects like sub-actions, pre/post-conditions, control flows. 

Method - LEAP:
- Proposes a new formulation of "action programs" that represents human actions in a structured way with sub-actions, pre/post-conditions, and control flows. These action programs are centered on egocentric videos.

- Uses a large language model (LLM - GPT-4) to generate these action programs from videos. Since LLMs don't take video input, the method has 5 components to convert different video aspects into text descriptors that are fed as input to the LLM.

- Applies the method on a majority (87%) of EPIC Kitchens training set to generate a dataset of action programs. This dataset is publicly released.

- Uses the generated action program dataset to train action recognition and anticipation networks by adding additional loss terms to align predictions to ground truth programs.

Contributions:
- New formulation of structured action programs capturing sub-actions, conditions, control flows grounded in video
- Novel way of using LLM to generate these programs by fusing different video modalities
- State-of-the-art results on EPIC Kitchens leaderboard among RGB only methods
- First dataset of action program annotations on a majority of EPIC Kitchens training set

The key idea is using an LLM to generate structured and detailed action representations from video by converting different video modalities into text. The generated structured action programs are shown to improve performance on action understanding tasks.
