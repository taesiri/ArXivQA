# [Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D   Generation](https://arxiv.org/abs/2212.00774)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we take a pretrained 2D diffusion model and lift it to perform 3D generative modeling, without requiring any 3D training data?

The key ideas proposed to address this question are:

- Interpret diffusion models as learning a vector field of gradients (scores). Apply chain rule to propagate these scores through a differentiable renderer to get 3D gradients.

- Use a voxel radiance field as the 3D representation, which is fast to query and differentiable. Render multiview images and backpropagate 2D gradients into 3D. 

- Identify and address the out-of-distribution problem faced when evaluating the denoising diffusion model on rendered images, via a proposed perturbation and ensemble technique.

- Validate the approach by taking various pretrained 2D diffusion models like Stable Diffusion and converting them into 3D generative models, demonstrated via text-to-3D generation.

In summary, the core hypothesis is that by exploiting score functions and differentiable rendering, they can repurpose a 2D generative model for 3D modeling without any 3D training data. The experiments and results validate this hypothesis.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- Proposing a method (Score Jacobian Chaining) to convert a pretrained 2D diffusion generative model into a 3D generative model of radiance fields, without requiring any 3D training data. 

- Interpreting diffusion models as learned predictors of gradient fields (score functions). The proposed method applies chain rule on the estimated 2D image scores and backpropagates them through the Jacobian of a differentiable volumetric renderer to obtain a 3D score.

- Identifying the out-of-distribution issue when evaluating a denoising diffusion model on non-noisy rendered images from a 3D scene. The paper proposes a perturbation-based method called Perturb-and-Average Scoring to address this issue.

- Conducting experiments first on a 2D image canvas to validate the proposed Perturb-and-Average Scoring method. The results illustrate the challenges of using unconditioned diffusion models and the benefits of strong conditioning texts.

- Demonstrating the application of Score Jacobian Chaining for 3D text-conditioned generation using the pretrained Stable Diffusion model. The results showcase the generation of complex 3D shapes from text prompts.

- Providing analysis to justify the proposed Perturb-and-Average Scoring method and ablation studies to validate the effectiveness of the proposed regularization techniques.

In summary, the core contribution is a novel method to repurpose a pretrained 2D diffusion model for 3D generation by chaining and propagating the 2D gradients based on the model's score function. The other contributions provide supporting empirical validation, analysis, and evidence for this idea.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the main contribution in the paper:

The paper proposes a method to convert a pretrained 2D diffusion generative model into a 3D generative model of radiance fields by applying chain rule to propagate the 2D gradients estimated by the diffusion model through the Jacobian of a differentiable volumetric renderer.


## How does this paper compare to other research in the same field?

 Here is a brief analysis of how this paper compares to other related work in 3D generative modeling:

- The key idea of lifting a pretrained 2D diffusion model to generate 3D assets is quite novel. Most prior work trains 3D generative models from scratch using 3D supervision, whereas this paper aims to repurpose an existing 2D model. This is an interesting direction that could allow leveraging the rapidly improving 2D models for 3D tasks.

- Compared to other optimization-based 3D models that also utilize 2D guidance like CLIP, this paper uses proper generative models (diffusion models) which seem more suitable for optimization than CLIP. The samples here look more photorealistic than typical CLIP-guided approaches.

- The concurrent work DreamFusion shares a similar high-level approach but differs in some technical details like the formulation and handling of out-of-distribution inputs. Both methods demonstrate promising results.

- Compared to 2D-supervised 3D GANs, this optimization-based approach is slower but provides more control over the 3D structure during generation. The results here also seem higher quality than current GAN methods.

- The proposed method is limited to single object generation, whereas some GANs have tackled scenes. Extending this approach to scenes could be an interesting avenue for future work.

- Overall, the idea of chaining gradients of a 2D model through a renderer Jacobian is novel and powerful. The results demonstrate potential for leveraging 2D models for 3D. More work is needed to scale and refine the approach, but it outlines a promising research direction.

In summary, the key novelty is in "recycling" a 2D model for 3D generation via gradients. The results are compelling compared to prior 3D optimization works, though not yet on par with end-to-end 3D GANs. But the approach opens up intriguing possibilities for the future.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Exploring more sophisticated and flexible parameterizations for representing 3D assets, beyond voxel grids. The authors mention potential options like neural radiance fields and implicit surface representations. 

- Developing techniques to better handle matching between the distribution of rendered 2D images and the distribution modeled by the pretrained diffusion model. The out-of-distribution issue identified in the paper remains an open challenge.

- Experimenting with more advanced sampling techniques during the iterative 3D optimization process. The authors point out that using the score for gradient descent does not produce samples that match the quality of standard diffusion sampling. Developing better optimization algorithms tailored for this setup could lead to further improvements.

- Applying the proposed score chaining framework to other types of generative models beyond diffusion models, such as GANs. The general principle of propagating gradients through a renderer could potentially work with other generative modeling techniques.

- Reducing the computational costs associated with rendering and gradient computation to make the overall approach more scalable and efficient.

- Expanding the diversity and fidelity of 3D content that can be generated through richer text conditioning strategies. The authors note current limitations in handling more complex prompts.

- Addressing the need for 3D training data through self-supervised techniques over generated assets rather than relying solely on 2D supervision.

Overall, the paper proposes an interesting approach to repurposing 2D generative models for 3D generation and highlights many promising research avenues to further develop this direction.
