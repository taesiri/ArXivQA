# [The Shaped Transformer: Attention Models in the Infinite Depth-and-Width   Limit](https://arxiv.org/abs/2306.17759)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we theoretically characterize and stabilize the neural covariance of Transformer-type architectures like Softmax-based attention models in the proportional infinite depth-and-width limit?More specifically, the paper seems to address the following key points:- Derive a neural covariance SDE to characterize the output distribution of residual networks with skip connections and shaped ReLU activations in the proportional infinite depth-and-width limit.- Propose a "shaped attention" mechanism that modifies Softmax attention to be closer to the identity matrix. Derive the corresponding neural covariance SDE.  - Combine the SDE results to fully characterize the output distribution of the "shaped Transformer", i.e. Transformer-type architectures with the proposed modifications, in the proportional infinite depth-and-width limit.- Demonstrate how the proposed modifications help prevent rank collapse and degeneracy of the neural covariance compared to standard Transformer architectures. - Provide guidance on architecture design and hyperparameter tuning for stability based on the theoretical analysis.- Validate the theory with simulations and preliminary experiments showing the shaped Transformer is trainable in practice.So in summary, the central focus seems to be on developing a theoretical understanding of Transformers in the proportional limit in order to diagnose sources of instability, propose modifications, and derive guidance for architecture design and hyperparameter tuning. The shaped Transformer is proposed based on these theoretical insights.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Studying Transformers in the proportional infinite depth-and-width limit, where depth and width go to infinity with their ratio held constant. Previous work has studied MLPs in this limit, but the authors provide the first characterization for Transformer-type architectures. - Proposing a modified "shaped" attention mechanism that prevents the degeneracy of the neural covariance matrix. This involves perturbing the Softmax matrix to be close to identity and scaling the temperature parameter appropriately. - Deriving stochastic differential equations (SDEs) that characterize the output distribution and neural covariance of the proposed shaped Transformer model in the proportional limit. This provides insight into the stability of the architecture.- Demonstrating through simulations that the SDE approximations are surprisingly accurate even for finite sized networks. - Providing preliminary experiments showing the proposed shaped Transformer can be trained effectively on language modeling tasks.In summary, the main contribution appears to be introducing modifications to the Transformer to allow analysis in the proportional infinite depth-and-width limit, deriving the corresponding SDEs, and showing this shaped Transformer is trainable and avoids instability issues like rank collapse. The theoretical analysis provides guidance on architecture design and hyperparameter settings.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in attention models and deep learning theory:- The paper provides one of the first theoretical characterizations of Transformers in the proportional infinite-depth-and-width limit. Previous work has mostly focused on other limits such as the NTK regime with infinite width but fixed depth. Studying the proportional limit allows the authors to better capture the stochasticity and randomness accumulated over layers in deep Transformers.- The paper proposes a novel "shaped attention" mechanism to stabilize the training of Transformer models. This is related to other recent work on shaping activation functions and initialization schemes to improve training, but the specific proposal for attention is novel.- The paper links rank collapse, a phenomenon observed empirically in Transformers, to the degeneracy of the neural covariance matrix. Making this connection allows the authors to leverage neural covariance SDEs to analyze the shaped attention mechanism. - By deriving an SDE to characterize the output distribution, the paper provides valuable theoretical guidance on hyperparameter selection, architecture design, and training procedures for deep Transformers. This is similar in spirit to other recent papers leveraging scaling limits for insight into deep network design.- The results complement another line of work like Stable ResNets that use skip connections to stabilize training. The paper shows skip connections alone are not sufficient for Transformers, and careful attention shaping is needed. The two stabilization techniques can be combined.- The paper focuses on characterizing the output distribution at initialization. An exciting future direction is extending the theory to study training dynamics as well, building on recent progress in analyzing neural network training in various scaling regimes.Overall, the paper makes several novel contributions, especially around the shaped attention mechanism and the neural covariance SDE analysis. It provides new theoretical insight into deep Transformers and directions for improving training stability. The results nicely combine and build on multiple threads of research in deep learning theory.
