# [Causal discovery from conditionally stationary time-series](https://arxiv.org/abs/2110.06257)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the key research question seems to be: How can we perform causal discovery from non-stationary time series data, where the underlying causal relationships change over time depending on some state variable? Specifically, the paper proposes a method called State-Dependent Causal Inference (SDCI) to address this problem. The key ideas are:- Model the data as a set of conditionally stationary time series, where the stationarity is conditioned on a categorical state variable. So the causal relationships can change depending on the state.- Propose a probabilistic deep learning approach to infer the state-dependent causal graph. This involves learning to infer the edge types between variables conditioned on the state, as well as modeling the dynamics.- Evaluate SDCI on two synthetic datasets with different types of state transitions, from independent states to states dependent on the time series dynamics.The main hypothesis seems to be that explicitly modeling the conditional stationarity via latent states can allow more accurate discovery of causal relationships in non-stationary time series, compared to prior methods that assume full stationarity. The experiments on synthetic data provide support for this hypothesis.In summary, the key research contribution is the SDCI method for causal discovery in conditionally stationary time series, and showing its effectiveness compared to prior stationary methods. The central hypothesis is that modeling non-stationarity via conditional states improves causal discovery.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing a new method called State-Dependent Causal Inference (SDCI) for causal discovery in time-series data where the dynamics and causal relationships change depending on an underlying state variable. - Formulating the problem of causal discovery in conditionally stationary time-series and modeling the stationarity as being conditioned on a categorical state variable.- Providing a probabilistic deep learning implementation of the SDCI method using ideas from variational autoencoders. The method involves inferring a causal summary graph conditioned on the state variable. - Evaluating the SDCI method on two different synthetic datasets with varying complexity in terms of system dynamics and observability of the state variable.- Showing through experiments that the SDCI method can effectively recover underlying causal relationships in non-stationary time-series data where the dynamics change according to a state variable. It outperforms a baseline method that assumes stationary dynamics.- Demonstrating the ability of SDCI to handle different scenarios in terms of the state variable, including observed states, hidden states, and states dependent on the dynamics. The method maintains decent performance even when the state transitions are complex.In summary, the main contribution appears to be proposing a way to perform causal discovery in a more general class of time-series data where the dynamics are not strictly stationary but conditioned on an underlying state variable. The SDCI method is shown to be effective at recovering causal relationships in such conditionally stationary data through synthetic experiments.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a deep learning method called State-Dependent Causal Inference (SDCI) for discovering causal relationships in time-series data where the underlying causal graph changes depending on a state variable.


## How does this paper compare to other research in the same field?

Based on my reading, here is a summary of how this paper compares to related work in causal discovery for time series data:- Overall approach: This paper presents a deep learning method for causal discovery from conditionally stationary time series. Many recent papers have explored deep learning for causal discovery, but most focus on i.i.d. data or simple time series with stationarity assumptions. This paper specifically tackles the more challenging problem of non-stationarity.- Handling non-stationarity: A key contribution is the idea of conditioning stationarity on an underlying state variable. This allows the method to model changes in the causal mechanisms over time. Other recent papers like Li et al. 2020 and Lowe et al. 2020 discover causal graphs under stationarity assumptions. - Method: The proposed SDCI method is based on variational inference, modeling the causal graph structure in the latent space of a VAE-like model. This is similar to other recent graph inference methods like Kipf et al. 2018. The difference is conditioning the latent graph on states.- Experiments: The experiments cover simulated physics datasets like linear message passing and spring systems. These are common benchmarks, though usually not with non-stationarity. The results show SDCI can accurately recover changing edge types.- Limitations: As the authors note, SNDCI currently relies on quite simplistic simulated data. Testing on more complex real-world time series would be an important next step. The method may also need to be extended to handle other issues like hidden confounders.In summary, this paper makes a nice contribution in tackling the under-studied problem of causal discovery under non-stationarity. It introduces the novel idea of conditional stationarity and demonstrates promising results on physics simulations. An important direction for future work is scaling up the complexity and realism of the experiments.
