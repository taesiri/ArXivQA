# [Causal discovery from conditionally stationary time-series](https://arxiv.org/abs/2110.06257)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the key research question seems to be: How can we perform causal discovery from non-stationary time series data, where the underlying causal relationships change over time depending on some state variable? Specifically, the paper proposes a method called State-Dependent Causal Inference (SDCI) to address this problem. The key ideas are:- Model the data as a set of conditionally stationary time series, where the stationarity is conditioned on a categorical state variable. So the causal relationships can change depending on the state.- Propose a probabilistic deep learning approach to infer the state-dependent causal graph. This involves learning to infer the edge types between variables conditioned on the state, as well as modeling the dynamics.- Evaluate SDCI on two synthetic datasets with different types of state transitions, from independent states to states dependent on the time series dynamics.The main hypothesis seems to be that explicitly modeling the conditional stationarity via latent states can allow more accurate discovery of causal relationships in non-stationary time series, compared to prior methods that assume full stationarity. The experiments on synthetic data provide support for this hypothesis.In summary, the key research contribution is the SDCI method for causal discovery in conditionally stationary time series, and showing its effectiveness compared to prior stationary methods. The central hypothesis is that modeling non-stationarity via conditional states improves causal discovery.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing a new method called State-Dependent Causal Inference (SDCI) for causal discovery in time-series data where the dynamics and causal relationships change depending on an underlying state variable. - Formulating the problem of causal discovery in conditionally stationary time-series and modeling the stationarity as being conditioned on a categorical state variable.- Providing a probabilistic deep learning implementation of the SDCI method using ideas from variational autoencoders. The method involves inferring a causal summary graph conditioned on the state variable. - Evaluating the SDCI method on two different synthetic datasets with varying complexity in terms of system dynamics and observability of the state variable.- Showing through experiments that the SDCI method can effectively recover underlying causal relationships in non-stationary time-series data where the dynamics change according to a state variable. It outperforms a baseline method that assumes stationary dynamics.- Demonstrating the ability of SDCI to handle different scenarios in terms of the state variable, including observed states, hidden states, and states dependent on the dynamics. The method maintains decent performance even when the state transitions are complex.In summary, the main contribution appears to be proposing a way to perform causal discovery in a more general class of time-series data where the dynamics are not strictly stationary but conditioned on an underlying state variable. The SDCI method is shown to be effective at recovering causal relationships in such conditionally stationary data through synthetic experiments.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a deep learning method called State-Dependent Causal Inference (SDCI) for discovering causal relationships in time-series data where the underlying causal graph changes depending on a state variable.


## How does this paper compare to other research in the same field?

Based on my reading, here is a summary of how this paper compares to related work in causal discovery for time series data:- Overall approach: This paper presents a deep learning method for causal discovery from conditionally stationary time series. Many recent papers have explored deep learning for causal discovery, but most focus on i.i.d. data or simple time series with stationarity assumptions. This paper specifically tackles the more challenging problem of non-stationarity.- Handling non-stationarity: A key contribution is the idea of conditioning stationarity on an underlying state variable. This allows the method to model changes in the causal mechanisms over time. Other recent papers like Li et al. 2020 and Lowe et al. 2020 discover causal graphs under stationarity assumptions. - Method: The proposed SDCI method is based on variational inference, modeling the causal graph structure in the latent space of a VAE-like model. This is similar to other recent graph inference methods like Kipf et al. 2018. The difference is conditioning the latent graph on states.- Experiments: The experiments cover simulated physics datasets like linear message passing and spring systems. These are common benchmarks, though usually not with non-stationarity. The results show SDCI can accurately recover changing edge types.- Limitations: As the authors note, SNDCI currently relies on quite simplistic simulated data. Testing on more complex real-world time series would be an important next step. The method may also need to be extended to handle other issues like hidden confounders.In summary, this paper makes a nice contribution in tackling the under-studied problem of causal discovery under non-stationarity. It introduces the novel idea of conditional stationarity and demonstrates promising results on physics simulations. An important direction for future work is scaling up the complexity and realism of the experiments.


## What future research directions do the authors suggest?

Based on my reading of the paper, some key future research directions suggested by the authors include:- Investigating why SDCI-Temporal does not achieve the same performance as SDCI-Static. The paper indicates that the temporal aggregation design may be the reason SDCI-Temporal performs worse, so the authors suggest exploring different temporal aggregation schemes like attentive pooling or average pooling to improve SDCI-Temporal.- Providing evidence for the hypothesized performance gap when increasing the number of states in the spring data experiments. The paper hypothesizes this gap is due to fewer timesteps per state, so validating this claim through additional experiments is suggested.- Extending the method to allow for hidden state variables with more complex transition schemes like being event-dependent. The current formulation only handles hidden states with transitions based on direct observations.- Applying the method to more realistic scenarios like sports, surveillance, or social interaction data. The main goal is applying this to video data, so testing on real-world video datasets is an important next step. - Adding a visual front-end for processing video data as a pre-processing step before the causal graph inference. This could involve detecting objects, humans, poses, etc. to enable applying the method to real video data.- Enabling inference of completely hidden state variables in an unsupervised manner to decompose general non-stationary time series data. The current method assumes at least partial observability of states.- Considering higher-order Markov assumptions beyond the simplified first-order assumption made in this work. The real-world may require modeling longer-term dependencies.So in summary, the key suggestions are around improving the temporal modeling, validating assumptions on the simulated data, extending the method to more complex scenarios with less state observability, applying the approach to real-world video data, and relaxing simplifying assumptions like the first-order Markov property.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper proposes a probabilistic deep learning method called State-Dependent Causal Inference (SDCI) for causal discovery in time-series data where the dynamics change depending on an underlying state variable. The method models the data as conditionally stationary, where the stationarity is conditioned on the state. SDCI extracts a causal summary graph that describes the edge interactions conditioned on the state variable. The method is evaluated on two synthetic datasets, one with linear dynamics and one with spring particle systems. Results show SDCI can accurately recover the causal graph structure even when the underlying state transitions are complex or unobserved. The method outperforms baseline approaches that assume stationary dynamics. Overall, the paper presents a novel approach to causal discovery that can handle non-stationary time-series data by conditioning stationarity on state variables. Experiments demonstrate its effectiveness on synthetically generated data.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:This paper proposes a new method called State-Dependent Causal Inference (SDCI) for performing causal discovery from time-series data where the dynamics depend on an underlying state variable. Causal discovery involves inferring cause-effect relationships from observational data, which is an inherent but challenging capability of human cognition. Most previous approaches for causal discovery consider constrained scenarios with stationary time-series data. In contrast, the authors address the more general case of conditionally stationary time-series, where the dynamics and causal relationships change depending on the value of a state variable. The SDCI method extracts a causal graph conditioned on the state variable from the time-series data. It is evaluated on two synthetic datasets where the complexity and observability of the state variable are varied. The results demonstrate that SDCI can accurately recover the underlying state-dependent causal graph even when the state transitions are complex or the state is hidden. The authors highlight that this contribution is an initial step towards causal discovery in more realistic scenarios like video, where objects interact and behave differently over time. Potential future work includes adding a visual front-end for object detection and developing applications for scene understanding tasks.


## Summarize the main method used in the paper in one paragraph.

The main method presented in this paper is State-dependent Causal Inference (SDCI), which is proposed for performing causal discovery from conditionally stationary time-series data. The key idea is to model the non-stationarity in time-series data by conditioning the stationarity on an underlying categorical state variable. This state variable captures different regimes in the dynamics of the time-series. The method involves two main components: 1) Inferring a causal summary graph representing the edge types between variables for each value of the state variable. This is done using graph neural networks. 2) Modeling the dynamics by using the inferred causal graph to compute inter-object interactions and predict the evolution of the variables over time. The method is evaluated on two synthetic datasets with different types of state variable regimes: independent vs dependent on observations, and fully observed vs hidden. Results show it can accurately recover the ground truth causal graph and model dynamics, outperforming a baseline method that assumes stationary data.


## What problem or question is the paper addressing?

Based on my reading, this paper is addressing the problem of causal discovery from time-series data where the underlying dynamics are not stationary, but rather change depending on an unobserved state variable. Specifically, the paper proposes a method called State-Dependent Causal Inference (SDCI) to infer causal relationships between variables in conditionally stationary time series data, where stationarity is conditioned on a categorical state variable. The key questions and goals addressed in the paper are:- How can we perform causal discovery when the underlying dynamics and causal relationships change over time depending on some unobserved state? - Can we model conditional stationarity in time series by conditioning the dynamics on a categorical state variable?- Can we infer the latent causal graph structure between variables even when the state variable is unobserved or hidden?- How does modeling conditional stationarity compare with methods that assume stationarity in the data?To address these questions, the paper introduces the SDCI method and evaluates it on synthetic datasets where the dynamics change according to an underlying state variable. The results demonstrate SDCI's ability to uncover accurate causal graphs in these conditionally stationary timeseries, significantly outperforming methods that assume stationary dynamics.In summary, the key contribution is a novel method for causal discovery in non-stationary time series data by modeling dynamics conditioned on latent categorical state variables. The paper shows promising results on inferring accurate causal relationships from conditionally stationary data.
