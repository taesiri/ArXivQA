# [Neural Scene Chronology](https://arxiv.org/abs/2306.07970)

## What is the central research question or hypothesis that this paper addresses?

This paper addresses the problem of reconstructing time-varying 3D models of landmarks from Internet photos, with the goals of being able to render photo-realistic novel views with independent control of viewpoint, illumination, and time. The core hypotheses are:1. Different types of temporal changes in Internet photo collections, like illumination variation vs. changes to the underlying scene, are entangled together but need to be disentangled. 2. Scene-level changes tend to be discrete and sporadic over time rather than continuous.To address these challenges, the main technical contributions are:- A scene representation using a neural radiance field conditioned on per-image illumination embeddings and encoded time inputs. This disentangles illumination from scene changes.- A novel temporal encoding method based on step functions that can model abrupt, sporadic changes over time without overfitting to noise.So in summary, the paper aims to achieve high-quality view synthesis results for landmarks that change substantially over time, while disentangling different factors of variation like illumination and discrete scene changes. The core technical novelty is the step function encoding method for time.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a new method for chronology reconstruction, which aims to reconstruct a time-varying 3D model from internet photos of a landmark that has changed significantly over time. The model can render photo-realistic images with independent control of viewpoint, illumination, and time.2. It introduces a novel temporal encoding method based on step functions that can effectively model abrupt, sporadic scene content changes over time without overfitting to transient per-image factors like illumination.3. It collects a new dataset of four scenes with timestamped internet photos exhibiting various temporal changes, including billboards, graffiti art, and banners. This facilitates research on chronology reconstruction.4. Experiments demonstrate the method achieves state-of-the-art view synthesis results on the collected scenes and outperforms extensions of prior work. Detailed ablations validate the proposed step function encoding.In summary, the key contribution is a new neural scene representation and fitting procedure that can disentangle illumination and transient scene factors from longer-term content changes in internet photo collections. This enables high-quality rendering of scenes with independently controllable time and lighting. The step function encoding is critical to avoiding overfitting and enabling this disentanglement.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper proposes a new 4D scene representation and temporal encoding method that can reconstruct photo-realistic time-varying 3D models from Internet photos, with independent control over viewpoint, time, and illumination.
