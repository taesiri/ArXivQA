# [Make-Your-Anchor: A Diffusion-based 2D Avatar Generation Framework](https://arxiv.org/abs/2403.16510)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing methods for generating human videos from an image struggle to produce high-quality and temporally consistent results. The problem is ill-posed when conditioning only on a single image.

Proposed Solution:
- Formulate the problem as generating a video from an input video of a person. This is more well posed and practical for applications.

- Propose a "Make-Your-Anchor" system with two main components:
  1) Frame-wise Motion-to-Appearance Diffusion 
     - Uses a Structure-Guided Diffusion Model to generate each frame conditioned on a pose and reference appearance image.
     - Employs identity-specific face enhancement using inpainting to improve facial quality.
     - Uses a two-stage training strategy to learn general motion and identity-specific appearance.

  2) Batch-overlapped Temporal Denoising
     - Extends the frame-level model to video-level using 3D convolutions and cross-frame attention.  
     - Enables generation of arbitrary length videos through an overlapped batch inference algorithm.

Main Contributions:
- Formulates the problem more practically as generation from an input video rather than a single image.
- Proposes an end-to-end system with novel frame and video-level generation models for high-quality and consistent video synthesis.  
- Achieves control over both motion and identity-specific appearance within generated videos.
- Demonstrates the ability to produce videos of arbitrary lengths with temporal consistency.

In summary, the paper presents a complete system to generate personalized talking head videos by learning identity-specific appearance and gestures from an input video of that person. The technical novelty lies in the frame and video-level diffusion models tailored for this video generation task.
