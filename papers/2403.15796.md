# [Understanding Emergent Abilities of Language Models from the Loss   Perspective](https://arxiv.org/abs/2403.15796)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Recent studies have questioned the existence of "emergent abilities" in large language models, which are abilities that suddenly appear in larger models but not smaller ones. This skepticism arises from observations that: (1) smaller models can also exhibit high performance on these abilities when trained on sufficient data, and (2) the discontinuous metrics used to measure emergent abilities are questionable. 

- The relationship between a language model's pre-training loss and its performance on downstream tasks is not well understood. Existing work has focused on singular models or tasks. This paper aims to study emergent abilities from the perspective of pre-training loss rather than model size or compute.

Methodology 
- The authors pre-train over 30 language models from scratch with varying model sizes and data sizes, using a fixed corpus, tokenization and architecture. The models are evaluated on 12 diverse datasets covering different tasks, languages, prompting types and answer forms.

- They find a strong correlation between pre-training loss and downstream performance, regardless of model size or data size. Models with the same loss exhibit the same capabilities. This is further validated on the open LLaMA models which use a different pre-training framework.

- On certain "emergent" tasks, performance only improves from random guess levels when loss drops below a threshold, while performance on other tasks improves smoothly from the outset. This holds even with continuous evaluation metrics, refuting claims that emergent abilities arise from discontinuous metrics.

Contributions
- The paper proposes defining emergent abilities based on pre-training loss thresholds, rather than model size or compute. Abilities are "emergent" if only present in models below a certain loss threshold.

- This definition better captures tipping points in training trajectories where models acquire new abilities. The existence of emergent abilities means we cannot simply extrapolate from higher-loss models to predict capabilities at lower losses. Further scaling may unlock unforeseen abilities.

- The loss thresholds likely correspond to model size thresholds under scaling laws. But loss provides a unified training trajectory view and more precise characterization of emergent phenomena.
