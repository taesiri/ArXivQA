# [Aligning Diffusion Models by Optimizing Human Utility](https://arxiv.org/abs/2404.04465)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing methods for aligning text-to-image (T2I) diffusion models with human preferences require expensive paired preference data or complex reward models. This limits their scalability and applicability. 

Proposed Solution:
The paper proposes Diffusion-KTO, a novel framework to align T2I models using only per-image binary feedback signals (like/dislike). It formulates the alignment as maximizing the expected human utility of each image independently. This avoids needing pairwise preferences or a separate reward model.

Key Points:

- Extends the utility maximization framework used recently to align LLMs (KTO) to T2I diffusion models. Defines alignment loss based on human utility of each image.

- Explores different utility functions like loss-averse, risk-seeking and Prospect Theory's Kahneman-Tversky utility. Finds Kahneman-Tversky to work best empirically.

- Alignment loss applies to each denoising step separately. Avoids expensive sampling through full diffusion process needed by prior works. Enables efficient end-to-end fine-tuning.

- Trains Diffusion-KTO model using SD 1.5 on Pick-a-Pic dataset. Uses images labeled as preferred at least once as desired, rest as undesired. 

- Comprehensive evaluations show Diffusion-KTO generations better align with human preferences over SD 1.5 and also outperform current state-of-the-art Diffusion-DPO.

- Demonstrates Diffusion-KTO can align to arbitrary preferences using simple heuristics. Showcases customization to user preferences.

Main Contributions:

1) Generalizes utility maximization for alignment to diffusion models 

2) Enables fine-tuning on readily available per-image feedback

3) Surpasses alignment performance of existing preference-based methods

Let me know if you need any clarification or have additional questions!
