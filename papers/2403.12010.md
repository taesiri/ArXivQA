# [VideoMV: Consistent Multi-View Generation Based on Large Video   Generative Model](https://arxiv.org/abs/2403.12010)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Generating consistent and high-quality multi-view images from a single image or text prompt is very challenging. Prior works suffer from issues like multi-face janus problem, content drifting, lack of generalizability, and slow optimization process. The key challenges are - what data and models to use for pre-training that can learn strong multi-view consistency patterns, and how to enforce an underlying 3D model to improve multi-view consistency.

Proposed Solution - VideoMV:
1) Uses video generation models (like ModelScope T2V and I2VGen XL) pretrained on large-scale video data as the base model. Video data inherently captures multi-view consistency patterns better. Fine-tunes the video models on multi-view rendered images to get a multi-view generative model.

2) Proposes a novel 3D-aware denoising sampling strategy - employs a feedforward network to reconstruct an explicit 3D Gaussian model from the generated multi-view images. Renders this 3D model to get images, and uses them to guide the denoising sampling process of the generator. This further improves multi-view consistency.

Main Contributions:
1) Shows how to effectively build a multi-view generative model by fine-tuning large video generation models, to inherit their strong priors. Converges much faster than prior arts.

2) Introduces an explicit 3D-aware denoising sampling strategy to significantly enhance multi-view consistency over the base video generation model.

3) Experiments show state-of-the-art performance than prior works like MVDream, SyncDreamer etc. in terms of efficiency, visual quality, consistency metrics etc.

4) The reconstructed explicit 3D model can also be used for downstream tasks like novel view synthesis, 3D editing, neural rendering etc.

In summary, VideoMV makes important contributions in using self-supervised video priors for multi-view synthesis, and enforcing consistency via explicit 3D geometric guidance.
