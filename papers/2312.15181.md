# [Multilingual Bias Detection and Mitigation for Indian Languages](https://arxiv.org/abs/2312.15181)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Wikipedia aims to provide neutral and unbiased information, but often lacks diverse perspectives leading to neutrality bias. This exposes millions of readers to potentially inaccurate information.
- Prior work on detecting and mitigating neutrality bias focuses only on English Wikipedia. No solutions exist for Indian languages.

Proposed Solution:
- The paper contributes two new multilingual datasets - mWikiBias and mWNC covering 8 languages - for bias detection and mitigation tasks.
- For bias detection, Transformer encoder models like mDeBERTa are fine-tuned to classify sentences as biased or neutral. 
- For bias mitigation, Transformer encoder-decoder models like mT5 are fine-tuned to convert biased sentences to neutral versions in a style transfer setup.

Key Contributions:
- First work to study neural multilingual bias detection and mitigation for Indian languages
- mWikiBias and mWNC datasets with ~568K and ~78K sentences spanning 8 languages
- mDeBERTa outperforms other models for bias detection with 65.14% F1 score
- mT5 and mT0 achieve best bias mitigation performance with 85.82 and 79.70 Harmonic Mean scores.

In summary, the paper introduces the task of multilingual bias detection and mitigation for Indian languages, provides datasets to study these problems, and demonstrates strong baseline results using Transformer models like mDeBERTa, mT5 and mT0.
