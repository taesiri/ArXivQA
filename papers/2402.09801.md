# [EFUF: Efficient Fine-grained Unlearning Framework for Mitigating   Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2402.09801)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Multimodal large language models (MLLMs) are capable of understanding images and generating relevant text descriptions. However, they sometimes hallucinate nonexistent objects in the images, reducing reliability. Existing methods to mitigate hallucinations require expensive paired data and high computational resources during training.

Proposed Solution:
The paper proposes an Efficient Fine-grained Unlearning Framework (EFUF) to reduce hallucinations in MLLMs without needing paired data. 

Key ideas:
- Use CLIP similarity scores between image segments and object phrases to identify positive samples (non-hallucinated objects) and negative samples (hallucinated objects) from MLLM captions, instead of manual annotation.
- Apply unlearning via fine-grained positive and negative losses on object phrases to reduce hallucinations.
- Add sentence loss to retain caption quality.

Main Contributions:
- Adopt unlearning for first time to mitigate multimodal hallucinations. 
- Propose efficient framework EFUF to construct dataset and perform unlearning without needing expensive paired data.
- EFUF reduces hallucinations by average 12-16% across models, while improving caption quality metrics like BLEU, fluency. 
- Compatible with other hallucination reduction methods.
- Cost-effective, needing 3 GPU hours compared to 8-20 hours for other finetuning methods.

In summary, the paper makes multimodal hallucination reduction more affordable by using CLIP and unlearning based EFUF framework. The method is model-agnostic, efficient and improves both reliability and quality.
