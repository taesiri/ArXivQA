# LogicSolver: Towards Interpretable Math Word Problem Solving with   Logical Prompt-enhanced Learning

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is that incorporating logical reasoning into math word problem (MWP) solving models can make them more interpretable and accurate. The key points are:- Current MWP solving models rely on pattern matching and lack grounded mathematical reasoning, making them uninterpretable "black boxes". - The authors create a new MWP dataset called InterMWP that contains annotated logical formulas representing the reasoning steps for each problem. - They propose a model called LogicSolver that incorporates logical reasoning in two ways:   - Using a retriever to find relevant logic formulas to use as prompts when encoding the problem text.   - Training a module to generate explanatory logic formulas alongside the math expression solution.- Experiments show LogicSolver achieves higher accuracy than non-logic baselines, while also being more interpretable due to its ability to generate logical explanations.In summary, the central hypothesis is that incorporating logical reasoning into MWP solvers, both through prompting and explicit formula generation, can make the models more accurate and interpretable. The InterMWP dataset and LogicSolver model provide evidence to support this hypothesis.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It constructs a new dataset called InterMWP for interpretable math word problem solving. This dataset contains 11,495 math word problems, each annotated with interpretable logic formulas that represent the reasoning steps for solving the problem. 2. It proposes a new method called LogicSolver that incorporates mathematical logic knowledge into the solver through logical prompt-enhanced learning. This allows the model to jointly predict the solution expression and corresponding logic formulas to explain the reasoning process.3. Experiments show LogicSolver achieves higher accuracy than baselines on InterMWP while also producing logical formula interpretations. This demonstrates interpretability and accuracy can be improved together through logical prompt learning on the new InterMWP dataset.In summary, the key contributions are proposing a new interpretable math dataset, a logical prompt learning method to inject logic knowledge, and showing jointly improved accuracy and interpretability on this dataset. The interpretable annotations and logical prompt approach enable more explainable math word problem solving.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Unfortunately I am an AI system and do not have the capability to deeply comprehend and summarize academic papers. However, based on skimming the paper, it seems to be about developing an interpretable math word problem solving system by annotating a dataset with logic formulas and predicting them alongside the solution expressions. The key points appear to be:- Constructing a dataset called InterMWP with 11,495 math word problems annotated with interpretable logic formulas - Proposing a model called LogicSolver that incorporates logic knowledge through prompts to improve problem understanding and generate logic-based interpretations - LogicSolver achieves higher accuracy than baselines while producing logic-based explanations for its solutionsSo a very brief 1-sentence TL;DR could be: The paper develops an interpretable math word problem solver by annotating a dataset with logic formulas and training a model to generate them alongside solutions.
