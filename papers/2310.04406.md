# [Language Agent Tree Search Unifies Reasoning Acting and Planning in   Language Models](https://arxiv.org/abs/2310.04406)

## What is the central research question or hypothesis that this paper addresses?

 The central hypothesis of this paper is that unifying language model planning, acting, and reasoning capabilities can lead to enhanced performance on complex decision-making tasks. Specifically, the paper proposes the LATS (Language Agent Tree Search) framework to synergize the strengths of LLMs in these areas in order to create more capable autonomous agents. 

The key ideas are:

- LLMs have shown impressive capabilities in planning (e.g. chain of thought), acting (e.g. ReAct), and reasoning (e.g. answering questions) separately. 

- However, existing methods in each area have limitations - planning methods like chain of thought lack environmental feedback, acting methods like ReAct lack deliberation and adaptability, and reasoning methods often rely solely on internal knowledge.

- By bringing together planning, acting, and reasoning in the LATS framework through a search algorithm, environmental interaction, and self-reflection, the authors hypothesize they can create more flexible, sensible, and adaptable LLM agents.

- LATS repurposes LLMs as agents, evaluators, and optimizers through natural language interfaces, avoiding costly training while harnessing innate LM abilities.

So in summary, the central hypothesis is that by unifying planning, acting, and reasoning in LATS, the authors can create more capable LLM agents that overcome limitations of existing approaches. The paper aims to demonstrate this through experiments across diverse tasks.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is proposing LATS (Language Agent Tree Search), a new framework to improve decision-making and reasoning abilities of large language models. LATS unifies planning, acting, and reasoning for language models by:

- Using Monte Carlo tree search to deliberately construct trajectories from sampled actions, enabling more flexible problem-solving compared to reflexive prompting methods. The search is guided by heuristics generated by the language model itself.

- Incorporating external feedback from environments through observations to enhance model sensibility. It also uses self-reflection to enable the agent to learn from experience. 

- The framework is general and can be applied to diverse tasks like programming, question answering, and web navigation without needing additional training.

In summary, the key innovation is developing LATS as the first framework that synergizes planning, reasoning, and acting with language models and an environment for enhanced decision-making. This is demonstrated through strong experimental results across different domains compared to prior prompting techniques.
