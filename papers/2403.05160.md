# [MamMIL: Multiple Instance Learning for Whole Slide Images with State   Space Models](https://arxiv.org/abs/2403.05160)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Whole slide images (WSIs) contain billions of pixels, making it challenging to apply deep learning for computational pathology tasks like cancer diagnosis. Obtaining patch-level annotations is infeasible and feeding the entire WSI into models leads to GPU memory limitations.  
- Prior work uses multiple instance learning (MIL) to extract features from small patches (instances) of the WSI and aggregate them for slide-level prediction. But these methods either assume instances are independent, limiting performance, or use Transformer self-attention, which has quadratic complexity unsuitable for large number of instances.

Proposed Solution:
- Propose MamMIL, a MIL framework that uses the recent Mamba state space model (SSM) to efficiently model dependencies between instances in a WSI while keeping linear complexity.
- Mamba extended to model bidirectional dependencies between instances with a bidirectional SSM (Bi-SSM) block. A 2D context-aware block (2D-CAB) incorporated to retain 2D spatial relationships lost when representing WSI as 1D sequence input to SSM.
- Multiple MIL-SSM modules stacked, each contains Bi-SSM and 2D-CAB blocks. Instance features aggregated and class token used as bag feature for slide-level prediction.

Main Contributions:
- First work to introduce Mamba SSM for efficient long sequence modeling into MIL framework for computational pathology. Enables modeling inter-instance dependencies for better WSI classification.
- Propose innovations like Bi-SSM and 2D-CAB to adapt Mamba for bidirectional dependency modeling and 2D spatial context retention in WSI MIL task.
- Experiments show MamMIL achieves state-of-the-art performance while reducing GPU memory requirements compared to Transformer-based MIL alternatives.

In summary, the paper develops an efficient and high-performing MIL solution for WSI analysis by innovatively adapting the Mamba model to incorporate domain-specific inductive biases. The proposed MamMIL framework sets a new benchmark and direction for MIL research in computational pathology.
