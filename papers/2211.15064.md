# [High-fidelity Facial Avatar Reconstruction from Monocular Video with   Generative Priors](https://arxiv.org/abs/2211.15064)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the main research question addressed in this paper is how to reconstruct a high-fidelity 3D facial avatar from a monocular video. Specifically, the paper proposes a new method to leverage 3D-aware generative priors to model an animatable 3D head from a monocular video. The key ideas are:

1. Learning a personalized generative prior as a local and low-dimensional subspace in the latent space of a 3D-aware GAN (EG3D). This helps maintain personalized facial characteristics compared to inverting into the full GAN latent space. 

2. Efficiently learning the personalized subspace, comprised of a set of basis vectors and an encoder, from just a small set of images of an individual. 

3. After training, novel frames can be projected into the subspace for high-quality 3D consistent reconstruction. The framework also supports reenactment driven by various signals like 3DMM coefficients or audio by modifying the encoder.

4. Extensive experiments demonstrate superior performance over prior arts in tasks like novel view synthesis and face reenactment.

In summary, the main hypothesis is that using a personalized 3D-aware generative prior can enable high-fidelity facial avatar reconstruction and reenactment from just monocular videos, overcoming challenges like complex dynamics and missing 3D information. The proposed method and experiments aim to validate this hypothesis.
