# [RTHDet: Rotate Table Area and Head Detection in images](https://arxiv.org/abs/2402.03315)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Traditional models focus on detecting horizontal tables and cannot accurately detect rotated tables or locate their head/tail parts. This limits downstream table recognition tasks.

Proposed Solution:
- Introduce new task of detecting rotated tables and localizing their heads/tails.
- Propose TRR360D dataset using Adaptively Bounded Rotation on ICDAR2019MTD to generate rotated tables with head/tail annotations.  
- Propose R360 AP metric to evaluate rotated box detection and head/tail localization accuracy.
- Develop RTHDet model by adding Angle Loss (AL) branch to RTMDet-S to enable learning 360° rotation features to locate heads/tails. Further improve RTHDet via transfer learning and adaptive boundary rotation data augmentation.

Key Contributions:
- TRR360D dataset containing 840 images with 1446 rotated box annotations of tables with head/tail labels.
- R360 AP metric that incorporates angle constraints to assess rotating region detection and head/tail localization accuracy.
- RTHDet model that builds on RTMDet-S and adds AL branch to support 360° rotation learning. Improves AP50(T<90) from 23.7% to 88.7% compared to RTMDet-S baseline.

In summary, this paper introduced a new task, dataset, evaluation metric and method to advance the state-of-the-art in detecting rotated tables and localizing their head/tail parts. The high performance of RTHDet model demonstrates efficacy of proposed solutions. This research facilitates downstream table recognition applications.
