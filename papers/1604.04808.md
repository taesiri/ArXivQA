# [Learning Models for Actions and Person-Object Interactions with Transfer   to Question Answering](https://arxiv.org/abs/1604.04808)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes deep convolutional network models to predict human activity labels in images, achieving state-of-the-art performance on two datasets with hundreds of labels each. The models utilize both local features from person bounding boxes and global context from the whole image. Multiple instance learning is used to handle the lack of supervision at the person instance level. The models are then applied to visual question answering, specifically on activity and person-object relationship questions from the Madlibs dataset. Features from the specialized activity prediction models lead to improved VQA performance over generic ImageNet-trained features. The best results are obtained by combining predictions from models trained on two complementary datasets - HICO, which has labels for human-object interactions, and MPII, which has labels for person activities not involving objects. Qualitative analysis shows the predictions correlate well with correct answer choices. The approach demonstrates how transferring knowledge from expert models trained for specialized tasks can benefit visual question answering.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes convolutional network models that use local and global context to predict human activities in images, shows how multiple instance learning can handle weak supervision, demonstrates state-of-the-art performance on human activity datasets, and transfers learned features to improve accuracy on related visual question answering tasks.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1) Proposing deep convolutional network models that use local and global context to predict human activity labels in images. The models achieve state-of-the-art performance on two datasets with hundreds of activity labels (HICO and MPII).

2) Using multiple instance learning to handle the lack of supervision at the level of individual person instances in the HICO dataset. This allows the model to be trained with image-level labels only.

3) Showing how features from models trained on these specialized activity datasets can be transferred to improve accuracy on a visual question answering task (MadLibs). Specifically, improved performance is demonstrated on two types of questions about a person's activity and their relationship with objects.

In summary, the key contributions are advancing the state-of-the-art in human activity recognition using deep networks and weak supervision, and demonstrating how this can improve performance on a downstream visual question answering task by transferring learned features.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, the main keywords or key terms associated with this paper are:

- Activity Prediction
- Deep Networks
- Visual Question Answering
- Multiple Instance Learning 
- Person-Object Interactions
- Transfer Learning
- Contextual Modeling

The paper proposes deep convolutional network models for human activity prediction in images, using both local and global context. It employs multiple instance learning to handle weak supervision. The paper then shows how these specialized activity features can be transferred to improve performance on visual question answering, specifically on questions about a person's activity and relationships between a person and object. So the key terms reflect this focus on activity modeling, visual question answering, transfer learning, contextual modeling, etc. The authors themselves provide "Activity Prediction, Deep Networks, Visual Question Answering" as keywords for the paper.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes simple CNN models for predicting human activity labels. What are the key components of these CNN models and how do they fuse features from the person bounding box and global image context?

2. The paper uses Multiple Instance Learning (MIL) to handle the lack of supervision at the person instance-level. Explain how MIL is formulated in this context and how it helps assign labels to individual person instances during training.

3. Weighted loss is used to handle the highly unbalanced label distribution in the training sets. What is the intuition behind using weighted loss and how is it implemented in the paper?

4. How does the proposed network architecture differ from prior work like R*CNN and Scene-RCNN? What are some reasons the paper gives to explain why their model outperforms these methods?

5. On the MPII dataset, the paper shows improved performance when assuming the same label applies to all ground truth person instances. Why does this make sense and why does MIL lead to slightly worse performance in this case?

6. For visual question answering, both fc7 and class score features are extracted from the activity prediction networks. Why do the class score features work comparably or better than the higher dimensional fc7 features?

7. When answering the relationship questions in the VQA experiments, why are the object bounding boxes ignored? Would incorporating them lead to better performance?

8. The paper shows that combining specialized features from both HICO and MPII datasets leads to the best VQA performance. What is the intuition behind this and what unique benefits does MPII provide over HICO?

9. What are some common failure cases illustrated for the VQA task? How could the system be made more robust to these issues?

10. The paper focuses on using global image context. What are some ideas suggested in the conclusion for exploring more sophisticated contextual models in future work?
