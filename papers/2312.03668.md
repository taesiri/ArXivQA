# [An Integration of Pre-Trained Speech and Language Models for End-to-End   Speech Recognition](https://arxiv.org/abs/2312.03668)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of the paper:

This paper proposes a novel end-to-end automatic speech recognition (ASR) model by integrating two large-scale pre-trained models - the HuBERT speech representation model and the GPT language model. The model connects the output of HuBERT to the input of GPT via a convolution-based bridge network. This allows GPT to generate text tokens autoregressively conditioned on the speech representations from HuBERT, taking advantage of GPT's powerful language modeling capabilities for decoding. Experiments on Japanese ASR datasets show that the model, dubbed Nue-ASR, achieves comparable performance to modern ASR models based on transformers and conformer encoders without needing complex decoding methods like external language model fusion. Ablation studies determine the optimal model fine-tuning strategy and choice of bridge network. Further analysis demonstrates the model's capability for low-resource domain adaptation via parameter-efficient fine-tuning of the bridge network and GPT decoder. Key advantages of Nue-ASR are its simplicity, strong performance despite greedy decoding, and integration of updates from the rapid progress in language model research. Future work includes multitask learning across speech, language and vision modalities by building on top of such integrated pre-trained models.
