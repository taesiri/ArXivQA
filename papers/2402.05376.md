# [Zero-Shot Chain-of-Thought Reasoning Guided by Evolutionary Algorithms   in Large Language Models](https://arxiv.org/abs/2402.05376)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing zero-shot chain-of-thought (CoT) prompting methods in large language models (LLMs) use the same prompting across all instances of a task. However, due to the evolving nature of sentence prefixes during LLMs' pre-training, using identical CoT prompting for all instances may disrupt predictions and degrade performance. The paper aims to address this issue.  

Proposed Solution:
The paper proposes a novel zero-shot prompting method called "zero-shot EoT (Evolutionary Chain-of-Thought) prompting". The key idea is to leverage evolutionary algorithms to generate diverse CoT promptings tailored to each instance within a task. 

The process has the following main steps:
1) Initialize two CoT promptings 
2) Use LLMs as an evolutionary optimizer to perform crossover and mutation on the initialized promptings to generate a diverse set of new promptings
3) Enable LLMs to select the most suitable prompting for the current instance
4) Rewrite the instance using selected prompting to enhance LLMs' understanding  

Main Contributions:
- Proposes a new zero-shot prompting approach that generates tailored CoT promptings for each instance using evolutionary algorithms, improving reasoning performance
- Achieves state-of-the-art results across 10 reasoning tasks compared to previous zero-shot CoT methods 
- Demonstrates comparable performance to few-shot methods without needing manually selected examples
- Provides extensive analysis and experiments highlighting the approach's effectiveness and adaptability for reasoning tasks

In summary, the paper introduces an innovative evolutionary algorithm-based method to produce customized CoT promptings that enhance zero-shot reasoning in LLMs, outperforming existing zero-shot CoT prompting baselines and rivaling few-shot performance without example selection.
