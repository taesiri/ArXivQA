# [Enhancing Security of AI-Based Code Synthesis with GitHub Copilot via   Cheap and Efficient Prompt-Engineering](https://arxiv.org/abs/2403.12671)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
AI assistants for coding like GitHub Copilot are becoming more popular. However, there are concerns about the security of the code they generate, which limits their adoption. The paper reviews the literature and identifies three main approaches to improving code synthesis by AI: optimizing the output, fine-tuning the model, and optimizing the prompt. However, output optimization and model fine-tuning have limitations around requiring access to proprietary models, being computationally expensive, and needing expert security knowledge.  

Proposed Solution: 
The paper focuses on prompt optimization techniques which are fast, low-cost, generalizable, and don't require internal access to models. The authors propose and evaluate three specific prompt altering methods:

1. Scenario-specific: Provide warnings and info related to security risks based on expected functionality. Requires some expert security knowledge.

2. Iterative: Iteratively provide general security commentary to nudge the model. Requires no expert knowledge. 

3. General clause: Add an inception prompt about being a security specialist. Simple to implement but may not influence model.

The methods are orthogonal and could be combined. The authors demonstrate them on GitHub Copilot using real-world coding tasks from the OpenVPN project.

Main Contributions:

1. Review the literature and identify output optimization, model fine-tuning and prompt engineering as ways to improve AI code synthesis.

2. Propose a systematic prompt optimization approach with three concrete methods to enhance security of generated code without needing access to model internals.

3. Evaluate proposed methods on GitHub Copilot, showing a 8% increase in secure samples and 16% decrease in insecure samples compared to no prompt alterations.

The paper lays a foundation for future work on prompt-enhancement systems and evaluating the methods on more code synthesizers. Limitations are around the small dataset size and focusing only on GitHub Copilot.
