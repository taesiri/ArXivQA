# [EMQ: Evolving Training-free Proxies for Automated Mixed Precision   Quantization](https://arxiv.org/abs/2307.10554)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be:How can we efficiently and automatically search for training-free proxies to predict the performance of different bit-width configurations for mixed-precision quantization, without requiring extensive expert knowledge or trial-and-error tuning?The key hypothesis appears to be: By representing the search space of possible proxies as branched computation graphs and using an evolution algorithm with specialized techniques like diversity-prompting selection and compatibility screening, it is possible to automatically evolve high-quality proxies that strongly correlate with quantization accuracy.In summary, the central focus is on using an automated, training-free approach to discover effective proxies for mixed-precision quantization, rather than relying on hand-crafted heuristics. The authors propose a framework called EMQ to achieve this goal.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. The introduction of MQ-Bench-101, a new benchmark for evaluating training-free proxies for mixed-precision quantization. This benchmark contains 425 randomly sampled bit configurations and their quantization accuracies using post-training quantization on ResNet-18. 2. The proposal of the Evolving proxies for Mixed-precision Quantization (EMQ) framework, which uses an evolution algorithm to automatically search for effective training-free proxies for mixed-precision quantization. The framework involves an elaborate search space, a diversity-prompting selection strategy, and a compatibility screening protocol.3. Extensive experiments on ImageNet demonstrating that the proxy searched by EMQ outperforms existing training-free proxies like SNIP, Synflow, etc. in terms of rank correlation and quantization accuracy. The searched proxy also exhibits a strong positive correlation with quantization accuracy on MQ-Bench-101.4. Ablation studies validating the effectiveness of the proposed diversity-prompting selection strategy and compatibility screening protocol in improving the efficiency of the evolution search process.In summary, the key novelty of this work seems to be the introduction of an automated framework (EMQ) for searching high-quality training-free proxies for mixed-precision quantization, as demonstrated through comprehensive experiments and analyses. The MQ-Bench-101 is also presented as a new benchmark to facilitate further research in this direction.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other related research:- This paper focuses on evolving training-free proxies for automated mixed precision quantization (MQ), which is a relatively new area of research. Many previous works on MQ rely on time-consuming training-based methods like reinforcement learning or one-shot approaches. This paper explores improving the efficiency of MQ through evolving proxies.- The authors introduce a new benchmark called MQ-Bench-101 for evaluating MQ proxies. This contributes the first standard dataset for analyzing and comparing different proxies, advancing the field. Many previous works lacked a common benchmark.- The proposed EMQ framework for automatically searching proxies is novel. It uses evolutionary techniques like crossover and mutation to generate and evolve proxy candidates. This is a unique approach not explored before for automating proxy discovery in MQ.- Most prior training-free MQ methods used handcrafted proxies designed through expert knowledge and trial-and-error. EMQ removes the need for manual proxy design by automatically searching effective proxies. This increases the flexibility and generalizability of the training-free approach.- Experiments demonstrate EMQ can find high-quality proxies for both quantization-aware training and post-training quantization tasks. The discovered proxies consistently outperform previous handcrafted proxies like HAWQ, showing the efficacy of automated search.- EMQ advances the state-of-the-art in training-free MQ by increasing the accuracy and reducing the search cost compared to prior arts. The results validate the potential of evolving proxies to make MQ more efficient and accessible.In summary, this paper pushes training-free MQ in new directions through benchmarking, automated search via evolution, and outperforming prior handcrafted methods. The unique EMQ framework moves the field forward compared to previous works.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors are:- Developing more efficient search algorithms for mixed-precision quantization that can find good solutions with less computation. The authors mention evolutionary algorithms and reinforcement learning as promising approaches. Reducing the search cost would allow mixed-precision quantization to be applied to larger models.- Exploring different search spaces and proxy metrics beyond the ones evaluated in this paper. The authors propose some ideas like using second-order information from the Hessian, but there may be other effective proxies to try. Expanding the search space could lead to finding better quantization configurations.- Applying mixed-precision quantization to additional model architectures beyond ResNet and MobileNet. The authors show results on these standard models, but quantizing other modern network designs could be beneficial.- Testing mixed-precision quantization on larger datasets. The authors use ImageNet, but applying these methods to larger datasets like social media or scientific data could reveal new challenges.- Combining mixed-precision quantization with other compression techniques like pruning or knowledge distillation. The authors suggest this could provide further compression and speedup on top of quantization alone.- Implementing optimized libraries and hardware to actually realize speedups from mixed-precision networks. The theoretical gains need to be translated into real-world improvements on devices.Overall, the authors position mixed-precision quantization as a promising technique, but suggest significant work is still needed to fully develop it and apply it to diverse scenarios. Their proposed benchmarking and search techniques aim to move progress forward in this area.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:This paper proposes EMQ, a framework to automatically search for effective training-free proxies for mixed-precision quantization (MQ). The authors first develop MQ-Bench-101, a benchmark to evaluate MQ proxies, and find that existing handcrafted proxies exhibit limited predictive capabilities. To efficiently seek superior proxies, they propose an evolution algorithm-based framework called Evolving proxies for Mixed-precision Quantization (EMQ). EMQ employs a comprehensive search space encompassing existing MQ proxies and evolves candidate proxies based on their predictive ability on MQ-Bench-101. Key innovations include a diversity-prompting selection strategy to avoid premature convergence and a compatibility screening protocol to improve search efficiency. Experiments on ImageNet demonstrate EMQ obtains superior performance compared to state-of-the-art mixed-precision methods at a significantly reduced cost. The core ideas are to benchmark existing MQ proxies, formulate an extensive search space for proxies, evolve them using an efficient evolution algorithm, and demonstrate superior performance.
