# [How Robust Are Energy-Based Models Trained With Equilibrium Propagation?](https://arxiv.org/abs/2401.11543)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Deep neural networks (DNNs) are vulnerable to adversarial attacks - small, imperceptible perturbations to inputs that cause networks to misclassify. Adversarial training helps but reduces clean accuracy and is computationally expensive.  
- Biological vision systems are much more robust to noise and use abundant feedback connections, unlike feedforward DNNs. Feedback is thought to help inference from weak/noisy inputs.

Proposed Solution:
- Use energy-based models (EBMs) trained with equilibrium propagation (EP) which have feedback connections and settle into equilibrium states. This recurrent, deep attractor architecture is hypothesized to make them naturally robust.

Contributions:
- First investigation of robustness of EBMs/EP-CNNs to adversarial attacks and natural corruptions.
- On CIFAR-10 and CIFAR-100, EP-CNNs match or exceed robustness of adversarially trained CNNs on white-box, black-box, and natural noise, without sacrificing clean accuracy or needing adversarial training.
- EP-CNNs significantly outperform CNNs and ViTs on natural corruptions. Adversarially trained CNNs fail catastrophically on natural noise. 
- Adversarial examples on EP-CNNs appear more semantically meaningful than those on other models, indicating they learn useful features.

Overall, EP-CNNs solve major problems like poor robustness and efficiency in DNNs through an elegant biologically-inspired framework, with comparable accuracy and robustness to state-of-the-art models without needing extensive data or adversarial training.


## Summarize the paper in one sentence.

 This paper investigates the robustness of energy-based models trained with equilibrium propagation to adversarial attacks and image corruptions, finding they are more robust than standard deep neural networks and as robust as adversarially-trained models without losing accuracy on clean images.


## What is the main contribution of this paper?

 Based on my understanding, the main contribution of this paper is:

The authors perform the first investigation into the robustness of energy-based models (EBMs) trained with equilibrium propagation (EP), which they refer to as EP-CNNs, to adversarial attacks and natural perturbations. They demonstrate that:

1) EP-CNNs are significantly more robust than standard CNNs and vision transformers (ViTs) to both white-box and black-box adversarial attacks as well as natural perturbations, without sacrificing accuracy on clean images or requiring adversarial training.

2) EP-CNNs display comparable robustness to adversarially-trained CNNs on gradient-based attacks, query-based attacks, and natural perturbations. However, unlike adversarially-trained CNNs, EP-CNNs do not suffer from reduced accuracy on clean images.

3) Adversarial attacks on EP-CNNs appear more semantically meaningful compared to those on standard CNNs, adversarially-trained CNNs, and ViTs. This indicates that EP-CNNs may learn features that are truly useful for the classification task rather than spuriously predictive features.

In summary, the authors show that EP-CNNs, which were originally designed for efficient implementation in neuromorphic hardware, also exhibit excellent robustness properties that match or exceed current state-of-the-art methods, without the need for adversarial training or other specialized techniques.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it are:

- Energy-based models (EBMs)
- Equilibrium propagation (EP) 
- Recurrent dynamics
- Feedback connections
- Robustness 
- Adversarial attacks
- White-box attacks 
- Black-box attacks
- Natural corruptions/perturbations
- Convolutional neural networks (CNNs)
- Vision transformers (ViTs)
- Adversarial training
- Gradient obfuscation
- Semantic perturbations

The paper explores the robustness of a class of biologically-inspired deep neural networks called energy-based models (EBMs) that are trained using an approach called equilibrium propagation (EP). It tests the robustness of these EP-CNNs to different types of adversarial attacks, both white-box and black-box, as well as to natural corruptions. The key finding is that EP-CNNs are much more robust compared to standard CNNs and vision transformers without needing adversarial training or other defenses. The adversarial examples crafted for EP-CNNs also tend to be more semantically meaningful compared to those for normal CNNs. So in summary, the key focus areas are on EBMs, equilibrium propagation, robustness, different attack types, comparing to CNNs/transformers, and avoiding common defense pitfalls like gradient obfuscation or reduced clean accuracy.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions I would ask about the method proposed in this paper:

1. The paper hypothesizes that the feedback connections in EP-CNNs lead to increased robustness against perturbations. However, what is the theoretical basis behind why this recurrent feedback architecture results in more robust models? Can you derive or explain the relationship mathematically?

2. You mention that EP-CNNs achieve competitive accuracy to adversarial training without sacrificing clean accuracy. However, the architectures used for EP-CNNs were quite shallow (only 4 conv layers). Have you experimented with deeper EP-CNN architectures? If so, does increased depth affect accuracy or robustness? 

3. How sensitive are the results to hyperparameters used during EP training, such as nudge iterations, learning rates schedules, etc.? Was any hyperparameter tuning conducted to choose the settings used in this paper?

4. The inference process for EP-CNNs requires executing the free phase to convergence. What is the computational overhead of this compared to standard DNN inference? How might this affect the feasibility of deploying EP-CNNs in practice?

5. Have you explored combining EP training with other techniques like adversarial training or stability training? Would these provide any additional gains in accuracy or robustness for EP-CNNs?

6. The pertubations computed on EP-CNNs appear more semantically meaningful compared to other models. What properties of the EP framework lead to this? And why should semantically meaningful perturbations indicate the model has learned useful features?

7. How does accuracy and robustness scale for EP-CNNs as model capacity is increased, for instance adding more layers or channels? Is there a point where accuracy saturated or robustness diminishes?

8. You mention compatibility of EP training for neuromorphic hardware, but results used standard GPUs. Have you quantified training time, speed, power usage differences when implementing EP-CNNs on neuromorphic platforms?

9. This paper evaluated image classification tasks. However, do you believe the robustness benefits of EP-CNNs hold for other domains like NLP or reinforcement learning?

10. The inference time for EP-CNNs to reach steady state can be long using traditional hardware. Can approximate solutions be used to reduce inference time while maintaining accuracy and robustness gains?
