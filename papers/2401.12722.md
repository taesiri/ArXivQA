# [Falcon: Fair Active Learning using Multi-armed Bandits](https://arxiv.org/abs/2401.12722)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper proposes a new framework called FALCON for fair active learning. The key problem it tries to solve is that existing active learning methods focus on maximizing accuracy but can sometimes worsen unfairness or discrimination issues in machine learning models. On the other hand, prior techniques for improving fairness assume access to ground truth labels, which is not the case during active learning. 

FALCON introduces a novel trial-and-error labeling strategy to handle unknown labels effectively. The key ideas are:
(1) Identify target groups based on the desired fairness measure (e.g. demographic parity). These are subgroups needing more labels.
(2) Actively sample informative points from target groups, but only use them for model training if their labels match expectations. Otherwise, usage is postponed. This avoids negatively impacting fairness.
(3) Balance informativeness of samples and risk of undesired labels using a policy search strategy based on multi-armed bandits. The right policy varies per dataset.
(4) Interleave fairness-based sampling with traditional active learning to also maximize accuracy.

The paper makes the following key contributions:
(1) Proposes FALCON, the first end-to-end framework for fair active learning using a data-centric approach.
(2) Introduces a trial-and-error labeling idea to handle unknown labels and avoid negative impact on fairness.
(3) Learns optimal sampling policies automatically using multi-armed bandits.
(4) Naturally balances between fairness and accuracy objectives.

Experiments on real datasets demonstrate FALCON significantly outperforms prior fair active learning techniques and standard active learning baselines on both fairness and accuracy metrics. The framework is also faster and more efficient than other methods. The results showcase the importance of strategic data labeling for improving model fairness.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes Falcon, a novel fair active learning framework that improves model fairness by strategically selecting the most informative samples to label from target subgroups, while balancing accuracy and efficiency through a multi-armed bandit approach.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. It proposes FALCON, a novel fair active learning framework that selects samples to label in order to improve the fairness and accuracy of a machine learning model. 

2. It introduces a trial-and-error labeling strategy to handle the lack of ground truth labels in an active learning setting. Samples are selected that are likely to be informative for improving fairness, but their usage is postponed if they turn out to have undesired labels.

3. It proposes using adversarial multi-armed bandits to automatically search for the best policy that balances the informativeness of selected samples and the risk of undesired labels. The rewards in terms of improved fairness guide the policy search.

4. It extends FALCON to also improve accuracy by probabilistically alternating between fair and accurate sample selection. This provides a tunable trade-off between maximizing fairness and accuracy.

5. Empirical evaluations on real-world datasets demonstrate that FALCON significantly outperforms prior fair active learning approaches in terms of both fairness and accuracy, while being faster and more efficient.

In summary, the main contribution is a new fair active learning framework with novel strategies for handling unknown labels and automatically finding optimal sampling policies to maximize fairness.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Fair active learning - The main problem studied in the paper of how to select samples to label to improve model fairness and accuracy.

- Trial-and-error labeling - A key strategy proposed where samples are labeled but only used for model training if they have the desired labels according to the target fairness metric. Samples with undesired labels are postponed.

- Target subgroups - Subgroups of data defined by sensitive attribute values and labels that need increased representation to improve fairness according to a given metric.

- Informativeness for fairness - Selecting samples that can best improve the accuracy of target subgroups and thus enhance overall fairness.

- Policies - Different strategies for selecting samples from target groups that balance informativeness and risk of undesired labels.

- Multi-armed bandits (MAB) - Used to automatically select the best policy based on observed rewards in terms of improved fairness. Adversarial MAB methods are used that make no assumptions about reward distributions.

- Balancing fairness and accuracy - Interleaving fair sample selection with standard active learning techniques to also enhance model accuracy.

Does this summary cover the key ideas and terms in the paper? Let me know if you need any clarification or have additional questions!


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes a trial-and-error labeling strategy to handle unknown ground truth labels. Can you explain in more detail how this strategy works and why it is effective for improving fairness? What are some limitations?

2. The paper claims that simply using pseudo-labels is not sufficient in a fair active learning scenario. Why is that the case? When would pseudo-labels potentially work?

3. The paper introduces the concept of "informativeness for fairness" to select the most useful samples for improving fairness. How is this notion different from standard informativeness measures in active learning? What kinds of samples would be considered informative for fairness?

4. The paper proposes using multi-armed bandits (MABs) to search for the best policy. Can you explain the exploration vs exploitation trade-off and why MABs help address this challenge? What theoretical guarantees do adversarial MABs provide? 

5. The reward function plays a critical role in guiding the MAB. The paper normalizes and propagates rewards. What is the intuition behind these strategies and how do they improve performance?

6. The method balances accuracy and fairness by interleaving fair active learning with standard active learning. How does this work? What are the limitations of only focusing on fairness or accuracy alone?

7. The paper claims the method generalizes to any group fairness measure. What is required to support a new fairness measure? Would the overall framework still work or need modifications?

8. How does the method perform when there are multiple sensitive attributes? What changes need to be made to the algorithm and why?

9. Active learning often operates in a batch setting. How does the batch size impact the overall performance of the method? What are the tradeoffs between small and large batch sizes?

10. The paper compares against fair active learning baselines. Why do these methods fail to improve fairness effectively? What are the key differences in the approach taken by the proposed method?
