# [Multimodal Web Navigation with Instruction-Finetuned Foundation Models](https://arxiv.org/abs/2305.11854)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we develop an autonomous web navigation agent that can be trained offline using multimodal inputs (HTML and screenshots) and leverage large pretrained language models?The key hypotheses appear to be:1) Grounded spatial understanding from multimodal inputs (HTML + screenshots) will improve a web navigation agent's ability to complete tasks, especially those involving dynamic page transitions or requiring global context. 2) Using an instruction-finetuned language model (Flan-T5) as opposed to a standard pretrained LM (T5) will improve the agent's HTML comprehension and multi-step reasoning abilities.3) Scaling up the training data (to 347K demonstrations) and model size will lead to better performance on web navigation tasks. The overall goal seems to be developing a practical offline training approach for web agents that can leverage inductive biases from large foundation models like Flan-T5 and achieve strong performance without needing massive online interaction. The paper aims to demonstrate this through experiments on MiniWoB and WebShop benchmarks.
