# [Distilling Autoregressive Models to Obtain High-Performance   Non-Autoregressive Solvers for Vehicle Routing Problems with Faster Inference   Speed](https://arxiv.org/abs/2312.12469)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Vehicle routing problems (VRPs) aim to find optimal routes for a fleet of vehicles to serve customers. Neural autoregressive (AR) models can generate high-quality VRP solutions but have slow inference due to their sequential nature. Non-autoregressive (NAR) models enable faster parallel inference but produce lower-quality solutions. There is a need for methods that can improve NAR performance while retaining fast inference.

Method: 
- The paper proposes a novel method called Guided Non-Autoregressive Knowledge Distillation (GNARKD). It transforms AR models into NAR models through distillation to achieve fast inference speed while preserving solution quality.

- GNARKD modifies only the input/output of the AR decoder to remove sequential dependencies. The encoder is kept intact so both models have similar representations. NAR training uses AR model's solutions as targets and aligns action distributions. This "guided distillation" enables learning order dependencies lacking in typical NAR models.

Contributions:
- First work transforming AR to NAR VRP solvers through distillation. Reduces inference time 4-5x with 2-3% performance drop.

- Analyzes issue of NAR models making less confident selections, substantiated through visualizations. Addresses via guided distillation.

- Applies GNARKD to prominent AR models (AM, POMO, TM). Comprehensive experiments on synthetic and real-world instances demonstrate efficacy.

- Pioneer NAR method for capacitated VRP achieving strong results. Provides valuable baseline for future NAR VRP research.

In summary, the paper makes significant contributions in obtaining high-performance NAR solvers for VRPs through a novel knowledge distillation technique. The faster inference enables real-world deployment meeting tight time constraints.
