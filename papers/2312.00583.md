# [MD-Splatting: Learning Metric Deformation from 4D Gaussians in Highly   Deformable Scenes](https://arxiv.org/abs/2312.00583)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key aspects of the paper:

Problem Statement:
The paper addresses the challenging problem of simultaneous 3D point tracking and novel view synthesis in highly dynamic scenes involving deformable objects such as cloth. This is a difficult task due to ambiguities arising from large deformations, occlusions, and shadows. Accurate tracking and novel view synthesis in such scenes can enable new applications in robotics, augmented reality, and generative AI.

Proposed Solution:
The paper proposes a method called "MD-Splatting" that builds on recent work in Gaussian splatting. MD-Splatting represents the scene using a canonical space of Gaussians with non-metric properties. It then learns a deformation function to map the canonical Gaussians into the metric space over time. This allows tracking points by finding their trajectory through the metric deformations. 

The deformation function uses a neural voxel encoding and a multilayer perceptron (MLP) to infer the Gaussian's position, rotation and a shadow scalar parameter at each timestep. Several physics-inspired regularization terms based on local rigidity, conservation of momentum, and isometry are enforced on the trajectories to get more accurate tracking.

The model is trained on multi-view image sequences to get gradients for optimizing both the canonical Gaussian properties and the deformation function parameters. This enables simultaneous high-quality novel view synthesis using splatting and improved 3D tracking even with shadows and occlusions.

Contributions:

- First approach to learn continuous metric deformations from canonical Gaussians
- Achieves state-of-the-art performance in simultaneous 3D tracking and novel view synthesis in highly dynamic deformable scenes  
- Improves 3D tracking accuracy by 16.7% over baselines
- Contributes a dataset of six photo-realistic synthetic cloth sequences for benchmarking

The key novelty is in modeling metric deformations from canonical Gaussians with enforced physics-based regularization for better real-world tracking performance.
