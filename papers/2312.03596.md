# [MMM: Generative Masked Motion Model](https://arxiv.org/abs/2312.03596)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Existing text-to-motion generation models suffer from a trade-off between speed, quality, and editability. Specifically, diffusion and autoregressive models achieve high quality but are very slow. Latent space alignment methods are faster but produce lower quality motions. None of the existing methods offer both high speed and quality while preserving editability.

Proposed Solution: The paper proposes the Generative Masked Motion Model (MMM) which consists of two key components:

1) Motion tokenizer: Transforms motion sequences into discrete tokens using vector quantization into a learned latent space codebook. This preserves fine-grained motion details while compressing the motion.

2) Conditional masked transformer: Predicts randomly masked motion tokens in parallel based on unmasked tokens and text embeddings from CLIP. Attends to all tokens bidirectionally to model dependencies.

During inference, MMM performs iterative parallel decoding where it predicts multiple low-confidence tokens simultaneously to generate the full motion.

Main Contributions:

- MMM achieves state-of-the-art motion quality surpassing current methods as evidenced by FID scores of 0.08 on HumanML3D and 0.429 on KIT-ML datasets.

- Two orders of magnitude faster inference than diffusion models, and 2x faster than autoregressive models. 

- Enables seamless motion editing capabilities such as body-part modifications, in-betweening, outpainting and long sequence generation.

- Simple yet effective masked modeling paradigm departing from predominant diffusion and autoregressive approaches for text-to-motion generation.

In summary, MMM pushes the state-of-the-art in text-to-motion generation by simultaneously achieving high speed, quality and editability, which has not been possible with prior works. The masked modeling paradigm offers a promising new direction for text-conditioned generative modeling.
