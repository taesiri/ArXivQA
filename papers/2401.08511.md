# [The Gaps between Pre-train and Downstream Settings in Bias Evaluation   and Debiasing](https://arxiv.org/abs/2401.08511)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Pre-trained language models (PLMs) exhibit social biases from their training data. These biases persist when the models are fine-tuned (FT) on downstream tasks.
- FT-based debiasing methods lead to a decline in downstream task performance. Also, there is low correlation between intrinsic bias scores of a PLM and its extrinsic bias scores under FT-based debiasing.
- It is unclear if these issues persist for in-context learning (ICL) methods which use the PLM to make predictions on new data without updating model parameters.

Proposed Solution:
- Compare FT- and ICL-based debiasing methods to analyze the gap between pre-train and downstream bias evaluations and performance.
- Use gender bias evaluations on intrinsic (pre-train) and extrinsic (downstream) tasks. Downstream tasks are question answering, natural language inference and coreference resolution.
- Use FT-based (CDA, ALT) and ICL-based (ZSD, FSD) debiasing methods.
- Evaluate correlation of bias scores between pre-train and downstream tasks for both debiasing approaches.
- Evaluate impact on downstream performance after equalizing the debiasing effect.

Key Contributions:
- ICL-based debiasing shows higher correlation between intrinsic and extrinsic bias scores compared to FT-based debiasing.
- Performance degradation on downstream tasks is lower for ICL-based debiasing compared to FT-based debiasing.
- Output embeddings change more for FT-based debiasing indicating loss of useful information from pre-training.
- Trends noted for FT-based debiasing may not apply directly to ICL-based debiasing.

In summary, the key finding is that ICL-based debiasing methods mitigate some of the issues seen with FT-based debiasing in terms of preservation of information from pre-training and downstream performance. This demonstrates debiasing methods need to be analyzed differently based on how they utilize the pre-trained model.


## Summarize the paper in one sentence.

 This paper demonstrates that in-context learning based debiasing methods exhibit higher correlation between intrinsic and extrinsic bias evaluations and lower performance degradation on downstream tasks compared to fine-tuning based debiasing methods.


## What is the main contribution of this paper?

 The main contribution of this paper is showing that in-context learning (ICL) based debiasing methods exhibit a higher correlation between intrinsic and extrinsic bias scores compared to fine-tuning (FT) based debiasing methods. Additionally, the performance degradation in downstream tasks due to debiasing is lower for ICL-based methods than for FT-based methods. 

Specifically, the paper demonstrates:

1) ICL-based debiasing methods have higher correlation between bias evaluations in pre-training tasks (e.g. CP, SS, MBE) and downstream tasks (e.g. BBQ, BNLI, WB) compared to FT-based methods.

2) The performance drop in downstream tasks (RACE, ANLI, WB) due to debiasing is lower for ICL-based methods (ZSD, FSD) than for FT-based methods (CDA, ALT).

3) Changes to model parameters and outputs are smaller for ICL-based debiasing compared to FT-based debiasing.

In summary, the main contribution is showing that the gap between pre-training and downstream task bias evaluations and performance is lower for ICL-based debiasing than for FT-based debiasing. This suggests that trends and assumptions from FT settings do not directly apply to ICL settings.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper abstract and contents, some of the key terms and concepts associated with this paper include:

- Pre-trained Language Models (PLM)
- Fine-tuning (FT) 
- In-context learning (ICL)
- Bias evaluation
- Bias mitigation/debiasing
- Downstream tasks (e.g. question answering, natural language inference, coreference resolution)
- Intrinsic vs extrinsic bias evaluations
- Social biases (e.g. gender bias)
- Performance degradation due to debiasing
- Correlation between intrinsic and extrinsic bias scores

The paper investigates the gaps between pre-training and downstream settings when evaluating and mitigating biases in PLMs using fine-tuning vs in-context learning based methods. It shows that ICL based debiasing leads to higher correlation of bias scores and lower performance degradation compared to FT based debiasing. The key concepts revolve around understanding how debiasing methods impact PLMs in different settings.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper hypothesizes that in-context learning (ICL) based debiasing methods would show higher correlation between intrinsic and extrinsic bias scores compared to fine-tuning (FT) based methods. What explanations are provided in the paper to support this hypothesis?

2. The paper conducts experiments using 8 LaMini pre-trained language models (PLMs). What were the criteria used to select these specific PLMs and what are the limitations of using LaMini instead of larger PLMs?

3. The paper evaluates gender bias in English using 3 intrinsic bias evaluation datasets - Crowds-Pairs (CP), StereoSet (SS) and Multilingual Bias Evaluation (MBE). What is the rationale provided for choosing to evaluate only gender bias in English despite other biases and languages existing?

4. For extrinsic bias evaluation, the paper uses Bias Benchmark for Question answering (BBQ), Bias Natural Language Inference (BNLI) and WinoBias (WB) datasets. Explain the methodology used in each of these datasets to evaluate gender bias. 

5. The paper compares two fine-tuning based debiasing methods (CDA and ALT) against two in-context learning based methods (ZSD and FSD). What are the key differences between fine-tuning and in-context learning based debiasing?

6. To evaluate impact on downstream performance, RACE, ANLI and OntoNotes datasets are used for question answering, natural language inference and coreference resolution tasks respectively. Why were these specific datasets chosen over other popular benchmarks?

7. Table 1 shows higher correlation between intrinsic and extrinsic bias evaluations for ICL compared to fine-tuning. Does this observation conclusively prove that ICL induces smaller changes in PLMs compared to fine-tuning? Justify your answer.

8. Figures 2a and 2b plot performance difference between original and debiased PLMs for fine-tuning and ICL based methods. What can be concluded about relative downstream performance impact? Substantiate with theoretical arguments.  

9. Table 2 shows cosine similarity between original and debiased PLMs is higher for ICL than for fine-tuning. Explain how this result provides evidence for ICL retaining more beneficial information from pre-training compared to fine-tuning.

10. The paper identifies some limitations of the current study such as focusing only on English language and binary gender bias. What are some interesting future work directions emerging from this limitations that can advance the understanding in this field?
