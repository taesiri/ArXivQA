# [Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large   Language Models](https://arxiv.org/abs/2312.01714)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel method for improving multi-modal Chain-of-Thought (CoT) reasoning with Large Language Models (LLMs) by dynamically retrieving relevant demonstration examples based on cross-modal similarities. Specifically, the authors leverage both intra-modality similarities within the textual or visual modalities, and cross-modality similarities connecting the text and images. Additionally, stratified sampling is introduced to enhance the diversity of retrieved examples. Comprehensive experiments conducted on the ScienceQA dataset demonstrate superior performance, with the ChatGPT-based and GPT-4-based variants achieving 82.67% and 87.43% accuracy respectively. Further analyses reveal consistent improvements across different question types compared to previous state-of-the-art methods like Chameleon. Moreover, the results underscore the effectiveness of combining retrieval mechanisms with CoT prompting for LLMs. The authors also present an insightful evaluation of the recently released GPT-4V model, showing substantially improved zero-shot reasoning abilities compared to the text-only GPT-4. Overall, this work makes notable contributions in advancing multi-modal CoT reasoning through an innovative retrieval-based approach tailored for LLMs.
