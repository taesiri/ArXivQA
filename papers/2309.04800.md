# [VeRi3D: Generative Vertex-based Radiance Fields for 3D Controllable   Human Image Synthesis](https://arxiv.org/abs/2309.04800)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How can we build a generative 3D-aware model for photorealistic human image synthesis that provides explicit control over pose, shape, appearance, and parts?

The key hypothesis is that incorporating a parametric human model (SMPL) will allow the generative model to achieve better generalization to novel poses/shapes and enable part-level control, compared to prior work on neural radiance fields for humans. 

Specifically, the paper proposes a vertex-based radiance field representation, VeRi3D, that maps 3D points to color/density based on features of nearest SMPL vertices. This representation aims to achieve the following:

1) Generalization to novel poses by transforming points to vertex-local coordinate systems 

2) Generalization to novel shapes by manipulating vertex locations

3) Part-level control by editing vertex features 

The central research question is whether this vertex-based radiance field parameterized by a human model can achieve superior performance on controllable human image synthesis compared to prior art. The paper aims to demonstrate this through experiments on pose/shape generalization and part editing.

In summary, the key hypothesis is that incorporating an explicit human model will allow for learning a generative radiance field that achieves better generalization and controllability for photorealistic human rendering. The vertex-based representation is proposed as a way to effectively incorporate the human model.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1. Proposing VeRi3D, a generative vertex-based human radiance field for 3D controllable human image synthesis. 

2. Incorporating the parametric human template SMPL into the radiance field representation in three aspects:

- Mapping points from observation space to canonical space using SMPL skinning weights for pose invariance. 

- Representing points using features of neighboring SMPL vertices and offsets for shape invariance.

- Learning vertex features with a 2D CNN on the SMPL UV map for part controllability.

3. Demonstrating that VeRi3D allows generating photorealistic human images with control over camera viewpoint, body pose/shape, and part-level editing.

4. Showing strong qualitative and quantitative results on DeepFashion, Surreal, and AIST++ datasets for unconditional image synthesis. Also showing competitive results on the ZJU-MoCap dataset for reconstruction.

In summary, the main contribution is proposing a novel way of incorporating a parametric human model into a generative radiance field to achieve better generalization and controllability for 3D-aware human image synthesis.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence TL;DR summary of the paper:

The paper proposes a 3D-aware generative adversarial network method called VeRi3D that can generate controllable radiance fields of human bodies, enabling control over pose, shape, appearance, and part-level editing.


## How does this paper compare to other research in the same field?

 This paper presents a novel method for generating controllable radiance fields for human bodies, enabling control over pose, shape, and part-level appearance. Here are some key ways this paper compares to related work:

- It builds on recent work on learning neural radiance fields in a generative setting (GRAF, Pi-GAN, EG3D, etc). However, those methods focus on non-articulated objects like faces and cars. This paper adapts the radiance field idea to articulated human bodies.

- Compared to other generative models for humans like SMPLicit and CAPE, this method can generate photo-realistic RGB images rather than just geometry/shape. It also does not require any 3D supervision.

- Relative to recent works on neural human radiance fields (ENARF, GNARF, AvatarGen), a key contribution is incorporating an explicit human model (SMPL) to enable better generalization and control. The vertex-based representation also avoids ghosting artifacts. 

- The level of control offered, especially part-level editing, goes beyond most prior human generative models. The controllability is comparable to SMPL and SMPL-based methods, while also generating realistic appearance.

- The image quality and pose/shape generalization ability is superior to existing neural human radiance fields like ENARF. The results are quite competitive to state-of-the-art on common benchmarks.

In summary, this paper pushes the state-of-the-art in 3D-aware generative modeling of humans by combining the benefits of classical parametric models and recent neural radiance fields. The vertex-based representation and incorporation of SMPL enables control and generalization not seen in prior neural human models.
