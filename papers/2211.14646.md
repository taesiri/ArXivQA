# [Towards Improved Input Masking for Convolutional Neural Networks](https://arxiv.org/abs/2211.14646)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How can we develop an improved input masking technique for convolutional neural networks (CNNs) that reduces the missingness bias caused by typical image masking?

The key points are:

- Image masking typically involves replacing parts of an input image with a baseline color like grey or black. This causes a large distribution shift and missingness bias, where models can start relying on the shape/color of the mask.

- Recently, progress has been made in reducing this issue for vision transformers by simply dropping tokens corresponding to masked patches. 

- The authors propose a new masking technique called "layer masking" for CNNs that propagates masks through the network to minimize missingness bias.

- Layer masking applies masks to activation maps rather than just the input image, so the model only sees the unmasked portions. It also uses neighbor padding to reduce artifacts.

- Experiments show layer masking makes CNNs more robust to large input occlusions, reduces reliance on mask shape/color, and produces better explanations via LIME.

In summary, the central hypothesis is that layer masking can significantly reduce missingness bias for input masking in CNNs, enabling improved feature removal for interpretability. The results appear to validate this hypothesis.


## What is the main contribution of this paper?

 This paper proposes a new masking technique called "layer masking" for convolutional neural networks (CNNs) to reduce missingness bias when parts of an input image are masked out for interpretability. The key contributions are:

- Layer masking propagates both the input image and mask through the layers of a CNN, carefully masking and padding activations at each layer. This allows the model to focus only on the unmasked portions of the input. 

- Layer masking uses a novel "neighbor padding" method to pad masked regions that helps minimize edge artifacts and distribution shift. 

- Experiments show layer masking makes CNNs like ResNets much more robust to removing large masked regions (up to 50% of pixels) compared to simply replacing masked parts with grey or black.

- Layer masking removes dependence of the model on the shape of the mask, which is important for precise removal of object features without leaking shape information.

- Interpretability methods like LIME have improved feature importance scores when using layer masking compared to baseline masking techniques.

- Layer masking helps mitigate "missingness bias" where models rely on masking color/shape when interpretability methods perturb inputs. This is a key problem in vision model interpretability.

Overall, layer masking allows better input removal for CNN interpretability by enabling precise and robust masking without distribution shift. The method could be useful for debugging vision models and obtaining more faithful explanations.
