# [SCoDA: Domain Adaptive Shape Completion for Real Scans](https://arxiv.org/abs/2304.10179)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is: How can we effectively transfer knowledge from synthetic 3D shapes to improve shape completion and reconstruction from real-world scans?The key challenges are:1) There is a domain gap between synthetic 3D shapes (e.g. from CAD models) and real-world scans. Real scans tend to be more sparse, noisy, and incomplete. 2) There is a lack of paired real scans and ground truth 3D shapes for supervision. Synthetic data has rich ground truth shapes, but does not match the characteristics of real scans.To address these challenges, the paper proposes a new task called SCoDA (Domain Adaptive Shape Completion) to transfer knowledge from synthetic data to real scan completion. The main contributions are:1) A new dataset called ScanSalon with 800 hand-created 3D shapes paired with real scans across 6 categories. This provides ground truth for real scans.2) A method using cross-domain feature fusion to combine global shape knowledge from synthetic data with local pattern knowledge from real data.3) A volume-consistency self-training approach to make the model robust to incomplete real scans.In summary, the key hypothesis is that combining global synthetic shape knowledge with local real scan knowledge can enable effective domain adaptation for scan completion. The paper aims to demonstrate this via the proposed SCoDA task, ScanSalon dataset, and cross-domain learning method.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Proposing a new task called SCoDA (Domain Adaptive Shape Completion) for transferring knowledge from synthetic 3D shape data to real-world scan completion. This is motivated by the lack of complete ground truth shapes for real scan data.2. Introducing a new dataset called ScanSalon with 800 manually created 3D models paired with real scans across 6 object categories. The models serve as ground truth for a subset of the scans to enable training and evaluation.3. Presenting a method for SCoDA that uses a cross-domain feature fusion (CDFF) module to combine global shape knowledge from synthetic data with local pattern knowledge from real data when training an implicit shape reconstruction network. 4. Proposing a volume-consistent self-training (VCST) method to improve reconstruction robustness to incomplete real scans during training. This is done by enforcing prediction consistency between two augmented views of the scan.5. Providing extensive experiments demonstrating the effectiveness of the proposed SCoDA method compared to other baselines, and ablations analyzing the individual contributions of the CDFF and VCST components.In summary, the key contribution appears to be proposing the new SCoDA task and ScanSalon dataset to enable research on transferring synthetic 3D shape knowledge to real scan completion, along with a method combining cross-domain feature fusion and self-training to effectively address this challenge.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new task called SCoDA for domain adaptive shape completion of real scans, where knowledge from synthetic data is transferred to improve completion of sparse and incomplete real scans, and contributes a dataset ScanSalon with elaborately created 3D models paired with real scans to enable research in this direction.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in the field of domain adaptation for shape completion:- This paper proposes a new task and dataset for domain adaptive shape completion, focusing specifically on adapting synthetic data to real scans. This is an underexplored area compared to other 3D domain adaptation tasks like point cloud classification/segmentation. The proposed dataset with manual shape annotations for real scans is also unique.- The method utilizes implicit functions for shape completion, which is becoming more popular recently due to its ability to represent shapes with complex topology. However, few prior works have explored implicit functions in the context of domain adaptation. - The cross-domain feature fusion module is a novel approach to combine global and local knowledge from different domains. This differs from typical feature alignment or adversarial techniques in domain adaptation. The idea of fusing multi-scale features could inspire more research on domain-specific vs invariant features.- The volume-consistent self-training framework is specialized for improving completion robustness against missing data. It differs from consistency training practices in other areas like image recognition by using surface-aware augmentations. This could provide a new direction for designing task-specific consistency training schemes.- Compared to other 3D domain adaptation works that simply apply standard techniques like adversarial learning, this paper better exploits the structure and properties of the shape completion problem in its designs. More analyses are provided on what is transferable across domains.- The experiments systematically compare with relevant baselines and thoroughly evaluate different design choices. Quantitative gains over baselines demonstrate the advantages of the proposed method.Overall, this paper presents more thorough investigations of the unique problem of domain adaptive shape completion, proposes tailored techniques for this task, and provides a solid benchmark for future works to improve upon. The ideas like cross-domain feature fusion and task-specific consistency training could also inspire related domain adaptation research.


## What future research directions do the authors suggest?

Based on my reading, the main future research directions suggested by the authors are:- Developing more effective methods to handle the domain gap between synthetic and real data. The current methods still struggle with the great incompleteness and noise in real scans, as well as the significant differences from synthetic data. New techniques need to be explored to better align the features and representations between the two domains.- Expanding the benchmark with more categories and samples. The current ScanSalon dataset contains 6 categories with 800 annotated models. Expanding it with more object types and samples would allow more thorough evaluation and investigation of different methods.- Exploring semi-supervised or weakly-supervised approaches. The requirement of elaborate 3D annotations for real scans is still a bottleneck for training. Developing methods that can learn from partial labels, noisy labels, or without labels has great practical value.- Investigating adversarial and generative approaches. Generative adversarial networks or autoencoders may help generate useful features or samples to reduce the domain gap between synthetic and real data. This can be a promising direction.- Applying the ideas to related tasks like single-view reconstruction. The proposed cross-domain feature fusion may inspire domain adaptation in other 3D vision tasks. Evaluating its effectiveness in other tasks is valuable future work.- Addressing the limitations of current methods on extremely sparse, noisy or incomplete data. More robust learning algorithms need to be developed to handle failure cases caused by these factors.In summary, the main future directions are to develop more advanced domain adaptation techniques, reduce the reliance on full supervision, investigate generative approaches, apply ideas to related tasks, and improve robustness to data challenges. Advancing research in these aspects would further push the domain adaptive shape completion from real scans.
