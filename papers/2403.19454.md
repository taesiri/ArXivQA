# [JDocQA: Japanese Document Question Answering Dataset for Generative   Language Models](https://arxiv.org/abs/2403.19454)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Document question answering requires understanding both textual and visual elements like figures and tables. Existing datasets are limited, especially for Japanese.
- Generative language models can hallucinate answers not grounded in the context. Mitigating this is an open challenge. 

Proposed Solution:
- Introduced JDocQA, a new Japanese document QA dataset with 11,600 QA pairs over 5,504 documents covering various formats like slides, reports, websites.
- Has 4 question types - yes/no, factoid, numerical, open-ended. Also includes 1,000 multi-page and 1,788 unanswerable questions.  
- Questions reference both text and visual elements like tables and figures.

Experiments & Results:  
- Tested several Japanese language models by finetuning on JDocQA. Larger models like StableLM performed the best. 
- Finetuning with unanswerable questions helps mitigate hallucination compared to without.
- Added visual modality further improves performance.

Main Contributions:
- First large-scale Japanese document QA dataset requiring visual and textual reasoning.  
- Detailed experiments highlighting model performances, the effect of unanswerable data on hallucination.
- Benchmark for developing document QA models in Japanese, especially multimodal models.

In summary, the paper introduced a new dataset to advance research in Japanese document question answering and analyzed model performances on it. The inclusion of unanswerable questions is a useful aspect to handle hallucination.
