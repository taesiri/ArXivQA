# [Few-Shot Class-Incremental Learning via Training-Free Prototype   Calibration](https://arxiv.org/abs/2312.05229)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
The paper addresses the problem of Few-Shot Class-Incremental Learning (FSCIL), where the goal is to incrementally learn new visual categories from limited labeled data, while retaining knowledge of previously seen categories. The key challenges in FSCIL are catastrophic forgetting of old knowledge and overfitting on scarce new data. Existing FSCIL methods freeze the feature extractor trained on base classes and plug new class prototypes into the classifier, which alleviates catastrophic forgetting but still suffers from biased prototypes of new classes. 

Observations:
The paper empirically analyzes existing FSCIL methods and makes two key observations:
1) Existing methods exhibit significantly lower accuracy on new classes compared to base classes. 
2) Instances of new classes are prone to being misclassified into their most similar base classes, due to biased prototypes.

Proposed Solution: 
The paper proposes a simple yet effective training-free prototype calibration method called TEEN that addresses the aforementioned issues. Key ideas: 
(1) Leverage semantic similarity between base classes and new classes already captured well by the frozen feature extractor. 
(2) Fuse the biased new class prototypes with weighted base class prototypes to enhance discriminability. The weights are computed via softmax over cosine similarity scores.

Main Contributions:
- Identify and analyze the problem of poor performance on new classes in FSCIL 
- Propose a simple and training-free prototype calibration method using inherent semantic similarity 
- Achieve consistent and significant gains over state-of-the-art FSCIL methods on all key metrics, especially on new classes (up to 18.4% better)
- Demonstrate wide applicability in few-shot learning scenarios as well

In summary, the paper provides useful insights into limitations of existing FSCIL methods, and presents an effective yet elegant solution for calibrating biased prototypes leveraging semantic similarity, with remarkable gains on new classes.
