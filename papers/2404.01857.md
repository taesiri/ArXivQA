# [Detecting Gender Bias in Course Evaluations](https://arxiv.org/abs/2404.01857)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper investigates potential gender bias in course evaluations written by students at Chalmers University of Technology. Prior analysis found that courses with female examiners received lower scores on average in the overall impression rating compared to courses with male examiners. This suggests a bias against female examiners. The goal of this paper is to analyze the free-text comments in the course evaluations to uncover linguistic differences depending on examiner gender that may indicate bias.  

Methods:
The data consists of over 9000 course evaluations spanning 2013-2021, including free-text comments, grades, examiner gender, etc. The comments were preprocessed - gendered pronouns removed, tokenized with POS tags using Spacy. Classification models (logistic regression and random forest) were trained to predict examiner gender from the free-text comments. The accuracy of prediction and most predictive features are analyzed to determine if differences exist in how students describe courses depending on examiner gender.

Results:
The classifiers achieved better-than-baseline accuracy in predicting examiner gender for both English and Swedish courses. Analysis of predictive features showed some differences in important words depending on predicted gender. For female predictions, "softer" words like "open" and "feels" were important. For male predictions, "harder" words like "perfect" and "process" were key. This suggests differences in how students describe courses and indicates potential gender bias.

Conclusions:
The ability of classifiers to predict examiner gender at above-baseline rates using free-text comments, along with differences in predictive features between genders, provides evidence that language differences exist depending on examiner gender. This points to potential gender bias in how students evaluate courses at Chalmers. Further analysis is needed to deepen understanding of detected bias and differences. Future work could investigate author gender prediction, analyze comments using word embeddings, explore detecting explicit gender bias, and reproduce the study at other universities.
