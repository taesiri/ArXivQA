# [MoST: Motion Style Transformer between Diverse Action Contents](https://arxiv.org/abs/2403.06225)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing motion style transfer methods struggle to effectively transfer style between motions with different contents. They fail to clearly disentangle style from content, resulting in transfer failures where the generated motion loses the content of the original motion or does not properly reflect the style. This problem is more severe when the content of the style motion and content motion are different. In addition, recent methods rely on heuristic post-processing steps like copying global translation from the content motion to mitigate issues in the generated motions.

Proposed Solution:
The paper proposes MoST, a Motion Style Transformer, to address these issues. The key ideas are:

1) A new framework with Siamese motion encoders to extract style and content features, a part-attentive style modulator (PSM) to modulate the style feature, and a motion generator.

2) The PSM aligns the style feature with the target content through cross-attention before inserting it into the generator. This enables clear disentanglement of style from the source motion.

3) New loss functions - a style disentanglement loss to separate style and content, and a physics-based loss to improve quality.

Main Contributions:

1) MoST effectively disentangles style from content using the proposed architecture and losses, enabling high-quality transfer between diverse motion contents.

2) It substantially outperforms state-of-the-art methods, especially for motions with different contents, without needing heuristic post-processing.

3) The generated motions have fewer artifacts and are more temporally coherent owing to the transformer architecture and physics-based loss.

In summary, MoST advances the capability of motion style transfer methods to robustly transfer style between varied content without compromising quality. The clear disentanglement of style and modular architecture offer flexibility and pave the way for few-shot transfer between new styles.
