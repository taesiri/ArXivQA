# [Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale   Annotations](https://arxiv.org/abs/2402.19133)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Explainable AI (XAI) methods are often evaluated based on human-annotated rationales, which are expensive and biased. 
- Webcam-based eye tracking provides a more natural annotation process, but it's unclear if gaze data can serve as an alternative for rationale evaluation.

Methods:
- Analyzed multilingual webcam eye tracking data (English, Spanish, German) from an information-seeking QA dataset (WebQAmGaze).
- Compared gaze patterns to human rationales and model explanations (attention, LRP, GradxInput) for 4 Transformer models (mBERT, distilmBERT, XLMR, XLMR-L).
- Evaluated gaze entropy, decoding accuracy, ranking of XAI methods with respect to rationales and gaze.  

Key Findings:
- Gaze entropy correlates with task errors, suggesting it indicates difficulty.
- Rationales can be decoded from gaze (60-70% ROC-AUC) and model explanations (67-96%).
- Ranking of XAI methods based on gaze shows comparable rankings to rationales.

Main Contributions:
- First analysis of using low-cost webcam eye tracking as an alternative for rationale annotations in NLP.
- Showed gaze provides useful linguistic signals (entropy, decoding accuracy) beyond rationales.
- Gaze-based ranking of XAI methods correlates with rationale-based rankings, suggesting gaze can serve for cheaper XAI evaluation.

Overall, the paper demonstrates the promise of leveraging webcam gaze data to complement or potentially replace expensive rationale annotations when evaluating explainability methods.
