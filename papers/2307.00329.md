# [DoReMi: Grounding Language Model by Detecting and Recovering from   Plan-Execution Misalignment](https://arxiv.org/abs/2307.00329)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is: How can we enable immediate detection and recovery from misalignments between high-level plans generated by language models and low-level skill executions in embodied agents? The key hypothesis appears to be: By leveraging language models to generate constraints that indicate plan-execution alignment, and using a visual question answering (VQA) model to continuously monitor these constraints, we can enable timely re-planning and recovery when misalignments occur during long-horizon robotic tasks.In summary, this paper focuses on detecting and recovering from mismatches between the high-level plans created by language models and the actual low-level execution in robotic systems. The core proposal is to use language models and VQA to quickly identify these plan-execution misalignments and trigger re-planning for more effective task completion.


## What is the main contribution of this paper?

 The main contributions of this paper are:1. It proposes a novel framework called DoReMi that enables immediate detection and recovery from misalignments between high-level plans and low-level executions in robotic tasks. 2. It leverages large language models (LLMs) for both high-level planning and generating constraints that can indicate whether the plan and execution are aligned.3. It uses a visual question answering (VQA) model during execution to periodically check if constraints are satisfied, enabling timely triggering of re-planning when misalignments occur.4. It provides theoretical analysis on how immediate re-planning can reduce wasted time and improve success rate compared to delayed re-planning. 5. It demonstrates the effectiveness of DoReMi through experiments on robot arm manipulation tasks and humanoid robot tasks under various disturbances, showing improved success rates and reduced execution times.In summary, the key innovation is the DoReMi framework that enables immediate and continuous detection of misalignments between plans made by LLMs and low-level skill executions, along with timely triggering of re-planning for recovery. This is shown to be more efficient than delayed re-planning approaches.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key point from this paper:The paper proposes a novel framework called DoReMi that enables immediate detection and recovery from misalignments between high-level plans and low-level execution in robotic tasks by using language models for planning and constraint generation and a VQA model to regularly check constraint satisfaction.


## How does this paper compare to other research in the same field?

 Here are some ways this paper compares to other research in the same field:- It builds on prior work that has explored integrating language models into robotic tasks. However, it focuses specifically on the problem of aligning high-level plans from the language model with low-level execution. Many previous methods assume successful execution of each step, while this paper emphasizes detecting and recovering from misalignments.- The key novelty is the proposed DoReMi framework that enables immediate detection and recovery from plan-execution misalignments. This sets it apart from prior hierarchical approaches that only incorporate feedback at the boundaries between steps. The continuous monitoring and re-planning of DoReMi allows faster reaction to failures.- It leverages recent advances in vision-language models (specifically VQA) as general "constraint detectors" to identify mismatches between the plan and execution. This is a flexible way to check constraints compared to having separate detectors for each type of failure. - The paper includes both theoretical analysis and physical experiments on robotic arms and humanoids. The experiments systematically validate the benefits of immediate re-planning under disturbances, complementing the theory.- Compared to end-to-end approaches that directly map language to robot actions, DoReMi adopts a hierarchical framework decomposing long-horizon tasks into skills. This modular approach allows incorporating powerful existing methods for high-level planning and low-level control.In summary, this paper makes contributions in timely detecting plan-execution misalignment, the use of VQA for flexible constraint checking, and experimental validation. The hierarchical framework and focus on alignment monitoring differentiate it from related works. The immediate recovery enabled by DoReMi is shown to improve performance on complex robotic tasks.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some future research directions the authors suggest include:- Exploring other types of detectors beyond vision-based ones to identify plan-execution misalignments. The authors note that detectors fully based on vision can be limited by issues like misdetection, occlusion, and perspective. Other modalities like sound, force, or tactile sensing could be investigated.- Improving the vision-language module to be a more powerful constraint detector. The authors find the zero-shot transferred VQA model is imperfect and could benefit from further training or a more advanced vision-language architecture. - Applying the framework to even more complex environments and tasks. The experiments focused on robot arm manipulation and humanoid locomotion scenarios. Testing the method on more dynamic, unstructured environments with more diverse disturbances could be valuable.- Integrating the framework with sim2real transfer methods to enable deployment on physical robots. The current experiments are in simulation and bridging to real-world application could expand the impact.- Exploring different ways for the language model to propose constraints, beyond natural language descriptions. For example, exploring logical or symbolic representations.- Developing more formal methods to verify and validate the safety of the overall system. Safety is critical for real-world deployment so analyzing the robustness could be important future work.- Improving the efficiency and runtime of the different components like the VQA detector to enable higher frequency operation.So in summary, the authors point to things like improving the detectors, vision-language modules, testing on more environments, safety validation, and runtime optimizations as interesting directions for extending this work. Advancing the techniques to handle more complex real-world tasks seems a key opportunity.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:This paper proposes a novel framework called DoReMi for grounding language models in robotic tasks through immediate detection and recovery from plan-execution misalignments. The key idea is to leverage large language models (LLMs) not only for high-level planning of skills, but also for generating executable constraints that indicate whether the low-level execution aligns with the plan. During skill execution, a visual question answering (VQA) model acts as a "constraint detector" by regularly checking images to see if constraints are satisfied. If a constraint violation is detected, indicating a misalignment between plan and execution, the LLM is immediately called to re-plan and recover. Experiments on robotic arm manipulation tasks and humanoid robot tasks with disturbances demonstrate that DoReMi enables faster task completion and higher success rates compared to methods without continuous alignment. Theoretical analysis also shows the benefits of immediate re-planning. Overall, this work emphasizes the importance of closely aligning high-level plans to low-level execution for effectively grounding language models in embodied agents.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points from the paper:The paper proposes a novel framework called DoReMi which enables immediate detection and recovery from misalignments between high-level plans and low-level execution in robotic tasks. Large language models (LLMs) are leveraged for both high-level planning and generating constraints that indicate whether the plan is properly executed. During low-level skill execution, a visual question answering (VQA) model regularly checks if these constraints are violated. If a violation is detected, indicating a misalignment between plan and execution, the LLM is immediately called to re-plan and recover. Experiments are conducted on robotic arm manipulation tasks and humanoid robot tasks with environmental disturbances and imperfect controllers. Results demonstrate that the proposed method leads to higher success rates and shorter task completion times compared to baselines. The key benefits are timely detection of mismatches using the VQA "constraint detector" and rapid re-planning by the LLM to realign plan and execution. Theoretical analysis also shows potential time savings and success rate improvements achievable through immediate re-planning upon detecting misalignments. Overall, the DoReMi framework effectively grounds language by continuously maintaining alignment between high-level plans from the LLM and low-level skill execution.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:The paper proposes a novel framework called DoReMi that enables immediate detection and recovery from misalignments between high-level plans generated by a language model and low-level skill executions. The key components are: 1) Using the language model not just for high-level planning but also to generate constraints for each planned step that indicate correct execution. 2) Maintaining a constraint set that is updated by the language model. 3) Using a visual question answering (VQA) model during skill execution to periodically check if constraints are satisfied, detecting any misalignments. 4) If misalignments are detected, immediately calling the language model to re-plan and recover. This allows timely re-planning at any point during execution, unlike prior methods that only re-plan at discrete steps. Experiments on robot arm and humanoid tasks demonstrate DoReMi achieves higher success rates and lower execution times.


## What problem or question is the paper addressing?

 Based on my reading, the key points of this paper are:1. The paper addresses the challenge of grounding language models for robotic control. Specifically, it focuses on the issue that low-level execution may deviate from high-level plans generated by language models, due to environmental perturbations or imperfect controllers. 2. The paper proposes a framework called DoReMi to enable immediate detection and recovery from misalignments between the high-level plan and low-level execution. 3. The key ideas are:- Leverage language models to generate constraints that can indicate misalignments during execution, in addition to planning. - Use vision language models to continuously detect violations of these constraints.- If a violation is detected, immediately invoke the language model to re-plan for recovery.4. Theoretical analysis shows potential benefits in terms of reducing wasted time and failure probability.5. Experiments on robot arm and humanoid robot tasks demonstrate that the proposed method leads to higher success rates and shorter task completion times in the presence of disturbances.In summary, the main problem is the misalignment between plans and execution, and the paper proposes a novel framework to achieve tight alignment by detecting violations and triggering re-planning in real-time. This allows the agent to be more robust to imperfections in the real world.
