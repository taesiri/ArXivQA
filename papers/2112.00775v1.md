# [Routing with Self-Attention for Multimodal Capsule Networks](https://arxiv.org/abs/2112.00775v1)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the abstract, the main research goals of this paper appear to be:

1. To propose a new multimodal capsule network architecture that can learn from large-scale noisy video data in a self-supervised manner. Specifically, the authors aim to leverage the ability of capsule networks to model semantic relationships between low-level features and higher-level concepts. 

2. To develop a novel routing mechanism based on self-attention that allows the capsule network to scale to large datasets while remaining computationally efficient. Traditional routing algorithms like dynamic routing are too expensive for large-scale data.

3. To demonstrate the effectiveness of the proposed multimodal capsule network on downstream tasks like zero-shot video retrieval and action localization after pretraining on a large narrated video dataset.

In summary, the key hypothesis seems to be that using capsules with a scalable self-attention based routing mechanism can lead to an effective architecture for multimodal self-supervised learning from large noisy video data. The authors evaluate this by pretraining their model on a narrated video dataset and testing on challenging zero-shot tasks that require modeling high-level semantic relationships across modalities.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. Proposing a new multimodal capsule network architecture that leverages the benefits of capsule networks for large-scale multimodal self-supervised learning. 

2. Introducing a novel routing by self-attention mechanism for capsule networks that is more efficient and scalable compared to prior routing techniques like dynamic routing and EM routing.

3. Showing that the proposed architecture and routing mechanism achieves state-of-the-art results on challenging multimodal benchmark tasks like zero-shot text-to-video retrieval and zero-shot temporal action localization.

4. Demonstrating that the capsules in the network are able to learn meaningful representations of various concepts and objects within each modality.

5. Providing a comprehensive experimental evaluation on two downstream tasks using four datasets that validates the effectiveness of the proposed multimodal capsule network and routing approach.

In summary, the key innovation is in adapting capsule networks, which have shown promise in modeling part-whole relationships, to large-scale multimodal self-supervised learning by introducing a novel self-attention based routing mechanism. The paper shows strong empirical results highlighting the benefits of this approach.
