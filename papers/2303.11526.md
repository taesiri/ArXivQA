# [PRISE: Demystifying Deep Lucas-Kanade with Strongly Star-Convex   Constraints for Multimodel Image Alignment](https://arxiv.org/abs/2303.11526)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to improve the accuracy and robustness of the Lucas-Kanade (LK) algorithm for multimodal image alignment. Specifically, the paper aims to address the issue of poor local optimality that the LK method often suffers from when aligning image pairs with large distortions. The main hypothesis is that enforcing deep neural networks to learn approximately star-convex loss landscapes around the ground truth will facilitate the convergence of the LK method to the global optimum through gradient descent.In summary, the key research question is: Can imposing star-convex constraints on deep network training improve the accuracy and robustness of the LK method for multimodal image alignment? The hypothesis is that learning approximately star-convex loss landscapes will guide the LK method to find better solutions.


## What is the main contribution of this paper?

This paper proposes a new method called PRISE (Dee\underline{p} Sta\underline{r}-Convexif\underline{i}ed Luca\underline{s}-Kanad\underline{e}) for multimodel image alignment. The key contributions are:- They introduce strongly star-convex constraints into the training of deep neural networks for Lucas-Kanade (LK) based homography estimation. This helps reshape the loss landscape of LK to be more convex-like around the ground truth solution. - They formulate the training as a minimax problem with contrastive losses derived from the definition of strong star-convexity. This leads to an adversarial training framework.- They provide an efficient sampling-based algorithm to train the network with star-convex constraints, which helps reduce computational complexity. - They analyze the quality of the solutions obtained from PRISE based on the star-convex loss landscapes. - They demonstrate state-of-the-art performance of PRISE on multimodel image alignment tasks on benchmark datasets like MSCOCO, GoogleEarth, and GoogleMap. PRISE significantly outperforms previous methods especially when the pixel error is small.In summary, the main contribution is the novel PRISE framework that introduces strongly star-convex constraints into deep network training to reshape the loss landscape and achieve better convergence for LK based multimodel image alignment. The effectiveness is shown through extensive experiments and analysis.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a new method called PRISE that introduces star-convex constraints during training to improve the optimization landscape and convergence properties of Lucas-Kanade for multimodal image alignment, achieving state-of-the-art performance on benchmark datasets especially for small pixel errors.


## How does this paper compare to other research in the same field?

Here are my thoughts on how this paper compares to other research in the field of homography estimation:- This paper proposes a new method called PRISE (Deep Star-Convexified Lucas-Kanade) that aims to improve upon DeepLK, a recent deep learning based approach for homography estimation. - The key novelty is the use of strongly star-convex constraints during network training to encourage the loss landscape to be approximately star-convex. This is claimed to help gradient descent find near globally optimal solutions.- The idea of using star-convexity in deep learning is relatively new and underexplored. Most prior work has focused on analyzing or optimizing existing star-convex functions, rather than explicitly training neural networks to learn such functions.- In that sense, the approach is quite unique compared to typical homography estimation methods that just train a network to directly predict the homography. Adding constraints during training to shape the loss landscape is an interesting idea.- The proposed training process incorporates elements of adversarial training and contrastive learning by creating fake samples and comparing losses. This is related to some other works using adversarial or contrastive techniques.- However, the overall formulation using strong star-convexity constraints seems novel and is the core contribution.- Experiments demonstrate state-of-the-art results on standard homography estimation benchmarks, especially for small pixel errors. This indicates the potential advantages of their proposed approach.- Compared to DeepLK, PRISE shows consistently better performance, which validates the benefits of the new star-convex training procedure. The analysis also helps explain some of DeepLK's properties.- Overall, the paper introduces a new technique for training homography estimation networks that seems promising based on results but is relatively unexplored in the literature. The novelty lies in the geometry-based star-convex constraints rather than the network architecture itself.
