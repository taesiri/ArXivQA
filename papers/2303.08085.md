# [Alias-Free Convnets: Fractional Shift Invariance via Polynomial   Activations](https://arxiv.org/abs/2303.08085)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes a new convolutional neural network (CNN) architecture called Alias-Free ConvNet (AFC) that aims to achieve true shift invariance and shift equivariance. The central hypothesis is that by preventing aliasing effects that stem from downsampling layers and non-linear activations, it is possible to construct a CNN that is provably invariant/equivariant to input image translations, even fractional (sub-pixel) shifts. 

Specifically, the paper addresses the following key questions:

- How can aliasing effects in CNNs, caused by downsampling and non-linearities, be eliminated to achieve true shift invariance/equivariance?

- Can polynomial activations be used instead of standard activations like ReLU to limit bandwidth expansion and prevent aliasing, while still achieving competitive accuracy on large-scale tasks like ImageNet? 

- Does preventing aliasing lead to CNNs that are more robust to adversarial attacks based on small input image translations?

- Can fractional shift invariance/equivariance be formally proven and demonstrated empirically?

The central hypothesis is that by using alias-free downsampling layers and polynomial activations in an end-to-end manner, it is possible to construct a CNN that is provably invariant/equivariant even to fractional input shifts. The paper proposes specific techniques and provides both theoretical analysis and empirical evaluations to test this hypothesis.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing an alias-free convolutional neural network (CNN) architecture that is provably invariant to translations, including fractional (sub-pixel) translations. The key ideas are:

- Using polynomial activations instead of standard activations like ReLU. Polynomials have limited frequency support, so with proper upsampling/downsampling they do not cause aliasing.

- Modifying downsampling operators like strided convolution to use anti-aliasing low-pass filters (BlurPool).

- Modifying normalization to be shift-equivariant. 

- Theoretical analysis showing these modifications make the network provably invariant to any translation of the input, even fractional shifts.

- Empirical evaluation showing the alias-free CNN has superior robustness to translation attacks compared to standard CNNs and prior methods for invariance.

So in summary, it presents the first CNN architecture that is provably invariant to all translations by comprehensively addressing aliasing in activations, downsampling and normalization. This is shown to improve robustness. The use of polynomial activations is key to handle aliasing from nonlinearities.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key point from the paper:

The paper proposes a new aliasing-free convolutional neural network architecture that uses polynomial activations to achieve guaranteed shift invariance and shift equivariance, even for fractional pixel translations.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other research on constructing shift-invariant convolutional neural networks (CNNs):

- The paper proposes a new method for creating CNNs that are provably shift-invariant, even to sub-pixel translations. This guarantees robustness to adversarial attacks based on image translations. Prior work like that of Azulay and Weiss (2019) showed CNNs are not inherently shift-invariant, while others like Zhang (2019) and Chaman et al. (2020) proposed methods to improve shift-invariance but could not achieve perfect invariance.

- The key innovation is using polynomial activations in an alias-free framework. Most prior work focused only on downsampling layers as a source of aliasing. The authors recognize non-linearities also introduce aliasing, and show polynomials have bounded frequency range to prevent this. 

- Using polynomials for activations is novel, as most prior work uses ReLUs or smooth activations like ELU/GeLU. The authors demonstrate polynomials can work well with proper initialization and normalization. This is an interesting finding even apart from the shift-invariance benefits.

- The method guarantees both shift-invariant outputs and shift-equivariant internal representations. Some prior work like Chaman et al. focused only on invariant outputs. Equivariance is useful for tasks like segmentation.

- The certified robustness is for circular shifts, which is limited. But the method still demonstrates improved robustness on other shifts like crop-based translations. And circular shifts are relevant in some application domains.

- There is an accuracy vs robustness tradeoff, with a 1% drop compared to baseline ConvNeXt. But the model outperforms others under adversarial shifts. Exploring ways to recover the accuracy loss could be interesting future work.

Overall, the alias-free framework with polynomial activations seems like an important advance over prior art in provable shift-invariance for CNNs. The method is novel and has nice theoretical properties. Demonstrating effectiveness on large-scale tasks like ImageNet classification is also significant.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Exploring other types of alias-free normalization layers besides the per-layer normalization used in their model. They hypothesize that other alias-free normalization techniques may exist that could help close the accuracy gap compared to the original ConvNeXt model.

- Using wider or deeper convolutional networks with the alias-free modifications. The authors suggest this could help recover some of the accuracy lost by replacing nonlinearities with polynomial activations, since their model is effectively a polynomial of the input. 

- Applying the alias-free convolutional network framework to other domains where aliasing has been shown to be problematic, such as in generative adversarial networks.

- Examining whether the shift-equivariance of the internal representations in their model is useful for other tasks besides classification, such as segmentation. Their method could potentially be expanded to build shift-equivariant convolutional networks for segmentation.

- Exploring the potential uses of polynomial activations more broadly, since they enable alias-free networks. The authors show polynomial activations may be a reasonable substitute for GELU in ViT and ConvNeXt, so more exploration of polynomial activations could be interesting.

- Testing the importance of circular shift invariance in application domains where it is especially relevant, like panoramic images or medical imaging with uniform backgrounds.

In summary, the main future directions focus on expanding alias-free convolutional networks to new domains, recovering the accuracy gap compared to original models, and further exploring the capabilities of polynomial activations.


## Summarize the paper in one paragraph.

 The paper presents an alias-free convolutional neural network (CNN) for image classification that is provably invariant to input image translations, including fractional pixel shifts. The key ideas are:

1) Replace downsampling operations like pooling and strided convolution with "BlurPool" layers that first low-pass filter to prevent aliasing. 

2) Replace non-linear activation functions like ReLU with polynomial activations, which have limited frequency bandwidth expansion so can prevent aliasing effects with proper upsampling/downsampling around the nonlinearity.

3) Modify normalization to be alias-free by normalizing across entire layers rather than per-pixel.

Together these modifications make the network provably invariant to translations, even fractional shifts, while maintaining competitive accuracy on ImageNet. The alias-free architecture also shows improved robustness to common image corruptions and adversarial translations compared to baseline ConvNets. Overall, this alias-free CNN provides a principled way to build networks that are inherently robust to input shifts.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper proposes a new convolutional neural network architecture called Alias-Free Convnet (AFC) that is guaranteed to be invariant to any input image translations, including fractional pixel shifts. Previous CNNs have aliasing effects caused by downsampling layers and non-linear activations, making them not truly shift-invariant. The AFC solves this by using low-pass filtering before downsampling to prevent aliasing, and replacing non-linear activations like ReLU with polynomial activations. Polynomials have limited frequency bandwidth so they do not cause aliasing like other activations. 

The AFC is proven theoretically and empirically to have shift-invariant outputs and shift-equivariant internal representations. Experiments on ImageNet show the AFC has similar accuracy to ConvNeXt baselines but perfect robustness to adversarial translations like pixel shifts. The AFC also outperforms previous methods like adaptive subsampling on robustness metrics. Limitations are reduced standard accuracy and increased computation costs. Overall, the AFC introduces architectural changes to create a shift-invariant CNN with certified robustness to small image translations.


## Summarize the main method used in the paper in one paragraph.

 The main method used in this paper is designing a convolutional neural network (CNN) architecture that is invariant to image translations. The key ideas are:

- Using polynomial activations instead of standard activations like ReLU. Polynomials have limited frequency bandwidth so they do not cause aliasing effects that break shift invariance. 

- Applying upsampling before nonlinear activations and downsampling after, to prevent aliasing effects in the discrete domain. This makes the activations essentially alias-free.

- Replacing downsampling operations like strided convolution with a "BlurPool" operation that first low-pass filters to prevent aliasing, then downsamples.

- Modifying normalization to be done per-layer rather than per-pixel, as per-pixel normalization breaks shift invariance. 

- Using cyclic/circular convolutions so signals are effectively periodic, enabling theoretical results on aliasing for infinite signals to apply.

In summary, the paper introduces modifications like polynomial activations, upsampling, and BlurPool to make all operations in the CNN shift-equivariant. This results in a network that is provably invariant to image translations, even fractional shifts, unlike standard CNNs. The method is evaluated on ImageNet classification showing improved robustness to translations.


## What problem or question is the paper addressing?

 This paper is proposing a new convolutional neural network (CNN) architecture called Alias-Free Convnet (AFC) that aims to achieve true shift invariance and shift equivariance.

The key problems/questions it is addressing are:

- Standard CNNs are not actually invariant to input image translations due to aliasing effects caused by downsampling layers and non-linearities. This makes them vulnerable to simple adversarial attacks based on image shifting.

- Existing methods to improve CNN shift invariance like using anti-aliasing filters before downsampling or adaptive subsampling grids are only partial solutions. They do not completely eliminate aliasing effects.

- No previous CNN architecture has been able to achieve true shift invariance to both integer and sub-pixel shifts.

- No previous CNN architecture has guaranteed both shift invariant outputs and shift equivariant internal representations. 

- Previous attempts to use polynomial activations for anti-aliasing failed to achieve good performance at scale (e.g. on ImageNet).

So in summary, the key problems are the lack of true shift invariance in CNNs, and their resulting vulnerability to adversarial shifts. The AFC architecture proposes a complete solution using anti-aliasing techniques and polynomial activations. A core contribution is showing polynomial activations can work well at ImageNet scale.
