# [Few shot font generation via transferring similarity guided global style   and quantization local style](https://arxiv.org/abs/2309.00827)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we develop an automatic few-shot font generation (AFFG) method that can capture both global style features as well as fine-grained local style details from very limited font examples?The key points are:- Existing AFFG methods using global style representations cannot capture diverse local details of fonts. - Component-based AFFG methods require pre-defined components/radicals, which is infeasible for new scripts.- This paper proposes an AFFG approach combining global and local style representations without needing predefined components. - The global style captures intra-style consistent properties like stroke thickness and spacing. - The local style focuses on inter-style inconsistent details like stroke shapes.- Local styles are transferred to self-learned components via cross-attention. - Global styles are aggregated with content similarity guidance.So in summary, the central hypothesis is that combining global style aggregation and local style transfer to self-learned components can enable effective AFFG from very few examples, without predefined components.


## What is the main contribution of this paper?

This paper presents a font generation method that combines global and local style representations. The key contributions are:- It proposes to use a similarity-guided global style aggregator (GSA) to capture overall font characteristics like stroke thickness and spacing. The style features of reference glyphs are weighted by their content similarity with the input glyph before aggregation.- It introduces a local style aggregator (LSA) to transfer fine-grained styles to self-learned components from vector quantization, without requiring predefined components. A cross-attention module is used to efficiently transfer styles to all components in one forward pass. - The global and local representations are combined with the content features for font generation. This allows capturing both the intra-style consistent properties and intra-style inconsistent details.- Experiments show the method achieves state-of-the-art results for few-shot font generation on Chinese characters. It also demonstrates good generalization to other scripts like English and Japanese.In summary, the key contribution is a hybrid global and local style transfer approach for few-shot font generation, which achieves strong results by leveraging complementary representations. The self-learned components and efficient style transfer via cross-attention are also notable features.
