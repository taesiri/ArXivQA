# [SubGen: Token Generation in Sublinear Time and Memory](https://arxiv.org/abs/2402.06082)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) require storing all previous tokens and their embeddings to generate new tokens in an autoregressive manner. This leads to a linear growth in memory and computation time as the sequence length increases. 
- There is a need for efficient methods to compress the cached key-value (KV) pairs from previous tokens while retaining the accuracy of LLMs for long context token generation.

Key Idea:
- Empirically observe that the key embeddings from the attention mechanism demonstrate a clustering pattern, unlike the value embeddings.
- Propose a streaming clustering algorithm called SubGen to efficiently find representative clusters and samples for compressing the KV cache.  

Proposed Method:
- Maintain a subsample of keys from each cluster found online using ideas from streaming k-center clustering.
- Additionally sample value embeddings based on their squared norms using reservoir sampling.  
- Use the subsampled keys and values to estimate the attention output.
- Analyze SubGen rigorously and show approximation guarantees under assumptions on clustering of keys and bounded query norms.

Main Contributions:
- Develop SubGen, first KV compression algorithm for LLMs with formally proven sublinear time and memory complexity.
- Empirically demonstrate the clusterability of key embeddings in LLMs over long context.
- Evaluate SubGen on long sequence tasks and show improved accuracy over prior KV compression methods under same memory budget.
