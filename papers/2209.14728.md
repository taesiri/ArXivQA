# [Dependent Bayesian Lenses: Categories of Bidirectional Markov Kernels   with Canonical Bayesian Inversion](https://arxiv.org/abs/2209.14728)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main research contributions of this paper appear to be:- Proposing a modified definition of Bayesian inversion in a Markov category using the notion of support objects, which gives unique Bayesian inverses.- Developing the theory of support objects and Bayesian inversion with supports in a Markov category.- Defining dependent Bayesian lenses, where the backwards object depends on a choice of prior over the forwards object. This is motivated by considering families of support objects indexed by priors.- Constructing the category of dependent Bayesian lenses as a Grothendieck construction over an indexed category of families of supports. - Showing this category has a section mapping morphisms to their canonical Bayesian inverses between support objects.So in summary, the central focus seems to be on developing a framework of dependent Bayesian lenses that allows for canonical Bayesian inversion relative to arbitrary priors in a Markov category. The key ideas are using support objects to get uniqueness and indexing over priors to get well-defined inversion. The overall goal appears to be equipping Markov categories with additional structure for studying Bayesian inversion and stochastic maps in a lens-like fashion.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper seem to be:- Proposing a modified definition of a Bayesian inverse in a Markov category using the notion of a "support object". This allows Bayesian inverses between support objects to be unique, giving a canonical Bayesian inversion functor.- Defining "dependent Bayesian lenses", a generalization of Bayesian lenses where the backward object can depend on a choice of distribution over the forward object. This allows modeling systems with families of Bayesian inverses parameterized by the prior.- Constructing the category of dependent Bayesian lenses in terms of families of support objects, indexed by the priors they depend on. This provides motivation for the definition and the "dependent" terminology.- Showing that the category of dependent Bayesian charts (a stepping stone to the lenses) has an oplax monoidal section embedding the base Markov category. Similarly, dependent Bayesian lenses have a lax monoidal section for Bayesian inversion.- Giving examples of Markov categories with supports for all distributions.So in summary, the main contributions seem to be proposing modified categorical definitions to allow canonical Bayesian inversion functors and parameterization by priors, developing the theory connecting this to families of support objects, and showing how this all fits together categorically.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a definition of dependent Bayesian lenses, which are a generalization of Bayesian lenses that allow the backwards object to depend on a choice of prior over the forwards object; this provides a setting to model stochastic processes with canonical Bayesian inversion restricted to points supported by a given prior.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other related research:- The paper focuses on generalizing the concept of lenses (bidirectional transformations) to stochastic/probabilistic settings. Most existing work on lenses has focused on deterministic transformations between data types. Extending lenses to the probabilistic setting is an interesting direction.- The paper takes a categorical approach to modeling probabilistic bidirectional transformations, using concepts like Markov categories and Bayesian inversion. Other related work has modeled probabilistic bidirectional programs more operationally. For example, some papers have proposed probabilistic bidirectional programming languages. The categorical approach here feels more foundational.- The core idea is extending Bayesian lenses, as defined in previous work by Smithe, to allow for dependencies between the forward and backward objects. This seems like a natural generalization that increases the expressiveness. - The paper leverages concepts like support objects, indexed categories, and the families fibration to motivate and define the extension to dependent Bayesian lenses. The connections drawn to dependent type theory are insightful.- Compared to related work on probabilistic bidirectional transformations, this paper stands out in its focus on finding canonical/natural notions of inversion in this setting. The uniqueness results for inverses between support objects are nice.- Overall, the categorical viewpoint and the goal of finding canonical inverses give this paper a somewhat different flavor from other related work. The connections made to concepts in applied category theory like dynamical systems also help distinguish it. The dependent Bayesian lenses proposed seem like a useful advancement of the theory in this area.


## What future research directions do the authors suggest?

Based on my reading, some of the main future research directions suggested by the authors include:- Investigating how Bayesian lenses can be used to formulate Bayesian filtering algorithms as stochastic dynamical systems. They mention this could build on previous work using probability monads for Markov decision processes.- Designing probabilistic programming languages with semantics given by Bayesian lenses, to allow for automatic Bayesian inversion. The authors suggest exploring languages exposing more of the structure of Bayesian lenses compared to just automatic inversion.- Representing Bayesian lenses as dependent optics, to get a more operationally useful perspective compared to representing them as functor lenses.- Finding more examples of Markov categories with support objects and Bayesian inversion, beyond the examples of finite stochastic relations and Gaussians mentioned. The authors want to find other useful categories of "nice" measure spaces or distributions.So in summary, the main suggestions are around further applications in stochastic/Bayesian modeling, probabilistic programming languages, relationships to dependent optics, and finding more conceptual examples of categories with the required structure. The authors seem interested in both practical applications and further theoretical understanding.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper proposes a modified definition of Bayesian inversion in a Markov category using the notion of support objects, based on a definition by Fritz. It shows that Bayesian inverses between support objects are unique, unlike regular Bayesian inverses, giving a canonical Bayesian inversion functor. To accommodate this new definition, the authors propose dependent Bayesian lenses, where the backwards object depends on a distribution over the forwards object. They motivate this by first considering families of support objects indexed by priors, formalized as an indexed category using the families fibration. This justifies calling them dependent lenses, by analogy with uses of the family fibration in dependent type theory. The paper develops the definition and properties of dependent Bayesian lenses, showing they have a canonical Bayesian inversion section embedding the Markov category.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:This paper proposes a modified definition for a Bayesian inverse in a Markov category using a notion of support object, based on a definition by Fritz. In a Markov category, the usual definition of a Bayesian inverse only specifies the inverse up to almost-sure equality. However, with support objects, Bayesian inverses between support objects are unique. To accommodate this new definition, the authors propose a definition for dependent Bayesian lenses where the backward object depends on a choice of distribution over the forward object. Rather than directly modifying the existing definition of Bayesian lenses, the authors motivate their definition by first considering families of support objects, indexed by the collection of all possible priors. They formalize this using the family fibration, obtaining an indexed category resembling the construction used for standard Bayesian lenses. This not only gives a way to define an indexed category for Bayesian lenses, but also justifies calling them dependent lenses by analogy with uses of the family fibration in dependent type theory. The authors show these dependent Bayesian lenses have a section sending morphisms to their canonical inverses between supports.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper:The paper introduces dependent Bayesian lenses, which generalize the concept of Bayesian lenses developed in previous work. The key idea is allowing the backward object in a lens to depend on a choice of distribution (interpreted as a prior) over the forward object. To motivate and justify this definition, the authors first construct an indexed category of families of support objects, indexed by priors. They show this category has a canonical embedding of the original Markov category mapping objects to families of their support objects. Taking the opposite fibres gives the definition of dependent Bayesian lenses. Thus the main method is using categorical constructions on indexed categories (specifically the families fibration and Grothendieck construction) to systematically derive the proposed definition of dependent Bayesian lenses from the concept of families of support objects.


## What problem or question is the paper addressing?

According to the abstract, the paper is addressing the problem that Bayesian inverses are not unique in Markov categories. Specifically:- In a Markov category, the abstract definition for Bayesian inversion does not uniquely specify a morphism because it allows the behavior to be arbitrary on points not supported by the prior.- This means that any embedding of a Markov category into a category of Bayesian lenses requires making coherent choices of inverses for each morphism-prior pair. To address this, the paper proposes:- A modified definition of Bayesian inverse in a Markov category using a notion of "support object". With support objects, Bayesian inverses are unique.- A definition of "dependent Bayesian lenses" where the backward object depends on a choice of distribution over the forward object. This allows working with inversion at arbitrary priors.- Constructing dependent Bayesian lenses by first considering families of support objects indexed by priors. This is formalized as an indexed category and connects to the use of the family fibration in dependent type theory.So in summary, the main problem is the non-uniqueness of Bayesian inverses in Markov categories, and the paper aims to address this by using support objects and constructing a category of dependent Bayesian lenses where inversion can be studied at arbitrary priors.
