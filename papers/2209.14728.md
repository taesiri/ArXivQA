# [Dependent Bayesian Lenses: Categories of Bidirectional Markov Kernels   with Canonical Bayesian Inversion](https://arxiv.org/abs/2209.14728)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the main research contributions of this paper appear to be:

- Proposing a modified definition of Bayesian inversion in a Markov category using the notion of support objects, which gives unique Bayesian inverses.

- Developing the theory of support objects and Bayesian inversion with supports in a Markov category.

- Defining dependent Bayesian lenses, where the backwards object depends on a choice of prior over the forwards object. This is motivated by considering families of support objects indexed by priors.

- Constructing the category of dependent Bayesian lenses as a Grothendieck construction over an indexed category of families of supports. 

- Showing this category has a section mapping morphisms to their canonical Bayesian inverses between support objects.

So in summary, the central focus seems to be on developing a framework of dependent Bayesian lenses that allows for canonical Bayesian inversion relative to arbitrary priors in a Markov category. The key ideas are using support objects to get uniqueness and indexing over priors to get well-defined inversion. The overall goal appears to be equipping Markov categories with additional structure for studying Bayesian inversion and stochastic maps in a lens-like fashion.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper seem to be:

- Proposing a modified definition of a Bayesian inverse in a Markov category using the notion of a "support object". This allows Bayesian inverses between support objects to be unique, giving a canonical Bayesian inversion functor.

- Defining "dependent Bayesian lenses", a generalization of Bayesian lenses where the backward object can depend on a choice of distribution over the forward object. This allows modeling systems with families of Bayesian inverses parameterized by the prior.

- Constructing the category of dependent Bayesian lenses in terms of families of support objects, indexed by the priors they depend on. This provides motivation for the definition and the "dependent" terminology.

- Showing that the category of dependent Bayesian charts (a stepping stone to the lenses) has an oplax monoidal section embedding the base Markov category. Similarly, dependent Bayesian lenses have a lax monoidal section for Bayesian inversion.

- Giving examples of Markov categories with supports for all distributions.

So in summary, the main contributions seem to be proposing modified categorical definitions to allow canonical Bayesian inversion functors and parameterization by priors, developing the theory connecting this to families of support objects, and showing how this all fits together categorically.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a definition of dependent Bayesian lenses, which are a generalization of Bayesian lenses that allow the backwards object to depend on a choice of prior over the forwards object; this provides a setting to model stochastic processes with canonical Bayesian inversion restricted to points supported by a given prior.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other related research:

- The paper focuses on generalizing the concept of lenses (bidirectional transformations) to stochastic/probabilistic settings. Most existing work on lenses has focused on deterministic transformations between data types. Extending lenses to the probabilistic setting is an interesting direction.

- The paper takes a categorical approach to modeling probabilistic bidirectional transformations, using concepts like Markov categories and Bayesian inversion. Other related work has modeled probabilistic bidirectional programs more operationally. For example, some papers have proposed probabilistic bidirectional programming languages. The categorical approach here feels more foundational.

- The core idea is extending Bayesian lenses, as defined in previous work by Smithe, to allow for dependencies between the forward and backward objects. This seems like a natural generalization that increases the expressiveness. 

- The paper leverages concepts like support objects, indexed categories, and the families fibration to motivate and define the extension to dependent Bayesian lenses. The connections drawn to dependent type theory are insightful.

- Compared to related work on probabilistic bidirectional transformations, this paper stands out in its focus on finding canonical/natural notions of inversion in this setting. The uniqueness results for inverses between support objects are nice.

- Overall, the categorical viewpoint and the goal of finding canonical inverses give this paper a somewhat different flavor from other related work. The connections made to concepts in applied category theory like dynamical systems also help distinguish it. The dependent Bayesian lenses proposed seem like a useful advancement of the theory in this area.


## What future research directions do the authors suggest?

 Based on my reading, some of the main future research directions suggested by the authors include:

- Investigating how Bayesian lenses can be used to formulate Bayesian filtering algorithms as stochastic dynamical systems. They mention this could build on previous work using probability monads for Markov decision processes.

- Designing probabilistic programming languages with semantics given by Bayesian lenses, to allow for automatic Bayesian inversion. The authors suggest exploring languages exposing more of the structure of Bayesian lenses compared to just automatic inversion.

- Representing Bayesian lenses as dependent optics, to get a more operationally useful perspective compared to representing them as functor lenses.

- Finding more examples of Markov categories with support objects and Bayesian inversion, beyond the examples of finite stochastic relations and Gaussians mentioned. The authors want to find other useful categories of "nice" measure spaces or distributions.

So in summary, the main suggestions are around further applications in stochastic/Bayesian modeling, probabilistic programming languages, relationships to dependent optics, and finding more conceptual examples of categories with the required structure. The authors seem interested in both practical applications and further theoretical understanding.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper proposes a modified definition of Bayesian inversion in a Markov category using the notion of support objects, based on a definition by Fritz. It shows that Bayesian inverses between support objects are unique, unlike regular Bayesian inverses, giving a canonical Bayesian inversion functor. To accommodate this new definition, the authors propose dependent Bayesian lenses, where the backwards object depends on a distribution over the forwards object. They motivate this by first considering families of support objects indexed by priors, formalized as an indexed category using the families fibration. This justifies calling them dependent lenses, by analogy with uses of the family fibration in dependent type theory. The paper develops the definition and properties of dependent Bayesian lenses, showing they have a canonical Bayesian inversion section embedding the Markov category.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper proposes a modified definition for a Bayesian inverse in a Markov category using a notion of support object, based on a definition by Fritz. In a Markov category, the usual definition of a Bayesian inverse only specifies the inverse up to almost-sure equality. However, with support objects, Bayesian inverses between support objects are unique. To accommodate this new definition, the authors propose a definition for dependent Bayesian lenses where the backward object depends on a choice of distribution over the forward object. 

Rather than directly modifying the existing definition of Bayesian lenses, the authors motivate their definition by first considering families of support objects, indexed by the collection of all possible priors. They formalize this using the family fibration, obtaining an indexed category resembling the construction used for standard Bayesian lenses. This not only gives a way to define an indexed category for Bayesian lenses, but also justifies calling them dependent lenses by analogy with uses of the family fibration in dependent type theory. The authors show these dependent Bayesian lenses have a section sending morphisms to their canonical inverses between supports.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper introduces dependent Bayesian lenses, which generalize the concept of Bayesian lenses developed in previous work. The key idea is allowing the backward object in a lens to depend on a choice of distribution (interpreted as a prior) over the forward object. To motivate and justify this definition, the authors first construct an indexed category of families of support objects, indexed by priors. They show this category has a canonical embedding of the original Markov category mapping objects to families of their support objects. Taking the opposite fibres gives the definition of dependent Bayesian lenses. Thus the main method is using categorical constructions on indexed categories (specifically the families fibration and Grothendieck construction) to systematically derive the proposed definition of dependent Bayesian lenses from the concept of families of support objects.


## What problem or question is the paper addressing?

 According to the abstract, the paper is addressing the problem that Bayesian inverses are not unique in Markov categories. Specifically:

- In a Markov category, the abstract definition for Bayesian inversion does not uniquely specify a morphism because it allows the behavior to be arbitrary on points not supported by the prior.

- This means that any embedding of a Markov category into a category of Bayesian lenses requires making coherent choices of inverses for each morphism-prior pair. 

To address this, the paper proposes:

- A modified definition of Bayesian inverse in a Markov category using a notion of "support object". With support objects, Bayesian inverses are unique.

- A definition of "dependent Bayesian lenses" where the backward object depends on a choice of distribution over the forward object. This allows working with inversion at arbitrary priors.

- Constructing dependent Bayesian lenses by first considering families of support objects indexed by priors. This is formalized as an indexed category and connects to the use of the family fibration in dependent type theory.

So in summary, the main problem is the non-uniqueness of Bayesian inverses in Markov categories, and the paper aims to address this by using support objects and constructing a category of dependent Bayesian lenses where inversion can be studied at arbitrary priors.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper abstract, some keywords or key terms associated with this paper are:

- Dependent Bayesian lenses
- Bidirectional Markov kernels
- Bayesian inversion 
- Support objects
- Markov categories
- Indexed categories
- Families fibration
- Stochastic maps

The paper proposes a definition of "dependent Bayesian lenses", which are a generalization of Bayesian lenses to allow the backwards object to depend on a distribution over the forwards object. This provides a framework to study stochastic maps with Bayesian inverses restricted to points supported by a given prior. The paper develops the idea of "support objects" in a Markov category to give a more canonical notion of Bayesian inversion. It motivates and justifies the definition of dependent Bayesian lenses using indexed categories and the families fibration from type theory. Overall, the key focus seems to be on developing categories of lenses that can model probabilistic bidirectional transformations, while also capturing a notion of Bayesian inversion more suited for stochastic settings.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to ask to create a comprehensive summary of the paper:

1. What is the motivation for studying dependent Bayesian lenses? Why are existing lens frameworks like optics insufficient?

2. What is the definition of a Markov category? What key concepts can be defined abstractly in a Markov category?

3. What is a support object in a Markov category? How does it help define Bayesian inversion more canonically? 

4. How are families of support objects defined, using the families fibration? What is the resulting indexed category of Bayesian charts?

5. How does the category of Bayesian charts embed the original Markov category via a section? What structure does this section preserve?

6. How are dependent Bayesian lenses defined from Bayesian charts? How do they differ from existing Bayesian lenses?

7. What is the relationship between the indexed categories defining ordinary and dependent Bayesian lenses?

8. How do dependent Bayesian lenses also embed the original Markov category via a section picking out canonical inverses?

9. What is the monoidal structure on dependent Bayesian lenses? Why does the inversion section fail to preserve copying?

10. How does the inverse of copying interact with the monoidal structure? What does this say about the types of processes modeled?

Asking these types of targeted questions about the key concepts, definitions, results, and relationships covered in the paper will help create a comprehensive summary. Let me know if you need any clarification on these suggested questions!


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes using support objects and families of support objects to create a canonical Bayesian inversion functor. How does this approach compare to other methods for defining Bayesian inversion functors, such as using almost-sure equivalence classes? What are the advantages and disadvantages?

2. The paper defines dependent Bayesian lenses using an indexed category built from the family fibration. How does this approach relate dependent Bayesian lenses back to other formulations of lenses and optics? Does it provide new insight into the meaning of "dependence" for lenses?

3. The monoidal structure defined on Bayesian charts is used to show the inversion functor preserves comonoids. Could a different monoidal product be defined that would allow the inversion functor to preserve monoids instead? What would be the implications?

4. What conditions on the underlying Markov category are necessary and/or sufficient for the construction of support objects and families of support objects to work? Can you give examples of categories that do or do not satisfy these conditions?

5. The paper claims the inversion functor provides a canonical choice of Bayesian inverse. But doesn't this depend on the choice of support objects? How much does the construction depend on this choice?

6. How does the relationship between Bayesian charts and Bayesian lenses compare to the relationship between dynamical systems and signal-flow graphs? Do the connections go deeper than just both being fiberwise duals?

7. What implications does the use of the family fibration have on the interpretation of "dependence" for Bayesian lenses? Does it relate to other notions of dependence in probability and statistics?

8. Can the constructions in this paper be extended to other variants of Markov categories, such as Markov categories with zero morphisms or continuous Markov categories? Would the results still hold?

9. The motivation of the paper is studying systems with Bayesian updating. What specific examples of Bayesian inverse problems could be modeled with the dependent Bayesian lenses proposed here?

10. What extensions or variations of this construction could be useful? For example, could it be adapted for modeling conditional independence or causal structures in Bayesian networks?
