# [Stable-Makeup: When Real-World Makeup Transfer Meets Diffusion Model](https://arxiv.org/abs/2403.07764)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing makeup transfer methods rely heavily on GANs and struggle to handle the diversity of real-world makeup styles, especially for transferring high-detailed and creative makeup looks. This limits their applicability and effectiveness. There is also a shortage of diverse makeup datasets to support research in this area. 

Method - Stable-Makeup:
The paper proposes Stable-Makeup, a novel diffusion-based makeup transfer approach, representing the first work to apply diffusion models for makeup transfer. Stable-Makeup comprises three key components:

1) Detail-Preserving Makeup Encoder: Uses a multi-layer strategy with a CLIP backbone to extract multi-scale, spatial-aware makeup features to preserve intricate details. 

2) Makeup Cross-Attention Layers: Aligns the extracted makeup embeddings with intermediate features of the face region in source image at different layers in the U-Net to enable accurate makeup transfer.

3) Content & Structural Control Modules: Encodes content and structural information from source image via two ControlNets to preserve content and structure consistency.

Through a specially designed data pipeline, a diverse paired dataset of 20K images is constructed covering various makeup styles. After content-structure decoupling training on this dataset, Stable-Makeup can further maintain content and facial structure consistency.

Contributions:
- First diffusion-based makeup transfer method with state-of-the-art performance. Demonstrates high robustness for transferring diverse and heavy makeup styles.
- Detail-preserving makeup encoder and makeup cross-attention layers accurately transfer intricate makeup details.
- Automatic pipeline to construct a high-quality, diverse dataset of 20K image pairs. 
- Content-structure decoupling training strategy to better maintain facial structure.
- Broad applicability demonstrated via cross-domain makeup transfer, makeup-guided text-to-image generation etc.

In summary, Stable-Makeup significantly pushes boundaries of makeup transfer via a novel diffusion-based approach and tailored training strategy, with substantial improvements in transfer quality and diversity.
