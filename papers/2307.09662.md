# [Object-aware Gaze Target Detection](https://arxiv.org/abs/2307.09662)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to perform gaze target detection in an explainable manner by modeling the relationship between people's heads and gazed objects in the scene. The key hypotheses are:1) Modeling head-object interactions and relationships will improve gaze target detection performance compared to just using holistic scene features or cropped head images.2) Detecting, localizing, and classifying gazed objects in addition to predicting gaze heatmaps will enable more explainable gaze analysis. 3) A Transformer-based architecture can effectively model head-object relationships and simultaneously perform gaze heatmap regression and objected detection/classification for explainable gaze target analysis.In summary, the main goal is to develop a gaze target detection method that not only accurately predicts where people are looking but also explains the predictions by identifying which objects people are looking at. This is in contrast to prior work which focuses only on predicting gaze heatmaps without explicitly modeling object interactions.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a novel object-oriented gaze target detection method based on a Transformer architecture. 2. The model can automatically detect heads and objects in the scene and build associations between each head and the gazed object/head. This allows for explainable gaze analysis by predicting the gaze target area, gaze pixel point, class of gazed object, and bounding box of gazed object. 3. The method achieves state-of-the-art performance on standard gaze target detection benchmarks like GazeFollow and VideoAttentionTarget. It improves AUC by up to 2.91%, reduces gaze distance by 50%, and increases out-of-frame AP by 9% compared to prior work.4. The model also shows 11-13% improvement in AP for gazed object classification and localization compared to using an off-the-shelf object detector. 5. The proposed gaze cone predictor and gaze object transformer modules are shown to be important components through ablation studies.6. The method performs well even in cases of high variance across multiple gaze annotations for the same image.7. Code is made publicly available to facilitate further research.In summary, the key contribution is a new Transformer-based architecture for object-aware gaze target detection that achieves state-of-the-art performance and provides more explainable gaze analysis by detecting relevant objects like heads and modeling their relationships. The object-oriented design and components like the gaze cone predictor and transformer are critical to the method's success.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a Transformer-based architecture for gaze target detection that detects objects (including heads) to build associations between heads and gazed objects, enabling the prediction of the gaze area, gaze pixel point, gazed object class and location, and whether the gaze point is out of frame, achieving state-of-the-art performance.
