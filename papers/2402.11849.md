# [ComFusion: Personalized Subject Generation in Multiple Specific Scenes   From Single Image](https://arxiv.org/abs/2402.11849)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper proposes a novel method called ComFusion for personalized text-to-image generation that can effectively synthesize subject instances in multiple distinct scenes specified by textual prompts. 

Problem: 
Existing personalized text-to-image generation methods often struggle to simultaneously maintain high fidelity to the subject instance while accurately depicting the scene described in the text prompt. They tend to suffer from issues like "language drift" which causes loss of scene details, and "catastrophic forgetting" which leads to poor instance fidelity.

Proposed Solution - ComFusion:
ComFusion introduces two key components to address the limitations of prior arts:

1) Composite Stream with Class-Scene Prior Loss: By generating images combining both subject class and specific scene texts, this loss preserves knowledge of both the instance class and textual scenes during finetuning. This enhances scene fidelity.  

2) Fusion Stream with Visual-Textual Matching Loss: This loss brings the instance visual features and scene textual semantics closer in the encoded space by reconstructing images guided by instance-scene text. It balances instance and scene fidelity.

Together these two streams composite instance class with scene knowledge while fusing visual and textual information effectively.

Main Contributions:
- Proposes a new finetuning strategy for personalized text-to-image generation to balance instance and scene fidelity
- Introduces class-scene prior loss to alleviate language drift and enhance scene details
- Uses visual-textual matching loss to fuse instance visual and scene textual information

Experiments show ComFusion generates images with higher quality, better instance fidelity and scene consistency compared to state-of-the-arts. The method advances personalized text-to-image generation with a single image across diverse scenes.
