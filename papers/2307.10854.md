# [BlendFace: Re-designing Identity Encoders for Face-Swapping](https://arxiv.org/abs/2307.10854)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we design an identity encoder that provides well-disentangled identity features for face swapping in order to reduce identity-attribute entanglements caused by biases in commonly used face recognition models?The key hypothesis appears to be that training a face recognition model like ArcFace on blended/swapped face images, where attributes are replaced with those of other individuals, will allow the model to focus less on extraneous attributes and provide more disentangled identity features. This identity encoder, which they call BlendFace, can then be incorporated into face swapping models to achieve better disentanglement of identity and attributes.In summary, the central research question is how to create a better identity encoder for face swapping that avoids inherent biases and entanglements caused by standard face recognition models like ArcFace. The core hypothesis is that training on blended/swapped faces can reduce dependence on attributes.


## What is the main contribution of this paper?

Based on my reading, the main contribution of this paper is proposing a novel identity encoder called BlendFace for more consistent and disentangled face swapping. The key ideas are:- Analyzing and showing that traditional face recognition models like ArcFace have inherent biases towards certain facial attributes like hairstyle, color, head shape etc. This causes identity-attribute entanglement in face swapping when using these models.- Designing BlendFace by pre-training ArcFace on blended/synthetic images with swapped attributes. This removes the biases and enables the model to focus only on inner facial features for identity encoding. - Incorporating BlendFace as the identity encoder and loss function in a face swapping model. This improves disentanglement of identity and attributes during face swapping.- Demonstrating through experiments that BlendFace outperforms previous state-of-the-art methods in preserving attributes like pose, gaze etc. while maintaining identity similarity. It also improves visual consistency of swapped results.In summary, the main contribution is proposing a novel bias-free identity encoder BlendFace that enables more disentangled and consistent face swapping when integrated into existing models. The key ideas are pre-training with blended images and using it for both identity encoding and loss computation during face swapping.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new identity encoder called BlendFace for face swapping that is trained on blended images to remove attribute biases, resulting in better disentanglement of identity and attributes compared to using standard face recognition models like ArcFace.
