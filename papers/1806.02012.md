# [A Peek Into the Hidden Layers of a Convolutional Neural Network Through   a Factorization Lens](https://arxiv.org/abs/1806.02012)

## What is the central research question or hypothesis that this paper addresses?

 The central research question addressed in this paper is: 

Given an already trained deep neural network and a set of test inputs, how can we gain insight into how those inputs interact with different layers of the neural network? And can we characterize a deep neural network based on its observed behavior on different inputs?

The key hypothesis is that by jointly factorizing the raw inputs to the deep neural network and the outputs of each layer to the same low-dimensional space, we can identify commonalities in the input data and how those are processed through the network. This factorization approach may reveal insights about the network's operations and quality of training.

In summary, the paper aims to provide interpretations and visualizations of a deep neural network's internal representations and operations by analyzing a joint factorization of the inputs and layer outputs. The central hypothesis is that the factorization can reveal meaningful patterns linking inputs to hidden layers.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing a novel problem formulation and modeling approach to provide insights into a deep neural network via joint factorization of the raw inputs and outputs of each layer. 

2. Conducting experimental case studies that reveal a pattern linking the rank of the joint factorization to the quality of the network training. Lower rank is associated with poorer training. This pattern is identified without using labels for the test data.

3. Providing a visualization tool that sheds light into how different high-level patterns in the input data traverse the hidden layers of the network. 

In summary, the paper introduces a new factorization-based method to characterize and visualize how inputs interact with the different layers of a deep neural network. The key insight is that joint factorization of inputs and layer outputs can reveal training quality and patterns in a completely unsupervised manner.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a new factorization-based method to gain insights into how test inputs interact with different layers of a deep neural network and characterize the network based on its behavior, identifying links between the factorization rank and training quality without using labels.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other research in interpreting and analyzing deep neural networks:

- The idea of using joint factorization to relate inputs and hidden layer representations is novel. Most prior work has focused on visualizing/interpreting individual layers, but not through a joint factorization lens. This provides a new approach to gain insight into how inputs are transformed through the network.

- Relating factorization rank to network training quality is an interesting finding. It provides a quantitative measure, without needing labels, that correlates with how well the network was trained. Other works have tried to interpret networks via visualization or alignment with human concepts, but not through rank.

- The visualization of how latent factors of the input traverse the network is similar to feature visualization techniques from prior works like Olah et al. But it provides visualizations tied to the joint factorization with the input, rather than optimizing inputs for individual units.

- Raghu et al. also analyzed hidden layers jointly with CCA, but did not relate them back to the input data. This work ties the internal network analysis directly to the inputs.

- Sedghi et al. analyzed singular values for regularization and model selection. This paper relates singular value spectra to training quality and visualization. 

- Overall, the joint factorization view provides a new lens for understanding these models. The patterns relating rank to training quality are novel empirical findings. And the method subsumes some prior visualization techniques. The work is still preliminary but introduces a promising new framework for interpreting neural networks.

In summary, the core ideas and findings seem unique compared to prior research in this problem space. The factorization view and qualitative patterns are novel contributions that open up new directions for understanding deep neural networks.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Extending the joint factorization model to leverage higher-order correlations via tensor modeling. The current model only captures pairwise relationships between the input data and layer activations. Using tensors could help capture more complex multivariate relationships.

- Further investigating whether the link between factorization rank and training quality holds more generally across different network architectures, datasets, etc. The authors currently only demonstrate this on a simple CNN architecture for MNIST and CIFAR-10.

- Expanding the visualization capabilities to provide more insights into how input patterns propagate through the network layers. The authors provide some preliminary visualizations but suggest this can be expanded.

- Applying the approach to additional domains beyond image classification, such as natural language processing, recommendation systems, etc. The current work focuses on image data but the general approach could extend elsewhere.

- Exploring modifications and extensions to the joint factorization objective function. The current model is a basic coupled NMF but other formulations could be studied.

- Leveraging the rank-quality relation for neural network debugging, regularization, hyperparameter optimization, and other applications. The authors suggest the rank could be used as an unsupervised metric.

In summary, the main future directions are developing the factorization framework further, validating it more thoroughly, enhancing the visualizations, and applying the approach to new problem domains and applications. The authors lay out some promising initial results to build on.


## Summarize the paper in one paragraph.

 The paper proposes a novel factorization-based approach to gain insights into how test inputs interact with different layers of a pre-trained deep neural network, and to characterize the network based on its behavior on different inputs. The key idea is to jointly factorize the raw inputs and outputs of each layer into a shared low-dimensional space to identify commonalities and correlations. Three case studies on MNIST and CIFAR-10 using CNNs reveal that the rank of the joint factorization is linked to how well the network was trained, without needing test labels. Lower rank indicates poorer training. The method also provides visualizations showing how parts of inputs propagate through the network. In summary, the paper introduces a new factorization viewpoint to peek into the hidden layers of CNNs, relate training quality and factorization rank, and visualize input patterns traversing the layers.


## Summarize the paper in two paragraphs.

 Here is a 2 paragraph summary of the key points from the paper:

Paragraph 1: This paper proposes a novel method to gain insights into how inputs interact with the hidden layers of a trained deep neural network. The key idea is to jointly factorize the raw inputs and the outputs of each layer into a shared low-dimensional space. This joint factorization seeks to identify common patterns in the input data and how those patterns are processed through the network layers. For example, with an image classifier it could identify shapes like circles that appear in multiple classes, and see how layers respond to those shapes across images. The authors use this approach in three case studies, training a CNN on MNIST in various problematic ways. The rank of the joint factorization, measuring how much structure is captured, correlates with the quality of the network training. This shows their method can characterize network training quality without using the test labels. 

Paragraph 2: The main contributions are: (1) a novel formulation to provide insights into deep networks via joint factorization, (2) experiments showing the rank correlates to training quality, revealing issues without labels, (3) a visualization tool that illustrates how parts of the input data flow through the network layers. The preliminary results demonstrate the promise of using factorization to interpret neural networks. Key limitations are that it is applied only to small CNNs on MNIST currently. Future work includes extending to larger and deeper networks and datasets. The visualizations also need further development. Overall this is an interesting new direction for understanding deep network representations and computations through factorization.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes a novel factorization-based approach to gain insight into how test inputs interact with different layers of a pre-trained deep neural network. The key idea is to jointly factorize the raw input images and the outputs of each hidden layer into a common low-dimensional space. This joint factorization seeks to identify shared latent factors between the inputs and layer outputs, such as common shapes or patterns across different input classes and how layers collectively process those patterns. Specifically, the raw input images and layer outputs are arranged as matrices and coupled non-negative matrix factorization is applied to find a joint low-rank approximation. The coupling matrix propagates information between the input and output factorizations to reveal correlations between how layers respond to similar high-level patterns in varied inputs. This approach provides a way to analyze and visualize how parts of the input data pass through the hidden layers of the network.
