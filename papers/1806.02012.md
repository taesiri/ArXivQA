# A Peek Into the Hidden Layers of a Convolutional Neural Network Through   a Factorization Lens

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is: Given an already trained deep neural network and a set of test inputs, how can we gain insight into how those inputs interact with different layers of the neural network? And can we characterize a deep neural network based on its observed behavior on different inputs?The key hypothesis is that by jointly factorizing the raw inputs to the deep neural network and the outputs of each layer to the same low-dimensional space, we can identify commonalities in the input data and how those are processed through the network. This factorization approach may reveal insights about the network's operations and quality of training.In summary, the paper aims to provide interpretations and visualizations of a deep neural network's internal representations and operations by analyzing a joint factorization of the inputs and layer outputs. The central hypothesis is that the factorization can reveal meaningful patterns linking inputs to hidden layers.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Proposing a novel problem formulation and modeling approach to provide insights into a deep neural network via joint factorization of the raw inputs and outputs of each layer. 2. Conducting experimental case studies that reveal a pattern linking the rank of the joint factorization to the quality of the network training. Lower rank is associated with poorer training. This pattern is identified without using labels for the test data.3. Providing a visualization tool that sheds light into how different high-level patterns in the input data traverse the hidden layers of the network. In summary, the paper introduces a new factorization-based method to characterize and visualize how inputs interact with the different layers of a deep neural network. The key insight is that joint factorization of inputs and layer outputs can reveal training quality and patterns in a completely unsupervised manner.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new factorization-based method to gain insights into how test inputs interact with different layers of a deep neural network and characterize the network based on its behavior, identifying links between the factorization rank and training quality without using labels.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in interpreting and analyzing deep neural networks:- The idea of using joint factorization to relate inputs and hidden layer representations is novel. Most prior work has focused on visualizing/interpreting individual layers, but not through a joint factorization lens. This provides a new approach to gain insight into how inputs are transformed through the network.- Relating factorization rank to network training quality is an interesting finding. It provides a quantitative measure, without needing labels, that correlates with how well the network was trained. Other works have tried to interpret networks via visualization or alignment with human concepts, but not through rank.- The visualization of how latent factors of the input traverse the network is similar to feature visualization techniques from prior works like Olah et al. But it provides visualizations tied to the joint factorization with the input, rather than optimizing inputs for individual units.- Raghu et al. also analyzed hidden layers jointly with CCA, but did not relate them back to the input data. This work ties the internal network analysis directly to the inputs.- Sedghi et al. analyzed singular values for regularization and model selection. This paper relates singular value spectra to training quality and visualization. - Overall, the joint factorization view provides a new lens for understanding these models. The patterns relating rank to training quality are novel empirical findings. And the method subsumes some prior visualization techniques. The work is still preliminary but introduces a promising new framework for interpreting neural networks.In summary, the core ideas and findings seem unique compared to prior research in this problem space. The factorization view and qualitative patterns are novel contributions that open up new directions for understanding deep neural networks.
