# [Doubly Right Object Recognition: A Why Prompt for Visual Rationales](https://arxiv.org/abs/2212.06202)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: Can computer vision models provide both correct categorical predictions as well as correct explanations (rationales) for their predictions?The key points are:- Existing computer vision models are evaluated only on classification accuracy, not on whether they provide correct explanations for their decisions. - Providing correct explanations is important for trustworthy AI systems, especially in critical applications like healthcare.- Current methods for generating explanations either produce vague saliency maps or require expensive manual annotation of rationales. - The authors propose using language models and web search to automatically collect explanatory rationales at scale.- They introduce a new "doubly right" benchmark that requires models to output both correct categories and rationales.- Experiments show current vision models often provide wrong rationales, even when categories are correct.- A novel "why" prompt is proposed to adapt models to produce better rationales, demonstrated quantitatively and qualitatively.In summary, the central hypothesis is that vision models can be adapted via prompting to produce both correct categorical predictions and explanatory rationales on a large-scale benchmark. The experiments aim to demonstrate this capability.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Introducing the problem of "doubly right" object recognition, where models must predict both the correct category and provide the correct rationale for their prediction. This is posed as a new challenge for visual recognition models.2. Constructing a large-scale benchmark dataset spanning multiple existing image datasets like CIFAR and ImageNet, that contains category labels and rationale annotations. This allows quantitative evaluation of models on the doubly right task.3. Proposing a method to transfer reasoning knowledge from language models to visual models via prompt learning. Specifically, they use GPT-3 to generate rationales for object categories, then collect paired images using Google search, and finally learn a "why" visual prompt to adapt models like CLIP to produce better rationales.4. Demonstrating quantitative and qualitative improvements on the doubly right recognition task using their prompt learning method, both on their collected datasets and on established datasets like ImageNet. The prompts help reduce cases where models predict the right category but wrong rationale.5. Analyzing the ability to produce hierarchical and multi-level rationales using additional prompting.So in summary, they introduced and constructed a benchmark for this new visually reasoned recognition task, proposed a way to transfer reasoning knowledge from language to vision models via prompting, and demonstrated improvements in rationale generation and doubly right recognition accuracy. The ability to produce better visual rationales in models is posed as an important direction for further progress in visual recognition.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper introduces a new "doubly right" object recognition benchmark where models must predict both the correct object category and provide plausible rationales, showing existing vision models like CLIP often fail this but visual prompts transferring reasoning from language models significantly improves performance.
