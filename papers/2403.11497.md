# [Do CLIPs Always Generalize Better than ImageNet Models?](https://arxiv.org/abs/2403.11497)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing benchmarks for evaluating robustness of vision language models like CLIP are primarily designed for ImageNet models, and may not adequately reflect real-world spurious correlations learned by models pre-trained on web-scale data.
- It is unclear if CLIPs exhibit better robustness to spurious correlations compared to ImageNet models, despite existing evidence suggesting they do. 

Proposed Solution:
- Introduce new real-world dataset "CounterAnimal" specifically designed to quantify reliance of CLIPs on spurious correlations between animals and backgrounds.
- Dataset contains images of 45 animal classes split into "common" (frequent backgrounds) and "counter" (unusual yet plausible backgrounds) groups. 
- Evaluate extensive set of CLIP models with varying backbones and pre-training datasets on CounterAnimal.

Key Findings:
- All CLIP variants exhibit substantial performance drops from common to counter groups, indicating reliance on spurious correlations.
- Surprisingly, ImageNet models are more robust than CLIPs to spurious features in CounterAnimal.  
- Scaling up backbone size improves robustness more than scaling up pre-train data.
- Pre-training on higher quality datasets enhances robustness.  
- Provide theoretical analysis on why contrastive pre-training fails to overcome spurious correlations.

Main Contributions:
- First systematic data curation and robustness benchmark tailored for evaluating spurious correlations in CLIPs
- Challenge common belief that CLIPs generalize better than ImageNet models, show distribution shift remains an open issue
- Present analysis and evidence on multiple factors impacting robustness of CLIPs
- Raise concerns about evaluating web-scale models on ImageNet-based datasets
