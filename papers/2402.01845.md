# [Multi-Armed Bandits with Interference](https://arxiv.org/abs/2402.01845)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- The paper studies the problem of experimentation (A/B testing) with interference, where the outcome of one unit depends on the treatments assigned to other units. This violates the common assumption of no interference. 
- Specifically, it introduces the problem of Multi-Armed Bandits with Interference (MABI), which considers the cumulative rewards over a time horizon. There are $N$ units arranged on a grid, $T$ rounds, and $k$ treatment arms.
- The reward of each unit in each round depends on the assignments of all units, with a decaying interference assumption - namely the interference effect decays with spatial distance between units.
- The goal is to maximize cumulative rewards by judiciously assigning treatments over the $T$ rounds. This is challenging since the reward functions can arbitrarily vary across units and rounds.

Proposed Solution:
- First, it shows switchback policies (which assign all units the same arm in each round) have optimal $\tilde{O}(\sqrt{T})$ expected regret. However, they suffer high variance. 
- To address this, a novel policy is proposed that integrates ideas from adversarial bandits (EXP3-IX algorithm) and causal inference (clustered randomization). Key ideas involve:
  - A Robust Randomized Partition to increase worst-case exposure probabilities. This helps reduce estimator variance.
  - A Horvitz-Thompson-IX estimator that unifies estimators from EXP3-IX and Horvitz-Thompson while allowing heterogeneity.
  - Analysis via concentration inequalities to bound and control variations.

Main Contributions:
- Formulates a novel and challenging MABI problem that connects adversarial bandits and experimentation under interference.
- Provides optimal expected regret policy and lower bound that expected regret cannot improve by considering multiple units. 
- Develops a policy whose regret (i) is optimal in expectation (ii) has high probability bound vanishing in number of units $N$. In contrast, regret of any switchback policy does not vanish in $N$.

The main innovation is in developing techniques to control and leverage variability arising from interference and non-stationarity, while retaining optimality guarantees. This helps bridge the theory and practice of experimentation.
