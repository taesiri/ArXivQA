# [SparseGS: Real-Time 360° Sparse View Synthesis using Gaussian   Splatting](https://arxiv.org/abs/2312.00206)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "SparseGS: Real-Time 360° Sparse View Synthesis using Gaussian Splatting":

Problem:
The paper tackles the problem of novel view synthesis from only a few input views (few-shot view synthesis). This is challenging because with few input views, there are many missing areas of the scene which can lead to artifacts like "floaters" (high-density regions irregularly positioned in space) and "background collapse" (background regions incorrectly rendered closer to camera). These artifacts are particularly problematic in 360° scenes which lack view constraints. Most prior work has focused on neural rendering techniques like Neural Radiance Fields (NeRFs) which can be slow and lack interpretability. 

Proposed Solution:
The paper proposes a technique built on top of 3D Gaussian Splatting which uses an explicit 3D representation of gaussians rather than an implicit neural network. This allows them to introduce a novel "floater pruning" technique which directly identifies and removes floater gaussians causing artifacts. Additionally, they use depth and image generation constraints to regularize the representation.

Key Contributions:
1) A technique to generate coherent 3D gaussian representations for 360° scenes from sparse views 
2) Introduction of an explicit "floater pruning" operator to remove artifacts by editing the 3D representation
3) State-of-the-art performance on few-shot 360° view synthesis with 30.5% better LPIPS than base 3D Gaussian Splatting and 15.6% better than NeRF methods while running in real-time.

The proposed method combines depth priors, generative guidance, and explicit constraints to outperform prior techniques on the task of few-shot novel view synthesis for full 360° scenes. The introduced "floater pruning" in particular helps reduce unwanted artifacts by leveraging the interpretability of the explicit gaussian representation.
