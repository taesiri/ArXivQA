# [The Surprising Effectiveness of Skip-Tuning in Diffusion Sampling](https://arxiv.org/abs/2402.15170)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Diffusion probabilistic models (DPMs) have shown great success in generative modeling of images. The UNet architecture with skip connections is crucial to their performance.  
- However, as sampling steps decrease, the role of UNet gets closer to push-forward transformation from Gaussian to target distribution, which requires high complexity to capture multimodal distributions.
- Skip connections provide shortcuts from encoder to decoder in UNet, potentially limiting its capacity for few-shot sampling.

Proposed Solution:
- Introduce Skip-Tuning - a simple training-free method to tune the skip connection strength by multiplying the skip vectors with a coefficient <1 before concatenation.
- Decreasing skip connection strength increases UNet complexity and its capability for few-shot sampling.

Key Results:
- Skip-Tuning improves sample quality significantly, e.g. 100% lower FID for EDM on ImageNet 64 with 10 NFEs.
- It surpasses ODE sampling limit of EDM on ImageNet 64, achieving 1.75 FID with 19 NFEs versus best of 2.2 previously.
- With 39 NFEs, Skip-Tuned original EDM (1.57 FID) beats the optimized EDM-2 (1.58 FID).
- Improves distilled models in one-step sampling, e.g. 5.56 versus 6.85 FID for CD-EDM.
- Generalizable across models (EDM, LDM, UViT) and stable across sampling steps.

Analysis:
- Although pixel-space score-matching loss increases, feature-space loss reduces with Skip-Tuning.
- Biggest gains in feature loss and FID from intermediate noise levels. 
- Brings inverted noise distribution closer to Gaussian in terms of MMD distance.

In summary, the paper proposes Skip-Tuning, a surprisingly effective yet simple training-free method to unlock the full potential of diffusion models by tuning the UNet skip connections.
