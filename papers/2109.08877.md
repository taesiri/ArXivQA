# [DuRecDial 2.0: A Bilingual Parallel Corpus for Conversational   Recommendation](https://arxiv.org/abs/2109.08877)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How can we create a bilingual parallel dataset to facilitate research on multilingual and cross-lingual conversational recommendation?The authors aim to create a new dataset called DuRecDial 2.0 that contains dialogues aligned across English and Chinese. This is intended to enable studies on multilingual and cross-lingual techniques for conversational recommendation systems.The key contributions seem to be:- Creation of DuRecDial 2.0, a large-scale bilingual parallel dialog dataset for conversational recommendation research. - Definition of monolingual, multilingual and cross-lingual tasks using this new dataset.- Development of baseline models for the defined tasks to benchmark performance.- Analysis of results showing the benefits of the bilingual data for Chinese conversational recommendation.So in summary, the core research contribution is the creation of a novel bilingual dataset to facilitate new research directions in multilingual and cross-lingual conversational recommendation systems. The authors demonstrate the value of the dataset by defining relevant tasks, building baselines, and showing performance improvements from bilingual training.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It introduces a new bilingual parallel dataset, DuRecDial 2.0, for conversational recommendation. This is the first publicly available parallel dataset in English and Chinese for this task. 2. It defines 5 tasks on this dataset - monolingual, multilingual, and cross-lingual conversational recommendation. This allows for exploring new research directions.3. It provides an in-depth analysis of the dataset, comparing it to existing datasets and showing its benefits. The analysis indicates the dataset has good diversity and parallelism.4. It establishes strong baselines for the tasks using state-of-the-art models XNLG and mBART. Experiments show benefits of using the bilingual dataset, especially for improving Chinese conversational recommendation.5. The dataset and experiments provide a challenging testbed to drive future research on monolingual, multilingual and cross-lingual conversational recommendation.In summary, the key contribution is creating a high-quality bilingual dataset for conversational recommendation, defining new tasks on it, analyzing its properties, establishing baselines, and showing the benefits it provides for improving Chinese conversational recommendation. The dataset enables new research directions in this space.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper introduces DuRecDial 2.0, a new bilingual parallel dataset for conversational recommendation comprising 8.2k dialogs aligned across English and Chinese, and defines 5 tasks on it - monolingual, multilingual, and cross-lingual conversational recommendation - to investigate the benefits of bilingual data and provide a new benchmark for multilingual modeling.


## How does this paper compare to other research in the same field?

Here are a few key points on how this paper compares to other related work:- This paper introduces a new bilingual parallel dataset, DuRecDial 2.0, for conversational recommendation. Previous datasets in this field have focused on monolingual dialogs in a single language. DuRecDial 2.0 provides aligned dialogs in both English and Chinese, enabling new research directions in multilingual and cross-lingual conversational recommendation.- Most prior conversational recommendation datasets are not parallel. For example, popular datasets like GoRecDial, TGReDial, and INSPIRED contain dialogs only in English. DuRecDial 2.0 is the first parallel dataset spanning two languages.- The paper defines 5 key tasks enabled by the parallel nature of DuRecDial 2.0: monolingual (in English and Chinese separately), multilingual (mixing dialogs from both languages), and cross-lingual (input in one language, output in the other). This allows for a richer set of experiments compared to standard monolingual setups.- The dataset analysis shows DuRecDial 2.0 has more diverse utterance prefixes compared to existing datasets like Redial. This indicates the dialogs exhibit more flexible language styles.- The authors establish baseline results on DuRecDial 2.0 using state-of-the-art models like XNLG and mBART. The results demonstrate the challenges posed by the new multilingual and cross-lingual tasks.In summary, the key novelty is the introduction of a parallel multilingual dataset to enable new research directions in conversational recommendation. The baseline experiments provide a starting point for future work to develop models that can effectively leverage the multilingual data.


## What future research directions do the authors suggest?

Based on my reading of the paper, here are some of the main future research directions suggested by the authors:- Investigate the possibility of combining multilinguality and few (or zero) shot learning to see if it can help dialog tasks in low-resource languages. The authors suggest extending their bilingual dataset to more languages and exploring the tasks in a few-shot or zero-shot setting.- Explore the reason why the cross-lingual model (ZH->EN) does not outperform the monolingual English model, while the reverse direction (EN->ZH) does. The asymmetry between the two cross-lingual directions is an interesting area for future work. - Look into the interaction between multilingual and cross-lingual training. The authors find performance continues to improve from the multilingual setting to the cross-lingual setting, so investigating this interaction could be fruitful.- Extend the study to more advanced models like large pre-trained transformers. The current baselines use XNLG and mBART, but more recent models could be applied.- Explore personalized/user-adaptive models leveraging the user profiles in the dataset. The authors suggest this as an interesting direction.- Investigate joint training over the heterogeneous dialog types in the dataset (chitchat, QA, task-oriented). The multi-type nature of the dialogs could enable new research.- Examine the dual objectives of recommendation and conversation more deeply. The authors propose this as an area for future work.In summary, the main suggested directions are: few-shot multilinguality, analyzing cross-lingual asymmetry, interacting multilingual/cross-lingual training, more advanced models, personalization, multi-type dialog modeling, and joint recommendation-conversation modeling. The authors position their dataset as enabling many new research avenues.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper introduces DuRecDial 2.0, a new bilingual parallel dataset for conversational recommendation consisting of 8.2k dialogs aligned across English and Chinese (16.5k dialogs and 255k utterances total). Each dialogue has seeker profiles, knowledge triples, and parallel goal sequences annotated in both languages. The authors define 5 tasks using the dataset: monolingual (English or Chinese), multilingual (mixed language training), and cross-lingual (model input and output are different languages) conversational recommendation. They build baselines using XNLG and mBART models and conduct experiments on the dataset. Results show benefits of the bilingual data, with additional English data improving Chinese model performance. The dataset provides a challenging testbed for future research on monolingual, multilingual and cross-lingual conversational recommendation. Key contributions are creating the novel bilingual dataset, defining tasks based on it, and establishing baselines to confirm its usefulness, especially for improving Chinese conversational recommendation systems.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:This paper introduces DuRecDial 2.0, a new bilingual parallel dataset for conversational recommendation. The dataset consists of 8.2K dialogs aligned across English and Chinese (16.5K dialogs and 255K utterances total). Each dialog contains seeker profiles, knowledge triples, and goal sequences all aligned between the two languages. The authors define 5 tasks using this dataset: monolingual (in English and Chinese separately), multilingual (training on mixed English and Chinese data), and cross-lingual (input context in one language, output response in the other). They build baselines using XNLG and mBART models. Results show mBART outperforms XNLG overall. The additional English data improves Chinese recommendation performance, demonstrating the benefits of bilingual data. However, additional Chinese data does not improve English performance, likely due to poor entity modeling. Overall, DuRecDial 2.0 provides a challenging testbed for monolingual, multilingual, and cross-lingual conversational recommendation.In summary, this paper introduces a new bilingual dataset for conversational recommendation and defines multilingual/cross-lingual tasks on it. Experiments show benefits of bilingual data and that the dataset presents challenges for future research.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper:The paper presents DuRecDial 2.0, a bilingual parallel dataset for conversational recommendation in English and Chinese. To construct the dataset, the authors first build a parallel knowledge graph covering 6 domains by translating entities and relation triples between the two languages. Based on the knowledge graph, they create parallel user profiles, task templates, and conversation situations. The dataset is then collected by crowdsourcing workers who are prompted with the parallel materials to produce conversations aligned across languages. In total, DuRecDial 2.0 contains 8.2k dialogs and 255k utterances parallel between English and Chinese. The authors define 5 tasks on DuRecDial 2.0: monolingual (English or Chinese separately), multilingual (mixed language training), and cross-lingual (input in one language, output in the other). They build baselines using cross-lingual models XNLG and mBART, fine-tuning them on DuRecDial 2.0 accordingly. Results show mBART generally outperforms XNLG, and the additional English data improves Chinese conversational recommendation, demonstrating the value of the parallel bilingual dataset.


## What problem or question is the paper addressing?

The paper is presenting a new bilingual dataset called DuRecDial 2.0 for multilingual and cross-lingual conversational recommendation. The key problems and questions it aims to address are:1. Lack of multilingual/cross-lingual datasets for conversational recommendation research. Existing datasets are only monolingual. 2. Potential benefits of multilingual and cross-lingual modeling for conversational recommendation are unexplored due to lack of suitable datasets.3. Evaluating and comparing progress on conversational recommendation across languages is difficult without a parallel multilingual dataset.4. End-to-end training of multilingual conversational recommendation models requires parallel training data which is currently unavailable. 5. Can a multilingual dataset bring performance gains for conversational recommendation compared to monolingual data?6. How to construct a high-quality parallel dataset for multilingual/cross-lingual conversational recommendation research?In summary, the key focus is on creating the first bilingual dataset to enable new research directions in multilingual and cross-lingual conversational recommendation. The dataset aims to support tasks like multilingual modeling, transfer learning, and cross-lingual evaluation for this domain.
