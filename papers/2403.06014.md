# [Hard-label based Small Query Black-box Adversarial Attack](https://arxiv.org/abs/2403.06014)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Deep neural networks are vulnerable to adversarial attacks using maliciously crafted inputs that cause misclassification. 
- Black-box attacks rely only on predictions from the model and are more practical, but suffer from needing a large number of queries to find adversarial examples.
- Hard-label black-box attacks only have access to the predicted class, making query efficiency even more critical.

Proposed Solution:
- The paper proposes a Small-Query Black-Box Attack (SQBA) that integrates transfer-based and hard-label based attacks. 
- It uses a surrogate model to generate gradients and guide the search direction. The gradients help accelerate the search compared to random sampling.
- It estimates a second gradient using Monte Carlo sampling for when the surrogate model gradients become ineffective. The two gradients are combined based on their expected reliability.
- A line search finds examples near the decision boundary to improve query efficiency.

Main Contributions:
- A novel transfer-based iterative gradient estimation method to guide the search direction in hard-label black-box attacks.
- The SQBA attack method integrating surrogate model guidance and Monte Carlo stochastic gradients.
- Experiments across CIFAR-10 and ImageNet datasets and models demonstrating SQBA achieves much higher attack success rates than benchmarks, especially for small query budgets of 100-250 queries. SQBA needs 5x fewer queries to achieve similar attack performance.
- Analysis of SQBA's robustness against defended models, where performance degrades significantly but still exceeds benchmarks.

In summary, the paper presents a more query-efficient hard-label black-box attack using ideas from transfer-based attacks, while remaining practical by not needing model internals or soft-labels. The higher attack success rate for low queries highlights its real-world applicability.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper proposes a new hard-label based black-box adversarial attack method called Small-Query Black-Box Attack (SQBA) that integrates transfer-based and query-based approaches to improve query efficiency compared to prior hard-label attack methods.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. A novel transfer based iterative gradient estimation is proposed to guide gradient direction in the black-box attack settings.

2. The authors design a hard-label based black-box attack method, called SQBA (Small-Query Black-Box Attack), which has an optimisation process guided by the proposed transfer based gradient estimation.  

3. Through experiments, the authors demonstrate the improved query-efficiency of the SQBA attack method compared to several state-of-the-art hard-label based black-box attack methods. Specifically, SQBA achieves approximately 5 times higher attack success rate at small query budgets of 100 and 250 queries.

So in summary, the main contribution is proposing the SQBA method that integrates transfer based and hard-label based attacks to achieve higher attack success rate with fewer queries compared to prior hard-label black-box attacks. The key ideas are using a surrogate model to estimate gradients and guide the optimisation process, and combining this with a hard-label attack procedure.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts include:

- Hard-label based black-box adversarial attack - The paper focuses on attack methods that can only access the predicted class (hard label) of a target model, without access to model internals or soft probability outputs.

- Query efficiency - A key goal is improving attack success rate with a limited query budget against the target model. 

- Transferability - The method exploits gradient transfers from surrogate models to guide the black-box attack process.

- Zeroth-order optimization - Gradient-free optimization techniques used in the black-box attack setting since gradients are not available.

- Untargeted vs targeted attacks - The method is evaluated on untargeted attacks trying to get the model to predict any incorrect class.

- Attack budgets - Constraints on perturbation size and number of queries to make attacks practical.

- Benchmark methods - State-of-the-art hard-label attacks like HSJA, Boundary Attack, Sign-Opt, Biased Boundary Attack are used as performance baselines.

- Surrogate models - Pre-trained models used to generate substitute gradients to guide the black-box attack.

So in summary, key focus is on improving practical hard-label black-box attacks using ideas from transferability and zeroth-order optimization under realistic query budgets.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes a novel transfer-based iterative gradient estimation approach. Can you explain in more detail how this method estimates the gradient from the surrogate model and integrates it with the optimization process? What are the key differences from prior transfer-based attacks?

2. The paper claims the proposed method significantly improves query efficiency compared to benchmark hard-label based attacks. What specifically about the integration of the surrogate model gradients leads to higher attack success rates with fewer queries? 

3. How does the method determine the best search direction from the multiple gradient estimates generated from the surrogate model? What is the intuition behind choosing the gradient vector that minimizes the distance to the original input?

4. The method combines the surrogate model gradients with random gradient estimates using a weighting factor beta. How is beta determined and adapted during optimization? What triggers switching between reliance on the surrogate vs random gradients?  

5. How does the method ensure the intermediate adversarial examples stay close to the decision boundary? Explain the line search process and how the scaling factor alpha is used to approach the boundary.

6. The method claims improved generalizability across model architectures and datasets. What experiments were conducted to demonstrate this? How do the results vary between datasets and surrogate model choices?

7. The paper acknowledges adversarial transferability failures when surrogate and target model gradients disagree. How might the method be enhanced to improve transferability in these cases?  

8. How does the performance of the method degrade when attacking robust models trained with adversarial training? What percentages of attack success rate drop are observed?

9. What assumptions does the method make about access to the target model? Could the approach be extended to a purely black-box setting with no surrogate model?

10. The method currently only considers l2 distance metric for measuring perturbations. How might the approach change if using lâˆž or other similarity metrics? Would the gradient estimations need adjustment?
