# [InterLUDE: Interactions between Labeled and Unlabeled Data to Enhance   Semi-Supervised Learning](https://arxiv.org/abs/2403.10658)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "InterLUDE: Interactions between Labeled and Unlabeled Data to Enhance Semi-Supervised Learning":

Problem:
The paper focuses on semi-supervised learning (SSL) for image classification, where the goal is to leverage both a small labeled dataset and a larger unlabeled dataset to train an accurate classifier. Mainstream SSL methods optimize an additive loss with two terms: a supervised classification loss on labeled data and a regularization loss derived solely from unlabeled data. The paper argues that this additive formulation leads to a disconnect between labeled and unlabeled data, failing to fully harness the potential of unlabeled data.  

Proposed Solution: 
The paper proposes InterLUDE, a new SSL approach with two key components aimed at promoting interactions between labeled and unlabeled data:

1. Embedding fusion: Interpolates between labeled and unlabeled embeddings to improve representation learning. It uses a circular shift strategy that perturbs each embedding with its neighbor embedding, ensuring labeled embeddings interact with unlabeled ones.

2. Cross-instance delta consistency loss: Aims to make changes ("deltas") in predicted probabilities similar across labeled and unlabeled inputs when applying the same augmentation swap (e.g. weak augmentation to strong). Intuitively, if an aug swap makes a dog look more like a cat, predictions should change similarly for unlabeled images.

Contributions:
- Proposes embedding fusion and cross-instance delta consistency as ways to promote labeled-unlabeled interaction in SSL. Shows strong empirical performance.
- Evaluates on both classic closed-set SSL benchmarks and a more realistic open-set medical imaging task. Shows benefits even for open-set. 
- Experiments across six datasets and two architecture families (CNNs and Vision Transformers). Emerges as top performer in many cases, especially with few labels.
- Opens an avenue for future SSL research to focus on labeled-unlabeled interplay, rather than processing each data type in isolation.
