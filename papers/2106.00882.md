# [Efficient Passage Retrieval with Hashing for Open-domain Question   Answering](https://arxiv.org/abs/2106.00882)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we reduce the memory cost of dense passage retrievers like DPR while maintaining high accuracy on open-domain question answering tasks?The paper proposes a new model called Binary Passage Retriever (BPR) that aims to address this question. The key ideas are:- Using a learning-to-hash technique to encode passages into compact binary codes rather than dense vectors. This drastically reduces the memory needed to store the passage index.- A two-stage retrieval approach that first does efficient candidate generation based on binary codes, then accurate reranking using dense embeddings. This maintains accuracy while improving search speed. - A multi-task training objective that simultaneously optimizes the model for both binary code search and dense vector reranking.So in summary, the central hypothesis is that BPR can reduce the memory cost of dense retrievers substantially through the use of binary hashing while achieving similar accuracy by still leveraging dense vectors in a two-stage retrieval process. The experiments aim to validate whether this approach works in practice.


## What is the main contribution of this paper?

The main contribution of this paper is the proposal of a new neural retriever model called Binary Passage Retriever (BPR). The key ideas are:- BPR uses a learning-to-hash technique to encode passages into compact binary codes instead of dense vectors. This allows reducing the memory footprint of the passage index from 65GB to 2GB.- BPR is trained with a multi-task objective over two tasks: efficient candidate generation based on binary codes, and accurate reranking based on dense vectors. This allows improving search efficiency while maintaining accuracy.- Experiments on Natural Questions and TriviaQA datasets show that BPR achieves similar accuracy as Dense Passage Retriever while using substantially less memory. With an improved reader model, it achieves competitive results with state-of-the-art on open-domain QA.In summary, the main contribution is a new passage retriever model that can drastically reduce the memory requirements for large-scale open-domain QA systems while maintaining accuracy. The key ideas are learning compact binary codes for passages, and using a two-stage approach with multi-task training.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper: The paper introduces a memory-efficient neural retrieval model called Binary Passage Retriever (BPR) that uses compact binary codes to represent passages, allowing for substantial compression of the passage index without losing accuracy compared to Dense Passage Retriever.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other research in open-domain question answering:- It builds on recent work like the Dense Passage Retriever (DPR) that uses dual-encoder architectures with BERT to encode questions and passages into a shared vector space. However, it focuses on reducing the memory requirements of these dense retrieval models.- The main contribution is a novel Binary Passage Retriever (BPR) model that compresses the passage embeddings using learning to hash. This allows the index to be stored in a very compact binary form rather than dense vectors. - BPR achieves similar accuracy as DPR on QA datasets like Natural Questions and TriviaQA, while reducing the index size from 65GB down to 2GB. This demonstrates the effectiveness of the hashing approach for efficiency.- For reranking, BPR retrieves a small set of candidates using efficient Hamming distance search on the binary codes, then reranks using the inner product of dense vectors. This two-stage approach balances efficiency and accuracy.- When coupled with a reader model, BPR achieves competitive results compared to state-of-the-art open domain QA systems like REALM and Fusion-in-Decoder. It gets close to SoTA with fewer parameters.- The learning to hash technique differentiates this from other work on compressing BERT models, as most rely on product quantization or pruning. Hashing allows extreme compression suitable for passage retrieval.- Overall, this paper makes an important contribution of dramatically reducing the memory requirements of dense retrieval systems without sacrificing accuracy. The innovations could make QA systems much more scalable.
