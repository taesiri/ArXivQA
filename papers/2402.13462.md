# [Potential and Challenges of Model Editing for Social Debiasing](https://arxiv.org/abs/2402.13462)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Large language models (LLMs) suffer from stereotypical biases learned from the data they are trained on. 
- Debiasing LLMs by fine-tuning is costly and data-hungry. Model editing methods that modify models post-training have potential for efficient debiasing.
- However, it lacks study on facilitating both internal and external editing methods for debiasing, supporting various bias types, and understanding the pros and cons.

Proposed Solution:
- Formulate social debiasing into an editing problem with minimal annotation needs, supporting both internal and external methods.
- Construct a debias editing dataset based on StereoSet with prompt, target, subject and paraphrases.
- Benchmark 7 editing algorithms on debiasing over LLaMA-2 and GPT2-XL in 3 scenarios:
   1) Single-edit: Achieve high success rate but generalization is limited.
   2) Sequential-edit: Most methods degrade except SERAC. Editing accuracy and knowledge retention are key challenges. 
   3) Generalization over bias types: Edits can transfer to unseen bias types.
- Propose rule-based and causal tracing methods to constrain target scope, showing effectiveness.

Main Contributions:
- First comprehensive study to reveal potentials and challenges of using model editing methods for stereotypical debiasing.
- Flexible problem formulation supporting both internal and external editing algorithms.
- Extensive experiments over two LLMs in three scenarios to demonstrate key observations. 
- Two simple but effective methods proposed to address the identified challenges.

The paper systematically studies debias editing, reveals unique pros and cons compared to fact editing, and provides effective solutions towards robust debiasing via model editing.
