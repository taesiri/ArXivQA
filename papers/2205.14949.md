# [HiViT: Hierarchical Vision Transformer Meets Masked Image Modeling](https://arxiv.org/abs/2205.14949)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research question addressed in this paper is: 

How can we design an efficient hierarchical vision transformer architecture that enjoys both high performance and training speed in masked image modeling (MIM)?

The authors note that hierarchical vision transformers like Swin Transformer have superior performance but slow training speed for MIM due to operations like shifting window attention. On the other hand, standard vision transformers like ViT have fast training but poorer performance. 

To get the best of both worlds, the paper proposes a new architecture called HiViT that modifies Swin Transformer to remove unnecessary local inter-unit operations that hinder computational efficiency for MIM. The goal is to achieve a hierarchical vision transformer that is high-performing, flexible, and fast for masked image modeling.

In summary, the central hypothesis is that by eliminating certain local inter-unit operations from hierarchical vision transformers, it is possible to attain both strong accuracy and high training speed in the MIM paradigm. The design of HiViT aims to test this hypothesis.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- The proposal of HiViT, a hierarchical vision transformer architecture designed to combine the strengths of both plain (e.g. ViT) and hierarchical (e.g. Swin) vision transformers for masked image modeling. 

- Removing redundant "local inter-unit operations" from hierarchical vision transformers like Swin Transformer to make them more efficient and flexible for masked image modeling. This involves modifications like aligning the masking unit size with the main stages' token size, removing later stages, and replacing early-stage window attentions with MLPs.

- Empirical evaluations showing HiViT can outperform both ViT and Swin Transformer on ImageNet classification with fully supervised training. It also shows advantages for masked image modeling, achieving better accuracy and 1.9x faster training than Swin Transformer.

- Demonstrations that removing the local inter-unit operations does not hurt performance on various vision tasks including classification, detection, and segmentation. This validates the flexibility of HiViT for different applications.

In summary, the main contribution appears to be proposing HiViT to make hierarchical vision transformers more compatible with masked image modeling, while retaining their performance advantages over plain vision transformers like ViT. The modifications to remove unnecessary local operations are shown to provide benefits across multiple vision tasks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key point in the paper:

The paper proposes a hierarchical vision transformer architecture called HiViT that achieves both high efficiency and good performance in masked image modeling for self-supervised visual pre-training by removing unnecessary local inter-unit operations.
