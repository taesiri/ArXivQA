# [The Queen of England is not England's Queen: On the Lack of Factual   Coherency in PLMs](https://arxiv.org/abs/2402.01453)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Pre-trained language models (PLMs) are known to contain factual knowledge captured during pre-training, which enriches their representations. 
- Prior work has focused on evaluating how much factual knowledge is contained in PLMs by measuring their ability to predict object entities given a subject and relation. 
- This paper argues that the internal coherence of factual knowledge in PLMs is an important complementary metric that has not been studied before. 

Proposed Solution:
- The authors introduce the notion of "coherency" to evaluate how often PLMs can predict the original subject entity when given the relation and the PLM's own (potentially incorrect) prediction for the object entity.
- This tests whether PLMs can inference bidirectional relationships, not just predict objects from subjects.
- Coherency is evaluated on the standard LAMA benchmark across various PLMs, prompt optimization methods, evidence paragraphs, etc.

Key Findings:
- PLMs show very poor internal coherency of factual knowledge. Their own predictions are often incoherent.
- Providing evidence paragraphs substantially improves coherency by giving context.
- Scaling model size and using entity-focused pre-training help improve coherency.
- Optimized prompts and paraphrasing do not help coherency, showing brittleness.

Main Contributions:
- Formalizes the novel metric of factual knowledge coherency in PLMs to study internal model consistency.
- Extensive experiments over factors like model scale, training objectives, prompts. 
- Key insight that existing PLMs lack coherent internal factual knowledge, limiting their use as knowledge bases.
- New direction for improving PLMs - enhancing internal coherence.

In summary, the paper identifies fundamental inconsistencies in how factual knowledge is stored in PLMs, and provides insights into potential areas of improvement.
