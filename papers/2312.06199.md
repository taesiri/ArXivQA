# [Towards Transferable Adversarial Attacks with Centralized Perturbation](https://arxiv.org/abs/2312.06199)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality one-paragraph summary of the key points from the paper:

This paper proposes a novel approach to craft transferable adversarial examples by centralizing perturbation optimization towards the dominant frequency regions of images. Specifically, the authors devise a systematic pipeline that first decomposes input images into frequency coefficients via discrete cosine transform (DCT), then dynamically constrains perturbation optimization through quantizing frequency coefficient blocks based on their sensitivity influence on model predictions. To enable precise control over this quantization process, they optimize the quantization matrix in parallel by propagating gradients from the prediction changes back to the matrix. This allows perturbation to concentrate on sample-specific important frequency features that are shared across models, avoiding source model overfitting. Comprehensive experiments demonstrate that by centralizing perturbation on influential frequency coefficients iteratively, the resulting adversarial examples exhibit significantly stronger transferability across black-box models. Also, under the same perturbation budgets, the proposed attack succeeds in bypassing various adversarial defenses, outperforming current state-of-the-art attacks.
