# [3D Motion Magnification: Visualizing Subtle Motions with Time Varying   Radiance Fields](https://arxiv.org/abs/2308.03757)

## What is the central research question or hypothesis that this paper addresses?

Based on my review, the central research question this paper addresses is: How can we extend video motion magnification techniques to model and visualize subtle motions in 3D scenes?Specifically, the paper proposes a method for 3D motion magnification that leverages neural radiance fields (NeRF) as the 3D scene representation. The key ideas are:- Model subtle 3D motions over time by modifying only the point embedding function in NeRF, while keeping the MLP network fixed. This allows capturing subtle variations through changes in the embeddings. - Apply principles from Eulerian video magnification (analyzing temporal pixel variations) to the analysis of temporal variations in NeRF embeddings. This allows extending 2D magnification techniques like linear and phase-based magnification to operate on the NeRF embeddings.- Compare positional encoding versus tri-plane based embeddings for NeRF in the context of 3D motion magnification. The tri-plane formulation provides a natural way to apply 2D magnification techniques on the feature planes.- Demonstrate 3D motion magnification results on both synthetic and real scenes captured with multi-camera and handheld single-camera setups. The method successfully magnifies subtle 3D motions even for handheld videos, which existing 2D magnification techniques fail to handle.In summary, the key hypothesis is that extending Eulerian video magnification principles to operate on temporal variations in neurally encoded 3D scene representations like NeRF can enable practical and effective magnification of subtle 3D motions from multi-view or monocular videos. The experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

The main contribution of this paper is presenting a method for 3D motion magnification using neural radiance fields (NeRF). Specifically:- They propose magnifying subtle motions in 3D scenes represented with NeRF by applying temporal filtering and amplification to the point embeddings over time, extending the Eulerian motion magnification principle from 2D videos to 3D NeRF embeddings.- They study and validate this idea using both standard NeRF with positional encoding as the point embedding and NeRF with tri-plane embedding. With tri-planes, they show the motion can be magnified using established 2D video magnification techniques like phase-based filtering by operating on the feature planes.- They demonstrate successful 3D motion magnification results on various real-world scenes captured under different camera setups, including handheld videos that are unsupported by prior 2D magnification methods. This shows their method's effectiveness and robustness. In summary, the key contribution is developing and validating the concept of 3D motion magnification on neural radiance fields, generalizing prior work on magnifying subtle motions in 2D videos and images. The method supports novel view synthesis and works on both multi-view and handheld monocular videos.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a method for 3D motion magnification using neural radiance fields by analyzing and amplifying the temporal variations in point embeddings to magnify subtle motions from both multi-view and single-view captured scenes.
