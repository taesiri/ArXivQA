# [The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning](https://arxiv.org/abs/2403.03218)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key aspects of the paper:

Problem: Large language models (LLMs) may empower malicious actors to more easily develop dangerous weapons like biological, chemical, and cyber weapons. Currently, evaluations of these risks are private and limited, restricting research into mitigating risks. Also, existing methods to reduce risks like training models to refuse queries can be bypassed. 

Solution: The paper introduces the Weapons of Mass Destruction Proxy (WMDP) benchmark, containing over 4,000 multiple choice questions that serve as a proxy for hazardous knowledge in biosecurity, cybersecurity and chemical security. This public benchmark allows measuring hazardous knowledge in models to guide risk mitigation research. They also propose a machine unlearning method called Contrastive Unlearn Tuning (CUT) to remove hazardous knowledge from models while retaining performance on general tasks.

Key Contributions:
- Publicly released benchmark, WMDP, to measure hazardous capabilities of models to empower research into mitigating risks 
- WMDP developed through expert threat models and stringently filtered to avoid releasing sensitive information 
- State-of-the-art unlearning method CUT that significantly reduces performance on WMDP while maintaining accuracy on general benchmarks
- Demonstration that unlearning on WMDP generalizes to reducing especially hazardous knowledge in model
- Discussion of combining unlearning with structured API access to reduce risks while retaining capabilities for benign applications

In summary, the paper makes the first public benchmark for evaluating and reducing hazardous knowledge in LLMs. Unlearning shows promise for mitigating risks from malicious use, and WMDP enables further research into precisely removing dangerous knowledge from models.
