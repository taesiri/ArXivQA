# [Unsupervised CNN for Single View Depth Estimation: Geometry to the   Rescue](https://arxiv.org/abs/1603.04992)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is:How can we train a convolutional neural network to estimate depth from a single image in an unsupervised manner, without requiring ground truth depth data? The key hypothesis is that an unsupervised training approach based on reconstructing one view of a stereo pair from the other view, using the predicted depth and known camera geometry, can enable training a CNN for single view depth estimation from scratch without manual labels.In summary, the main research focus is on developing an unsupervised learning approach for single view depth estimation using a convolutional neural network. The key idea is to use stereo image pairs during training, with a reconstruction loss between one image and a warped version of the other image based on the predicted depth. This avoids the need for ground truth depth data.


## What is the main contribution of this paper?

The main contribution of this paper is an unsupervised framework to learn a convolutional neural network (CNN) for single view depth prediction, without requiring any ground truth depth data or pre-training. The key ideas are:- They train the CNN in an "autoencoder" setup, where the encoder predicts a depth map from a single image, and the decoder uses this depth map along with the known camera motion between a source and target image to warp the target image and reconstruct the source image. The loss function is the difference between the reconstructed and original source images.- This allows them to train the depth prediction CNN in an end-to-end unsupervised manner using only stereo image pairs, without needing ground truth depth. The stereo pairs provide the source and target images, and the known baseline provides the camera motion.- They use a coarse-to-fine training approach, progressively increasing the resolution of the predicted depth maps. This helps deal with the limitation that the image warp needs to be locally linearized during backpropagation.- They show results on KITTI dataset comparable to state-of-the-art supervised methods, demonstrating the effectiveness of this unsupervised training approach.Key advantages are that it removes the need for costly ground truth depth data collection, and allows training on unlimited amounts of stereo imagery. This is a step towards in-situ and lifelong learning.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes an unsupervised framework to train a convolutional neural network for single view depth estimation using only stereo image pairs, without requiring ground truth depth data.


## How does this paper compare to other research in the same field?

This paper presents an innovative unsupervised learning approach for single view depth estimation using stereo image pairs. Here are some key ways it compares to other research in this field:- Most prior work on single view depth estimation uses fully supervised training with ground truth depth maps. This requires expensive data collection and annotation. The method proposed here is completely unsupervised, training on unlabeled stereo pairs which are much easier to acquire.- Other unsupervised approaches like stereo-supervised training can suffer from "baking in" the errors of the stereo algorithm used to generate proxy ground truth. By directly optimizing a photometric loss, this method avoids that issue.- The coarse-to-fine training strategy with upsampling layers is similar to some fully convolutional network architectures. However, the application of these techniques to enable unsupervised training via stereo image alignment seems novel. - The performance achieved is on par or better than recent supervised methods, despite having an order of magnitude fewer parameters, and no pre-training on labeled data like ImageNet.- For training data, the authors use stereo pairs from KITTI, which is a standard benchmark. But a strength of their unsupervised approach is that it could easily use other much larger stereo video datasets.- The idea of geometry-based losses for unsupervised representation learning seems powerful and underexplored compared to generative adversarial networks or other popular approaches.In summary, the key novel contribution is an unsupervised training framework that can match or exceed supervised methods by using stereo image pairs and photometric alignment losses. This could enable cheaper and easier training of depth prediction networks for new domains.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the key future research directions suggested by the authors include:- Training the network on continuous stereo video captured "in the wild" rather than the KITTI dataset. The authors suggest this could improve accuracy and allow the network to learn from more varied data.- Augmenting the KITTI data with new stereo pairs to explore the effect on accuracy.- Using a monocular SLAM system instead of stereo to estimate camera motion between frames, and training the network using this motion within the autoencoder framework. This could allow training on monocular video.- Evaluating whether the low-level features learned by the network could be effective for other vision tasks like classification and recognition, by transferring them to new models.- Exploring better loss functions and replacing the linear interpolation with learned conditional random fields (CRFs) to further refine the depth maps.- Training deeper networks and estimating depth at full image resolution to capture more variation. - Applying the method to much larger stereo video datasets like Cityscapes to improve generalization.So in summary, the main future directions are around expanding the training data, replacing the stereo with monocular SLAM, transferring features to other tasks, improving the depth maps with better losses and CRFs, and scaling up to deeper networks and full resolution. The overarching goal is to move towards cheaper unsupervised training "in the wild" and continuous lifelong learning.
