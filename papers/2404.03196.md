# [Okay, Let's Do This! Modeling Event Coreference with Generated   Rationales and Knowledge Distillation](https://arxiv.org/abs/2404.03196)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Event coreference resolution (ECR) aims to connect event mentions in text that refer to the same real-world event. This is challenging when event mentions use different words (lexical variability) or when mentions seem similar but actually refer to distinct events (lexical similarity despite semantic difference). Neural ECR models often fail on such cases. 

Solution:
This paper proposes using free-text rationales (FTRs) generated by large language models (LLMs) to provide additional contextual information to guide an ECR model. Specifically:

1. FTRs resembling an "inner monologue" are generated for event mention pairs using the LLaMA model, conditioned on the gold coreference labels. This provides step-by-step reasoning explaining the coreference decisions.

2. A student ECR model is trained to embed event mention pairs close to their corresponding FTRs, aligning their vector spaces (Rationale-Oriented Event Clustering). 

3. The student model is further tuned using knowledge distillation losses to distill coreference cues from the FTRs and teacher LLM into the student model.

So FTRs provide extra supervision to enhance the student model, without needing FTRs at inference time.

Contributions:

- Method to generate FTRs for event pairs using LLMs to provide reasoning for ECR decisions

- Novel event clustering method aligning mention pairs with FTRs

- Optimization framework distilling knowledge from FTRs and teacher LLM into a student ECR model

- Achieves state-of-the-art or competitive performance on ECB+, GVC and AIDA Phase 1 benchmarks without using document clustering

The results demonstrate that although imperfect, automatically generated rationales contain useful cues for ECR decisions. Distilling this into a specialized ECR model enhances performance over models lacking this extra context.
