# [HE is all you need: Compressing FHE Ciphertexts using Additive HE](https://arxiv.org/abs/2303.09043)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we compress fully homomorphically encrypted (FHE) ciphertexts, specifically Learning with Errors (LWE) and Ring Learning with Errors (RLWE) ciphertexts, to reduce their size before sending them back to the client?The key points about the research question:- The focus is on compressing FHE ciphertexts, particularly LWE and RLWE ciphertexts, which tend to be very large. - The goal is to reduce the ciphertext size before sending from server to client.- This addresses the issue of large FHE ciphertext sizes being an obstacle for practical deployment, especially for clients with limited bandwidth.- The paper proposes the first technique to compress FHE ciphertexts by using an additional additive encryption scheme with smaller ciphertexts.So in summary, the central research question is how to compress large FHE ciphertexts to make them more practical, by leveraging an additional additive encryption scheme. The core contribution is a novel technique to achieve this ciphertext compression.


## What is the main contribution of this paper?

The main contribution of this paper is proposing techniques to compress FHE ciphertexts, particularly those based on LWE/RLWE,  using an additive encryption scheme with smaller ciphertexts. The key ideas are:- The first step of LWE/RLWE decryption is linear in the secret key. So if the client sends encryptions of the secret key bits under an additive scheme to the server, the server can compute this linear step homomorphically and send back a compressed ciphertext. - For RLWE, the client can send encryptions of the secret key coefficients. The server can then extract and compress only the desired coefficients instead of the full ciphertext.- The paper shows up to 95% and 97% compression for LWE and RLWE ciphertexts respectively using these techniques.- The paper proves these techniques are secure under standard assumptions.In summary, the main contribution is protocols to significantly compress FHE ciphertexts by leveraging properties of LWE/RLWE and using an additional additive cryptosystem. This addresses the large ciphertext sizes which is an obstacle to adopting FHE.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other research in homomorphic encryption:- It proposes a novel technique to compress ciphertexts sent from the server to the client using an additive encryption scheme. Most prior work has focused on compressing or reducing the size of ciphertexts sent from client to server. This is the first work to address reducing the size of responses sent back to the client.- The technique applies to important homomorphic encryption schemes like TFHE, BFV, and BGV that are based on LWE/RLWE assumptions. It provides a general framework that can work with different FHE schemes.- The paper shows very significant ciphertext size reductions - up to 95% for LWE and 97% for RLWE. This could enable more practical use cases and applications where bandwidth is a major bottleneck.- The security analysis leverages composition theorems and semantic security. The composition of the LWE/RLWE scheme and additive scheme maintains security if the underlying schemes are secure.- It discusses integrating the technique into the OpenFHE library and prototype implementations showing its applicability. The overheads are reasonable - key encryption takes seconds and ciphertext compression takes under a second.- The paper connects the technique to applications like filtering on encrypted images and private data analysis. Compressing responses will help make these use cases more efficient and practical.Overall, this is an innovative technique to address a major bottleneck in FHE adoption - large ciphertext sizes. It provides a general framework applicable to major FHE schemes and demonstrates substantial compression rates. The practicality is backed by prototype implementations and integration into OpenFHE.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors are:- Investigating different additive homomorphic encryption schemes besides Paillier and ElGamal that could offer even better compression rates or other advantages. The authors mention this could be an interesting direction.- Exploring ways to compress the auxiliary encrypted secret key information that needs to be sent from client to server. The authors note this data is still fairly small compared to other FHE metadata, but reducing its size could be beneficial.- Applying the proposed compression techniques to real-world FHE applications like private data analysis and filters over encrypted images, and evaluating the impact on performance. The authors identify these as good use cases but do not implement them.- Extending the techniques to support compression across multiple servers in a distributed setting. The current protocols are designed for a client-server model.- Developing methods to compress bootstrapping-related data like the bootstrapping key. The authors currently only focus on compressing ciphertexts.- Investigating security proofs in the quantum setting. The authors prove semantic security against classical adversaries but do not analyze security against quantum algorithms.- Exploring ways to reduce the computational overhead introduced by the compression process. The authors note there is some additional computation needed by the server to support compression.In summary, the main directions are improving the compression techniques, applying them to real applications, analyzing their security with respect to quantum attacks, and reducing the computational costs. The authors lay out several interesting open problems to build upon their initial work.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the key points from the paper:This paper proposes the first technique to compress Fully Homomorphic Encryption (FHE) ciphertexts sent from the server back to the client using an additive encryption scheme with smaller ciphertexts. The main insight is that the first step of decryption for common FHE schemes like LWE and RLWE is linear in the secret key. So the client can send encryptions of the secret key bits under an additive scheme to the server, allowing it to compute this decryption step homomorphically and return a much smaller ciphertext. For LWE, the entire ciphertext can be compressed, while for RLWE, individual coefficients can be extracted and compressed. The paper shows this technique reduces ciphertext sizes by 86-95% for LWE and 70-97% for RLWE. It argues the composed scheme is still semantically secure and identifies applications like encrypted image filtering and private data analysis where this compression would be beneficial.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a novel technique to compress FHE ciphertexts sent from the server to the client by having the client provide encrypted bits of the secret key under an additive encryption scheme with smaller ciphertexts, allowing the server to compute a compressed ciphertext homomorphically.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the key points in the paper:This paper proposes a technique to compress fully homomorphic encryption (FHE) ciphertexts sent from the server to the client using an additive encryption scheme with smaller ciphertexts. FHE allows computation on encrypted data but produces large ciphertexts, especially for cryptosystems based on lattice assumptions like LWE/RLWE. This is problematic for bandwidth-constrained clients. The main idea is that the first step of LWE/RLWE decryption is linear in the secret key. So if the client sends encryptions of the secret key bits under an additive scheme to the server, the server can compute this step homomorphically and only send back a small additive ciphertext. Experiments show up to 95-97% compression for LWE/RLWE ciphertexts from various FHE schemes. Encrypting the secret key is efficient and only done once. The technique preserves security under standard assumptions. Applications include encrypted image filters and private data analytics.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper:The paper proposes a technique to compress fully homomorphic encryption (FHE) ciphertexts sent from the server to the client using an additive encryption scheme with smaller ciphertexts. The key insight is that the first step of decryption for common FHE schemes like LWE and RLWE is linear in the secret key. Therefore, if the client sends encryptions of the secret key bits under an additive scheme to the server, the server can compute this linear step homomorphically and only send back an encrypted scalar result to the client. This compressed response is much smaller than the original FHE ciphertext if the additive scheme has smaller ciphertexts. The paper shows this technique can compress LWE and RLWE ciphertexts by over 95%, enabling significant bandwidth savings for applications using FHE with large response sizes.


## What problem or question is the paper addressing?

Based on my reading of the paper, the main problem it is addressing is the large size of ciphertexts in fully homomorphic encryption (FHE) schemes, particularly those based on lattice assumptions like LWE/RLWE. The paper points out that FHE ciphertexts are much larger than the underlying plaintext, with expansion factors of thousands or more. This makes transmitting these ciphertexts costly in terms of bandwidth.The paper notes that while there are techniques to compress "fresh" ciphertexts sent from client to server, there are no existing techniques to compress ciphertexts sent in the other direction, from server back to client. So in summary, the key problem is the large size of FHE ciphertexts, particularly those being sent from server to client, which creates challenges for bandwidth and adoption of FHE schemes. The paper aims to provide the first technique to address this issue.
