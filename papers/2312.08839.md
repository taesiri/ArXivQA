# [Exploration of visual prompt in Grounded pre-trained open-set detection](https://arxiv.org/abs/2312.08839)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel visual prompt method for grounded pre-trained open-set object detection models. Existing methods rely on text prompts to generalize models to new categories, but have limitations related to description difficulty, language ambiguity, and optimization uncertainty. To address this, the authors develop a statistical-based visual prompt construction approach that does not require manual text descriptions. Specifically, prompts are initialized by sampling vectors from distributions modeled on the pre-training data statistics. A stochastic similarity layer then correlates the within-class vectors while keeping between-class vectors distinct. Additionally, a task-specific similarity dictionary is constructed to generate confusing text prompts as negative examples during training, improving the discriminability of the visual prompts. Experiments on 13 public datasets demonstrate state-of-the-art performance compared to previous prompt learning techniques. Ablations validate the efficacy of each component, and tests show the visual prompts enable more consistent combined inference across tasks. Key advantages are eliminating reliance on textual descriptions, extending prompt representation capacity, and enabling prompt reuse across downstream tasks.
