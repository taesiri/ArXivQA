# ["According to ..." Prompting Language Models Improves Quoting from   Pre-Training Data](https://arxiv.org/abs/2305.13252)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is whether prompting language models to ground their responses in pre-training data can improve the factual accuracy and reduce hallucination in their generations. 

Specifically, the key hypotheses are:

1) Prompting language models to quote from or ground responses in pre-training data like Wikipedia can increase the amount of verbatim overlap between generations and the training corpus.

2) This "grounding prompting" can reduce hallucination and improve factual accuracy, as measured by performance on question answering datasets. 

3) The improvements in grounding and accuracy from prompting increase with language model scale.

4) Language models can be steered to either increase or decrease grounding based on the prompt wording.

To test these hypotheses, the authors propose a new metric called QUIP that efficiently measures overlap between generations and training data using n-gram matching. They perform prompting experiments on various models and datasets to quantify changes in QUIP and factual accuracy. The results support the hypotheses, showing prompting can substantially increase grounding and accuracy, with greater effects from larger models. The prompts steer models in the intended grounding direction.

In summary, the central research aims to demonstrate and quantify how prompting can improve language model grounding and accuracy by leveraging memorization of pre-training data. The proposed QUIP metric enables efficiently measuring this effect.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a method to improve the grounding of language model generations in their pre-training data. Specifically:

- They introduce a new metric called QUIP-Score (Quoted Information Precision) to efficiently measure the overlap between model generations and the pre-training corpus by using n-gram matching with a data sketch. 

- They propose a prompting strategy called "according-to" prompting, where models are prompted to ground their responses in pre-training data (e.g. "According to Wikipedia...").

- Through experiments on question answering datasets, they show that these grounding prompts can increase the QUIP-Score (amount of quoted pre-training text) while maintaining or even improving end task performance.

- They find prompting is more effective at improving grounding for larger, instruction-tuned models. The QUIP-Score also correlates with entity popularity.

- Overall, this shows that prompting can steer language models to quote more frequently from curated pre-training sources like Wikipedia, reducing their tendency to hallucinate while improving grounding. The authors suggest this approach could improve reliability and trust in language model generations.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes prompting language models to quote more from their pre-training data as a way to reduce hallucination and improve grounding, introduces a new metric called QUIP to quantify the amount of quoting from pre-training data, and shows via experiments that prompting models to quote more improves both QUIP and often end-task performance while prompting to quote less has the opposite effect.


## How does this paper compare to other research in the same field?

 This paper introduces a novel prompting strategy called "according-to prompting" that aims to ground language model generations in their pre-training data. The key contributions are:

1. Proposing the use of prompts like "According to Wikipedia..." to encourage language models to quote directly from their pre-training corpus when generating responses. This is a simple yet effective method to reduce hallucination.

2. Introducing a new evaluation metric called QUIP Score that efficiently measures the overlap between model generations and the pre-training corpus using data sketches. This enables quantifying grounding to pre-training data.

3. Comprehensive experiments across models, datasets, and scaling trends that provide evidence that prompting can increase grounding, with the additional benefit of often improving end task performance.

Compared to related work, this paper presents a novel perspective on utilizing language model memorization in a positive way, by prompting models to quote factual sources more. It differs from methods that retrieve or append documents, as it aims to directly increase the model's own quoting. 

The QUIP Score metric also provides a new way to quantify grounding that is efficient, scalable, and privacy-preserving compared to prior proxy metrics like web search overlap.

Overall, this is an innovative approach to mitigating hallucination in LLMs via better utilization of memorization abilities. The prompting strategy is simple and generic. The QUIP Score provides a valuable new technique for quantifying grounding. Together, these contributions advance the understanding of steering LLMs to be more grounded.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some potential future research directions the authors suggest include:

- Exploring the use of according-to prompting strategies for other task domains besides open-domain question answering, such as scientific reasoning, law, or medicine. The authors note the domain-agnostic nature of their approach.

- Using according-to prompting strategies with closed-source or proprietary trained models, while still being able to report groundedness via the QUIP metric. This could help establish trust or provenance for systems like ChatGPT.

- Developing more advanced grounding metrics beyond simple lexical overlap, to account for paraphrasing or semantic similarity to source text.

- Conducting further analysis into the factors that influence a model's ability to quote pre-training data, such as popularity, frequency, instruction tuning, etc. 

- Exploring potential techniques to further improve the efficacy of according-to prompting, such as tuning prompts specifically for individual models.

- Leveraging according-to prompting strategies to encourage quoting from curated, high-quality sources during fine-tuning as well as pre-training.

- Studying the impact of scaling trends on the effectiveness of according-to prompting by testing even larger models.

- Mitigating the brittleness of prompting by developing methods to make steering more robust and reliable across prompt variations.

In summary, the main future directions focus on expanding the domains and models applicable to according-to prompting, developing more advanced grounding metrics, analyzing what factors impact quoting capability, and improving prompting techniques like tuning and scaling.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper proposes using natural language prompting to steer large language models (LLMs) towards generating outputs that are more grounded in their pre-training data. The authors introduce a new metric called QUIP Score that efficiently measures the overlap between an LLM's generated text and its pre-training corpus, as a way to quantify grounding. They conduct experiments on open-domain question answering using Wikipedia as the target pre-training corpus for grounding. By prompting models to "respond using information from Wikipedia", they are able to increase the QUIP Score (overlap with Wikipedia) while maintaining or even improving downstream task performance. The results are consistent across models and datasets. The paper suggests that prompting provides a simple yet effective way to reduce LLM hallucination by encouraging the models to rely more on the factual information they were trained on.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper introduces a new method called "Grounding via Prompting" to improve the grounding of large language model (LLM) generations in their pre-training data. The key idea is to prompt LLMs with phrases like "According to Wikipedia" to encourage them to quote directly from Wikipedia or other trusted sources they were trained on. 

To measure this grounding, the authors propose a new metric called QUIP-Score that efficiently checks model outputs for n-gram overlap with the pre-training corpus. Experiments on question answering datasets show that grounding prompts increase the QUIP-Score (i.e. amount of quoting from Wikipedia) by 5-100% compared to no prompt, while maintaining or even improving end task performance. Additional analysis reveals that grounding improves with model size and works better on popular entities. Overall, this is a simple but effective approach to steering LLMs towards more grounded and factual generations by exploiting their tendency to memorize pre-training data. The work has implications for improving reliability and trust of LLM-based systems.
