# [Dual feature-based and example-based explanation methods](https://arxiv.org/abs/2401.16294)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing explanation methods like LIME have limitations - perturbation techniques can generate out-of-domain samples leading to incorrect explanations. Also difficult to tune parameters and apply to complex data like images. 
- SHAP has computational complexity exponential in number of features.
- Need better methods for local and global explanation that work for tabular and complex data.

Proposed Solution:
- Introduce dual representation using convex hull of nearest neighbors around instance to be explained. 
- Map instances inside convex hull as convex combinations of extreme points (vertices).
- Uniformly sample dual representation from simplex instead of perturbing features.
- Construct surrogate model on dual representation. Allows transforming importance from dual to original feature space.

Contributions:
- New feature-based explanation method using dual representation to avoid limitations of perturbation techniques.
- Computationally simpler by transforming features to simplex instead of perturbing in Euclidean space. 
- Naturally leads to example-based explanation by examining effect of extreme points.
- Can apply to LIME, SHAP, Neural Additive Models to provide feature and example-based explanations.  
- Flexible approach that works for local and global explanation.
- Experiments on synthetic and real datasets demonstrate effectiveness over LIME.

Main limitations:
- Reduced dual dimensionality can incorrectly restrict generated primal points.
- Convex hull calculation exponentially complex in high dimensions.

Overall, the paper introduces a novel perspective for model explanation through convex duality that mitigates limitations of existing methods and opens up new research directions.


## Summarize the paper in one sentence.

 The paper proposes a new approach to local and global explanation of machine learning models based on selecting a convex hull of training data points around an explained instance and using a dual representation of data points as convex combinations of extreme points to train an interpretable surrogate model.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. A new feature-based explanation method is proposed based on dual representation of datasets using convex hulls. This replaces the perturbation process in methods like LIME with simpler uniform generation of points from a unit simplex.

2. A new example-based explanation method is proposed, also using the dual representation. This provides an inherent way to get example-based explanations and to use models like NAM to show contributions of different dual features. 

3. The proposed methods are demonstrated on several numerical experiments with synthetic and real datasets. Code is also made available to implement the proposed algorithms.

In summary, the main contribution is the novel use of dual representation and convex hulls to develop improved feature-based and example-based explanation methods for machine learning models. This avoids some limitations of existing methods and provides simpler ways to generate local explanations.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the main keywords and key terms associated with it include:

- Machine learning
- Explainable AI
- Neural additive network
- Dual representation
- Convex hull
- Example-based explanation
- Feature-based explanation
- Local explanation
- Global explanation
- Perturbation technique
- Out-of-domain data
- Mixup method
- Shape functions
- Accumulated local effect

The paper proposes a new approach to local and global explanation of machine learning models based on selecting a convex hull around the explained instance and using a dual representation of data points inside the hull. It develops methods for both feature-based and example-based explanations using concepts like the convex hull, duality, neural additive networks, etc. The key terms reflect the main techniques and concepts involved in the proposed explanation methods.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the dual explanation method proposed in the paper:

1. The paper mentions two key concepts that form the basis of the proposed method - convex hull and duality. Can you elaborate more on these concepts and how they enable the generation of new dual dataset?

2. One limitation mentioned is that smaller dimensionality in dual representation can incorrectly restrict the set of generated primal points. Can you suggest some ways to overcome this limitation? 

3. The uniform generation of points in simplex is claimed to be an advantage over perturbation based techniques. Can you think of some cases or data types where this may not hold an advantage?

4. The paper shows numerically that dual model provides lower MSE than LIME. Can you theoretically analyze the dual model and LIME to explain when and why this is the case?

5. How can the ideas from this paper be extended to make global explanations more efficient, especially for high dimensional data? 

6. The paper claims dual approach can be adapted for SHAP method. Can you elaborate an algorithm to achieve this? What advantages and limitations would it have over vanilla SHAP?

7. The example-based explanation method chooses most influential instances from among the nearest neighbors. Is there a risk of overfitting to anomalies or outliers in neighbors? How can this issue be resolved?

8. For image data, how exactly can the convex hull and dual representation be constructed? What modifications would be needed compared to tabular data?

9. The paper uses Euclidean distance to find nearest neighbors. How sensitive are the results to the choice of proximity measure? When would alternatives like cosine similarity be more appropriate?

10. The optimization problem to map dual coefficients to primal coefficients seems simple for linear model. But how can this mapping be achieved for non-linear surrogate models like NAM?
