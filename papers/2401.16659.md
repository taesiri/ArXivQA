# [History-Aware Conversational Dense Retrieval](https://arxiv.org/abs/2401.16659)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
- Conversational search systems need to understand the context from previous turns in the conversation to formulate good search queries. 
- However, existing methods simply concatenate the full conversation history to the current query, which can be long and noisy. This leads to models overly relying on irrelevant historical information instead of focusing on the current query.

Proposed Solution - HAConvDR:
- Performs pseudo relevance judgment (PRJ) between current query and each historical turn to decide if a turn is relevant. This uses both the historical query and its ground truth passage.
- Selects only relevant turns for context-denoised query reformulation to reduce noise.  
- Mines additional positive and negative training examples from historical passages based on their PRJ results. Pseudo positives from relevant turns and hard negatives from irrelevant turns.
- New history-aware contrastive learning objective using mined supervisions along with original query-passage pair.

Main Contributions:
- Novel way to leverage historical ground truth passages as extra supervision signals through PRJ and mining.
- Outperforms state-of-the-art methods on two conversational search datasets, especially for long conversations with topic shifts. 
- Comprehensive analysis providing insights into the role of relevant historical turns in enhancing model's history modeling capability.
- Demonstrates the feasibility of using top retrieved passages when ground truths are not available.

In summary, the paper presents an effective technique to exploit historical information in conversations via selective context modeling and mining extra supervisions for better history handling ability. The gains are more significant for complex conversations with shifts in topics.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a history-aware conversational dense retrieval method called HAConvDR that performs context-denoised query reformulation and mines additional supervision signals from historical turns to improve retrieval effectiveness, especially for long conversations with topic shifts.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a new history-aware contrastive learning strategy called HAConvDR for conversational dense retriever training. Specifically, it incorporates two key ideas:

1) Context-denoised query reformulation: It generates pseudo relevance judgments to select relevant historical turns for reformulating the current query, in order to reduce noise from irrelevant history. 

2) Automatic mining of supervision signals from historical turns: It leverages historical ground-truth passages deemed relevant to the current turn as pseudo positives, and irrelevant ones as hard negatives, to enhance the contrastive learning process.

Through experiments on two conversational search datasets, the paper shows HAConvDR outperforms existing methods for conversational retrieval, especially for long conversations with topic shifts. The analyses also provide insights into how modeling the relevance of historical turns can benefit the overall retrieval effectiveness.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- History-Aware Conversational Dense Retrieval (HAConvDR): The proposed method for improving conversational search by better incorporating relevant history and mining additional supervision signals.

- Conversational query reformulation (CQR): Reformulating queries in a conversational setting by incorporating context. 

- Conversational dense retrieval (CDR): Retrieving relevant passages by encoding conversational context into dense representations.

- Pseudo relevance judgment (PRJ): Assessing relevance of historical turns by evaluating impact on current turn retrieval. Used for context denoising and mining extra supervisions. 

- Context-denoised query reformulation: Reformulating queries by selecting relevant historical turns judged by PRJ.

- History-aware contrastive learning: Contrastive learning framework enhanced with mined pseudo positives and hard negatives from historical turns.

- Shortcut history dependency: Issue where models rely excessively on historical turns while ignoring current query.

- Topic shift/topic switch: Common phenomenon in conversations where the focus changes between different subtopics.

So in summary, key terms cover the proposed HAConvDR method, task setup for conversational search, and some of the key issues it aims to address.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a pseudo relevance judgment (PRJ) approach to select relevant historical turns. What are the key insights behind using both the historical query and passage for PRJ compared to only using the historical query? What are the limitations of only using the historical query for PRJ?

2. The paper leverages additional supervision signals from historical turns deemed relevant by PRJ. What is the intuition behind using relevant historical passages as pseudo positives? What kind of relationship do you think exists between the current query and these pseudo positives?

3. Hard negatives play an important role in contrastive learning. Compare and contrast the historical hard negatives used in this paper with other common approaches for obtaining hard negatives such as BM25 retrieval. What are the key differences and why might the historical hard negatives be more useful?

4. The performance improvement of the proposed method is more significant on the TopiOCQA dataset than the QReCC dataset. Analyze the differences between these two datasets and explain why the method works better for TopiOCQA.

5. The ablation study shows removing pseudo positives causes a larger performance drop than removing hard negatives. Why do you think the pseudo positives provide a stronger training signal? What does this reveal about the nature of positives versus negatives in contrastive learning?

6. The paper shows an interesting trend where the percentage of relevant history first decreases then plateaus as the conversation evolves. Analyze this trend and discuss what it might indicate about the change of history dependency over the course of a long conversation.

7. Qualitatively analyze the t-SNE visualization provided in the paper. How does the model trained with the proposed method better distinguish between the current query's gold passage versus distractors compared to the vanilla model?

8. When historical ground-truth passages are not available, the paper proposes using top-retrieved passages as a substitute. Discuss the limitations of this approach and how it might impact performance compared to having the real ground truths. Suggest ways to improve the adaptation.

9. Beyond the methods explored in this paper, propose other potential ways to obtain or approximate historical ground-truth passages in a real application where explicit ground truths are not logged. What are the advantages and disadvantages of your proposed approaches?

10. The paper focuses on exploiting historical ground-truth passages rather than the queries. Propose ways to also take advantage of historical queries in addition to the passages, and discuss challenges that need to be addressed.
