# [Improving Legal Judgement Prediction in Romanian with Long Text Encoders](https://arxiv.org/abs/2402.19170)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Legal documents tend to be very long which poses challenges for standard Transformer models like BERT to process due to their limitations on sequence length.  
- Specialized solutions are needed to handle long documents in the legal domain, especially for low-resource languages like Romanian.
- Existing multilingual language models (LLMs) also underperform on legal judgment prediction (LJP) tasks in Romanian.

Proposed Solution:
- Experiment with different methods to extend Transformer models to handle longer sequences:
  - Split documents into multiple blocks of 512 tokens
  - Build Longformer variants of JurBERT with increased max sequence lengths
  - Employ SLED encoding to split text into overlapping blocks
- Compare specialized JurBERT models versus general LLMs like Llama2 and Okapi
- Test on 4 legal datasets in Romanian related to banking cases, including real-world long documents

Key Results:
- SLED encoding delivers best performance on dataset with long real-world cases
- Specialized vocabulary of JurBERT more efficient at encoding legal texts
- Multilingual LLMs underperform due to little Romanian training data
- Long sequence length alone not enough, still needs specialized modelling

Main Contributions:
- First analysis of SLED encoding for LJP in Romanian 
- Show specialized modelling critical for good performance in low-resource legal NLP
- Demonstrate encoding long documents boosts accuracy on real-world datasets
- Highlight need for methods to handle long sequences in legal domain
- Provide benchmark for Romanian LJP with long document support

The key conclusion is that both specialized modelling and long context encoding are crucial to effectively apply Transformer models on legal judgment prediction tasks for long documents in low-resource languages like Romanian.


## Summarize the paper in one sentence.

 This paper investigates methods for handling long legal documents in Romanian to improve legal judgment prediction, finding that using SLED encoding to process longer contexts significantly increases performance compared to baseline methods.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is:

The paper investigates methods for handling long document lengths in legal judgment prediction for Romanian, a low-resource language. Specifically, it shows that using a SLED-style encoding to process longer document contexts significantly improves performance on legal judgment prediction tasks compared to baseline methods. This is especially important for low-resource languages where language-specific LLMs with long-context support are not yet available. 

The key findings are:

1) Encoding long documents with SLED can provide an important increase in performance for legal judgment prediction.

2) Multi-lingual LLMs currently underperform on legal judgment prediction in Romanian, both on smaller and larger documents. Specialized solutions still outperform them in this low-resource setting.

In summary, the paper demonstrates the need for methods that can process long sequences and leverage specialized vocabularies to effectively handle legal documents in low-resource languages. The SLED encoding approach is shown to be an effective way to achieve improved performance.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, the keywords associated with it are:

"legal judgement prediction, long context encoding, Romanian language"

These keywords are listed at the end of the abstract:

"\Keywords{legal judgement prediction, long context encoding, Romanian language}"

So the key terms that summarize the focus of this paper are:

- legal judgement prediction - referring to the task of predicting the outcome of legal cases
- long context encoding - referring to methods to handle long document texts
- Romanian language - indicating the paper deals with these tasks for the Romanian language specifically


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper experiments with splitting long legal documents into shorter sequences in various ways (2*512 tokens, 3*512 tokens, 32*256 tokens) to handle longer contexts. Why did the authors choose these specific split configurations? What are the trade-offs with each approach?

2. The SLED encoding method seems to work best for the small BRDCases dataset. Why do you think properly encoding longer contexts is more important for small and noisy datasets compared to the larger BankingCases set? 

3. The paper shows that specialized vocabularies are much more efficient at encoding legal texts compared to general vocabularies. Can you explain why this is the case? Does this indicate intrinsic limitations of general vocabularies for specialized domains?

4. The authors claim that current multilingual LLMs (like Llama2 and Okapi) underperform on legal judgement prediction in Romanian. What deficiencies do you think these models have that cause this underperformance? 

5. The paper evaluates performance using AUC. What are some limitations of using AUC for a classification task? Would other metrics like F1 be better suited? Why or why not?

6. How robust do you expect the improvements from SLED encoding to be as the size of the BRDCases dataset scales up? Would the relative gains diminish or be consistent?

7. The authors use handcrafted features related to location and time of each case. How impactful were these features? Could an end-to-end model learn to use such metadata implicitly?

8. What kinds of biases could exist in the BRDCases dataset that contains legal documents from a single bank? How could these biases impact model performance?

9. The authors claim their real-world BRDCases data is less noisy than BankingCases. What could be some sources of noise in both datasets? How can noise impact model performance?

10. The paper focuses only on Transformer models. What other model architectures could be effective for legal judgement prediction tasks? What modifications would be needed to handle long sequences?
