# Least-to-Most Prompting Enables Complex Reasoning in Large Language   Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, it appears the central research question is:How can complex reasoning skills be taught to large language models using only a small number of demonstration examples, without any training or fine-tuning? More specifically, the paper investigates an approach called "least-to-most prompting" for enabling language models to generalize to problems more difficult than those provided in the prompts. The key ideas are:1) Breaking down complex problems into simpler subproblems2) Solving the subproblems sequentially, with answers to earlier subproblems facilitating solutions to later ones3) Implementing both the decomposition and solving steps via prompting, without any model trainingThe paper hypothesizes that least-to-most prompting will outperform other prompting techniques like chain-of-thought prompting in terms of easy-to-hard generalization. Experiments on symbolic manipulation, compositional generalization, and math reasoning tasks are conducted to test this hypothesis.In summary, the central research question is how to design effective prompting strategies to teach complex reasoning skills to large pre-trained language models using very few examples, with a focus on generalization to more difficult problems. Least-to-most prompting is proposed and evaluated as a promising approach.


## What is the main contribution of this paper?

The main contribution of this paper seems to be proposing a novel prompting strategy called "least-to-most prompting" to enable large language models to solve problems that are more complex than the examples provided in the prompts. The key ideas of least-to-most prompting are:1) Breaking down a complex problem into a series of simpler subproblems.2) Solving each subproblem sequentially, where solving one subproblem is facilitated by the answers to previously solved subproblems. Both the decomposition and solving stages are implemented via prompting, without any model training or fine-tuning.The authors demonstrate that least-to-most prompting enables models like GPT-3 to achieve strong performance on tasks involving symbolic manipulation, compositional generalization, and math reasoning, even generalizing to test cases more difficult than the prompt examples. A key result is that with just 14 examples, GPT-3 can solve the full SCAN benchmark using least-to-most prompting, reaching over 99% accuracy on all splits. This is notable since prior specialized models for SCAN are trained on the full dataset of over 15,000 examples.Overall, the paper proposes a novel prompting strategy to improve generalization and shows its effectiveness on various reasoning tasks. The idea of breaking down problems and leveraging solutions to simpler subproblems seems to be the main technical contribution.
