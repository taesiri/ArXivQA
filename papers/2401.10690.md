# [Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and   unfairness in dyadic regression models](https://arxiv.org/abs/2401.10690)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Dyadic regression models predict real-valued outcomes for pairs of entities (e.g. predicting a user's rating for a product). These models are important in many domains but can exhibit unfair biases. 
- Specifically, non-uniform distributions of observed values for individual users and items lead to biased predictions that just gravitate towards the average past value. This is named "eccentricity bias".
- Standard evaluation metrics like RMSE only measure overall error and fail to detect such biases. This is problematic as biases can cause issues in critical applications.

Proposed Solution:  
- Introduce a new metric called EAUC (Eccentricity-Area Under Curve) that measures model performance across all levels of "eccentricity" - how much an observed value deviates from the expected average for that user-item pair.
- EAUC quantifies the bias and ability to handle uncommon cases. Lower EAUC indicates lower bias. Values range from 0 (perfect, unbiased) to 0.5 (biased predictor).

Main Contributions:
- Show that state-of-the-art dyadic regression models exhibit strong eccentricity bias, performing far worse than random in eccentric cases.
- Demonstrate global metrics like RMSE cannot detect this severe bias.
- Propose EAUC to evaluate model bias/fairness by accounting for eccentricity of samples.
- Provide comprehensive analysis across datasets and models showing prevalence of bias and that EAUC reliably quantifies it.
- Suggest adaptation of Kolmogorov-Smirnov statistic to quantify susceptibility of datasets to induce bias.

In summary, this paper identifies and provides solutions for addressing an important fairness issue in dyadic regression models, caused by non-uniformity in observed value distributions. The EAUC metric proposed enables proper bias-aware evaluation.


## Summarize the paper in one sentence.

 This paper introduces a new metric called Eccentricity-Area Under the Curve (EAUC) to evaluate bias and unfairness in dyadic regression models by capturing their tendency to make increasingly worse predictions as the target values deviate further from a user's or item's average historical values.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1) Showing that state-of-the-art dyadic regression models exhibit a strong predictive bias, skewing towards the average observed values of each user and item's past interactions. This leads to poor performance on non-regular cases and algorithmic unfairness. 

2) Demonstrating limitations of global error metrics like RMSE and MAE which are typically the only metrics used to evaluate dyadic regression models. These metrics fail to detect the identified predictive bias.

3) Proposing a new metric called EAUC (Eccentricity-Area Under the Curve) which provides a bias-aware assessment of model performance by quantifying the degree of eccentricity bias and subsequent unfairness in dyadic regression models.

In summary, the key contribution is identifying limitations in current evaluation protocols for dyadic regression models, demonstrating the prevalence of predictive bias issues leading to potential unfairness, and introducing a new metric to measure this bias to enable more comprehensive, bias-aware assessments.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts covered are:

- Dyadic regression models: Models that predict real-valued outcomes for pairs of entities, like users and items. Used in many domains like recommender systems or personalized medicine.

- Eccentricity bias: The paper introduces this concept to refer to the bias of dyadic regression models to skew predictions towards the average past observed values of individual entities, leading to poor performance on non-regular cases.  

- Algorithmic fairness/unfairness: The paper examines how eccentricity bias can lead to unfairness issues and risks in real-world applications of dyadic regression models.

- Evaluation metrics: The paper analyzes limitations of global error metrics like RMSE and MAE in detecting eccentricity bias, and proposes a new metric called EAUC to quantify this bias.

- Bias mitigation: The paper shows experimentally that conscious mitigation of eccentricity bias leads to lower EAUC, demonstrating its adequacy.

In summary, the key focus is on analyzing potential biases and fairness considerations in dyadic regression models, limitations of current evaluation practices, and proposing improved bias-aware evaluation.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a new metric called EAUC (Eccentricity-Area Under the Curve) to evaluate dyadic regression models. Can you explain in detail the steps involved in computing EAUC? What is the intuition behind using eccentricity of the samples in defining this metric?

2. One of the key ideas presented is the concept of "eccentricity bias" in dyadic regression models. Can you clearly define what constitutes eccentricity bias? Why is it problematic in real-world applications involving dyadic data?

3. The paper argues that global error metrics like RMSE and MAE are insufficient to detect eccentricity bias in models. Can you critically examine this argument? What specific limitations do RMSE/MAE have in this context?  

4. Explain the working of the debiasing corrections presented in Section 4.2 of the paper. How exactly are they learning and correcting the bias? Analyze the differences between the Clipping and Sigmoid approaches.

5. The difficulty measure $D_{KS_{\mathcal{D}}}$ is proposed to quantify the non-uniformity of value distributions. Intuitively explain why higher non-uniformity results in increased model bias. Is there a theoretical basis you can provide?

6. For the TripAdvisor dataset results in Table 2, the Dyad Average baseline obtains the best MAE score. But its EAUC is higher than the MF model. Critically analyze what this implies about the metrics.

7. The paper focuses exclusively on regression tasks over dyadic data. Do you think similar biases could exist even for classification or ranking models over such data? Justify your view.

8. Real-world dyadic datasets often have additional contextual attributes. How can they be utilized to mitigate the identified bias? Explain with examples.

9. The analysis in the paper relies on specific benchmark datasets and models. What steps would you take to ensure the observed phenomena generalizes well to unseen data?

10. The paper motivated the problem from a fairness perspective but did not explicitly measure fairness. What specific statistical measures of fairness can be used along with EAUC? Explain suitable options.
