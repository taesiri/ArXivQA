# [Neural Stochastic Dual Dynamic Programming](https://arxiv.org/abs/2112.00874v1)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper tries to address is:

How to efficiently solve multi-stage stochastic optimization (MSSO) problems in high dimensions with long horizons?

The paper proposes a new approach called Neural Stochastic Dual Dynamic Programming (\algname or \algshort) to address the limitations of current state-of-the-art methods like Stochastic Dual Dynamic Programming (SDDP) which do not scale well due to the "curse of dimensionality". 

The key ideas are:

- Learn a neural network model to map problem instances to value function approximations that can warm-start SDDP and reduce the number of iterations needed.

- Learn a low-dimensional projection of the action space to simplify the subproblems solved in SDDP.

- Restrict the neural network to output convex piecewise linear value functions that can naturally interact with the cutting plane method in SDDP.

The hypothesis is that by meta-learning across problem instances, \algname can exploit structure in related problems to accelerate solving new instances, while retaining solution quality. Experiments on inventory control and portfolio optimization suggest the proposed approach achieves substantially better time-quality trade-offs compared to alternatives.


## What is the main contribution of this paper?

 Based on my reading, the main contribution of this paper is proposing a novel algorithm called Neural Stochastic Dual Dynamic Programming (ν-SDDP) to accelerate solving multi-stage stochastic optimization (MSSO) problems. The key ideas are:

- The paper introduces a trainable neural network module that learns to map a MSSO problem instance to a piecewise linear convex value function approximation. This allows warm-starting SDDP with a good initial value function. 

- The neural network is designed to output value functions in an intrinsically low-dimensional space. This helps alleviate the curse of dimensionality in SDDP.

- The neural module can be seamlessly integrated into the SDDP solver for further refinement, ensuring solution feasibility.

- A meta-learning strategy is used to train the neural module on prior solved MSSO instances. This allows the module to continually improve as more instances are solved, amortizing the cost.

- Evaluations on inventory control and portfolio optimization show ν-SDDP can significantly accelerate solving new MSSO instances compared to baselines like vanilla SDDP and RL algorithms, without sacrificing solution quality.

In summary, the key contribution is developing a learnable neural component to warm-start SDDP in an appropriate function space, along with a meta-learning strategy to leverage experience, which together enable faster solving of new MSSO instances.
