# MotionGPT: Finetuned LLMs are General-Purpose Motion Generators

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research focus of this paper seems to be exploring a new framework for human motion generation that can leverage multiple control signals, including both text and poses, within a unified model. Specifically, the paper introduces MotionGPT, which is proposed as a novel method capable of generating human motions using multimodal control conditions like text descriptions and single-frame poses. The central hypothesis appears to be that large language models like LLMs can be adapted to serve as effective human motion generators through proper finetuning and instruction design. By quantizing pose conditions into discrete codes and creating composite instructions using both text and pose codes, MotionGPT aims to enable LLMs to generate suitable motion sequences in response.The experiments conducted on the HumanML3D and KIT-ML datasets seem designed to validate the effectiveness of MotionGPT at motion generation under diverse control signals like text, initial poses, final poses, and random keyframe poses. The results help demonstrate that MotionGPT can achieve competitive performance to prior specialized models, while using far fewer training parameters.In summary, the key research focus is on introducing and validating MotionGPT as a novel framework that can unify text and pose based motion generation within a single model by leveraging the capabilities of large language models. The paper aims to show LLMs can be readily adapted for human motion generation when provided with properly constructed multimodal instructions.
