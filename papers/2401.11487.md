# [Towards Better Inclusivity: A Diverse Tweet Corpus of English Varieties](https://arxiv.org/abs/2401.11487)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- NLP datasets and models are predominantly composed of and trained on standard American/British English, leading to biases against non-standard varieties of English.  
- These biases have negative implications for speakers of underrepresented English varieties, including worse performance on tasks like speech recognition and sentiment analysis.

Solution:
- Create a diverse tweet corpus containing informal written text in English varieties like Indian English and Singaporean English.
- Annotate tweets using a classification system across 6 categories that measures distance from standard formal English. 
- Demonstrate biases in common language ID tools (langid.py, spaCy, Google Translate) which have 12-33% lower accuracy on non-western tweets.

Data Collection:
- Collect 170,800 geo-located tweets from 5 non-western cities and 2 western cities over 8 months in 2022.
- Preprocess data to filter out non-English tweets.

Annotation Process: 
- Develop annotation guidelines through iterative refinement and inter-annotator agreement metrics.
- Recruit and train bilingual students from target countries to label tweets. 
- Annotators label over 3,500 tweets after meeting benchmark agreement scores.

Observations:
- Distribution across categories shows greater diversity for non-western tweets.
- Code-switching is especially prevalent for Indian and Filipino tweets.  
- Informal English dominates Ghanaian and Singaporean tweets.

Future Work: 
- Expand the coverage through active learning or leveraging LLMs.
- Apply the corpus to train more inclusive NLP models for tasks like sentiment analysis.
- Include more global varieties of English in the corpus.

Main Contributions:
- Novel diverse corpus of English language varieties
- Annotation framework with categories that measure distance from standard English
- Demonstration of biases in common language ID tools on non-standard Englishes


## Summarize the paper in one sentence.

 This paper presents a diverse tweet corpus of underrepresented varieties of English, annotated using a framework aimed at capturing linguistic diversity, and shows that existing language identification tools exhibit bias towards non-western English varieties.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is:

The authors curate a dataset of tweets from countries with high proportions of underserved English variety speakers, and propose an annotation framework of six categorical classifications to measure the degree of standard English in the tweets. This annotated corpus of 170,800 tweets highlights linguistic diversity and aims to contribute to the growing literature on identifying and reducing implicit demographic discrepancies in NLP. Specifically, it demonstrates the lower accuracy of common language identification tools on non-western English varieties compared to American/British English.

In summary, the key contribution is a new linguistically diverse Twitter dataset that exposes biases in NLP models, with the goal of developing more inclusive natural language processing tools.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this paper include:

- English varieties (Hinglish, Singlish, African-American English etc.)
- Twitter corpus
- Annotation framework 
- Linguistic diversity
- Code-switching
- Non-standard English
- Language identification tools
- Bias towards non-western English varieties
- Inclusivity in NLP
- Representation of underserved communities
- Orthographic variation 
- Lexical variation
- Syntactic variation

The paper introduces a diverse Twitter corpus of different English language varieties spoken globally, with a focus on non-western, underrepresented varieties. It develops an annotation framework to categorize tweets along a spectrum of standard to non-standard English. Analysis reveals linguistic diversity through code-switching, informal lexicon, and non-standard syntax. Experiments also demonstrate biases in existing NLP tools against these non-western varieties. Overall, the paper aims to contribute to greater inclusivity, fairness and representation in NLP through increased diversity of English language data.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The authors collect tweets from 7 different countries/cities to build their diverse English varieties corpus. What were the criteria for selecting these specific locations? Could there be limitations to focusing solely on capital cities to represent linguistic diversity within a country?

2. The annotation framework consists of 6 categories that aim to measure distance from standard/formal English. Could you explain the rationale behind this pseudo-spectrum of categories? How do you think merging some categories (e.g. syntactic and non-syntactic English) would impact analysis of linguistic features? 

3. Five student annotators from the respective countries were recruited and trained to label tweets. What measures were taken to ensure the quality and consistency of annotations across different annotators? How suitable do you think student annotators are for this linguistic analysis task?

4. The confusion matrix in Figure 1 shows disagreement concentrated around the diagonal. What might this suggest about the relationships between adjacent annotation categories? Do you think breaking down the code-switched category into more nuanced labels would be beneficial? 

5. In the annotation observations, some annotators felt there was too much diversity being "lumped" into the code-switched category. What are some ways the authors could address this to better capture different types of code-switching linguistically?

6. The authors demonstrate bias in language ID tools on non-western English varieties from their corpus. What other NLP tasks do you think could exhibit similar issues? How might the corpus be used proactively to improve model performance across varieties?

7. Although Twitter provides useful informal language data, what do you see as some of the demographic limitations in using tweets as representative linguistic samples? How could the authors supplement tweets to build a more balanced corpus?

8. Active learning is suggested to efficiently expand the labeled subset of the corpus. What are some heuristic strategies you think could be effective for identifying informative unlabeled examples to label? What challenges might arise?

9. Beyond language ID, what are some specific NLP tasks you think this diverse corpus would be uniquely useful for studying? For example, how could it be used for comparative sociolinguistic analysis?

10. What ethical considerations should be kept in mind when developing NLP systems targeting underserved demographic groups, such as speakers of non-standard language varieties? How might the authorsâ€™ corpus drive positive change here?
