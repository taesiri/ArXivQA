# [Learning to Name Classes for Vision and Language Models](https://arxiv.org/abs/2304.01830)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to make vision and language models less sensitive to the choice of handcrafted class names used in text queries, and improve their ability to adapt to new datasets. The key hypothesis is that by learning optimal class-specific word embeddings from visual content, rather than using predefined class names, the models can become more robust and performant.Specifically, the paper proposes to learn a new set of word embeddings to represent classes of interest, based on the available visual data. These learned embeddings can replace the original class names in text queries, removing dependence on potentially suboptimal or erroneous handcrafted names. The paper tests this hypothesis by evaluating the proposed approach on image classification and object detection tasks. The results demonstrate improved performance in various scenarios like model adaptation, open-vocabulary recognition, and continual learning. The paper also shows the interpretability benefits of learning class names, in terms of identifying model biases and labeling errors.In summary, the central hypothesis is that learning optimal class names from visual data can enhance vision-language models, making them more robust, accurate and interpretable. The experimental results validate this hypothesis across multiple tasks and datasets.
