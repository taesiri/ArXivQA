# Towards AGI in Computer Vision: Lessons Learned from GPT and Large
  Language Models

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: What are the lessons learned from recent progress in natural language processing with large language models, particularly GPT, that could help advance computer vision towards artificial general intelligence?The key points are:- GPT and large language models have shown promising progress towards AGI in NLP through abilities like multitask learning and few-shot learning. - Computer vision has seen efforts towards unification across tasks, but is far from a system like GPT. - The key difference is NLP has established the text "world" through the chat/dialog task, allowing interaction and learning. CV lacks such environments.- The paper proposes an imaginary pipeline with 3 stages: establishing interactive environments, generative pre-training for world modeling, and instruct fine-tuning for tasks. - This is envisioned to allow CV models to learn from interaction and accomplish real-world visual tasks, moving towards AGI.In summary, the paper aims to absorb lessons from progress in NLP to outline a potential path towards AGI in computer vision, based on learning in interactive environments. The central hypothesis is that this paradigm will allow more capable and general CV models.
