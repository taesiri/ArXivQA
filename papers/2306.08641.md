# Towards AGI in Computer Vision: Lessons Learned from GPT and Large   Language Models

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: What are the lessons learned from recent progress in natural language processing with large language models, particularly GPT, that could help advance computer vision towards artificial general intelligence?The key points are:- GPT and large language models have shown promising progress towards AGI in NLP through abilities like multitask learning and few-shot learning. - Computer vision has seen efforts towards unification across tasks, but is far from a system like GPT. - The key difference is NLP has established the text "world" through the chat/dialog task, allowing interaction and learning. CV lacks such environments.- The paper proposes an imaginary pipeline with 3 stages: establishing interactive environments, generative pre-training for world modeling, and instruct fine-tuning for tasks. - This is envisioned to allow CV models to learn from interaction and accomplish real-world visual tasks, moving towards AGI.In summary, the paper aims to absorb lessons from progress in NLP to outline a potential path towards AGI in computer vision, based on learning in interactive environments. The central hypothesis is that this paradigm will allow more capable and general CV models.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It provides an analysis of the current status and recent progress towards unification in computer vision (CV), including efforts in open-world recognition, the Segment Anything task, generalized visual encoding, LLM-guided understanding, and multimodal dialog. 2. It identifies the key difference between natural language processing (NLP) and CV that has made unification more challenging in CV - the lack of interactable environments for agents to learn from, compared to the natural text environment in NLP.3. It proposes an imaginary pipeline for training stronger CV agents that involves first establishing high-quality 3D embodied environments, then generatively pre-training agents to explore and predict future frames based on their actions, and finally instruct fine-tuning the agents on real world tasks.  4. It reviews existing works related to parts of this pipeline, such as efforts in environment simulation, visual pre-training, reinforcement learning for games, and embodied CV.5. It provides perspectives on future research directions to realize this pipeline, including establishing more abundant and higher-fidelity environments, designing pre-training objectives focused on data compression, collecting large-scale human instructions for fine-tuning, and unifying tasks into a prompting system.In summary, the key contribution is identifying the weakness of current CV research as lacking interactable environments for learning, proposing a learning pipeline to address this, and outlining research directions to realize such an approach towards artificial general intelligence in computer vision.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper analyzes why computer vision lags behind natural language processing in achieving artificial general intelligence, pointing to the lack of interactive environments for pre-training as the key issue, and proposes a pipeline involving establishing environments, pre-training agents to explore and predict frames, and fine-tuning with human instructions.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research on achieving AGI in computer vision:- The paper provides a nice conceptual overview of AGI and the progress made in NLP, helping frame the challenges in achieving AGI for CV. Many other papers in this space focus more narrowly on technical details without providing this broader context. - In reviewing recent efforts towards unification in CV, the paper categorizes and succinctly summarizes work across diverse topics like open-world recognition, universal visual representations, LLM-based methods, and dialog. This provides useful synthesis and structure to a rapidly evolving research landscape.- The analysis on the limitations of proxy tasks and the lack of learning from environments provides an insightful critique on the status quo in CV research. The paper makes a compelling case for the need to establish interactive environments and pre-train generatively on agent-environment interactions.- The proposed conceptual pipeline for future CV research seems promising for making progress towards AGI. While related ideas have been explored in domains like embodied AI and robotics, the paper provides a thoughtful discussion on how CV research needs to embrace such paradigms more fully.- Compared to some other conceptual/opinion papers on this topic, this paper grounds its perspectives in detailed analysis of existing work and draws substantively from progress in NLP via models like GPT. The imagined pipeline and directions seem actionable.In summary, I think this paper makes a valuable contribution in providing cross-disciplinary context, thoughtful critiques, and a constructive vision to work towards AGI in CV. The comparative analysis and proposes future directions help advance the discourse in this emerging field.
