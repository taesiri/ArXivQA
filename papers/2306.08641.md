# Towards AGI in Computer Vision: Lessons Learned from GPT and Large   Language Models

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: What are the lessons learned from recent progress in natural language processing with large language models, particularly GPT, that could help advance computer vision towards artificial general intelligence?The key points are:- GPT and large language models have shown promising progress towards AGI in NLP through abilities like multitask learning and few-shot learning. - Computer vision has seen efforts towards unification across tasks, but is far from a system like GPT. - The key difference is NLP has established the text "world" through the chat/dialog task, allowing interaction and learning. CV lacks such environments.- The paper proposes an imaginary pipeline with 3 stages: establishing interactive environments, generative pre-training for world modeling, and instruct fine-tuning for tasks. - This is envisioned to allow CV models to learn from interaction and accomplish real-world visual tasks, moving towards AGI.In summary, the paper aims to absorb lessons from progress in NLP to outline a potential path towards AGI in computer vision, based on learning in interactive environments. The central hypothesis is that this paradigm will allow more capable and general CV models.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It provides an analysis of the current status and recent progress towards unification in computer vision (CV), including efforts in open-world recognition, the Segment Anything task, generalized visual encoding, LLM-guided understanding, and multimodal dialog. 2. It identifies the key difference between natural language processing (NLP) and CV that has made unification more challenging in CV - the lack of interactable environments for agents to learn from, compared to the natural text environment in NLP.3. It proposes an imaginary pipeline for training stronger CV agents that involves first establishing high-quality 3D embodied environments, then generatively pre-training agents to explore and predict future frames based on their actions, and finally instruct fine-tuning the agents on real world tasks.  4. It reviews existing works related to parts of this pipeline, such as efforts in environment simulation, visual pre-training, reinforcement learning for games, and embodied CV.5. It provides perspectives on future research directions to realize this pipeline, including establishing more abundant and higher-fidelity environments, designing pre-training objectives focused on data compression, collecting large-scale human instructions for fine-tuning, and unifying tasks into a prompting system.In summary, the key contribution is identifying the weakness of current CV research as lacking interactable environments for learning, proposing a learning pipeline to address this, and outlining research directions to realize such an approach towards artificial general intelligence in computer vision.
