# [MobileBrick: Building LEGO for 3D Reconstruction on Mobile Devices](https://arxiv.org/abs/2303.01932)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we create a high-quality dataset with precise 3D ground truth shapes to support research on detailed 3D object reconstruction, especially using images captured on mobile devices?

The key ideas and contributions to address this question appear to be:

- Using LEGO models as the objects of interest. Since LEGOs have known geometry, this allows for accurate alignment of ground truth 3D models to captured image sequences.

- Designing a pipeline to accurately align the LEGO 3D models to the captured images sequences, involving keypoint annotation, manual refinement, and bundle adjustment.

- Capturing data on a mobile device (iPhone) to provide a unique modality of high-res RGB images along with low-res depth maps. 

- Creating a diverse dataset of 153 LEGO models with aligned ground truth 3D shapes.

- Demonstrating the value of the dataset on tasks like multi-view reconstruction, novel view synthesis, and depth map enhancement.

In summary, the core hypothesis seems to be that creating precise 3D ground truth shapes using LEGO models and capturing images on a mobile device will produce a valuable dataset to drive progress on high-quality 3D reconstruction for mobile AR/VR and related problems. The paper details the creation of such a dataset and validates its usefulness.
