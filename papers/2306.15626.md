# [LeanDojo: Theorem Proving with Retrieval-Augmented Language Models](https://arxiv.org/abs/2306.15626)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research questions/hypotheses appear to be:1) Can open-source toolkits, data, models, and benchmarks facilitate research on machine learning methods for theorem proving, by removing barriers like private code/data and large compute requirements?2) Can retrieval-augmented language models effectively select relevant premises from a large mathematical library when proving new theorems? 3) Will a retrieval-augmented prover outperform non-retrieval baselines and state-of-the-art models like GPT-4 on the task of theorem proving?4) Can the proposed LeanDojo toolkit robustly extract training data from Lean and enable reliable interaction for evaluating theorem provers?5) Will the proposed LeanDojo Benchmark, with its novel data splits, provide a challenging testbed to evaluate whether provers can generalize to novel premises outside the training set?In summary, the central research questions seem to be around using open resources to facilitate ML research for theorem proving, and demonstrating the effectiveness of a retrieval-augmented prover on challenging theorem proving benchmarks extracted using the LeanDojo toolkit.
