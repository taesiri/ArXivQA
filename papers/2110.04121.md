# [On the Limitations of Multimodal VAEs](https://arxiv.org/abs/2110.04121)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is that multimodal variational autoencoders (VAEs) that use modality sub-sampling during training are fundamentally limited in their ability to accurately model the joint distribution of multiple modalities. Specifically, the paper argues that modality sub-sampling, where only a subset of modalities is used to train the inference network during each training step, places an undesirable upper bound on the multimodal evidence lower bound (ELBO). This prevents the model from tightly approximating the true joint distribution when there is modality-specific variation in the data.The key contributions of the paper are:- A theoretical analysis proving that modality sub-sampling introduces an irreducible discrepancy in the multimodal ELBO that depends on the amount of modality-specific information.- Empirical validation of this discrepancy on both synthetic and real multimodal datasets, showing a gap in generative quality compared to unimodal VAEs.- Demonstrating a tradeoff between generative quality and coherence when modality sub-sampling is used, revealing limitations of existing multimodal VAE methods.Overall, the central hypothesis is that sub-sampling modalities fundamentally limits the ability of multimodal VAEs to accurately model joint distributions, especially in the presence of modality-specific variation. The theoretical and empirical results support this claim.


## What is the main contribution of this paper?

Based on the abstract, it seems the main contribution of this paper is identifying and analyzing limitations of multimodal variational autoencoders (VAEs). Specifically:- The paper uncovers a fundamental limitation that applies to a large family of mixture-based multimodal VAEs. It proves that modality sub-sampling enforces an undesirable upper bound on the multimodal ELBO that limits the generative quality of these models.- Empirically, the paper showcases the generative quality gap compared to unimodal VAEs on both synthetic and real datasets. It presents tradeoffs between different variants of multimodal VAEs. - The paper finds that none of the existing approaches fulfills all desired criteria of an effective multimodal generative model when applied to more complex datasets than previous benchmarks. - Overall, the paper identifies, formalizes, and validates fundamental limitations of VAE-based approaches for modeling weakly-supervised multimodal data. It discusses implications for real-world applications.In summary, the key contribution seems to be a theoretical and empirical analysis of limitations of multimodal VAEs, especially relating to modality sub-sampling and performance on complex real-world datasets. The paper uncovers tradeoffs between different variants of multimodal VAEs and highlights open challenges for developing more effective multimodal generative models.
