# [vMAP: Vectorised Object Mapping for Neural Field SLAM](https://arxiv.org/abs/2302.01838)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the central research question this paper seeks to address is: 

How can we efficiently build object-level scene representations for neural field SLAM in real-time, without any 3D shape priors, while still enabling geometrically accurate and complete reconstruction of individual objects?

The key ideas and contributions in addressing this question appear to be:

- Representing each object instance with a separate small MLP neural field model, which encourages object completeness and coherence even under partial views. 

- Showing that many such object models can be simultaneously and efficiently optimized in real-time via vectorized training on a GPU. This enables scaling to mapping scenes with many objects.

- Demonstrating that representing objects separately leads to significantly more accurate scene-level and object-level reconstruction compared to using a single big model, while still being highly efficient in memory and compute.

- Enabling scene re-composition and rendering novel views by combining the individually optimized object models.

So in summary, the central hypothesis is that an object-centric approach with vectorized training of separate MLPs per object can enable real-time, geometrically accurate and complete neural field SLAM, without relying on 3D shape priors. The experiments seem to validate this hypothesis and show advantages over prior monolithic scene modeling approaches.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

- It presents vMAP, a real-time object-level dense SLAM system using neural field representations. Each object is represented by a small MLP neural network, enabling efficient and watertight object modeling without requiring 3D shape priors. 

- It shows that many individual neural field models (up to 50 per scene) can be simultaneously and efficiently optimized on a single GPU during live operation via vectorized training. This allows for representing complex scenes with many objects.

- It demonstrates significantly improved scene-level and object-level reconstruction quality compared to prior monolithic neural field SLAM systems like iMAP. Experiments on simulated and real datasets validate the approach.

- Object-level representation also enables scene recomposition with new object configurations. The disentangled object models can be manipulated independently.

- The system is highly efficient in terms of computation and memory, using only 40KB of parameters per object. It can process frames at 5Hz on a single GPU.

In summary, the key innovation is representing the scene as independent neural field models per object, and showing this can be done efficiently for many objects via vectorized training. This leads to better reconstruction quality and flexibility compared to monolithic scene representations.
