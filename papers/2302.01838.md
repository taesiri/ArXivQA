# [vMAP: Vectorised Object Mapping for Neural Field SLAM](https://arxiv.org/abs/2302.01838)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the central research question this paper seeks to address is: 

How can we efficiently build object-level scene representations for neural field SLAM in real-time, without any 3D shape priors, while still enabling geometrically accurate and complete reconstruction of individual objects?

The key ideas and contributions in addressing this question appear to be:

- Representing each object instance with a separate small MLP neural field model, which encourages object completeness and coherence even under partial views. 

- Showing that many such object models can be simultaneously and efficiently optimized in real-time via vectorized training on a GPU. This enables scaling to mapping scenes with many objects.

- Demonstrating that representing objects separately leads to significantly more accurate scene-level and object-level reconstruction compared to using a single big model, while still being highly efficient in memory and compute.

- Enabling scene re-composition and rendering novel views by combining the individually optimized object models.

So in summary, the central hypothesis is that an object-centric approach with vectorized training of separate MLPs per object can enable real-time, geometrically accurate and complete neural field SLAM, without relying on 3D shape priors. The experiments seem to validate this hypothesis and show advantages over prior monolithic scene modeling approaches.
