# [Automatic Scoring of Students' Science Writing Using Hybrid Neural   Network](https://arxiv.org/abs/2312.03752)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Constructed response questions allow students to demonstrate scientific knowledge application, but are time-consuming for teachers to evaluate. Machine learning (ML) models can automate scoring, but face challenges with scoring accuracy and efficiency.  
- Existing models struggle to accurately score multi-dimensional assessments across multiple rubric perspectives.

Proposed Solution:
- The authors develop a multi-perspective Hybrid Neural Network (HNN) approach to automatically score constructed student responses on an analytic rubric with multiple perspectives.

Methods:
- The HNN combines BERT embeddings, Bi-LSTM sequential processing, and attention mechanisms.
- It is applied to score middle school student explanations about gases and matter properties across 5 scoring rubric perspectives. 
- Compared to BERT, Adapted Algorithm Classifier Regressors (AACR), Naive Bayes, and Logistic Regression models.

Results: 
- The HNN achieved the highest accuracy on all 5 rubric perspectives (97.6%, 98.1%, 94.8%, 97.4%, 96.8%)
- It was significantly more accurate than the other models, outperforming Naive Bayes by 8%.
- Training and inference was over 2 times more efficient than individual BERT models.

Conclusions:
- The multi-perspective HNN approach allows accurate automatic scoring of complex multi-dimensional science assessments.  
- It leverages label semantics and text data to capture student cognitive processes.
- The methodology shows promise for improving automated scoring in education more broadly.

Main Contributions:
- A new HNN method for accurately scoring multi-faceted science explanations.
- Demonstrating superior performance over existing ML models on a real-world dataset. 
- Enhanced efficiency over individual BERT models for each rubric perspective.
- Advancing the state-of-the-art in automated assessment capabilities.
