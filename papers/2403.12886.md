# [EmoVOCA: Speech-Driven Emotional 3D Talking Heads](https://arxiv.org/abs/2403.12886)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Generating emotional 3D talking heads is challenging due to lack of datasets combining speech and expressions. Previous works use 2D videos as proxy to reconstruct 3D data, but this has limitations in modeling subtle motions. 

Proposed Solution:
- Introduce a data-driven approach to realistically combine speech and expression deformations from two 3D face datasets:
    - VOCAset (inexpressive 3D talking heads) 
    - Florence4D (3D expressive sequences without speech)
- Propose a Double Encoder/Shared Decoder (DE-SD) architecture
    - Two encoders to separately learn speech and expression features
    - Shared decoder learns to reconstruct faces from combined features
- Used DE-SD to generate EmoVOCA, a new 3D emotional talking heads dataset
- Customize FaceFormer and S2L+S2D architectures to be conditioned on emotion/intensity and train them on EmoVOCA

Main Contributions:
- Novel way to synthesize emotional 3D talking heads by combining two purely 3D datasets
- EmoVOCA dataset enabling training of emotional talking heads generators  
- Emotional extensions of FaceFormer and S2L+S2D outperform state-of-the-art methods reliant on 2D-to-3D reconstruction
- More realistic emotional expressions and lip synchronization than previous work

In summary, the paper introduces an innovative 3D data-driven approach to address lack of datasets for building emotional 3D talking heads. By combining speech and expressive datasets and generating new synthetic data, they achieve superior performance to prior work.
