# Chain-of-Thought Prompting Elicits Reasoning in Large Language Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be:How does generating a "chain of thought" - a series of intermediate reasoning steps - impact the ability of large language models to perform complex reasoning tasks?In particular, the paper explores using a simple method called "chain-of-thought prompting" to elicit reasoning abilities in large language models. In this method, the model is prompted with a few examples that demonstrate a chain of thought leading to the final answer. The key hypothesis seems to be that sufficiently large language models can generate logical chains of thought if provided with these kinds of demonstrations in the prompt. The paper then provides empirical evidence to evaluate this hypothesis across arithmetic, commonsense, and symbolic reasoning tasks.In summary, the central research question is whether chain-of-thought prompting can unlock reasoning abilities in large language models, which is assessed through experiments on a diverse set of reasoning tasks. The key hypothesis is that this method can elicit reasoning in sufficiently large models.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution seems to be proposing and evaluating a method called "chain-of-thought prompting" to improve the reasoning abilities of large language models. Specifically:- The key idea is to augment few-shot prompting exemplars with a "chain of thought" - a series of intermediate reasoning steps leading to the final answer. This is inspired by how humans break down complex reasoning tasks into multiple steps. - The paper shows that prompting large language models (specifically LaMDA, GPT-3, PaLM) with these chain-of-thought examples significantly improves performance on a diverse set of reasoning tasks: arithmetic (math word problems), commonsense reasoning, and symbolic reasoning.- The gains are especially large for more complex, multi-step reasoning problems where standard prompting has flat scaling curves. For instance, on the GSM8K math word problem benchmark, chain-of-thought prompting helps the 540B parameter PaLM model achieve state-of-the-art performance, surpassing even finetuned models.- The approach appears quite general, requiring only a few examples of reasoning chains rather than task-specific training. The paper also analyzes the types of errors, showing many could be fixed by improving arithmetic or semantic understanding abilities.In summary, the main contribution is showing how chain-of-thought prompting can unlock latent reasoning abilities in large language models, enabling significant gains on challenging reasoning tasks with minimal intervention. The simple prompting approach could be widely applicable.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on skimming through the paper, a one sentence summary could be: The paper explores how prompting large language models to generate a chain of thought, which is a series of intermediate reasoning steps, can significantly improve their ability to perform complex reasoning tasks involving arithmetic, commonsense, and symbolic reasoning.
