# [LIEDER: Linguistically-Informed Evaluation for Discourse Entity   Recognition](https://arxiv.org/abs/2403.06301)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Discourse entity (DE) recognition involves identifying novel and known entities introduced within a text. 
- Prior work found language models have basic DE recognition abilities but did not assess their knowledge of key semantic properties governing DE introduction and reference.
- The paper identifies four key properties: existence, uniqueness, plurality, and novelty. Existence means entities must be introduced before being referenced. Uniqueness means singular definites like "the dog" require one unique referent. Plurality means plural definites like "the dogs" require multiple referents. Novelty means indefinites like "a dog" introduce new discourse referents.  

Proposed Solution:
- The paper proposes the Linguistically-Informed Evaluation for Discourse Entity Recognition (LIEDER) dataset to assess language models' knowledge of the four key properties. 
- The dataset includes various context sentence types (e.g. "John owns a dog" vs "John doesn't own a dog") combined with singular or plural definite noun phrase continuations.
- By comparing language models' probability judgments on felicitous vs infelicitous continuations, the dataset can evaluate sensitivity to the key properties.

Main Contributions:
- Evaluation of four state-of-the-art language models (GPT-2, Llama, Llama 2, Code Llama) using LIEDER reveals:
  - Solid knowledge of existence, uniqueness and plurality properties governing definite noun phrases
  - Lack of understanding of the novelty property governing indefinite noun phrases
  - Overreliance on linear distance, preferring to resolve discourse references introduced more recently
- The findings indicate current language models do not reach human language understanding abilities, particularly in recognizing distinct discourse entities introduced with the same lexical items.
- More broadly, the work demonstrates the utility of linguistically principled evaluation suites for precisely diagnosing language models' semantic knowledge.

In summary, the key innovation is the LIEDER evaluation suite enabling fine-grained assessment of language models' discourse competency, revealing gaps in their ability to recognize distinct discourse entities based on the novelty condition alone. The findings help chart progress towards human-level language understanding.
