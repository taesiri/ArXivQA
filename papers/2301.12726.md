# Specializing Smaller Language Models towards Multi-Step Reasoning

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is whether it is possible to specialize smaller language models to achieve improved performance on targeted reasoning abilities, such as multi-step math reasoning via chain-of-thought prompting. Specifically, the paper investigates whether smaller language models (<= 10B parameters) can emulate the strong chain-of-thought reasoning capabilities exhibited by very large models (100B+ parameters) through a process of "model specialization". The hypothesis is that large models have strong but general modeling power spread over many tasks, while smaller models with limited capacity can concentrate their capacity on a specific target task and achieve decent improved performance on that task. The paper focuses on multi-step math reasoning as a testbed for studying this hypothesis of specializing smaller models towards particular reasoning abilities. The overarching goal is to understand how to improve the parameter efficiency and accessibility of powerful large language models by transferring their capabilities to smaller specialized models.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. Showing that chain-of-thought reasoning ability for math word problems can be improved in smaller language models (~10B parameters or less) through a process of "model specialization". This challenges the previous belief that chain-of-thought reasoning only emerges in very large models (100B+ parameters).2. Demonstrating a tradeoff between general reasoning abilities and specialized math reasoning abilities when specializing smaller models. The paper shows that as models are specialized on math reasoning, they lose performance on generic reasoning tasks like those in the BigBench benchmark. 3. Providing an analysis of the model specialization process, including how in-distribution vs out-of-distribution performance evolves during training, and the differences between starting from a raw pretrained checkpoint vs an instruction-tuned checkpoint.4. Introducing techniques like dynamic programming alignment of tokenizers and model selection based on multiple datasets to improve specialization and generalization. 5. Showing that after specialization, smaller models exhibit log-linear scaling curves on math reasoning similar to large models, rather than the flat scaling curves previously observed, suggesting chain-of-thought reasoning may not be an "emergent" ability exclusive to large models.In summary, the main contribution is demonstrating that specialized smaller models can attain improved reasoning abilities on targeted tasks like math word problems, at the expense of general reasoning skills. The paper provides an in-depth analysis of this specialization process and tradeoffs involved.
