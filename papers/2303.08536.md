# [Watch or Listen: Robust Audio-Visual Speech Recognition with Visual   Corruption Modeling and Reliability Scoring](https://arxiv.org/abs/2303.08536)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is: How can we develop a robust audio-visual speech recognition (AVSR) system that performs well even when both the audio and visual inputs are corrupted? 

The key points are:

- Previous AVSR systems assume clean visual inputs and mainly handle corrupted audio inputs. But in real situations, visual inputs can also be corrupted (e.g. occluded faces, blurry/noisy video).

- The authors analyze that current AVSR systems actually perform worse than audio-only ASR systems under joint audio-visual corruption. 

- They propose two main contributions to handle this:
  - Audio-visual corruption modeling during training to make the model robust.
  - A novel Audio-Visual Reliability Scoring (AV-RelScore) module that scores the reliability of each modality's features and emphasizes the more reliable ones.

- Experiments show the proposed method outperforms previous AVSR systems under various audio-visual corruption scenarios, demonstrating its robustness.

In summary, the central hypothesis is that by explicitly modeling audio-visual corruption and scoring reliability during training/inference, they can develop an AVSR system that is robust to real-world audio-visual input degradations.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel audio-visual speech recognition (AVSR) framework that is robust to corrupted multimodal inputs, including both audio and visual corruption. Specifically, the key contributions are:

- Analyzing the robustness of previous AVSR models under different types of input corruption, including audio-only, visual-only, and audio-visual corruption. The analysis shows that previous AVSR models are not robust to multimodal corruption.

- Proposing audio-visual corruption modeling with occlusion patches and noises to simulate real-world corruption during training. This is shown to be important for developing robust AVSR models. 

- Proposing a new AVSR framework called Audio-Visual Reliability Scoring (AV-RelScore) that can evaluate the reliability of each modality's features and emphasize more reliable representations. This allows focusing on less corrupted modalities.

- Conducting comprehensive experiments on LRS2 and LRS3 datasets validating the effectiveness of the proposed audio-visual corruption modeling and AV-RelScore. The method achieves state-of-the-art performance.

In summary, the key contribution is developing a novel AVSR framework that is robust to simultaneous corruption in both audio and visual modalities, through corruption modeling and reliability scoring. This advances AVSR performance in noisy real-world conditions.
