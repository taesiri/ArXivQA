# [Self-supervised Learning of Implicit Shape Representation with Dense   Correspondence for Deformable Objects](https://arxiv.org/abs/2308.12590)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is how to learn an implicit shape representation that can represent deformable 3D objects with large deformations and provide dense correspondence across different poses, in a fully self-supervised manner without requiring additional semantic priors or annotations. The key ideas and contributions to address this question are:- Proposing to constrain the template shape in the same latent space as the training shapes to get a reasonable template and prevent artifacts.- Designing a novel local rigid constraint formulation that enforces rigid transformation in local regions and prevents flip mappings. This is an ARAP-equivalent constraint for implicit representations. - Introducing hierarchical rigid constraints with local, neighborhood, and piece-wise components to incorporate spatial context and large deformation priors to reduce ambiguity in joint learning of shape and correspondence.- Demonstrating the capability of the learned representation on shape reconstruction, interpolation, correspondence estimation, and applications like texture transfer and shape editing.So in summary, the main research contribution is a new self-supervised framework to learn an implicit neural representation for deformable 3D shapes that can effectively handle large deformations and establish dense correspondences, without needing any semantic priors or annotations. The key ideas are the embedded shape space, novel rigid constraints, and hierarchical multi-scale regularization.


## What is the main contribution of this paper?

Based on my understanding, the main contributions of this paper are:1. It proposes a novel self-supervised approach to learn an implicit neural representation for deformable 3D objects like humans and animals. The key advantage is that it does not require any additional annotations like skeletons or skinning weights.2. It introduces three key techniques to handle large deformations in a self-supervised manner:- Constraining the template shape to lie in the same latent space as the training shapes. This helps regularize the template shape.- A new local rigid constraint formulation that enforces rigid transformations locally while avoiding reflection issues. This is an ARAP-equivalent constraint for implicit representations. - A hierarchical rigid constraint with local, neighborhood, and part-level components to incorporate spatial context and deal with large rigid parts.3. Extensive experiments show the method can effectively represent shapes undergoing large deformations. Applications like texture transfer and shape editing also produce good results.In summary, the main contribution is a novel self-supervised framework to learn an implicit neural representation for deformable shapes that does not need semantic domain-specific priors like skeletons. The techniques to handle large deformations in a self-supervised manner are key to making this approach work well.
