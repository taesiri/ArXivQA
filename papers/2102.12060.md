# [Teach Me to Explain: A Review of Datasets for Explainable Natural   Language Processing](https://arxiv.org/abs/2102.12060)

## What is the central research question or hypothesis that this paper addresses?

 After carefully reading the paper, it seems the central research question is:

What can we learn from existing datasets that contain human-annotated textual explanations, and what recommendations can we provide for collecting high-quality explainable NLP datasets in the future? 

The authors review and summarize the literature on collecting textual explanations for explainable NLP. They identify three main types of textual explanations that have been collected in datasets: highlights, free-text, and structured. The paper analyzes strengths and shortcomings of existing data collection methodologies for each explanation type. It highlights important considerations from the interplay between data collection, modeling, and evaluation assumptions. The authors provide recommendations for future data collection based on what has been learned so far in this emerging research area. The overarching goal is to promote better practices and standardization when creating new textual explanation datasets for explainable NLP.


## What is the main contribution of this paper?

 The main contribution of this paper is a comprehensive review and analysis of datasets for explainable natural language processing (ExNLP). Specifically:

- The paper surveys and categorizes 65 existing ExNLP datasets into three main types: highlights, free-text explanations, and structured explanations. It provides an overview of each dataset and how the explanations were collected.

- It highlights and discusses important lessons learned from analyzing existing ExNLP data collection methodologies. In particular, it focuses on two main case studies: (1) issues with using human-annotated highlights for evaluating model-generated highlights, and (2) the emergence of structured explanations as an alternative to purely free-text explanations. 

- It synthesizes best practices and gives recommendations for future ExNLP dataset construction. This includes suggestions for ensuring data quality, increasing diversity, embracing natural structure in explanations, and the importance of documenting data collection details and constraints.

Overall, the main contribution is a thorough literature review of ExNLP datasets coupled with an insightful critical analysis and synthesis of recommendations for the research community. The paper helps standardize practices around ExNLP dataset creation and highlights important considerations for using existing datasets.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper reviews existing datasets for explainable NLP, categorizes them into three types (highlights, free-text, and structured), analyzes their collection methodologies, and provides recommendations for future dataset creation based on lessons learned.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other research on explainable natural language processing (ExNLP) datasets:

- Scope - This paper provides a broad review of 65 datasets with textual explanations, categorizing them into highlights, free-text, and structured explanations. Other surveys tend to focus on a specific explanation type or application area. For example, some reviews cover just free-text rationales or visual explanations. This paper aims to synthesize findings across different explanation formats.

- Critical analysis - The authors provide a more critical analysis of ExNLP dataset creation compared to other surveys. They highlight potential issues like insufficient or non-comprehensive highlights, lack of annotation diversity leading to artifacts, and over-constraining free-text explanations. Other reviews tend to just summarize datasets without as much discussion of limitations.

- Recommendations - A key contribution is the set of recommendations for creating higher quality ExNLP datasets. These cover best practices like using a "collect-and-edit" approach, assessing task explainability, and embracing natural structure in explanations. Other surveys focus less on guidelines for future data collection.

- Up-to-date - At 65 datasets, this is one of the most comprehensive reviews to date. The authors cover very recent datasets and preprints through 2021. Other surveys cover fewer or older datasets since this is a rapidly expanding field.

In summary, this review provides a uniquely broad, critical, and up-to-date analysis of ExNLP datasets compared to other literature surveys. The actionable recommendations for improving dataset creation are a notable addition not found in most reviews.


## What future research directions do the authors suggest?

 Here are some of the main future research directions suggested by the authors:

- Studying how to best define and utilize the second class of "explaining observed events or phenomena" datasets (discussed in Section 3 and Appendix A). The authors suggest these datasets currently do not directly serve the three main goals of ExNLP, but could potentially be useful in the future.

- Exploring contrastive and negative explanations more thoroughly (Section 6.3), such as by collecting contrastive free-text or structured explanations. The authors believe these types of explanations could help train more robust and better-explaining models.

- Developing methods to automatically measure meaning overlap between explanations, which is needed to quantify diversity (Section 6.4). The authors suggest drawing from fundamental NLP research.

- Studying the quality-quantity tradeoff in automatic explanation collection methods (Section 5.1). The authors believe this is an important direction for future work.

- Exploring other potential necessary properties of human explanations besides those discussed in the paper (end of Appendix A). The authors focus on properties most relevant to current ExNLP research but acknowledge others may exist.

- Continuing to critically evaluate explanation collection methodologies to promote standardization and reveal implications for downstream uses (throughout). The authors call for explanation datasets and their constraints to be thoroughly documented.

In summary, the main suggested directions are: better defining the emerging second class of ExNLP datasets, collecting new annotation types like contrastive explanations, developing methods to quantify explanation diversity, studying the quality-quantity tradeoff, identifying other key properties of human explanations, and continued critical evaluation of explanation collection practices.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper reviews datasets for explainable natural language processing (ExNLP) that contain human-annotated textual explanations. It summarizes 65 existing ExNLP datasets into three main types: highlights, free-text explanations, and structured explanations. The paper analyzes the strengths and shortcomings of different data collection methodologies used for these datasets. Two key points are highlighted - first, that common methods for collecting highlight explanations can result in datasets that are insufficient or non-comprehensive, causing issues for model training and evaluation. Second, that while some researchers discard template-like free-text explanations as low quality, embracing structure in explanations can be useful when it naturally arises from a task. The paper also provides recommendations for creating higher quality ExNLP datasets in the future, such as using a "collect-and-edit" approach and increasing diversity of explanations. Overall, the paper aims to promote discussion and standardization around ExNLP dataset development.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper provides a review of existing datasets for explainable natural language processing (ExNLP) research. The authors identify and organize 65 existing datasets into three main types: those with highlight, free-text, or structured explanations. They analyze the strengths and weaknesses of different data collection methodologies that have been used. The key points made are:

Paragraph 1) For highlight explanations, the authors find that existing human annotations are not necessarily sufficient nor comprehensive for evaluating model-generated highlights. They recommend avoiding highlights with low sufficiency, collecting comprehensive highlights to evaluate faithfulness, and carefully reporting collection details like instructions given to annotators. They warn researchers to avoid making assumptions about properties like comprehensiveness based on general dataset descriptions. 

Paragraph 2) For free-text explanations, the authors use a case study of two datasets to show that not all template-like explanations are undesirable, and structured explanations should be embraced when appropriate for a task. The authors give recommendations to improve free-text explanation quality, like teaching the task, addressing ambiguity, using a collect-and-edit approach, recruiting diverse annotators, and collecting contrastive or negative explanations. They synthesize recommendations from related work to further increase diversity and reduce artifacts.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper presents a review of datasets for explainable natural language processing (ExNLP). The authors first define key terminology related to ExNLP, such as highlights, free-text explanations, and structured explanations. They then provide an overview of 65 existing ExNLP datasets, categorizing them based on the type of textual explanation they contain - highlights, free-text, or structured. The datasets are summarized in tables detailing the task, type of explanation, collection method, number of instances, etc. 

The authors then analyze what can be learned from the various dataset collection methodologies. They focus on two important points - the traditional process of collecting highlight explanations and its discrepancies with evaluating highlight models, and the emergence of structured explanations. They argue that assumptions made during data collection influence downstream uses of the datasets. The authors also discuss strategies to increase explanation quality and diversity. Overall, the main method is a comprehensive literature review categorized into highlight, free-text, and structured explanation datasets, along with a critical analysis of collection methodologies and recommendations for future work.


## What problem or question is the paper addressing?

 The paper is reviewing datasets that contain human-annotated textual explanations for machine learning models. These explanations are used to train more interpretable models and evaluate how well models can generate explanations. The key questions and goals of the paper are:

- To categorize and summarize existing datasets with textual explanations (highlights, free-text, and structured).

- To analyze the strengths and shortcomings of different data collection methodologies used for these explanation datasets. 

- To provide recommendations for collecting high-quality explanation datasets in the future.

The paper argues that dataset collection is an under-scrutinized aspect of machine learning research. By critically examining explanation dataset construction, the authors aim to highlight best practices, standardize procedures, and avoid common pitfalls. The paper focuses specifically on textual explanations as they are predominant across tasks and modalities. It provides an in-depth analysis of how data collection decisions influence downstream modeling and evaluation of interpretable systems.

In summary, the key focus is on reviewing and synthesizing prior work on collecting textual explanation datasets, in order to guide and improve future research in interpretable and explainable AI. The paper examines the assumptions, constraints, and procedures involved in constructing these datasets.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts include:

- Explainable Natural Language Processing (ExNLP): The main focus of the paper is examining datasets for explainable NLP, which the authors refer to as ExNLP. This is a growing subfield of NLP focused on producing explanations for model predictions.

- Textual explanations: The paper focuses specifically on datasets containing textual explanations, as opposed to other modalities. The main types examined are highlights, free-text explanations, and structured explanations.

- Highlights: Subsets of input words or sentences that explain a model's prediction. Should be compact and sufficient. 

- Free-text explanations: Free-form natural language justifications not constrained to words in the input. More expressive than highlights.

- Structured explanations: Explanations with some constraints or structure, like requiring certain inference rules. A middle ground between highlights and free-text.

- Human-annotated explanations: The paper examines many datasets where humans wrote or selected explanations for model training, evaluation, and analysis.

- Data collection methodologies: The paper analyzes strengths and shortcomings of different methods for collecting human explanation datasets.

- Evaluation: Evaluation methodologies for generated explanations using human explanations, like plausibility, sufficiency, comprehensiveness, and faithfulness. 

- Recommendations: The paper synthesizes recommendations for collecting high-quality explanation datasets based on analysis of prior work.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 suggested questions to summarize the key points of the paper:

1. What is the purpose and scope of the paper?

2. What are the main categories of textual explanations identified in the paper? 

3. What are the key strengths and weaknesses of existing datasets identified in the paper?

4. What recommendations does the paper make for improving dataset quality and diversity?

5. What is the importance of annotator diversity and collecting multiple explanations per instance? 

6. How should highlights be collected to enable evaluation of both plausibility and faithfulness?

7. Why might entirely free-text explanations not always be the most natural form? 

8. When is embracing structure in explanations preferred over entirely free-form ones?

9. What are some effective strategies for quality control in collecting explanations?

10. How can contrastive and negative explanations contribute to model training and evaluation?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper introduces a new dataset with textual explanations. What was the motivation behind creating this new dataset? How does it differ from existing datasets for explainable NLP?

2. The paper categorizes explanations into three main types: highlights, free-text, and structured. Can you explain the key differences between these types of explanations? What are some pros and cons of each?

3. The paper argues that highlights collected for existing datasets may not always be sufficient or comprehensive. What do the authors mean by "sufficiency" and "comprehensiveness" in this context? Why are these properties important?

4. The authors recommend collecting comprehensive highlights to better evaluate both plausibility and faithfulness of highlight explanations. What is the reasoning behind this recommendation? How does comprehensiveness enable the evaluation of faithfulness?

5. The paper suggests that entirely free-text explanations are not always the most natural form of explanation. Can you summarize the authors' perspective on structured vs. free-text explanations? When might incorporating structure into explanations be beneficial?

6. The paper advocates for a "Collect-and-Edit" approach to improve explanation diversity and reduce annotator bias. How exactly does this two-stage annotation process work? What are the expected benefits compared to single-stage collection?

7. Several strategies are proposed to improve explanation quality, including teaching the task, addressing ambiguity, and collecting contrastive/negative examples. Can you explain one of these techniques in more detail? Why is it important?

8. The authors recommend reporting inter-annotator agreement on explanation plausibility. What does this measure indicate about the data? How could it influence modeling and evaluation decisions?  

9. The paper argues that assumptions made during data collection can propagate to influence modeling decisions. Could you provide an example of how this occurs? How can researchers mitigate this issue?

10. The authors call for better documentation of data collection procedures and constraints via "datasheets". What key details should these datasheets include to support reuse and accurate interpretation?
