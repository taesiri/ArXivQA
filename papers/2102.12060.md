# Teach Me to Explain: A Review of Datasets for Explainable Natural   Language Processing

## What is the central research question or hypothesis that this paper addresses?

After carefully reading the paper, it seems the central research question is:What can we learn from existing datasets that contain human-annotated textual explanations, and what recommendations can we provide for collecting high-quality explainable NLP datasets in the future? The authors review and summarize the literature on collecting textual explanations for explainable NLP. They identify three main types of textual explanations that have been collected in datasets: highlights, free-text, and structured. The paper analyzes strengths and shortcomings of existing data collection methodologies for each explanation type. It highlights important considerations from the interplay between data collection, modeling, and evaluation assumptions. The authors provide recommendations for future data collection based on what has been learned so far in this emerging research area. The overarching goal is to promote better practices and standardization when creating new textual explanation datasets for explainable NLP.


## What is the main contribution of this paper?

The main contribution of this paper is a comprehensive review and analysis of datasets for explainable natural language processing (ExNLP). Specifically:- The paper surveys and categorizes 65 existing ExNLP datasets into three main types: highlights, free-text explanations, and structured explanations. It provides an overview of each dataset and how the explanations were collected.- It highlights and discusses important lessons learned from analyzing existing ExNLP data collection methodologies. In particular, it focuses on two main case studies: (1) issues with using human-annotated highlights for evaluating model-generated highlights, and (2) the emergence of structured explanations as an alternative to purely free-text explanations. - It synthesizes best practices and gives recommendations for future ExNLP dataset construction. This includes suggestions for ensuring data quality, increasing diversity, embracing natural structure in explanations, and the importance of documenting data collection details and constraints.Overall, the main contribution is a thorough literature review of ExNLP datasets coupled with an insightful critical analysis and synthesis of recommendations for the research community. The paper helps standardize practices around ExNLP dataset creation and highlights important considerations for using existing datasets.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper reviews existing datasets for explainable NLP, categorizes them into three types (highlights, free-text, and structured), analyzes their collection methodologies, and provides recommendations for future dataset creation based on lessons learned.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other research on explainable natural language processing (ExNLP) datasets:- Scope - This paper provides a broad review of 65 datasets with textual explanations, categorizing them into highlights, free-text, and structured explanations. Other surveys tend to focus on a specific explanation type or application area. For example, some reviews cover just free-text rationales or visual explanations. This paper aims to synthesize findings across different explanation formats.- Critical analysis - The authors provide a more critical analysis of ExNLP dataset creation compared to other surveys. They highlight potential issues like insufficient or non-comprehensive highlights, lack of annotation diversity leading to artifacts, and over-constraining free-text explanations. Other reviews tend to just summarize datasets without as much discussion of limitations.- Recommendations - A key contribution is the set of recommendations for creating higher quality ExNLP datasets. These cover best practices like using a "collect-and-edit" approach, assessing task explainability, and embracing natural structure in explanations. Other surveys focus less on guidelines for future data collection.- Up-to-date - At 65 datasets, this is one of the most comprehensive reviews to date. The authors cover very recent datasets and preprints through 2021. Other surveys cover fewer or older datasets since this is a rapidly expanding field.In summary, this review provides a uniquely broad, critical, and up-to-date analysis of ExNLP datasets compared to other literature surveys. The actionable recommendations for improving dataset creation are a notable addition not found in most reviews.
