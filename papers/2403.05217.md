# [Harnessing Multi-Role Capabilities of Large Language Models for   Open-Domain Question Answering](https://arxiv.org/abs/2403.05217)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Open-domain question answering (ODQA) aims to answer factoid questions without constraints on domains. It requires collecting evidence passages to provide necessary context.  
- Existing ODQA methods follow either a retrieve-then-read paradigm using retrieved documents as evidence, or a generate-then-read paradigm using virtually generated documents. Both have limitations.

Proposed Solution:
- The paper proposes LLMQA, a unified ODQA framework combining strengths of both retrieval-based and generation-based evidence.
- LLMQA formulates the ODQA process into 3 steps:
   1) Query expansion to enrich question context 
   2) Document selection to retrieve and rerank evidence
   3) Answer generation based on question and evidence
- LLMQA utilizes large language models (LLMs) in 3 collaborative roles: 
   1) Generator for query expansion and answer generation
   2) Reranker for evidence document selection
   3) Evaluator to score quality of expansions and document rankings
- A prompt optimization method is introduced to automatically refine prompts for the LLM roles.

Main Contributions:
- Proposes LLMQA, a novel ODQA framework unifying retrieval-based and generation-based evidence using multi-role LLMs.
- Achieves new state-of-the-art results on NQ, TriviaQA and WebQ datasets, advancing answer accuracy and evidence quality.
- Introduces a prompt optimization technique to automatically refine prompts for LLMs playing different roles.
- Showcases the potential of coordinating multiple LLM roles under a unified framework to accomplish complex NLP tasks.

In summary, the key innovation is developing a generalized ODQA framework using LLMs in collaborative generator, reranker and evaluator roles, enabled by prompt optimization. This achieves top results on standard datasets, highlighting the promise of multi-role LLMs.
