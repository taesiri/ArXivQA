# [SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via   Self-Supervised Learning](https://arxiv.org/abs/2402.11933)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
The paper aims to tackle three key challenges in dynamic anomaly detection on continuous-time dynamic graphs (edge streams):
(1) Quickly detecting anomalies in real-time as edges arrive to minimize harm. Most methods designed for static graphs have delays. 
(2) Adapting to dynamically changing node states over time.
(3) Lack of anomaly labels for training, especially for dynamic anomalies.

Proposed Solution:
The paper proposes SLADE, a self-supervised method to incrementally identify dynamic anomalies in edge streams without relying on labels. SLADE learns dynamic node representations that capture long-term interaction patterns. It does this by training a neural network to perform two self-supervised tasks:

(1) Minimizing drift in node representations over time. This assumes normal nodes have stable interaction patterns.
(2) Accurately generating long-term patterns from recent interactions. This assumes feasibility of restoring patterns of normal nodes. 

Poor performance on these tasks indicates deviation from normal patterns. 

The neural network architecture and tasks are designed for constant time complexity per edge. Key components are:
- Memory modules to represent long-term interaction patterns
- Memory updater to update memories upon new edges
- Memory generator to reconstruct memories from recent interactions

Losses encourage agreement between current/previous memories (task 1) and current/generated memories (task 2). The model learns normal patterns. At inference, nodes with poor performance on these tasks get high anomaly scores.

Main Contributions:
- Proposes SLADE, an unsupervised method to detect complex dynamic anomalies in edge streams in real-time.
- Carefully designs neural network components and self-supervised tasks to enable constant time complexity per edge.
- Outperforms state-of-the-art methods, even supervised ones, with 12.8% and 4.23% higher AUC on average. Handles various anomaly types.
- Empirically shows constant runtime per edge, providing the best trade-off between speed and accuracy.

The key idea is to learn normal interaction patterns in a self-supervised manner and identify anomalies as deviations from them. The method is responsive, effective and robust.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes SLADE, a self-supervised method for detecting dynamic anomalies in edge streams without relying on labels, by training a model to minimize drift in node representations over time and accurately regenerate them from recent interactions.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing SLADE, a self-supervised method for detecting dynamic anomalies in edge streams. Specifically:

1) SLADE is able to incrementally detect complex dynamic anomalies in edge streams without relying on any label supervision. It uses two self-supervised tasks - minimizing drift in node representations over time and accurately generating long-term patterns from short-term ones - to learn normal interaction patterns.

2) Experiments on four real-world datasets show SLADE outperforms state-of-the-art methods, with improvements of up to 12.80% over the best unsupervised method and 4.23% over the best supervised method in terms of AUC.

3) SLADE processes each edge in constant time regardless of the accumulated graph size. This ensures rapid anomaly detection in response to new edges. Both theoretical analysis and experiments confirm the constant inference speed.

In summary, SLADE advances dynamic anomaly detection in edge streams through its unsupervised learning approach, high accuracy, and constant detection speed. It addresses key challenges like handling complex anomalies, adapting to dynamic states, and lacking labels.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Dynamic anomaly detection
- Edge streams
- Continuous-time dynamic graphs (CTDGs)
- Self-supervised learning
- Memory modules
- Temporal contrast
- Memory generation
- Incremental computation
- Unsupervised learning
- Deep neural networks

The paper proposes a new method called SLADE for detecting anomalies in edge streams representing continuous-time dynamic graphs, without relying on label supervision. The key ideas include using self-supervised learning on memory modules to capture normal patterns in edge streams, and defining tasks related to temporal contrast and memory generation that aim to spot deviations from normal behaviors. A notable aspect is the use of incremental computation to enable constant-time anomaly scoring per edge, for rapid detection. The method outperforms both unsupervised and supervised baseline methods on real-world datasets.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes two key assumptions (A1 and A2) about the interaction patterns of normal nodes over time. Explain these assumptions and discuss why they are reasonable for modeling normal behavior. 

2. The paper uses two self-supervised tasks, temporal contrast and memory generation, to train the model. Explain the objectives of these tasks and how they relate to the key assumptions A1 and A2.

3. The memory module is a key component of the proposed method. Discuss the purpose of the memory module and how it is updated over time using the memory updater.

4. Explain the memory generation task in detail, including how the memory generator module is used to generate a node's memory vector based on its recent interactions. Discuss the rationale behind this task.

5. The paper defines two scores - temporal contrast score and memory generation score - to quantify the anomaly level of a node. Explain how each of these scores measures deviation from assumptions A1 and A2 respectively.

6. Batch training is used in the proposed method for efficiency. Explain the batch training procedure, including how multiple interactions within a batch are aggregated. Discuss how batch size impacts training.  

7. The method can detect various types of anomalies including hijacked, new, and consistent anomalies. Pick one anomaly type and explain in detail, with examples, how the proposed method is able to detect such anomalies.

8. From Figure 3, we observe different patterns in the anomaly scores over time for hijacked vs new anomalies. Explain why these temporal patterns emerge and how the method is able to distinguish between hijacked and new anomalies.  

9. The paper analyzes the time complexity of memory update and anomaly scoring after model training. Explain these analyses and discuss why constant time complexity is important for dynamic anomaly detection.

10. The design of the loss functions uses contrastive learning principles to distinguish between normal and abnormal interaction patterns. Explain the design of the temporal contrast and memory generation losses and discuss how contrastive learning helps in anomaly detection despite lack of labels.
