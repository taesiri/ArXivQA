# [An Empirical Study on Usage and Perceptions of LLMs in a Software   Engineering Project](https://arxiv.org/abs/2401.16186)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like ChatGPT have shown promising capabilities for code generation, but their usefulness in real-world software engineering projects is not well studied. 
- Specifically, how students leverage LLMs in academic software engineering projects and what are their perceptions of using AI for coding have not been explored before.

Methodology: 
- The authors conducted a study with 214 students working on semester-long software engineering projects in teams. 
- Students were allowed to use LLMs like GitHub Copilot and ChatGPT to generate code. They annotated AI-generated code snippets with metadata like the tool used and level of human intervention needed.
- At the end of the semester, 139 students responded to a survey capturing usage behavior, performance and effort expectancy, social influence, facilitating conditions etc. based on the UTAUT model.
- Sentiment analysis was performed on free-form responses to questions about how LLMs impact students as coders and future software engineers.

Key Findings:
- 40.5% of teams used AI-generated code, with ChatGPT-3.5 being the most popular. The majority of code was generated in early sprints.
- On average, 33 lines of code were generated per snippet in sprint 1, increasing to 73 lines by sprint 3, indicating students got better at prompt engineering over time.
- With Copilot, 100% of generated code needed human intervention before usage. With paid ChatGPT-v4, most code could be used as-is.
- Students highly rated performance expectancy, effort expectancy and facilitating conditions as drivers of AI usage, while social influence was minimal.
- Students with lower coding skills were more averse to using AI tools compared to highly skilled ones. Prior experience with AI tools increased usage and intent.
- Sentiment analysis revealed positive perceptions as students but concerns about jobs as future software engineers.

Contributions:
- First study analyzing real-world integration challenges of AI generated code in software projects 
- Blueprint of most useful AI code generation use cases over a project lifecycle
- Framework to incorporate LLMs as enhancements, not replacements, for software engineering education.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

This paper presents the first comprehensive study on the usage and perceptions of large language models in a software engineering project conducted with 214 students, revealing insights into the usefulness of AI tools for enhancing productivity in early development stages, the impact of coding skills and prior experience on adoption, and the ability to maintain code quality with proper human oversight.


## What is the main contribution of this paper?

 Based on my review of the paper, the main contribution is:

The paper presents the first comprehensive study on the use of large language models (LLMs) in academic software engineering team projects. It examines the usage patterns and perceptions of students who have used LLMs to generate code in their semester-long software development project. Key findings and contributions include:

- Analysis of AI-generated code, prompts used, and human intervention levels across project milestones to integrate code into the codebase. This shows LLMs are most useful early on for basic algorithms/design patterns.

- Sentiment analysis revealing student perceptions on the usefulness of LLMs for improving productivity but also concerns about impact on gaining coding skills and the job market.

- Observation that only a small proportion of teams accounted for most AI-generated code, but there was no significant difference in code correctness/quality between heavy AI users and non-users.

- Framework and implications for educators on emphasizing human-AI collaboration skills among students to leverage productivity gains from AI tools without compromising learning outcomes.

In summary, the paper provides valuable insights into the usage and perceptions of LLMs in software engineering team projects from an academic perspective, including analysis of usage patterns and student sentiments.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper's content, some of the main keywords or key terms associated with this paper include:

- Large language models (LLMs)
- Code generation
- Software engineering 
- Academic project
- Student perceptions
- Prompt engineering
- Human intervention
- Productivity
- Correctness
- Quality
- Unified Theory of Acceptance and Use of Technology (UTAUT)
- Sentiment analysis

The paper presents a study on using LLMs to generate code in a software engineering student project. It analyzes the AI-generated code, prompts used, and human intervention required to integrate the code. It also conducts a perception survey to understand students' views on using LLMs. Key terms cover the LLMs themselves, the software engineering project context, analysis of code and prompts, perception factors based on technology acceptance models, and evaluation of output quality.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions that students were encouraged to use LLMs in their projects. Were there any specific guidelines provided on how to appropriately use LLMs? If not, do you think guidelines would have been helpful?

2. The level of human intervention metric seems subjective. Were there clear criteria provided to students on how to determine the level of intervention? If not, how could this metric be made more objective in future studies? 

3. Was any analysis done to see if certain types of prompts or certain LLMs led to code snippets that required more or less human intervention before usage? Could prompt engineering be optimized in the future based on such analysis?

4. The study found no significant difference in code correctness and quality between teams using LLMs heavily versus not at all. But were other software quality metrics analyzed, like maintainability, efficiency, security etc.? 

5. The perception analysis relied solely on self-reported survey data. Could other data sources like interviews, focus groups etc. reveal additional insights into student perceptions and experiences using LLMs?

6. Were there any differences observed in how undergraduate versus graduate students utilized and perceived LLMs? Would a similar study with industry software engineers show different results? 

7. The study suggests shifting educational focus to prepare students for human-AI collaboration. What specific curriculum updates would you suggest to achieve this? Any best practices from industry that could be applied?

8. With only 40% of teams reporting LLM usage, why do you think adoption was not higher? Were there any common barriers reported by students for not utilizing LLMs more extensively? 

9. The analysis relies extensively on annotations provided voluntarily by students. Do you think requiring annotations, rather than making them optional, would have provided more exhaustive data for analysis?

10. The survey analysis reveals negative sentiments regarding impact on the job market. But were any positive implications also reported, like LLMs making software engineers more productive or enhancing job satisfaction?
