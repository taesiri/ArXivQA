# [Improving Adversarial Robustness of Masked Autoencoders via Test-time   Frequency-domain Prompting](https://arxiv.org/abs/2308.10315)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How does the choice of reconstruction target in masked image modeling (BERT-style pretraining) impact the adversarial robustness of vision transformers? The key hypotheses explored are:1) Using raw pixel values as the reconstruction target (as in MAE) leads to worse adversarial robustness compared to using semantic targets (as in BEiT and PeCo). This is because predicting raw pixels makes models rely more on high-frequency image details.2) The homogeneity of attention across spatial regions is higher in models pretrained with masked image modeling compared to supervised or contrastive approaches. This also contributes to the robustness difference between methods like MAE and BEiT/PeCo.3) Strategies like adding perceptual losses or adversarial training to MAE pretraining can mitigate the robustness gap by guiding representations to focus less on pixel-level details.In summary, the paper analyzes how design choices in masked image modeling pretraining impact robustness and proposes methods to improve the robustness of approaches like MAE. The central question is understanding and improving the adversarial vulnerability of different self-supervised vision transformers.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- An analysis of the adversarial robustness of vision transformers (ViTs) with different BERT-style pre-training methods. The key finding is that MAE, which directly predicts raw pixels of masked image patches, has significantly worse adversarial robustness compared to methods like BEiT and PeCo that predict semantic targets.- An empirical analysis linking MAE's worse robustness to its reliance on medium/high frequency image content. Experiments show MAE is more impacted when these frequencies are removed.- A proposed method to improve MAE's robustness by learning frequency-domain visual prompts that fill in medium/high frequencies with dataset patterns. This is shown to boost robustness while maintaining accuracy.In summary, the main contribution is an analysis of why MAE has worse adversarial robustness than other BERT-style vision pre-training methods, linked to its reconstruction target being raw pixels. The paper proposes a way to address this via frequency-domain prompting.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a method to improve the adversarial robustness of masked autoencoders like MAE by using test-time frequency-domain prompting, which fills the medium/high-frequency components of images with dataset-extracted patterns to make it harder to generate effective adversarial perturbations.
