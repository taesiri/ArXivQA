# [Search-based Optimisation of LLM Learning Shots for Story Point   Estimation](https://arxiv.org/abs/2403.08430)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Large language models (LLMs) like GPT-4 can be used for software effort estimation tasks like predicting story points for user stories. 
- Providing the LLM with a few example user stories (called shots) in a few-shot learning setting affects the accuracy of the model's estimations. 
- Finding the optimal set of example shots to provide is challenging due to prompt length limitations and computational constraints.

Proposed Solution:
- Use a multi-objective genetic algorithm called CoGEE to optimize the selection of learning shots. 
- Define and minimize 3 objectives: 
   1) Sum of Absolute Error (SAE) of LLM's estimates
   2) Confidence Interval (CI) of the error distribution  
   3) Number of shots (N) used
- Configure and apply NSGA-II algorithm with custom crossover and mutation operators to search for Pareto optimal shot sets.

Key Contributions:
- First study to use Search-Based Software Engineering (SBSE) to optimize learning shots for an LLM's software effort estimation.
- Optimization objectives balance accuracy, uncertainty and cost of using the LLM.  
- Approach improved GPT-4's estimation accuracy by 59.34% on average compared to zero-shot learning baseline.
- Demonstrates feasibility of using SBSE to improve few-shot learning prompts for LLM-based systems.

In summary, the paper proposes a way to automatically find better few-shot learning examples to improve a large language model's performance on a software estimation task. Preliminary results on 3 datasets show SBSE helps substantially boost the accuracy of GPT-4's story point predictions.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes using search-based software engineering techniques to optimize the set of example issues provided to a large language model in order to improve its few-shot learning performance for estimating story points of software development tasks.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is:

The paper proposes using search-based software engineering (SBSE) techniques to optimize the set of example user stories (called "shots") provided to a large language model (LLM) in a few-shot learning setting for estimating story points of new user stories. Specifically, the paper employs a multi-objective evolutionary algorithm called CoGEE to minimize the sum of absolute errors, confidence interval, and number of shots, in order to find a near-optimal set of shots that improves the LLM's story point estimation accuracy. The paper demonstrates this approach on three software projects, showing that the optimized shots using CoGEE leads to significantly better estimation accuracy (59.34% lower mean absolute error on average) compared to using no shots or random shots. To the authors' knowledge, this is the first study applying SBSE to optimize shots selection for LLMs for software effort estimation.

In summary, the key contribution is using SBSE to optimize few-shot learning prompts to improve LLM accuracy for story point estimation.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the main keywords or key terms associated with it are:

- Search-Based Software Effort Estimation
- Large Language Model 
- Few-shot Learning
- Multi-objective Optimisation

As stated in the abstract, the keywords are:

"Search-Based Software Effort Estimation \and Large Language Model \and Few-shot Learning \and Multi-objective Optimisation"

So the main focus is on using search-based software effort estimation techniques to optimize the few-shot learning performance of a large language model for estimating story points. The specific methods used are multi-objective optimization and genetic algorithms.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes using a multi-objective evolutionary algorithm called NSGA-II for optimizing the set of example issues provided to the LLM. What are the key configuration choices made for NSGA-II in this study (e.g. population size, number of generations, etc.) and what is the rationale behind them?

2. The paper defines three objectives for optimization - minimizing the sum of absolute errors (SAE), confidence interval (CI), and number of shots. Why is minimizing the number of shots an important third objective? What trade-offs does it enable?

3. The prompt design in Figure 1 is crucial for extracting a numerical story point estimate from the LLM's textual response. What are some challenges faced in designing an effective prompt and how are they addressed? Could the prompt be further improved?

4. Only 3 projects with 30 issues each were used for evaluation. What are some reasons for the small dataset size? How could the experimental evaluation be expanded in future work?

5. Beyond story point estimation, what are some other potential software engineering tasks where this approach of optimizing LLM few-shot learning could be applied? 

6. The paper demonstrates optimizing shots for a single LLM model (GPT-4). How could the approach be extended to optimize shots in a transfer learning scenario across multiple LLM models?

7. The paper uses a genetic algorithm for optimization. What are some pros and cons of this choice over other optimization algorithms? When might other algorithms like simulated annealing be more appropriate?

8. How sensitive are the results to changes in key GA parameters like population size and number of generations? Is there a way to statistically establish these values?

9. Table 1 shows promising SAE improvements but what other evaluation metrics could reveal further insights into the effectiveness of this approach?

10. The CI metric captures uncertainty but doesn't guarantee statistical rigor. How could resampling methods like bootstrapping help quantify uncertainty more accurately?
