# [Polynomial Implicit Neural Representations For Large Diverse Datasets](https://arxiv.org/abs/2303.11424)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to design an implicit neural representation (INR) that can scale to represent large diverse image datasets like ImageNet. The key hypotheses are:1) Representing an image as a polynomial function of its coordinate location can capture high frequency details better than using sinusoidal positional encodings.2) A multilayer perceptron (MLP) model can be designed to approximate higher order polynomials by progressively increasing the polynomial order with network depth through element-wise multiplications. 3) Such a polynomial INR model can scale to complex datasets like ImageNet and perform comparably to convolutional neural network (CNN) based generators like StyleGAN with far fewer parameters.So in summary, the main goal is to design a polynomial INR that can scale to diverse datasets by eliminating the need for positional encodings while still capturing high frequency details. The key hypothesis is that a properly designed MLP can approximate higher order polynomials to achieve this.
