# [Polynomial Implicit Neural Representations For Large Diverse Datasets](https://arxiv.org/abs/2303.11424)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to design an implicit neural representation (INR) that can scale to represent large diverse image datasets like ImageNet. The key hypotheses are:1) Representing an image as a polynomial function of its coordinate location can capture high frequency details better than using sinusoidal positional encodings.2) A multilayer perceptron (MLP) model can be designed to approximate higher order polynomials by progressively increasing the polynomial order with network depth through element-wise multiplications. 3) Such a polynomial INR model can scale to complex datasets like ImageNet and perform comparably to convolutional neural network (CNN) based generators like StyleGAN with far fewer parameters.So in summary, the main goal is to design a polynomial INR that can scale to diverse datasets by eliminating the need for positional encodings while still capturing high frequency details. The key hypothesis is that a properly designed MLP can approximate higher order polynomials to achieve this.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel Implicit Neural Representation (INR) model based on polynomial functions for large image datasets. The key highlights are:- They propose Poly-INR, an INR model that represents images as polynomial functions of the pixel coordinates. This eliminates the need for positional encodings used in other INR models. - The Poly-INR model uses only linear and ReLU layers in the network architecture. It progressively increases the degree of the polynomial with network depth by element-wise multiplication between features and affine transformed coordinates.- They show Poly-INR performs comparably to state-of-the-art StyleGAN models on ImageNet and outperforms previous INR-GAN models on FFHQ, using significantly fewer parameters.- The proposed model provides advantages like smooth interpolation, style mixing, high-resolution image generation, extrapolation beyond image borders. - Overall, the paper demonstrates INR models can scale to large diverse datasets like ImageNet by representing images as polynomials rather than using positional encodings. The lightweight architecture also enables training complex generative models with fewer parameters.In summary, the key contribution is proposing and demonstrating a polynomial function based INR model that scales to large datasets and outperforms prior INR-GANs, using only linear and ReLU layers in the generator architecture.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper proposes a new implicit neural representation method for generating images that uses polynomials instead of positional encodings, enabling it to scale to large diverse datasets like ImageNet while using fewer parameters than convolutional GANs.
