# [Bridging Textual and Tabular Worlds for Fact Verification: A   Lightweight, Attention-Based Model](https://arxiv.org/abs/2403.17361)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Fact checking is important to validate claims and promote reliable information spreading. Several benchmarks exist but are limited to either only text data or only tabular data. 
- FEVEROUS benchmark combines both text and tables to better represent real-world fact checking, but existing methods often convert the multi-modal data into a single format, losing critical context/nuances.

Proposed Solution:
- A modular dual transformer model to seamlessly integrate text and tabular evidence without converting modalities.
- Uses pre-trained BERT models fine-tuned on text (DeBERTa) and tables (TAPAS) to encode evidence.  
- A cross-attention module establishes correlations between text and table embeddings and fuses them into an enriched, context-aware claim representation.
- Final MLP and softmax layer makes 3-way verdict prediction (Supported/Refuted/Not Enough Info).

Main Contributions:
- Achieves competitive scores to top models on FEVEROUS benchmark by effectively exploiting connections between textual and tabular data.
- Eliminates need for trouble-prone data format conversions, preserving nuances. 
- Modular design enables easy incorporation of improved components.
- Shows model's robustness using different transformer encoders for text and tables.
- Underscores the importance of multi-modal evidence integration.

In summary, the paper introduces a modular dual transformer approach to multi-modal fact verification that avoids pitfalls of existing techniques and demonstrates strong performance on the FEVEROUS benchmark.
