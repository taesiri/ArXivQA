# [Aligning Large Language Models to a Domain-specific Graph Database](https://arxiv.org/abs/2402.16567)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Graph databases are widely used but querying them requires expertise in complex graph query languages (GQLs). Translating natural language (NL) questions into GQLs (NL2GQL) is very challenging. 
- Prior work on this is limited and accuracy is low, especially for domain-specific graphs lacking training data.

Proposed Solution:
- Present a pipeline to align large language models (LLMs) to a domain-specific graph database to achieve high NL2GQL accuracy.

Key Steps:
1) Generate NL-GQL template pairs from the graph schema using ChatGPT via self-instruction, expanding diversity via self-supervision. Ground truth answers are verified.

2) Fine-tune foundation LLMs (e.g. BaiChuan2) on generated data using Lightweight Randomized Parameterization to align them with the graph.

3) During inference, extract schema relevant to the NL question to formulate the prompt to bound the LLM, generating the GQL.

Main Contributions:
- Propose a well-defined pipeline to align LLMs to domain-specific graph databases for accurate NL2GQL, generating labeled data.
- Technique to extract relevant schema as prompt to guide aligned LLM to generate accurate GQLs. 
- Created and evaluated on two new datasets: FinGQL and MediGQL based on real-world finance and medical graphs.
- Significantly outperforms baseline natural language to SQL methods and in-context learning, with over 5-7% absolute improvement in accuracy.
