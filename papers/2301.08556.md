# [NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via   Novel-View Synthesis](https://arxiv.org/abs/2301.08556)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we improve imitation learning for 6-DOF object grasping from RGB images, particularly for eye-in-hand robot policies?The key ideas and contributions to address this question are:1) Proposing a new offline data augmentation technique called SPARTN that leverages neural radiance fields (NeRFs) to generate corrective visual observations and action labels. 2) Showing that this NeRF-based augmentation can produce reactive, real-time, RGB-only policies for 6-DOF grasping.3) Demonstrating that SPARTN significantly improves imitation learning for 6-DOF grasping policies without requiring online expert supervision or environment interaction.4) Evaluating SPARTN on simulated and real-world 6-DOF grasping tasks, where it boosts success rates substantially compared to baseline imitation learning.In summary, the paper introduces a novel way to perform corrective visual augmentation using NeRFs in order to improve imitation learning for eye-in-hand grasping policies, with promising results demonstrated in both simulation and the real world. The key hypothesis is that this offline NeRF-based augmentation can produce reactive policies and reduce compounding errors for complex vision-based robot control problems like 6-DOF grasping.
