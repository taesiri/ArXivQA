# [iMatching: Imperative Correspondence Learning](https://arxiv.org/abs/2312.02141)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a new self-supervised learning framework called iMatching for training feature correspondence models using only unannotated video sequences. It formulates the problem as a bilevel optimization, with bundle adjustment (BA) at the lower level optimizing camera poses and 3D landmark positions to minimize reprojection error given the model-predicted correspondences. At the upper level, the model parameters are updated to minimize the final reprojection error from BA. This eliminates the need for ground truth labels and allows the BA process to provide supervision. To enable end-to-end learning without differentiating through the complex BA computations, the authors leverage the stationary point of the BA optimization to implicitly calculate gradients after convergence. Experiments demonstrate that iMatching boosts state-of-the-art matching models like ASpanFormer, improving feature matching accuracy by 13.6% and pose estimation accuracy by over 30% on unseen datasets. The robust BA process is critical to handling outliers and enabling the performance gains. Overall, iMatching sets a new bar for self-supervised correspondence learning without any labels.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a new self-supervised learning framework called imperative learning that formulates feature correspondence as a bilevel optimization problem, using bundle adjustment on unlabeled video data to supervise the training of feature matching networks without requiring any ground truth labels.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing the first imperative learning (IL)-based framework for training feature correspondence models using uninterrupted videos without any ground truth labels such as pose or depth. Specifically:

1) They formulate the problem of feature matching as a bilevel optimization where the lower level performs bundle adjustment to find the best camera poses and 3D landmark positions that explain the predicted correspondences, and the upper level optimizes the network parameters to minimize the reprojection error from bundle adjustment.

2) They design an efficient method to propagate the gradients through the bundle adjustment process to enable end-to-end training, without having to differentiate the individual steps of the optimization. 

3) Through experiments on multiple state-of-the-art matching models, they demonstrate superior performance with average 30% accuracy gains on tasks like feature matching and pose estimation, showing the effectiveness and generalizability of their self-supervised imperative learning framework.

In summary, the key contribution is proposing a novel imperative learning scheme for self-supervised training of correspondence models that only requires unlabeled video data, eliminating the need for expensive ground truth annotations.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this work include:

- Imperative learning (IL): An emerging self-supervised learning framework based on bilevel optimization that is used in this work to train feature correspondence models without ground truth labels.

- Bundle adjustment (BA): An optimization technique used in computer vision to simultaneously estimate camera parameters and 3D landmark positions by minimizing reprojection error. This paper uses BA as the low-level optimization in the IL framework.

- Bilevel optimization: A mathematical optimization framework with two nested levels - an upper-level optimization constrained by a lower-level optimization problem. Used to formulate the IL training scheme. 

- Feature correspondence: The task of identifying matching visual features between images, which is learned in a self-supervised manner using IL and BA in this work.

- Reprojection error: The discrepancy between observed 2D keypoint locations and locations obtained by projecting 3D points onto the image plane using estimated camera poses. Minimized during BA.

- Differentiable matching: Techniques to make the predicted discrete correspondences differentiable, required for end-to-end training. Includes expectation-based and regression-based approaches.

- Camera pose estimation: A major downstream application task used to evaluate correspondence models trained with IL. Poses are estimated from correspondences using RANSAC.

- Robustness: A key focus in the design of the BA formulation, aimed at handling noise and outliers in correspondence predictions during self-supervised training.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 suggested in-depth questions about the method proposed in the paper:

1. The paper proposes a new self-supervised learning framework called "imperative learning" for training feature correspondence models. Can you explain in more detail the key ideas behind imperative learning and how it formulates the correspondence learning problem differently compared to previous approaches?

2. The proposed method treats correspondence learning as a bilevel optimization problem. What is optimized at the upper level and lower level respectively? How does the optimization at one level affect the other?

3. The paper mentions two key challenges in optimizing the bilevel formulation - making the feature matching network differentiable and making bundle adjustment differentiable. Can you elaborate on the solutions proposed in the paper for these two challenges? 

4. The method propagates gradients through bundle adjustment by leveraging its convergence point rather than unrolling the optimization steps. What is the intuition behind this? What are the advantages of this approach over unrolling BA iterations?

5. The iterative bundle adjustment procedure in the paper involves both map initialization and outlier rejection stages. Can you explain the motivation and details of each of these stages? How do they improve training convergence?

6. What modifications need to be made for models like SuperPoint that have non-differentiable keypoint detection stages? What about methods with search-based matching predictions?

7. Qualitatively, what improvements do you observe in the performance of models like CAPS and Patch2Pix after applying imperative learning? What kinds of scenes or cases benefit the most?

8. For the pose estimation experiments, why does the paper claim that the SGP method shows negligible gains compared to imperative learning? What differences in the supervision signals can explain this? 

9. The paper demonstrates impressive zero-shot transfer of models to unseen real image datasets after imperative learning. What factors contribute to this strong generalization ability?

10. The method currently processes video clips batch-by-batch independently. Can you suggest any ideas to extend imperative learning to an online, sequential setting leveraging temporal continuity in videos?


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Learning feature correspondence across images is critical for downstream computer vision tasks like visual odometry and 3D reconstruction. However, getting accurate per-pixel correspondence labels for supervised training is extremely difficult.
- Existing methods rely on synthetic data or sensors like depth cameras/LiDARs to get labels, but they have limitations in diversity, scale and accuracy. Self-supervised methods exist but have their own drawbacks. 

Proposed Solution:
- The paper proposes a new self-supervised learning framework called "iMatching" using imperative learning to train feature correspondence networks.
- It formulates feature matching as a bilevel optimization problem. The lower level does bundle adjustment to estimate optimal camera poses and 3D landmark positions that explain the predicted matches. The upper level optimizes network parameters to minimize the reprojection error from bundle adjustment.
- This reciprocal optimization allows end-to-end training using just unlabeled videos without needing ground truth poses or depth. It is more generalized and robust than prior self-supervised methods.

Main Contributions:
- First framework to self-supervisedly train correspondence networks through imperative learning using bundle adjustment. Eliminates need for manual labels.
- Careful design of bundle adjustment procedure to provide robust supervisory signal. Includes map initialization, pose tracking, and iterative optimization.  
- Efficient way to propagate gradients through bundle adjustment by leveraging its stationarity at convergence. Avoids computational overhead.
- Experiments showed average 30% gain over state-of-the-art matching models on unseen datasets, demonstrating strong adaptability.

In summary, the paper presents a novel end-to-end self-supervised learning idea for feature correspondence that gives significantly improved performance without requiring manual annotation effort.
