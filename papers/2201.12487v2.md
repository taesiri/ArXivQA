# [Counterfactual Plans under Distributional Ambiguity](https://arxiv.org/abs/2201.12487v2)

## What is the central research question or hypothesis that this paper addresses?

 This paper studies the problem of generating robust counterfactual explanations under uncertainty about the model's parameters. The key research question is: How can we generate counterfactual explanations that remain valid even when the model is updated or its parameters change in the future? 

The authors' main hypothesis is that accounting for uncertainty in the model's parameters when generating counterfactuals can improve their robustness to distributional shifts over time. Rather than assuming the model's parameters are fixed, they model the parameters as random variables with a nominal mean and covariance. 

The main contributions are:

1) A method to compute bounds on the probability that a given counterfactual plan will remain valid under the distributional uncertainty. This allows evaluating the robustness of a plan.

2) Correction methods to adjust an existing plan to improve the lower validity bound and increase robustness. 

3) A framework called COPA to construct a counterfactual plan by optimizing for proximity, diversity, and validity under the parameter uncertainty.

Overall, the central hypothesis is that explicitly accounting for uncertainty in the model's parameters when generating counterfactual plans can improve their robustness over time as the model gets updated. The core research questions are how to quantify the validity under uncertainty, and how to construct optimized plans that balance validity, proximity, and diversity.


## What is the main contribution of this paper?

 The main contribution of the paper "Counterfactual Plans Under Distributional Ambiguity" is proposing methods to construct counterfactual explanations that are robust to changes in the model's parameters over time. Here are the key points:

- The paper considers the problem that counterfactual explanations designed for a current model may become invalid when the model gets updated with new data. To address this, the authors model the uncertainty in the model parameters using partial moment information (mean and covariance).

- They propose a method to compute lower and upper bounds on the probability that a given counterfactual plan will remain valid under the ambiguous model parameters. This acts as a diagnostic tool to assess the robustness of a counterfactual plan. 

- To improve the validity of a counterfactual plan, they introduce two types of corrections - a requirement correction to ensure the expected model parameters satisfy the plan, and an improvement correction to maximize the lower validity bound.

- They develop a framework called COPA to generate counterfactual plans by optimizing a weighted sum of validity, proximity to the original input, and diversity of explanations under the model parameter uncertainty.

- Experiments on synthetic and real-world datasets demonstrate that their proposed validity bounds are correct, and that the COPA method produces more robust counterfactual plans compared to prior approaches.

In summary, the key novelty is explicitly accounting for uncertainty in model parameters when designing counterfactual explanations, in order to improve their robustness over time as the model evolves. The validity bounds and proposed corrections provide useful tools for this purpose.
