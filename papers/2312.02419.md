# [Human Demonstrations are Generalizable Knowledge for Robots](https://arxiv.org/abs/2312.02419)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of this paper:

This paper proposes a novel approach called DigKnow for enabling robots to learn generalizable knowledge from human demonstration videos. Rather than simply treating videos as step-by-step instructions for robotic repetition as in prior research, DigKnow regards videos as a source of hierarchical knowledge. Specifically, DigKnow distills human demonstration videos into multiple levels of knowledge for observation (scene graphs of object relations and states), action (human behaviors in the form of action sequences), and patterns (summarized task and object patterns). This provides a structured representation of the knowledge contained in videos that is conditioned to enhance generalization capabilities. At test time, when deployed to new scenarios with different tasks or objects, DigKnow retrieves the most relevant stored knowledge based on text similarity for tasks and visual similarity for objects. This knowledge then informs planning by a large language model, execution by a low-level policy, and knowledge-based validation and correction mechanisms to handle potential failures. Experiments in real physical robot environments demonstrate that by effectively leveraging videos as knowledge in this framework, DigKnow enables improved generalization to previously unseen task and object configurations compared to methods that purely treat videos as step-wise instructions.
