# [Recurrence without Recurrence: Stable Video Landmark Detection with Deep   Equilibrium Models](https://arxiv.org/abs/2304.00600)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How can deep equilibrium models be adapted and utilized for facial landmark detection, particularly for improving temporal coherence in facial landmark detection on videos?

The key hypotheses appear to be:

1) Deep equilibrium models can achieve state-of-the-art accuracy for facial landmark detection on images by formulating it as a constrained optimization problem.

2) Deep equilibrium models are particularly well-suited for facial landmark detection in videos because their formulation allows modifying the objective function at test time to improve temporal coherence, even without having access to video data at training time. This "recurrence without recurrence" approach can reduce flickering/oscillations in landmarks across video frames.

3) A new dataset and evaluation metric focused on temporal coherence are needed to properly benchmark video facial landmark detection models.

In summary, the central research direction is exploring how to adapt deep equilibrium models for facial landmark detection, with a focus on leveraging their formulation to improve temporal coherence for video landmark detection. The key hypotheses are that deep equilibrium models can achieve state-of-the-art accuracy on images and that their formulation enables improving video coherence through modifying the objective at test time.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing a new facial landmark detection model called Landmark DEQ (LDEQ) based on Deep Equilibrium Models. The LDEQ achieves state-of-the-art performance on the WFLW facial landmark dataset while having lower parameters and constant memory cost compared to prior cascaded models like Stacked Hourglass.

2. Introducing a new paradigm called "Recurrence without Recurrence" (RwR) that leverages the flexibility of DEQs to modify the objective function at test time. Specifically, RwR adds a temporal coherence loss at inference to reduce landmark flickering in videos, despite only having access to images during training.

3. Contributing a new facial landmark video dataset called WFLW-Video (WFLW-V) to benchmark temporal coherence. The dataset has 1000 creative commons YouTube videos with dense 98-point annotations. A new metric called Normalized Mean Flicker (NMF) is also introduced to specifically measure landmark flickering.

4. Demonstrating superior performance of LDEQ+RwR in reducing flickering on WFLW-V compared to conventional post-processing filters like exponential moving average. RwR decreases NMF by 13% while maintaining landmark accuracy.

In summary, the key innovations are a new state-of-the-art facial landmark model using DEQs, a technique to leverage DEQs for video coherence without video training data, a new benchmark for facial landmark videos, and strong experimental results validating these contributions.
