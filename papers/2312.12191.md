# [CUDC: A Curiosity-Driven Unsupervised Data Collection Method with   Adaptive Temporal Distances for Offline Reinforcement Learning](https://arxiv.org/abs/2312.12191)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Most existing offline reinforcement learning (RL) works focus on developing new algorithms, with less emphasis on improving the data collection process. Moreover, it is challenging to extend from single-task to multi-task settings and collect a task-agnostic dataset for learning multiple downstream tasks. 

Proposed Solution:
This paper proposes CUDC, a Curiosity-driven Unsupervised Data Collection method with Adaptive Temporal Distances to expand the feature space for task-agnostic data collection in multi-task offline RL.

Key ideas:
- A reachability module is introduced to estimate the probability of a k-step future state being reachable from the current state. This allows adapting how many steps into the future the dynamics model predicts.

- The temporal distance k between current and future states is adaptively increased based on the agent's curiosity level. This expands the feature space to learn more complex dynamics over time.  

- A mixed intrinsic reward combining state-action entropy and prediction error encourages diverse exploration and focusing on surprising states.

- Regularization based on curiosity weights makes the agent focus more on under-learned transitions.

Main Contributions:

1) First work to introduce reachability for improving data collection in offline RL, enabling coherent curiosity-driven exploration.

2) Identify issue of fixing k in prior works, and show adapting k enhances representations by expanding feature space.

3) Additional components like mixed rewards and regularization further improve exploration and sample efficiency.

4) CUDC outperforms state-of-the-art unsupervised methods for data collection on DeepMind Control Suite tasks under the ExORL benchmark.

In summary, CUDC collects higher-quality datasets leading to improved efficiency, sample-efficiency and performance of offline RL agents across multiple downstream tasks.
