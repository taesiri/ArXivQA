# [Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive   Bias](https://arxiv.org/abs/2306.03509)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we design an effective large-scale text-to-speech (TTS) system that incorporates proper inductive biases for different aspects of speech? The key hypotheses are:1) Speech can be decomposed into several attributes like content, timbre, prosody, and phase, each with distinct properties. Modeling them separately with proper inductive biases can improve TTS performance.2) Using mel-spectrogram instead of raw waveform as the intermediate representation allows separating phase from other attributes. Phase can be reconstructed separately. 3) Timbre is a global attribute that changes slowly, so a global vector is suitable for representing it.4) Prosody has both local and long-range dependencies, making autoregressive language models ideal for modeling it.5) Content has a monotonic alignment with speech, which autoregressive models may not guarantee.So the overall goal is to design a large-scale TTS system called Mega-TTS that models the different speech attributes appropriately, leveraging the strengths of various modeling techniques like VQGAN, global vectors, and latent code language models. The paper aims to demonstrate the benefits of this inductive bias-aware approach for zero-shot TTS.


## What is the main contribution of this paper?

This paper presents Mega-TTS, a large-scale text-to-speech system with proper inductive biases for different speech attributes. The main contributions are:1. The paper proposes to disentangle speech into content, timbre, prosody and phase attributes based on their intrinsic properties. Different architectures are designed to model each attribute accordingly.2. It trains a VQGAN-based acoustic model to generate mel-spectrogram and uses a prosody language model (P-LLM) to model the prosody attribute. A novel prosody-oriented decoding method is proposed for TTS inference. 3. The model is trained on 20k hours of multi-domain speech data. Experiments show it achieves state-of-the-art performance on zero-shot TTS, speech editing and cross-lingual TTS tasks.In summary, the key contribution is introducing proper inductive biases into large-scale TTS systems by disentangling and modeling different speech attributes separately according to their intrinsic properties. This leads to superior zero-shot synthesis ability and controllability.
