# Prompting and Evaluating Large Language Models for Proactive Dialogues:   Clarification, Target-guided, and Non-collaboration

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How capable are Large Language Models (LLMs) at handling proactive dialogues, and how can prompting schemes be designed to enhance the proactivity of LLM-based conversational systems?Specifically, the paper comprehensively evaluates and analyzes the performance of LLM-based dialogue systems on three key aspects of proactive dialogues:1) Asking clarification questions when encountering ambiguous user queries.2) Proactively guiding the conversation towards a designated target topic or entity. 3) Strategically handling dialogues with competing or conflicting goals between the system and user.To address potential limitations of LLMs for proactive dialogues, the authors propose a prompting scheme called Proactive Chain-of-Thought (ProCoT) prompting. This is designed to trigger the reasoning and planning capabilities of LLMs to allow them to take initiative and work towards conversational goals. The central hypothesis seems to be that LLMs have inherent strengths and weaknesses when it comes to proactive dialogues, and that appropriate prompting schemes can significantly enhance their capabilities in this area. The comprehensive empirical analysis aims to test this hypothesis and shed light on how best to design LLM-based proactive dialogue systems.


## What is the main contribution of this paper?

Based on my reading of the paper, the key contributions are:1. This work presents the first comprehensive evaluation on the proactivity of LLM-based dialogue systems, including handling clarification, target-guided, and non-collaborative dialogues. This provides a broad assessment on whether recent LLM-based conversational systems like ChatGPT are equipped to manage different aspects of proactive dialogues.2. The paper proposes a novel prompting scheme called proactive chain-of-thought (ProCoT) prompting to enhance the proactivity of LLM-based dialogue systems. ProCoT augments LLMs with the capability of planning and taking initiative towards conversational goals by generating descriptive reasoning chains. 3. Through extensive experiments on clarification, target-guided, and non-collaborative dialogue tasks, the paper provides an in-depth analysis of the capabilities and limitations of LLM-based systems for proactive dialogues under different prompting schemes. Key findings include:- LLMs fail to ask clarification questions without explicit instructions. ProCoT overcomes this limitation but performance still lags on domain-specific tasks.- LLMs aggressively shift topics towards targets. ProCoT enables smoother topic transitions. - LLMs struggle with strategy learning for non-collaborative dialogues even with ProCoT.Overall, the comprehensive evaluation and analysis in this paper shed light on the potentials as well as current limitations of LLM-based conversational systems for proactive dialogues, while the proposed ProCoT prompting provides a means to enhance their proactivity. The findings help guide future research towards building more capable LLM-based proactive dialogue systems.
