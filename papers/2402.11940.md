# [AICAttack: Adversarial Image Captioning Attack with Attention-Based   Optimization](https://arxiv.org/abs/2402.11940)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Image captioning models are vulnerable to adversarial attacks where small perturbations to the input image can cause the model to generate incorrect or misleading captions. Most prior work has focused on white-box attacks that require access to model gradients. This paper explores black-box attacks on image captioning models without relying on internal model information.  

Proposed Solution - AICAttack
- Presents a novel attention-based adversarial attack strategy called AICAttack to attack image captioning models. 
- Uses an attention mechanism to identify the most influential pixels to perturb rather than attacking all pixels. This enhances efficiency and reduces the attack cost.  
- Applies a differential evolution algorithm to determine the optimal RGB value perturbations for the selected pixels to maximally impact the generated caption.
- Operates in a black-box setting without access to model architecture, parameters or gradients.

Key Contributions:
- Attention-based pixel selection to identify optimal attack locations instead of random selection.
- Black-box attack that does not require any internal model information.
- Differential evolution optimisation of pixel perturbations targeting semantic coherence of captions.  
- Extensive experiments on COCO and Flickr8K datasets with multiple victim models demonstrating AICAttack outperforms prior arts in decreasing BLEU and ROUGE scores.
- Analysis of attention region sizes and attack intensities on success rate.
- Evaluation of transferability by attacking unseen captioning models.

In summary, the paper presents a novel attention-guided, black-box adversarial attack strategy AICAttack to effectively attack image captioning models by subtly perturbing input images and disrupting semantic alignment in generated captions. Rigorous experiments demonstrate its superiority over state-of-the-art approaches.
