# [Rehearsal-Free Domain Continual Face Anti-Spoofing: Generalize More and   Forget Less](https://arxiv.org/abs/2303.09914)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key points of this paper are:

- It addresses the problem of face anti-spoofing (FAS) under the setting of domain continual learning (DCL). The goal is to enable FAS models to continually evolve when encountering new data domains, while avoiding catastrophic forgetting of previous domains.

- The main research questions/hypotheses are:

1) How to efficiently adapt FAS models to new domains with only a small amount of new training data, without accessing previous data? 

2) How to improve the model's generalization capability to unseen domains?

3) How to alleviate catastrophic forgetting of previous domains during continual learning, without storing previous data?

- To address these questions, the main contributions are:

1) Proposing a Dynamic Central Difference Convolutional Adapter (DCDCA) to efficiently adapt Vision Transformer models to new domains by extracting fine-grained features.

2) A Proxy Prototype Contrastive Regularization method to improve generalization and reduce forgetting by constraining the model with "pseudo" prototypes from previous domains. 

3) Extensive experiments on 15 datasets showing the proposed method generalizes better on unseen domains and forgets less compared to baselines.

In summary, the core hypothesis is that by designing a more adaptive and generalizable model architecture, along with a regularization method using proxy prototypes, one can achieve better generalization and less forgetting in the challenging problem setting of rehearsal-free DCL for FAS. The experiments seem to validate these hypotheses.


## What is the main contribution of this paper?

 This paper proposes a new approach for face anti-spoofing under the domain continual learning setting, where the model needs to adapt to new domains sequentially with only limited data, without catastrophically forgetting previous domains. The main contributions are:

1. They formulate and tackle the face anti-spoofing problem under a practical but challenging scenario of low-shot and rehearsal-free domain continual learning. 

2. They design a Dynamic Central Difference Convolutional Adapter (DCDCA) to efficiently adapt Vision Transformer models to extract fine-grained features for face anti-spoofing in continual domains.

3. They propose a Proxy Prototype Contrastive Regularization method to improve generalization and alleviate catastrophic forgetting during continual learning, without needing to store or reuse previous data.

4. They evaluate the method on two new protocols covering 15 diverse datasets with 2D and 3D attacks. Results show their method can improve generalization on unseen domains and reduce forgetting of previous knowledge compared to baselines.

In summary, the key contribution is developing a new rehearsal-free approach to adapt face anti-spoofing models efficiently in practical domain continual learning settings, through architectural design and regularization methods. The experiments demonstrate improved generalization and anti-forgetting ability over strong baselines.
