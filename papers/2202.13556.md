# [Filter-enhanced MLP is All You Need for Sequential Recommendation](https://arxiv.org/abs/2202.13556)

## What is the central research question or hypothesis that this paper addresses?

This paper proposes and evaluates an "all-MLP" neural network architecture enhanced with learnable filters for sequential recommendation. The main research questions/hypotheses appear to be:1) Can simple filtering algorithms like those used in signal processing help improve the performance of deep sequential recommendation models like RNNs and Transformers? 2) Can an all-MLP model with learnable filters match or exceed the performance of more complex models like RNNs, CNNs, and Transformers on sequential recommendation tasks?3) Can learnable filters help make an all-MLP model more robust to noise in the input data compared to other architectures?The key ideas explored are:- Using classical filtering algorithms like low-pass filters on the input embeddings as a simple way to reduce noise.- Proposing an all-MLP model called FMLP-Rec that incorporates learnable filters to adaptively attenuate noise.- Showing the learnable filters are theoretically equivalent to circular convolutions, giving them greater representational capacity.- Demonstrating superior performance of FMLP-Rec over competitive baselines on several real-world datasets.In summary, the main hypotheses are around using learnable filters to create a simple yet effective all-MLP model for sequential recommendation that is robust to noise. The experiments aim to validate these hypotheses.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:1. The paper proposes FMLP-Rec, a new model for sequential recommendation that uses an all-MLP architecture with learnable filters. This is the first model that combines an MLP-only structure with learnable filters for sequential recommendation.2. The learnable filters help attenuate noise in the input sequence and extract useful sequential features. Theoretically, the learnable filters are equivalent to circular convolutions, giving them a large receptive field to capture periodic patterns.3. The all-MLP structure makes the model simpler and more efficient than recurrent, CNN, or Transformer models typically used for sequential recommendation.4. Empirical experiments on 8 real-world datasets demonstrate state-of-the-art performance of FMLP-Rec compared to strong baselines including RNN, CNN, GNN, and Transformer-based models.In summary, the main contribution is proposing and empirically validating a new MLP-based sequential recommendation model enhanced with learnable filters that is simple, effective, and efficient compared to existing models. The combination of the all-MLP architecture and learnable filters is novel for this problem.
