# [Filter-enhanced MLP is All You Need for Sequential Recommendation](https://arxiv.org/abs/2202.13556)

## What is the central research question or hypothesis that this paper addresses?

This paper proposes and evaluates an "all-MLP" neural network architecture enhanced with learnable filters for sequential recommendation. The main research questions/hypotheses appear to be:1) Can simple filtering algorithms like those used in signal processing help improve the performance of deep sequential recommendation models like RNNs and Transformers? 2) Can an all-MLP model with learnable filters match or exceed the performance of more complex models like RNNs, CNNs, and Transformers on sequential recommendation tasks?3) Can learnable filters help make an all-MLP model more robust to noise in the input data compared to other architectures?The key ideas explored are:- Using classical filtering algorithms like low-pass filters on the input embeddings as a simple way to reduce noise.- Proposing an all-MLP model called FMLP-Rec that incorporates learnable filters to adaptively attenuate noise.- Showing the learnable filters are theoretically equivalent to circular convolutions, giving them greater representational capacity.- Demonstrating superior performance of FMLP-Rec over competitive baselines on several real-world datasets.In summary, the main hypotheses are around using learnable filters to create a simple yet effective all-MLP model for sequential recommendation that is robust to noise. The experiments aim to validate these hypotheses.
