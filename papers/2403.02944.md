# [Neural Image Compression with Text-guided Encoding for both Pixel-level   and Perceptual Fidelity](https://arxiv.org/abs/2403.02944)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper "Neural Image Compression with Text-guided Encoding for both Pixel-level and Perceptual Fidelity":

Problem: 
Recent image compression methods that utilize text guidance (e.g. image captions) can achieve high perceptual quality of reconstructed images. However, they suffer from substantially degraded pixel-level fidelity compared to standard image compression methods. It was unknown whether text-guided compression schemes could achieve competitive pixel-level fidelity while maintaining high perceptual quality.

Proposed Solution:
The authors propose TACO, a text-adaptive image compression framework that leverages text guidance mainly through text-adaptive encoding and joint image-text training loss. This avoids text-guided decoding, which tends to have high generative diversity that degrades pixel-wise fidelity. Instead, TACO utilizes an autoencoder architecture with a text adapter module to inject semantic text information into the latent code at the global image level.  

Main Contributions:
- TACO outperforms state-of-the-art image compression methods in terms of perceptual quality (LPIPS) while achieving competitive pixel-level fidelity (PSNR, within 1 dB).
- TACO also achieves state-of-the-art or competitive performance in terms of realism metrics like FID. 
- The results hold for both human-generated and machine-generated image captions.
- Analyses show the text adapter architecture is more effective than prior text injection approaches, and introduces only a small computation overhead (~10%).

In summary, TACO advances text-guided image compression by enabling simultaneous high pixel-level and perceptual fidelity reconstruction quality for the first time. The key insight is to leverage text guidance mainly through encoding rather than decoding.
