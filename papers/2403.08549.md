# [Wet TinyML: Chemical Neural Network Using Gene Regulation and Cell   Plasticity](https://arxiv.org/abs/2403.08549)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Embedding machine learning algorithms into extremely compact devices is challenging with conventional silicon-based hardware. New paradigms are needed that adhere to the goals of low energy usage and small code sizes.  

- Biological cells exhibit neural network-like information processing capabilities, but their potential for low-power machine learning has not been explored.

Proposed Solution:
- Introduce the concept of "Wet TinyML" where the gene regulatory networks (GRNs) inherent in cells are transformed into gene regulatory neural networks (GRNNs) that can perform computation like artificial neural networks.

- Map transcription factors and gene expression levels in GRNNs to inputs, weights and outputs in ANNs. This allows cells to naturally compute without training, bypassing a key limitation of ANNs.

- Leverage cell plasticity to selectively activate different GRNN subnetworks based on chemical inputs. This matches subnetworks to specific tasks, enhancing efficiency.

- Show through analysis that GRNNs consume orders of magnitude less power than even specialized neuromorphic chips.

Key Contributions:
- Formalize the notion of gene-perceptrons and methods to extract weights transforming GRNs into pre-trained GRNNs that mirror ANN architectures.

- Demonstrate how cell plasticity expands the diversity of computable functions, enabling the selection of application-specific GRNN subnetworks.

- Energy analysis proves extreme efficiency of wet TinyML, with power usage in GRNNs below 50 picowatts even for complex networks.

- Showcase how temporal plasticity facilitates the derivation of diverse regression models from GRNN subnetworks.

- Propose wet TinyML as a new paradigm for low-power on-device ML that leverages the computational capabilities inherent in biological cells.

In summary, the paper introduces and analyzes the promising concept of bio-chemical neural networks based on gene regulatory processes in cells, opening doors to tiny machine learning devices that operate at minute power levels compared to current silicon hardware.
