# [Towards Zero-Shot Scale-Aware Monocular Depth Estimation](https://arxiv.org/abs/2306.17253)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key points of this paper are:

- It proposes a novel monocular depth estimation framework called ZeroDepth that is capable of predicting metric depth and transferring it across datasets with different camera geometries. 

- It introduces two main modifications to standard monocular depth architectures:

    1) Using input-level geometric embeddings to encode camera parameters jointly with image features. This allows the network to learn scale priors based on physical sizes/shapes.

    2) Maintaining a variational latent representation that enables sampling during decoding to generate probabilistic depth estimates.

- ZeroDepth is trained on large and diverse real and synthetic datasets to learn robust depth and scale priors that transfer across domains. 

- It does not require pose information, multi-view training, or ground truth depth for scale alignment at test time.

- Experiments show ZeroDepth achieves state-of-the-art zero-shot transfer results on KITTI, DDAD, nuScenes and NYUv2 datasets. It outperforms methods that train on target data and rely on median scaling.

So in summary, the key hypothesis is that by using geometric embeddings and a variational latent space trained on diverse data, the framework can learn transferable scale priors to enable robust metric depth prediction across datasets with different camera parameters and geometries.


## What is the main contribution of this paper?

 This paper introduces a novel framework called ZeroDepth for zero-shot scale-aware monocular depth estimation. The main contributions are:

- Proposes a new monocular depth estimation architecture that can transfer metrically accurate predictions across different datasets with varying camera geometries. This is achieved through:

1) Input-level geometric embeddings that allow the network to reason about scale and physical size. 

2) A variational latent representation that enables sampling during decoding to generate probabilistic depth estimates.

- Introduces several encoder-level data augmentation techniques like resolution jittering, ray jittering, and embedding dropout to improve robustness to appearance and geometric gaps between datasets.

- Achieves state-of-the-art zero-shot transfer results on multiple indoor and outdoor benchmarks, outperforming methods that require in-domain training data and ground truth scaling. The same pre-trained model generalizes well to both settings.

- Enables metric depth prediction directly from monocular images, without relying on other sensor modalities or test-time alignment. This has important practical applications in robotics, autonomous driving, etc.

In summary, the main contribution is a new framework for monocular depth estimation that can directly transfer metrically accurate predictions across different datasets in a zero-shot manner, eliminating the need for domain-specific scaling. This is enabled by learning deep priors over geometry and scale.
