# [Equity through Access: A Case for Small-scale Deep Learning](https://arxiv.org/abs/2403.12562)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Recent advances in deep learning rely on large-scale data and compute, resulting in high resource costs like energy, emissions, etc. 
- This is creating a barrier to entry for researchers and practitioners with limited access to such large-scale resources, especially in the Global South.
- There is a lack of focus on model efficiency and equity considerations in much of deep learning research.

Proposed Solution:
- The paper argues for greater focus on small-scale deep learning models rather than singularly chasing state-of-the-art performance with ever-larger models. 
- It introduces a new metric called PePR score to capture performance per unit resource, allowing joint optimization of efficiency and accuracy.

Methods:
- Experiments conducted with 131 CNN architectures from 1M to 130M parameters on 3 medical imaging datasets.
- Models evaluated on metrics like accuracy, energy use, training time, etc. 
- PePR score formulated to quantify accuracy achieved per unit resource consumed, enabling tradeoff assessments.

Key Results:
- No accuracy difference between small and large scale models when fine-tuned from pre-trained weights with limited compute. 
- Significantly higher PePR score for small models, indicating better efficiency.
- Qualitative evidence that pre-trained models can reduce need for large datasets.
- PePR score captures diminishing returns in accuracy with increasing model scale.

Main Contributions:
- First comprehensive analysis of accuracy-efficiency tradeoffs spanning diverse model types and scales.
- Demonstrates potential for small specialized models in medical imaging vs chasing ever-larger models.
- Introduces new PePR metric to capture performance per resource unit consumed.
- Argues for greater focus on model efficiency and access to improve equity in AI.

In summary, the paper makes a case for small-scale deep learning based on experiments capturing accuracy-efficiency tradeoffs using a novel PePR score, and calls for the community to prioritize efficiency and accessibility over singularly chasing SOTA accuracy.
