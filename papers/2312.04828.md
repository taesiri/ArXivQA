# [HuRef: HUman-REadable Fingerprint for Large Language Models](https://arxiv.org/abs/2312.04828)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Protecting large language models (LLMs) against unauthorized use has become important due to their resource-intensive training and careful licensing. However, identifying the original base model of an LLM is challenging because parameters may change from fine-tuning or continued pretraining. Existing methods like post-hoc detection or watermarking have limitations in this context.

Proposed Solution:
The authors propose HuRef, a human-readable fingerprint to uniquely identify an LLM's base model without exposing parameters or interfering with training. 

Key Observations:
- The vector direction of LLM parameters remains stable after convergence during pretraining, with negligible changes from subsequent training like fine-tuning or continued pretraining. This makes it a sufficient condition to identify the base model. 
- Intentionally suppressing the cosine similarity between an LLM and its base model during continued training damages performance, showing vector direction's necessity.

However, simple attacks like permutation can alter the direction without affecting performance. 

Main Contributions:
- Derive 3 invariant terms robust to attacks by analyzing Transformer structure.
- Map terms to Gaussian vectors using a convolutional encoder, trained with contrastive learning and adversarial training for locality preservation.
- Convert Gaussian vectors into dog images using StyleGAN2 generator to make fingerprints human-readable.

Therefore, the method yields a dog image fingerprint that indicates an LLM's base model. The dog appearance remains consistent over various subsequent training while differing for models with different origins. This allows tracking LLM origins easily without exposing parameters or interfering training.
