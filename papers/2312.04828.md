# [HuRef: HUman-REadable Fingerprint for Large Language Models](https://arxiv.org/abs/2312.04828)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of the paper:

This paper introduces HuRef, a human-readable fingerprinting approach for identifying the base model of large language models (LLMs) without exposing model parameters or interfering with training. The authors first observe that the vector direction of LLM parameters remains stable after convergence during pretraining, showing negligible changes from subsequent training like fine-tuning or continued pretraining. This direction alone is insufficient since it's vulnerable to attacks like matrix rotations that don't affect performance. To address this, leveraging Transformer structures, the authors systematically analyze potential attacks and define three invariant terms robust to these attacks. They make the terms human-readable by mapping them to a Gaussian vector using a convolutional encoder, then converting that vector into a natural image with StyleGAN2. The encoder ensures Gaussian output and locality preservation via adversarial training and contrastive learning. As a result, LLMs adapted from the same base model generate similar dog images, while independently trained LLMs yield distinct dogs. Extensive experiments validate the effectiveness and invariance of this fingerprinting approach across diverse LLMs and training paradigms. The generated dog images reliably indicate LLM origins without revealing parameters or disturbing training.
