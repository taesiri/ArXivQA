# [Learning Long-Range Perception Using Self-Supervision from Short-Range   Sensors and Odometry](https://arxiv.org/abs/1809.07207)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be whether a self-supervised learning approach can be used to predict the future outputs of a short-range sensor (like a proximity sensor) by interpreting the current outputs of a long-range sensor (like a camera). Specifically, the authors aim to develop and experimentally validate a general framework for this type of self-supervised learning of long-range perception tasks. The key hypothesis appears to be that by using future short-range sensor outputs as labels for current long-range sensor data, a model can learn to interpret the long-range data in a way that is useful for perception tasks like obstacle detection. The experiments then evaluate whether this approach is effective in practice.


## What is the main contribution of this paper?

The main contribution of this paper is a novel, general approach for self-supervised learning of long-range perception. The key ideas are:- Using a combination of a long-range sensor (e.g. camera) and a short-range sensor (e.g. proximity sensor). - The short-range sensor provides direct but local information relevant to a perception task. The long-range sensor provides wider contextual information that is harder to interpret directly.- Future/past outputs of the short-range sensor are used as labels to train a model to interpret the current long-range sensor data. This allows self-supervised training without human labeling effort.- The approach is instantiated for obstacle detection but is general and could be applied to other tasks like terrain classification, grasping, etc.- A robotic platform acquires training data autonomously by roaming environments. Odometry relates future short-range sensor readings to current long-range data.- A neural network model is trained on this self-supervised data to predict short-range sensor outputs at multiple future distances from the current long-range data.- Experiments on a robot with camera and proximity sensors show the approach can learn to detect obstacles at distances beyond the proximity sensors' range.In summary, the key contribution is a self-supervised learning framework to extend perception range by combining sensors with complementary characteristics. The effectiveness of the approach is demonstrated for obstacle detection.
