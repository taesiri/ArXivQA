# [Learning Long-Range Perception Using Self-Supervision from Short-Range   Sensors and Odometry](https://arxiv.org/abs/1809.07207)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be whether a self-supervised learning approach can be used to predict the future outputs of a short-range sensor (like a proximity sensor) by interpreting the current outputs of a long-range sensor (like a camera). Specifically, the authors aim to develop and experimentally validate a general framework for this type of self-supervised learning of long-range perception tasks. The key hypothesis appears to be that by using future short-range sensor outputs as labels for current long-range sensor data, a model can learn to interpret the long-range data in a way that is useful for perception tasks like obstacle detection. The experiments then evaluate whether this approach is effective in practice.


## What is the main contribution of this paper?

The main contribution of this paper is a novel, general approach for self-supervised learning of long-range perception. The key ideas are:- Using a combination of a long-range sensor (e.g. camera) and a short-range sensor (e.g. proximity sensor). - The short-range sensor provides direct but local information relevant to a perception task. The long-range sensor provides wider contextual information that is harder to interpret directly.- Future/past outputs of the short-range sensor are used as labels to train a model to interpret the current long-range sensor data. This allows self-supervised training without human labeling effort.- The approach is instantiated for obstacle detection but is general and could be applied to other tasks like terrain classification, grasping, etc.- A robotic platform acquires training data autonomously by roaming environments. Odometry relates future short-range sensor readings to current long-range data.- A neural network model is trained on this self-supervised data to predict short-range sensor outputs at multiple future distances from the current long-range data.- Experiments on a robot with camera and proximity sensors show the approach can learn to detect obstacles at distances beyond the proximity sensors' range.In summary, the key contribution is a self-supervised learning framework to extend perception range by combining sensors with complementary characteristics. The effectiveness of the approach is demonstrated for obstacle detection.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other research on self-supervised learning for robot perception:- The proposed approach is more general than most prior work, as it can learn to predict arbitrary short-range sensor outputs (not just terrain classification or detection of nearby obstacles). The authors demonstrate this by applying the method to two very different tasks.- It does not require accurate calibration between sensors, unlike some methods that rely on registered camera and depth sensor data. The camera can be placed arbitrarily.- It associates camera frames to sensor outputs from different times, not just simultaneous data. This allows creating training labels from odometry, rather than assumptions about what's in view.- The use of future short-range sensor outputs as "labels" for current long-range data is novel. Most self-supervised methods predict properties of the current sensory input. - They collect a fairly large dataset (50K examples) using an autonomous data collection behavior. Many comparable works gather less data or require more human effort.- The performance degrades gracefully with distance, rather than just near/far binary predictions. This is likely due to the multi-label classification formulation.Overall, this appears to be a flexible and practical approach that advances self-supervised learning for robot perception. The quantitative experiments and comparisons to a random baseline demonstrate its effectiveness. Testing generalization to new environments is also a strength.
