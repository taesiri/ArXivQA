# [AttentionViz: A Global View of Transformer Attention](https://arxiv.org/abs/2305.03210)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we gain a deeper understanding of the self-attention mechanism in transformer models through interactive visualization techniques? More specifically, the authors propose a new visualization approach to help researchers explore and analyze the patterns learned by the query and key vectors used in transformer self-attention calculations. Their technique involves creating a joint embedding space for the queries and keys from multiple input sequences, then visualizing this space to reveal global attention trends across many examples. The main hypothesis behind this work seems to be that visualizing query and key vectors in this joint embedding will provide new insights into transformer self-attention that previous visualization methods, focused on single input sequences, could not offer. The authors implement their technique in an interactive tool called AttentionViz and apply it to study attention in major language models like BERT and GPT as well as vision transformers.Through case studies and expert interviews, they aim to demonstrate that their visualization approach and AttentionViz tool can:- Help researchers better understand how self-attention informs model behavior in general- Allow easy comparison and contrasting of attention heads - Facilitate the identification of attention anomalies or unexpected model behavior- Provide a flexible platform to study attention across various models, tasks, and modalitiesIn summary, the central research question is about gaining insights into transformer self-attention through a new multi-sequence visualization approach, embodied in the AttentionViz system. The utility of this technique is evaluated through usage scenarios and domain expert feedback.


## What is the main contribution of this paper?

The main contribution of this paper is a new visualization technique for exploring self-attention in transformer models. Specifically, the key ideas are:- Visualizing a joint embedding space of the query and key vectors used in the self-attention computation. This creates a visual signature for each attention head that reveals patterns across multiple input sequences. - Applying this technique to build an interactive tool called AttentionViz that allows users to explore attention patterns in language (BERT, GPT-2) and vision (ViT) transformers. The tool provides a global view of all heads as well as the ability to drill down into details.- Demonstrating how AttentionViz can offer insights about attention mechanisms through several application scenarios, including:    - Finding visual traces linked to positional attention patterns in BERT        - Uncovering hue/brightness specialization in ViT's visual attention        - Detecting potential anomalies in GPT-2's attention patterns- Collecting feedback from domain experts that supports the utility of this approach for understanding and analyzing self-attention in transformers. The experts also proposed additional applications for visualizing other types of embeddings at scale.In summary, the main contribution is a novel visualization technique for studying transformer self-attention across multiple inputs, its implementation in an interactive tool, and evidence that this approach can provide new insights about attention mechanisms in state-of-the-art models. The joint query-key embedding view allows researchers to explore attention patterns at a higher, more global level compared to previous instance-based techniques.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper introduces a new visualization technique to understand transformer self-attention by creating a joint embedding space of query and key vectors, and applies this in an interactive tool called AttentionViz to gain insights about attention mechanisms in language and vision transformers.
