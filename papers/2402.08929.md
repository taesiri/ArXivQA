# [Second Order Methods for Bandit Optimization and Control](https://arxiv.org/abs/2402.08929)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Bandit convex optimization (BCO) is an important framework for online decision making under uncertainty. Existing algorithms that achieve tight regret bounds have prohibitive computational complexity for high dimensional problems.
- Online control with adversarial noise is challenging. The best known regret rate was $\tilde{O}(T^{2/3})$. It was an open question whether the optimal $\tilde{O}(\sqrt{T})$ rate can be attained. 

Proposed Solutions:

1. For BCO:
- Propose a simple and efficient "Bandit Newton Step" (BNS) algorithm for a broad class of $\kappa$-convex losses like quadratic, generalized linear models etc.
- BNS attains $O(d^{2.5}\sqrt{T})$ regret with $O(d^2)$ per-iteration complexity. This is the first computationally efficient algorithm for several BCO problems like bandit logistic regression.

2. For Online Control: 
- Leverage the affine memory structure in control problems to attain $\tilde{O}(\sqrt{T})$ regret even with fully adversarial noise. This resolves an open question.
- Propose an efficient "Newton Bandit Perturbation Controller" algorithm by reducing control to BCO with affine memory.

3. Hardness of BCO with General Memory:
- Provide a $\tilde{\Omega}(T^{2/3})$ lower bound on regret even for smooth quadratic losses. This separates control from general BCO with memory.

Main Contributions:

- First efficient BCO algorithm for rich $\kappa$-convex losses with optimal regret.
- First optimal regret algorithm for adversarial control by using affine memory structure. 
- Separated control and general BCO-M via lower bound construction.

The paper makes significant progress on long-standing open problems in bandit convex optimization and online control. The proposed algorithms are simple, practical and come with strong theoretical guarantees.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the key points from the paper:

The paper develops an efficient bandit second-order algorithm that attains optimal regret for a broad class of κ-convex losses including generalized linear models, addresses the open problem of optimal rates for bandit linear control by leveraging affine memory structure, and shows a lower bound indicating the hardness of bandit convex optimization with general non-affine memory.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. It proposes a new bandit convex optimization algorithm called Bandit Newton Step (BNS) that achieves optimal (in terms of time horizon T) regret bounds for a broad class of convex functions called κ-convex functions. This class contains many practical loss functions like quadratic, generalized linear models etc. In addition to optimal regret, BNS is also computationally efficient with per-iteration complexity of O(d^2).

2. It extends the BNS algorithm to the setting of online convex optimization with memory (OCO-M). For loss functions with certain affine structure, the extended BNS algorithm attains optimal regret bounds. This leads to an optimal regret algorithm for bandit LQR/LQG control problems. 

3. It shows that the more general BCO-M problem with non-affine memory is harder, by deriving a ~Ω(T^(2/3)) regret lower bound even for smooth, quadratic losses. This separates the complexities of bandit LQR/LQG control and general BCO-M.

In summary, the main contributions are an efficient bandit convex optimization algorithm with optimal regret guarantees, its extension to specialized structured memory settings like control, and fundamental limits for the general BCO-M problem.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Bandit convex optimization (BCO): A framework for online decision making under uncertainty where the learner only receives partial feedback (bandit feedback) instead of full loss functions. 

- $\kappa$-convex functions: A broad class of convex functions with curvature bounded between two positive definite matrices. Includes quadratic, generalized linear models, etc.

- Online Newton Step: An algorithm for online optimization that uses second-order information. This paper adapts it to the bandit setting.

- Regret bounds: Performance metric that measures how much worse the online learner performs compared to the best fixed decision in hindsight. Tight rates are $O(\sqrt{T})$.

- Online control: Extension of bandit optimization to control problems with state and dynamics. Related problems include LQR and LQG control.

- Memory: Some online problems like control have loss functions that depend on previous decisions, known as "memory".

- Affine memory: A structural property where the memory depends linearly (affinely) on past actions. Special case of general memory.

- Lower bounds: Fundamental limits on the performance of bandit algorithms shown through explicit construction of hard instances. 

- Improper learning: Algorithms that are allowed to play points outside the feasible set to get better regret. Many bandit algorithms are improper.

The key contributions are tight regret bounds and efficient algorithms for $\kappa$-convex losses, as well as upper and lower bounds for control problems.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes a bandit Newton step algorithm for a class of κ-convex losses. How does the definition of κ-convex losses generalize notions of strong convexity and smoothness? What key properties of κ-convex losses facilitate the analysis of the bandit Newton step algorithm?

2. One of the main challenges in bandit optimization is balancing the bias and variance in gradient estimates. How does the paper address this challenge through the use of stochastic Hessian estimates? What is the intuition behind using a Hessian-based preconditioner matrix?

3. The regret analysis relies on bounding differences between various smoothed variants of the loss function f_t. What is the motivation behind defining these smoothed loss functions? How do they connect the gradient and Hessian estimates to the actual loss f_t?  

4. The paper shows an application of the proposed method to bandit logistic regression. How does the inherent structure of the logistic loss function satisfy the requirements of a κ-convex loss? What implications does this have on the regret bound?

5. For the online control setting, the paper leverages the affine memory structure of linear dynamical systems. What specifically makes this affine structure amenable to attaining optimal regret? How does this contrast with the lower bound for general loss functions with memory?

6. The control algorithm NBPC relies on system Markov parameters for computing Hessian approximations. What role do the Markov parameters play in encapsulating the system dynamics? How does this facilitate regret analysis?

7. The lower bound construction is based on a multi-scaled random walk. What properties of this random process make it suitable for showing a regret lower bound? How is the adaptive nature of the loss captured through this construction?

8. How does the improper learning aspect of the algorithm contrast with typical proper learning algorithms? What benefits and potential downsides are there to allowing improper learning actions?

9. The matrix concentration results rely on matrix versions of classic concentration inequalities. How do matrix Azuma and Freedman inequalities facilitate bounding cumulative Hessian estimates?

10. For extending the control results to unknown systems, what are the main additional challenges? What systemic properties need to be estimated, and how can online algorithms be adapted?
