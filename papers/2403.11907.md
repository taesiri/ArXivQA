# [Distill2Explain: Differentiable decision trees for explainable   reinforcement learning in energy application controllers](https://arxiv.org/abs/2403.11907)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
- Demand-side flexibility from residential sector is important for grid balancing and energy transition. Home energy management systems (HEMS) are needed to unlock this flexibility from assets like home batteries. 
- Reinforcement learning (RL) methods can be used to develop HEMS but suffer from two issues: (i) data inefficiency of RL training, and (ii) opaque/non-interpretable policies. 
- While issue (i) has been addressed in some prior works, explainability of RL-based HEMS remains a gap.

Proposed Solution:
- The paper proposes a novel method to obtain explainable RL policies using policy distillation and differentiable decision trees (DDTs). 
- First, a standard RL agent (DQN) is trained to obtain a good control policy (teacher policy). 
- Then, using policy distillation, the DQN policy's knowledge is transferred to a student policy based on DDTs. DDTs allow gradient-based training while ensuring structural explainability.
- By distilling the DQN policy into DDTs, the method obtains control policies that have good performance and are explainable.

Main Contributions:
- Novel framework for explainable RL using policy distillation and DDTs. Can convert black-box RL policies into explainable decision trees.
- Validate method on HEMS battery control scenario. Show DDT policies achieve ~20-25% better cost than rules-based control.
- Present explainability analysis of DDT policies. Much more intuitive and decomposable than DQN policies.  
- Highlight smaller compute footprint of DDTs. Around 200x fewer parameters than DQN policies.

Overall, the paper makes a novel contribution in using DDTs and policy distillation for explainable reinforcement learning-based control policies in the energy domain.
