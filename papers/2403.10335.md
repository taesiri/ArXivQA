# [NECA: Neural Customizable Human Avatar](https://arxiv.org/abs/2403.10335)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Human avatars are becoming increasingly useful for applications like metaverse, telepresence, and games. However, most existing methods for creating neural human avatars are limited in customizability, only enabling animation or relighting rather than full control over aspects like pose, shape, lighting, texture, and shadow. There is a need for methods that can generate customizable and photorealistic human avatars.

Method:
This paper proposes NECA, a novel framework to learn fully customizable neural human avatars from monocular or sparse multi-view videos. The key ideas are:

1) Represent humans in complementary canonical and surface spaces to capture both high-frequency details and geometry-aware characteristics. 

2) Disentangle the representation into distinct neural fields for geometry, albedo, shadow and lighting to enable granular control.

3) Self-supervised training with only photometric losses and normal regularization.

Specifically, a pose-aware feature is defined on factorized tri-planes in the canonical space to enable deformation, while a subject-level feature using local tangent space coordinates and UV map facilitates consistency. Separate MLPs then predict properties like SDF, albedo and shadow fields. Volumetric rendering creates photorealistic results.

Contributions:
1) NECA is the first approach to enable full control over pose, shape, lighting, texture and shadow for neural human avatars.

2) The method achieves state-of-the-art performance on tasks like novel pose synthesis and relighting. 

3) Extensive qualitative results demonstrate real-world editing scenarios like reposing, reshaping, retexturing, relighting and reshadowing.

The approach advances the capability for customizable and photorealistic neural human digitization with applications across gaming, VR, digital fashion and more. Limitations relate to sensitivity to pose estimate errors and environment lighting assumptions.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

This paper presents NECA, a novel framework to learn fully customizable neural human avatars from monocular or sparse-view videos, which enables photorealistic rendering and editing capabilities across various attributes such as pose, shape, texture, lighting, and shadow.


## What is the main contribution of this paper?

 Based on my understanding, the main contribution of this paper is proposing NECA, a novel framework that can learn fully customizable neural human avatars from monocular or sparse-view videos. Specifically, NECA represents humans in complementary dual spaces to capture both high-frequency details and geometry-aware characteristics. It predicts disentangled neural fields for geometry, albedo, shadow, and lighting, enabling photorealistic rendering and editing capabilities across various attributes like pose, shape, texture, lighting, and shadow. Experiments demonstrate NECA's improvements over prior arts in tasks such as novel pose synthesis and relighting. In summary, NECA advances the state-of-the-art by enabling more versatile and controllable neural human avatar creation and editing.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- Neural customizable human avatar
- Disentangled neural fields
- Dual space representation (canonical space and surface space)
- Self-supervised learning
- Novel pose synthesis
- Human relighting
- Shape/texture/shadow editing
- Photorealistic rendering
- Granular customization

The paper introduces NECA, a novel framework to learn fully customizable neural human avatars from videos. Key capabilities enabled by NECA include generating realistic renderings under arbitrary poses, viewpoints and lighting, as well as editing the shape, texture, shadow, etc of the avatar. The core technical ideas include dual space representation to capture both high-frequency details and geometry-aware features, disentangled neural fields for shape, albedo, shadow and lighting, and self-supervised learning with only photometric losses and normal regularization. Evaluation is performed comprehensively on tasks like novel pose synthesis and relighting to showcase NECA's versatility. So in summary, the key terms reflect ideas around customizable neural avatars, disentanglement, dual spaces, editing capabilities and self-supervision.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1. The paper proposes learning a human representation in complementary dual spaces - canonical space and surface space. Why is learning features in dual spaces beneficial compared to just using one representation? What are the limitations of only using canonical or surface space features?

2. The paper disentangles the neural fields into separate components for geometry, albedo, shadow, and lighting. Why is this disentanglement useful? How does it enable the customization capabilities highlighted in the paper? What challenges arise from predicting these components with separate neural networks?

3. The method constructs a per-pose tri-plane feature using CP decomposition to capture high-frequency details. Explain the motivation and formulation for this component. What are the tradeoffs with different numbers of components R in the CP decomposition?

4. Explain the formulation of the local tangent space coordinates used in the surface space representation. Why is this proposed compared to alternatives like relative position or UV coordinates? What challenges arise from needing to find the nearest surface point?  

5. The self-supervised losses include photometric consistency, mask prediction, eikonal, and normal regularization terms. Explain the motivation and formulation of each loss term. What impact did you observe from ablating different loss components?

6. The method assumes a single grayscale environment light during capture. How was this light modeled and optimized? Why make this simplifying assumption and what are its limitations? How could the approach be extended to colored or dynamic lighting?

7. The paper demonstrates applications like novel pose synthesis, relighting, and reshaping. What customization results were most compelling? What applications are enabled by the editable attributes? What tasks remain challenging for the method?

8. How does the performance of the approach compare quantitatively and qualitatively to other state-of-the-art neural human modeling methods? What benchmark datasets were used for evaluation? What metrics and protocols were followed?

9. What limitations exist in the current method? How might the representation capacity, computational efficiency, or editing robustness be improved in future work? What ethical concerns need to be considered when generating highly realistic and editable human models?

10. The method requires only monocular or sparse multi-view video as input. How is this achieved? What information enables learning detailed geometry and appearances from such limited input data compared to dense camera arrays? Could fewer input views be used?
