# Learning Vision-based Pursuit-Evasion Robot Policies

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we learn vision-based robot policies that can reason strategically through partially observable physical state and latent intent in multi-agent interactions?Specifically, the authors aim to develop an approach for learning robot policies that can exhibit strategic behaviors like information gathering, intent prediction, and anticipation when interacting with other agents in the real world under sensing constraints (i.e. using only onboard sensors like cameras). The key challenges are handling the partial observability of the physical state and modeling the latent intent of other agents.To tackle this, the main idea is to use a privileged learning approach where a fully observable policy generates supervision for training a partially observable policy. The future trajectory of the other agent is used as a novel type of privileged information to infer their latent intent. The authors study how different models for the fully observable supervisor policy and different agent policies affect the quality of the distillation.The central hypothesis is that by leveraging privileged information about latent intent from future trajectories, they can transform the intractable planning problem into a supervised learning problem. This allows the robot policy to gather information, make predictions, and act strategically despite real-world sensing constraints.


## What is the main contribution of this paper?

The main contribution of this paper is developing a method to learn pursuit-evasion robot policies that can reason strategically through partial observability of the physical state and latent intent of other agents. The key ideas are:- Using a fully-observable teacher policy with access to future opponent trajectories to generate supervision for a partially-observable student policy. This converts the intractable Dec-POMDP formulation into a more tractable supervised learning problem.- Learning a latent representation of the opponent's intent from future trajectories that captures goal direction, policy class, etc. The student policy must estimate this latent intent from noisy observations.- Analyzing the importance of diversity vs optimality in the opponent behavior during training. Opponents that are too optimal (e.g. game theoretic) provide poor supervision. - Demonstrating the approach on a physical quadruped robot playing pursuit-evasion games against humans and other robots using only onboard proprioception and vision. The robot exhibits interesting behaviors like information gathering, intent prediction, and anticipation.So in summary, the main contribution is using privileged learning to enable a robot to learn strategic planning behaviors for decentralized partially-observable multi-agent interactions purely from onboard sensing and interaction experience.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper presents a method to train a robot policy for pursuit-evasion games that can reason strategically through partial observability by using a fully-observable policy to generate supervision.


## How does this paper compare to other research in the same field?

Here are some key points comparing this paper to other related work in multi-agent robot learning:- This paper focuses specifically on pursuit-evasion games between two mobile robots with onboard sensing, which is a relatively underexplored setting compared to simulation environments or with global state information. Most prior work in multi-agent RL has been in simulated environments like video games.- The approach uses privileged learning to train a partially observable policy, with the privileged information being the future trajectory of the evader agent. This is a novel application of privileged learning. Other related work learns latent intent models but assumes more state observability.- They find that the quality of the supervision signal depends heavily on the diversity and optimality of the evader behavior during training. Game theoretic opponents that are very optimal under perfect state assumptions provide weak supervision. This insight on the role of the opponent model is a key contribution.- They demonstrate the approach on a physical quadruped robot playing pursuit-evasion games in the real world using only onboard sensing and compute. There has been very little prior work showing decentralized multi-agent interactions on real robotic systems.- Limitations include not explicitly modeling environmental affordances and a limited field of view assumption. The approach is also currently specialized to the pursuit-evasion setting.Overall, this paper makes progress on a very challenging robot learning problem of decentralized multi-agent interaction using only onboard sensing. The insights on opponent modeling, applicability to the real-world, and method of using privileged learning help advance the field.
