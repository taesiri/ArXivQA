# [InsCL: A Data-efficient Continual Learning Paradigm for Fine-tuning   Large Language Models with Instructions](https://arxiv.org/abs/2403.11435)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) show impressive capabilities on various NLP tasks through instruction tuning. However, in real applications, the environment keeps changing and new tasks/data keep emerging, requiring continual adaptation of LLMs without catastrophic forgetting of previous tasks.

- Traditional replay-based continual learning methods do not fully utilize the available instruction information to customize an optimal replay strategy for instruction tuning scenarios.

Method:
- The paper proposes InsCL, an Instruction-based Continual Learning paradigm that leverages instructions to guide the replay process. 

- InsCL allocates replay data amount dynamically based on task similarity calculated by Wasserstein Distance using instruction embeddings. More different tasks get more replay.

- An Instruction Information Metric (InsInfo) is proposed to quantify complexity and diversity of instructions. InsCL replays more high InsInfo data.

Contributions:
- Extensive experiments over 16 tasks show InsCL consistently outperforms baselines, achieving 3.0 higher average Relative Gain than random replay.

- Analysis on forgetting rate and category reveals complex reasoning tasks suffer more forgetting without replay. Forgetting instances are mainly instruction-unrelated.

- InsCL provides an effective replay-based continual learning solution that fully utilizes instruction information. The idea of leveraging instructions for similarity calculation and data selection is novel.

In summary, the paper explores continual learning for instruction tuning of LLMs, and proposes the instruction-based InsCL method to customize replay strategies based on instruction information. Both the idea and experimental results are solid and promising.
