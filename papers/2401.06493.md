# [Expected Shapley-Like Scores of Boolean Functions: Complexity and   Applications to Probabilistic Databases](https://arxiv.org/abs/2401.06493)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- The paper studies the problem of computing expected Shapley-like scores (expected Shapley values and expected Banzhaf values) for Boolean functions representing database queries over probabilistic databases. 
- Computing these scores helps explain the contribution of individual database facts to the query results in a probabilistic setting. 
- However, computing these scores is challenging as they generalize probabilistic query evaluation which is often intractable.

Key Contributions:

1. Formalizes the problem of computing expected Shapley-like scores for Boolean functions and shows they generalize probabilistic query evaluation.

2. Proves that computing expected Shapley-like scores reduces to computing expected values for many common classes of Boolean functions like decision trees and deterministic decomposable circuits. 

3. Shows an equivalence between computing expected Shapley values and expected values for "reasonable" function classes that can compute empty-set values in PTIME.

4. Gives a polynomial time algorithm to compute expected Shapley-like scores for deterministic decomposable circuits and simplifications for specific cases.

5. Applies the framework to probabilistic databases, shows computing expected Shapley values of database facts reduces to probabilistic query evaluation.

6. Implements the algorithms within an open-source probabilistic database system and validates their feasibility on benchmark database queries.

In summary, the paper provides a complexity analysis of computing expected Shapley-like scores, establishes connections to probabilistic query evaluation, and presents new tractable algorithms for meaningful classes of Boolean functions. The validation on a real database system demonstrates the practical utility of these scoring mechanisms.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The paper studies the computation of expected Shapley-like scores for Boolean functions, shows the problem can be reduced to computing expected values, gives algorithms for deterministic and decomposable Boolean circuits, implements this for probabilistic databases, and shows experimentally that computing expected scores is feasible in practical scenarios.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1) It proposes the notion of expected Shapley-like scores for Boolean functions, which is a probabilistic generalization of standard Shapley-like scores used in areas like explainable AI and databases.

2) It shows that computing expected Shapley-like scores can always be reduced in polynomial time to computing expected values of Boolean functions. Further, it shows an equivalence between these two problems under common assumptions.

3) For the case of deterministic and decomposable (d-D) Boolean circuits, it provides concrete polynomial-time algorithms to compute expected Shapley-like scores.

4) It implements these algorithms within a probabilistic database system and experimentally validates their feasibility on some standard database benchmark queries.

In summary, the paper introduces the notion of expected Shapley-like scores, situates its complexity compared to related problems, gives tractable algorithms for an important Boolean function representation, and shows the practical viability of using these scores for explanations over probabilistic databases.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it include:

- Shapley value
- Banzhaf value
- power index
- Boolean function
- expected value
- probabilistic database
- provenance
- knowledge compilation
- d-D circuit
- tractable
- \#P-hard

The paper studies the complexity of computing expected Shapley-like scores, which generalize the Shapley value and Banzhaf value, over Boolean functions and in the context of probabilistic databases. It relates this problem to computing expected values of Boolean functions and probabilistic query evaluation. Key results show equivalences between these problems under certain assumptions. Algorithms are presented for the tractable case of deterministic and decomposable Boolean circuits. Experiments on probabilistic databases demonstrate the feasibility of computing expected Shapley-like scores in practice.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes the notion of expected Shapley-like scores. How is this notion formally defined, and how does it generalize the standard notion of Shapley values from cooperative game theory?

2. Theorem 1 shows that computing expected Shapley-like scores can be reduced to computing expected values. Explain the high-level idea behind this reduction and why it is non-trivial. 

3. The paper shows an equivalence result between computing expected Shapley values and computing expected values (Corollary 1). What assumptions on the Boolean functions are needed for this equivalence to hold? Discuss whether these assumptions are reasonable.

4. Algorithm 1 gives a method to compute expected Shapley-like scores when the Boolean function is represented as a deterministic and decomposable (d-D) circuit. Explain how this algorithm works, in particular how do the β and γ values allow dynamic programming. 

5. For the specific case of expected Banzhaf values, the paper gives a faster quadratic time algorithm. Intuitively explain why the complexity can be improved in this case.

6. The paper discusses applications to probabilistic databases, by viewing query answers as Boolean functions. Explain how Corollary 3 gives a complexity dichotomy for computing expected Shapley values of conjunctive queries.

7. The experimental evaluation relies on compiling query provenance circuits to d-D representations. Discuss the different approaches used for this compilation and their relative merits. 

8. Analyze the experimental results. Which observations validate or invalidate the theoretical complexity results? Are there cases where theory and practice diverge?

9. The related work discusses connections and differences with computing non-expected Shapley values and SHAP scores. Summarize what the key similarities and differences are. 

10. The paper leaves open the problem of designing approximation schemes. What approaches from the literature on approximating Shapley values could be promising for this problem? What hardness results need to be circumvented?
