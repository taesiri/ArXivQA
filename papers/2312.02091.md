# [Physics simulation capabilities of LLMs](https://arxiv.org/abs/2312.02091)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality one-paragraph summary of the key points from the paper:

This paper presents an evaluation of the capabilities of state-of-the-art large language models (LLMs) like GPT-4 on challenging, graduate to research-level computational physics problems. Specifically, the authors design about 50 original problems spread across 4 simulation codebases - stellar physics, celestial mechanics, fluid dynamics, and non-linear dynamics - that would plausibly appear on a PhD qualifier exam. They find that while today's most capable LLM in GPT-4 is not able to satisfactorily solve these research problems, it is able to generate code containing 70-90% correct lines with a combination of physics and coding errors and placeholder code. About 40% of the solutions could plausibly pass at some minimal level. The most prominent failure modes identified include poor physical units handling, inconsistent code versioning, hallucinating plausible functions, inadequate justification of simulation parameters, and unreliable definition of stopping criteria. This analysis provides a snapshot of progress and limitations of LLMs on autonomous scientific simulation capabilities using classical physics problems, while also outlining promising directions for future improvements.
