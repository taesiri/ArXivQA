# [Key-Graph Transformer for Image Restoration](https://arxiv.org/abs/2402.02634)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Image restoration (IR) aims to reconstruct high-quality images from degraded inputs. Effectively capturing global information is crucial but also computationally expensive. 
- CNNs have limited receptive fields. MLPs/Transformers lose inductive bias and have quadratic complexity with input resolution.
- Standard self-attention is prone to considering unnecessary global cues from unrelated regions, causing inefficiency.

Proposed Solution - Key-Graph Transformer (KGT):

1) Key-Graph Constructor:
- Views patch features as graph nodes. 
- Selectively connects essential nodes instead of all nodes to form a sparse yet representative Key-Graph.
- Criteria for selecting nodes is based on self-similarity between patches.

2) Key-Graph Attention:  
- Conducted under guidance of Key-Graph among selected nodes.
- Greatly reduces computational complexity from O((hw)^2) to O((hw)*k) per window.

3) Overall Framework:
- Multi-stage architecture used for SR, U-shaped architecture for other IR tasks.
- Key-Graph is constructed at beginning and shared across layers in each stage.
- Enables capturing global cues with efficiency.

Main Contributions:

- Propose novel Key-Graph Constructor and Key-Graph Attention mechanisms for efficient yet effective global modeling tailored for IR.  
- First work to incorporate graph perspective into Vision Transformers specifically for IR.
- Achieves new SOTA results across 6 IR tasks - deblurring, JPEG artifacts removal, denoising, adverse weather, demosaicking, and SR.

In summary, the paper introduces an efficient Vision Transformer architecture called Key-Graph Transformer for image restoration. By selectively modeling global contexts over a graph, it achieves significantly improved efficiency and effectiveness compared to prior arts. Extensive experiments validate its state-of-the-art performance.
