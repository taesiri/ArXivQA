# [LU-NeRF: Scene and Pose Estimation by Synchronizing Local Unposed NeRFs](https://arxiv.org/abs/2306.05410)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to jointly estimate camera poses and scene representation from images without strong assumptions on camera poses or pose priors. The key hypothesis is that by taking a local-to-global approach and synchronizing local unposed NeRFs, the joint estimation of poses and scene can be made more tractable compared to trying to optimize everything globally from the start.The main limitations the paper aims to address with existing methods are:- BARF and GARF require good initialization of poses, within 15 degrees of ground truth.- NeRF--, X-NeRF, SiNeRF, and SaNeRF only handle forward-facing scenes.  - GNeRF and VMRF assume a limited 2D camera model (upright cameras) and require accurate prior distributions on poses.To overcome these limitations, the paper introduces a pipeline that:1) Partitions the data into mini-scenes and optimizes poses locally using LU-NeRF, without assumptions on pose priors or distributions.2) Synchronizes the local LU-NeRF estimations into a global frame using robust pose synchronization. 3) Refines the poses and scene globally after synchronization provides a good initialization.The key hypothesis is that by taking this local-to-global approach, joint pose and scene estimation can be made more flexible and applicable to broader settings compared to prior work.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method for jointly estimating camera poses and neural radiance fields (scene representation) from an unordered collection of images. The key ideas are:- A local-to-global approach where the scene is partitioned into overlapping mini-scenes. Camera poses and radiance fields are estimated locally for each mini-scene. - A novel model called LU-NeRF for estimating local camera poses and radiance fields from few images without assumptions on camera configurations.- Resolving mirror symmetry ambiguities that can arise during local estimation.- Bringing the local estimations into a global coordinate frame using pose synchronization techniques.- Jointly refining the global camera poses and radiance field using all images after synchronization.The main advantage of this approach is it avoids the need for accurate pose initialization like prior works. By operating locally first, the pose estimation problem becomes better constrained before stitching local estimations together globally. The local-to-global framework also enables operating in more general SE(3) camera configurations compared to prior works.In summary, the key contribution is a full pipeline for jointly estimating camera poses and neural radiance fields from unordered image collections while making minimal assumptions about camera poses. This is enabled by the proposed local-to-global framework and the LU-NeRF model for few-shot local estimation.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new approach called LU-NeRF for jointly estimating camera poses and neural radiance fields for novel view synthesis from unordered image collections, using a pipeline that operates locally on image subsets to estimate poses and geometry before synchronizing everything globally.
