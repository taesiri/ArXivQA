# [LU-NeRF: Scene and Pose Estimation by Synchronizing Local Unposed NeRFs](https://arxiv.org/abs/2306.05410)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to jointly estimate camera poses and scene representation from images without strong assumptions on camera poses or pose priors. The key hypothesis is that by taking a local-to-global approach and synchronizing local unposed NeRFs, the joint estimation of poses and scene can be made more tractable compared to trying to optimize everything globally from the start.The main limitations the paper aims to address with existing methods are:- BARF and GARF require good initialization of poses, within 15 degrees of ground truth.- NeRF--, X-NeRF, SiNeRF, and SaNeRF only handle forward-facing scenes.  - GNeRF and VMRF assume a limited 2D camera model (upright cameras) and require accurate prior distributions on poses.To overcome these limitations, the paper introduces a pipeline that:1) Partitions the data into mini-scenes and optimizes poses locally using LU-NeRF, without assumptions on pose priors or distributions.2) Synchronizes the local LU-NeRF estimations into a global frame using robust pose synchronization. 3) Refines the poses and scene globally after synchronization provides a good initialization.The key hypothesis is that by taking this local-to-global approach, joint pose and scene estimation can be made more flexible and applicable to broader settings compared to prior work.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method for jointly estimating camera poses and neural radiance fields (scene representation) from an unordered collection of images. The key ideas are:- A local-to-global approach where the scene is partitioned into overlapping mini-scenes. Camera poses and radiance fields are estimated locally for each mini-scene. - A novel model called LU-NeRF for estimating local camera poses and radiance fields from few images without assumptions on camera configurations.- Resolving mirror symmetry ambiguities that can arise during local estimation.- Bringing the local estimations into a global coordinate frame using pose synchronization techniques.- Jointly refining the global camera poses and radiance field using all images after synchronization.The main advantage of this approach is it avoids the need for accurate pose initialization like prior works. By operating locally first, the pose estimation problem becomes better constrained before stitching local estimations together globally. The local-to-global framework also enables operating in more general SE(3) camera configurations compared to prior works.In summary, the key contribution is a full pipeline for jointly estimating camera poses and neural radiance fields from unordered image collections while making minimal assumptions about camera poses. This is enabled by the proposed local-to-global framework and the LU-NeRF model for few-shot local estimation.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new approach called LU-NeRF for jointly estimating camera poses and neural radiance fields for novel view synthesis from unordered image collections, using a pipeline that operates locally on image subsets to estimate poses and geometry before synchronizing everything globally.


## How does this paper compare to other research in the same field?

This paper presents a novel approach for jointly estimating camera poses and scene representation from unordered image collections, without relying on accurate poses or pose priors. Here are some key ways it compares to prior work:- Most prior work on neural scene representation with unknown poses makes assumptions like small pose perturbations, narrow pose distributions, or depth priors. This paper tackles the more challenging setting of arbitrary unknown 6DOF poses.- Existing methods like BARF and GNeRF rely on good pose initialization or priors, while this method operates directly on unposed images through local-to-global synchronization. It does not need accurate initialization.- Approaches like GNeRF assume a limited 2DOF camera model (elevation and azimuth). This method works for full 3DOF camera poses.- It presents the first approach designed specifically for the ambiguous few-shot local unposed setting, with strategies to handle issues like mirror symmetry.- The method is complementary to classic SfM pipelines like COLMAP. It succeeds on low-texture scenes where SfM struggles.- It naturally handles both ordered (video) and unordered image collections, while most prior work focuses on one setting.- The local to global framework draws inspiration from prior divide-and-conquer SfM methods, but innovates by incorporating neural scene representations.In summary, this paper pushes the envelope on jointly estimating pose and geometry from unordered unposed images. It relaxes assumptions made in prior work and addresses challenges like ambiguity and failure modes in the local setting. The local-to-global framework and proposed LU-NeRF model offer more flexibility compared to existing methods.


## What future research directions do the authors suggest?

The authors suggest a few potential future research directions:- Exploring better methods for building connected graphs from unordered image collections. The simple methods based on DINO features or RGB distances used in this work have limitations. Developing more robust techniques for estimating image similarity without pose information could further improve performance. - Accelerating the training and inference of LU-NeRF models using recent advances in neural scene representations like PlenOctrees and InstantNGP. This could help address the relatively high computational cost of the current approach.- Extending the method to handle scenes with dynamic content and relighting effects. The current method assumes static scenes with fixed lighting. Building in capabilities to model lighting changes and non-rigid motion would increase applicability.- Applying the local-to-global framework to other neural scene representations beyond NeRF, like neural volumes and radiance fields. The overall pipeline is general and could likely be adapted to other scene representations.- Exploring whether pose estimation can be improved by incorporating information from the optimized neural scene representation back into the pose optimization process. Currently poses are refined only based on image pixels, but the scene geometry could provide useful cues.- Developing unsupervised techniques for building connected graphs that exploit scene-specific characteristics. For example, using geometric cues rather than just image features.- Extending the method to handle extremely large scenes that need to be partitioned into more mini-scenes than currently demonstrated. Exploring hierarchical pose synchronization approaches could be beneficial.In summary, the authors point to improving graph construction, accelerating training and inference, handling dynamic scenes, applying the framework to other scene representations, leveraging optimized scene geometry, developing specialized graph building techniques, and scaling to massive scenes as interesting future research directions.
