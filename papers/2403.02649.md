# [Few-shot Learner Parameterization by Diffusion Time-steps](https://arxiv.org/abs/2403.02649)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Few-shot Learner Parameterization by Diffusion Time-steps":

Problem:
- Few-shot learning (FSL) aims to classify categories using only a few training examples per class. This is challenging for large foundation models like CLIP, as they can easily overfit to spurious correlations between irrelevant attributes (e.g. background) and class labels in the small training set.

- Existing works attach adapters to CLIP, but still suffer from spurious correlations as there is no inductive bias to isolate the nuanced class attributes that define each category.

Proposed Solution: 
- The paper reveals an inductive bias using the diffusion model (DM): as DM's forward process adds noise over time-steps, nuanced attributes like "windows" defining an aircraft get lost earlier than visually prominent attributes like "sky" background. 

- Based on this, the paper proposes Time-step Few-shot (TiF) learner. For each class, it trains an adapter for a text-conditioned DM that enables reconstructing images from their noisy version. Hence the adapter isolates nuanced attributes at small time-steps.

- For a test image, TiF learner classifies it by selecting the adapter that can best reconstruct the nuanced attributes of that image, removing influence from prominent attributes.

Main Contributions:
- Formulates FSL for foundation models and introduces a theoretical framework to separate nuanced and prominent attributes by DM time-steps
- Proposes TiF learner that mitigates spurious correlations in FSL via DM adapter training and specialized inference
- Significantly outperforms OpenCLIP and adapter baselines on fine-grained classification and re-ID tasks, improving by up to 21.6%

In summary, the paper introduces an elegant inductive bias leveraging DM time-steps that enables isolating nuanced visual attributes for robust few-shot learning with foundation models.
