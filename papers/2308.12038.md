# Large Multilingual Models Pivot Zero-Shot Multimodal Learning across   Languages

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research focus of this paper is proposing an effective training paradigm called MpM (Multilingual language models Pivot Multimodal learning across languages) for training large multimodal models in low-resource non-English languages. The central hypothesis is that by leveraging a pretrained multilingual language model as a pivot, multimodal models trained solely on English image-text data can generalize well to other languages like Chinese in a zero-shot manner, even surpassing models trained on native language image-text data.Specifically, the paper aims to address the challenge of developing competitive multimodal models for non-English languages, which is difficult due to the scarcity of large-scale high-quality image-text data in those languages. The proposed MpM paradigm tries to mitigate the dependence on native language image-text data by transferring visual knowledge learned from English data through the "language bridge" provided by the multilingual LLM.The effectiveness of MpM is demonstrated through comprehensive experiments on Chinese image-to-text and text-to-image tasks. The results show the models trained with MpM can outperform existing Chinese multimodal models, even without using any Chinese image-text data for pretraining. This supports the hypothesis that multilingual LMs can pivot effective zero-shot transfer of multimodal knowledge across languages.In summary, the key research question is how to develop competitive multimodal models for low-resource non-English languages. MpM provides an effective solution by utilizing multilingual LMs to transfer and align visual knowledge from English to the target language.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It proposes MpM, an effective training paradigm for large multimodal models in low-resource non-English languages. MpM utilizes a multilingual language model as a pivot to transfer multimodal knowledge from English to other languages in a zero-shot manner. 2. It develops VisCPM, a series of Chinese multimodal models for image-to-text and text-to-image generation. VisCPM models achieve state-of-the-art performance among open-source Chinese multimodal models by pretraining exclusively on English data and transferring to Chinese via the bilingual language model.3. It validates the effectiveness of MpM by applying it to train multimodal chatbots in 6 languages (English, German, French, Spanish, Italian, Portuguese), demonstrating the generalization capability of MpM.4. It open-sources the pre-trained VisCPM models to facilitate research, providing model weights, training details, and evaluation benchmarks.In summary, the key contribution is proposing MpM for low-resource multimodal learning and demonstrating its effectiveness by developing high-performance Chinese and multilingual multimodal models VisCPM. The paper highlights that leveraging multilingual language models is an effective way to address the lack of native multimodal data in non-English languages.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares and contrasts with other related work in multilingual multimodal learning:- Focus on leveraging pretrained multilingual LLMs: This paper specifically focuses on effectively utilizing pretrained multilingual LLMs to enable multimodal learning across languages. In contrast, many other works try to simultaneously learn multilingual and multimodal representations from scratch. - Demonstrates strong zero-shot transfer: A key result is that models pretrained on English image-text data transfer surprisingly well to other languages in a zero-shot manner, even outperforming models trained on native language data. Other works have shown some preliminary cross-lingual transfer capabilities, but not to this extent.- Systematic training paradigm: The proposed MpM training paradigm provides a principled and systematic framework for training multilingual multimodal models by dividing the process into multilingual alignment and multimodal alignment stages.- State-of-the-art for Chinese: The VisCPM models achieve new state-of-the-art results for open-source Chinese multimodal models, validating the effectiveness of the proposed approach.- Generalization to multiple languages: This work shows the approach can be extended to multiple languages by developing a conversational model across 6 languages, demonstrating wider applicability.- Focus on low-resource languages: A key motivation is enabling multimodal learning for low-resource non-English languages. This contrasts with many works centered on English.In summary, this work provides novel insights into cross-lingual transfer for multimodality via pretrained LLMs, proposes a systematic training paradigm, and achieves strong results - especially for lower-resource languages. The zero-shot transfer abilities and multilingual results are particularly noteworthy comparisons to prior work.
