# Large Multilingual Models Pivot Zero-Shot Multimodal Learning across   Languages

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research focus of this paper is proposing an effective training paradigm called MpM (Multilingual language models Pivot Multimodal learning across languages) for training large multimodal models in low-resource non-English languages. The central hypothesis is that by leveraging a pretrained multilingual language model as a pivot, multimodal models trained solely on English image-text data can generalize well to other languages like Chinese in a zero-shot manner, even surpassing models trained on native language image-text data.Specifically, the paper aims to address the challenge of developing competitive multimodal models for non-English languages, which is difficult due to the scarcity of large-scale high-quality image-text data in those languages. The proposed MpM paradigm tries to mitigate the dependence on native language image-text data by transferring visual knowledge learned from English data through the "language bridge" provided by the multilingual LLM.The effectiveness of MpM is demonstrated through comprehensive experiments on Chinese image-to-text and text-to-image tasks. The results show the models trained with MpM can outperform existing Chinese multimodal models, even without using any Chinese image-text data for pretraining. This supports the hypothesis that multilingual LMs can pivot effective zero-shot transfer of multimodal knowledge across languages.In summary, the key research question is how to develop competitive multimodal models for low-resource non-English languages. MpM provides an effective solution by utilizing multilingual LMs to transfer and align visual knowledge from English to the target language.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It proposes MpM, an effective training paradigm for large multimodal models in low-resource non-English languages. MpM utilizes a multilingual language model as a pivot to transfer multimodal knowledge from English to other languages in a zero-shot manner. 2. It develops VisCPM, a series of Chinese multimodal models for image-to-text and text-to-image generation. VisCPM models achieve state-of-the-art performance among open-source Chinese multimodal models by pretraining exclusively on English data and transferring to Chinese via the bilingual language model.3. It validates the effectiveness of MpM by applying it to train multimodal chatbots in 6 languages (English, German, French, Spanish, Italian, Portuguese), demonstrating the generalization capability of MpM.4. It open-sources the pre-trained VisCPM models to facilitate research, providing model weights, training details, and evaluation benchmarks.In summary, the key contribution is proposing MpM for low-resource multimodal learning and demonstrating its effectiveness by developing high-performance Chinese and multilingual multimodal models VisCPM. The paper highlights that leveraging multilingual language models is an effective way to address the lack of native multimodal data in non-English languages.
