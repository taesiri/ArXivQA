# [A Large-Scale Outdoor Multi-modal Dataset and Benchmark for Novel View   Synthesis and Implicit Scene Reconstruction](https://arxiv.org/abs/2301.06782)

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the central research question addressed in this paper is:How to develop a large-scale outdoor multi-modal dataset with calibrated images, point clouds, and text prompts to benchmark neural radiance fields (NeRF) methods for novel view synthesis, implicit scene reconstruction, and multi-modal synthesis? The key aspects are:1. Currently there is a lack of large-scale outdoor datasets to evaluate NeRF methods, due to high data acquisition and calibration costs. Most existing datasets focus on indoor scenes or single objects. 2. The paper introduces a new large-scale outdoor dataset called OMMO with 33 real-world scenes and over 14K calibrated images, along with point clouds and text prompts.3. They provide a pipeline to generate the dataset from drone videos in a cost-effective way.4. Benchmarks are established on the dataset to evaluate state-of-the-art NeRF methods on tasks like novel view synthesis, surface reconstruction, and multi-modal synthesis.5. Experiments show the dataset can support benchmarking most recent NeRF methods on different tasks for large outdoor scenes.In summary, the main research hypothesis is that a large-scale, multi-modal outdoor dataset can be created to enable benchmarking and advancing NeRF research on outdoor scene tasks, which currently lacks suitable datasets. The paper demonstrates this via introducing OMMO dataset and establishing benchmarks.
