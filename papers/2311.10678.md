# [Distilling and Retrieving Generalizable Knowledge for Robot Manipulation   via Language Corrections](https://arxiv.org/abs/2311.10678)

## Summarize the paper in one sentence.

 The paper presents Distillation and Retrieval of Online Corrections (DROC), a system that enables robots to respond to arbitrary language corrections from humans, distill generalizable knowledge from the corrections, and retrieve relevant past experiences to improve performance on new tasks.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the paper:

This paper presents a system called Distillation and Retrieval of Online Corrections (DROC) that enables robots to respond to arbitrary language corrections from humans, distill generalizable knowledge from those corrections, and retrieve relevant past knowledge when faced with novel tasks. DROC consists of three main components: a correction handler that generates new plans or skills in response to human feedback, a knowledge extractor that summarizes important information from the history of corrections into a knowledge base, and a knowledge retriever that finds relevant past experiences from the knowledge base to aid in new tasks. Experiments across manipulation tasks demonstrate that DROC can effectively respond to both high-level planning corrections and low-level skill corrections. By distilling knowledge from corrections, DROC is able to reduce the number of corrections needed over repeated tasks with new configurations. The results show that DROC exceeds baselines in adapting policies based on human feedback and in generalizing prior knowledge to novel settings.
