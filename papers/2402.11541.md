# [Counter-intuitive: Large Language Models Can Better Understand Knowledge   Graphs Than We Thought](https://arxiv.org/abs/2402.11541)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like GPT-3 struggle with reasoning over structured knowledge graphs (KGs) and can hallucinate facts. Researchers explore enhancing LLMs with KGs by co-training model parameters or converting KG triples to text. However, co-training is computationally expensive and converting KG triples well into fluent text is challenging. 

- This paper explores an alternative: injecting KG knowledge into pre-trained LLMs via prompts to query their understanding, rather than re-training the models. The authors use complex KG question answering (KGQA) as the task for evaluating LLM's KG understanding.

Method:
- The authors systematically evaluate LLM comprehension of KGs by varying:
    - Scale of injected KG subgraphs 
    - Noisiness of KG triples (random deletion/replacement)
    - KG injection format (triples vs generated text)

- They expand subgraphs around core reasoning paths and inject via triples or generated text. Performance on KGQA is measured across subgraph scale, noise, and format variations.

Key Findings:
- Contrary to expectations, LLMs handle messy, abstract KG triples better than fluent generated text for KGQA. This demonstrates LLMs' unexpected proficiency in organizing and comprehending structured knowledge.

- Irrelevant KG triples do not necessarily degrade LLM reasoning. LLMs can filter out irrelevant information and leverage relevant details to even improve accuracy.

- Larger LLMs exhibit less robustness to noisy KG triples, with performance degrading more severely.

Main Contributions:
- First comprehensive evaluation of how systematically varying scale, noise and format of injected KG knowledge impacts LLM reasoning ability.

- Surprising findings that go against intuitions about fluent text vs structured knowledge for large language models.

- Analysis provides insights into effectively prompting LLMs with structured knowledge graphs.
