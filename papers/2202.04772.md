# [GrASP: Gradient-Based Affordance Selection for Planning](https://arxiv.org/abs/2202.04772)

## What is the central research question or hypothesis that this paper addresses?

This paper presents GrASP, an algorithm for gradient-based affordance selection for planning in reinforcement learning (RL) problems with continuous action or option spaces. The central research question is how to effectively deal with continuous action spaces when using tree-search planning methods like Monte Carlo Tree Search (MCTS). The key challenge is that it is not feasible to expand every possible action at each node when the action space is continuous. The main hypothesis is that we can learn to select a small set of "affordance" actions or options that are useful to consider during the tree expansion process in planning. The affordances would be selected in a goal-and-state-conditional way, so that different affordances are chosen depending on the state and goal. The key ideas are:- Represent affordances as parametric mappings from states (and goals) to actions/options. Learning to select K affordances means learning K such mappings. - Use gradients through the planning computations to update the parameters of the affordance mapping functions. This allows dynamically discovering good affordances online during learning and planning.- Show that it is possible to simultaneously learn good affordances and a value-equivalent model of their effects, such that planning performance is competitive or better than model-free RL on several benchmark domains.So in summary, the central hypothesis is focused on using gradients through planning to dynamically discover a small set of affordances or high-level actions that are useful for tree-search planning in continuous action/option spaces.
