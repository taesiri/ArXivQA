# [Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4   on mock CFA Exams](https://arxiv.org/abs/2310.08678)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the key research questions and goals appear to be:

- To evaluate and benchmark the capabilities of LLMs like ChatGPT and GPT-4 on complex financial reasoning tasks, specifically using mock exam questions from the prestigious CFA exams. 

- To analyze the strengths and limitations of ChatGPT and GPT-4 when applied to financial reasoning problems in zero-shot, few-shot, and chain-of-thought prompting scenarios.

- To estimate whether ChatGPT and GPT-4 would be able to pass the actual CFA exams based on their performance on the mock exams. 

- To provide insights and suggestions for how to enhance LLMs to make them more applicable for finance-related tasks through rigorous benchmarking and analysis.

In summary, the central research question seems to be assessing how capable current non-domain-specific LLMs like ChatGPT and GPT-4 are at financial reasoning, using the well-established CFA exams as a rigorous benchmark. The goal is to analyze their strengths and weaknesses on this domain through different prompting techniques, estimate their viability for passing the actual exams, and provide guidance for how to improve LLMs for finance going forward.


## What is the main contribution of this paper?

 The main contribution of this paper appears to be an evaluation of the financial reasoning capabilities of two large language models (LLMs), ChatGPT and GPT-4, using mock exam questions from the Chartered Financial Analyst (CFA) program. 

The key points I gathered are:

- They conduct a comprehensive evaluation of ChatGPT and GPT-4 on CFA Level I and Level II mock exam questions, considering zero-shot, few-shot, and chain-of-thought prompting scenarios.

- They analyze the models' performance and limitations in solving these financial reasoning problems across different topics, and estimate whether the models could pass the actual CFA exams. 

- GPT-4 outperforms ChatGPT in most cases, but both models still struggle with certain financial topics like financial reporting and quantitative methods. Chain-of-thought prompting provides marginal improvements. 

- Providing a few correct examples (few-shot prompting) helps the most, especially for ChatGPT and on Level I exams. But the models would likely still fail Level II.

- They outline potential strategies to enhance LLMs for financial reasoning, such as using external knowledge bases and critic models.

In summary, the key contribution appears to be a rigorous benchmarking of LLMs on practical financial reasoning exams to assess their capabilities and limitations in this domain, paving the way for developing more effective financial NLP applications.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Based on my review of the paper, the main takeaway in one sentence is: This paper evaluates the capabilities of ChatGPT and GPT-4 in solving complex financial reasoning problems using mock exam questions from the Chartered Financial Analyst (CFA) program across different prompting techniques, finding that while the models struggle with certain aspects like calculations and tables, their overall performance shows promise for applications in finance.


## How does this paper compare to other research in the same field?

 Based on my review, this paper presents an interesting evaluation of two large language models, ChatGPT and GPT-4, on mock CFA exam questions. Here are some key points about how it relates to other research:

- Assessing performance of LLMs on exams/benchmarks is an active area of research. Several recent works have looked at evaluating LLMs like ChatGPT and GPT-4 on exams like the MCAT, Bar Exam, clinical reasoning exams, etc. This paper contributes by analyzing these models on the finance domain using CFA exams.

- Using the CFA exams as a benchmark dataset is a unique aspect. The CFA exams rigorously test practical financial reasoning abilities, making them well-suited for evaluating applicability of LLMs to finance. There are few existing works that assess LLMs on finance-specific datasets. 

- The analysis of different prompting techniques like zero-shot, few-shot, chain of thought is also a key contribution. This provides insights into how different prompting strategies impact reasoning performance on complex finance questions.

- Estimating passing thresholds on CFA exams provides a concrete assessment of whether LLMs could realistically pass these exams currently. This is valuable practical insight beyond just reporting accuracy scores.

- Identifying limitations of LLMs on certain finance topics based on error analysis is useful for guiding future research on how to improve financial reasoning.

Overall, while prior works have analyzed LLMs on exams in other domains, this paper uniquely contributes an in-depth assessment on the finance domain using CFA exams. The analysis provides both theoretical insights and practical implications for applying LLMs to finance. The results highlight current capabilities but also limitations that can inform promising directions for future work.


## What future research directions do the authors suggest?

 Based on my review of the paper, here are some of the future research directions suggested by the authors:

- Developing prompting techniques and training methods to further enhance the financial reasoning abilities of LLMs. They suggest combining few-shot learning and chain-of-thought prompting could be an interesting avenue to provide richer examples and explanations.

- Leveraging external knowledge through retrieval augmented generation, to equip the LLMs with more accurate and comprehensive finance knowledge. This could help address the knowledge gap issues highlighted in the analysis. 

- Incorporating specialized math functions or APIs to help LLMs perform calculations more accurately. The analysis showed calculation errors were a major issue, especially for more complex quantitative problems.

- Using critic models to validate the reasoning of LLMs before finalizing answers, in order to reduce reasoning errors and inconsistencies.

- Expanding the evaluation to cover the Level III CFA exam, which features essay questions. Developing methods for LLMs to generate free-form essay responses could be an impactful area of research.

- Curating larger datasets of finance exam questions across different contexts, to facilitate more rigorous testing and development of LLMs specialized for finance.

- Exploring personalized prompting and few-shot learning approaches to adapt LLMs more effectively to particular users and use cases in finance.

In summary, the authors lay out several interesting directions to continue enhancing LLMs for financial reasoning through techniques like specialized prompting, knowledge integration, reasoning validation, and expanded datasets and evaluations.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper conducts an evaluation of ChatGPT and GPT-4 on mock exam questions from the Level I and Level II Chartered Financial Analyst (CFA) exams. The CFA exam is known for its rigorous assessment of financial expertise, making it well-suited for assessing the capabilities of large language models (LLMs) on complex financial reasoning tasks. The authors tested ChatGPT and GPT-4 on CFA exam questions using zero-shot prompting, chain-of-thought prompting, and few-shot prompting. They found that GPT-4 consistently outperformed ChatGPT across topics and prompting methods. However, certain specialized finance topics like Financial Reporting and Portfolio Management remained challenging for both models. The authors estimate that GPT-4 would have a decent chance at passing the CFA Level I and II exams if provided with few-shot examples, while ChatGPT is unlikely to pass in any setting tested. Overall, the study provides a comprehensive analysis of the strengths and limitations of current LLMs on financial reasoning tasks, and suggests strategies like retrieval augmentation and hybrid prompting to enhance their applicability in finance.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper evaluates the capabilities of two large language models, ChatGPT and GPT-4, in performing financial reasoning using mock exam questions from the Chartered Financial Analyst (CFA) exams. The CFA exams are known for their rigorous assessment of financial knowledge and are composed of three increasing difficulty levels. The authors test ChatGPT and GPT-4 on Level I (180 multiple choice questions) and Level II (item sets with case descriptions and questions) mock exams under zero-shot, few-shot, and chain-of-thought prompting scenarios. 

The results show that GPT-4 outperforms ChatGPT across all settings, but both models struggle more on the more complex Level II exam. The models perform best on topics with less calculations and more familiar concepts like derivatives and ethics. Providing a few correct examples helps the most, while asking the models to show step-by-step reasoning only marginally improves performance. Based on estimated passing thresholds, the authors conclude that only GPT-4 would have a chance at passing the exams, specifically Level I. The analysis provides insights into the limitations of current LLMs on financial reasoning, and proposes strategies like utilizing external knowledge and offloading calculations to enhance their capabilities. Overall, the rigorous evaluation methodology paves the way for developing LLMs specialized in finance.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper conducts an evaluation of ChatGPT and GPT-4 on mock exam questions from the Chartered Financial Analyst (CFA) Program levels I and II. The CFA exam questions span ten finance topics and are known for their rigorous assessment of financial reasoning abilities. The authors test ChatGPT and GPT-4 on the exam questions using zero-shot prompting, few-shot prompting with 2, 4, 6, and 10 examples, and chain-of-thought prompting where the models explain their reasoning step-by-step. The models' predictions are compared against the established solutions for the mock exams to measure their accuracy across topics for each prompting technique. The analysis focuses on the performance limitations of the models on the CFA exams and their likelihood of passing the actual tests. The work provides insights into strategies for improving large language models for complex financial reasoning tasks.
