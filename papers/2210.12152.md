# WikiWhy: Answering and Explaining Cause-and-Effect Questions

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we create a question answering dataset to better assess the reasoning capabilities of large language models? The key points are:- Existing QA datasets are limited in their ability to measure reasoning skills, as they focus on retrieving factoids or conducting multi-hop fact chaining. - The authors propose that "why" questions requiring explanations can better probe for reasoning skills.- They introduce WikiWhy, a new QA dataset containing "why" questions along with answers and multi-sentence rationales explaining the answers. - The aim is to use WikiWhy to analyze whether LLMs can generate satisfactory explanations demonstrating reasoning skills and commonsense knowledge, rather than just memorization.So in summary, the central research question is how to design a QA dataset, using "why" questions and explanations, that can better measure the reasoning capabilities of large language models. The hypothesis is that models will struggle to produce complete and logically valid explanations for WikiWhy compared to just retrieving answers, indicating deficiencies in reasoning skills.


## What is the main contribution of this paper?

The main contribution of this paper is introducing WikiWhy, a new question answering dataset for testing reasoning capabilities of large language models. Specifically:- WikiWhy contains over 9,000 "why" question-answer-rationale triples grounded in Wikipedia facts across diverse topics. - Each rationale is a set of supporting statements explaining why the answer is true, aiming to require models to demonstrate understanding rather than just memorization. - Experiments show state-of-the-art generative models like GPT-3 struggle to produce satisfying explanations, with only 38.7% correctness based on human evaluation. - The paper proposes new automatic metrics for evaluating free-form explanation generation, and shows these correlate with human judgments of explanation quality.In summary, the key contribution is the creation of WikiWhy as a new benchmark for probing and improving reasoning skills of large language models, which requires generating explicit explanations justifying answers using common sense knowledge. Baseline results leave significant room for future improvement on this challenging task.
