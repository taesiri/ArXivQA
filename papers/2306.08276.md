# [TryOnDiffusion: A Tale of Two UNets](https://arxiv.org/abs/2306.08276)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we generate high-resolution photorealistic virtual try-on results that preserve garment details and warp/deform the garment naturally for significant changes in body pose and shape between the person and the garment image?The key hypothesis is that a diffusion model architecture with two communicating UNet streams (dubbed Parallel-UNet) can effectively achieve garment warping and person blending in a single network, leading to better preservation of garment details compared to prior work. Specifically, the two key ideas this Parallel-UNet architecture explores are:1) Implicit garment warping via cross-attention between the garment and person streams, rather than relying on explicit flow estimation or thin-plate splines. 2) Combining garment warping and person blending in a single network pass rather than as separate sequential steps.The aim is to generate photorealistic 1024x1024 try-on results that can handle differences in body pose and shape while keeping intricate garment details intact, which has been a major limitation of previous virtual try-on methods.


## What is the main contribution of this paper?

The main contributions of this paper are:1. They propose a new method called TryOnDiffusion for virtual try-on that can handle large occlusions, pose changes, and body shape changes, while preserving garment details at high 1024x1024 resolution. 2. They introduce a novel architecture called Parallel-UNet, which can warp the garment implicitly using cross attention and combines garment warping and person-garment blending in one network pass.3. They achieve state-of-the-art performance both qualitatively and quantitatively. Their results were chosen as best 92.72% of the time compared to other recent methods in a user study.4. They generate photorealistic virtual try-on results at 1024x1024 resolution that accommodate significant body pose and shape modification, while preserving garment details like patterns, text, and labels.In summary, the key innovation is the Parallel-UNet architecture that allows implicit garment warping via cross attention and unifies garment warp and person blend in one network. This addresses limitations of prior methods that either fail to preserve details or cause artifacts when warping garments to fit new body shapes and poses.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new diffusion model architecture called Parallel-UNet for virtual try-on that can warp garments to fit diverse body poses and shapes while preserving garment details, through the use of cross-attention between two sub-networks to perform implicit warping and joint warping-blending in a unified process.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other research in virtual try-on:- The paper focuses on synthesizing high-resolution (1024x1024) try-on results with complex body poses and shapes while preserving fine garment details. Many previous methods struggle with these challenging cases. - The proposed method TryOnDiffusion is based on diffusion models, which have become state-of-the-art for image generation. Diffusion models have not been extensively explored for virtual try-on before.- A novel neural architecture called Parallel-UNet is introduced. It allows implicit garment warping via cross attention and combines warping and image blending in one network. This is different from most works that perform explicit warping followed by a separate image blending step.- The paper demonstrates superior performance both quantitatively (lower FID/KID) and qualitatively compared to recent state-of-the-art methods like TryOnGAN, SDAFN, HR-VITON. An extensive user study with over 2000 samples also prefers their results over others.- The training data is based on 4 million image pairs of the same person in different poses. This is much larger than datasets used in other works, which allows modeling more variation.- Limitations are that the method focuses on upper body clothing and relies on separate pose/segmentation estimation steps. The clothing-agnostic representation may also lose some identity information.Overall, this paper pushes the state-of-the-art in virtual try-on, especially for challenging cases with large pose/shape differences and garment details preservation. The proposed model architecture and training data are key factors behind the improved performance.


## What future research directions do the authors suggest?

Based on my reading of the paper, some future research directions suggested by the authors include:- Exploring the applicability of the proposed Parallel-UNet architecture for general image editing tasks beyond just virtual try-on. The authors believe this architecture could be useful for other image-to-image translation problems that involve complex spatial transformations.- Extending the approach to video try-on by adapting the architecture to model temporal consistency across frames. The authors suggest the Parallel-UNet concept could potentially be extended to video.- Improving the representation of personal identity in the clothing-agnostic RGB image. Currently this representation only preserves partial identity information like face and hands. The authors note limitations in representing aspects like tattoos, muscle structure, and accessories. - Testing the method on more complex backgrounds beyond the relatively simple/clean backgrounds used in training and testing. It is unknown how the method generalizes to cluttered backgrounds.- Experimenting with full body try-on rather than just upper body clothing. The current work focuses on tops but the approach could be adapted to full body in future work.- Continuing to scale up the training data size to improve results. The experiments show benefit from increasing dataset size from 10K to 100K to 4M pairs.In summary, the main future directions are around extending the approach to new tasks/domains, improving identity representation, and scaling up the data and training. The Parallel-UNet architecture seems promising for other image editing tasks.
