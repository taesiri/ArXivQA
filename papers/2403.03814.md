# [Evaluating the Elementary Multilingual Capabilities of Large Language   Models with MultiQ](https://arxiv.org/abs/2403.03814)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Large language models (LLMs) today are primarily intended for use in English or a small set of high-resource languages, posing a barrier to equal access. 
- However, recent research shows people still prompt LLMs in many languages beyond their intended use. 
- This motivates the need to study the basic multilingual capabilities of current chat-optimized open LLMs.

Proposed Solution 
- The authors introduce MultiQ, a new silver standard benchmark for open-ended question answering across 137 typologically diverse languages, created by translating 200 English questions.
- Using MultiQ, they evaluate the language fidelity (ability to respond in prompted language) and question answering accuracy of 6 popular open LLMs. 
- They also explore the relationship between language fidelity and accuracy, and differences in tokenization strategies as a potential explanatory factor.

Main Contributions
- MultiQ benchmark with 27,400 question prompts in 137 languages for testing basic multilingual QA capabilities 
- Analysis of language fidelity and QA accuracy for 6 open LLMs, revealing:
   - Significant capabilities beyond intended language use
   - Positive link between fidelity and accuracy
   - Large variations across models and languages
- Identification of tokenization as a potential driver of differences in multilinguality

In summary, the paper introduces a new broad multilingual benchmark to test the basic capabilities of today's chat models beyond their intended language scope, revealing interesting yet complex multilingual behaviors that warrant future investigation. Key factors likely include model scale, tokenization strategies, as well as tailoring models to be explicitly multilingual.
