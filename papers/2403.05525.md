# [DeepSeek-VL: Towards Real-World Vision-Language Understanding](https://arxiv.org/abs/2403.05525)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
There is a significant performance gap between most open-source large multimodal models (LMMs) and proprietary models in terms of real-world performance and user experience. The key issues are: (1) Over-reliance on instruction tuning rather than extensive pretraining; (2) Instruction tuning datasets are not representative of real usage scenarios; (3) Vision encoders operate on low resolution inputs which limits detailed understanding; (4) There is often degradation of language skills after prolonged multimodal training.

Proposed Solution:
The paper presents DeepSeek-VL, an open-source LMM aimed at adept real-world performance. The key aspects are:

(1) Diverse and large-scale pretraining data encompassing web screenshots, PDFs, OCR, charts, textbooks etc. to represent real-world scenarios.

(2) Instruction tuning dataset based on a manually-curated taxonomy of real user test cases for better alignment with practical applications.  

(3) Hybrid vision encoder combining semantic features from a text-aligned encoder and detailed features from a high-resolution encoder for efficient 1024x1024 image encoding.

(4) Joint language-multimodal training strategy to preserve language skills. Gradual adjustment of modality ratios and a "warm-up" approach manages competitive dynamics between vision and language.

Main Contributions:

- A systematic methodology for multimodal model development targeting real-world performance through data curation, model architecture and training strategy. 

- The DeepSeek-VL model family, available in 1.3B and 7B parameter sizes, which demonstrates state-of-the-art or competitive performance on vision-language tasks while maintaining language performance.

- Superior real-world experience as a chatbot across diverse tasks like diagrams, web pages, math, literature etc. as evidenced by human evaluation.

- Public release of models to promote further research and innovation in multimodal AI.
