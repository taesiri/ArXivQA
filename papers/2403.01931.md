# [VariErr NLI: Separating Annotation Error from Human Label Variation](https://arxiv.org/abs/2403.01931)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Annotation errors and human label variation (HLV) are both prevalent issues in NLP datasets. However, prior work has studied them separately, without teasing apart errors from plausible HLV. 
- It is an open challenge to define errors in an ecologically valid way. It is also unknown whether existing automatic error detection (AED) methods can help uncover such errors or if new methods are needed.

Proposed Solution:  
- Introduce a new NLI dataset called VariErr with a 2-round annotation methodology to elicit ecologically valid explanations paired with validity judgments to identify errors.  
- 500 NLI items are annotated by 4 annotators with NLI labels and explanations in Round 1. Round 2 involves validity judgments on all label-explanation pairs to identify errors.
- Leverage differences between self-judgments versus peer-judgments to define errors versus HLV. 

Main Contributions:
- A new multi-annotator dataset VariErr containing both plausible HLV and detected errors for studying AED, released for research.
- A systematic annotation methodology using ecological valid explanations and validity judgments to tease apart errors from HLV.  
- Benchmarking experiments with AED methods, large language models (LLMs) and human heuristics for error detection on VariErr. Findings indicate traditional AED methods underperform substantially compared to GPT-4 and humans.

The methodology is applicable beyond NLI and lays groundwork to yield better, more trustworthy NLP with both high-quality data and accounting for HLV where it exists.
