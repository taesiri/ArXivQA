# [Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement   Learning with General Function Approximation](https://arxiv.org/abs/2312.04464)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes a new reinforcement learning algorithm, termed UCRL-WVTR, for model-based reinforcement learning with general function approximation. The key contributions are: (1) It achieves the first horizon-free and instance-dependent regret bound for this setting, eliminating the polynomial dependency on the planning horizon. (2) The regret bound matches the minimax lower bound for linear mixture MDPs up to logarithmic factors, showing its sharpness. (3) The algorithm is computationally efficient given access to a regression oracle. These results are enabled by novel algorithm designs of weighted value-targeted regression and a high-order moment estimator, as well as new analyses including a concentration inequality for weighted non-linear regression and refined analyses that connect the regret to instance-dependent quantities. Comprehensive experiments validate the proposed method and corroborate the theoretical findings. Overall, this work significantly advances the state-of-the-art in reinforcement learning theory and algorithms by tackling a long-standing open problem of achieving efficient, horizon-free and instance-dependent learning for general function approximation.
