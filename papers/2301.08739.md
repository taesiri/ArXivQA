# [FlatFormer: Flattened Window Attention for Efficient Point Cloud   Transformer](https://arxiv.org/abs/2301.08739)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be:How can we design an efficient point cloud transformer that achieves comparable or better accuracy than sparse convolutional models, while being faster in inference speed?The key hypotheses seem to be:- The inefficiency of prior point cloud transformers is largely due to irregular computations caused by the inherent sparsity and non-uniformity of point clouds.- By partitioning the point cloud into groups of equal sizes rather than windows of equal shapes, and applying self-attention within each group, we can improve computational regularity and avoid expensive padding and partitioning overheads.- With proper algorithmic and systems-level optimizations, it is possible to design a point cloud transformer that is faster than sparse convolutional methods while achieving state-of-the-art accuracy.The paper introduces FlatFormer to validate these hypotheses. By trading off some spatial proximity for better computational regularity, FlatFormer is able to achieve 1.4-4.6x speedup over prior methods with comparable or higher accuracy on the Waymo Open Dataset. This demonstrates the potential of point cloud transformers to be faster and more accurate than sparse convolutional models.In summary, the key research question is how to design an efficient yet accurate point cloud transformer, which the authors address through algorithmic and systems-level optimizations in FlatFormer. The results validate their hypotheses about improving computational efficiency while maintaining accuracy.


## What is the main contribution of this paper?

The main contribution of this paper is proposing FlatFormer, an efficient point cloud transformer for 3D object detection. Specifically:- It proposes Flattened Window Attention (FWA) which partitions the point cloud into groups of equal sizes rather than windows of equal shapes. This trades off spatial proximity for improved computational regularity and avoids expensive partitioning and padding overheads. - FWA applies self-attention within each group to extract local features. It alternates the sorting axis and shifts windows to enable communication across groups.- The paper provides optimizations like fused kernels and dropping residuals to further improve efficiency. - Experiments show FlatFormer achieves state-of-the-art accuracy on Waymo Open Dataset with up to 4.6x speedup over previous point cloud transformers like SST. It is also 1.4x faster than sparse convolution methods like CenterPoint with better accuracy.- FlatFormer is the first point cloud transformer to achieve real-time inference on edge GPUs. This enables transformer-based perception on autonomous vehicles.In summary, the key contribution is designing an efficient point cloud transformer using techniques like equal-size grouping, fused kernels, and alternating axis sorting. This matches or exceeds the efficiency of sparse convolution methods for the first time.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points in the paper:The paper introduces FlatFormer, a point cloud transformer that partitions the input into groups of equal sizes rather than windows of equal shapes, enabling faster and more efficient computation while achieving state-of-the-art accuracy on 3D object detection benchmarks.
