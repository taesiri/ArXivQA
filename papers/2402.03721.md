# [Enhancing Embodied Object Detection through Language-Image Pre-training   and Implicit Object Memory](https://arxiv.org/abs/2402.03721)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Image object detectors trained on internet data do not perform optimally under the embodied conditions experienced by robots, where long streams of spatially and temporally correlated data are collected.
- Existing work in embodied active learning uses such sub-optimal detectors and fails to leverage models trained with language-image data. 
- Methods in video object detection using external memories to aggregate information across time are not designed for the greater viewpoint shift and objects per image in robotics.
- Semantic mapping approaches build spatial representations but do not use them to improve image detectors or leverage language-image training.

Proposed Solution:
- Use an object detector pre-trained on language-image data as the base model, making it more robust to domain shift.
- Propose a novel implicit object memory that uses projective geometry to aggregate confident detections across long temporal horizons and wide viewpoint changes. 
- Read from this memory to enhance the image features of the base detector with implicit spatial-temporal information.

Contributions:
- A method to enhance language-image detectors for embodied conditions using external memory.
- An implicit memory based on projective geometry that captures long-term object dependencies.  
- Evaluation showing the approach outperforms other external memories designed for video object detection and semantic mapping when tested on embodied indoor streams.
- Demonstration that the detector is robust to noise and improves performance on a real robot deployment.
- Significant gains relative to methods that do not first leverage language-image pre-training.
