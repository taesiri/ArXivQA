# [Context-Aware Planning and Environment-Aware Memory for Instruction   Following Embodied Agents](https://arxiv.org/abs/2308.07241)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the key research question seems to be: 

How can embodied AI agents effectively plan and complete long-horizon interactive tasks in complex 3D environments, particularly in novel/unseen environments?

More specifically, the paper proposes two key components to address this:

1) Context-aware planning (CAP): This incorporates semantic context (relevant objects to interact with) when generating a sequence of sub-goals for a task. The goal is to help the agent focus on task-relevant objects during planning.

2) Environment-aware memory (EAM): This stores information about changes in object states and appearances to help the agent track interactions and changed environments. The goal is to enable better object interaction over time.

Together, CAP and EAM aim to improve an agent's ability to navigate environments and manipulate objects to successfully complete multi-step interactive tasks, even in novel environments they haven't seen before. The central hypothesis seems to be that incorporating context when planning and remembering environment changes will lead to better generalization and task completion.

The experiments then validate this hypothesis by testing CAP and EAM on a challenging interactive instruction following benchmark and showing state-of-the-art performance, especially on unseen environments.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution seems to be proposing a new approach called Context-Aware Planning (CAP) and Environment-Aware Memory (EAM) for interactive instruction following by embodied AI agents. 

Specifically, the key ideas presented are:

- Context-Aware Planning (CAP): This divides the planning process into two stages - predicting task-relevant "context" objects from instructions first, and then planning detailed action sequences using those context objects. The goal is to help the agent focus on task-relevant objects during planning.

- Environment-Aware Memory (EAM): This stores information about changes in object states and masks in a spatial memory to help the agent track object interactions over time. This aims to improve navigation and interaction when object appearances change.

The authors evaluate their method on the ALFRED benchmark and show state-of-the-art performance, especially on unseen environments. They argue CAP and EAM help the agent better plan sequences focused on task-relevant objects and track object states over time, leading to better generalization.

In summary, the core ideas are using context prediction and environment memory to improve planning, navigation and interaction for instruction following agents. The main contribution seems to be proposing and evaluating these ideas to advance progress on this challenging embodied AI task.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this paper compares to other research in the field of embodied AI agents:

- The paper focuses on improving long-horizon task completion for interactive instruction following. This is an important area of research in embodied AI as being able to follow complex natural language instructions over many steps is challenging but crucial for real-world assistant robots. 

- The key ideas proposed are context-aware planning using predicted task-relevant objects and environment-aware memory to track object states. These seem novel compared to prior work like FILM, Prompter, MAT, etc. that relied more on templates or reactive policies. Utilizing context and memory seems more flexible and generalizable.

- The proposed Context-Aware Planning module is related to some prior works on hierarchical planning but differs in explicitly predicting task-relevant objects first before generating the sub-goal sequence. This helps the model focus on task-relevant entities.

- The Environment-Aware Memory module is unique in tracking object states, locations, and masks over time. This allows interacting with objects properly as their states change. I haven't seen explicit memory proposed this way in other embodied AI papers.

- For evaluation, they use the challenging ALFRED benchmark which is becoming a standard testbed. The gains over prior published methods are significant (+10.7% unseen SR), showing the impact of their ideas. The ideas seem general too, not tied to a particular dataset.

- The approach seems like a nice blend of structured knowledge and learning-based components. The hierarchical planning and memory modules incorporate more structure while the perception, prediction, and control parts use deep networks trained on data. This balance is promising.

Overall, the proposed context-aware planning and environment-aware memory seem like novel and impactful ideas for embodied agents. The paper demonstrates substantial gains over prior art on a complex benchmark. The ideas could be useful for other interactive agents beyond just instruction following as well.
