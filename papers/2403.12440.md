# [Self-learning Canonical Space for Multi-view 3D Human Pose Estimation](https://arxiv.org/abs/2403.12440)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Multi-view images contain useful information like camera poses, 2D/3D poses, and 3D geometry for 3D human pose estimation. However, annotating this information is labor-intensive and the information is heterogeneous, making it challenging to effectively exploit them.

Proposed Solution:
This paper proposes a fully self-supervised framework called Cascaded Multi-view Aggregating Network (CMANet) to construct a canonical parameter space to holistically integrate and exploit the heterogeneous multi-view information. 

CMANet consists of two modules:
1) Intra-View Module (IRV): Estimates per-view camera pose and 3D pose from each image view independently.
2) Inter-View Module (IEV): Refines the camera poses and optimizes a unified 3D pose by aggregating features and enforcing consistency across views.

A canonical parameter space is proposed to represent the heterogeneous information, including per-view camera poses, global orientations, and a unified human shape and pose parameters from SMPL model.

A two-stage learning procedure is used:
1) IRV is first trained with reprojection and SMPL losses from confident 2D poses. 
2) IRV is frozen and IEV is trained with reprojection and SMPL losses from all views to implicitly exploit inter-view information.

Main Contributions:
1) A self-supervised cascaded framework and canonical space to effectively integrate multi-view information for 3D human pose estimation.

2) An intra-view and inter-view module design to separately model view-dependent and view-independent information.

3) A two-stage learning strategy to better optimize the framework by first focusing on intra-view modeling before inter-view aggregation.

The framework, modules and learning strategy are shown through experiments to achieve state-of-the-art performance among self-supervised methods on Human3.6M, MPI-INF-3DHP and TotalCapture datasets.
