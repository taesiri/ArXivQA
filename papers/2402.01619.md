# [KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce   Programs over Low-resourced Knowledge Bases](https://arxiv.org/abs/2402.01619)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Program induction (PI) methods rely on large annotated question-program pairs to train language models (LMs) to be aware of each knowledge base's (KB's) schema. This is challenging for low-resourced KBs lacking such annotations.  
- Directly feeding schema info to LMs is infeasible due to limited context windows. Prior PI transfer methods perform poorly without fine-tuning on the target KBs.

Proposed Solution - KB-Plugin:
- Learns two pluggable modules to inject skills and KB schema into LMs:
   - Schema plugin: Encodes details of a KB's schema via self-supervised triple completion task.
   - PI plugin: Trained on annotated data from a rich KB to extract schema info from any schema plugin to induce programs.
- Transfers PI plugin to low-resourced KBs by simply plugging their schema plugin, without any fine-tuning.

Main Contributions:
- Proposes KB-Plugin, a novel plug-and-play framework to enable LMs to induce programs over any low-resourced KB.
- Empirically validates KB-Plugin's effectiveness through experiments on 5 heterogeneous KBQA datasets.
- Shows comparable performance to state-of-the-art PI methods for low-resourced KBs using 25x smaller LM backbone.
- Demonstrates advantages over prior PI transfer methods without needing fine-tuning on target KBs.

In summary, KB-Plugin enables easy PI for low-resourced KBs via transfer learning, using a schema plugin to inject KB details and a PI plugin to acquire schema-aware program induction skills. Experiments prove its efficacy over prior SoTA low-resource PI techniques.
