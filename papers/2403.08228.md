# [Empowering Robotics with Large Language Models: osmAG Map Comprehension   with LLMs](https://arxiv.org/abs/2403.08228)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like ChatGPT have shown promise for enhancing robots' intelligence by providing general knowledge to handle unpredictable situations. 
- However, effectively applying LLMs in robotics requires finding suitable map representations that are understandable to LLMs, compatible with traditional robotic algorithms, and readable by humans. 

Proposed Solution:  
- The paper proposes using a textual map format called osmAG which stores topological and hierarchical information about environments using polygons and tags. 
- osmAG is naturally compatible with LLMs as it is text-based, compact enough to not exceed LLMs' token limits, interpretable by conventional path planning algorithms, and can be easily visualized.

Key Contributions:
- Identified osmAG, an XML-based semantic map, as an effective common representation for integrating LLMs into mobile robot systems
- Created variants and prompt engineering strategies to allow better comprehension of osmAG topology by LLMs 
- Developed datasets and fine-tuning methods using Low Rank Adaptation to significantly enhance LLaMA models' understanding of osmAG (90%+ success rate)
- Showed how fine-tuned LLaMA models can surpass ChatGPT-3.5 in map-related reasoning tasks 
- Demonstrated ChatGPT-4's ability to plan valid paths on a real osmAG map and adapt routing based on external textual information

In summary, the key insight is that using a compact textual map format like osmAG allows harnessing the general knowledge of LLMs for robotic path planning while retaining compatibility with conventional algorithms. The results show fined-tuned LLMs can effectively understand topology and hierarchy within osmAG maps.
