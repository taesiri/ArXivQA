# [STDiff: Spatio-temporal Diffusion for Continuous Stochastic Video   Prediction](https://arxiv.org/abs/2312.06486)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel video prediction model called STDiff that combines a spatio-temporal diffusion process to generate diverse and plausible future video frames. Specifically, STDiff first extracts motion features from past frame differences using a Conv-GRU. Then a neural stochastic differential equation (SDE) predicts future motion features over continuous time steps. Finally, an image diffusion model generates each future frame by conditioning on the predicted motion feature and previous frame in an autoregressive manner. By modeling both spatial and temporal dynamics with SDEs, STDiff achieves state-of-the-art performance on multiple datasets in terms of Fr√©chet Video Distance and Learned Perceptual Image Patch Similarity. Compared to prior stochastic models, STDiff also demonstrates significantly improved diversity and efficiency in generating multiple possible futures, as measured by a new metric called inter-LPIPS. Additionally, STDiff is among the first diffusion models capable of arbitrary frame rate prediction without ground truth supervision. The combination of continuous temporal modeling and explicit learning of spatial and temporal uncertainty enables STDiff to synthesize more realistic, diverse and temporally coherent future video frames.
