# [CommVQA: Situating Visual Question Answering in Communicative Contexts](https://arxiv.org/abs/2402.15002)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Current VQA models are trained and evaluated on image-question pairs in isolation, without considering the context in which images appear and the goals/prior knowledge of question askers. This is unlike real-world settings where questions depend on context and informational needs.

- Existing VQA datasets also lack naturalistic context and mainly focus on image-text alignment as a decontextualized task. 

Proposed Solution:

- The authors introduce a new VQA dataset called CommVQA which provides contextual information like:
   - Descriptions of images
   - Plausible real-world scenarios where images might appear (e.g. shopping website, social media)
   - Follow-up questions conditioned on scenarios and descriptions
   - Answers to questions based on scenarios and descriptions

- The dataset contains 300 image-scenario pairs with 3,642 unique question-answer pairs.

- Questions and answers were elicited from crowdworkers situating them in specific scenarios, unlike existing datasets where questions are asked in isolation.

Key Contributions:

- Introduce CommunicVQA, the first VQA dataset situating images in natural contexts and considering goals/needs of question askers.

- Analysis shows questions and answers in CommunicVQA fundamentally vary across contexts, posing challenges for current VQA models.  

- Providing context to models improves performance, highlighting relevance of situating VQA in communicative settings.

- Dataset allows analytical insights into model behaviors due to controlled data collection process.

Overall the paper makes the case for reframing VQA as a context-dependent communicative task rather than a context-independent image-text alignment task. The introduced dataset and analyses shed light on how contextual factors affect VQA.
