# [GridMM: Grid Memory Map for Vision-and-Language Navigation](https://arxiv.org/abs/2307.12907)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is how to effectively represent the navigation history and environment for vision-and-language navigation (VLN). The key hypothesis is that explicitly structuring the visited environment into a top-down egocentric grid map with fine-grained visual features can improve an agent's understanding of instructions, visual surroundings, and navigation history for VLN.Specifically, the paper proposes representing the environment using a dynamically growing Grid Memory Map (GridMM) to capture detailed visual information and spatial relationships. It hypothesizes that this structured grid map representation can:1) Provide global space-time relations of the visited environment by projecting visual features into a top-down map. 2) Capture fine-grained visual clues relevant to instructions via an instruction relevance aggregation method.The paper aims to demonstrate that this GridMM representation can enhance navigation performance compared to prior approaches like recurrent memory states, topological maps, and semantic maps. The effectiveness of GridMM is evaluated extensively on VLN benchmarks in both discrete environments like R2R and REVERIE, and continuous environments like R2R-CE.In summary, the central hypothesis is that the proposed Grid Memory Map can better represent spatial, visual and temporal information to improve an agent's understanding and grounding of instructions for VLN tasks. The experiments aim to demonstrate the benefits of this representation.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes Grid Memory Map (GridMM), a visual representation structure for modeling global historical observations during navigation. GridMM divides the visited environment into grid regions and projects visual features extracted from observations into these regions based on their coordinates. 2. It introduces an instruction relevance aggregation method to capture fine-grained visual clues in each grid region that are most relevant to the navigation instruction. This allows focusing on the most useful visual information.3. It conducts extensive experiments on VLN datasets in both discrete environments (REVERIE, R2R, SOON) and continuous environments (R2R-CE). The results demonstrate the effectiveness of GridMM and show that it outperforms previous state-of-the-art methods on most metrics.4. It provides comprehensive analyses and ablation studies on different types of maps for VLN, including topological maps, semantic maps, and the proposed grid memory map. The analyses give insights into representing the visited environment and reveal advantages of GridMM.In summary, the key contribution is proposing the Grid Memory Map to structure the global spatial-temporal relations of the environment during navigation and using instruction relevance to capture fine-grained visual clues. This approach is shown to achieve new state-of-the-art results on major VLN benchmarks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on my understanding, the main contribution of this paper is proposing a grid memory map to represent the global spatial-temporal relations of the visited environment for vision-and-language navigation. The grid map divides the environment into grid regions and leverages an instruction relevance aggregation method to obtain fine-grained visual features in each region. Experiments show that modeling the environment with such a grid map improves navigation performance compared to using other types of maps.In one sentence, I would summarize it as: The paper proposes a grid memory map to represent fine-grained spatial-temporal visual features of the environment for improved vision-and-language navigation.
