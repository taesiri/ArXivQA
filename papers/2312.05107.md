# [DreaMoving: A Human Dance Video Generation Framework based on Diffusion   Models](https://arxiv.org/abs/2312.05107)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper presents DreaMoving, a new diffusion-based framework for generating high-quality, controllable dance videos of humans. The key innovation is the ability to take as input a target identity via an image prompt and a sequence of body poses, and output a realistic video of that person dancing according to the provided poses. DreaMoving utilizes two main components: a Video ControlNet module that controls the motion based on the input poses, and a Content Guider module that preserves the identity and appearance details from the image prompt. Through modifications to diffusion models like adding motion blocks, the system can generate videos with improved temporal consistency. DreaMoving is shown to work with varying input modalities, from text prompts alone to text + face images to text + face + clothing images, allowing control over both motion and personalied appearance. Experiments demonstrate photorealistic dance videos with maintenance of spatio-temporal coherence as well as fidelity to provided identity/style guidance. The approach represents important progress in conditional, human-centric video generation.
