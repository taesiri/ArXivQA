# [Aligning Large Language Models with Human: A Survey](https://arxiv.org/abs/2307.12966)

## What is the central research question or hypothesis that this paper addresses?

After carefully reading the paper, the central research question is how to effectively and efficiently align large language models (LLMs) with human expectations and values. Specifically, the authors survey methods for:1) Collecting high-quality instruction data for training and aligning LLMs to follow human preferences, including leveraging existing benchmarks, human annotations, and strong LLMs like ChatGPT to generate instructions. 2) Training techniques like supervised fine-tuning, online/offline reinforcement learning, and parameter efficient methods to incorporate human preferences into LLMs in a stable and efficient manner.3) Evaluating the alignment of LLMs using specialized benchmarks and paradigms like human evaluations, reference-free LLMs evaluation, and evaluation-specific LLMs. The overarching goal is to provide a comprehensive overview of techniques for collecting alignment data, training aligned LLMs, and evaluating their capabilities so as to equip researchers with the knowledge to advance the alignment of large models like ChatGPT with human values and preferences. The survey synthesizes a broad swath of recent research to highlight promising future directions in this rapidly evolving field.


## What is the main contribution of this paper?

Based on my reading, the main contribution of this paper is proposing an efficient solution to adapt the English-oriented Large Language Model (LLM) LLaMA to better understand Chinese inputs. Specifically, the authors first analyze that the original LLaMA has limited Chinese vocabulary (less than 1k characters) and thus relies on inefficient byte-fallback strategy to tokenize Chinese text, resulting in long input sequences. To address this issue, they propose a two-stage Chinese pre-training approach:1) In the first stage, they expand the LLaMA vocabulary with 20k additional Chinese words/phrases and fine-tune the input embeddings while keeping other parameters frozen. This allows LLaMA to form better input representations for Chinese.2) In the second stage, they add LoRA parameters to all layers in LLaMA and jointly fine-tune the input embeddings, self-attention heads, and LoRA parameters. LoRA enables efficient adaptation of the entire LLaMA model using limited additional parameters.Through experiments on Chinese tasks like pCLUE and C-Eval, they demonstrate that their proposed approach allows LLaMA to achieve significantly better efficiency and performance on understanding Chinese text with limited additional pre-training.In summary, the key contribution is using vocabulary expansion and a two-stage LoRA-based fine-tuning process to efficiently adapt the English LLaMA model into a Chinese-friendly version while preserving its original capabilities. This makes LLaMA more accessible to Chinese users without extensive re-training.
