# [Dense X Retrieval: What Retrieval Granularity Should We Use?](https://arxiv.org/abs/2312.06648)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper investigates using different granularities of text units - passages, sentences, and propositions - as retrieval units when indexing a corpus like Wikipedia for dense retrieval. The authors introduce the concept of a "proposition", defined as an atomic expression within text that encapsulates a distinct factoid and is presented in a concise, self-contained natural language format. They process an English Wikipedia dump into these three levels of granularity to create a dataset called FactoidWiki. Through experiments on multiple open-domain QA datasets, they find that retrieving by propositions, compared to passages or sentences, improves the performance of various dense retrievers. Specifically, proposition retrieval enhances generalization, with larger gains on queries about less common entities. It also improves downstream QA when using a retriever-reader pipeline with limited input length, owing to the higher density of question-relevant information. The gains highlight propositions as an effective retrieval unit, being compact yet also sufficiently contextualized. The authors propose proposition-level indexing of corpora as a simple but impactful strategy to boost dense retrievers at inference time.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes using propositions (self-contained facts) as a retrieval unit when indexing Wikipedia for dense retrieval, showing empirically that proposition-based retrieval outperforms passage or sentence retrieval in terms of generalization for passage retrieval and accuracy for downstream open-domain question answering given the same input token limit.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing the use of propositions as retrieval units when indexing a retrieval corpus to improve the dense retrieval performance. 

2. Introducing FactoidWiki, a processed English Wikipedia dump, where each page is segmented into multiple granularities: 100-word passages, sentences and propositions. 

3. Discovering that retrieval by proposition outperforms passage or sentence retrieval in terms of generalization for passage retrieval and accuracy for downstream question-answering given the same input token limit.

So in summary, the key contribution is showing that using propositions - defined as atomic expressions within text that encapsulate distinct factoids - as the retrieval unit can improve performance for dense retrieval and downstream QA tasks compared to typical passage or sentence level retrieval. The paper demonstrates this through introducing FactoidWiki and experiments on retrieval and QA using this corpus indexed at different granularities.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts include:

- Dense retrieval - Using dense vector representations and similarity search for information retrieval, as opposed to sparse representations.

- Retrieval units - The granularity at which the corpus is segmented and indexed, such as documents, passages, sentences, or propositions. 

- Propositions - Defined in the paper as atomic expressions within text, encapsulating distinct factoids and presented in a concise, self-contained format. Proposed as a novel retrieval unit.

- FactoidWiki - The Wikipedia corpus processed at multiple granularities (passage, sentence, proposition) introduced in the paper.

- Retrieval performance - Evaluation metrics like Recall@k used to assess retrieval accuracy. Proposition retrieval is shown to outperform passage and sentence retrieval. 

- Downstream QA performance - Evaluation of how retrieval impacts overall question answering accuracy. Proposition retrieval boosts performance within constrained input lengths.

- Information density - Propositions provide higher density of query-relevant information compared to passages or sentences.

- Generalization - Proposition retrieval especially improves cross-task generalization to unseen datasets compared to passage retrieval.

The key ideas focus on using propositions as a retrieval unit to enhance both retrieval and downstream task performance. The introduced FactoidWiki resource and empirical comparisons are also important contributions.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. What motivated the authors to propose using propositions as a retrieval unit instead of passages or sentences? What advantages did they hypothesize propositions would have over other units?

2. How did the authors define a "proposition" in the context of this work? What were the key principles they used? 

3. Can you explain in detail the process the authors used to segment Wikipedia articles into propositions? What model did they train and how?

4. What specifically does the FactoidWiki dataset introduced in this paper contain? How is it structured compared to a typical Wikipedia dump?

5. What evaluation metrics did the authors use to compare passage, sentence, and proposition-based retrieval? Why did they choose those specific metrics?

6. What trends did the authors observe when analyzing retrieval performance on less common entities in the EntityQuestions dataset? How does this provide insight into the benefits of proposition retrieval?

7. Can you analyze the error cases provided for passage, sentence, and proposition retrieval? What inherent limitations exist for each retrieval granularity?  

8. How exactly did the authors measure "information density" in the retrieved context? Explain their analysis showing propositions provide higher density.

9. What architectural constraints on recent reader models motivate having higher information density in the retrieved context? How do propositions help address this?

10. What limitations exist in the current study on using propositions for retrieval? What future directions could be explored to address these?


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Dense retrievers are commonly used to access external knowledge for open-domain NLP tasks. An important design choice for using a dense retriever is determining the retrieval unit (e.g. document, passage, sentence) to segment and index the corpus. 
- Typical choices like passages can contain extraneous details that distract the retriever. Sentences may lack needed context. An optimal retrieval unit should provide precise and contextualized information.

Proposed Solution:  
- The paper proposes using "propositions" as the retrieval unit. Propositions are defined as atomic expressions within text, encapsulating distinct factoids in a concise, self-contained natural language format.
- The paper introduces FactoidWiki, a processed Wikipedia corpus with each page segmented into passages, sentences and propositions.

Main Results:
- Retrieving by propositions significantly outperforms passage or sentence retrieval in terms of accuracy and downstream performance. 
- On 5 QA datasets, average improvement over passages is +10.1 R@20 for unsupervised retrievers and +2.2 for supervised ones.
- In retrieve-then-read QA, proposition retrieval also shows gains, with +5.8-6.9 EM@100 from using more condensed, relevant units.

Main Contributions:
- Proposing propositions as a retrieval unit to improve dense retriever generalization
- Introducing FactoidWiki, a multi-granularity segmented Wikipedia corpus
- Empirical analysis showing advantages of proposition-based retrieval for accuracy and downstream QA
