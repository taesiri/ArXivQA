# [Understanding Fine-grained Distortions in Reports of Scientific Findings](https://arxiv.org/abs/2402.12431)

## What is the main contribution of this paper?

 This paper makes three main contributions:

1. It annotates 1,600 instances of scientific findings from academic papers paired with corresponding findings reported in news articles and tweets. The pairs are annotated with labels indicating changes in four characteristics: causality, certainty, generality and sensationalism. 

2. It establishes baselines for automatically detecting changes in those four characteristics, by training and evaluating models on the annotated dataset. The best models achieve macro F1 scores between 0.56-0.61 on detecting changes in each characteristic.

3. It analyzes the prevalence of changes in those four characteristics, in both the expert annotated dataset and a larger automatically labeled dataset of over 1.6 million paper findings paired with over 400,000 news and 350,000 tweet findings. The analysis shows that distortions frequently occur when reporting scientific findings, especially in tweets compared to news.

In summary, the main contributions are: (1) a new annotated dataset of distortions in science reporting, (2) benchmark models for automatically detecting those distortions, and (3) analysis of how prevalent different types of distortions are when scientific findings are reported to the public.
