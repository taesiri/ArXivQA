# [Explanatory Learning: Beyond Empiricism in Neural Networks](https://arxiv.org/abs/2201.10222)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we design machine learning systems that can effectively leverage existing symbolic knowledge and learn to interpret it, in order to discover explanations for novel phenomena like humans do?The key hypothesis appears to be:By taking a "rationalist" approach that focuses on interpreting existing symbolic knowledge, rather than just an "empiricist" end-to-end learning approach, machine learning systems can more effectively discover explanations for new phenomena given existing explanatory knowledge, similar to how human scientists leverage existing theories and knowledge to explain new discoveries. Specifically, the authors propose Critical Rationalist Networks (CRNs) as a model that separates the learning into two components - a generator of symbolic conjecture explanations, and an interpreter that learns to map explanations to observations. They hypothesize this will outperform standard neural network approaches on tasks requiring explanatory generalization.So in summary, the central research question is how to design ML systems that can leverage symbolic knowledge to explain new phenomena, and the key hypothesis is that a rationalist approach with separate conjecture generation and interpretation will work better than end-to-end empirical learning. The CRN model is proposed to test this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Introducing a new framework called Explanatory Learning (EL) for learning to interpret symbolic explanations paired with observations in order to make predictions on new phenomena. This allows machines to make use of existing knowledge without needing a rigid compiler or grammar.2. Presenting a new environment called Odeen for testing EL approaches. Odeen simulates scientific discovery in a simple "universe" of geometric shapes and rules.3. Proposing Critical Rationalist Networks (CRNs) as a "rationalist" approach to EL that focuses on interpreting existing knowledge and explanations rather than solely extracting patterns from data. CRNs have an explicit conjecture generator and learned interpreter.4. Comparing CRNs to end-to-end "empiricist" neural networks on the Odeen benchmark. The results show CRNs can discover the correct explanations for a much higher percentage of new phenomena compared to the neural networks.5. Analyzing properties of CRNs like handling ambiguity, explainability, adjustable thinking time, and confidence estimation. The authors argue CRNs are more aligned with how humans acquire knowledge compared to standard deep learning models.In summary, the main contribution seems to be introducing the EL framework and Odeen environment, as well as proposing and evaluating the CRN model as a rationalist approach well-suited for explanatory learning compared to end-to-end empirical methods.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on my review of the paper, here is a one sentence summary:The paper introduces Explanatory Learning, a framework for machines to interpret symbolic knowledge, such as explanations in natural language, in order to make predictions and discover new knowledge, rather than relying solely on statistical patterns in data.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other research in explanatory learning and rationalist AI:- The concept of Explanatory Learning (EL) seems relatively new and this paper provides one of the first formal frameworks for it. Related prior work like Angluin's learning of regular sets or program synthesis do not fully capture the goals and approach of EL.- The introduction of an EL environment and benchmark like Odeen is a novel contribution. Many prior works have proposed AI environments and benchmarks, but Odeen's focus on scientific discovery and abduction appears unique.- The proposal of Critical Rationalist Networks (CRNs) aligns with a growing interest in rationalist AI, explainable models, and incorporating prior knowledge. However, the specific CRN design does not seem to directly follow any prior work. The interpretable model architecture resonates with some prior ideas like neuro-symbolic AI.- The comparison of CRNs to end-to-end empiricist models is a useful empirical analysis. It provides evidence for the benefits of the rationalist approach in this new EL setting. But the scope is limited to one environment and simple baselines.- The connections made to long-standing debates like empiricism vs rationalism are thought-provoking but also quite philosophical. The concepts and hypotheses need more rigorous investigation.Overall, this paper introduces some interesting new ideas to the intersection of machine learning and scientific reasoning. The EL framework, Odeen environment, and CRN model offer original contributions. But significant more work seems needed to fully develop and evaluate these concepts. The empirical analysis is limited in scope. And the philosophical undertones raise more questions than answers.


## What future research directions do the authors suggest?

Based on my reading of the paper, some key future research directions suggested by the authors include:- Developing more complex environments and languages for the Explanatory Learning paradigm, beyond the current Odeen benchmark. The authors suggest adjusting parameters like structure length, number of shapes/attributes, and grammar specifications to create more challenging EL problems.- Studying the performance of EL models under adversarial attacks or biased training data. The authors believe CRNs may be more robust in these settings compared to end-to-end neural networks.- Extending the framework to include an active interaction phase, where the model must discover its own observations rather than being provided a pre-determined dataset. This could better simulate the full scientific discovery process.- Analyzing the binary semantic representations in more depth. The authors provide some initial analysis of the Odeen semantic matrix but leave further exploration for future work.- Applying the EL paradigm to real-world tasks and domains beyond the current geometric Odeen environment. The authors believe the overall concepts could transfer, but practical applications remain to be demonstrated.- Comparing CRNs against a wider range of model architectures and training techniques, beyond the Transformer baselines presented.- Investigating algorithmic fairness, transparency, and interpretability within the EL framework, as CRNs provide some advantages in these areas over black-box models.Overall, the authors frame Explanatory Learning as a rich paradigm with many promising research directions remaining to be explored in future work. The key themes seem to be developing more complex languages and environments, testing the robustness of EL models, and ultimately applying the concepts to real-world domains.
