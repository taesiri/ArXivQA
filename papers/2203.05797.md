# Long Time No See! Open-Domain Conversation with Long-Term Persona Memory

## What is the central research question or hypothesis that this paper addresses?

This paper addresses the problem of generating coherent and engaging open-domain dialogues in long-term interactions between humans and chatbots. The central hypothesis is that equipping chatbots with long-term persona memory and the ability to actively track both their own persona and the user's persona during conversations will lead to more consistent and engaging dialogues over multiple turns. Specifically, the paper proposes that current chatbots lack "long-term persona ability", which refers to the capability of understanding and modeling the user's and the chatbot's persona through long conversations. This inability to leverage long-term persona information leads to poor performance in multi-turn chats. To test this hypothesis, the paper introduces a new task called "Long-term Memory Conversation" (LeMon) that focuses on mutual persona modeling in long dialogues. It also constructs a new Chinese dataset called DuLeMon for this task. Furthermore, the paper proposes a novel framework called PLATO-LTM that adds a Long-Term Memory (LTM) module to existing chatbot models like PLATO-2. This LTM module enables real-time extraction and storage of both user and chatbot persona from dialogues.In summary, the central hypothesis is that modeling long-term mutual persona through mechanisms like the proposed LTM will improve chatbot consistency and engagingness in long conversations, which is tested through the introduction of the LeMon task, DuLeMon dataset, and PLATO-LTM model.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a new long-term persona chat task LeMon and builds a corresponding Chinese dataset DuLeMon, which focuses on modeling both the user's and chatbot's persona in long-term conversations. 2. It designs a PLATO-LTM framework by adding a novel Long-Term Memory (LTM) mechanism to the state-of-the-art open-domain dialogue model PLATO. The LTM can extract and store both parties' persona information from the conversation history and retrieve relevant personas to generate responses.3. Experiments show that PLATO-LTM can significantly improve the consistency and engagingness of dialogues compared to baselines, enabling more coherent and intimate long-term conversations without relying on multi-session training data.In summary, this paper makes both conceptual and technical contributions to enhancing chatbots' ability to understand and utilize long-term persona information of both parties through real-time extraction and memory. The proposed dataset and model framework help advance research on this important but less studied problem in open-domain conversational AI.
