# [Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing   Mistake Severity](https://arxiv.org/abs/2303.05689)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research question seems to be: 

How can we reduce the severity of mistakes made by a deep neural network image classifier by inducing the network's features to collapse onto a hierarchy-aware frame rather than an equiangular tight frame?

The key hypotheses appear to be:

1) Fixing the classifier layer of a neural network to a hierarchy-aware frame (HAFrame) that encodes the semantic relationships between classes will bias mistakes to be less severe based on the class hierarchy. 

2) Adding a cosine similarity-based auxiliary loss will further facilitate the collapse of features onto the desired HAFrame and hierarchy-aware structure.

3) This approach of fixing the classifier to a HAFrame and using an auxiliary loss will reduce mistake severity while maintaining competitive accuracy compared to other methods.

So in summary, the main research question is about reducing mistake severity in image classification by imposing a certain structure on the network through the classifier and loss function. The key hypotheses are that fixing the classifier to a HAFrame and using a cosine similarity loss will induce features to collapse onto the desired hierarchy-aware structure and reduce mistake severity.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a method to induce neural collapse of a deep neural network to a fixed hierarchy-aware frame (HAFrame) instead of an equiangular tight frame (ETF). This is done in order to reduce the mistake severity of the model's predictions while maintaining classification accuracy. The key ideas include:

- Mapping the hierarchical distances between classes to target cosine similarities using an exponential function. This encodes the class hierarchy into the HAFrame. 

- Providing an analytical solution to construct the HAFrame from a positive definite similarity matrix derived from the hierarchy.

- Adding a transformation layer and fixing the classifier weights to the HAFrame. 

- Using a cosine similarity-based auxiliary loss to facilitate the penultimate features collapsing onto the HAFrame.

- Demonstrating on several datasets that this approach reduces the average mistake severity and hierarchical distance of incorrect predictions while maintaining competitive accuracy compared to previous methods.

So in summary, the main contribution is proposing a straightforward way to modify a neural network to induce collapse onto a hierarchy-aware structure rather than an ETF in order to reduce mistake severity based on the class hierarchy.
