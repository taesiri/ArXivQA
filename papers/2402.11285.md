# [Fair Resource Allocation in Virtualized O-RAN Platforms](https://arxiv.org/abs/2402.11285)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Virtualized RAN (vRAN) architectures are expected to bring major performance improvements in future mobile networks, but their energy consumption is a major concern that threatens adoption. The energy spent on executing virtual base station (vBS) software functions can exceed that of wireless transmissions.
- The energy costs of vBS functions depend on volatile factors like data traffic volume and radio conditions, as well as the heterogeneous hardware in the server pools (O-Cloud). Optimally assigning workloads to servers and controlling radio parameters could curb energy costs but requires solving challenging optimization problems with unknown parameters.

Proposed Solution: 
- The paper develops two policies that are implemented as apps on O-RAN's non-real-time (non-RT) and near-RT controllers:
   1) A compute policy that assigns vBS workloads to O-Cloud servers, balancing energy savings across servers and performance across vBSs.
   2) A radio policy that sets a minimum transport block (TB) size for each user's uplink to curb unnecessary energy expenditures, while ensuring fairness in service quality across users.
- The policies rely on an online learning algorithm based on Follow-the-Regularized-Leader (FTRL) that handles the problem dynamics and unknowns. The algorithm uses predictions to accelerate learning, and a saddle-point reformulation to cater for two-sided fairness properties.

Contributions:
- Experimental analysis of computing delays/energy costs in O-RAN under different conditions.
- New compute and radio control policies with formal optimality guarantees, even under unpredictable environments.
- Customization of FTRL learning framework, using predictions and two-sided fairness reformulation, to enable efficient and fair control.
- Implementation of the data-driven policies on a standards-compliant O-RAN testbed. Real experiments demonstrate significant energy savings, e.g. 67%, with bounded impact on service quality.

In summary, the paper makes a major contribution in tackling the emerging challenge of high energy consumption in virtualized RANs. The proposed solutions leverage key RAN programmability concepts and online learning tools to save energy in cloud infrastructure while retaining performance and fairness service properties.
