# [Predicting city safety perception based on visual image content](https://arxiv.org/abs/1902.06871)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

How accurately can a computational model predict people's perception of safety in different areas of a city, using only visual information from street view images? 

The key points are:

- The authors aim to predict people's subjective perception of safety in different zones of Bogota, Colombia based only on visual cues in street images. 

- They use a convolutional neural network (CNN) approach called transfer learning to extract visual features from the images.

- They collect a dataset of street view images from Bogota along with crowdsourced safety ratings of image pairs from locals. 

- They train a model to predict the safety rating of one image compared to another based on their visual features.

- They test the model on new images from the same and other zones of Bogota to see how well it predicts safety perceptions.

So in summary, the central research question is whether they can accurately predict subjective safety ratings of street scenes using only visual information and their CNN-based approach. The key hypothesis is that visual cues in street images contain enough signals to allow reasonably accurate automated prediction of human safety perceptions.


## What is the main contribution of this paper?

 The main contribution of this paper is the development of an approach to predict people's perception of safety in different areas of the city of Bogota, Colombia based on visual images of those areas. The key points are:

- They collected street view images from different zones of Bogota and had local people rate their perceived safety by comparing image pairs. 

- They used a pre-trained VGG19 convolutional neural network model to extract visual feature vectors from the images. 

- They trained a fully connected neural network on the feature vectors and safety ratings to predict safety perception from new images.

- They achieved 81% accuracy in predicting safety perception on a test set, which they claim is higher than previous state-of-the-art methods.

- They generated synthetic ratings for images from new areas of Bogota to predict safety maps of those areas. 

- They demonstrate the model captures visual cues related to safety perception, like clean vs dirty streets, illumination, etc.

So in summary, the main contribution is developing a machine learning approach tailored to predicting safety perception from visual street images in the specific context of Bogota, achieving high accuracy with a modest dataset size. The method is novel in focusing on a particular city and using transfer learning on a pre-trained CNN model.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 The paper presents an approach using image processing and machine learning to predict people's perception of safety in different areas of the city of Bogota, Colombia based on visual characteristics of street images, achieving 81% accuracy.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other research on predicting city safety perception:

- It focuses on a specific geographical and sociocultural context (Bogota, Colombia) rather than trying to build a general worldwide model like some other papers. This restricted context likely helps reduce noise in the data.

- The dataset is more modest in size compared to some other papers that use hundreds of thousands to millions of images. This paper uses transfer learning with a pre-trained VGG19 model rather than training a CNN from scratch on a huge dataset.

- It achieves a higher prediction accuracy (81%) compared to related papers like Porzi et al. (71%) and Dubey et al. (67%). The geographical/sociocultural restrictions and transfer learning approach may contribute to the better accuracy.

- It generates synthetic votes for prediction rather than relying solely on crowdsourced votes. This allows the model to make predictions on new localities where crowdsourced data may not exist.

- The approach is not as computationally intensive as some other papers, making it more feasible to develop into an online prediction tool.

Overall, the restrictions on geography/culture and the use of transfer learning seem to allow this paper to achieve better accuracy with a smaller dataset compared to some other broader approaches. The synthetic vote generation also provides more flexibility. The authors have focused narrowly on certain research decisions to advance the state of the art in this specific domain.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some future research directions suggested by the authors include:

- Carrying out more exhaustive evaluations to determine the robustness and statistical stability of the predictions. The authors state they plan to do more testing to evaluate how robust and stable the model's predictions are.

- Developing an online tool using the presented method. The authors note their approach does not require high computing capacity, making it suitable for an online application. They suggest this as a direction for future development.

- Expanding the image datasets and visual surveys to additional areas. The current work focused on a limited geographic area and sociocultural context. The authors could expand this to build larger datasets covering more cities/areas. 

- Incorporating additional data beyond visual images. The current model uses only street view images. The authors could look at integrating other data sources (e.g. crime statistics) to complement the visual data.

- Exploring the use of different CNN architectures and machine learning techniques. The authors used a specific CNN model (VGG19) and training method - they could experiment with other approaches to see if accuracy can be further improved.

In summary, the main future directions highlighted are: more robustness testing, developing an online tool, expanding the dataset coverage, incorporating additional data sources beyond images, and exploring alternative machine learning methods/architectures. The authors lay out these areas to build on their initial work on predicting safety perception from visual street images.


## Summarize the paper in one paragraph.

 The paper presents an approach for predicting city safety perception based on visual image content. The authors use image processing and machine learning techniques to detect patterns in urban environments that affect citizens' safety perception. They take a restricted geographical and sociocultural approach, focusing on Bogota, Colombia and using a modest image dataset and transfer learning with the VGG19 model. Through visual surveys, they collect image pairs and safety perception comparisons from Bogota residents to train the model. They achieve 81% accuracy in predicting safety perception on a test set. The model is then used to predict safety perception scores and generate perception maps for other Bogota neighborhoods, showing its ability to generalize. Overall, the restricted context and transfer learning allow high accuracy prediction of city safety perception from images.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper presents an approach for predicting people's perception of safety in different zones of the city of Bogota, Colombia based on analyzing visual images of city streets. The authors collected over 5,000 geo-tagged images from one zone of Bogota and had people rate pairs of images through a website survey to indicate which place looked safer. They used these ratings to train a neural network model to predict safety perception from the image features extracted from a pre-trained VGG19 convolutional neural network model. The model achieved 81% accuracy on a test set. The authors then applied the model to generate synthetic ratings on images from other zones of Bogota to predict safety perception maps of those areas. The results demonstrated an ability to predict safety perception solely from visual street scenes. This approach could be useful for identifying areas where people feel less safe based only on how they appear visually without needing direct surveys.

The key aspects of this work are the use of transfer learning from a CNN model pre-trained on unrelated image classification to extract informative features from the street view images, surveying people to directly rate comparative safety of different scenes, and the ability to take a model trained on one zone and generalize it to predict perceptions on totally separate zones not involved in the original training. The accuracy levels achieved along with the demonstrated transferability provide evidence this approach could be a practical way to infer public safety perceptions at scale across cities based on analyzing visual street scenes.


## Summarize the main method used in the paper in one paragraph.

 The paper presents an approach to predict citizens' perception of safety in different areas of the city of Bogota, Colombia based on visual content of street images. The main method involves using a pre-trained VGG19 deep convolutional neural network as a fixed feature extractor to obtain vector representations of street images. These vectors are paired along with human votes on their relative perceived safety collected through a visual survey website. A shallow fully connected neural network model is then trained on this dataset of image vector pairs and votes to predict the safety perception of new street images. The model achieves 81% accuracy in predicting human votes. This trained model is used to generate synthetic votes between images of new city areas and create perception maps.
