# [GTA: Gated Toxicity Avoidance for LM Performance Preservation](https://arxiv.org/abs/2312.06122)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper explores the trade-off between toxicity avoidance and language model performance in controllable text generation (CTG) methods. The authors find that while existing CTG techniques like PPLM, GeDi, and DExperts successfully reduce toxicity, they also negatively impact other performance metrics like topic accuracy, grammar, and perplexity. To address this, the authors propose a novel solution called Gated Toxicity Avoidance (GTA) which selectively applies CTG only when toxicity is detected. Experiments across diverse datasets demonstrate that GTA achieves comparable toxicity reduction to original CTG methods while preserving language model performance across metrics. The simplicity and model-agnostic nature of GTA makes it an appealing plug-and-play solution to mitigate CTG's holistic performance degradation. Key results highlight GTA's effectiveness in toxicity avoidance with negligible impact on accuracy, fluency or speed.
