# [Supersizing Self-supervision: Learning to Grasp from 50K Tries and 700   Robot Hours](https://arxiv.org/abs/1509.06825)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is whether it is possible to scale up trial-and-error experiments to collect large datasets for training high-capacity deep learning models, like CNNs, to predict grasp locations for novel objects. The key hypotheses are:1) Large-scale datasets collected from physical robot trial-and-error interactions are needed to train high-capacity models like CNNs for grasp prediction without overfitting. 2) Formulating grasp prediction as a multi-class classification over grasp angles for image patches works better than regression.3) A multi-stage reinforcement learning approach allows collecting hard negatives to train better grasp prediction models.4) Larger datasets and multi-stage training lead to better generalization performance in grasp prediction for novel objects.The paper aims to demonstrate the feasibility of large-scale self-supervised data collection for grasp prediction, and show that larger datasets and multi-stage training can improve grasp prediction performance, especially for novel objects.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Introduction of one of the largest robot datasets for grasping, with over 50K datapoints collected using 700 hours of trial-and-error experiments on a Baxter robot. 2. A novel formulation for grasp prediction using CNNs, where grasping locations are predicted by sampling image patches and performing 18-way binary classification over grasp angles. 3. A multi-stage learning approach to collect hard negatives and improve the grasping model, showing the benefits of large-scale data and multi-stage training for grasping.In summary, the key contribution is using a large-scale robot grasping dataset along with a multi-stage CNN model to achieve improved grasp prediction, especially for generalizing to novel objects. The large dataset and comparative experiments demonstrate the importance of scale for learning grasping representations.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper presents a deep learning approach using 50K grasps over 700 robot hours to enable robots to learn to grasp objects through trial-and-error, showing good generalization performance to novel objects.
