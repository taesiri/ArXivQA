# [Using an LLM to Turn Sign Spottings into Spoken Language Sentences](https://arxiv.org/abs/2403.10434)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Sign Language Translation (SLT) aims to translate sign language videos into spoken language sentences. SLT is challenging because sign and spoken languages have different grammar structures and it is difficult to align and tokenize continuous sign language videos. Existing methods rely on gloss supervision which is resource intensive or do not work well on large domain datasets.

Proposed Solution: The paper proposes a hybrid SLT approach called Spotter+GPT that combines a sign spotter and the ChatGPT language model. First, a sign spotter based on an I3D model is trained on a linguistic sign language dataset to spot individual signs from videos. Then the sequence of spotted sign glosses is fed to ChatGPT via prompting to generate a spoken language sentence.

Main Contributions:
- Proposes a new hybrid SLT approach combining sign spotting and ChatGPT without needing SLT specific training data.
- Leverages ChatGPT's natural language abilities to produce coherent and contextually relevant spoken sentences from sequences of spotted glosses. 
- Introduces prompt engineering to handle cases when no glosses are spotted or translation is not possible.
- Evaluated on the MeineDGS dataset and a new DGS-20 video dataset, showing the approach can generate high quality translations when sufficient glosses are spotted.
- Qualitative examples demonstrate ChatGPT's ability to preserve meaning despite some errors in sign spotting and differences in grammar between sign and spoken languages.

In summary, the key novelty is the demonstration that sign spotting combined with the zero-shot translation capabilities of ChatGPT can produce strong sign language translation without additional training data or models. The results show the promise of this hybrid approach to SLT.
