# [Locating and Mitigating Gender Bias in Large Language Models](https://arxiv.org/abs/2403.14409)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Biases in large language models (LLMs) can lead to issues when deployed. Prior work has mostly focused on either locating biases or mitigating them, but not both within a unified framework. 

- The mechanisms underlying how gender bias is generated in LLMs is not well understood. Most debiasing methods rely on black-box fine-tuning rather than targeting root causes.

Methodology:
- The paper traces how information flows through an LLM to understand where and how gender bias originates using causal mediation analysis. Experiments on GPT-2 XL and GPT-J reveal that:
  - Bottom MLP modules acting on occupational pronoun tokens play a key role in generating gender bias. 
  - Top attention modules then capture the biased information and propagate it to influence outputs.

- Based on these insights, the paper proposes the Least Square Debias Method (LSDM) to edit the bottom MLP modules to mitigate gender bias associated with occupational pronouns. LSDM solves a matrix equation with constraint terms to minimize interference with the model's other capabilities.

Contributions:
- Integrates locating and mitigating bias within a unified framework, using causal tracing to inform targeted debiasing.

- Reveals that bottom MLP modules generate gender bias which top attention modules then propagate, through causal mediation experiments.

- Proposes LSDM to edit bottom MLP modules based on mathematical optimization, overcoming catastrophic forgetting issues faced by other debiasing methods.

- Achieves over 70% reduction in gender bias related to occupational pronouns while preserving performance on other tasks, outperforming baselines.

- First work to adapt knowledge editing techniques for debiasing, sets foundation for eliminating other biases in LLMs.

In summary, the key innovation is using causal tracing to understand and target the root causes of gender bias in LLMs, enabling more interpretable and effective debiasing via knowledge editing.
