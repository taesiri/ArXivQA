# [Efficient View Synthesis and 3D-based Multi-Frame Denoising with   Multiplane Feature Representations](https://arxiv.org/abs/2303.18139)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to perform efficient and high-quality 3D-based multi-frame denoising using multiplane representations. 

Specifically, the paper focuses on solving two key challenges:

1. Cross-depth consistency in multiplane representations: How to enforce consistency across different depth planes in the multiplane representation to avoid artifacts and improve quality.

2. 3D-based multi-frame denoising: How to re-purpose multiplane image representations originally developed for novel view synthesis for the task of multi-frame video denoising by exploiting 3D scene structure.

To address these challenges, the paper introduces a new framework called Multiplane Feature Encoder-Renderer (MPFER) that represents scenes using multiplane features (MPF) rather than standard multiplane images (MPI). The key ideas are:

- Enforcing cross-depth consistency at the rendering stage using a learned renderer rather than in the encoder. This allows the encoder to focus only on fusing information across views.

- Moving the multiplane representation to feature space rather than RGB space. This increases representational power. 

- Applying the re-designed MPF framework to multi-frame denoising by using input views for both encoding and rendering. This enables exploiting 3D structure for denoising.

The central hypothesis is that the proposed MPF representation and encoder-renderer architecture will enable efficient, high-quality 3D-based multi-frame denoising compared to prior 2D and 3D methods. The experiments validate this hypothesis empirically on different datasets.


## What is the main contribution of this paper?

 The main contribution of this paper is introducing a novel 3D-based multi-frame denoising method using multiplane representations. Specifically:

- It proposes to solve the cross-depth consistency problem for multiplane representations at the rendering stage by introducing a learnable renderer. This allows the encoder to focus on fusing information across views in a depth-independent manner.

- It introduces the Multiplane Feature (MPF) representation, which is a generalization of the standard Multiplane Image (MPI) to feature space. This provides higher representational power compared to MPI.

- It re-purposes the MPI framework, originally developed for novel view synthesis, for multi-frame denoising. This enables 3D-based reasoning for denoising.

- It validates the proposed approach called Multiplane Features Encoder-Renderer (MPFER) on multiple tasks and datasets. For multi-frame denoising, it significantly outperforms existing 2D-based and 3D-based methods while having much lower computational requirements.

In summary, the main contribution is a new 3D-based multi-frame denoising method built upon a novel multiplane feature representation and rendering framework that outperforms prior state-of-the-art approaches. The key novelty is using a learnable renderer for multiplane representations to achieve efficient depth fusion.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper introduces a 3D-based multi-frame denoising method using multiplane feature representations that significantly outperforms existing 2D alignment techniques and other 3D approaches, demonstrating the promise of leveraging volumetric scene representations and learnable rendering for multi-frame restoration tasks.
