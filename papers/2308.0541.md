# [Detecting Cloud Presence in Satellite Images Using the RGB-based CLIP   Vision-Language Model](https://arxiv.org/abs/2308.0541)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How capable is the pre-trained CLIP vision-language model at identifying cloud presence in satellite images, and how transferable are the methods across different datasets and sensor types (Sentinel-2 and Landsat-8)?The key hypotheses appear to be:1) CLIP can achieve non-trivial performance on cloud presence detection despite not being trained specifically for this task. 2) CLIP has the capability to generalize across different sensing modalities and bands.3) The representations learned by CLIP are useful for satellite image processing tasks involving clouds.The authors test these hypotheses by exploring different approaches for using CLIP for cloud presence detection, including zero-shot classification, fine-tuning, and multi-modal (optical + radar) methods. They evaluate performance on two different benchmark datasets from different sensors to analyze transferability. The results provide evidence supporting the hypotheses.In summary, the central research question is evaluating CLIP's capabilities and transferability for cloud presence detection in satellite imagery, with the key hypotheses relating to CLIP's applicability and generalization ability for this application.


## What is the main contribution of this paper?

The main contribution of this paper is exploring the capabilities of the pre-trained CLIP vision-language model for the task of cloud presence detection in satellite imagery. Specifically:- The paper proposes and evaluates several approaches for using CLIP to detect cloud presence, including zero-shot classification with text prompts as well as minor fine-tuning of the model. - It tests the transferability of these CLIP-based methods across different datasets (CloudSEN12 and SPARCS) and sensor types (Sentinel-2 and Landsat-8).- The key findings are that CLIP can achieve non-trivial performance on cloud presence detection without training, and a small amount of fine-tuning leads to large gains in true negative rate. - The results demonstrate the potential utility of CLIP's learned representations for cloud-related tasks in satellite image processing.In summary, the main contribution is exploring and evaluating the capabilities of CLIP for the novel application of cloud presence detection in satellite imagery in a transferable manner across datasets and sensors.
