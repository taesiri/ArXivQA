# [Hierarchical Source-to-Post-Route QoR Prediction in High-Level Synthesis   with GNNs](https://arxiv.org/abs/2401.08696)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- High-level synthesis (HLS) speeds up hardware design by using high-level languages like C/C++ instead of RTL. However, considering post-route quality of results (QoR) like latency and resource usage significantly increases HLS turnaround time.
- Existing analytical models for QoR prediction have limited scalability. Machine learning models using features from HLS reports still require running HLS flow. 
- Graph neural networks (GNNs) have been used recently for QoR prediction. But they don't fully capture the impact of hierarchies in code structure and HLS pragmas.

Proposed Solution:
- Propose a hierarchical GNN-based methodology to directly predict post-route QoR from C/C++ without running any EDA tools.
- An effective graph construction approach that jointly represents control-data flow graph of code and effects of pragmas like loop pipelining, unrolling and array partitioning.
- Hierarchical training of GNNs - first predict QoR of inner loop hierarchies, then merge them into super nodes to predict overall QoR using global GNN.

Main Contributions:
- Efficiency - direct C/C++ to post-route QoR prediction without invoking any EDA tools like HLS or logic synthesis.
- Pragma modeling - joint graph representation of code and common HLS pragmas.
- Hierarchical training - captures code hierarchies and gradually predicts QoR from inner to outer loops. 
- Accuracy - average prediction error <10% for post-route latency and resource usage, outperforming state-of-the-art GNN methods.
- Productivity - with fast and accurate QoR feedback, design space exploration time reduced from weeks to minutes.

In summary, the paper proposes a hierarchical GNN approach for efficient and accurate post-route QoR prediction to boost HLS productivity. The hierarchical modeling and joint code-pragma graph representation are the main innovations.


## Summarize the paper in one sentence.

 This paper proposes a hierarchical graph neural network approach to efficiently and accurately predict post-route quality of results directly from C/C++ source code to enable fast design space exploration for high-level synthesis of FPGAs.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes a hierarchical post-route quality of results (QoR) prediction approach for FPGA high-level synthesis (HLS), which can directly estimate latency and post-route resource usage from C/C++ programs. 

2. It introduces an effective graph construction method that jointly represents the control and data flow graph of the source code along with the effects of HLS pragmas. 

3. It develops a hierarchical graph neural network (GNN) training and prediction methodology that is capable of capturing the impact of loop hierarchies in the code.

4. Experimental results demonstrate that the proposed approach achieves less than 10% prediction error on average for different post-route QoR metrics, outperforming state-of-the-art GNN methods. 

5. By adopting the proposed fast and accurate QoR prediction, the design space exploration time is significantly reduced to tens of minutes, while achieving low optimality loss in terms of average distance from the reference set.

In summary, the key innovation is the hierarchical modeling approach using GNNs that incorporates loop structures and HLS pragmas for accurate and efficient source-level post-route QoR prediction.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it are:

- High-level synthesis (HLS)
- Quality of results (QoR) 
- Post-route metrics (e.g. latency, resource usage)
- Graph neural networks (GNNs)
- Hierarchical modeling 
- Loop pipelining
- Loop unrolling
- Array partitioning
- Control and data flow graph (CDFG)
- Design space exploration (DSE)
- Prediction accuracy 
- Pragmas
- Resource usage (DSP, LUT, FF)

The paper proposes a hierarchical GNN-based approach to predict post-route QoR metrics directly from C/C++ code. It represents the code and effects of HLS pragmas using a CDFG, and trains GNN models in a hierarchical manner to estimate latency and resource usage. The prediction results are then used to guide design space exploration to find optimal pragma configurations. The key benefits are efficiency, accuracy, and the ability to model pragmas and loop hierarchies.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions I would ask about the hierarchical source-to-post-route QoR prediction method proposed in this paper:

1. The graph construction process is key to representing the effects of HLS pragmas. What other types of pragmas could be incorporated in the future and how might the graph construction process need to be extended to capture their effects?

2. What mechanisms allow the hierarchical GNN models to learn and capture the cascading effects of changes in the inner loop hierarchy on the performance of the outer loops and overall application? 

3. How was the decision made regarding the specific set of node features to use? Was any feature selection process conducted and if so, what was the methodology?

4. What were the key differences when designing the architectures for the GNN models at the inner vs outer hierarchies? What customizations were made and why?

5. The training methodology trains models at inner and outer hierarchies separately. What would be the tradeoffs of a joint end-to-end training approach instead?

6. How was the allocating of loops to inner vs outer hierarchies decided? What criteria determined which loops were flattened/unrolled and modeled as super nodes?

7. What were the major challenges faced when scaling up the methodology to real applications with complex nested loop hierarchies? How were these issues resolved?

8. The design space exploration utilizes the GNN models to bypass RTL synthesis and implementation. What is the estimated speedup over the traditional flow and how does this contribute to faster design convergence?

9. How well would this methodology generalize to exploring optimizations like function inlining, array reshape, memory partitioning beyond loop pragmas? What changes are needed?

10. The predictions currently target a specific FPGA platform. What adaptations would enable architecture-agnostic predictions applicable to different vendors and families of FPGAs?
