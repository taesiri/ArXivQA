# [Learning adaptive planning representations with natural language   guidance](https://arxiv.org/abs/2312.08566)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper tackles the challenge of adapting general world knowledge to support flexible long-term planning in AI agents. While techniques exist for solving restricted, short-term planning problems, generalized and long-horizon planning remains an open challenge across AI paradigms. The key bottleneck is identifying useful hierarchical action representations tailored to a particular domain that enable efficient planning. Most state-of-the-art systems rely on human expertise to hand-engineer these representations.

Proposed Solution: 
The paper proposes a framework called "Action Domain Acquisition" (Ada) for automatically constructing task-specific planning representations using background knowledge from language models (LLMs). Ada interactively learns a library of planner-compatible high-level action abstractions and low-level controllers adapted to a domain of planning tasks. 

It uses LLM prompts to initially propose candidate operator definitions consisting of preconditions, effects, and low-level controllers. It then uses a bi-level planner that refines high-level plans into low-level action sequences to iteratively ground and verify these operators based on environment interaction. Useful operators are added to the library, while inaccurate ones are rejected. The low-level controllers are also refined over time using policy learning techniques.

Main Contributions:

- A novel framework for using LLMs to propose an initial set of useful planning operator abstractions tailored to a domain using language, then iteratively grounding and verifying these representations through environment interaction

- Demonstrating that language provides an effective prior for proposing planning representations that enable efficient search

- Introducing two language-goal based planning benchmarks based on Mini Minecraft and ALFRED household environments  

- Showing significantly improved performance over baselines on complex, compositional tasks requiring abstraction hierarchies to solve efficiently

The main insight is utilizing linguistic knowledge as a rich general prior for planning that can be adapted to different domains through interaction, reducing manual engineering effort.


## Summarize the paper in one sentence.

 This paper describes Ada, a framework for interactively learning a library of hierarchical planning operators from language model proposals and environment interactions, enabling efficient planning for complex, compositional tasks.


## What is the main contribution of this paper?

 The main contribution of this paper is a framework called "Action Domain Acquisition" (Ada) for interactively learning a library of symbolic, hierarchical action abstractions tailored to a given environment and task distribution. 

Specifically, Ada leverages language models to propose candidate high-level action operators, then uses a bi-level planning and execution loop to verify and refine these operators over multiple interactions in an environment. The end result is a learned library of operators that enable efficient hierarchical planning by decomposing tasks into high-level subgoals that can be achieved by learned low-level controllers.

The key benefits highlighted are:

- Using language as a rich source of human priors and background knowledge to propose useful action abstractions
- Adapting these proposals into grounded, verifiable representations suited to hierarchical planning 
- Learning operators at an appropriate level of abstraction by fitting them to the planning context and capacity of low-level controllers
- Demonstrating substantially improved planning accuracy and generalization over baselines on complex, language-specified planning tasks

In summary, the main contribution is a complete framework for interactively learning hierarchical planning representations tailored to particular environments and tasks by leveraging language model knowledge.


## What are the keywords or key terms associated with this paper?

 Based on my analysis of the paper, some of the key terms and concepts related to this work include:

- Action domain acquisition (Ada) - The overall framework proposed for learning task-specific planning representations from language models and environment interaction.

- Hierarchical planning - Using high-level symbolic action abstractions that decompose into lower-level policies to efficiently solve long-horizon planning problems. 

- Operator learning - Learning the symbolic definitions and low-level controllers associated with high-level action abstractions. Evaluating whether proposed operators support valid planning.

- Language guidance - Using language models to propose candidate action abstractions and planning goals based on natural language descriptions of tasks. 

- Interactive learning - Iteratively proposing, evaluating and refining operators based on experience attempting to solve tasks in an environment.

- Generalization - Evaluating whether action libraries learned on simpler tasks can directly transfer to efficiently solve more complex, compositional tasks.

- Environments: Mini Minecraft, ALFRED - Two interactive environments for language-guided planning tasks used to evaluate the approach.

In summary, the key ideas relate to using language to guide the learning of reusable, hierarchical planning operators tailored to environments and tasks, through an interactive learning process.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes learning a library of hierarchical actions tailored to a given environment and task space. How does it balance learning high-level abstractions useful for efficient planning versus low-level controllers that can accurately achieve the effects of those abstractions?

2. The operator scoring procedure described in Section 3.4 evaluates whether proposed operators are accurate and support low-level planning. What are some strengths and weaknesses of this scoring approach? How might it be improved or made more rigorous? 

3. The paper describes learning shared, subgoal-conditioned policies to accelerate low-level planning. What are the tradeoffs in using a single shared policy versus separate policies or more specialized representations for each high-level action?

4. How does the paper handle stochasticity and noise in both the environment dynamics and the language model proposals? Could the approach be made more robust to these sources of uncertainty? 

5. The prompting strategies employ several heuristics and design choices for few-shot prompting of the language model, such as providing unrelated examples initially. What is the sensitivity of the overall approach to these prompt engineering decisions?

6. How does the balance between language model sampling and search-based planning shift as the learned representation improves over iterations? Does planning become more or less important?

7. What mechanisms support generalizing the learned action representations to new and more complex tasks? Are there ways the approach could accelerate or improve this generalization capability?

8. How does the choice of language model scale or architecture impact the overall quality and sample efficiency of representation learning? What are the tradeoffs?

9. The paper leaves open integrating perceptual grounding of symbols and predicates. What are promising ways language guidance could be integrated with learning these grounded representations?

10. What other modalities beyond language might provide useful background knowledge for learning planning representations? Could the approach integrate other forms of supervision or priors?
