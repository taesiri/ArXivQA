# [Solving Dense Linear Systems Faster than via Preconditioning](https://arxiv.org/abs/2312.08893)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes new randomized algorithms for solving dense linear systems and least squares problems with matrices that have a relatively small number of large singular values. The key idea is to use a stochastic block coordinate descent method, where blocks of rows/columns are sampled randomly in each iteration to update the solution. The main challenge is obtaining fast per-iteration running time while still ensuring strong convergence guarantees that depend on the number of large singular values $k$ rather than the matrix dimensions. To achieve this, the algorithms first apply a randomized Hadamard transform to uniformize the block sampling probabilities. Then, they solve the small sampled linear system via an approximate sketch-and-project method, relying on a preconditioner constructed by sketching the rectangular matrix formed in each iteration. For dense $n\times n$ systems, this leads to a total runtime of $\tilde{O}(n^2 + nk^{\omega-1})$ to find an approximate solution, improving over standard iterative solvers. For tall least squares, the runtime becomes $\tilde{O}(\nnz(A) + d^2 + dk^{\omega-1})$, also leveraging input sparsity. Similar guarantees are derived for dense positive semidefinite systems.
