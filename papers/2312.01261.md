# [TIBET: Identifying and Evaluating Biases in Text-to-Image Generative   Models](https://arxiv.org/abs/2312.01261)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
- Text-to-image (TTI) models can generate high quality images from text descriptions, but have been shown to suffer from societal and incidental biases.  
- Existing methods to detect biases rely on pre-defined bias categories like gender, age, etc. But relevant biases can vary across prompts.  
- Prior works don't offer explainability of detected biases in terms of concepts in generated images.

Proposed Solution - TIBET:
- Dynamically identifies potential bias axes relevant for a given prompt using large language models like GPT-3.
- Generates counterfactual prompts along each bias axis.  
- Feeds prompts to TTI model to generate images. Extracts concepts from images using VQA model.
- Proposes metrics - Concept Association Score (CAS) and Bias Axis Variance (BAV) to quantify bias using concept similarity between original and counterfactual image sets.
- Also provides qualitative explanation of biases using frequent concepts.

Main Contributions:
- Bias identification approach adaptable across prompts instead of predefined bias categories.
- Quantification and concept-level explanations of multidimensional biases.
- Demonstrates analysis like exploring intersectionality of biases, and integration with bias mitigation methods.
- Comprehensive human evaluations validate effectiveness for bias analysis.

The summary covers the key aspects of the paper - the problem being addressed, the proposed TIBET solution and its main capabilities, the core contributions compared to prior works, and evaluations that validate the utility of this approach.
