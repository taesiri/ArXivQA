# [Readout Guidance: Learning Control from Diffusion Features](https://arxiv.org/abs/2312.02150)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper introduces Readout Guidance, a method to control text-to-image diffusion models using lightweight neural networks called readout heads that are trained on top of a frozen pre-trained diffusion model. These readout heads can extract useful signals or "readouts" from the diffusion model's intermediate features, including properties about a single image like pose, depth, and edges, as well as relative properties between images like correspondence points and appearance similarity. At sampling time, these readouts can be compared to user-defined target values, and the difference can be used to guide the sampling process towards images that match the desired constraints. Compared to prior conditional diffusion models, Readout Guidance requires much less training data and parameters to add control capabilities. The method is demonstrated on applications like drag-based image manipulation, identity-consistent image generation, and spatially-aligned control. Notably, Readout Guidance performs competitively on pose-guided generation using 350x less data than prior work. The general framework allows diverse forms of control to be implemented under the same architecture and sampling procedure.
