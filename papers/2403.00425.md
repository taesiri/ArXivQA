# [HALC: Object Hallucination Reduction via Adaptive Focal-Contrast   Decoding](https://arxiv.org/abs/2403.00425)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Vision-language models (VLMs) have demonstrated impressive capabilities in interpreting multi-modal contexts, but they invariably suffer from object hallucination (OH), where they erroneously generate hallucinated objects and descriptions that are not grounded in the actual visual input. OH is a persistent challenge and has gained increased attention recently as large VLMs also exhibit this issue. Existing efforts on mitigating OH have limitations in terms of eliminating different types of OH, reliance on additional resources, and compatibility with existing VLMs. Therefore, there is an urgent need to develop effective and adaptable approaches to reduce OH in VLMs.  

Proposed Solution - HALC:
The paper proposes HALC, a novel decoding algorithm to mitigate OH in VLMs by operating on both local and global contexts simultaneously without requiring extra resources. 

Locally, HALC employs an adaptive focal-contrast grounding mechanism. It first identifies candidate tokens that may hallucinate based on their syntactic categories. Then for each such token, it retrieves a visual context from the image using off-the-shelf detectors. Next, it samples multiple fields of views (FOVs) around this context and selects FOV pairs with highest distribution divergences. Finally, it decodes the token from the contrasted distributions of these FOV pairs to correct potential hallucinations.

Globally, HALC incorporates a matching-based beam search where beam sequences are scored by the visual similarity between the generated text and the original image. This balances OH reduction and text quality during the overall decoding.

Main Contributions:
1) HALC significantly reduces different types of OH in VLMs while preserving text generation quality.

2) It is model-agnostic and can be conveniently integrated as a plug-and-play module into existing VLMs without retraining or extra data.

3) Extensive experiments show HALC achieves state-of-the-art performance in reducing OH over strong baselines across diverse evaluation benchmarks. 

4) An open platform is introduced to unify OH reduction methods for easy adaptation, providing various LVLM backbones and OH metrics for comprehensive assessments.

In summary, HALC offers an effective and adaptable approach to alleviate OH in VLMs via a novel decoding algorithm tailored for fine-grained visual grounding during text generation. The plug-and-play nature also enables convenient integration into existing models.
