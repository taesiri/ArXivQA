# [Extending 6D Object Pose Estimators for Stereo Vision](https://arxiv.org/abs/2402.05610)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Accurately estimating the 6D pose (3D translation and 3D rotation) of objects in real-time is challenging but critical for robotics, AR/VR, and other applications. 
- Using stereo vision could help reduce ambiguity and leverage depth information compared to monocular images.
- Recent state-of-the-art methods use dense intermediate features like 2D-3D correspondences for direct 6D pose regression, but are designed for monocular images.

Proposed Solution:
- Extend current state-of-the-art monocular 6D pose estimation networks GDRNet and SO-Pose to leverage stereo input.
- Explore fusing information from the stereo pair at different stages: early, mid, late, and double fusion.
- Also predict disparity using the shared backbone and integrate it as an additional feature.

Contributions:
- SO-Stereo and GDRN-Stereo: Stereo extensions of SO-Pose and GDRNet respectively.
- Analysis of different fusion techniques within the network architecture.  
- YCB-V DS: Stereo + depth version of the YCB-Video dataset with perfect labels.
- GDRN-Stereo variants outperform prior state-of-the-art on heavily occluded data, showing benefit of stereo for 6D pose estimation.

The key ideas are extending existing monocular networks to stereo, fusing features from the stereo pair in different ways, adding disparity as an extra signal, and demonstrating improved performance over the previous state-of-the-art on a new stereo dataset.
