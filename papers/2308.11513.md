# [TrackFlow: Multi-Object Tracking with Normalizing Flows](https://arxiv.org/abs/2308.11513)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can multi-modal information such as 2D motion cues, visual appearance, and 3D pose estimates be effectively merged into a single comprehensive cost metric for multi-object tracking?The key points are:- The paper focuses on extending tracking-by-detection to multi-modal settings where different types of information need to be integrated. - Traditional approaches use simple rules or heuristics to combine different costs, but this requires careful tuning and assumes the costs are independent.- The paper proposes a probabilistic formulation that models the cost as the negative log-likelihood from a conditional density estimator trained on correct associations. - This allows jointly modeling the conditional distribution over multiple input costs in a data-driven way without independence assumptions.- The proposed method TrackFlow uses normalizing flows to model this distribution and outperforms baselines on simulated and real tracking benchmarks.So in summary, the main research question is how to effectively integrate multi-modal cues for tracking-by-detection, with the proposed solution being a learned conditional density estimator using normalizing flows.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing TrackFlow, a method to combine multi-modal costs into a single metric for tracking-by-detection algorithms. This is done by modeling the cost of a candidate detection-track association as the negative log likelihood under a conditional joint probability distribution estimated by a deep density estimator (specifically a normalizing flow model).- Introducing a deep neural network called DistSynth to estimate the distance of pedestrians from the camera in monocular images. This provides the 3D localization cues that can be combined with 2D information like bounding box IoU. The network uses a temporal module and FPN branch to handle occlusions and preserve spatial details.- Conducting experiments on MOTSynth, MOT17, and MOT20 datasets that demonstrate TrackFlow consistently improves the performance of several tracking-by-detection methods by merging 2D and estimated 3D cues. The results also show competitive performance by training only on synthetic MOTSynth data.- Providing analysis suggesting the benefits of conditioning the density estimator on scene-level context and fine-tuning on real data.So in summary, the main contribution is presenting a way to effectively combine heterogeneous cues like 2D motion and estimated 3D localization for tracking-by-detection, enabled by a learned conditional density model. The results demonstrate improved tracking performance across various methods and datasets.
