# [What Planning Problems Can A Relational Neural Network Solve?](https://arxiv.org/abs/2312.03682)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper presents a theoretical analysis of the circuit complexity of goal-conditioned policies represented by relational neural networks (RelNNs) such as graph neural networks and Transformers. It draws connections between the regression width of a planning problem and the size and depth required for a RelNN to solve that problem. The authors define the notion of strong optimally-serializable (SOS) width, which characterizes how effectively the subgoals in backward search can be serialized and achieved sequentially. They show constructively that for planning problems with constant SOS width, there exist RelNNs of constant breadth (independent of number of objects) that can solve those problems. Furthermore, they provide algorithms to compile the backward search directly into polynomial-sized RelNN circuits for problems with small SOS widths. The results also explain why certain difficult planning problems like Sokoban require RelNNs with unbounded breadth. Overall, this theoretical characterization highlights the relationship between the structure of planning problems and the complexity of neural networks required to represent policies, providing insights into generalizability.


## Summarize the paper in one sentence.

 This paper analyzes the circuit complexity of relational neural networks representing policies for planning problems by drawing connections with serialized goal regression search.


## What is the main contribution of this paper?

 The main contribution of this paper is a theoretical analysis that connects the complexity of planning problems to the circuit complexity of neural network policies that can solve those problems. Specifically:

- The paper introduces the notion of "regression width", which measures the complexity of backward search through a problem's goal regression rules. This is related to but differs from prior notions of planning width that focused on forward search.

- The paper shows a relationship between a problem's regression width and the size (depth and breadth) of relational neural network circuits that can represent optimal policies for those problems. Problems with small, constant regression widths have policies that can be represented by small, constant-sized neural networks.

- Through this analysis, the paper provides explanations for why neural networks can learn generalizable policies for some planning domains like Blocks World, but not others like Sokoban. It also provides guidance on how to design network architectures for different planning problems.

- The paper validate the theoretical results experimentally, by training neural networks of different sizes on planning problems and showing the impact on generalization. The experiments confirm that network size predicted by the theory is necessary and sufficient.

In summary, the key contribution is a new complexity measure for planning tied to the learnability of neural network policies, with theoretical and empirical validation. This begins to explain the learnability of policies in different domains.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Goal-conditioned policies - Policies that map from current state and goal specification to next action.

- Regression width - A measure related to the notion of "width" from the AI planning literature, indicating the number of constraints that need to be tracked during backward search. 

- Serialized goal regression search (S-GRS) - A variant of backward search that commits to achieving subgoals in a particular order.

- Strong optimally-serializable (SOS) width - A property indicating that subgoal orderings can be serialized in an optimal way. 

- Relational neural networks (RelNNs) - Neural networks like graph neural networks and Transformers that can operate on inputs of variable size by reusing parameters. 

- Circuit complexity - Analyzing the depth and breadth/arity of relational networks representing policies.

- Goal regression rule selector - Determines which regression rule to apply without needing full backward search, enabling more efficient policies.

- Compiling planning algorithms into neural policies - Constructively mapping search procedures into feedforward neural networks.

The key ideas revolve around using backward search structures to analyze planning complexity, serializing subgoals to improve efficiency, and compiling these algorithms into goal-conditioned policies represented as relational neural networks. The circuit complexity measures then characterize what network sizes are needed.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper introduces the concept of "regression width" for analyzing the complexity of planning problems. How is this concept defined formally? How does it relate to existing notions like the width of a planning problem in classical planning?

2. The paper proposes using serialized goal regression search (S-GRS) for solving planning problems more efficiently. Explain the S-GRS algorithm and its key differences from plain backward search. What are the completeness and optimality guarantees for S-GRS?

3. What is the notion of "strong optimal serializability" (SOS) introduced in the paper? Why is this property useful for characterizing problems that have efficient S-GRS algorithms? Provide an illustration with the Blocks World domain.  

4. The paper shows how to compile BWD and S-GRS search algorithms into relational neural network policies. Explain these compilation schemes. What are the depth and breadth requirements for the resulting neural networks?

5. For problems with non-constant SOS widths, the paper proposes learning a "regression rule selector" to reduce the complexity of the policy network. Formalize what a rule selector is and discuss when they can be efficiently learned.

6. The experiments focus on problems with constant vs non-constant circuit depths. Explain the motivation behind choosing Assembly3 and Logistics as test domains. How do the results validate the theoretical analysis?

7. The paper claims Sokoban has unbounded regression width. Intuitively explain why, even for single-atom goals, Sokoban does not have simple serializable goal regression rules.  

8. Discuss the connections and differences between the proposed "regression width" analysis and existing width-based forward search algorithms like IW(k). Is there an equivalence between the two concepts?

9. The current analysis focuses on deterministic planning problems. How might the results extend to planning under uncertainty? Would the notion of "regression width" still be applicable?

10. Beyond discrete planning domains, can we extend the theoretical analysis to problems like robotic manipulation that involve continuous state and action spaces? What new challenges need to be addressed?


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper studies goal-conditioned policies, which are feed-forward neural networks that map from the current state and goal specification to the next action. Specifically, it aims to understand under what circumstances such policies can be efficiently learned and how efficient the learned policies will be. This is an open theoretical challenge, as planning problems are generally PSPACE-hard with respect to the state space size. 

Proposed Solution:
The paper presents a circuit complexity analysis for relational neural networks (RNNs) representing policies for planning problems. It draws connections with serialized goal regression search (S-GRS), a backward search algorithm. Based on the regression width of planning problems, three general complexity classes are identified:

1. Problems with constant SOS (strong optimally serializable) width: RNN policies with constant breadth and depth can be constructed. Examples include Blocks World and Logistics.

2. Problems with constant but non-SOS width: RNN policies with constant breadth but unbounded depth can be constructed. Examples include path finding in acyclic graphs. 

3. Problems without constant width bounds: RNN policies require unbounded breadth. Examples include Sokoban and general TAMP problems.

For the first two cases, the paper gives algorithms to compile planning problems directly into goal-conditioned RNN policy circuits. The complexity of these networks aligns with the theoretical analysis. For learnability, policy gradient methods can be used to learn such policies from environment interactions.

Main Contributions:
- Identified connection between regression width of planning problems and circuit complexity of policies
- Provided complexity classes for policies, gave constructive proofs in the form of compilation algorithms
- Demonstrated the utility of this analysis for designing neural network policies
- Provided insights into why certain planning problems like Sokoban are hard for fixed-sized RNN policies

The key insight is that for object-centric domains with relational structure and sparse transition models, there exist simple generalized goal regression rules that can be serialized and solved efficiently. This enables constructing compact RNN policy circuits.
