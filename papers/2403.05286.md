# [LLM4Decompile: Decompiling Binary Code with Large Language Models](https://arxiv.org/abs/2403.05286)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "LLM4Decompile: Decompiling Binary Code with Large Language Models":

Problem:
- Decompilation aims to convert compiled machine code/bytecode back to human-readable source code. It struggles to recreate finer details like variable names and high-level structures like loops and conditionals, which are lost during compilation.
- Existing decompilers like IDA Pro and Ghidra rely on handcrafted rules and patterns, which are laborious to build and have limited coverage. Their output is often not human-readable.
- Recent advances in large language models (LLMs) for coding tasks motivate their application for decompilation. However, existing models are small (<1B parameters) and not publicly available, limiting progress. 
- There is also no standard decompilation benchmark focused on generating usable and robust code, as existing metrics like BLEU simply measure surface similarity.

Proposed Solution:
- Release the first open-source decompilation LLMs ranging from 1B to 33B parameters, pre-trained on 4 billion tokens of C source and assembly code pairs.
- Introduce Decompile-Eval, the first decompilation benchmark that tests if the decompiled code can recompile and re-execute correctly using the original test cases. This evaluates syntax recovery and semantic preservation.

Contributions:
- Provide the first open-source LLMs tailored for decompilation to serve as baselines for further research.
- Construct the first decompilation benchmark focused on re-compilability and re-executability rather than superficial similarity.
- Experiments show the 6B LLM4Decompile model can decompile 21% of assembly code to pass test cases, achieving 50% higher accuracy than GPT-4.
- The benchmark and analyses represent an encouraging first step toward data-driven decompilation.

In summary, the paper releases new open-source assets to facilitate decompilation research and establishes a practical benchmark to motivate future progress. The presented experiments demonstrate promising capabilities of data-driven techniques for this complex problem.
