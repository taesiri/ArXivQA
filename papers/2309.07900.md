# [Ambiguity-Aware In-Context Learning with Large Language Models](https://arxiv.org/abs/2309.07900)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is:

Whether considering the language model's existing knowledge about the task, especially with respect to the output label space, can help in selecting more effective in-context learning (ICL) demonstrations? 

The key hypothesis is that it is beneficial to not only choose semantically similar ICL demonstrations based on input text, but also to choose those demonstrations that help resolve the inherent label ambiguity surrounding the test example.

The authors explore this by proposing methods to select ICL demonstrations that consider:

1) The label ambiguity of the test example, identifying top ambiguous labels the model is confused about 

2) Limiting demonstrations to those previously misclassified by the model

3) Considering the label ambiguity of the training examples used for demonstrations

By incrementally adding these constraints that leverage the model's predictions, they aim to test the hypothesis that this knowledge about the label space leads to better demonstration selection and downstream model performance on classification tasks.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a method to select better in-context learning (ICL) demonstrations for large language models (LLMs) by leveraging the model's existing knowledge about the task. Specifically:

- They hypothesize that in addition to semantic similarity, considering the model's knowledge about the label space can help select more effective demonstrations. 

- They propose to identify the "ambiguous label set" for each test example based on the model's likelihood scores, which captures label confusion.

- They select demonstrations whose labels are in this ambiguous set, are misclassified by the model, and whose predicted labels are also in the ambiguous set. 

- Through experiments on text classification, they show their proposed method outperforms strong baselines like retriever-based selection, especially for smaller LLM sizes.

- They analyze that the ambiguous label set acts as a good proxy for the true label, which helps guide the model. Misclassified examples on the decision boundary are also useful.

- Overall, the key ideas are leveraging the model's predictions on both the test example and demonstrations to extract signals about label space confusion, in order to select better ICL prompts.

In summary, the main contribution is a new demonstration selection method for ICL that considers both semantic similarity and the model's existing knowledge about the task label space.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a method to select better in-context learning demonstrations for language models by considering the model's existing knowledge and confusion about the task, rather than just semantic similarity between the examples.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other related research:

- It focuses on in-context learning (ICL) with large language models (LLMs), which is an increasingly popular research area as LLMs grow in size and capability. Many recent works have explored techniques to improve ICL performance.

- The core idea is to leverage the LLM's existing knowledge about a task, in terms of its predictions and uncertainties, to select better ICL demonstrations. This goes beyond just using semantic similarity of inputs. Other works have looked at the training labels or model scores, but not jointly.

- For demonstration selection, it builds on prior work using semantic similarity between test input and candidates. But it adds constraints based on the LLM's predictions to pick harder, more useful examples. This is a novel technique of using the model's predictions.

- Experiments are done on classification tasks with fine-grained labels, where ambiguity is likely. Most prior work focuses on coarse-grained tasks like sentiment analysis. Testing on more subtle distinctions evaluates the proposed techniques better.

- Gains are shown from adding constraints incrementally, indicating their individual benefits. Other works tend to evaluate a single demonstration selection strategy. The breakdown provides more analysis.

- Analysis shows the ambiguous label set acts as a proxy for the true label, explaining the technique's efficacy. Such analysis into why the proposed methods work is rare in related literature.

Overall, this paper presents an original technique of leveraging LLM predictions for better ICL, with extensive experiments and analysis on fine-grained classification. The analysis into model ambiguity and usefulness of demonstrations enhances understanding of effective ICL.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors are:

- Expanding the ambiguous label set to more than two labels for datasets like GoEmotions that have a large and fine-grained label space. The authors mention that considering more than just the top 2 ambiguous labels could be more beneficial in these cases. 

- Applying the techniques to other tasks beyond sentence classification, such as token/span-level tasks like named entity recognition and part-of-speech tagging. The authors propose their methods could be adapted to incorporate label ambiguity at the token level for these tasks.

- Using a task-specific retriever rather than just an off-the-shelf one. The authors expect their methods would also benefit from a retriever tailored to the specific task, versus the general retriever they used.

- Combining their techniques with other complementary methods like chain-of-thought prompting or ordering demonstrations. The authors mention their methods are orthogonal to things like prompt ordering and could be used together.

- Further analysis into why the ambiguous label set acts as a good proxy for the true label, and how the model biases its predictions based on labels paired with demonstrations. More investigation into the dynamics of how the model makes predictions based on the demonstrations.

In summary, the key future directions focus on applying the core ideas to other tasks and settings, combining the methods with complementary techniques, and better understanding the underlying reasons why their methods are effective through further analysis. The authors propose several interesting ways to build on this work around ambiguity-aware prompt engineering.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper proposes a new method for selecting effective in-context learning (ICL) demonstrations for large language models (LLMs). The key idea is to leverage the LLM's existing knowledge and ambiguity surrounding the output label space for both the test example and candidate training examples. Specifically, they first use a text retriever to find semantically similar examples from the training set for each test input. Then they identify the top 2 most likely but ambiguous output labels for the test input based on the LLM's predictions. They select demonstrations whose ground truth label falls in this ambiguous label set, especially those that were previously misclassified by the LLM but have a predicted label from the ambiguous set. By applying these constraints, they are able to select more useful demonstrations that help resolve the LLM's confusion on the test example. They show consistent gains over retriever-based selection across three text classification tasks. The method is most beneficial for smaller LLM models which have more ambiguity. Overall, the work demonstrates the importance of considering the LLM's existing knowledge about label space when selecting ICL demonstrations.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper explores how the existing knowledge of large language models (LLMs) can be leveraged to select better demonstrations for in-context learning (ICL). ICL involves conditioning LLMs on a few task-specific examples to perform a task, without any fine-tuning. The authors hypothesize that considering the LLM's knowledge about the task label space can help select more effective demonstrations beyond just using semantic similarity of the input text. 

To test this, they propose constraints to select ICL demonstrations that help resolve label ambiguity surrounding the test example. Specifically, they identify the top 2 labels the LLM is most confused about for the test input, referred to as the "ambiguous label set". Then they select demonstrations from semantically similar examples whose ground truth labels are in this set. Further, they select examples misclassified by the model but with predictions in the ambiguous label set. Through experiments on text classification datasets, they find that incrementally adding these constraints leads to improved performance over retriever-based selection. The ambiguous label set acts as a good proxy for the true label, allowing demonstrations to guide the model. The method works better for smaller LLM, showing it compensates for less capability.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes a method to select good demonstrations for in-context learning (ICL) with large language models (LLMs). The key idea is to leverage the LLM's existing knowledge about the task to select demonstrations that help resolve label ambiguity surrounding the test example. First, for each test example, semantically similar examples are retrieved from the training data using a text retriever. Next, the ambiguous label set (top 2 likely labels) is identified for the test example using the LLM's predictions. The retrieved examples are then filtered to only keep those whose ground truth label is in the ambiguous label set. Further, only misclassified examples are kept whose predicted label also lies in the ambiguous label set. This results in demonstrations that help resolve label confusion and guide the LLM to the correct prediction. The method is evaluated on three text classification tasks and found to outperform baselines that use only semantic similarity for demonstration selection.


## What problem or question is the paper addressing?

 Based on my reading, the key points of this paper are:

- The paper aims to investigate whether leveraging a language model's (LLM's) existing knowledge about a task can help select better in-context learning (ICL) demonstrations. 

- Prior work has shown that retrieving semantically similar examples as ICL demonstrations leads to good performance. However, this solely focuses on input text similarity and does not consider the LLM's knowledge about the output label space. 

- The authors hypothesize that considering the LLM's existing knowledge and ambiguity surrounding the output labels for both test examples and ICL demonstrations can lead to better prompt engineering.

- They propose methods to identify the top ambiguous labels the LLM is confused about for a test example, and constrain ICL demonstrations to only those that help resolve this ambiguity.

- Through experiments on text classification tasks, they find that their proposed methods which leverage output label space outperform semantic similarity based demonstration selection.

- Key findings are: considering label ambiguity is as important as input similarity, their methods help more for smaller LLM models, and the ambiguous label set acts as a good proxy for the true test label.

In summary, the key research question is whether existing LLM knowledge about the output label space can be used to select even better ICL demonstrations beyond just input text similarity. The paper provides evidence this is indeed effective across multiple text classification datasets.
