# [OT-Attack: Enhancing Adversarial Transferability of Vision-Language   Models via Optimal Transport Optimization](https://arxiv.org/abs/2312.04403)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel adversarial attack method called OT-Attack that enhances the transferability of adversarial examples against vision-language models. The key insight is that prior attacks like SGA fail to optimally align augmented image sets with text sets, leading to overfitting on the source model. OT-Attack addresses this by treating image and text features as distinct distributions and leveraging optimal transport theory to derive the optimal mapping between them, which guides adversarial example generation. Specifically, it uses similarity as the cost matrix and computes the total transfer cost between distributions via Sinkhorn optimization. Experiments across models like ALBEF, TCL, and CLIP on image-text retrieval using Flickr30K and MSCOCO show OT-Attack achieves new state-of-the-art attack transferability. The method also demonstrates strong cross-task transferability on image captioning and visual grounding. Notably, OT-Attack can successfully attack commercial systems like GPT-4 and Bing Chat. Overall, the paper makes significant contributions in advancing adversarial attacks against vision-language models by optimally integrating data augmentation, modality alignment, and optimal transport theory for superior transferability. The results underscore vulnerabilities of advanced AI systems to such sophisticated attacks.
