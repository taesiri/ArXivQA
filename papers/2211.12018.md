# [Level-S$^2$fM: Structure from Motion on Neural Level Set of Implicit   Surfaces](https://arxiv.org/abs/2211.12018)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is: How can we optimize a neural SDF (or other neural fields such as NeRF) from only a set of uncalibrated images without any 3D information?The paper focuses on exploring ways to integrate neural implicit surface representations like SDFs into the incremental Structure from Motion (SfM) pipeline. Specifically, it looks at how to tackle the challenges of optimizing neural SDFs with only two-view or few-view image inputs, which is common in incremental SfM systems. The key ideas proposed are:- Using 2D correspondences to provide inductive biases to make two-view and few-view optimization of neural SDFs possible.- Renewing key SfM components like two-view geometry initialization, camera pose registration, 3D point triangulation, and bundle adjustment to work with neural SDF representations.- Unifying scene geometry in a neural SDF to provide a top-down regularization and enable outlier rejection, point management, and geometry refinement in SfM.Through these ideas, the paper aims to present the first fully implicit neural SfM approach as well as a way to do neural implicit rendering without knowing camera poses a priori. The experiments evaluate the proposed method's performance on camera pose estimation, scene geometry reconstruction, and view synthesis across different datasets.In summary, the central research question is how to optimize neural implicit surface representations from uncalibrated image sets in an incremental SfM setting, which requires tackling two-view and few-view optimization challenges. The key ideas involve using 2D correspondences as inductive biases and reformulating the SfM pipeline.


## What is the main contribution of this paper?

This paper presents a novel neural incremental Structure-from-Motion (SfM) approach called Level-S$^2$fM, which estimates camera poses and scene geometry from uncalibrated images by learning coordinate MLPs for implicit surfaces and radiance fields. The main contributions are:1. Level-S$^2$fM is the first implicit neural SfM solution that represents the scene geometry as the zero-level set of an implicit surface parameterized by MLPs.2. It shows that challenging problems of two-view and few-view optimization of neural implicit fields can be addressed by exploiting inductive biases conveyed in 2D correspondences. This also enables neural implicit rendering without knowing camera extrinsics.3. It revisits the incremental SfM pipeline and renews key components like two-view initialization, camera registration, points triangulation, and bundle adjustment based on implicit neural representations. 4. It unifies scene geometry in a top-down manner with MLPs and uses the implicit surface as regularization to manage reconstructed points, reject outliers, and refine geometry.5. Experiments show Level-S$^2$fM outperforms traditional SfM by large margins in pose accuracy and geometry reconstruction on the BlendedMVS dataset while achieving on-par results on DTU and ETH3D datasets.In summary, the main contribution is a novel neural SfM approach that represents scenes with implicit neural surfaces and shows promising ways to optimize neural fields from only images by exploiting 2D correspondences. This also sets new state-of-the-art for incremental SfM.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper presents a new neural structure from motion (SfM) approach called Level-S$^2$fM that optimizes coordinate MLPs to represent implicit surfaces and radiance fields from 2D keypoint correspondences across uncalibrated images, enabling joint estimation of camera poses and scene geometry in an incremental SfM pipeline.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in the field of Structure from Motion (SfM):- This paper presents a novel neural network-based approach for SfM called Level-S^2fM. Most prior work in SfM uses traditional computer vision techniques and does not leverage neural networks. This paper explores using neural implicit surfaces and radiance fields for SfM, which is a relatively new approach.- Many recent papers have looked at integrating deep learning into specific components of the SfM pipeline, like feature matching, pose estimation, etc. However, this paper proposes an end-to-end learned SfM system based on neural representations. Few other works have formulated SfM in this holistic neural framework.- A key contribution is handling SfM from only uncalibrated images without known camera poses or 3D data. Most learning-based SfM methods require some poses or 3D supervision. This paper shows how to optimize neural implicit surfaces directly from only 2D matches and images.- The proposed method is evaluated on standard SfM datasets like BlendedMVS and shown to outperform traditional SfM pipelines like COLMAP. Comparisons to other learning-based SfM methods are limited since there are not many comparable end-to-end learned systems.- For neural scene representations, this paper builds on top of recent work like NeRF and VolSDF but adapts these methods to the incremental SfM setting. The differentiable sphere tracing used is also novel in the context of SfM.In summary, this paper pushes SfM in a more end-to-end deep learning direction compared to prior work, while handling uncalibrated images in a way few other learning-based SfM approaches have shown. The comparisons are mainly to traditional SfM pipelines, suggesting avenues for future comparisons to other learning techniques.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Exploring different sequence order selection strategies for incremental reconstruction in SfM. The paper uses a simple next best view selection method based on number of 3D-2D pairs, but mentions this could likely be improved.- Using more robust deep learning-based 2D matching methods to handle challenging cases like textureless regions where traditional SIFT matching struggles. This could alleviate issues like insufficient matches that caused problems in some of their experiments.- Trying second-order optimizers like Levenberg-Marquardt or Gauss-Newton instead of Adam for optimizing the pose and geometry networks. The authors note Adam was sometimes unstable and think these methods could help.- Extending the method to larger scenes by using techniques like dividing into sub-regions or using multiple implicit field networks. A single network struggled to represent very large scenes well.- Incorporating uncertainty quantification into the optimization process. The authors suggest probabilistic formulations could help make the optimization more robust.- Exploring the use of depth sensors or multi-view stereo datasets to provide additional shape cues and make the method work in challenging sparse imagery cases.Overall, the main directions seem to be around improving the robustness in difficult cases by using better learning-based techniques for matching and optimization, as well as scaling up the approach to handle larger scenes. The authors propose several interesting ways this could be achieved based on the limitations they observed.
