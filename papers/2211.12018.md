# [Level-S$^2$fM: Structure from Motion on Neural Level Set of Implicit   Surfaces](https://arxiv.org/abs/2211.12018)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper aims to address is: 

How can we optimize a neural SDF (or other neural fields such as NeRF) from only a set of uncalibrated images without any 3D information?

The paper focuses on exploring ways to integrate neural implicit surface representations like SDFs into the incremental Structure from Motion (SfM) pipeline. Specifically, it looks at how to tackle the challenges of optimizing neural SDFs with only two-view or few-view image inputs, which is common in incremental SfM systems. 

The key ideas proposed are:

- Using 2D correspondences to provide inductive biases to make two-view and few-view optimization of neural SDFs possible.

- Renewing key SfM components like two-view geometry initialization, camera pose registration, 3D point triangulation, and bundle adjustment to work with neural SDF representations.

- Unifying scene geometry in a neural SDF to provide a top-down regularization and enable outlier rejection, point management, and geometry refinement in SfM.

Through these ideas, the paper aims to present the first fully implicit neural SfM approach as well as a way to do neural implicit rendering without knowing camera poses a priori. The experiments evaluate the proposed method's performance on camera pose estimation, scene geometry reconstruction, and view synthesis across different datasets.

In summary, the central research question is how to optimize neural implicit surface representations from uncalibrated image sets in an incremental SfM setting, which requires tackling two-view and few-view optimization challenges. The key ideas involve using 2D correspondences as inductive biases and reformulating the SfM pipeline.


## What is the main contribution of this paper?

 This paper presents a novel neural incremental Structure-from-Motion (SfM) approach called Level-S$^2$fM, which estimates camera poses and scene geometry from uncalibrated images by learning coordinate MLPs for implicit surfaces and radiance fields. 

The main contributions are:

1. Level-S$^2$fM is the first implicit neural SfM solution that represents the scene geometry as the zero-level set of an implicit surface parameterized by MLPs.

2. It shows that challenging problems of two-view and few-view optimization of neural implicit fields can be addressed by exploiting inductive biases conveyed in 2D correspondences. This also enables neural implicit rendering without knowing camera extrinsics.

3. It revisits the incremental SfM pipeline and renews key components like two-view initialization, camera registration, points triangulation, and bundle adjustment based on implicit neural representations. 

4. It unifies scene geometry in a top-down manner with MLPs and uses the implicit surface as regularization to manage reconstructed points, reject outliers, and refine geometry.

5. Experiments show Level-S$^2$fM outperforms traditional SfM by large margins in pose accuracy and geometry reconstruction on the BlendedMVS dataset while achieving on-par results on DTU and ETH3D datasets.

In summary, the main contribution is a novel neural SfM approach that represents scenes with implicit neural surfaces and shows promising ways to optimize neural fields from only images by exploiting 2D correspondences. This also sets new state-of-the-art for incremental SfM.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence TL;DR summary of the paper:

The paper presents a new neural structure from motion (SfM) approach called Level-S$^2$fM that optimizes coordinate MLPs to represent implicit surfaces and radiance fields from 2D keypoint correspondences across uncalibrated images, enabling joint estimation of camera poses and scene geometry in an incremental SfM pipeline.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other research in the field of Structure from Motion (SfM):

- This paper presents a novel neural network-based approach for SfM called Level-S^2fM. Most prior work in SfM uses traditional computer vision techniques and does not leverage neural networks. This paper explores using neural implicit surfaces and radiance fields for SfM, which is a relatively new approach.

- Many recent papers have looked at integrating deep learning into specific components of the SfM pipeline, like feature matching, pose estimation, etc. However, this paper proposes an end-to-end learned SfM system based on neural representations. Few other works have formulated SfM in this holistic neural framework.

- A key contribution is handling SfM from only uncalibrated images without known camera poses or 3D data. Most learning-based SfM methods require some poses or 3D supervision. This paper shows how to optimize neural implicit surfaces directly from only 2D matches and images.

- The proposed method is evaluated on standard SfM datasets like BlendedMVS and shown to outperform traditional SfM pipelines like COLMAP. Comparisons to other learning-based SfM methods are limited since there are not many comparable end-to-end learned systems.

- For neural scene representations, this paper builds on top of recent work like NeRF and VolSDF but adapts these methods to the incremental SfM setting. The differentiable sphere tracing used is also novel in the context of SfM.

In summary, this paper pushes SfM in a more end-to-end deep learning direction compared to prior work, while handling uncalibrated images in a way few other learning-based SfM approaches have shown. The comparisons are mainly to traditional SfM pipelines, suggesting avenues for future comparisons to other learning techniques.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Exploring different sequence order selection strategies for incremental reconstruction in SfM. The paper uses a simple next best view selection method based on number of 3D-2D pairs, but mentions this could likely be improved.

- Using more robust deep learning-based 2D matching methods to handle challenging cases like textureless regions where traditional SIFT matching struggles. This could alleviate issues like insufficient matches that caused problems in some of their experiments.

- Trying second-order optimizers like Levenberg-Marquardt or Gauss-Newton instead of Adam for optimizing the pose and geometry networks. The authors note Adam was sometimes unstable and think these methods could help.

- Extending the method to larger scenes by using techniques like dividing into sub-regions or using multiple implicit field networks. A single network struggled to represent very large scenes well.

- Incorporating uncertainty quantification into the optimization process. The authors suggest probabilistic formulations could help make the optimization more robust.

- Exploring the use of depth sensors or multi-view stereo datasets to provide additional shape cues and make the method work in challenging sparse imagery cases.

Overall, the main directions seem to be around improving the robustness in difficult cases by using better learning-based techniques for matching and optimization, as well as scaling up the approach to handle larger scenes. The authors propose several interesting ways this could be achieved based on the limitations they observed.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points from the paper:

The paper presents a neural incremental Structure-from-Motion (SfM) approach called Level-S$^2$fM, which estimates camera poses and scene geometry from a set of uncalibrated images. It does this by learning coordinate MLPs to represent implicit surfaces and radiance fields, using 2D keypoint correspondences across images to drive the optimization. Key challenges addressed include the two-view and few-view configurations inherent in incremental SfM, which complicate optimizing MLPs for neural rendering with unknown poses. The paper shows strong inductive biases from 2D matches can tackle these problems through relating ray sampling schemes. Based on this, the method revisits incremental SfM to renew key components like two-view initialization, camera registration, points triangulation, and bundle adjustment using neural implicit surfaces. Experiments demonstrate improved camera pose and geometry estimation over traditional SfM, setting a new state-of-the-art on the BlendedMVS dataset. The unified optimization of neural scene representations and SfM from only images is a promising direction for advancing both implicit neural rendering and 3D reconstruction.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper presents a neural incremental Structure-from-Motion (SfM) approach called Level-S2fM, which estimates camera poses and scene geometry from a set of uncalibrated images. The key idea is to learn coordinate MLP networks to represent implicit surfaces and radiance fields, using the established keypoint correspondences across images as supervision. This allows imposing continuous surface priors to facilitate outlier rejection and improve reconstruction accuracy. A main challenge is optimizing the MLPs from only two initial views and incrementally registering new views with very limited overlap during SfM, unlike most prior works on neural fields that assume many densely sampled views with known poses. The paper shows that strong inductive biases from sparse 2D matches can drive successful optimization in this underconstrained setting. 

The method renews standard SfM pipeline components like two-view initialization, incremental pose estimation, triangulation, and bundle adjustment to operate on the implicit neural level sets. This unifies the scene geometry in a compact MLP network, enabling more globally consistent reasoning. Experiments on benchmark datasets demonstrate significant improvements over traditional SfM, reducing average rotation error by 55% on one dataset. The implicit surface formulation also naturally handles outlier rejection and continuous optimization better than prior sparse point-based SfM. The method also provides a promising way to achieve neural rendering without known camera poses.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper presents a neural incremental Structure-from-Motion (SfM) approach called Level-S2fM, which estimates camera poses and scene geometry from a set of uncalibrated images. The method uses coordinate MLP networks to represent implicit surfaces and radiance fields. It formulates the SfM problem as jointly optimizing these neural networks alongside estimating camera poses and scene points. The core components in Level-S2fM include two-view geometry initialization, new frame registration, points triangulation, and a Neural Bundle Adjustment method. The two-view initialization step traces 3D points from 2D keypoints using differentiable sphere tracing and computes losses like reprojection error to optimize the networks. New frames are registered using PnP algorithms and refined with rendering and reprojection losses. Points triangulation and outlier rejection are done by leveraging the global surface priors from the implicit neural networks. Neural Bundle Adjustment refines all estimated variables by moving points to the closest surface and minimizing reprojection error. Overall, Level-S2fM renews key parts of SfM with implicit neural representations to integrate top-down surface priors.


## What problem or question is the paper addressing?

 Based on my reading, the key points about the problem and questions addressed in this paper are:

- The paper focuses on the problem of Structure-from-Motion (SfM), which aims to reconstruct 3D scenes and estimate camera motions from a set of uncalibrated images. 

- Existing SfM methods rely on bottom-up feature correspondences across images and lack top-down scene understanding, leading to issues like flying 3D points as shown in Figure 1. 

- The paper proposes to integrate top-down information into SfM using neural implicit surfaces represented by MLPs. The key question is: how to optimize the neural SDF and camera poses jointly from only uncalibrated images without any 3D supervision?

- Previous methods like BARF and NeRF-- can optimize neural radiance fields without known poses but only work for small forward-facing scenes. The paper aims to tackle more general scenes in an incremental SfM pipeline.

- The main challenges are optimizing the neural field from only two views during initialization and from few views when adding new frames incrementally. 

- The paper shows that strong inductive biases from 2D matches can help address these challenges and enable joint optimization of neural implicit surface, radiance field and camera poses for SfM from scratch.

In summary, the key problem is integrating top-down neural scene representations into incremental SfM using only uncalibrated images, and the main questions are how to effectively optimize the neural fields and camera poses jointly under two-view and few-view settings inherent in SfM pipelines.
