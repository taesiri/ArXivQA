# [A Distributionally Robust Optimisation Approach to Fair Credit Scoring](https://arxiv.org/abs/2402.01811)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Credit scoring models can exhibit unfair bias against certain demographic groups, which is an important ethical issue. 
- Many existing techniques to enhance fairness may fail to maintain fairness on out-of-sample data due to distributional shifts over time.

Proposed Solution:  
- Use distributionally robust optimization (DRO) to make the model robust against distributional shifts while enhancing fairness. DRO works by optimizing the worst-case over a set of plausible neighboring distributions rather than just the empirical distribution.

- Specifically, they propose a distributionally robust fair logistic regression (DRFLR) which includes a fairness penalty term and constructs an ambiguity set using the Wasserstein metric to account for distributional shifts. 

- The Wasserstein ambiguity set allows controlling the relative importance given to shifts in sensitive attributes vs other features. Additional hyperparameters also control tradeoffs between performance, fairness and robustness.

Key Contributions:
- First application of DRO with fairness constraints to credit scoring.
- Empirical evaluation on 5 credit scoring datasets shows DRFLR substantially enhances fairness according to the LEO metric, with minimal impact on predictive performance.
- Analysis and guidelines provided for tuning the various DRFLR hyperparameters.
- Highlights issues with common fairness metrics like statistical parity that depend on choice of threshold.
- Experiments with shifting marginal distributions demonstrate improved robustness of DRFLR to such distributional shifts.

Overall, the paper makes a strong case that DRO is a promising approach for fair and robust credit scoring models, while also laying out useful practical guidance and insights for further research to address existing limitations.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

This paper investigates applying distributionally robust optimization with fairness constraints to credit scoring to enhance fairness empirically, finding it provides substantial improvement in fairness with almost no loss in performance, although further advances in efficiently implementing these systems are still needed.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1) Empirically evaluating how distributionally robust optimization (DRO) methods perform in terms of fairness, ability to classify correctly, and robustness against changes in marginal proportions when applied to credit scoring.

2) Finding that DRO methods provide substantial improvement in fairness terms, with almost no loss in performance compared to standard and regularized logistic regression. This indicates DRO can improve fairness in credit scoring if implemented efficiently.  

3) Analyzing commonly used fairness metrics and suggesting they are unsuitable for credit scoring as they depend on the choice of classification threshold. The paper proposes an alternative metric called Log Probabilistic Equalized Opportunities (LEO) that does not have this issue.

4) Providing guidance for credit scorers on the practical modeling aspects and effects of the various hyperparameters when using DRO for fair credit scoring.

In summary, the main contribution is an empirical evaluation demonstrating the potential of DRO methods to improve fairness in credit scoring applications, if computational complexities can be overcome. The paper also provides useful insights and guidance around evaluating and tuning fair DRO classifiers.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with it are:

- Credit scoring - The paper focuses on applying the methods to credit scoring and loan default prediction.

- Fairness - A major focus of the paper is on enhancing fairness and reducing unfair bias against certain demographic groups in credit scoring models.

- Distributionally robust optimization (DRO) - The paper proposes using DRO methods to make credit scoring models more robust and fair.

- Logistic regression - Logistic regression is the main classification method used. The paper compares regular logistic regression to distributionally robust logistic regression.

- Equalized odds - A relaxation of this fairness metric is used as the measure of unfairness that the models try to reduce. 

- Separation measures - The paper uses fairness measures based on the concept of separation, which requires equalized performance metrics between groups.

- Out-of-sample robustness - The paper argues DRO can improve the robustness and fairness of models on out-of-sample data collected after model development.

- Wasserstein metric - This metric is used to define the ambiguity sets in the distributionally robust optimization formulations.

So in summary, the key terms cover credit scoring, fairness, distributional robustness, logistic regression, and metrics related to both predictive performance and fairness constraints.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. The paper argues that distributionally robust optimization (DRO) can enhance fairness in credit scoring models. However, implementing DRO has high computational costs. What are some ways the computational efficiency of DRO could be improved to make it more applicable for real-world credit scoring situations?

2. The Wasserstein metric is used to define the ambiguity set in the DRO formulation. What are the specific advantages of using the Wasserstein metric over other metrics like Kullback-Leibler divergence in this credit scoring application? 

3. The ground metric used incorporates separate transportation costs kappa_s and kappa_y for the sensitive attribute and outcome variable. How sensitive are the results to different settings of these hyperparameter values? What guidelines should be followed in setting them?

4. The paper evaluates performance using AUC, LEO, and SP metrics. What are the relative advantages and disadvantages of each metric, especially in the context of credit scoring? Why might SP be less suitable than LEO?

5. Distributional robustness is argued to have connections to improved fairness. What might the underlying reasons be? Does incorporating distributional robustness directly target and help resolve certain sources of algorithmic unfairness?  

6. The formulation uses a convex relaxation of an equalized odds fairness constraint. How tight is this relaxation and could a different relaxation provide even better performance?

7. Fig. 5 shows the robust methods are more stable under shifts in marginal distributions. What other types of distribution shifts should be evaluated? Would the relative performance of methods differ?

8. Hyperparameter tuning shows very low kappa_y values optimize LEO while hurting ROC. How should this tradeoff be balanced in practice? What should the guidelines be?

9. The paper argues DRO should be preferred to heuristic regularization techniques like ridge/lasso. What are some specific benefits seen in the credit scoring application by taking a DRO approach?

10. The DRO formulation could be extended to also robustify against uncertainty in proxy variables. What would be an appropriate way to model this? How much improvement in fairness could be expected by doing this?
