# [A Theory of Unimodal Bias in Multimodal Learning](https://arxiv.org/abs/2312.00935)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Multimodal neural networks that combine multiple data inputs (e.g. vision+text) are challenging to train effectively. A key issue is "unimodal bias", where networks overly rely on one input modality and ignore others.
- Unimodal bias is a well known issue but there is little theoretical understanding of what causes it or how it depends on architectures and datasets.

Main Contributions:  
- The paper develops a theoretical analysis of unimodal bias in deep multimodal linear networks, focusing on common architectures with early, intermediate and late fusion layers.

- It is shown that unimodal bias (long duration learning only one modality first) arises in intermediate and late fusion but not early fusion architectures. The depth of the fusion layer is a key factor determining the bias.

- Analytical expressions are derived that relate the "unimodal phase duration" to the network depth, fusion layer depth, correlations between modalities, and input-output correlations. Key results are deeper fusion layers and higher input correlations prolong the unimodal bias phase.  

- The theory reveals the first modality learned is based on a "superficial preference" for the faster modality rather than the more informative modality. Conditions are given where this occurs.

- Simulation results on deep linear networks validate the analysis. Results also extend well to two-layer ReLU nets for linear tasks. The theory gives insights into architectural choices for multimodal learning.

Overall, this provides the first analytical characterization of unimodal bias in multimodal deep learning, relating it to depth, correlations and architecture. The results aim to provide insights to guide more effective multimodal algorithms.
