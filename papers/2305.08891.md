# [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/abs/2305.08891)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we ensure consistency between the training and inference behavior of diffusion models, so they can generate samples across the full range of brightness levels?The key hypotheses appear to be:1) Common diffusion noise schedules and sampling implementations have flaws that cause a discrepancy between training and inference. Specifically:- Noise schedules do not enforce zero signal-to-noise ratio (SNR) at the last timestep. This causes signal leakage during training.- Samplers do not always start from the last timestep. This exposes models to nonzero SNR inputs at inference. 2) Aligning the training and inference by enforcing zero terminal SNR, using v prediction, sampling from the last timestep, and rescaling classifier-free guidance will allow models to generate the full range of brightness.So in summary, the central research question is how to make diffusion training and inference congruent so models can generate samples with diverse brightness levels. The hypotheses are that common schedules and samplers have flaws, and fixing them will solve the problem.


## What is the main contribution of this paper?

The main contribution of this paper is identifying and fixing flaws in common diffusion noise schedules and sampling implementations that cause a discrepancy between training and inference. Specifically:- The paper points out that common noise schedules like linear, cosine, and the schedule used in Stable Diffusion do not enforce zero signal-to-noise ratio (SNR) at the last timestep. This causes some signal information to leak to the model during training, while at inference the model gets pure noise. - The paper proposes rescaling existing schedules to ensure zero terminal SNR, which aligns the training and inference distributions.- The paper highlights that many sampling implementations like DDIM and PNDM do not properly start from the last timestep, further contributing to the discrepancy. The paper advocates always sampling from the last step.- To counter image over-exposure from a zero SNR schedule, the paper proposes a simple rescaling method for classifier-free guidance.- The paper shows both qualitatively and quantitatively that these fixes allow models to generate samples with a full range of brightness as opposed to just medium brightness, and that the samples better match the true data distribution.In summary, the main contribution is identifying flaws in existing diffusion training and sampling methods, and proposing simple fixes to align the behavior between training and inference. This results in improved sample quality and diversity.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper discovers flaws in common diffusion model training procedures, namely noise schedules that leak signal and samplers that don't start from the last timestep, and proposes fixes like rescaling schedules to zero SNR, using v prediction, always sampling from the last step, and rescaling classifier guidance to enable models to generate the full range of brightness.
