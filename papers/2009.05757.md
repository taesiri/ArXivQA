# [Enhancing Unsupervised Video Representation Learning by Decoupling the   Scene and the Motion](https://arxiv.org/abs/2009.05757)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research question this paper aims to tackle is:How to alleviate the "scene-dominated bias" in video representation learning, so that the learned representations are more sensitive to motion patterns rather than just static scene context. The authors motivate this question by showing that for some action categories in current video datasets, models can recognize them just from static backgrounds without looking at the motions. This indicates the models are relying too much on scene context rather than learning distinctive motion patterns. To address this issue, the central hypothesis of the paper is:By explicitly decoupling the scene and motion information during self-supervised pre-training, through specific data augmentation strategies, the model can learn representations that are more sensitive to temporal motion patterns and less biased by static scene context.In summary, the key research question is how to reduce scene bias and enhance motion modeling in video representation learning. The central hypothesis is that by decoupling scene and motion via data augmentations during self-supervised pre-training, the model can learn representations that focus more on distinctive motions rather than just scene context.
