# [Seeing the World through Your Eyes](https://arxiv.org/abs/2306.09348)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:Can we reconstruct a 3D scene of the world observed by a person, using only reflections from their eyes captured in a monocular image sequence?The key hypothesis is that by capturing multiple images of a person's eyes as they move their head naturally, the eye reflections will provide sufficient multi-view information to allow reconstructing the 3D scene beyond the camera's line of sight using a neural radiance field approach. The paper aims to demonstrate the feasibility of this idea and introduces techniques like joint optimization of eye poses and iris texture decomposition to address the challenges unique to using eye reflections as input.In summary, the core goal is 3D scene reconstruction from eye reflections in monocular video, which requires addressing factors like noisy eye localization, intricate iris textures, and low-resolution reflections. The central hypothesis is that with proper handling of these challenges, the eye reflections can enable reasonable 3D scene reconstruction.


## What is the main contribution of this paper?

The main contribution of this paper is developing a method to reconstruct 3D scenes from eye reflections in portrait images. Specifically:- They propose a novel approach to use neural radiance fields (NeRF) to model the 3D scene reflected in a person's eyes, by tracing reflected rays off the cornea surface. - They introduce a texture decomposition technique to separate the iris texture from the scene reflection, using a learnt 2D texture field and a radial regularization loss.- They develop a cornea pose refinement procedure to improve the noisy cornea pose estimates caused by the small eye region size. - They create a synthetic eye reflection dataset for method validation.- They demonstrate reconstructing real-world scenes from eye reflections through experiments on captured portraits of different people/eye colors.In summary, the key contribution is enabling 3D scene reconstruction beyond the camera's line of sight by leveraging subtle eye reflections, via tailored techniques like texture decomposition and pose refinement to handle challenges unique to using eye images as input. This opens up new possibilities for recovering 3D scenes from accidental reflections.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The paper presents a method to reconstruct a 3D scene from a sequence of eye images capturing reflections. The key ideas are jointly optimizing the radiance field, iris texture, and cornea poses to overcome challenges like noisy cornea localization and complex iris patterns. The main takeaway is that eye reflections contain overlooked cues about the surrounding world that can enable 3D scene reconstruction from a fixed viewpoint video.


## How does this paper compare to other research in the same field?

This paper presents a novel method for reconstructing 3D scenes from monocular eye reflection images, which differs from prior work in several key ways:Comparison to panoramic imaging from eyes:- Prior work like Nishino and Nayar (2004) reconstructed panoramic/environment maps from eye reflections. This paper goes further to recover a full 3D neural radiance field. Comparison to reflection removal:- Methods for removing reflections typically rely on multi-view images or strong priors. This paper utilizes eye reflections as the signal of interest.Comparison to NLOS imaging: - Existing NLOS methods use controlled lighting or known relay surfaces. This method works with ambient illumination and accidental reflections.- Unlike Orca which uses a moving camera, this method is fixed view relying only on eye movement.Key differences:- Jointly optimizes radiance field, iris texture, and eye poses using a novel radial iris prior.- Designed specifically for eye reflections which have complex elliptical geometry, texture entanglement.- Demonstrates feasibility of 3D reconstruction from small low-resolution accidental reflections.In summary, this paper introduces tailored techniques for extracting 3D cues from eye reflections, validating the possibility of scene reconstruction from accidental imagery, with differences from prior work in domain, setup, and technical approach. It represents an advance in recovering spatial information from the human eye.


## What future research directions do the authors suggest?

Based on my reading of the paper, some key future research directions suggested by the authors include:- Testing the method on more unconstrained settings like video conferencing with natural head movement. The current real-world results rely on a more controlled "laboratory" setup with zoom-in captures of the face, deliberate lighting, and movement. Applying the method to more natural videos could be challenging due to lower resolution, dynamic range, and motion blur.- Developing more sophisticated models for the iris texture. The assumptions made in this work about the iris texture being constant and radially symmetric may be too simplistic, especially for large eye rotations. More complex iris texture models could improve performance.- Exploring other applications beyond 3D scene reconstruction, such as using accidental imaging for gaze tracking, biometric identification, health monitoring, etc. The eye reflections provide a rich source of information about the observer's pose, environment, and physiology. - Investigating multi-view and stereo formulations to further leverage signals from two eyes. The current approach uses monocular sequences, but simultaneously modeling left and right eyes could improve reconstruction.- Developing unsupervised or self-supervised approaches to avoid requiring ground truth 3D scenes. Relying less on supervised training could increase the flexibility of the method.- Testing on eyes with various pathological conditions or optics like contact lenses or eye surgeries. The eye geometry and reflections may differ in these cases.- Addressing privacy concerns with accidentally captured signals. Image processing techniques could help suppress sensitive information in eye reflections.In summary, the authors point to several opportunities around capturing more natural/unconstrained data, enhancing the eye appearance models, exploring new applications, harnessing binocular information, reducing supervision, and addressing privacy. Advancing research in these directions could help unlock the full potential of this approach.


## Summarize the paper in one paragraph.

The paper presents a method for reconstructing 3D scenes from images capturing reflections in human eyes. The key ideas are:- The eye acts like a curved mirror that reflects light from the surrounding environment. By capturing images of a person's eyes as they move their head, the method obtains different viewpoints of the scene from the eye reflections. - The method represents the unknown 3D scene as a neural radiance field and renders it by ray marching. However, instead of camera rays, it traces reflected rays bouncing off the eye surface.- Two main challenges are the intricate iris texture occluding the reflections and the noise in estimating the eye poses. The method addresses these via joint optimization of a texture prediction model to estimate the iris appearance and refinement of the estimated eye poses.- A simple radial regularization is proposed to encourage the texture prediction network to focus on modeling the iris rather than absorbing scene content. This improves decomposition of the eye appearance from the true scene reflections.- The method is evaluated on both synthetic and real captures of people observing different objects and scenes. The results demonstrate plausible 3D scene reconstruction from only eye reflections in monocular image sequences.In summary, the key novelty is in repurposing neural scene representations and rendering techniques to work with accidental reflections from eyes, which act as mirrors enabling non-line-of-sight 3D sensing from regular 2D portraits. The texture prediction and pose refinement techniques address the unique challenges that arise from using eye reflections as input.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the key points in the paper:The paper presents a method to reconstruct 3D scenes from images capturing reflections in a person's eyes. The key insight is that as a person moves their head, their eyes naturally capture different viewpoints of the surrounding scene through light reflection. By analyzing a sequence of eye images, the paper shows it is possible to recover the 3D structure of the scene the person is observing. The authors propose a framework that combines classical eye geometry models with neural rendering techniques. Specifically, the eye is modeled as an ellipsoid mirror and used to trace reflection rays into the scene. A neural radiance field is optimized to represent the scene's appearance and geometry. To handle the intricate iris textures blended with the desired reflections, the method also estimates a separate neural texture field for the iris. Experiments on synthetic and real data demonstrate reconstruction of non-line-of-sight scenes from eye reflections across various capture conditions.In summary, the paper introduces a novel approach for 3D scene reconstruction that turns the eyes into accidental cameras viewing beyond the line of sight. By modeling eye geometry and handling challenges like iris textures, compelling results are shown from this unconventional image source.
