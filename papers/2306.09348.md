# [Seeing the World through Your Eyes](https://arxiv.org/abs/2306.09348)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:Can we reconstruct a 3D scene of the world observed by a person, using only reflections from their eyes captured in a monocular image sequence?The key hypothesis is that by capturing multiple images of a person's eyes as they move their head naturally, the eye reflections will provide sufficient multi-view information to allow reconstructing the 3D scene beyond the camera's line of sight using a neural radiance field approach. The paper aims to demonstrate the feasibility of this idea and introduces techniques like joint optimization of eye poses and iris texture decomposition to address the challenges unique to using eye reflections as input.In summary, the core goal is 3D scene reconstruction from eye reflections in monocular video, which requires addressing factors like noisy eye localization, intricate iris textures, and low-resolution reflections. The central hypothesis is that with proper handling of these challenges, the eye reflections can enable reasonable 3D scene reconstruction.


## What is the main contribution of this paper?

The main contribution of this paper is developing a method to reconstruct 3D scenes from eye reflections in portrait images. Specifically:- They propose a novel approach to use neural radiance fields (NeRF) to model the 3D scene reflected in a person's eyes, by tracing reflected rays off the cornea surface. - They introduce a texture decomposition technique to separate the iris texture from the scene reflection, using a learnt 2D texture field and a radial regularization loss.- They develop a cornea pose refinement procedure to improve the noisy cornea pose estimates caused by the small eye region size. - They create a synthetic eye reflection dataset for method validation.- They demonstrate reconstructing real-world scenes from eye reflections through experiments on captured portraits of different people/eye colors.In summary, the key contribution is enabling 3D scene reconstruction beyond the camera's line of sight by leveraging subtle eye reflections, via tailored techniques like texture decomposition and pose refinement to handle challenges unique to using eye images as input. This opens up new possibilities for recovering 3D scenes from accidental reflections.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The paper presents a method to reconstruct a 3D scene from a sequence of eye images capturing reflections. The key ideas are jointly optimizing the radiance field, iris texture, and cornea poses to overcome challenges like noisy cornea localization and complex iris patterns. The main takeaway is that eye reflections contain overlooked cues about the surrounding world that can enable 3D scene reconstruction from a fixed viewpoint video.
