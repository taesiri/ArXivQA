# [Diffusion Reward: Learning Rewards via Conditional Video Diffusion](https://arxiv.org/abs/2312.14134)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Diffusion Reward: Learning Rewards via Conditional Video Diffusion":

Problem: 
- Specifying reward functions is challenging for reinforcement learning (RL), especially for real-world tasks like robotics where state information is limited and designing good rewards is difficult. Using only sparse rewards results in very poor sample efficiency.
- Prior works tried learning reward functions from expert demonstrations to provide more dense supervision, but they have limitations in utilizing temporal structure and modeling complex demonstration distributions.

Proposed Solution:
- The paper proposes Diffusion Reward, which learns reward functions by leveraging the strong generative modeling capability of video diffusion models. 
- Key idea: conditioned on expert trajectories, diffusion models exhibit lower diversity in video generations compared to non-expert ones. This insight is formalized by using the negative conditional entropy as reward.
- A video diffusion model is first pretrained on expert videos. During RL, rewards are computed by: 1) performing latent diffusion conditioned on historical observations, 2) estimating conditional entropy over predicted latents, 3) combining with a novelty-seeking reward and sparse environment reward.

Main Contributions:
- Proposes a novel way to learn informed reward functions from videos using conditional video diffusion models, by estimating conditional entropy as rewards.
- Significantly outperforms prior video-based reward learning methods on 10 visual robotic manipulation tasks.
- Shows the learned reward can generalize to unseen tasks and guide the agent to solve them successfully.
- Provides detailed analysis on design choices through comprehensive ablations.
- Demonstrates the potential of applying large-scale pretrained video diffusion models for generalized reward learning.
