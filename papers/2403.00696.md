# [Self-Consistent Decoding for More Factual Open Responses](https://arxiv.org/abs/2403.00696)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) can generate false or unsupported information (hallucinations) when generating text. Recent work has shown that if multiple responses are sampled from an LLM, they tend to hallucinate different details. So details shared between multiple samples are more likely to be factual.  

- Existing methods address hallucination in extracted short answers, but not for full open-ended text generation tasks where the full response is needed.

Method:
- Propose a novel "Sample & Select" decoding method to reduce hallucinations in LLM text generation:
  - Iteratively sample multiple candidate next sentences with nucleus sampling, conditioned on prompt and previous selected sentences
  - Score each sentence by average token overlap with other sampled sentences 
  - Select highest scoring grammatical sentence to extend output
  - Continue generating sentences until end token is reached

- Intuition is that tokens occurring in multiple samples are more likely to represent true details

Contributions:
- First application of self-consistency to reduce hallucinations for full open-ended text generation tasks
- Simple and efficient token overlap scoring function to select most consistent samples
- Experiments on zero-shot summarization, comparing to baselines like nucleus sampling, beam search and other recent decoding methods
- Significantly improves factual accuracy metrics (30%+ relative gains) while maintaining ROUGE scores
- Human evaluation confirms improved factuality over baselines

So in summary, the paper proposes a novel iterative sampling and scoring method to reduce factual inconsistencies/hallucinations in LLM text generation by selecting the most self-consistent samples.
