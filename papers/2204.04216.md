# [Learning Trajectory-Aware Transformer for Video Super-Resolution](https://arxiv.org/abs/2204.04216)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is: How can we enable effective spatio-temporal learning in videos to improve video super-resolution? The key hypothesis is that modeling long-range temporal dependencies across frames in a video can help recover finer details and improve video super-resolution performance. However, existing methods are limited in their ability to aggregate useful information across long sequences. To address this, the paper proposes a novel trajectory-aware Transformer model called TTVSR that can effectively learn from long-range sequences for video super-resolution. The key ideas are:1) Formulating video frames into trajectories of visual tokens and limiting self-attention to tokens along the same trajectories. This reduces computational cost and enables modeling long sequences. 2) Proposing a location map to efficiently track and update token trajectories over time.3) Using cross-scale feature tokenization to handle scale changes in long sequences.In summary, the paper aims to improve video super-resolution by enabling effective modeling of long-range dependencies, which existing methods fail to fully capture. The proposed TTVSR model provides an efficient Transformer-based approach to achieve this goal.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel Trajectory-aware Transformer for Video Super-Resolution (TTVSR). The key ideas include:1. Formulating video frames into pre-aligned trajectories of visual tokens, and calculating self-attention within the same trajectory. This enables modeling long-range dependencies while reducing computational costs. 2. Proposing a location map to efficiently generate and update token trajectories based on pixel motions. The location map enables efficient trajectory generation through matrix operations.3. Introducing a cross-scale feature tokenization module to handle scale changes in long videos and enhance multi-scale feature representations. 4. Conducting extensive experiments showing superiority of TTVSR over state-of-the-art methods on four video super-resolution benchmarks. TTVSR demonstrates strong capability in modeling long-range dependencies for video super-resolution.In summary, the main contribution is proposing the trajectory-aware Transformer architecture for efficient and effective long-range video modeling in the application of video super-resolution. The introduction of token trajectories and location map enablesTransformer to handle long videos with reduced complexity.
