# [In-Context Learning Demonstration Selection via Influence Analysis](https://arxiv.org/abs/2402.11750)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Large language models (LLMs) can perform few-shot inference through in-context learning (ICL) without any gradient updates. However, ICL performance is sensitive to the selected demonstrations. Selecting effective demonstrations for ICL remains an open challenge. 

Proposed Solution: 
- The paper proposes an influence function analysis-based method called InfICL to select effective ICL demonstrations. 
- InfICL employs a local LLM to generate embeddings for the training data. A classifier is trained on these embeddings and used to calculate influence scores that measure the effect of up-weighting each training point on the validation loss. 
- The top influential points per class are selected as the ICL demonstrations. This connects influential points for the classifier to being influential for the LLM too under certain assumptions.

Main Contributions:
- Proposes InfICL method for selecting influential ICL demonstrations based on influence analysis without fine-tuning the LLM.
- Provides theoretical analysis to relate classifier influence scores to LLM influence, avoiding direct influence calculations on the LLM.
- Empirical evaluation on CoLA and RTE datasets shows InfICL outperforms baselines like random selection and similarity-based selection of demonstrations.
- Analysis shows InfICL has lower runtime than prior influence-based demonstration selection methods by avoiding costly LLM computations.

In summary, the paper presents an efficient influence analysis framework InfICL to select effective ICL demonstrations for LLMs, with empirical and theoretical analysis to support its advantages. Key aspects are avoiding direct influence computations on the LLM and connecting classifier influences to LLM influences.
