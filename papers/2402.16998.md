# [What Do Language Models Hear? Probing for Auditory Representations in   Language Models](https://arxiv.org/abs/2402.16998)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper investigates whether language models trained solely on text corpora can encode grounded knowledge about the sounds of objects, without having access to any explicit sound data during training. Specifically, the authors probe whether the vector representations of objects in language models have structural similarities with vector representations of the sounds of those objects from separately trained audio models.

Methodology: 
The authors first do a preliminary qualitative analysis using Procrustes analysis to align vector spaces of text representations and sound representations of the same set of objects. This shows some structural similarities, motivating a more rigorous quantitative analysis. 

The main analysis involves training a contrastive probe on a training set of objects to align their text and sound representations. The probe applies linear projections to both spaces and optimizes their similarity via a contrastive loss. If this probe generalizes to a held-out set of unseen objects, it suggests the text and sound spaces have inherent structural commonalities that facilitate the mapping between them.

The authors experiment with various language models (BERT, GPT-2 etc.) and audio models (AudioMAE, PaSST etc.). The audio models are all pretrained without access to symbolic text. Some audio models are supervised on sound classification while others are purely self-supervised.

Key Results:
- The probe generalizes significantly above chance across most language and audio model combinations, even on held-out objects not seen during training. This suggests language models learn grounded knowledge about the sounds of objects despite training on just text.

- Probe performance is better when using auditory-aligned sound representations from audio models pretrained on sound classification, compared to purely acoustic representations from self-supervised models.

- Analysis shows certain categories of sounds like instruments and human speech are better encoded in language models.

Overall, the paper provides evidence that language models can learn surprisingly grounded representations, acquiring knowledge about concepts like sounds which they have no explicit access to during training. The paper also analyses what kinds of auditory knowledge is better learned by language models.
