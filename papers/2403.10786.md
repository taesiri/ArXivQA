# [ContourDiff: Unpaired Image Translation with Contour-Guided Diffusion   Models](https://arxiv.org/abs/2403.10786)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Accurately translating medical images between modalities (e.g. CT to MRI) is useful for many downstream tasks like segmentation. 
- Existing unpaired image translation methods often prioritize perceptual quality over preserving anatomical fidelity. This causes misalignment between translated images and segmentation masks.
- Structural biases between modalities (e.g. CT scans showing two legs, MRI scans showing one) exacerbate this issue in adversarial models.

Proposed Solution:
- Propose ContourDiff, a novel unpaired image translation framework using contour representations to preserve anatomy.
- Contours are domain-invariant yet capture precise spatial information about anatomical content. 
- A diffusion model is trained on target domain images and their extracted contours.
- At test time, extract contour from source image, condition diffusion model sampling on it to translate source image while constraining it to match the contour.

Main Contributions:
- First unpaired image translation method that requires no source domain data, only target domain images. Enables translating unseen domains.
- Contour guidance allows precise enforcement of anatomical consistency despite severe domain biases.
- Evaluated on multi-modal medical translation tasks with downstream segmentation. ContourDiff outperforms existing methods in segmentation performance by large margins.
- Qualitative results also show ContourDiff translations better preserve anatomical alignment to source domain segmentation masks.

In summary, ContourDiff introduces contour conditioning to diffusion models for unpaired medical image translation to achieve superior anatomical fidelity over existing methods. It also uniquely does not require source domain data. Evaluations verify clear benefits to downstream tasks relying on anatomical consistency.
