# [Improving Zero-shot Generalization and Robustness of Multi-modal Models](https://arxiv.org/abs/2212.01758)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the key research question this paper tries to address is: 

How to improve the top-1 zero-shot classification accuracy of multi-modal models like CLIP and LiT on ImageNet dataset?

The authors noticed a large gap between the top-1 and top-5 zero-shot classification accuracy of CLIP model on ImageNet. They investigated the failure cases and found many mistakes are caused by ambiguity in the text prompts and sensitivity of the text encoder. 

To improve the top-1 accuracy, the authors propose two main techniques:

1) Develop a confidence estimation method to identify low-confidence predictions that are likely to be incorrect, by measuring consistency across different text prompts and image perturbations.

2) Improve the accuracy on those low-confidence examples by augmenting their class labels using the WordNet hierarchy, incorporating semantic information from parent nodes (top-down) and child nodes (bottom-up). 

The key hypothesis is that by identifying likely mistakes through the confidence estimation, and fixing them using the label augmentation based on WordNet, they can significantly boost the top-1 zero-shot classification accuracy on ImageNet for multi-modal models like CLIP and LiT.

The experiments verify their hypothesis, showing up to 17.13% improvement on the low-confidence subset and 3.6% overall accuracy improvement on ImageNet using their proposed techniques.
