# [LaserHuman: Language-guided Scene-aware Human Motion Generation in Free   Environment](https://arxiv.org/abs/2403.13307)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Existing datasets and methods for language-guided scene-aware human motion generation have several key limitations: 1) They rely on synthesized human motions which lack authenticity and physical plausibility; 2) The language descriptions use restricted templates and action types lacking diversity; 3) They focus only on static indoor scenes lacking variety in space and terrain; 4) The scenes only contain static furniture not capturing the dynamic nature of real environments. These limitations hinder the capability to generate human motions applicable to real-world scenarios like animation, VR/AR and robotics control.

Proposed Solution:
The paper proposes a new large-scale dataset called LaserHuman to address the limitations of existing datasets. Key features of LaserHuman:
1) Contains real human motions captured using motion capture in 3D scenes rather than synthesized motions.
2) Annotated with free-form diverse natural language descriptions rather than templates.
3) Covers both indoor and outdoor scenes spanning over 2000 sq. m with variety of terrains and objects.  
4) Includes dynamic environments with moving humans and objects interacting with target person.

The paper also proposes a new multi-conditional diffusion model to effectively integrate textual and visual scene contexts to generate motions consistent with language descriptions and physically plausible for 3D scenes. A key contribution is the cross-fusion mechanism between language and scene features.

Main Contributions:
1) LaserHuman - first real-world language-guided scene-aware human motion dataset spanning diverse spaces.
2) State-of-the-art multi-conditional diffusion model for coherent text-to-motion generation. 
3) Extensive experiments highlighting advanced consistency of generated motions to textual and scene-based constraints.
4) Detailed discussions offering insights and future opportunities in this research field.
