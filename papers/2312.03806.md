# [XCube ($\mathcal{X}^3$): Large-Scale 3D Generative Modeling using Sparse   Voxel Hierarchies](https://arxiv.org/abs/2312.03806)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Current 3D generative models are limited in their ability to generate high-resolution and diverse 3D shapes and scenes. Specifically, they face the following key challenges:
(1) Limited resolution and detail. Existing models can typically only generate low-resolution 3D outputs (e.g 2048 points or up to $256^3$ voxels) which lack fine details.
(2) Do not scale well to large scenes. Generating large-scale outdoor driving/robotics scenes (e.g. 100m x 100m) remains an open challenge.  
(3) Expensive optimization during sampling. Many recent works rely on slow and expensive test-time optimization.
(4) Lack of control and editing capabilities. Allowing user guidance and control is still largely unexplored.

Proposed Solution: 
This paper proposes a novel 3D generative model called \textit{Sparse Voxel Hierarchy Latent Diffusion (\LongName)} that addresses the above limitations. The key ideas are:

(1) It represents the 3D shape/scene as a \emph{hierarchy} of sparse voxel grids, from coarser to finer resolutions. This allows it to model details at multiple scales and reach very high resolutions (e.g. $1024^3$) efficiently.  

(2) It models the joint distribution of the voxel hierarchy using a hierarchical latent diffusion model. Each level of the hierarchy is modeled using a Variational Autoencoder (VAE) followed by a latent diffusion model conditioned on the previous coarser level in a cascading manner.

(3) The voxel hierarchy can be enriched with various attributes at each voxel such as normals, semantics, SDF, etc. allowing tasks beyond just geometry generation.

(4) It is built using a highly customized sparse 3D deep learning framework leveraging state-of-the-art data structures, allowing fast feedforward generation even at very high resolutions.


Main Results:

The method is demonstrated to achieve state-of-the-art performance on object-level shape generation tasks using ShapeNet and Objaverse datasets. Both unconditional and conditional generation from text are shown. Additionally, it generates large 100m x 100m outdoor driving scenes with details at 10cm resolution from the Waymo dataset - one of the first model to achieve this. The high quality as well as diversity of generations is confirmed through both qualitative visual inspection and quantitative user studies. Ablations further validate the design choices and the capability for intuitive user-guided editing.

Overall, this work pushes the boundary of what is possible for high-resolution and large-scale 3D scene generation thanks to the introduced sparse voxel hierarchy representation and the highly customized framework. It helps bridge the gap between current 3D generative modeling capabilities and the demanding applications in robotics and graphics.
