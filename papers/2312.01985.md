# [UniGS: Unified Representation for Image Generation and Segmentation](https://arxiv.org/abs/2312.01985)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes UniGS, a novel unified representation for image generation and segmentation within diffusion models. It represents segmentation masks as colormaps that can align closely with the RGB image domain while supporting variable entity numbers. Two key modules are introduced - a location-aware palette that assigns distinct colors to entities based on their center-of-mass location for discrimination, and a progressive dichotomy module that efficiently decodes the synthesized noisy colormaps into high-quality segmentation masks in a depth-first manner without needing to know entity numbers. UniGS is trained under an inpainting pipeline to address insufficient segmentation training data. This allows employing the unified representation flexibly across various tasks like inpainting, image synthesis, referring segmentation and entity segmentation with minor modifications. Experiments validate UniGS' effectiveness, generating quality on par with state-of-the-art in both image synthesis and segmentation tasks. The unified image and mask representation in UniGS has strong potential for developing foundation models capable of both generation and perception.
