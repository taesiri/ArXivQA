# [One scalar is all you need -- absolute depth estimation using monocular   self-supervision](https://arxiv.org/abs/2303.07662)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to transfer the depth scale from datasets with ground truth depth to a monocular depth estimator trained with self-supervision on a new dataset without ground truth depth. 

The key hypothesis is that the relationship between predicted up-to-scale depth and ground truth depth is linear across images from different datasets. This enables using a global depth scaling factor learned on a source dataset to convert predicted up-to-scale depth to absolute depth on a target dataset.

In summary, the paper aims to solve the scale ambiguity issue in self-supervised monocular depth estimation by transferring depth scale from existing datasets with ground truth depth. The key idea is that depth rankings are linearly correlated across datasets, allowing a global depth scaling factor to be applied.


## What is the main contribution of this paper?

 The main contribution of this paper is a method for transferring the depth scale from existing datasets with ground truth depth to a new target dataset that only has images, in order to predict absolute depth values. Specifically:

- The paper shows that monocular depth estimators (MDEs) trained with self-supervision using view reconstruction losses exhibit a linear relationship between predicted up-to-scale depths and ground truth depths. This linear depth ranking holds globally across the dataset.

- By training a MDE on mixed batches of images from a source dataset (with ground truth depth) and target dataset (without), the linear depth ranking extends across both datasets. This enables transferring the depth scale from the source to target. 

- A global depth scaling factor is calculated on the source dataset and applied to the up-to-scale depth predictions on the target dataset to convert them to absolute depths.

- This approach allows training or fine-tuning an MDE on new target images alone, without needing to collect new ground truth depth data. It transfers depth scale from existing real or synthetic datasets.

- The method is demonstrated on KITTI and DDAD datasets using different source domains, achieving competitive accuracy to supervised training and other depth scale transfer techniques.

In summary, the key contribution is a simple yet effective way to predict absolute depths by transferring depth scale properties from existing datasets to new self-supervised training data, avoiding the need for expensive ground truth depth collection.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points in the paper:

The paper presents a method to transfer the depth scale from existing datasets with ground truth depth to a self-supervised monocular depth estimator trained on new target images, enabling prediction of absolute depth values without requiring ground truth depth data for the new scenes.


## How does this paper compare to other research in the same field?

 Here are some thoughts on how this paper compares to other research in monocular depth estimation:

- The key contribution of this paper is a method to transfer the depth scale from an existing dataset with ground truth depth to a new target dataset without ground truth. This allows models to be trained on new data in a self-supervised manner while still predicting absolute depth values. 

- Most prior work on monocular depth estimation focuses on either fully supervised training with ground truth depth or self-supervised training which can only predict relative depth. This paper offers a way to get the benefits of self-supervised training on new data while still getting absolute depth values.

- Compared to other work on transferring depth scale, this paper uses a simpler single global scaling factor rather than methods that estimate per-image scale factors. The results show this global approach works reasonably well. 

- Unlike some other depth scale transfer methods, this approach does not require tailoring synthetic source datasets to match the characteristics of the real target dataset (e.g. using virtual KITTI for KITTI dataset). It demonstrates transferring scale between different real and synthetic datasets.

- The accuracy results are competitive with other depth scale transfer approaches, often matching or exceeding their performance, despite using a simpler scaling factor model.

- The depth accuracy is not as high as fully supervised training on the target dataset itself or state-of-the-art self-supervised methods, but the goal is reasonable accuracy without the need for extra ground truth depth.

- Overall, this depth scale transfer approach offers a useful way to train depth models on new target datasets in a self-supervised manner while predicting absolute depth. The simplicity of the single scaling factor method is a notable advantage compared to other techniques.

So in summary, this paper presents a simple yet effective approach for transferring depth scale across datasets, with competitive accuracy, which helps address a key weakness of self-supervised monocular depth training. It is an incremental improvement over existing techniques that provides a useful addition to the field.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors are:

- Developing more advanced architectures and losses for self-supervised monocular depth estimation (MDE) training. The authors note that their relatively simple architecture and standard self-supervised loss leaves room for improvement. More accurate self-supervised MDEs could help reduce variability in the predicted depth scales across images, improving generalization of the single global depth scale correction factor.

- Exploring ways to improve the per-image depth scale estimation using methods like specialized losses for the convolutional network approach they tested. Their global single scale factor performed better than the CNN per-image approach, but they suggest future work on improving the per-image accuracy.

- Applying the depth scale transfer approach to additional datasets beyond KITTI and DDAD to further demonstrate its applicability. The authors claim the method is insensitive to domain gaps, but testing on more diverse data could further validate this.

- Leveraging the decoupling of depth ranking and depth scaling to independently improve each component. For example, alternate losses or architectures could improve depth ranking, while the scaling could remain simple.

- Reducing the variability in depth scale across images to better enable generalization of a single global scale factor. The authors hypothesize this could come from improved self-supervised training.

- Extending the continuous learning benefits of the method by frequently fine-tuning on new data without needing additional ground truth depth measurements.

In summary, the main future directions focus on improving the self-supervised training, generalizing the approach to more domains, independently evolving the depth ranking and scaling components, reducing depth scale variability, and enabling continuous learning. The overall goal is improving monocular depth estimation using only images.


## Summarize the paper in one paragraph.

 The paper proposes a method to transfer the depth scale from existing source datasets with ground truth depth to new target datasets that only have images, allowing monocular depth estimators trained with self-supervision on the target images to predict absolute depth. The key insights are:

1) Monocular depth estimators trained with self-supervision based on projective geometry can linearly rank depths globally across images, though the predicted depths are ambiguous up-to-scale. 

2) When trained on mixed batches of source and target images adjusted to the same field-of-view, the depth estimator learns to rank depths on a common scale across both domains.

3) A single global scaling factor estimated on the source domain can then transfer the depth scale to the target domain.

The method is demonstrated on KITTI and DDAD datasets using various synthetic and real sources, achieving competitive accuracy to supervised methods without requiring ground truth depth for the target images. The global scaling factor avoids altering the base monocular depth estimator architecture. Overall, it enables training on new target images to predict absolute depth by reusing existing source datasets with depth ground truth.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper presents a method to transfer the depth scale from existing datasets with ground truth depth to monocular depth estimators trained in a self-supervised manner on new target datasets without ground truth depth. Self-supervised training results in depth predictions that are ambiguous in scale. The authors first show that the relationship between predicted and ground truth depth is linear, both within images and across a dataset. They then demonstrate that training on mixed batches of source and target images, after adjusting their fields of view, results in a common depth scale across domains. This enables using the ground truth depth from the source domain to estimate a global depth scaling factor that can be applied to the target domain, transferring the depth scale without needing ground truth depth for the new target images. 

The method is evaluated by training on mixed batches of real-world automotive datasets with different fields of view. A single global scaling factor estimated on the source test set is able to scale the target predictions to absolute depth with accuracy competitive with supervised training on target ground truth. The approach does not require tailored synthetic datasets and works across domain gaps in image style and content. By decoupling depth ranking and scaling, the method provides an effective way to obtain absolute depth predictions for new test images using only a lightweight self-supervised model and existing ground truth data.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

This paper presents a method for transferring the absolute depth scale from existing source datasets with ground truth depths to depth estimators trained in a self-supervised manner on target datasets with only images. The key insight is that even though self-supervised monocular depth estimators can only predict depths up-to-scale, their predictions are linearly correlated with the ground truth depths. This allows modeling the relationship between predicted and ground truth depths on the source domain using a single global scaling factor. By training the depth network on mixed batches from the source and target domains after aligning their fields-of-view, this global scaling factor can then be applied to scale the up-to-scale depth predictions on the target domain to absolute depths, thereby transferring the depth scale from source to target. The method is demonstrated by training on mixed batches of real and synthetic datasets and then transferring scale to the KITTI and DDAD target datasets, achieving accuracy competitive with supervised training and other depth scale transfer techniques.
