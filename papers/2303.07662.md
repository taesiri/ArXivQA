# [One scalar is all you need -- absolute depth estimation using monocular   self-supervision](https://arxiv.org/abs/2303.07662)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to transfer the depth scale from datasets with ground truth depth to a monocular depth estimator trained with self-supervision on a new dataset without ground truth depth. The key hypothesis is that the relationship between predicted up-to-scale depth and ground truth depth is linear across images from different datasets. This enables using a global depth scaling factor learned on a source dataset to convert predicted up-to-scale depth to absolute depth on a target dataset.In summary, the paper aims to solve the scale ambiguity issue in self-supervised monocular depth estimation by transferring depth scale from existing datasets with ground truth depth. The key idea is that depth rankings are linearly correlated across datasets, allowing a global depth scaling factor to be applied.


## What is the main contribution of this paper?

The main contribution of this paper is a method for transferring the depth scale from existing datasets with ground truth depth to a new target dataset that only has images, in order to predict absolute depth values. Specifically:- The paper shows that monocular depth estimators (MDEs) trained with self-supervision using view reconstruction losses exhibit a linear relationship between predicted up-to-scale depths and ground truth depths. This linear depth ranking holds globally across the dataset.- By training a MDE on mixed batches of images from a source dataset (with ground truth depth) and target dataset (without), the linear depth ranking extends across both datasets. This enables transferring the depth scale from the source to target. - A global depth scaling factor is calculated on the source dataset and applied to the up-to-scale depth predictions on the target dataset to convert them to absolute depths.- This approach allows training or fine-tuning an MDE on new target images alone, without needing to collect new ground truth depth data. It transfers depth scale from existing real or synthetic datasets.- The method is demonstrated on KITTI and DDAD datasets using different source domains, achieving competitive accuracy to supervised training and other depth scale transfer techniques.In summary, the key contribution is a simple yet effective way to predict absolute depths by transferring depth scale properties from existing datasets to new self-supervised training data, avoiding the need for expensive ground truth depth collection.
