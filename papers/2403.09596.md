# [Scalable Autonomous Drone Flight in the Forest with Visual-Inertial SLAM   and Dense Submaps Built without LiDAR](https://arxiv.org/abs/2403.09596)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Forestry is crucial for sustainability but lacks efficiency due to the difficulty of obtaining accurate forest maps to support decision-making. This is due to the vast areas forests cover and the large number of trees. Autonomous drones can address this by flying missions to map forests, but forests present challenges like lack of GPS, clutter, and need for obstacle avoidance. Existing systems rely on heavy, expensive LiDAR sensors.

Proposed Solution:
The paper presents an autonomous drone system using only visual and inertial sensors for under-canopy navigation. The key components are:

1) Visual-inertial SLAM (VI-SLAM) for state estimation and sparse mapping. This corrects odometry drifts, especially upon loop closures.

2) Deep learning-based dense depth estimation from stereo images, integrated into volumetric occupancy submaps associated with VI-SLAM keyframes. This allows scalability and handles drifts/loop closures. 

3) Planning safe paths using the submaps and tracking them using a model predictive controller.

4) A novel method to "anchor" and deform reference trajectories upon state estimate changes from VI-SLAM. This ensures continuous, safe trajectory tracking after loop closures.

Main Contributions:

- Complete vision-based drone autonomy system with all computation on-board
- Submapping approach to handle SLAM drifts and loop closures  
- Novel trajectory anchoring technique enabling safe navigation under state estimate changes
- Validation in simulated and real-world forests with high tree density, speeds up to 3 m/s without any collisions

The system demonstrates the first successful vision-only drone autonomy in dense forests without relying on LiDAR, towards cheaper and more scalable solutions. Key applications are forestry mapping to support sustainability.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper presents an autonomous drone system using only visual and inertial sensors to safely navigate dense forest environments at high speeds by performing visual-inertial SLAM, submap-based mapping, trajectory anchoring upon state updates, and model predictive control - validated both in simulation and real-world experiments without any collisions.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1) Presenting an autonomous drone system which performs under-canopy autonomous navigation using only visual and inertial sensors (stereo camera and IMU). The system performs visual-inertial SLAM, deep learning-based depth estimation, volumetric occupancy mapping in submaps, path planning, and trajectory tracking all on-board.

2) Introducing a novel approach to trajectory deformation that updates the reference trajectory upon state estimation updates from the VI-SLAM system, allowing continued trajectory tracking even when significant changes occur such as after loop closures.

3) Demonstrating the system in simulated and real-world forest environments with high tree densities up to 467 trees per hectare. It achieved speeds up to 3 m/s without any collisions, which the authors believe makes it the first passive vision-based system to accomplish this performance.

4) Performing an analysis that shows the mapping quality improvement enabled by using SLAM instead of just visual inertial odometry, thanks to the drift correction from loop closures. More loop closures lead to higher reconstruction accuracy and completeness.

In summary, the main contribution is presenting a vision-based autonomous forest navigation drone system and approach that achieves state-of-the-art performance in challenging real-world conditions using only passive sensing and on-board computation. The trajectory anchoring technique and mapping analysis are also significant contributions.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- Autonomous drone navigation
- Visual-inertial SLAM (VI-SLAM)
- Volumetric occupancy mapping
- Submapping
- Trajectory anchoring/deformation
- Under-canopy flight
- Passive visual sensors (stereo camera)
- Loop closures
- Deep learning for depth estimation
- Onboard computation
- Path planning
- Model predictive control
- Forestry/forest environments

The paper presents an approach for autonomous drone navigation in forest environments using only visual and inertial sensors, with all computation performed onboard. Key aspects include visual-inertial SLAM for state estimation, volumetric occupancy mapping using submaps, trajectory anchoring to handle loop closures and SLAM pose graph changes, deep learning for depth estimation, path planning, and model predictive control for trajectory tracking. The system is validated in challenging real-world forest environments with high tree densities, demonstrating successful fully autonomous flight without any collisions.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1) The paper mentions using a deep stereo network for dense depth estimation. What are some of the key advantages and disadvantages of using a learning-based approach compared to traditional stereo matching algorithms? How was the network trained and what type of synthetic data was used?

2) The submapping approach associates submaps with keyframes from the VI-SLAM system. What are the specific advantages of using a submapping approach compared to maintaining a single, monolithic map? How exactly do the submaps move upon keyframe pose updates and what assumptions does this rely on?

3) The paper proposes a novel trajectory anchoring scheme. What is the intuition behind anchoring the trajectory states to past keyframe poses estimated by the VI-SLAM system? Explain in detail the weighting scheme used to update the anchored trajectory states upon changes in the keyframe poses. 

4) Loop closures can cause significant "jumps" in state estimates by the VI-SLAM system. How does the proposed approach ensure continued safe trajectory tracking despite these discontinuities? What could go wrong without the trajectory anchoring scheme?

5) The informed RRT* algorithm is used for replanning paths. Why was this specific algorithm chosen over other sampling-based planners? How exactly is the planner adapted to leverage the concept of submaps rather than a single monolithic map?

6) What modifications were made to the MPC framework to enable it to accept trajectory updates from the anchoring scheme? Why is synchronizing these updates important?

7) The real-world experiments used a relatively high tree density of 467 trees per hectare. What implications does such a high density have on the perception and planning capabilities required? How does the proposed approach demonstrate sufficient robustness?

8) For the real-world experiments, what was the quantitative assessment of odometry drift over the length of the mission? How does this compare to related state-of-the-art visual-inertial odometry systems?

9) The paper claims fully on-board computation including VI-SLAM on the platform. What are the advantages of not relying on an external compute base station? What hardware was used on the drone itself to enable this?

10) The approach is validated without using any LiDAR sensors. What are some of the trade-offs compared to LiDAR-based state estimation and mapping pipelines? What limitations exist when using only visual and inertial sensing?
