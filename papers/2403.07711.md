# [SSM Meets Video Diffusion Models: Efficient Video Generation with   Structured State Spaces](https://arxiv.org/abs/2403.07711)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Recent video generation models using diffusion models have shown impressive results. However, these models typically use attention layers to capture temporal dependencies, which have quadratic memory complexity with respect to sequence length. This limits the application of these models to longer video sequences. 

Proposed Solution:
This paper proposes to incorporate state space models (SSMs) which have linear complexity into the temporal layers of video diffusion models. Specifically, the authors propose a temporal SSM layer consisting of:

- Bidirectional SSM module based on S4D to capture temporal dynamics 
- Addition of a multi-layer perceptron (MLP) after the SSM module to integrate information across channels

This temporal SSM layer replaces the temporal attention layers in existing video diffusion models like VDMs.

Experiments:
The proposed model is evaluated on UCF101 and long MineRL videos with 64 and 150 frames. It shows competitive or better Fr√©chet Video Distance (FVD) compared to attention-based models on UCF101, and the ability to generate much longer 150 frame MineRL videos which attention models fail to do due to memory constraints.

Ablations:
Ablations validate the importance of bidirectionality and the MLP in the temporal SSM layer through FVD comparisons. Comparisons to prior SSM architectures like GSS, BiGS and Mamba also show the superiority of the proposed simplified temporal SSM layer.

Main Contributions:
- Proposal of a simple yet effective temporal SSM layer to incorporate SSMs into video diffusion models 
- Demonstration of competitive video generation quality compared to attention models 
- Ability to generate longer video sequences not feasible with attention models
- Analysis of design choices through extensive ablations

The main impact is the potential to develop video generation models that can handle longer sequences without the quadratic memory cost of attentions.
