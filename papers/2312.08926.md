# [Modeling Complex Mathematical Reasoning via Large Language Model based   MathAgent](https://arxiv.org/abs/2312.08926)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes a novel framework called Planner-Reasoner-Executor-Reflector (PRER) to model the complex multi-step process of mathematical reasoning using large language models (LLMs). PRER decomposes the reasoning into modules of planning actions, logical inference, executing actions, and self-verification. Building on this, the authors implement two types of MathAgent systems: one aligned with model behaviors (MathAgent-M) that allows more freeform reasoning, and one aligned with human cognition (MathAgent-H) that constrains actions into logical workflows. Experiments demonstrate that both MathAgents integrated with the powerful LLM GPT-4 achieve state-of-the-art performance on the challenging MATH and miniF2F mathematical reasoning datasets. In particular, MathAgent-H outperforms GPT-4 baseline by 9.26% on MATH and 12.3% on miniF2F, showcasing the benefits of systematically modeling reasoning chains. Ablation studies provide further insights, suggesting refined actions enable better LLM cooperation on complex tasks, while regulating LLM behaviors also improves reasoning. Overall, the proposed PRER framework and MathAgent systems present a promising direction for eliciting stronger mathematical reasoning from LLMs.
