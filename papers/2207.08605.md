# [Class-incremental Novel Class Discovery](https://arxiv.org/abs/2207.08605)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
The paper tackles the problem of class-incremental novel class discovery (class-iNCD). In this setting, a model is first trained on a labeled dataset containing a set of base classes. Then, the model is presented with an unlabeled dataset that contains novel classes disjoint from the base classes. The goal is two-fold: (1) discover and cluster the novel classes in the unlabeled data (2) prevent catastrophic forgetting of the base classes learned previously, without accessing the original labeled data. Most prior work in novel class discovery (NCD) focuses only on novel class discovery while ignoring base class performance. 

Proposed Solution:
The paper proposes a new method called FRoST that effectively handles class-iNCD. The key ideas are:

(1) Use a separate novel class head to cluster the unlabeled data. This head is trained with a clustering loss that leverages the feature representation learned on the base classes.

(2) Prevent forgetting on base classes via two strategies - feature replay and feature distillation. Class prototypes computed from the base classes are stored and replayed to preserve performance. Feature distillation ensures the feature extractor does not drift too much.  

(3) Learn a joint classifier for both base and novel classes using pseudo-labels from the novel head via self-training. This removes reliance on knowing task IDs at test time.

Main Contributions:

- Introduces a new more practical and challenging class-iNCD setting for incremental learning

- Proposes a new method FRoST that can effectively handle this setting by discovering novel classes while retaining high performance on base classes

- Achieves state-of-the-art results on multiple datasets compared to prior NCD and incremental learning methods

- Demonstrates the ability to operate in a class-incremental manner on a sequence of unlabeled datasets with new classes

The main novelty lies in explicitly tackling the joint novelty discovery and catastrophic forgetting problem in an incremental class scenario using dedicated strategies like feature replay and distillation.
