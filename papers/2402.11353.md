# [Understanding the Impact of Long-Term Memory on Self-Disclosure with   Large Language Model-Driven Chatbots for Public Health Intervention](https://arxiv.org/abs/2402.11353)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Recent advances in large language models (LLMs) have enabled the development of chatbots that can engage in free-form conversations on open-ended topics. This presents an opportunity to leverage such chatbots to support public health monitoring by eliciting self-disclosure about personal health from individuals. However, a key limitation of current LLM-driven chatbots is that they rarely preserve knowledge gained about individuals across repeated interactions. Augmenting LLMs with long-term memory (LTM) could help address this gap by allowing chatbots to remember and appropriately reference information from previous sessions. However, there is limited understanding of how LTM impacts people's willingness to self-disclose health information to and their perceptions of LLM-driven chatbots.

Proposed Solution:
This paper examines the impact of LTM on self-disclosure and user impressions through a case study of CareCall, an LLM-driven voice chatbot deployed to monitor the wellbeing of socially isolated individuals via weekly check-up calls. CareCall was initially deployed without LTM from Nov 2021 to Sep 2022 and then upgraded to incorporate LTM since Sep 2022. The LTM stores summarized information on five topics from each call, including health, meals, sleep, visited places and pets. 

The study analyzes 1,252 call logs from 147 CareCall users - 66 who used the system with LTM and 81 without LTM. It also conducts interviews with 9 users who engaged with the LTM-enabled CareCall.

Main Findings:
- Users disclosed more health details when conversing with the LTM-enabled CareCall, especially about the specific health conditions they have and clinical care they are seeking.  
- As users experienced more LTM events, they disclosed increasingly more detailed information about their health over time.
- Users showed more positive reactions (e.g. expressing appreciation) and fewer negative reactions (e.g. disregarding questions) to the LTM-enabled CareCall. LTM offered familiarity with users, making conversations feel more personal and emotionally supportive.
- However, LTM also introduced some challenges - repetitive questions about chronic conditions that won't improve frustrated some users, limiting further disclosure. LTM-triggered questions also raised privacy concerns among some users.

Main Contributions:
- Empirical evidence that augmenting LLMs with LTM can elicit greater self-disclosure from users in the public health context.
- Demonstration of LTM's potential to mitigate the impersonal nature of chatbots and improve perceptions by offering familiarity. 
- Implications for designing LTM in LLMs - carefully selecting memory topics based on public health goals, designing thoughtful LTM-triggered questions to demonstrate care, balancing needs for health monitoring utility and privacy sensitivity.
