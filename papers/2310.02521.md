# [Who Audits the Auditors? Recommendations from a field scan of the   algorithmic auditing ecosystem](https://arxiv.org/abs/2310.02521)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper seeks to address is: what are the key policy recommendations for effective AI audits that can help mitigate algorithmic bias and harm, grounded in insights from current practitioners?

The authors conduct interviews and a survey of current AI auditors, advocates, regulators, and researchers to understand:

1) What methods and tools are currently being used to audit AI systems?

2) What are the emerging standards and best practices in AI audits? 

3) What are the biggest barriers to effective AI auditing?

4) Whether practitioners investigate potential and real-world harm across the AI lifecycle.

5) Whether practitioners pay attention to harm incident reporting for deployed systems.

Based on their findings, the authors then outline policy recommendations aimed at lawmakers, regulators, companies, standards bodies, and auditors themselves to enable more effective auditing practices that can help reduce algorithmic bias and harm.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It provides the first comprehensive field scan of the algorithmic auditing ecosystem, including a catalog of 189 organizations and 438 individuals involved in audits. 

2. It summarizes the results of interviews with 10 industry leaders and a survey of 152 individuals to identify current practices, emerging standards, barriers, and areas of agreement/disagreement around audits.

3. Based on the field scan, interviews, and survey, it makes 6 policy recommendations to enable more effective and impactful audit practices:

- Require independent audits against defined standards for AI system owners and operators 

- Notify individuals when they are subject to algorithmic decision systems

- Mandate disclosure of key audit results for peer review

- Consider real-world harm in audits, including harm incident reporting 

- Prioritize involvement of stakeholders likely to be harmed in audits

- Formalize evaluation and potential accreditation of auditors

In summary, the key contribution is providing the first in-depth look at the emerging ecosystem of algorithmic auditors, summarizing current practices and challenges, and outlining policy recommendations to strengthen audits as an accountability mechanism. The field scan, interviews with leaders, and broad survey provide a comprehensive view of this rapidly growing field.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper provides a comprehensive overview of the emerging field of AI auditing, including current practices, barriers, and policy recommendations to strengthen algorithmic accountability through more effective audits.


## How does this paper compare to other research in the same field?

 Here are some thoughts on how this paper comparing to other research on algorithmic auditing:

- It provides a comprehensive overview of the current state of the field through interviews with leading practitioners and a broad survey. Many existing papers focus on just one methodology (e.g. only interviews or only surveys) or a narrow group (e.g. only ML engineers). This paper incorporates multiple methods and perspectives.

- The field scan provides a valuable catalog of 189 organizations and 438 individuals doing work related to algorithmic auditing. This helps map the ecosystem in a way that few other papers have done. 

- The survey includes auditors as well as advocates, regulators, and researchers. This allows the authors to identify areas of agreement and disagreement between different groups, which gives useful insight into ongoing debates.

- The focus on barriers, best practices, consideration of harm, and policy recommendations makes the findings very actionable. Other literature reviews tend to focus more on categorizing methods or critiquing theoretical flaws.

- The emphasis on understanding both second-party and third-party audits distinguishes this from most prior work, which looks primarily at first-party audits by tech companies. 

- The attention to real-world harm and stakeholder involvement is important; many technical audits overlook these critical issues.

- Compared to papers that focus narrowly on technical audits, this provides a more well-rounded view by considering qualitative assessments as well. 

In summary, this paper makes excellent contributions through its comprehensive multi-method approach, focus on translating findings into policy recommendations, attention to second- and third-party audits, and emphasis on inclusion of perspectives from vulnerable communities. It significantly expands our understanding of the algorithmic auditing field.


## What future research directions do the authors suggest?

 The paper suggests several future research directions, including:

- Further research focusing specifically on algorithmic audits in the Global South. The authors note that their survey responses came primarily from the US, UK, and EU, with little representation from other regions. There is a need for research centered on auditing practices and perspectives from the Global South.

- Investigation into the demographics of algorithmic auditors. The authors believe future work should systematically explore the identities and backgrounds of individuals conducting algorithmic audits. 

- Linking the policy recommendations to existing policies and developing practical recommendations for implementation. The authors provide high-level policy recommendations but note that additional work is needed to connect these to current policies and develop specifics around how they could be implemented. 

- Developing additional domain-specific audit standards. The recommendations are intended as overarching ideas that should be built upon with more detailed, industry- and context-specific standards.

- Research into strategies for meaningful community engagement and support for community-led auditing processes. The authors highlight the need for further exploration of participatory design methods and investment in effectively involving affected stakeholders and communities in audits.

- Educational curricula, improved tools/frameworks, and mentoring to grow and diversify the pool of auditors. Whether or not formal accreditation is developed, there is a need to build up resources to train auditors.

In summary, the main future directions are: more geographic diversity, studying auditor demographics, implementation details for policy recommendations, domain-specific standards, participatory design for audits, and educational resources/mentorship for auditors. The authors lay out high-level policy ideas but call for additional research to put these into practice.


## What future research directions do the authors suggest?

 The paper suggests the following future research directions:

- More research on algorithmic auditing practices in the Global South. The current study focused primarily on auditors in the US, UK, and EU. Expanding to include auditors in Africa, Asia, South America, and Australia would provide a more global perspective. 

- Deeper exploration of the demographics of algorithmic auditors. The authors acknowledge that they did not collect auditors' demographic information in this study, but believe future work to systematically study auditor demographics is important.

- Further research to link the policy recommendations from this study to existing policies and develop practical implementation guidance. The authors provide high-level policy recommendations, but recognize additional work is needed to connect these to real-world implementation.

- Development of additional domain-specific audit standards beyond the general recommendations provided. While this study gives overarching suggestions, standards tailored to different industries and applications will be important.

- Testing and validation of the policy recommendations with broader groups of stakeholders. The current recommendations are based on a survey of auditors, but should be refined and validated through engagement with lawmakers, companies, advocates, researchers, and community members.

- Exploration of community-based and participatory audit approaches. This study focused on professionalized auditors, but the authors note the importance of connecting to participatory, community-led accountability processes.

In summary, the main future directions suggested are: expanding the geographic scope, studying auditor demographics, implementing the recommendations, developing domain-specific standards, validating the ideas with diverse stakeholders, and connecting professional auditing with community-based accountability efforts.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper provides the first comprehensive field scan of the algorithmic auditing ecosystem through interviews with 10 industry leaders and a survey of 152 practitioners. The authors find that the audit ecosystem is growing rapidly but lacks consensus on standards and best practices. They identify consensus around the need for regulation requiring audits, notification of automated decision systems, and disclosure of some audit results, but disagreement on details like scope and degree of disclosure. The paper finds a mismatch between auditors' stated priorities (like investigating real-world harm and involving stakeholders) and actual practices. Based on these findings, the authors recommend: 1) mandatory independent audits against defined standards; 2) notifying individuals subject to automated decisions; 3) disclosing some audit results; 4) incorporating real-world harm analysis; 5) involving impacted stakeholders; and 6) evaluating and potentially accrediting auditors. Overall, the paper provides valuable insights into the state of algorithmic auditing and recommendations to strengthen audits as an accountability mechanism.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper presents the first comprehensive field scan of the algorithmic auditing ecosystem. The authors interviewed 10 industry leaders and surveyed 152 individuals, including first-, second-, and third-party auditors as well as advocates, researchers, and regulators. They find that the auditing field is growing rapidly but lacks clear standards and oversight. Auditors rely more on quantitative than qualitative methods and face barriers getting buy-in from auditees. There is consensus on the need for regulation requiring audits, notification of algorithmic decision-making, and disclosure of key audit results, but disagreement on details. The authors make 6 policy recommendations: 1) require independent audits against defined standards; 2) notify individuals subject to algorithmic decisions; 3) mandate disclosure of key audit findings; 4) consider real-world harm via standardized reporting; 5) involve stakeholders likely to be harmed; and 6) evaluate and potentially accredit auditors.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper provides an overview of the emerging field of algorithmic auditing through interviews with industry leaders and a survey of auditors, advocates, researchers, and regulators. The authors find that while algorithmic auditing is growing rapidly, there are not yet clear standards or best practices. They identify several areas of consensus, including the need for regulation requiring independent audits and disclosure of key audit results. However, auditors disagree on the details, such as whether audits should be required for all AI systems or only high-stakes ones. The authors also find a mismatch between what auditors say is important, like considering real-world harm, and what they currently do in practice. Based on these findings, they make several policy recommendations aimed at lawmakers, companies, standards bodies, and auditors themselves. These include requiring notification when individuals are subject to automated decision systems, involving affected communities in audits, and establishing a formal evaluation or accreditation system for auditors. Overall, this paper provides valuable insights into the state of algorithmic auditing and recommendations to strengthen audits as an accountability mechanism.

In summary, this paper explores the emerging field of algorithmic auditing through interviews and surveys with practitioners. It finds consensus on the need for greater regulation and transparency, but disagreement over the specifics. It also reveals gaps between auditors' aspirations and actual practices. Based on these findings, the authors propose policy recommendations to establish clearer audit standards and oversight.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper provides an overview of the current state of the algorithmic audit field through interviews with leading audit practitioners and a survey of first-, second-, and third-party auditors, advocates, regulators, and researchers. The authors find that the algorithmic audit ecosystem is growing rapidly, but there is a lack of consensus on audit practices and standards. Auditors agree regulation is needed, but disagree on the details like whether audits should be required for all AI systems or only high-stakes ones. The authors outline six policy recommendations: 1) require independent audits against defined standards for AI system owners and operators; 2) notify individuals subject to automated decisions; 3) mandate disclosure of key audit results; 4) consider real-world harm in audits through harm incident reporting; 5) involve stakeholders likely to be harmed in audits; and 6) evaluate and potentially accredit auditors. 

Overall, the paper finds a mismatch between what auditors say is important and what they actually do in practice. For example, many auditors focus on technical assessments over qualitative ones and say intersectional analysis is important but rarely demonstrate it. Additionally, while auditors agree including analysis of real-world harm and stakeholder perspectives is critical, few actually incorporate this into their audits. The recommendations aim to address these gaps through regulation and policy to enable auditors to play a more meaningful role in algorithmic accountability.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the methods used in the paper:

The authors first conducted a field scan to identify 438 individuals from 189 organizations involved in AI auditing, including first-, second-, and third-party auditors as well as advocates, researchers, and regulators. They then interviewed 10 leaders in the field of AI auditing to understand current practices, standards, barriers, and approaches to harm. Based on these interviews, they developed a survey that was completed by 152 individuals, including 56 auditors. The survey asked about methods, tools, standards, regulation, barriers, consideration of harm, and stakeholder involvement in audits. The combination of a broad field scan, in-depth leader interviews, and a survey targeting both auditors and non-auditors provided a comprehensive overview of the emerging algorithmic audit ecosystem.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the methods used in the paper:

The authors conducted a field scan to identify 438 individuals from 189 organizations involved in algorithmic auditing, including first-, second-, and third-party auditors as well as advocates, researchers, and regulators. They interviewed 10 industry leaders in depth. Based on the field scan and interviews, they developed a survey that was completed by 152 individuals, including 56 auditors. The survey explored methods and tools used, barriers faced, and perspectives on regulation and best practices. The mixed methods approach allowed the authors to both gather broad perspectives through the survey and gain more in-depth insights through the interviews.


## What problem or question is the paper addressing?

 The paper "Who Audits the Auditors? Recommendations from a field scan of the algorithmic auditing ecosystem" addresses the challenges and gaps in the growing field of algorithmic auditing. The key questions and problems it seeks to address are:

- What methods and tools are practitioners currently using to audit AI systems? 

- What are the emerging standards and best practices in AI audits?

- What are some of the biggest barriers to effective AI auditing? 

- Do practitioners currently investigate potential and real harm across the AI lifecycle?

- Do practitioners specifically pay attention to harm incident reporting for deployed systems?

The authors conducted a field scan, interviews, and a survey to understand the current state of algorithmic auditing. They found that while the field is growing rapidly, there is a lack of consensus on audit practices and standards. The paper makes recommendations to improve audit quality and impact, targeting policymakers, companies, standards bodies, and auditors. The key recommendations are around requiring independent audits against defined standards, notifying individuals subject to automated decisions, disclosing audit results, incorporating analysis of real-world harms, involving affected stakeholders, and potentially accrediting auditors.

In summary, the paper provides a comprehensive overview of the algorithmic auditing ecosystem, identifies gaps and challenges, and makes recommendations to strengthen audits as a mechanism for accountability and oversight of AI systems.


## What problem or question is the paper addressing?

 The paper titled "Who Audits the Auditors? Recommendations from a field scan of the algorithmic auditing ecosystem" is addressing the lack of knowledge and standards around algorithmic audits, also known as AI audits. 

The key problems and questions the paper seeks to address are:

- What methods and tools are practitioners currently using to audit AI systems?

- What are the emerging standards and best practices in AI audits? 

- What are some of the biggest barriers to effective AI auditing?

- Do practitioners currently investigate potential and real harm across the AI lifecycle?

- Do practitioners specifically pay attention to harm incident reporting for deployed systems?

The authors aim to provide recommendations for improving algorithmic audits and making them more effective accountability mechanisms, based on a field scan, interviews, and a survey of current auditing practitioners. The paper seeks to understand the current state of algorithmic auditing and provide guidance on regulation, standards, and best practices to address the lack of clarity and consistency in this emerging field.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper abstract, some of the key terms and concepts are:

- Algorithmic audits (or AI audits) - The main focus of the paper is examining the ecosystem and practices around auditing algorithmic systems and AI products.

- Algorithmic accountability - Audits are framed as a mechanism for accountability of algorithmic systems.

- AI audit methods - The paper examines the methods and tools auditors are using to conduct audits.

- Emerging standards - It looks at whether standards or best practices are emerging around conducting audits. 

- Barriers - The paper identifies barriers that make it difficult to conduct effective audits.

- Regulation - It considers whether and what kinds of regulation around audits may be needed.

- Disclosure - Whether and how audit results should be disclosed publicly is discussed. 

- Real-world harm - The extent to which audits consider potential real-world harms from AI systems is examined.

- Stakeholder involvement - Whether audits involve participation by impacted communities is assessed.

So in summary, the key concepts cover the practices, methods, challenges, and policy issues related to algorithmic auditing and using audits as a mechanism for algorithmic accountability. The paper provides an overview of this emerging field of algorithmic audits.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper abstract, some of the key terms are:

- Algorithmic audits/AI audits - The paper examines the practices and ecosystem around audits of algorithmic systems and AI. 

- Algorithmic accountability - The goal of algorithmic auditing is to improve accountability of AI systems.

- Bias and harm - The paper examines how audits aim to identify bias and potential harms caused by AI systems.

- Policy recommendations - The authors provide policy recommendations to improve AI auditing practices.

- Methods and tools - The paper examines the methods and tools currently used for algorithmic audits.

- Standards and best practices - It looks at emerging standards and best practices in the AI auditing field.

- Stakeholder involvement - The authors recommend greater involvement of stakeholders affected by AI systems in the auditing process.

- Harm incident reporting - They suggest standardized processes for reporting real-world harms caused by AI systems.

- Disclosure and peer review - The paper recommends mandated disclosure of key audit results for peer review.

- Regulatory oversight - It examines views on needed AI audit regulation and oversight.

So in summary, the key terms cover practices, tools, recommendations, and oversight around auditing algorithmic systems and AI for accountability, transparency, and reduction of bias and harm.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to summarize the key points of the paper:

1. What was the purpose and goal of the study?

2. What methods did the authors use to conduct the study (field scan, interviews, survey, etc.)? 

3. Who were the main participants in the study (AI auditors, advocates, researchers, etc.)?

4. What are some of the key findings from the field scan and interviews? 

5. What are some of the main methods and tools currently used by AI auditors? 

6. What are some of the barriers and challenges faced by AI auditors?

7. What are some of the emerging best practices for AI audits?

8. Do auditors currently investigate real-world harm and involve stakeholders in audits?

9. What are the authors' policy recommendations for more effective AI audits?

10. What are some limitations of the study that should be considered when interpreting the findings?


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to summarize the key points of the paper:

1. What was the motivation for conducting this research on algorithmic auditing? Why is it an important area to study?

2. How did the authors go about conducting their research - what methods did they use (field scan, interviews, surveys, etc.)? 

3. What are some of the key findings from the interviews and surveys with regards to current practices in algorithmic auditing?

4. What barriers or challenges do auditors face in conducting effective audits? How do the barriers differ between 1st, 2nd, and 3rd party auditors?

5. What are some of the emerging best practices or standards in algorithmic auditing based on the authors' research?

6. What is the current state of considering real-world harm and incorporating stakeholder perspectives in audits? How could this be improved?

7. What are the authors' 6 main policy recommendations for improving algorithmic auditing practices? 

8. What are some areas of consensus vs. disagreement/debate around algorithmic auditing based on the survey responses?

9. Who should pay attention to the recommendations - policymakers, companies, auditors, etc.?

10. What are some limitations of the research methods used that could affect the conclusions or generalizability of the results?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 in-depth questions about the methods proposed in the paper:

1. The paper proposes mandatory independent AI audits against clearly defined standards for both AI product owners and operators. What are some key considerations in determining which systems should be subject to mandatory auditing? Should the requirements differ based on sector, application area, or potential risk of harm? 

2. The authors recommend requiring notification when individuals are subject to algorithmic decision-making systems. What methods could be effective for achieving meaningful notification in different contexts? How can notification avoid becoming a meaningless legal disclaimer?

3. The paper argues for mandated disclosure of key components of audit results for peer review. What is the right balance between transparency and protecting proprietary information or security concerns? Should the level of mandated disclosure differ based on sector or application?

4. The authors recommend standardized processes for harm incident reporting and response as part of audits. What existing incident reporting systems could serve as models? How can underreporting of harm incidents be addressed? What mechanisms can ensure company accountability in responding to reports?

5. How can regulators and companies ensure meaningful involvement of affected stakeholders and communities in audits? What methods and processes facilitate substantive engagement rather than token participation? How can power imbalances between companies and impacted groups be addressed?

6. What are some specific ways regulators could promote investment in educational curricula, tools, frameworks, and mentorship programs to grow the pool of skilled auditors from diverse backgrounds? What role could professional organizations play?

7. The authors acknowledge concerns about potential accreditation of auditors becoming a rubber stamp process. How could an accreditation program be designed to maintain high standards while not creating excessive barriers to entry? What is the right balance of requirements?

8. What mechanisms would enable effective decentralized regulation of domain-specific AI systems by multiple agencies? How can coordination between agencies be facilitated? How can regulatory capture be avoided?

9. How can transparency regulations balance the need for disclosure to improve accountability while protecting legitimate corporate interests and security concerns? What disclosure should be mandatory versus voluntary? 

10. What provisions would help ensure that new regulations continue to evolve with advances in technology and new understandings of algorithmic harms? How can ongoing monitoring, evaluation, and community input be incorporated?
