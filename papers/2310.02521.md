# [Who Audits the Auditors? Recommendations from a field scan of the   algorithmic auditing ecosystem](https://arxiv.org/abs/2310.02521)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper seeks to address is: what are the key policy recommendations for effective AI audits that can help mitigate algorithmic bias and harm, grounded in insights from current practitioners?

The authors conduct interviews and a survey of current AI auditors, advocates, regulators, and researchers to understand:

1) What methods and tools are currently being used to audit AI systems?

2) What are the emerging standards and best practices in AI audits? 

3) What are the biggest barriers to effective AI auditing?

4) Whether practitioners investigate potential and real-world harm across the AI lifecycle.

5) Whether practitioners pay attention to harm incident reporting for deployed systems.

Based on their findings, the authors then outline policy recommendations aimed at lawmakers, regulators, companies, standards bodies, and auditors themselves to enable more effective auditing practices that can help reduce algorithmic bias and harm.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It provides the first comprehensive field scan of the algorithmic auditing ecosystem, including a catalog of 189 organizations and 438 individuals involved in audits. 

2. It summarizes the results of interviews with 10 industry leaders and a survey of 152 individuals to identify current practices, emerging standards, barriers, and areas of agreement/disagreement around audits.

3. Based on the field scan, interviews, and survey, it makes 6 policy recommendations to enable more effective and impactful audit practices:

- Require independent audits against defined standards for AI system owners and operators 

- Notify individuals when they are subject to algorithmic decision systems

- Mandate disclosure of key audit results for peer review

- Consider real-world harm in audits, including harm incident reporting 

- Prioritize involvement of stakeholders likely to be harmed in audits

- Formalize evaluation and potential accreditation of auditors

In summary, the key contribution is providing the first in-depth look at the emerging ecosystem of algorithmic auditors, summarizing current practices and challenges, and outlining policy recommendations to strengthen audits as an accountability mechanism. The field scan, interviews with leaders, and broad survey provide a comprehensive view of this rapidly growing field.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper provides a comprehensive overview of the emerging field of AI auditing, including current practices, barriers, and policy recommendations to strengthen algorithmic accountability through more effective audits.
