# [ELAD: Explanation-Guided Large Language Models Active Distillation](https://arxiv.org/abs/2402.13098)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Deploying large language models (LLMs) like GPT-3 is challenging due to their massive computational demands and high costs. 
- Traditional knowledge distillation methods that transfer LLM capabilities to smaller models often fail to determine if knowledge transfer is sufficient, leading to poor performance or unnecessary costs.

Proposed Solution:
- The authors propose an Explanation-Guided LLMs Active Distillation (ELAD) framework that uses an active learning strategy to optimize the balance between annotation costs and model performance.

Key Points:
- Explanation-Guided Sample Selection: Identifies challenging samples for the student model by detecting uncertainties in explanation steps using novel intra- and inter-explanation uncertainty metrics.

- Customized LLM-Annotated Explanation Revision: Leverages the teacher LLM's capabilities to detect and correct flaws in the student's reasoning explanations, providing customized guidance.  

- Experiments across reasoning datasets show ELAD significantly improves annotation efficiency over baselines.

Main Contributions:
- A new active learning framework for efficiently distilling knowledge from large to small language models using explanations.
- An explanation-guided sample selection method exploiting stepwise uncertainties.  
- A customized LLM-annotated explanation revision technique allowing the teacher to pinpoint and correct student reasoning errors.
- Demonstrating enhanced efficiency in LLM distillation annotation across benchmarks.
