# [Machine Vision Therapy: Multimodal Large Language Models Can Enhance   Visual Robustness via Denoising In-Context Learning](https://arxiv.org/abs/2312.02546)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel Machine Vision Therapy (MVT) framework to enhance the robustness of computer vision models on out-of-distribution tasks without needing additional human annotations. The key idea is to leverage the knowledge embedded within Multi-modal Large Language Models (MLLMs) that possess exceptional few-shot learning capabilities and reasoning skills about visual concepts. To align the text generation process of MLLMs with vision tasks, the authors design a Denoising In-Context Learning strategy. Specifically, by estimating a transition matrix capturing label noise, an instruction is constructed containing a correct and an erroneous visual example from the most probable confusing category. When fed into MLLMs, such an instruction helps detect and rectify incorrect predictions. The rectified supervision then guides a self-supervised fine-tuning to boost vision models' robustness on downstream distributions. Through comprehensive experiments on ImageNet, WILDS, DomainBed etc., the authors demonstrate the effectiveness of Machine Vision Therapy in improving performance under distribution shifts and on corrupted images, showing superiority over several baseline methods. The work provides a novel perspective to exploit MLLMs for enhancing vision models without human effort.
