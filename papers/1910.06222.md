# [Understanding the Limitations of Variational Mutual Information   Estimators](https://arxiv.org/abs/1910.06222)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question it addresses is: What are the limitations of existing variational approaches for estimating mutual information (MI), and how can we develop improved variational estimators with better bias-variance tradeoffs?In particular, the paper:- Theoretically shows that certain variational MI estimators like MINE can have variance that grows exponentially with the true underlying MI. This leads to poor bias-variance tradeoffs.- Empirically demonstrates that existing variational MI estimators fail to satisfy basic properties of MI like data processing and additivity under independence. - Provides a unified perspective of variational MI estimators as optimization over valid density ratios. This highlights the role of partition function estimation as a source of high variance.- Proposes a new estimator called SMILE that focuses on reducing variance in partition function estimates to achieve better bias-variance tradeoffs.- Shows improved performance of SMILE over existing estimators like MINE, NWJ, CPC on benchmark tasks while satisfying more self-consistency properties.So in summary, the key hypothesis is that variational MI estimators have limitations like exponential variance growth and self-consistency violations, and the paper aims to understand these limitations and develop improved estimators. The SMILE estimator is proposed as a solution that mitigates some of these issues.


## What is the main contribution of this paper?

This paper analyzes the limitations of variational mutual information estimators based on neural networks. The main contributions are:- It theoretically shows that certain estimators like MINE can have variance that grows exponentially with the true mutual information. This leads to poor bias-variance tradeoffs. - It proposes a set of self-consistency tests for mutual information estimators based on properties like independence, data processing and additivity. Empirically it demonstrates that existing estimators fail these tests on image datasets.- It provides a unified perspective on variational MI estimators as optimization over valid density ratios. From this view, it develops a new estimator called SMILE that focuses on reducing variance.- Empirical results on benchmark tasks show SMILE has improved bias-variance tradeoffs compared to prior estimators like MINE and CPC. It also performs better on the proposed self-consistency tests.In summary, the key contribution is analyzing limitations of existing variational MI estimators, both theoretical and empirical, and developing an improved estimator that mitigates some of these issues through a variance reduction approach. The analyses and new estimator help better understand the properties of these methods for estimating mutual information.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research on variational mutual information estimation:- This paper provides theoretical analysis on the limitations of popular variational MI estimators like MINE and NWJ. Prior work has mostly focused on empirical evaluation of these methods, without much analysis on their theoretical properties. The analysis here on the exponential variance scaling of MINE/NWJ with MI is novel.- The paper proposes some "self-consistency" tests like independence, data processing, and additivity to evaluate MI estimators. These tests assess if estimators satisfy basic expected properties of MI. Using these tests to benchmark estimators is a simple but useful idea not seen in prior work. - The proposed SMILE estimator builds on MINE but introduces a clipping technique to reduce variance. This improves bias-variance tradeoffs. Other papers have proposed techniques to reduce bias in MI estimators, but less work on directly reducing variance.- Experiments compare SMILE to MINE, NWJ, CPC on Gaussian toy data and images. Most prior empirical evaluations of MI estimators use Gaussian data, so benchmarking on images is interesting. The results align with the paper's analysis. - The unified view of MI estimation as density ratio optimization highlights the role of partition function estimation. This perspective isn't discussed much in other work.Overall, this paper provides useful theoretical and empirical analysis on limitations of variational MI estimators. The proposed variance reduction technique and benchmarking methodology also advance the field. The unified density ratio view offers new insights. Comparatively, most prior work has focused on proposing new estimators without much analysis. So this paper provides a useful critique and improvements over existing methods.
