# [Consistent Mesh Diffusion](https://arxiv.org/abs/2312.00971)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Consistent Latent Diffusion for Mesh Texturing":

Problem:
- Generating textures for 3D models is an important task with applications in games, VR, etc. 
- Prior work either uses slow optimization-based approaches or fast projection-based approaches that lack consistency across views.
- Optimization-based approaches are compute-intensive, requiring multiple GPUs and hours of training. 
- Projection-based approaches like TEXTure can result in visible seams, shading differences, and stretching across views.

Proposed Solution:
- Propose a novel approach using a single Depth-to-Image diffusion network to generate consistent textures from text prompts in 5 minutes.
- Unify diffusion paths of multiple 2D image views and hoist to 3D using MultiDiffusion. This retains expressiveness of 2D diffusion models while ensuring cross-view consistency.  
- Use a spherical harmonic latent texture map to control independence vs correlation across views.
- Perform GAN inversion in latent space to stitch latent view representations for consistency. 
- Weigh views by orientation towards camera to mitigate projection warping effects.

Main Contributions:
1. A diffusion approach for pixel-wise similarity in a masked image region
2. Generalization of MultiDiffusion from panoramas to texturing 3D surfaces
3. Comparisons to prior work TEXTure and Text2Tex showing higher consistency and quality

The approach is almost as fast as TEXTure while producing higher quality, more consistent textures across views. It works for arbitrary meshes and camera positions. This could be useful for procedural content generation in games and VR.
