# [Do GPTs Produce Less Literal Translations?](https://arxiv.org/abs/2305.16806)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is whether large language models (LLMs) like GPT produce less literal translations compared to standard neural machine translation (NMT) models. The key hypothesis is that GPT translations tend to be less literal, particularly when translating idiomatic expressions out of English into other languages.Some key points:- The paper investigates differences in literalness of translations from GPT models vs NMT systems using measures based on word alignment and monotonicity. - It finds GPT models produce less literal translations from English into German, Chinese and Russian.- This is verified through human evaluations showing GPT translations rated as less literal.- The paper shows this difference is especially pronounced for sentences containing idiomatic expressions, which GPTs are better able to translate figuratively.- Overall, the central hypothesis is that GPTs produce less literal translations from English, particularly for idiomatic expressions, compared to standard NMT systems. The paper provides evidence to support this through automatic metrics and human evaluation.
