# [MobiLlama: Towards Accurate and Lightweight Fully Transparent GPT](https://arxiv.org/abs/2402.16840)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

The paper introduces MobiLlama, an accurate and efficient small language model (SLM) designed specifically for resource-constrained devices. 

Problem:
Recent large language models (LLMs) like ChatGPT, while impressive, have massive computational requirements. This makes them unsuitable for on-device processing, limiting their usage for edge computing/mobile devices where compute/memory is limited. Smaller models are needed. However, simply downscaling LLMs leads to reduced accuracy.

Solution: 
The paper proposes a novel SLM architecture called MobiLlama. Instead of having separate feedforward networks (FFNs) per transformer layer like conventional SLMs, MobiLlama uses a shared FFN that is reused across layers. This sharing scheme reduces redundancy and allows fitting a larger model into a smaller parameter budget without compromising accuracy or efficiency.

Contributions:
1) Introduce MobiLlama, an accurate and efficient 0.5B parameter SLM specially designed for on-device usage. Outperforms prior 0.5B SLMs by 2.4% on average across 9 NLP benchmarks.
2) Propose shared FFN architecture to reduce redundancy and improve parameter efficiency. Enables scaling to 22 layers and 2048 dimensionality within 0.5B budget.  
3) Develop transparent framework with full access to data, code and 300+ checkpoints for reproducible research.
4) Demonstrate 46.6B tokens/sec on-device throughput with 5x lower power consumption than comparable models.
5) Extend MobiLlama to multimodal domain by combining it with CLIP vision encoder. Shows strong performance on visual QA datasets.

In summary, the paper presents MobiLlama, a novel SLM architecture tailored for resource-constrained on-device usage that sets new SOTA for transparent SLMs under 1B parameters. The shared FFN scheme improves parameter efficiency. Extensive experiments validate accuracy and efficiency gains.
