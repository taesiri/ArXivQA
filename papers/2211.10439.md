# [BEVFormer v2: Adapting Modern Image Backbones to Bird's-Eye-View   Recognition via Perspective Supervision](https://arxiv.org/abs/2211.10439)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question or hypothesis appears to be: How can modern image backbones be effectively adapted and unleashed for bird's-eye-view (BEV) recognition models without cumbersome depth pre-training or 3D pre-training?The key points seem to be:- Existing BEV recognition models rely on depth pre-trained backbones like VoVNet, limiting exploration of more modern image backbones. - The authors hypothesize that with proper perspective supervision, modern image backbones can be readily adapted to BEV models without 3D pre-training.- They propose a two-stage BEV detector BEVFormer v2 with perspective supervision to address this question.- Perspective supervision is provided by an auxiliary 3D detection loss from a perspective view detection head. This guides the backbone to learn useful 3D properties.- The perspective head also generates first-stage proposals to ease optimization of the BEV head.- Experiments show BEVFormer v2 effectively unleashes modern backbones for BEV recognition, outperforming prior state-of-the-art without depth pre-training.In summary, the central hypothesis is that perspective supervision can enable modern image backbones to be readily adapted for BEV recognition without cumbersome 3D pre-training. The proposed BEVFormer v2 method is used to validate this hypothesis.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Pointing out that perspective supervision is key to adapting general 2D image backbones to BEV models. They add this supervision explicitly through a detection loss in the perspective view.2. Presenting a novel two-stage BEV detector, BEVFormer v2, which consists of a perspective 3D detection head and a BEV detection head. The proposals from the perspective head are combined with the learned object queries in the BEV head. 3. Showing the effectiveness of their approach by combining it with latest image backbones like ConvNeXt and Internorm and achieving significant improvements over previous state-of-the-art results on the nuScenes dataset.In summary, the key contribution is introducing perspective supervision to facilitate adapting modern image backbones to BEV models, which is realized by adding an auxiliary perspective detection head and integrating it with the BEV head in a two-stage framework. This allows them to unlock the potential of advanced image backbones for BEV recognition.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes BEVFormer v2, a novel two-stage bird's-eye-view object detector for autonomous driving that incorporates perspective-view supervision to facilitate optimizing modern image backbones without cumbersome depth pre-training, achieving new state-of-the-art results on the nuScenes dataset.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other research on bird's-eye view object detection:- Focus on image backbone adaptation: Most prior work has focused on designing and improving the BEV detector architectures. This paper instead focuses on adapting modern image classification backbones like ConvNeXt and Intern to BEV detection, which is relatively underexplored.- Perspective supervision: The key idea proposed is adding an auxiliary perspective detection head and loss to facilitate optimization and adaptation of image backbones. This differs from prior approaches like using depth pre-training. - Achieves new SOTA results: By using the proposed perspective supervision and large backbones like InternImage, this paper achieves new state-of-the-art results on nuScenes, surpassing prior work by a significant margin. This demonstrates the effectiveness of the proposed ideas.- Generalizable approach: The benefits of perspective supervision are shown across a range of backbones like ResNet, DLA, VoVNet, and InternImage. This suggests it is a generally useful technique, not just tied to specific architectures.- Two-stage BEV detector: The integration of perspective and BEV detection heads into a two-stage model is novel for BEV detection. Most prior work has focused on single-stage detectors.Overall, the key novelties are the use of perspective supervision to facilitate image backbone adaptation, and the resulting significant improvements in BEV detection accuracy from using modern classification backbones. The generalizable improvements suggest this is a promising direction for future research on optimizing BEV detectors.
