# [SfM-TTR: Using Structure from Motion for Test-Time Refinement of   Single-View Depth Networks](https://arxiv.org/abs/2211.13551)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is:How can we combine the strengths of sparse but accurate Structure from Motion (SfM) reconstructions with dense but less accurate single-view depth predictions from neural networks to improve the performance of single-view depth estimation?The key hypothesis appears to be that using sparse SfM point clouds as a test-time self-supervisory signal during fine-tuning can help the network learn a better representation of the test scene and produce more accurate depth estimates.In summary, the paper proposes and validates a novel test-time refinement (TTR) method called SfM-TTR that leverages SfM multi-view cues to boost the performance of existing single-view depth networks.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel test-time refinement (TTR) method called SfM-TTR that boosts the performance of single-view depth networks using sparse Structure from Motion (SfM) point clouds as a self-supervisory signal at test time. Specifically, the key contributions are:- Using sparse SfM point clouds from wide baselines as pseudo ground truth for test-time refinement, instead of the commonly used photometric losses from adjacent frames. This provides stronger multi-view geometric constraints.- A robust two-stage method for aligning the scale and selecting valid points between the SfM reconstruction and the network's dense depth map. This accounts for outliers and depth-dependent noise.- Showing significant improvement over various state-of-the-art self-supervised and supervised networks by fine-tuning only the encoder, keeping the decoder fixed. This preserves sharpness while improving scene understanding.- Outperforming previous test-time refinement methods, especially at medium and large depths, by leveraging wider-baseline geometric cues from SfM instead of only photometric consistency between close views.- Providing a simple, effective pipeline requiring no per-network or per-sequence tuning. The same approach improves all networks evaluated.In summary, the key novelty is using SfM-based self-supervision at test time to boost depth networks, enabled by a robust alignment and refinement procedure. This sets the state-of-the-art for test-time refinement of single-view depth prediction.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes SfM-TTR, a novel test-time refinement method that boosts the performance of single-view depth networks by using sparse Structure from Motion point clouds as supervision to fine-tune the network encoder on the test data.


## How does this paper compare to other research in the same field?

This paper presents a novel test-time refinement (TTR) method called SfM-TTR that uses sparse 3D points from Structure from Motion (SfM) to improve the performance of single-view depth prediction networks. Here are some key ways it compares to other related work:- Most prior TTR methods for depth prediction use photometric losses between nearby frames during inference, similar to the losses used for self-supervised training. This includes works like Monodepth2+TTR, ManyDepth+TTR, and others. The key difference in this paper is using SfM points rather than photometric losses for TTR.- The benefit of using SfM is that it provides wider baseline constraints compared to photometric losses between adjacent frames. This makes SfM supervision more accurate, especially for medium and large depths where small baselines produce little parallax. The results show SfM-TTR substantially outperforms photometric TTR.- Unlike some prior works that jointly optimize depth networks along with pose during TTR, this method uses SfM points directly without needing complex optimization. The results are also better than joint optimization methods.- The method is demonstrated to improve various state-of-the-art supervised and self-supervised depth networks with the same set of hyperparameters. This shows it is widely applicable as a general refinement approach.- The novel scale alignment method accounts for outliers and depth-dependent noise when aligning SfM points to network predictions. This is more robust than prior alignment techniques like median scaling.In summary, using SfM as supervision for TTR is a novel approach compared to prior photometric losses, and results show it is more accurate while also being simpler to implement across different network architectures. The scale alignment and direct use of SfM points are also new compared to prior works.
