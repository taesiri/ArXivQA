# [The Past, Present and Better Future of Feedback Learning in Large   Language Models for Subjective Human Preferences and Values](https://arxiv.org/abs/2310.07629)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper surveys the past, present, and future of using human feedback to align large language models (LLMs) with subjective human preferences and values. It reviews 95 articles, finding that pre-LLM era alignment relied more on proxies like user simulations, while current approaches directly collect human ratings or comparisons of model outputs. However, ratings often come from small, unrepresentative crowdworker pools. The paper argues future work should address conceptual challenges in defining values, which lack universality and stability in interpretation across people. It also raises practical challenges in converting concepts to reliable empirical signals. Overall, the paper advocates for more open, democratic processes to determine whose voices and values shape LLMs. It encourages interdisciplinary borrowing and external scrutiny around measurement biases. Lastly, it argues documentation, transparency and model release are currently lacking.


## Summarize the paper in one sentence.

 This paper surveys approaches for incorporating human feedback into large language models to align them with subjective human preferences and values, identifies current practices and challenges, and provides recommendations for future work.


## What is the main contribution of this paper?

 This paper makes three main contributions:

1. It provides a review of past and present approaches for incorporating human feedback into language models, summarizing trends and common practices. It reviews 95 articles, including some before the advent of large language models (pre-2018) and some using the latest LLMs.

2. It highlights five key challenges that remain unresolved in using human feedback to align LLMs with preferences and values. These include both conceptual challenges (e.g. preferences and values are not universal) and practical challenges (e.g. operationalizing a "good" output is difficult). 

3. It makes recommendations for future work to address these challenges, such as anchoring alignment efforts more closely to legal theory and existing legal systems; diversifying who provides feedback using democratic and participatory approaches; and increasing transparency and external scrutiny around practices of soliciting and integrating human feedback.

In summary, the paper surveys the past and present landscape, identifies open problems, and suggests ways forward for using human feedback to shape the behaviors of large language models. Its main contribution is providing a comprehensive review and critique to guide future research directions.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the main keywords and key terms associated with it include:

- Human feedback
- Large language models (LLMs)
- Preferences
- Values 
- Alignment
- Reinforcement learning
- Crowdworkers
- Conceptual challenges
- Practical challenges
- Future recommendations

The paper surveys approaches for incorporating human feedback into large language models to align them with preferences and values. It reviews past and present practices, identifies conceptual and practical challenges that remain, and provides recommendations for future work to address these challenges. Key aspects examined include how feedback is collected from crowdworkers, integrated via reinforcement learning or other techniques, evaluated, and how well conceptual notions of preferences and values are defined and operationalized.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the methods proposed in the paper:

1. The paper discusses both conceptual and practical challenges for future work on feedback learning in LLMs. Which of the 5 key challenges outlined do you think is the most pressing to address? Why? 

2. The authors advocate for greater openness and democratization in deciding how different voices shape LLMs. What specific mechanisms or processes could be implemented to facilitate this open and democratic collaboration across different stakeholders?

3. The paper argues against the assumption of universal human preferences and values in aligning LLMs. How might the field better account for plurality, context-dependence and instability of values during feedback collection and integration?  

4. The authors highlight issues with operationalizing abstract concepts like "helpfulness" into concrete signals for models. What steps could be taken to bridge this gap more robustly while avoiding oversimplification of complex values?

5. Much research relies on crowdworkers for feedback collection. What are some of the limitations of this approach? How might sampling be improved to better represent end users, and what democratic principles could guide this?

6. The paper argues legal theory could help better specify concepts for alignment. But law can also be criticized for falsely universalizing values. How might researchers avoid this issue if adopting a legal framing? 

7. What mechanisms could address the risk of path dependence and local optima when using human feedback for reinforcement learning? How might we know if global vs local optimum is reached?

8. The paper discusses possible overfitting risks when incorporating human feedback. What processes are needed to rigorously audit for subtle misalignments not visible during training?

9. The conceptual distinction between preferences and values is highlighted as unclear. What precisely is this distinction according to theory? How might better clarity here motivate and focus alignment efforts?

10. The review scope had to necessarily exclude related subfields on bias, fairness etc. But could insights from these fields inform best practices for soliciting human perspectives? How might they guide processes of dissent, participation and oversight?
