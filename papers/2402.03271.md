# [Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information   Seeking in Large Language Models](https://arxiv.org/abs/2402.03271)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Large language models (LLMs) are being deployed in real-world settings involving uncertainty and ambiguity, where they need to actively seek out information by asking questions. However, most benchmarks assume all necessary information is provided upfront and do not evaluate models' abilities to ask effective questions to gather missing information. 

Proposed Solution: 
The authors propose Uncertainty of Thoughts (UoT), an algorithm to enhance LLMs' abilities to actively reduce their uncertainty by asking useful questions. UoT has three main components:

1) An uncertainty-aware simulation framework where the LLM generates candidate questions and simulates possible futures and likelihoods for each question. 

2) Uncertainty-based rewards motivated by information gain, which incentivize the LLM to seek information that maximally reduces uncertainty.

3) A reward propagation scheme to select the optimal question that maximizes expected reward over both the immediate and downstream rewards.

Main Contributions:

1) Introduce a benchmark with 3 tasks (20 Questions, medical diagnosis, troubleshooting) over 5 datasets to evaluate LLMs' active information gathering through questions.

2) Propose UoT, a novel method to improve LLMs' question asking abilities by modeling and seeking to reduce uncertainty. UoT uses simulation, information gain rewards, and reward propagation.

3) Experiments over multiple LLMs show UoT improves success rate by 57.8% on average over direct prompting baselines. UoT also shows gains over prior methods like Chain of Thought and Tree of Thoughts.

In summary, this paper makes significant contributions in developing methods for LLMs to gather needed information via effective questioning, introducing suitable benchmarks, and demonstrating strong empirical improvements.
