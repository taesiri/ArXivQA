# [Contrastive Decoding Improves Reasoning in Large Language Models](https://arxiv.org/abs/2309.09117)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is whether Contrastive Decoding, a text generation method originally proposed for improving long-form text generation, can also improve the performance of large language models on reasoning tasks. The key hypothesis seems to be that Contrastive Decoding, which searches for strings that maximize the difference in likelihood between a stronger "expert" model and a weaker "amateur" model, can prevent reasoning errors and improve logical reasoning in large LMs. Specifically, the authors hypothesize that Contrastive Decoding will outperform greedy decoding for solving reasoning problems.The paper tests this hypothesis across a variety of reasoning benchmarks, including math word problems, commonsense reasoning, and multiple choice question answering. The results generally support the hypothesis, showing improved performance over greedy decoding and other baseline methods on tasks like arithmetic reasoning and multiple choice ranking.In summary, the central research question is whether Contrastive Decoding can enhance reasoning abilities in large LMs, and the key hypothesis is that it will outperform greedy decoding on logical reasoning tasks. The paper presents experiments across different models and datasets to test this hypothesis.
