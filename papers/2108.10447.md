# [One TTS Alignment To Rule Them All](https://arxiv.org/abs/2108.10447)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How can we develop a generic alignment learning framework that can improve speech-text alignment convergence, robustness, and speech quality across different types of neural TTS models (both autoregressive and non-autoregressive)?

The key hypothesis appears to be that by combining forward-sum, Viterbi, and diagonal alignment priors in an unsupervised alignment learning objective, they can improve alignment learning for neural TTS models in three main ways:

1) Faster convergence of alignments during training

2) More robust alignments, reducing errors on long utterances  

3) Improved overall speech quality as judged by human listeners

The authors propose a framework for unsupervised alignment learning that can be applied to different neural TTS architectures. They show experimentally that this framework improves convergence speed, alignment robustness on long sequences, and speech quality over baseline alignment techniques for several autoregressive and non-autoregressive TTS models. The main goal is developing a generic framework that simplifies TTS training pipelines while also improving alignments and speech synthesis compared to existing methods relying on external alignment tools or pre-trained aligners.
