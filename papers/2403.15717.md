# [Ev-Edge: Efficient Execution of Event-based Vision Algorithms on   Commodity Edge Platforms](https://arxiv.org/abs/2403.15717)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Event cameras are emerging sensing modalities with high temporal resolution and wide dynamic range. To process the asynchronous event streams from such sensors, recent works have shown artificial neural networks (ANNs), spiking neural networks (SNNs) and hybrid SNN-ANN algorithms work well on event-based vision tasks like optical flow, segmentation etc. However, deploying these algorithms on commodity edge platforms with heterogeneous compute like CPUs, GPUs and neural accelerators results in poor performance. This is due to - (1) Mismatch between irregular event streams and algorithms requiring fixed matrix operations, resulting in many wasteful computations (2) Inability of hardware platform to match high event rates (3) Lack of optimization in mapping multiple concurrently executing tasks.

Proposed Solution - Ev-Edge Framework:
The paper proposes Ev-Edge, a framework with three optimizations to address the limitations above - 

1. Event2Sparse Frame (E2SF) converter - Directly transforms raw events to sparse frames, eliminating intermediate event representations. Enables use of sparse libraries.

2. Dynamic Sparse Frame Aggregator (DSFA) - Merges sparse frames at runtime by trading off temporal resolution and compute demand. Improves hardware utilization. 

3. Network Mapper (NMP) - Maps concurrent tasks to processing elements and selects layer precision, optimizing for compute, communication and accuracy. Formulated as an evolutionary search problem.

Main Contributions:
- Novel E2SF converter to mitigate wasted computations from dense encodings
- DSFA component to dynamically adapt sparse frames based on input and hardware constraints  
- Network Mapper methodology to explore large mapping design space for multi-task scenarios

Results:
- For single task execution, Ev-Edge achieves 1.28x-2.05x speedup and 1.23x-2.15x energy savings over GPU baseline
- For multi-task execution, 1.43x-1.81x speedup over round-robin scheduling techniques
- Minimal accuracy loss in most cases

The paper addresses the limitations of event-based vision systems on commodity hardware through an integrated optimization framework spanning the algorithm, system and hardware levels.
