# [On the Origins of Linear Representations in Large Language Models](https://arxiv.org/abs/2403.03867)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Recent works have shown that high-level semantic concepts tend to be encoded "linearly" in the representations learned by large language models (LLMs). However, the origins and underlying reasons for this linear structure are not well understood. 

Proposed Solution:
This paper introduces a simple latent variable model that abstracts the concept dynamics of LLM token prediction. Using this model, the authors theoretically show that the standard LLM pipeline of next token prediction objective (softmax cross-entropy) combined with the implicit bias of gradient descent promotes linear encoding of concepts.

Key Contributions:

1. Introduces a latent variable model between context sentences and next tokens to study concept representations in LLMs. The model assumes sentences and tokens reflect the same latent binary concept variables.

2. Shows theoretically that matching log-odds conditions can lead to linear representations, extending prior theory on word embeddings.

3. Proves that even when log-odds conditions fail, the implicit bias of gradient descent aligns concept representations and also matches embedding and unembedding vectors, inducing linear representations. 

4. Shows gradient descent bias results hold even when learning from incomplete sets of contexts and concept vectors at reduced dimensions.

5. Conducts experiments on simulated data from the latent variable model, confirming the emergence of linear representations. Also checks predictions of the theory on LLaMA-2, finding evidence that the simplified model yields generalizable insights.

In summary, the paper proposes a formal latent variable model along with theoretical analysis to uncover origins of linear concept representations in LLMs, namely the objective and optimization algorithm. The theory is also verified through simulations and experiments on LLaMA-2.
