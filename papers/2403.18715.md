# [Mitigating Hallucinations in Large Vision-Language Models with   Instruction Contrastive Decoding](https://arxiv.org/abs/2403.18715)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large vision-language models (LVLMs) can generate detailed and coherent text from images, but suffer from a high rate of hallucinations - where the generated text does not accurately reflect the visual contents. 
- Hallucinations can occur at both the object-level (incorrect objects) and attribute-level (incorrect attributes or relationships).
- Identified causes include statistical biases in training data, over-reliance on language priors, and multimodal misalignment in the fusion module.

Proposed Solution:
- Introduce the concept of "instruction disturbance", where appending role prefixes to instructions exacerbates hallucinations by increasing uncertainty in the multimodal alignment module.
- Propose Instruction Contrastive Decoding (ICD) method which contrasts the output distributions from the standard instruction and disturbed instruction. This aims to highlight and then detach hallucinated concepts.
- Apply adaptive plausibility constraints to focus on reliable candidate tokens and avoid erroneously rewarding implausible concepts.

Main Contributions:
- Show that instruction disturbance significantly increases hallucinations due to amplified statistical biases and over-reliance on language priors. 
- Demonstrate that the proposed ICD method effectively mitigates both object and attribute-level hallucinations across discriminative benchmarks like POPE and MME.
- Validate qualitatively on the LLaVa-Bench generative benchmark that ICD produces more accurate text grounded in the visual context.
- ICD enhances the general perception and recognition capabilities of LVLMs across comprehensive benchmarks.
- As training-free method agnostic to the choice of LVLM, ICD enables convenient integration and deployment.
