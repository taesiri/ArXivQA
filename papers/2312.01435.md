# [Automatic Report Generation for Histopathology images using pre-trained   Vision Transformers and BERT](https://arxiv.org/abs/2312.01435)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Automatic report generation for high resolution histopathology images is a challenging task due to the extremely large size of these images (up to 150,000 x 150,000 pixels). Existing state-of-the-art methods struggle to effectively encode these images and fuse the image representations with text for generating descriptions. 

Proposed Solution: 
- The paper proposes using a pre-trained Vision Transformer (ViT) called Hierarchical Image Pyramid Transformer (HIPT) to encode the Whole Slide Images (WSIs) at multiple scales and levels. The multi-scale encoding captures both cellular level details and tissue region level semantics. This WSI encoding from HIPT is then fed to a pre-trained BioClinicalBERT text decoder for generating captions for the image. 

- For encoding the WSIs, 4096x4096 patches are extracted from the image and encoded by both a ViT model trained at the 256x256 level and a ViT trained at the 4096x4096 level. The encodings are concatenated to get multi-scale WSI representations. These encodings are then attended over and projected before being input to the BioClinicalBERT decoder.

- The full framework is trained end-to-end by fine-tuning both the projection layer and the top layers of the BioClinicalBERT decoder.

Key Contributions:
- Proposes a novel transformer based encoder-decoder approach for histopathology image captioning using state-of-the-art self-supervised models like HIPT and BioClinicalBERT.
- Provides an effective way to encode very high resolution histopathology images leveraging multi-scale pre-trained ViT features.  
- Achieves strong quantitative results for caption generation using BLEU scores and auxiliary predictions like tissue type and patient gender classification.
- Opens up opportunities for using powerful pre-trained transformer models instead of CNN-RNN architectures for histopathology image analysis tasks.

In summary, the key novelty is in effectively harnessing self-supervised pre-trained vision and language transformers for the challenging task of whole slide image captioning in histopathology.
