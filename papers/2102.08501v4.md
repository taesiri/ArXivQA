# [DEUP: Direct Epistemic Uncertainty Prediction](https://arxiv.org/abs/2102.08501v4)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we improve upon existing measures of epistemic uncertainty, which rely on the variance of the Bayesian posterior predictive distribution, in order to account for model misspecification as well?

The key hypothesis is that directly estimating the excess risk by training a separate model to predict the generalization error can provide a better measure of epistemic uncertainty. The excess risk captures both the approximation uncertainty and model uncertainty (bias) components of epistemic uncertainty.

Some key points:

- Existing variance-based measures like in Bayesian neural networks do not account for model misspecification/bias. This can lead to poor uncertainty estimates.

- The excess risk, defined as the gap between the generalization error and irreducible aleatoric uncertainty, captures the reducible aspects of the lack of knowledge.

- The proposed DEUP method trains an "error predictor" model directly on observed out-of-sample errors to estimate the excess risk. This provides a measure of epistemic uncertainty.

- In interactive learning settings, additional "stationarizing" features are proposed to make the error predictor robust to the non-stationarity of acquiring more data.

So in summary, the central hypothesis is that directly targeting the estimation of excess risk can improve upon standard Bayesian posterior variance for epistemic uncertainty estimation, especially in the presence of model misspecification.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. It analytically characterizes the sources of lack of knowledge (epistemic uncertainty) in predictive models, arguing that model misspecification or bias is an important component that is not captured by variance-based uncertainty estimates. 

2. It proposes a framework called DEUP (Direct Epistemic Uncertainty Prediction) to directly estimate epistemic uncertainty by training a secondary model to predict the generalization error (risk) of the main predictor. This accounts for both approximation and model uncertainty.

3. It describes how DEUP can be applied in both fixed dataset and interactive learning settings, proposing the use of stationarizing features like density and variance estimates to help the error predictor generalize as the dataset changes over time.

4. It provides experimental validation that DEUP's uncertainty estimates can improve sequential model optimization, drive more efficient exploration in RL, and provide higher quality uncertainty estimates for tasks like drug synergy prediction and out-of-distribution detection compared to existing methods.

In summary, the key idea is to directly learn to predict the epistemic uncertainty based on the actual generalization error, instead of relying on variance or entropy which do not account for model misspecification. The framework is model-agnostic and demonstrated to be useful across different applications needing uncertainty estimates.
