# [Self-Supervised Learning of Pretext-Invariant Representations](https://arxiv.org/abs/1912.01991)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question/hypothesis appears to be:Can learning image representations that are invariant to image transformations used in self-supervised pretext tasks improve the semantic quality of the representations?The authors propose an approach called Pretext-Invariant Representation Learning (PIRL) to learn invariant representations for self-supervised learning. Their main hypothesis seems to be that invariance to image transformations will allow the representations to focus more on modeling semantic information rather than properties of the transformation, thereby improving the usefulness of the representations for downstream tasks like image classification and object detection.Specifically, the paper introduces PIRL as an alternative to existing self-supervised approaches like solving jigsaw puzzles that learn representations covarying with the transformations. PIRL instead encourages similarity between representations of an image and its transformed version using a contrastive loss. The central hypothesis is that this invariance objective will yield representations with better semantics and performance on transfer learning benchmarks. The experiments aim to test if PIRL representations are indeed more invariant and achieve superior transfer performance compared to prior self-supervised approaches, validating their hypothesis.In summary, the key research question addressed is whether enforcing invariance to pretext image transformations can improve representation learning for self-supervised approaches. PIRL is proposed as a way to achieve this invariance and the results are analyzed to determine if it indeed learns improved semantic representations.
