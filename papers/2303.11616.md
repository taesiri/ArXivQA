# [HRDFuse: Monocular 360°Depth Estimation by Collaboratively Learning   Holistic-with-Regional Depth Distributions](https://arxiv.org/abs/2303.11616)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper seeks to address is: 

How can we improve monocular 360° depth estimation by combining global context from the equirectangular projection (ERP) with regional detail from tangent projection (TP) patches?

The key points are:

- Previous methods using ERP or TP alone have limitations. ERP suffers from distortion while TP lacks global context. 

- The paper proposes a new method called HRDFuse that combines ERP and TP information.

- HRDFuse uses a spatial feature alignment (SFA) module to aggregate TP patch features into a full ERP feature map. 

- It uses a collaborative depth distribution classification (CDDC) module to learn global ERP depth distributions and regional TP depth distributions.

- Depth predictions from ERP and TP branches are fused to produce the final result.

So in summary, the main hypothesis is that combining global ERP context with regional TP detail in this collaborative way can improve 360° depth estimation accuracy and smoothness compared to prior methods. The experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

 The main contributions of this paper on monocular 360° depth estimation are:

1. It proposes a new framework called HRDFuse that combines the strengths of convolutional neural networks (CNNs) and transformers. It exploits both the holistic contextual information from the equirectangular projection (ERP) image and the regional structural information from the tangent projection (TP) patches.

2. It introduces a spatial feature alignment (SFA) module to efficiently aggregate the individual TP patch information into the ERP space in a pixel-wise manner. This avoids expensive patch merging operations. 

3. It proposes a collaborative depth distribution classification (CDDC) module to learn both holistic and regional depth distribution histograms. This allows predicting depth values as a linear combination of histogram bin centers.

4. The method achieves state-of-the-art performance on three 360° depth estimation benchmarks, producing smoother and more accurate depth maps compared to prior works.

In summary, the key novelty is the collaborative modeling of holistic and regional depth distributions via the SFA and CDDC modules. This allows combining ERP and TP effectively, avoiding patch merging issues, and improving depth accuracy. The experiments demonstrate the advantages over existing methods.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points of the paper:

The paper proposes a new framework called HRDFuse for monocular 360° depth estimation that combines convolutional neural networks and transformers to exploit both holistic contextual information from the equirectangular projection and regional structural details from tangent projections, achieving state-of-the-art performance.
