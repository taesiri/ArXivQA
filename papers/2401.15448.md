# [A Systematic Review of Available Datasets in Additive Manufacturing](https://arxiv.org/abs/2401.15448)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper presents a systematic review that investigates the availability of open and annotated image datasets originating from additive manufacturing (AM) processes. Such datasets are necessary for the application of computer vision and machine learning methods for quality assessment and defect detection during AM. However, acquiring labeled data is expensive and time-consuming in AM. The review aims to identify the gap between currently available image datasets in AM and what is available in other domains where large annotated datasets exist.

Methodology:
The methodology follows a standard systematic review process with 7 key stages: team formation, questioning the aim, planning the search methods, searching and screening datasets, managing and reporting results, analyzing patterns and gaps, and drawing conclusions. Search terms related to AM, images, machine/deep learning were used to retrieve datasets from 9 dataset search engines and a highly-ranked AM journal. Screening was done manually based on 5 inclusion criteria: open access, image format, AM domain, involves ML/DL applications, readily usable formats.  

Key Findings:
- Only 10 open AM image datasets were found across the dataset search engines
- Most focused on detection/segmentation of large components rather than microstructure defects
- Only 3 datasets aligned with all criteria but 2 required heavy pre-processing
- Screening 96 journal articles yielded 10 open datasets, but only 1 contained images readily usable for defect detection

Conclusions:
- Significant gap exists in availability of open, annotated AM image datasets compared to other domains 
- Such datasets are essential for advancing computer vision and ML for AM quality and process monitoring
- Need for greater openness and standardization of image datasets from AM processes

Contributions: 
The paper contributes a systematic methodology and thorough investigation of the landscape of currently available image datasets in AM. It highlights a critical gap that hinders advancement of ML for AM quality and process control, and calls for greater openness and collaboration around sharing useful datasets.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the key points from the paper:

This systematic review investigates the availability of open, annotated image datasets from additive manufacturing processes suitable for computer vision and machine learning applications, identifies gaps compared to datasets from other domains, and indicates a need for greater access to such datasets to enable quality assessment and defect detection during manufacturing.


## What is the main contribution of this paper?

 The main contribution of this paper is a systematic review to investigate the availability of open image-based datasets originating from additive manufacturing (AM) processes. Specifically, the paper:

1) Performs comprehensive searches across 9 dataset databases as well as a highly-regarded AM journal to identify existing open AM image datasets.

2) Applies a set of 5 pre-defined eligibility criteria to screen the retrieved datasets and select those suitable for computer vision and machine learning applications. 

3) Analyzes the screened datasets in terms of size, format, type of machine learning applications, etc.

4) Discovers a significant gap in the availability of open and annotated image datasets from AM processes, especially those capturing microstructure defects like porosity variance and cracks. 

5) Highlights the need for greater availability of such datasets to enable quality assessment and defect detection using machine learning during AM processes.

In summary, the key contribution is clearly identifying the current lack of appropriate open image datasets to support computer vision and machine learning for AM quality control, through a systematic methodology. The paper also defines requirements and opportunities for future dataset development in this space.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and keywords associated with this paper include:

- Additive manufacturing (AM)
- 3D printing
- In-situ monitoring 
- Process sensors
- Melt-pool
- Microstructure defects
- Porosity variance
- Cracking
- Image datasets
- Annotated images
- Machine learning (ML)
- Deep learning
- Computer vision
- Systematic review
- Dataset databases
- Selection criteria 
- Screening
- Gap analysis
- Availability of datasets
- Defect detection

The paper presents a systematic review to identify gaps in the availability of open, annotated image datasets from additive manufacturing processes, particularly looking for images that could be used to train machine learning algorithms to recognize microstructure defects like porosity variance and cracks. It searches multiple dataset databases and a key journal using defined selection criteria, screens the results, and analyzes gaps. Keywords and terms cover the AM domain, types of defects, need for annotated image datasets, use of systematic review methodology, and machine learning concepts. Let me know if you need any clarification or have additional questions!


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. The paper mentions using a systematic review methodology. Can you expand more on the specific steps involved in conducting a systematic review, especially as applied to this domain of additive manufacturing image datasets? What are some of the advantages and challenges with using this methodology?

2. One of the selection criteria is that the datasets must be "readily available for ML/DL practices". What exactly does this entail in terms of required preprocessing and formatting? How might this criterion impact the availability and diversity of qualifying datasets? 

3. When searching across the 9 dataset databases, what considerations went into formulating the search queries? How were decisions made regarding using variations of search strings and boolean operators?

4. During the screening process for the journal articles, what were some of the main reasons for exclusion of initially retrieved articles? Could the excluded articles still provide value and if so, how might they be utilized?

5. For the final set of 10 eligible journal articles, you ultimately found that none actually contained annotated melt-pool microstructure image datasets. Why do you think researchers failed to share such datasets?

6. Considering the overall lack of relevant image datasets found, what might this suggest in terms of priorities and incentives in the AM research community? How could dataset sharing be encouraged?

7. Do you think requiring "no heavy computational pre-processing" is reasonable criteria given the typically complex sensory data captured during AM processes? How could datasets still be made usable?

8. Since numerical sensor and parameter data files were excluded, what image preprocessing steps would be necessary to transform such data into usable image datasets?

9. For the defect detection dataset that was identified, what unique advantages does it offer over numerical process data alone? How might the available images be utilized?

10. Given the gaps identified in this review, what specific recommendations would you propose to improve sharing and availability of annotated microstructure image datasets in AM research?
