# [SimNP: Learning Self-Similarity Priors Between Neural Points](https://arxiv.org/abs/2309.03809)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research question this paper aims to address is:How can we combine the strengths of neural radiance field methods that perfectly reconstruct visible object regions with object-level priors that allow inferring complete shapes, in order to get the best of both worlds?The paper argues that current methods lie on two extremes of the spectrum - either using no data prior at all and relying completely on observations (e.g. NeRF), or using a fully global object-level prior that lacks detail (e.g. DeepSDF, SRN). The key proposal is to learn an object-level prior that focuses on encoding self-similarities between local regions, rather than learning the full radiance field distribution. This allows combining a detailed local representation that fits observations, with a global prior about how information can be propagated between similar object parts.The main hypothesis seems to be that by learning such category-level self-similarities, the model will be able to reconstruct unobserved object regions in a detailed way by transferring information from the visible parts. The results then aim to demonstrate that this approach leads to improved performance in reconstructing symmetric unseen parts compared to methods without such priors.In summary, the core research question is how to effectively combine local detail with global shape priors for high-quality few-shot 3D reconstruction, which this paper addresses through category-level self-similarity learning.


## What is the main contribution of this paper?

Based on my understanding, the main contributions of this paper are:1. It proposes a new method called SimNP that combines a category-level data prior with a local representation for 3D object reconstruction from limited views. 2. It introduces the first neural point radiance field on the category level, which uses a coherent point cloud representation. This allows capturing high-frequency details while also enabling explicit modeling of self-similarities.3. It presents a simple but effective mechanism to learn category-specific self-similarities between local object regions in an unsupervised and unconstrained way, by connecting neural points to shared embeddings via learned attention scores.4. It shows experimentally that SimNP outperforms previous methods, especially in reconstructing symmetric unseen parts of objects from a single view. It also demonstrates much better two-view reconstruction results compared to baselines.5. The method provides a meaningful disentangled representation space that allows interpolation of shape and appearance.6. SimNP is shown to be very efficient in terms of training and rendering compared to pixel-aligned radiance field methods.In summary, the key novelty is the combination of a category-level prior based on learned self-similarities with a detailed local neural point representation, which improves the observation-prior trade-off compared to previous work. The attentional mechanism to share information between coherent point cloud regions is intuitive yet effective.
