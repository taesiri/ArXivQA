# [Efficient Online Learning for Networks of Two-Compartment Spiking   Neurons](https://arxiv.org/abs/2402.15969)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Spiking neural networks (SNNs) have shown promise for efficient temporal signal processing. However, most SNNs rely on overly simplified neuron models like the leaky integrate-and-fire (LIF) model, which struggle to retain information over long time periods. 
- Recently, the two-compartment LIF (TC-LIF) neuron was proposed to capture dendritic-somatic interactions in biological neurons and achieve superior sequential modeling capabilities. However, training TC-LIF neurons using backpropagation through time (BPTT) has challenges like high memory consumption and vanishing gradients.

Proposed Solution:
- The authors propose using an online learning approach called e-prop which relies on local eligibility traces instead of BPTT's global error propagation. This eliminates the need to store intermediate network states.
- They derive the mathematical formulation to compute eligibility traces for TC-LIF neurons. The traces capture gradient information and get updated in a forward manner at each timestep.
- They also introduce an Adaptive TC-LIF neuron with time-varying membrane potential decay constants. This balances contributions from past and new inputs during online learning.

Main Contributions:
- Extends e-prop online learning approach designed for LIF neurons to accommodate multi-compartment TC-LIF neurons 

- Proposes Adaptive TC-LIF neuron specifically tailored for efficient online learning by using time-varying decay constants

- Achieves competitive performance to offline BPTT training of TC-LIF networks across sequential modeling benchmarks like Sequential MNIST, while requiring constant memory usage independent of sequence length

- Overall enables training high-performance multi-compartment SNNs suitable for implementation on emerging neuromorphic hardware.
