# [Continual Domain Randomization](https://arxiv.org/abs/2403.12193)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Continual Domain Randomization":

Problem:
- Deep reinforcement learning (DRL) relies heavily on simulation due to sample inefficiency and safety concerns with training on real robots. However, differences between simulation and the real world lead to poor performance of simulation-trained policies when transferred to real robots (known as the reality gap).

- Domain randomization is commonly used to bridge this gap by randomizing simulation parameters to cover the differences from reality. But selecting all relevant parameters upfront is challenging, and jointly randomizing many parameters makes the task very difficult, leading to worse policies.

Proposed Solution: 
- The paper proposes Continual Domain Randomization (CDR), which combines domain randomization with continual learning. 

- In CDR, training starts in an idealized simulation, then parameters are sequentially randomized, with continual learning used to retain knowledge from past randomizations and avoid catastrophic forgetting.

- Two versions are presented - CDR-EWC uses Elastic Weight Consolidation (EWC) for explicit regularization, while CDR-onlineEWC uses online EWC for implicit regularization with lower memory overhead.

Main Contributions:
- Introduces the concept of viewing domain randomization as a continual learning problem over a sequence of randomization tasks.

- Shows CDR matches or improves on joint randomization baselines while being more robust to order of randomizations than sequential finetuning.

- Demonstrates sim-to-real transfer for reaching and grasping tasks on a real robotic manipulator, with CDR variants achieving top performance.

- Provides an algorithmic framework in CDR-EWC and CDR-onlineEWC that enables flexible use of different subsets of randomizations without having to define them all upfront.

In summary, the paper presents Continual Domain Randomization as a way to bridge the reality gap in reinforcement learning by incrementally adapting policies to new randomizations with continual learning. Experiments show performance gains over standard domain randomization approaches.
