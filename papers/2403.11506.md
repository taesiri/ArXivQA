# [End-To-End Underwater Video Enhancement: Dataset and Model](https://arxiv.org/abs/2403.11506)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing methods for underwater video enhancement (UVE) primarily rely on extending image enhancement techniques to process individual frames independently. However, this can lead to temporally inconsistent results with flickering artifacts across frames. There is a lack of tailored datasets and models specifically designed for the video-based UVE task.

Solution:
This paper introduces:

1) SUVE Dataset: The first paired underwater video dataset comprising 840 video pairs, each with an underwater-style video and corresponding ground truth reference video synthesized using underwater neural rendering. 

2) UVENet: A novel CNN-based model for end-to-end UVE which takes multiple adjacent frames as input. It extracts multi-scale features using a shared encoder and aligns them across frames using proposed Feature Alignment and Aggregation Modules (FAAMs). These aggregated spatio-temporal features are decoded and further enhanced by a Global Restoration Module (GRM) to output the final frame.

Main Contributions:

- Constructs the large-scale SUVE dataset to enable supervised video-based learning for UVE

- Designs the UVENet architecture to effectively exploit inter-frame relationships through feature alignment and aggregation

- Demonstrates state-of-the-art performance over existing methods on both synthetic and real underwater videos in terms of image quality and temporal consistency

The paper represents the first comprehensive exploration of the UVE problem and the results showcase the benefits of video-based modeling over single image enhancement techniques.
