# [Pretext-Contrastive Learning: Toward Good Practices in Self-supervised   Video Representation Leaning](https://arxiv.org/abs/2010.15464)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we combine pretext tasks and contrastive learning in a general framework to boost performance on self-supervised video representation learning?The authors propose combining pretext tasks (which focus on learning representations within a sample) and contrastive learning (which aims to distinguish between different instances) into a joint optimization framework called Pretext-Contrastive Learning (PCL). Their goal is to show that this framework can facilitate the advantages of both pretext tasks and contrastive learning to achieve state-of-the-art performance on downstream tasks like video retrieval and recognition. They test their PCL framework on three different pretext task baselines using different network backbones. The results demonstrate substantial improvements over the individual baselines and the generality of their framework across tasks and models. Through extensive experiments and ablation studies, they aim to show that each component of their proposal (pretext task, contrastive learning, residual clips, data augmentation) contributes positively to performance.In summary, the central hypothesis is that combining pretext tasks and contrastive learning in an effective general framework can boost performance on self-supervised video representation learning across different models and tasks. The experiments and results are meant to demonstrate and validate this hypothesis.
