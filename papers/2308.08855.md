# [Realistic Full-Body Tracking from Sparse Observations via Joint-Level   Modeling](https://arxiv.org/abs/2308.08855)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question it addresses is: How can we accurately estimate full-body human motion from only sparse observations of the head and hands, such as those available from head-mounted displays (HMDs) and hand controllers in VR/AR settings?The key hypothesis is that explicitly modeling the correlations between different body joints will allow for more accurate and realistic full-body motion estimation from the very limited head and hand observations. The paper proposes a two-stage deep learning framework to model these joint-level correlations spatially and temporally in order to address the highly underconstrained problem of inferring full body motion from sparse inputs.In summary, the paper aims to show that despite having only sparse observations from HMDs and controllers, careful joint-level modeling can enable realistic and accurate full-body human motion estimation for VR/AR applications.


## What is the main contribution of this paper?

This paper presents a two-stage framework for realistic full-body tracking from sparse head and hand tracking signals. The key contributions are:- A two-stage joint-level modeling framework:     - Stage 1 explicitly models joint-level features including joint rotation, joint position, and embedded input features.     - Stage 2 uses these features as spatiotemporal tokens in a transformer network to capture joint-level correlations.- Carefully designed loss functions including hand alignment loss, motion smoothness loss, and physical loss to constrain the underdetermined problem and avoid artifacts.- Extensive experiments showing state-of-the-art performance on AMASS dataset and real captured data. The method achieves higher accuracy and smoothness compared to previous methods without needing any post-processing.In summary, the main contribution is the joint-level modeling framework and associated training techniques to accurately and smoothly estimate full-body pose from sparse head and hand observations. This could enable realistic avatar control and body tracking for AR/VR applications.
