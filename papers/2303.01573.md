# [DejaVu: Conditional Regenerative Learning to Enhance Dense Prediction](https://arxiv.org/abs/2303.01573)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to improve deep networks for dense prediction tasks such as segmentation, depth estimation, and surface normal prediction using conditional image regeneration as an auxiliary training objective. 

The key hypothesis is that by including an additional loss term based on reconstructing the original input image from a corrupted version conditioned on the network's dense predictions, the network can learn to produce more accurate predictions with clearer boundaries and better spatial consistency.

In particular, the paper proposes a framework called "DejaVu" which involves:

1) Redacting the input image to remove certain structural information (e.g. by sparse sampling or frequency removal). 

2) Using a conditional regenerator module to reconstruct the original image from the redacted image and the network's dense predictions.

3) Adding the reconstruction loss as an auxiliary objective during training to encourage the base network to embed the missing structural information in its predictions.

The central hypothesis is that the requirement to reconstruct the original image will push the base network to learn more robust and spatially consistent features related to shapes and boundaries, thus improving the dense prediction performance.
