# [Pose-Guided Self-Training with Two-Stage Clustering for Unsupervised   Landmark Discovery](https://arxiv.org/abs/2403.16194)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper tackles the problem of unsupervised landmark discovery (ULD) for object categories like faces. ULD aims to detect semantically meaningful landmarks on objects without using any manual annotations during training. This is challenging as landmarks need to be invariant to viewpoint changes, occlusions and other variations while capturing the shape perception of non-rigid objects like faces. Existing methods struggle to detect consistent landmarks under large intra-class variations.  

Proposed Solution:
The paper proposes a new diffusion-based ULD approach called D-ULD++ that leverages the implicit correspondence cues in pre-trained diffusion generative models. The key ideas are:

1) A simple baseline (ZeroShot) that clusters the internal representations from a pre-trained diffusion model at random pixel locations. This surprisingly outperforms prior ULD methods.

2) An algorithm called D-ULD that fine-tunes the diffusion model and uses clustering to obtain pseudo-labels for landmarks. These are used in a self-training loop leading to improved performance over ZeroShot.

3) A pose-guided proxy task using a VAE that reconstructs predicted landmark heatmaps after projecting them to a latent pose space. This adds pose awareness.

4) A two-stage clustering mechanism that first clusters images based on latent pose codes from the VAE and then clusters landmarks within each pose cluster. This captures pose variations better.

The combination of ideas 3) and 4) with D-ULD results in the proposed D-ULD++ algorithm.

Main Contributions:

- A simple yet effective ZeroShot baseline for exploration of diffusion models for ULD

- D-ULD algorithm involving diffusion feature fine-tuning and self-training with pseudo-labels 

- Pose-guided proxy task and two-stage clustering to make D-ULD robust to pose variations

- Consistent and significant improvement over prior state-of-the-art on four datasets including human and cat faces

The main highlight is leveraging correspondence cues in diffusion models via careful fine-tuning and self-training to push the envelope in ULD performance. The introduction of explicit pose modeling and two-stage clustering leads to the best results.
