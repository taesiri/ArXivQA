# [Visual Hallucinations of Multi-modal Large Language Models](https://arxiv.org/abs/2402.14683)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Visual hallucination (VH) is a major issue with multi-modal large language models (MLLMs) where they imagine incorrect visual details about an image when answering visual questions. 
- Prior works have limitations in benchmarking MLLMs' VHs due to using only existing image datasets, resulting in insufficient diversity of VH instances and potential data contamination.

Proposed Solution - VHTest:
- A 3-step approach to generate diverse and new VH instances to test MLLMs:
  1) Find initial VH instances in existing image datasets. 
  2) Generate text descriptions summarizing potential causes of VHs for different modes.
  3) Use text-to-image models to generate more VH images based on the descriptions.
- Constructed benchmark with 1,200 VH instances in 8 VH modes.

Key Contributions:  
- Proposed VHTest to generate diverse VH instances beyond existing image datasets to properly evaluate VHs in MLLMs.
- Formulated new VH modes - shape and size that are unexplored previously. 
- Comprehensive evaluation showed state-of-the-art MLLMs hallucinate on a large fraction of the benchmark VH instances.
- Demonstrated fine-tuning MLLMs on the proposed benchmark reduces hallucination without sacrificing performance on other benchmarks.

In summary, the paper presented VHTest to generate a diverse set of VH instances to properly evaluate and mitigate visual hallucinations in multi-modal large language models.
