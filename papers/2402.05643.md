# [Improving Token-Based World Models with Parallel Observation Prediction](https://arxiv.org/abs/2402.05643)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Recent token-based world models (TBWMs) represent agent experiences as sequences of discrete tokens for improved sample efficiency in reinforcement learning. However, during imagination, the sequential token-by-token generation of next observations creates a severe computational bottleneck, leading to long training times, poor GPU utilization, and limited sequence lengths.

Proposed Solution:
This paper proposes a novel Parallel Observation Prediction (POP) mechanism to overcome the imagination bottleneck of TBWMs. POP allows the entire next observation token sequence to be generated in parallel during world model imagination. This is achieved by augmenting a Retentive Network (RetNet) sequence model with a specialized forward pass that retains training efficiency. 

Specifically, POP maintains dedicated prediction tokens that are only used during inference to generate the next observations in one shot. By using a recurrent state in RetNet that summarizes long history, the per-token prediction cost is reduced. During training, a two-step computation is introduced to allow the parallel computation of outputs for variable-length inputs. This enables efficient batch processing of sequences.

Based on POP, the authors present REM, the first TBWM agent to incorporate the RetNet architecture.

Main Contributions:
- Proposal of the novel POP mechanism to resolve the severe inference bottleneck of existing TBWMs, enabling the use of longer observation sequences.
- Introduction of REM, the first TBWM approach driven by the Retentive Network architecture, providing initial evidence of RetNet's efficacy in RL.
- Evaluation of REM on Atari 100K, showcasing the effectiveness of POP. REM trains in under 12 hours, while outperforming prior TBWMs in terms of agent performance. The improved computational efficiency is evidenced by a 15.4x speedup during imagination.

In summary, this paper makes TBWMs practical by resolving their bottleneck through POP and presents REM as an effective agent that harnesses the representational benefits of the token-based paradigm. The incorporation of the RetNet architecture is another noteworthy contribution.
