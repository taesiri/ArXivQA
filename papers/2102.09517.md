# [Essentials for Class Incremental Learning](https://arxiv.org/abs/2102.09517)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Essentials for Class Incremental Learning":

Problem:
The paper focuses on the problem of class-incremental learning (class-IL), where the goal is to learn a unified classifier that can classify new classes of data that arrive sequentially over time, without forgetting the previously learned classes. However, neural networks suffer from catastrophic forgetting when trained on new tasks sequentially - their performance on previous tasks deteriorates rapidly. The key challenges in class-IL include selecting exemplar samples from old classes to retain knowledge, constraints to alleviate forgetting of old classes, and balancing learning of old and new classes.

Proposed Solution: 
The paper proposes a Compositional Class Incremental Learning (CCIL) model that combines simple yet effective solutions to the above challenges. 

For exemplar selection, samples are randomly selected from old classes. Forgetting is alleviated using plain knowledge distillation loss between outputs of the old and new models. The core contribution is a compositional learning system that handles inter-task and intra-task learning separately - it uses a separate softmax for new classes, and a joint softmax over all classes for the exemplar set. This eliminates bias towards new classes. Transfer learning is improved by using lower learning rates for incremental steps.

The paper also shows overfitting the base model correlates with more forgetting later. Regularization techniques are analyzed - only techniques preserving secondary class information (relation between classes) help alleviate catastrophic forgetting. Data augmentation proves most effective for this.

Main Contributions:
- Proposes CCIL model with a compositional learning system for balancing old and new classes 
- Shows overfitting base model causes more forgetting later
- Identifies preserving secondary class information as key for alleviating forgetting
- Achieves new state-of-the-art results on CIFAR-100 and ImageNet datasets, using a simple yet effective approach

The paper provides useful design guidelines through extensive analysis, while keeping the overall approach simple and achieves significantly improved class-IL performance over prior works.
