# [Evaluating Task-oriented Dialogue Systems: A Systematic Review of   Measures, Constructs and their Operationalisations](https://arxiv.org/abs/2312.13871)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper provides a systematic review of evaluation methods used for task-oriented dialogue systems, with a focus on applications in customer service. The key problem highlighted is the lack of standardization in evaluation approaches, with a diversity of metrics and constructs as well as inconsistencies in terminology. 

The paper first categorizes evaluation methods into intrinsic methods that focus on core system performance, and extrinsic methods that evaluate the system in context. Intrinsic methods are further divided into natural language understanding (NLU), natural language generation (NLG), and performance/efficiency. Extrinsic methods look at task success, usability, and user experience. 

In total, 108 different constructs are identified across the literature related to dialogue system evaluation. The paper discusses a subset of these in detail, analyzing definitions, operationalizations, and rationales behind different metrics. For example, coherence is measured via automatic methods like QuantiDCE as well as human ratings; correctness uses accuracy metrics as well as surveys; and fluency relies on metrics like perplexity and BLEU as well as expert assessment.  

Key contributions of the paper include:

- A structured taxonomy of evaluation constructs, methods, and metrics for task-oriented dialogue systems
- An analysis of deficiencies in current practice, including lack of construct definitions and details on operationalization
- Recommendations for improving validity, reliability, standardization, and reporting in dialogue system evaluation
- Identification of open questions around relating constructs, developing metrics for new models, and connecting to customer service theory

The paper concludes that while intrinsic system performance is well studied, there are opportunities to better incorporate extrinsic factors and connect to neighboring fields like marketing and human-computer interaction. Establishing standardized terminology and reporting procedures is an important step towards more integrated evaluation practices.
