# [On the Inadequacy of Similarity-based Privacy Metrics: Reconstruction   Attacks against "Truly Anonymous Synthetic Data''](https://arxiv.org/abs/2312.05114)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper analyzes the privacy metrics and filters commonly used by synthetic data companies to empirically guarantee privacy. The authors demonstrate several critical flaws with relying solely on similarity-based metrics, including lack of theoretical guarantees, treating privacy as a binary property, non-contrastive computations, and more. To highlight these weaknesses, they propose ReconSyn, a novel reconstruction attack that recovers the majority of underrepresented training records (outliers) by querying the privacy metrics and a single trained generative model. Experiments across five datasets and models show that ReconSyn successfully reconstructs at least 78% of outliers in all settings. Crucially, the attack remains effective even when the models satisfy differential privacy or have severely restricted modeling capabilities. Overall, the paper serves as a stark warning against attempts to ensure privacy purely through empirical evaluations rather than established privacy-preserving techniques. It advises practitioners to prioritize privacy and rely on notions like differential privacy when working with sensitive data.


## Summarize the paper in one sentence.

 This paper analyzes the inadequacy of similarity-based privacy metrics for synthetic data and shows how they can be exploited to reconstruct sensitive outliers from the training data.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. The authors are the first to analyze the undesirable properties of the most common similarity-based privacy metrics (SBPMs) used in industry to empirically "guarantee" the privacy of synthetic data.

2. They propose a novel reconstruction attack, ReconSyn, with minimal and realistic assumptions - black-box access to a single trained generative model and the privacy metrics. 

3. They demonstrate that applying differential privacy to the generative model does not mitigate ReconSyn when combined with unperturbed heuristics, as leakage persists through the metrics.

4. They show that using similarity-based privacy metrics does not provide GDPR compliance.

5. They discuss how, assuming a similar threat model, ReconSyn can be adapted to other attacks like membership and attribute inference.

In summary, the main contribution is analyzing the flaws of similarity-based privacy metrics for synthetic data and proposing a reconstruction attack that exploits these weaknesses to violate privacy, even when differential privacy is used, due to the metrics leaking sensitive information. This shows that reasoning about privacy purely through empirical evaluation is inadequate.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Synthetic data
- Differential privacy (DP) 
- Generative models
- Privacy metrics
- Similarity-based privacy metrics (SBPMs)
- Reconstruction attack
- Outliers
- ReconSyn attack
- SampleAttack
- SearchAttack

The paper analyzes commonly used similarity-based privacy metrics in the synthetic data industry and shows their limitations. It proposes a new reconstruction attack called ReconSyn that combines SampleAttack and SearchAttack to successfully recover outliers from the training data. The attack makes minimal assumptions and works even against models trained with DP or low utility models. Overall, the paper demonstrates the inadequacy of relying solely on empirical privacy evaluations for synthetic data and advocates using established privacy notions like DP.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes a reconstruction attack called ReconSyn against similarity-based privacy metrics. What are the key assumptions made about the adversarial model and how realistic are they? Could the attack plausibly be made more practical under different assumptions?

2. ReconSyn comprises two subattacks - SampleAttack and SearchAttack. What are the key strategies employed by each? What are their relative strengths and weaknesses? Could you conceive of alternative search strategies that may perform better?

3. The paper demonstrates ReconSyn against several generative models on different datasets. What factors contribute to its variable performance across settings? Can you hypothesize why graphical models appear more vulnerable than GANs? 

4. ReconSyn targets the reconstruction of outliers or underrepresented train records. Why is this a sensible strategy, both from an attacker's and a regulator's perspective? How does targeting outliers simplify or complicate the attack?

5. The privacy metrics analyzed make use of discretization and Hamming distance. What impact does this design choice have on privacy evaluations and attack strategies? How could relying on continuous data and Euclidean distances affect ReconSyn?

6. Differential privacy (DP) is proposed as a principled defense against privacy attacks. The paper shows DP does not mitigate ReconSyn due to metric access. What modifications could make DP effective? Does this demonstrate inherent weaknesses in DP or just flawed implementation?

7. ReconSyn requires access to a fitted generator and privacy metrics. What auxiliary information could supplement or replace these attack requirements? For example, could partial knowledge of train data or distribution suffice?

8. The attack complexity grows exponentially in data dimensionality. What techniques could address this limitation and extend ReconSyn to medical imagery, video, etc.? Would different search heuristics help?

9. ReconSyn aims to completely violate privacy by recovering full train records. How could its framework be adapted for membership inference or attribute inference attacks? What would a tailored strategy for those scenarios look like?

10. The privacy metrics analyzed are widely used in industry. What are the practical implications of ReconSyn? Should regulators prohibit empirical evaluations? Could metrics be repaired or safely used in combination with other privacy technologies?


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Many companies use ad-hoc heuristics like similarity-based privacy metrics (SBPMs) to empirically evaluate the privacy of synthetic data instead of established frameworks like differential privacy (DP). 
- The paper analyzes SBPMs used by leading industry providers and identifies several critical flaws in relying solely on empirical evaluation to guarantee privacy.
- It shows SBPMs can be inconsistent, do not provide theoretical privacy guarantees, treat privacy as a binary property, lack worst-case analysis, etc.

Proposed Solution:
- The paper introduces ReconSyn, a novel reconstruction attack to demonstrate the unreliability of SBPMs.
- ReconSyn has black-box access to only a trained generative model and privacy metrics. It reconstructs train data outliers (underrepresented records) which are inherently more difficult to model.
- The attack comprises SampleAttack to generate potential outliers and query the metrics, and SearchAttack to refine the matches by modifying values.

Main Contributions:
- Empirically demonstrates inconsistencies and counter-examples that trick SBPMs to label non-private data as private.
- ReconSyn successfully recovers 78-100% of outliers across various models and datasets with perfect precision.
- Shows applying DP or using low-utility models does not mitigate ReconSyn due to metric leakage.
- Argues SBPMs cannot provide robust privacy guarantees and should not replace established notions like DP.
- Warns against potential privacy violations from industry's empirical evaluation practices for synthetic data.

In summary, the paper highlights the severe flaws of reasoning about privacy purely through SBPMs and empirical metrics, proposing ReconSyn attack to unequivocally demonstrate their unreliability. It advises practitioners to rely on formal privacy frameworks like DP.
