# Considering Likelihood in NLP Classification Explanations with Occlusion   and Language Modeling

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How do explanation methods that consider the discrete structure and likelihood of language data differ from methods that ignore these properties, when explaining modern NLP models with increasing syntactic capabilities?The key points are:- Modern NLP models have increasing syntactic and semantic understanding of language.- Current occlusion methods often produce invalid or unlikely inputs, not utilizing models' syntactic abilities. - Gradient methods disregard the discrete distribution of language data.- The paper proposes a new method OLM that uses a language model to produce likely replacements when occluding parts of the input. - Experiments compare OLM to baselines using occlusion and gradients.- Results show OLM explanations differ from baselines, suggesting the importance of considering data likelihood and discrete structure for explaining NLP models.So in summary, the central question examines how considering properties of discrete language data impacts the explanations produced for modern NLP models, compared to methods that ignore these properties. The proposed OLM method accounts for data likelihood and structure. Experiments demonstrate that this provides distinctive explanations compared to baselines.


## What is the main contribution of this paper?

The main contribution of this paper is presenting OLM, a new explanation method for NLP models that combines occlusion and language modeling. The key ideas are:- OLM generates replacements for occluded words using a language model, producing syntactically valid and contextually appropriate inputs. This accounts for the discrete structure of language data better than gradient methods or naive occlusion.- Theoretical analysis showing OLM satisfies several desirable axioms like Implementation Invariance and Sensitivity-1. - Introduction of the Class Zero-Sum axiom, an alternative to Completeness for explanation methods.- Experiments comparing OLM to deletion, UNK, Sensitivity Analysis, Gradient*Input, and Integrated Gradients. OLM gives distinctive, low-correlated explanations, suggesting the importance of syntactic validity and likelihood.So in summary, OLM is a new occlusion-based explanation method tailored to modern NLP models with increasing syntactic capabilities. It has a stronger theoretical motivation than previous methods, and experiments demonstrate it produces distinctive explanations that consider likelihood.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a new explanation method OLM that uses a language model to generate syntactically and semantically likely replacements when occluding words from an input text, in order to provide more faithful explanations of NLP models compared to existing methods like deletion/UNK and gradient-based approaches.
