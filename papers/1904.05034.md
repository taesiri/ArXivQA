# [ThumbNet: One Thumbnail Image Contains All You Need for Recognition](https://arxiv.org/abs/1904.05034)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is:How can we accelerate deep convolutional neural networks (CNNs) for efficient test-time deployment by enabling the networks to infer accurately on lower resolution, thumbnail images?The key hypotheses are:1) Reducing the input image size will lower the computation and memory costs of running a CNN model, allowing for faster and more efficient inference. 2) It is possible to train a CNN model to perform equally well on thumbnail images as on full-size images, through techniques like knowledge distillation and feature mapping regularization. 3) A supervised image downscaling approach can be developed to generate thumbnail images that retain critical discriminative information for the model compared to typical downscaling methods like bicubic interpolation.4) The proposed framework, called ThumbNet, can learn to generate thumbnail images and an efficient inference network that preserves accuracy of the original full-input network at substantial speedup ratios.So in summary, the paper focuses on accelerating CNNs by training them to work well on smaller thumbnail images rather than the full-sized inputs, enabling major improvements in efficiency and resource requirements while maintaining accuracy. The key hypotheses center around whether effective techniques can be developed to accomplish this goal successfully.


## What is the main contribution of this paper?

The main contribution of this paper is proposing ThumbNet, a unified framework to accelerate deep convolutional neural networks (CNNs) by enabling them to infer on thumbnail images. Specifically:- ThumbNet trains a network to perform equally well on small input images as the original network on large images. This allows using thumbnail images at test time to dramatically reduce computation and memory requirements.- A key component is a supervised image downscaler that generates thumbnail images preserving discriminative information. The downscaler is trained with losses including moment-matching, knowledge distillation, classification, and feature-mapping regularization.- Experiments show ThumbNet can accelerate networks by 4x on ImageNet and 16x on Places with minimal accuracy drop. The downscaler also generalizes to new datasets and networks. - Compared to prior art like LWAE, ThumbNet is more efficient as it only requires one thumbnail image and network at test time. It also achieves higher or comparable accuracy.In summary, ThumbNet provides an orthogonal way to accelerate deep CNNs by enabling inference on thumbnail images, with a supervised downscaler that generates generic discriminative thumbnails. This allows substantial reductions in computation and memory for deployment.
