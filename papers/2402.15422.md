# [A Data-Centric Approach To Generate Faithful and High Quality Patient   Summaries with Large Language Models](https://arxiv.org/abs/2402.15422)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Patients often lack understanding of their hospitalization and medical instructions upon discharge. However, healthcare workers have limited time to provide explanations.
- Large language models (LLMs) show promise for generating patient summaries, but they are prone to hallucinations - generating unsupported or incorrect facts.
- Evaluating hallucinations requires thorough human review, but this is difficult and time-consuming.

Proposed Solution: 
- Create a filtered clinical notes dataset called MIMIC-IV-Note-DI with 100k examples.
- Develop a rigorous protocol for annotating hallucinations in patient summaries.  
- Have medical experts annotate 100 real and 100 generated summaries for hallucinations.
- Create hallucination-free and improved training data subsets with 100 examples.
- Evaluate data-centric approaches to reduce hallucinations in LLMs like Llama 2 and GPT-4 while retaining key information.
- Conduct qualitative analysis of summaries generated by fine-tuned LLMs.
- Explore GPT-4 for automatic hallucination detection.

Main Contributions:
- MIMIC-IV-Note-DI dataset for training patient summarization models
- Protocol and benchmark dataset for labeling hallucinations  
- Demonstration that fine-tuning on hallucination-free data reduces hallucinations in LLMs
- Finding that GPT-4 generates very good summaries even without fine-tuning
- Emphasis on importance of high-quality training data for LLMs
- Analysis showing common metrics do not indicate faithfulness
- Promising results for GPT-4 on automatic hallucination detection
