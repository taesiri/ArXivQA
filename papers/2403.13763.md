# [Practical End-to-End Optical Music Recognition for Pianoform Music](https://arxiv.org/abs/2403.13763)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Optical music recognition (OMR) has seen great progress recently using end-to-end deep learning models. However, most progress has been on monophonic or homophonic scores, while piano scores remain a challenge. 
- Piano scores have multiple independent voices that are difficult to linearize for sequence models. Most OMR systems use custom linearized formats instead of structured formats like MusicXML. This makes it hard to compare systems.
- Evaluation is also difficult. Metrics like symbol error rate depend on the encoding and don't correlate well with human assessment of recognition quality.

Proposed Solution:
- Introduce Linearized MusicXML (LMX) - a sequential format derived from MusicXML that retains compatibility with it. LMX linearizes the MusicXML tree structure using depth-first traversal.
- Implement direct conversion between LMX and MusicXML. This allows end-to-end training with MusicXML data.
- Create the OLiMPiC dataset based on the OpenScore Lieder corpus piano scores. It has over 17,000 synthesis samples and 1,500 test samples from IMSLP scans.
- Use Tree Edit Distance (TEDn) to compare MusicXML ground truth with recognition output directly. TEDn correlates better with human assessment.

Main Contributions:
- LMX format and MusicXML converters to enable end-to-end OMR with MusicXML data
- OLiMPiC dataset with synthetic and real-world scanned piano images along with MusicXML ground truth  
- TEDn evaluation method to compare MusicXML files directly
- Achieve state-of-the-art results on piano scores, with less than 20% TEDn error on real-world test images

The proposed infrastructure brings end-to-end OMR systems much closer to practical usefulness by supporting MusicXML natively. The OLiMPiC dataset and TEDn evaluation provide a more realistic assessment of real-world piano score recognition performance.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes Linearized MusicXML for encoding sheet music to enable end-to-end optical music recognition with sequence-to-sequence models, collects a challenging piano dataset, establishes evaluation based on tree edit distance between MusicXML representations, and achieves state-of-the-art piano music recognition results.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1) Proposing and implementing a direct linearization and de-linearization procedure for MusicXML (LMX format) to allow training end-to-end models directly while maintaining compatibility with the industry-standard MusicXML format. 

2) Creating a new dataset called OLiMPiC, based on the OpenScore Lieder corpus, consisting of pianoform music notation with MusicXML ground truth. It has synthetic training images and real-world dev/test images from IMSLP scans.

3) Establishing an evaluation pipeline that compares MusicXML files directly using the Tree Edit Distance (TEDn) metric, which better correlates with human editors' preferences.

4) Achieving state-of-the-art performance on pianoform music using the proposed methods and datasets.

In summary, the main contribution is improving the infrastructure for optical music recognition of pianoform scores - the input, output, training data, and evaluation - to bring recent progress in end-to-end models closer to useful applications.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it are:

- Optical Music Recognition (OMR)
- end-to-end models
- pianoform music
- MusicXML
- Linearized MusicXML (LMX) 
- OpenScore Lieder Corpus
- OLiMPiC dataset
- Tree Edit Distance (TEDn)
- evaluation metrics
- sequence-to-sequence models
- state-of-the-art results

The paper proposes a linearized version of MusicXML called LMX to allow training end-to-end models on pianoform music and outputting the industry-standard MusicXML format. It creates a new challenging dataset called OLiMPiC based on the OpenScore Lieder corpus and establishes an evaluation methodology using Tree Edit Distance to compare MusicXML representations directly. The experiments in the paper achieve state-of-the-art results on pianoform music recognition and demonstrate the viability of the proposed LMX format and evaluation approach.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes a linearized representation of MusicXML called LMX. What were the key design principles behind LMX and what modifications were made to reduce verbosity compared to standard MusicXML?

2. The paper creates a new pianoform music dataset called OLiMPiC based on the OpenScore Lieder corpus. What steps were taken to extract the piano parts from the original MusicXML files and prepare them as individual systems with LMX annotations? 

3. The paper argues that evaluating OMR systems directly on structured format like MusicXML files is preferable to metrics like SER. What is the proposed TEDn metric and how does it aim to better correlate with human judgments of recognition quality?

4. What MusicXML canonization procedure does the method rely on and why does this represent a limitation regarding transparency and standalone use of the LMX workflow?

5. What types of training data augmentations were applied and what was their effect on recognition performance on the scanned OLiMPiC test set images?

6. How does the model architecture balance efficiency and performance compared to recent Transformer-based approaches? What inductive biases helped improve generalization?  

7. What categories of musical symbols could not be encoded in LMX? Approximately what proportion of nodes did these constitute in the OLiMPiC data based on the TEDn results?

8. Tuplets represented a major remaining challenge - what aspect caused difficulties recognizing implicit triplets not explicitly marked in the notation?

9. How much worse does the model perform on the real-world scanned OLiMPiC images compared to the synthetic training data? What does this suggest about remaining gaps to practical OMR use cases?

10. The paper argues we are significantly closer to OMR systems usable by end users thanks to improvements in infrastructure. What further community adoption could help address remaining limitations?
