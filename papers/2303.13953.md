# [AssetField: Assets Mining and Reconfiguration in Ground Feature Plane   Representation](https://arxiv.org/abs/2303.13953)

## What is the central research question or hypothesis that this paper addresses?

The central hypothesis of this paper is that representing 3D scenes with explicit ground feature planes enables intuitive object-level and group-level editing of neural radiance fields. The key claims are:- Factorizing radiance fields into ground feature planes and a shared vertical axis encourages ground planes to encode more informative scene contents and layout.- Modeling scene density, color, and semantics in integrated RGB-DINO planes makes them more robust to vertical object displacement, enabling cross-scene analogue discovery. - Assets can be directly mined and grouped from the ground planes in an unsupervised manner. - Storing template feature patches in a shared asset library allows efficient group editing by manipulating category templates.- The ground plane representation provides an intuitive "canvas" for users to manipulate individual objects or entire scene layouts.- Realistic novel views can be rendered for new scene configurations by combining edited ground planes with original vertical axes and decoder networks.In summary, the ground plane radiance field representation enables object-level and group-level editing flexibility reminiscent of traditional graphics pipelines, while retaining the realism of neural rendering.
