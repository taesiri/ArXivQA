# [Disentangling Linear Mode-Connectivity](https://arxiv.org/abs/2312.09832)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Linear mode connectivity (LMC) of neural network loss landscapes is an intriguing phenomenon but lacks theoretical understanding. 
- While empirical evidence on LMC is abundant, there is no systematic study on when networks exhibit LMC.

Proposed Solution:
- The authors explore how LMC is affected by 3 factors - architecture, training strategy, and dataset.
- They identify a minimal non-linear model (1 hidden layer MLP with ReLU activation) that robustly exhibits LMC as a baseline.
- They study effects of:
  - Architecture: Introducing locality, weight-sharing, sparsity. Locality preserves LMC but weight-sharing breaks it.
  - Optimization: ADAM breaks LMC more than SGD. LMC can be recovered by modifying learning rate and adding warm-up.
  - Dataset: Increasing complexity hinders LMC.

Main Contributions:  
- Provide a systematic study isolating factors that affect LMC in neural nets.
- Identify a minimal model amenable to theoretical analysis that clearly shows how architecture, optimization, and datasets influence LMC.
- The insights serve as an empirical guide for future theoretical work on understanding the inner workings of LMC.

In summary, the paper performs a principled investigation to disentangle the effects of various components on the linear mode connectivity of neural network loss landscapes. The minimal setting identified can facilitate theoretical progress on this phenomenon.
