# [Towards Fairness-Aware Adversarial Learning](https://arxiv.org/abs/2402.17729)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Towards Fairness-Aware Adversarial Learning":

Problem:
- Deep learning models can be vulnerable to adversarial attacks, where small perturbations to inputs can cause misclassifications. Adversarial training enhances robustness against such attacks.  
- However, recently it has been shown that adversarial training can introduce unfairness in robustness across classes, known as the robust fairness issue. The robust accuracy can vary significantly between classes.
- This is problematic for safety-critical applications like self-driving cars, where certain categories like humans need consistently high robustness.

Proposed Solution: 
- The paper proposes that the robust fairness issue arises due to unknown distribution shifts between classes induced by adversarial perturbations.
- They formulate a novel Fairness-Aware Adversarial Learning (FAAL) approach based on distributionally robust optimization to address such shifts.
- FAAL has 3 phases - (1) Generate adversarial examples (2) Learn distributionally adversarial class weights by maximizing loss under distribution shift constraints (3) Minimize loss weighted by learned weights to update model.
- Weights force model to learn under worst-case class distribution shifts, improving fairness.

Main Contributions:
- First work to connect robust fairness to distribution shifts and use distributionally robust optimization to address it.
- Propose a new min-max-max adversarial learning formulation with intermediate maximization over distributions.
- Achieve state-of-the-art robust fairness results on CIFAR-10 and CIFAR-100 with only 2 epochs of fine-tuning, demonstrating efficiency.
- Show FAAL can generalize to enhance multiple adversarial training methods like PGD, TRADES etc.
- Provide theoretical generalization guarantee for learned adversarial weights.

In summary, the paper provides a novel perspective and solution methodology to address the critical robust fairness problem in adversarial learning based on distributionally robust optimization.
