# [Physical-World Optical Adversarial Attacks on 3D Face Recognition](https://arxiv.org/abs/2205.13412)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to physically attack real-world 3D face recognition systems using adversarial illumination. The key hypothesis is that by optimizing perturbations in the projected illumination and modeling the face reflection process, it is possible to generate adversarial point clouds that can dodge or impersonate 3D face recognition systems.Specifically, the paper proposes two main attack methods:1. Phase Shifting Attack: This attacks multi-step structured light systems by hiding perturbations in the projected fringe patterns. It involves the phase shifting algorithm in the attack optimization process through a differential 3D reconstruction.2. Phase Superposition Attack: This uses an additional projector to add perturbations. It models the face relighting process through a Lambertian reflectance model and optimizes the noise end-to-end to attack single-step systems.The overall hypothesis is that by carefully designing the attack pipeline for 3D structured light imaging, adversarial illuminations can be generated to attack real-world 3D face recognition with high success rates using fewer perturbations than previous physical attacks.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes novel physical adversarial attacks against 3D face recognition using adversarial illumination. The attacks can generate point-wise perturbations at arbitrary 3D positions.2. It involves the complex face reflection process in the attack pipeline through the Lambertian reflectance model and a differential 3D reconstruction algorithm. 3. It introduces a 3D transform invariant loss and sensitivity maps to improve the attack's robustness and invisibility. 4. It evaluates the attacks on various 3D face recognition models, including both point cloud based and depth image based methods. The results show the attack can achieve high success rates while needing fewer perturbations than previous physical attacks.In summary, this paper presents the first physical adversarial attack method for 3D face recognition that considers the face reflection process and can generate precise 3D perturbations. The attacks are demonstrated to be effective against state-of-the-art 3D face recognition systems.
