# [Flow supervision for Deformable NeRF](https://arxiv.org/abs/2303.16333)

## What is the central research question or hypothesis that this paper addresses?

 This paper presents a new method for supervising deformable neural radiance fields (NeRF) using optical flow, with the goal of improving novel view synthesis for monocular videos with rapid object motion. 

The key research question is: how can optical flow be used to provide temporal supervision for the backward warping field used in deformable NeRF?

The main hypothesis is that enforcing optical flow constraints between frames will provide useful temporal regularization that helps deformable NeRF avoid poor local minima during optimization. This will improve deformable NeRF's performance on videos with more rapid object motion compared to using only photometric supervision.

The key insight presented is that the backward warping function used in deformable NeRF does not need to be inverted to compute scene flows between frames. By applying the inverse function theorem, velocities can be analytically computed from the backward warp. These velocities are then integrated over time to compute scene flows for optical flow supervision.

So in summary, this paper hypothesizes that optical flow supervision computed directly from the backward warp will improve deformable NeRF optimization, and presents a method to achieve this supervision without needing to invert the warp function. Experiments validate the hypothesis by demonstrating improved novel view synthesis on challenging monocular video datasets.


## What is the main contribution of this paper?

 The main contribution of this paper is deriving an analytical solution to compute velocities of objects directly from the backward warping field of deformable NeRF. This allows using optical flow as supervision to improve novel view synthesis results for videos with rapid object motions.  

Specifically, the key contributions are:

- Deriving velocities from the backward warp using the inverse function theorem, without needing to invert the warp. This makes it applicable to many deformation representations.

- Using the velocities to compute scene flows via temporal integration. This allows enforcing optical flow constraints on the deformation field. 

- Demonstrating significant improvements on monocular novel view synthesis, especially for videos with rapid motions. 

- Advocating to remove gauge freedom in deformable NeRF by attaching the canonical frame to an input frame. This improves background stability.

Overall, this work enables using optical flow supervision for deformable NeRF in an efficient and generalizable manner. The flow supervision helps optimize the deformation field and improve view synthesis. This could be useful for other dynamic 3D reconstruction works using deformable representations.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper presents a method to supervise deformable neural radiance fields (NeRFs) with optical flow by deriving an analytical solution to compute object velocities directly from the backward warping field, avoiding the need to invert the warp and enabling the use of common deformation representations like neural networks.


## How does this paper compare to other research in the same field?

 Here are some key points comparing this paper to other related works on deformable NeRF:

- The main contribution is using optical flow supervision on the backward warping field of deformable NeRF. This is novel compared to prior works like Nerfies, NR-NeRF, etc. that do not use any flow supervision. 

- Compared to methods using neural scene flow fields (NSFF, Gao et al.) or blend skinning (Yang et al.), this paper's approach is more general and efficient since it does not require inverting the backward warp analytically. The derivation using the inverse function theorem allows applying flow supervision to any differentiable backward warp function.

- Compared to methods using invertible normalizing flows (Lei et al., Cai et al.), this paper's approach has fewer architectural constraints on the warp function and does not need expensive flow integration over long sequences.

- Unlike some other methods, this paper removes the gauge freedom which helps stabilize background reconstruction without needing separate modeling.

- A limitation is the ambiguity in recovering correct relative scale of object motions from monocular video. The paper shares this challenge with other monocular methods without depth supervision like NSFF.

- Experiments show advantages over no-flow baselines, and competitive results to NSFF on some metrics. But scale ambiguity affects quantitative metrics unfavorably.

Overall, the key novelty is an efficient and general way to apply optical flow supervision to deformable NeRFs. This could enable better view synthesis on dynamic scenes, especially non-teleporting videos. The theory and experiments validate the utility of this contribution.


## What future research directions do the authors suggest?

 Based on my reading of the paper, here are some of the future research directions suggested by the authors:

- Improving the method's ability to recover correct relative scale of moving objects in the scene. The authors note their method suffers from scale ambiguity due to the lack of depth supervision. They suggest using mid or higher level reasoning, like learning-based depth estimation or 2D supervision from image generative models, could help recover more accurate scale.

- Making the method more robust to large object deformations when selecting the canonical frame. The authors show an example where choosing a topologically very different frame as canonical leads to degenerated results. More sophisticated algorithms for canonical frame selection could improve this.

- Adapting the method to work with more general camera motions beyond frontal views. The current implementation assumes frontal cameras. Extending it to support inward or outward facing cameras is noted as future work.

- Reducing the long optimization time through more efficient implementation. The authors note recent work on speeding up NeRF optimization could help make their approach more efficient.

- Applying the proposed flow supervision technique to other vision and graphics problems that use backward warping. The authors suggest their way of enforcing flow constraints on backward warps could have broad applicability beyond deformable NeRF.

- Exploring different ways of rendering flow from 3D scene flow or evaluating flow loss. The authors share some alternatives they tried which underperformed their current approach. Understanding why those did not work as well could lead to better solutions.

In summary, the main future directions revolve around improving robustness, efficiency, and generalizability of the method to more complex scenarios and other problems. Enforcing flow supervision on backward warps appears to be a useful technique worthy of further exploration.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points from the paper:

The paper presents a new method to enable deformable neural radiance fields (NeRFs) to use optical flow supervision. Deformable NeRFs represent dynamic scenes as deformations from a canonical space, but enforcing optical flow constraints on the backward warping field used is challenging. The main contribution is deriving an analytical solution to compute velocity fields directly from the backward warp using the inverse function theorem. This allows computing scene flows via temporal integration of velocities, without needing to invert the backward warp. Optical flows between frames can then supervise the deformable NeRF optimization. Experiments demonstrate the proposed flow supervision significantly improves novel view synthesis on videos with rapid motion compared to baselines without flow supervision. Advantages are the general applicability to different backward warp representations and computational efficiency compared to other flow-based methods. A secondary contribution is removing gauge freedom in deformable NeRF by fixing the canonical space to a reference frame, which improves background reconstruction.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points in the paper:

The paper presents a new method for deformable neural radiance fields (NeRF) that enables the use of optical flow as direct supervision. Deformable NeRF represents a dynamic scene as a deformation of a static template NeRF. The deformation is modeled as a backward warping that maps points from the input frames back to a canonical space. However, current deformable NeRF methods lack explicit modeling or supervision of the scene flow between frames. The authors propose a way to analytically compute velocities and scene flows directly from the backward warping field, without needing to invert it. This allows optical flow between frames to be rendered from the model and used as supervision. Experiments show that adding flow supervision significantly improves results on videos with rapid motions compared to baseline deformable NeRFs trained with only photometric losses.

The proposed flow computation method applies to various deformation representations thanks to its derivation from the inverse function theorem. This is an advantage over prior works that rely on restricted network architectures to ensure invertibility. Compared to methods using explicit neural scene flow fields, this approach is also more computationally efficient since flows can be computed directly from the backward warp without integration. The authors also address the gauge freedom issue in deformable NeRF that leads to background jittering. Overall, optical flow supervision constrained to the backward warp provides useful temporal regularization that improves deformable NeRF view synthesis, especially for videos with large object motion. Limitations remain due to monocular scale ambiguity, but the proposed flow computation provides a general tool for temporal supervision.
