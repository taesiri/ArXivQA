# [Flow supervision for Deformable NeRF](https://arxiv.org/abs/2303.16333)

## What is the central research question or hypothesis that this paper addresses?

 This paper presents a new method for supervising deformable neural radiance fields (NeRF) using optical flow, with the goal of improving novel view synthesis for monocular videos with rapid object motion. 

The key research question is: how can optical flow be used to provide temporal supervision for the backward warping field used in deformable NeRF?

The main hypothesis is that enforcing optical flow constraints between frames will provide useful temporal regularization that helps deformable NeRF avoid poor local minima during optimization. This will improve deformable NeRF's performance on videos with more rapid object motion compared to using only photometric supervision.

The key insight presented is that the backward warping function used in deformable NeRF does not need to be inverted to compute scene flows between frames. By applying the inverse function theorem, velocities can be analytically computed from the backward warp. These velocities are then integrated over time to compute scene flows for optical flow supervision.

So in summary, this paper hypothesizes that optical flow supervision computed directly from the backward warp will improve deformable NeRF optimization, and presents a method to achieve this supervision without needing to invert the warp function. Experiments validate the hypothesis by demonstrating improved novel view synthesis on challenging monocular video datasets.


## What is the main contribution of this paper?

 The main contribution of this paper is deriving an analytical solution to compute velocities of objects directly from the backward warping field of deformable NeRF. This allows using optical flow as supervision to improve novel view synthesis results for videos with rapid object motions.  

Specifically, the key contributions are:

- Deriving velocities from the backward warp using the inverse function theorem, without needing to invert the warp. This makes it applicable to many deformation representations.

- Using the velocities to compute scene flows via temporal integration. This allows enforcing optical flow constraints on the deformation field. 

- Demonstrating significant improvements on monocular novel view synthesis, especially for videos with rapid motions. 

- Advocating to remove gauge freedom in deformable NeRF by attaching the canonical frame to an input frame. This improves background stability.

Overall, this work enables using optical flow supervision for deformable NeRF in an efficient and generalizable manner. The flow supervision helps optimize the deformation field and improve view synthesis. This could be useful for other dynamic 3D reconstruction works using deformable representations.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper presents a method to supervise deformable neural radiance fields (NeRFs) with optical flow by deriving an analytical solution to compute object velocities directly from the backward warping field, avoiding the need to invert the warp and enabling the use of common deformation representations like neural networks.


## How does this paper compare to other research in the same field?

 Here are some key points comparing this paper to other related works on deformable NeRF:

- The main contribution is using optical flow supervision on the backward warping field of deformable NeRF. This is novel compared to prior works like Nerfies, NR-NeRF, etc. that do not use any flow supervision. 

- Compared to methods using neural scene flow fields (NSFF, Gao et al.) or blend skinning (Yang et al.), this paper's approach is more general and efficient since it does not require inverting the backward warp analytically. The derivation using the inverse function theorem allows applying flow supervision to any differentiable backward warp function.

- Compared to methods using invertible normalizing flows (Lei et al., Cai et al.), this paper's approach has fewer architectural constraints on the warp function and does not need expensive flow integration over long sequences.

- Unlike some other methods, this paper removes the gauge freedom which helps stabilize background reconstruction without needing separate modeling.

- A limitation is the ambiguity in recovering correct relative scale of object motions from monocular video. The paper shares this challenge with other monocular methods without depth supervision like NSFF.

- Experiments show advantages over no-flow baselines, and competitive results to NSFF on some metrics. But scale ambiguity affects quantitative metrics unfavorably.

Overall, the key novelty is an efficient and general way to apply optical flow supervision to deformable NeRFs. This could enable better view synthesis on dynamic scenes, especially non-teleporting videos. The theory and experiments validate the utility of this contribution.
