# [GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models   Evaluation](https://arxiv.org/abs/2402.15745)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing multimodal benchmarks focus on primary perception abilities and commonsense knowledge, which are insufficient to comprehensively evaluate large vision-language models (LVLMs).
- There is a need for a more human-level benchmark to test LVLMs on a wide range of capabilities including perception, understanding, knowledge and reasoning.

Proposed Solution:  
- The authors propose GAOKAO-MM, a new Chinese multimodal benchmark based on the Chinese College Entrance Examination (GAOKAO) questions.
- It covers 8 subjects (Chinese, Math, Physics, etc.) and comprises 646 multiple choice questions with 897 images across 12 types. 
- Questions are much longer (4x) than existing benchmarks and require fusing knowledge with visual and textual reasoning to answer correctly.

Main Contributions:
- Introduces a human-level, comprehensive Chinese benchmark to evaluate LVLMs.  
- Tests 10 prominent LVLMs and finds accuracy lower than 50% for all, showing considerable room for improvement.
- Provides multi-dimensional analysis showing models still lack abilities in mathematical reasoning, comprehending long text+images, and robustness across different inputs.
- Believes GAOKAO-MM can facilitate development of LVLMs towards artificial general intelligence and their application in education.

In summary, the paper presents GAOKAO-MM, a new challenging Chinese multimodal QA dataset that requires human-level well-rounded capabilities from LVLMs, and shows current models still have significant limitations in skills needed for real-world reasoning.
