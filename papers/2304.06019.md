# [Generating Aligned Pseudo-Supervision from Non-Aligned Data for Image   Restoration in Under-Display Camera](https://arxiv.org/abs/2304.06019)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to generate high-quality and well-aligned pseudo training pairs for under-display camera (UDC) image restoration. The key idea is to learn to "copy" details from a high-quality reference image and "paste" them onto the corresponding UDC image in a spatially aligned manner.

The main hypothesis is that using such pseudo training pairs generated from real non-aligned stereo data will lead to improved performance and generalizability for UDC image restoration networks compared to previous approaches like using synthetic data or unpaired training schemes.

To test this hypothesis, the authors propose AlignFormer, a Transformer-based framework to generate aligned pseudo pairs by mitigating both the domain discrepancy and spatial misalignment between UDC and reference images. The effectiveness of the generated pseudo pairs is then evaluated by training a baseline restoration network and comparing against other datasets and methods.

In summary, the central research question is how to create high-quality spatially aligned pseudo pairs from non-aligned real stereo data to improve UDC image restoration. The key hypothesis is that AlignFormer can generate such useful training data better than previous approaches.


## What is the main contribution of this paper?

 The main contribution of this paper is a framework for generating high-quality and well-aligned pseudo training image pairs for under-display camera (UDC) image restoration. The key ideas are:

1. They propose to use a stereo camera setup with one UDC camera and one normal camera to capture images of the same scene. This allows collecting real degraded UDC images and high-quality reference images. 

2. They present AlignFormer, a novel Transformer-based method, to generate pseudo training pairs from the non-aligned stereo images. AlignFormer has two main components:

- Domain Alignment Module (DAM) to reduce the domain discrepancy between UDC and reference images to enable better matching.

- Geometric Alignment Module (GAM) to establish accurate dense correspondences between UDC and reference images using both semantic and geometric cues.

3. The well-aligned and high-quality pseudo pairs from AlignFormer can be used to train UDC restoration networks with standard pixel-wise losses. This avoids previous limitations of using synthetic or monitor-based training data.

4. They demonstrate improved UDC restoration performance by training a baseline network on the AlignFormer pseudo pairs compared to state-of-the-art methods.

In summary, the main contribution is a practical framework to generate realistic aligned training data for UDC restoration, which can alleviate previous issues with training data and lead to better generalization. The AlignFormer leverages Transformer architectures to perform robust alignment even with significant domain gaps between UDC and reference images.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a novel framework called AlignFormer to generate high-quality and well-aligned pseudo training pairs from non-aligned real stereo data (comprised of UDC and reference images) to enable end-to-end training of deep networks for Under-Display Camera image restoration.
