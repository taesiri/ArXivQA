# [Generating Aligned Pseudo-Supervision from Non-Aligned Data for Image   Restoration in Under-Display Camera](https://arxiv.org/abs/2304.06019)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to generate high-quality and well-aligned pseudo training pairs for under-display camera (UDC) image restoration. The key idea is to learn to "copy" details from a high-quality reference image and "paste" them onto the corresponding UDC image in a spatially aligned manner.

The main hypothesis is that using such pseudo training pairs generated from real non-aligned stereo data will lead to improved performance and generalizability for UDC image restoration networks compared to previous approaches like using synthetic data or unpaired training schemes.

To test this hypothesis, the authors propose AlignFormer, a Transformer-based framework to generate aligned pseudo pairs by mitigating both the domain discrepancy and spatial misalignment between UDC and reference images. The effectiveness of the generated pseudo pairs is then evaluated by training a baseline restoration network and comparing against other datasets and methods.

In summary, the central research question is how to create high-quality spatially aligned pseudo pairs from non-aligned real stereo data to improve UDC image restoration. The key hypothesis is that AlignFormer can generate such useful training data better than previous approaches.


## What is the main contribution of this paper?

 The main contribution of this paper is a framework for generating high-quality and well-aligned pseudo training image pairs for under-display camera (UDC) image restoration. The key ideas are:

1. They propose to use a stereo camera setup with one UDC camera and one normal camera to capture images of the same scene. This allows collecting real degraded UDC images and high-quality reference images. 

2. They present AlignFormer, a novel Transformer-based method, to generate pseudo training pairs from the non-aligned stereo images. AlignFormer has two main components:

- Domain Alignment Module (DAM) to reduce the domain discrepancy between UDC and reference images to enable better matching.

- Geometric Alignment Module (GAM) to establish accurate dense correspondences between UDC and reference images using both semantic and geometric cues.

3. The well-aligned and high-quality pseudo pairs from AlignFormer can be used to train UDC restoration networks with standard pixel-wise losses. This avoids previous limitations of using synthetic or monitor-based training data.

4. They demonstrate improved UDC restoration performance by training a baseline network on the AlignFormer pseudo pairs compared to state-of-the-art methods.

In summary, the main contribution is a practical framework to generate realistic aligned training data for UDC restoration, which can alleviate previous issues with training data and lead to better generalization. The AlignFormer leverages Transformer architectures to perform robust alignment even with significant domain gaps between UDC and reference images.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a novel framework called AlignFormer to generate high-quality and well-aligned pseudo training pairs from non-aligned real stereo data (comprised of UDC and reference images) to enable end-to-end training of deep networks for Under-Display Camera image restoration.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this paper compares to other research in the field of under-display camera (UDC) image restoration:

- This paper focuses on generating high-quality and aligned training data for UDC image restoration networks, which is a significant challenge in this field. Previous work has relied on synthetic data or data from monitor-based imaging systems, which have limitations in realism and dynamic range. 

- The key novelty is the use of a Transformer-based framework (AlignFormer) to align real stereo image pairs obtained from a UDC and normal camera. This allows more realistic training data to be generated through "copying" details from the normal image and "pasting" onto the UDC image.

- Other recent work like DISCNet (CVPR 2021) and BNUDC (CVPR 2022) has focused more on architecture designs for the restoration network itself. This paper complements that line of work by contributing better training data.

- The proposed AlignFormer framework integrates optical flow guidance into a Transformer, which is a unique approach for handling the alignment. Prior work like TTSR (ECCV 2020) used semantic similarity but no explicit geometric guidance.

- For data collection, this paper uses a practical stereo setup whereas most prior real data collection relied on beam splitters or manual alignment. The proposed framework is shown to be robust enough to align such stereo pairs.

- Extensive experiments demonstrate the benefit of AlignFormer's pseudo pairs for training restoration networks. Both quantitative metrics and user studies confirm improved performance, especially in recovering fine details.

In summary, this paper makes valuable contributions on the data side for UDC restoration, allowing more real-world and aligned training data to be leveraged. The AlignFormer framework is an innovative way to integrate geometric and semantic guidance within a Transformer structure for this application.
