# [Bridging Cross-task Protocol Inconsistency for Distillation in Dense   Object Detection](https://arxiv.org/abs/2308.14286)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question it aims to address is:How can knowledge distillation for dense object detection be improved by bridging the cross-task protocol inconsistency between distillation and classification?The key hypothesis appears to be:By converting inconsistent cross-task protocols into consistent protocols tailored for dense object detection, both classification and localization distillation can be significantly improved.In particular, the paper identifies that common classification distillation techniques directly adopt the softmax protocol from image classification, which leads to suboptimal results when applied to dense object detectors that use sigmoid. To address this protocol inconsistency, the authors propose a binary classification distillation loss using sigmoid. They also introduce a novel IoU-based localization distillation loss to avoid relying on specific prediction heads like prior work. The central goal is to show these tailored distillation losses that bridge the cross-task inconsistencies can substantially boost student detector performance on tasks like classification and localization for dense object detection.


## What is the main contribution of this paper?

Based on my understanding, the main contributions of this paper are:1. It identifies the cross-task protocol inconsistency problem as a key reason for the ineffectiveness of applying original classification distillation techniques directly to dense object detection. The protocols used for classification distillation (softmax) and dense object detection (sigmoid) differ, leading to suboptimal solutions when minimizing the distillation loss. 2. To address this issue, the paper proposes a Binary Classification Distillation Loss that converts the problem into multiple binary classification distillation tasks. This allows consistent protocols to be used for distillation and dense object detection.3. The paper also proposes an IoU-based Localization Distillation Loss that eliminates the need for a special prediction head like the Generalized Focal Loss used in prior works. This makes the distillation approach more widely applicable.4. Experiments demonstrate that the proposed distillation losses significantly improve performance over baseline and prior logit distillation techniques for dense object detection. The method also combines well with existing feature distillation techniques for further gains.In summary, the key contribution is identifying and addressing the protocol inconsistency issue to enable more effective logit distillation for dense object detection, through tailored binary classification and IoU-based localization distillation losses.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key point from the paper:The paper proposes novel distillation losses tailored for classification and localization in dense object detection to address the limitations of applying existing logit distillation techniques directly from image classification, achieving improved performance.
