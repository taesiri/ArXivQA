# [Optimistic Safety for Linearly-Constrained Online Convex Optimization](https://arxiv.org/abs/2403.05786)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper studies online convex optimization (OCO) with unknown linear constraints. In this setting, at each round the player chooses an action vector, suffers a loss according to an adversarially chosen convex loss function, and then receives noisy bandit feedback on whether their action violated a fixed but unknown linear constraint. The goal is to minimize regret compared to the best fixed action satisfying the constraints, while ensuring the constraints are never violated. 

Prior work achieved $\tilde{O}(T^{2/3})$ regret with zero constraint violations. However, the best regret for OCO without constraints is $\tilde{O}(\sqrt{T})$, so there is a gap.

Proposed Solution: 
The key idea is "optimistic safety" - maintain optimistic (outer approximation) and pessimistic (inner approximation) estimates of the constraint set. Use the optimistic set to choose low regret actions and scale them into the pessimistic set to ensure safety.

Specifically, in each round:
1) Estimate constraints via least squares. 
2) Construct optimistic set (overestimates feasible set) and pessimistic set (underestimates feasible set).
3) Run an online optimization algorithm on optimistic set to get optimistic action.
4) Scale down optimistic action to maximum value that lies in pessimistic set.
5) Play scaled down action and update estimates.

This framework ensures safety via the pessimistic set while still optimizing for low regret via the optimistic set.

Main Contributions:
1) Propose above "optimistic safety" approach and prove it achieves $\tilde{O}(\sqrt{T})$ regret with high probability and zero constraint violations. Improves over prior $\tilde{O}(T^{2/3})$ results using slightly stronger assumptions.

2) Show the algorithm gives $\tilde{O}(\sqrt{T})$ expected regret and zero expected constraint violation when constraints are stochastic. Comparable to algorithms that get $\tilde{O}(\sqrt{T})$ regret and violation for stochastic constraints. 

3) Give computationally efficient version with $\tilde{O}(d^{3/2}\sqrt{T})$ regret.

4) Empirically demonstrate improved performance over benchmarks.
