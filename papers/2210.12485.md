# DANLI: Deliberative Agent for Following Natural Language Instructions

## What is the central research question or hypothesis that this paper addresses?

This paper proposes a neuro-symbolic deliberative agent (DANLI) for following natural language instructions in 3D environments. The central hypothesis is that incorporating explicit symbolic reasoning and planning will allow the agent to better handle complex, long-horizon tasks compared to reactive approaches. Specifically, the paper hypothesizes that:1. Predicting subgoals in symbolic form will allow the agent to monitor and complete hierarchical tasks expressed in natural language instructions.2. Constructing an object-centric spatial-symbolic representation of the environment will support grounded reasoning and planning. 3. Applying online symbolic planning using the predicted subgoals and spatial-symbolic representation will lead to more reliable and efficient task completion compared to reactive approaches.The experiments aim to validate these hypotheses by evaluating DANLI against reactive baselines on the challenging TEACh benchmark. The results show DANLI significantly outperforms the baselines, supporting the claim that incorporating symbolic reasoning and planning mechanisms enables better performance on complex, hierarchical embodied tasks specified through natural language.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a neuro-symbolic deliberative agent, called DANLI, for following natural language instructions in 3D environments. The key ideas are:- It combines neural and symbolic representations for reasoning and planning. Symbolic representations of subgoals, objects, states, and actions enable interpretable planning, while neural models are used for perceiving the environment and extracting high-level goals from language. - It uses online symbolic planning with several innovations tailored for embodied AI, including searching for unobserved objects, pruning the search space, and recovering from action failures. This allows it to create efficient plans dynamically as it acts in the environment.- It achieves strong performance on the challenging TEACh benchmark, significantly outperforming prior reactive approaches. The transparent reasoning process also enables detailed analysis of the agent's capabilities.- It proposes a modular framework that integrates neural perception, language understanding, symbolic representation, and planning components. This demonstrates one effective way of building neuro-symbolic agents for instruction following.In summary, the paper makes contributions in proposing a novel deliberative agent architecture, achieving new state-of-the-art results on a complex benchmark, and providing insights into designing neuro-symbolic systems for embodied AI tasks involving language, perception, and planning. The results show the promise of deliberative neuro-symbolic methods compared to reactive approaches.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a neuro-symbolic deliberative agent, DANLI, that combines learned symbolic representations of subgoals and the surrounding environment with robust symbolic planning to efficiently follow natural language instructions in embodied AI environments.


## How does this paper compare to other research in the same field?

This paper presents a neuro-symbolic deliberative agent called DANLI for following natural language instructions. Here are some key ways it compares to related work:- Most prior work on instruction following uses reactive agents that directly map inputs to actions without explicit reasoning. This paper shows the benefits of a deliberative approach that plans actions using symbolic representations.  - For scene representation, DANLI builds a 3D semantic map with object instances and states. This is more detailed than vector representations used in some prior work, and captures finer details than 3D scene graphs.- For hierarchical policies, DANLI introduces specialized planners for manipulation and navigation actions, rather than just planning at the high level. This enables more reliable subgoal completion.- For symbolic planning, DANLI learns symbolic goals from language and leverages an online-constructed scene representation. This differs from methods that learn planning operators directly from perception. DANLI also adds capabilities like object search and error recovery.- Compared to similar neuro-symbolic planners like JARVIS, a key difference is that DANLI uses automatic planning for low-level actions rather than hand-coded procedures.- The paper shows strong empirical gains over reactive baselines on the challenging TEACh benchmark, including much higher success rates and efficiency.- The interpretable representations and reasoning process also enable analysis of the agent's capabilities and limitations to guide future improvements.In summary, the key novelties are using neuro-symbolic techniques for richer representations and hierarchical planning in instruction following, while achieving strong results on a complex benchmark. The analysis also sheds new light on how to improve instruction following agents.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Handling uncertainty in perception and language grounding - The authors suggest exploring tighter integration between neural and symbolic components to allow for better learning of symbolic representations while still providing interpretable reasoning.- Robust exception handling - The authors suggest incorporating dialog-powered exception handling policies to allow the agent to proactively seek help when it gets stuck, similar to how humans might behave.- Scalability of symbolic representations - The authors suggest improving the scalability of the symbolic representations to novel situations rather than having a predefined symbol set. This could involve using large language models to acquire action planning knowledge in an open-world setting.- Tighter neuro-symbolic integration - The authors suggest exploring ways to allow for better learning of symbolic representations while still providing interpretable reasoning and decision making.- Learning task knowledge in an open world - Rather than relying on hard-coded domain knowledge, the authors suggest moving towards learning task knowledge and predicate symbols in situations where the vocabulary is not pre-defined.- Learning action effects and operators - The authors suggest future work on learning action effects and operators for task and motion planning in a flexible way.In summary, the key future directions focus on improving the learning and scalability of the symbolic representations, integrating neural and symbolic components more tightly, and moving towards acquiring knowledge in an open-world setting rather than relying on predefined vocabulary or hard-coded knowledge. The overarching goal seems to be developing more flexible, learnable, and scalable deliberative agents.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper proposes DANLI, a neuro-symbolic deliberative agent for following natural language instructions in 3D environments. DANLI combines learned symbolic representations of tasks and surroundings with robust symbolic planning. It constructs a semantic spatial representation from visual observations and language, capturing object instances, physical states, and spatial relationships. A neural sequence-to-sequence model then predicts subgoals in symbolic form from the dialog history. Using the subgoals and spatial representation, DANLI applies an online PDDL planning algorithm to generate low-level action plans. To handle partial observability and complexity, it incorporates capabilities like mocking full observability, pruning the search space, and recovering from failed actions. Experiments on the TEACh benchmark show DANLI outperforms reactive baselines in task success rate and efficiency. The reasoning process also provides transparency into the agent's capabilities.
