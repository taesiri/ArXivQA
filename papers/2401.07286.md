# [CANDLE: Iterative Conceptualization and Instantiation Distillation from   Large Language Models for Commonsense Reasoning](https://arxiv.org/abs/2401.07286)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Commonsense reasoning relies on the ability to apply existing knowledge to novel situations, which requires both conceptualization (abstracting concrete instances into general concepts) and instantiation (grounding concepts into new instances). 
- However, most prior work focuses only on conceptualization and relies heavily on human annotations or predefined taxonomies, lacking diversity and scalability. The importance of instantiation is underestimated and the full chain of conceptualization-instantiation is not realized.

Proposed Solution:
- The paper proposes CANDLE, a framework to iteratively perform contextualized conceptualization and instantiation from language models to augment commonsense knowledge bases. 
- It instructs ChatGPT to generate diverse contextualized conceptualizations based on concrete triples. 
- It then instructs LLAMA2 to instantiate these concepts into new instances.  
- Critic models are used to filter low-quality generations.
- The instantiated triples can be fed back to initiate another round of conceptualization.

Main Contributions:
- Constructs a comprehensive commonsense KB with 6M high-quality conceptualizations and instantiations firmly rooted in ATOMIC, far surpassing other benchmarks.
- Demonstrates the efficacy of the full chain of conceptualization and instantiation in improving coverage and diversity. 
- Alleviates the reliance on human annotations by utilizing critic models for quality control.
- Shows extrinsic benefits across tasks by transferring conceptualization and instantiation knowledge to student models, outperforming previous distillation methods.

In summary, the key innovation is completing the chain of conceptualization and instantiation to iteratively expand commonsense knowledge, while ensuring scalability and contextualization. Downstream evaluations validate the quality and benefits of the distilled knowledge.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper introduces CANDLE, a framework that utilizes large language models to iteratively generate contextualized conceptualizations and instantiations from commonsense knowledge bases, which are then used to augment training data for improving downstream commonsense reasoning tasks.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing CANDLE, a distillation framework that realizes the chain of conceptualization and instantiation over commonsense knowledge bases (CSKBs) by instructing large language models to sequentially generate both types of knowledge. Specifically, CANDLE:

1) Completes the full chain of conceptualization and instantiation to introduce both abstract and concrete knowledge that significantly expands the coverage of the original CSKB.

2) Employs critic filtering models to eliminate low-quality generations while avoiding expensive human annotations, making the framework more scalable. 

3) Demonstrates both intrinsic efficacy through evaluations of the distilled knowledge quality and diversity, as well as extrinsic benefits by showing performance improvements when using the distilled knowledge to enhance various downstream commonsense reasoning tasks.

In summary, the key contribution is developing an iterative conceptualization and instantiation distillation framework that leverages the power of large language models to effectively augment commonsense knowledge bases.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this paper include:

- CANDLE - The proposed framework for Conceptualization And iNstantiation Distillation from Large language modEls. Iteratively performs contextualized conceptualization and instantiation to augment commonsense knowledge bases.

- Conceptualization - The process of abstracting concrete instances/events into more general concepts while preserving the original context.

- Instantiation - The process of grounding an abstract concept into more specific instances/events. 

- Knowledge distillation - Transferring knowledge from a large, complex teacher model into a smaller, simpler student model. This paper distills conceptualizations and instantiations from LLMs.

- Commonsense reasoning - The ability to make inferences and draw conclusions based on everyday knowledge about the world.

- Commonsense knowledge base (CSKB) - Structured collections of commonsense facts and relations, like ATOMIC. 

- ATOMIC - A commonsense knowledge graph with 877k textual triples across inferential relationships. Used as the basis for conceptualization and instantiation in this paper.

- Downstream tasks - Tasks like CSKB conceptualization, generative commonsense inference, and zero-shot QA that can benefit from the additional conceptualized and instantiated knowledge.

So in summary, the key ideas have to do with leveraging LLMs to expand commonsense knowledge bases via conceptualization and instantiation, and showing improvements on downstream commonsense reasoning tasks.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the CANDLE method proposed in the paper:

1. How does CANDLE address the issue of relying too heavily on pre-built concept taxonomies and human annotations for collecting conceptualizations and instantiations? What novel techniques does it introduce?

2. Explain the process of contextualized conceptualization in CANDLE. Why is it superior to simply matching instances against concepts from resources like WordNet? 

3. What is the motivation behind employing two separate LLMs, ChatGPT and LLAMA2, for the conceptualization and instantiation steps respectively? What are the tradeoffs?

4. Elaborate on the critic filtering models used in CANDLE and their role. What thresholds were set for eliminating low-quality generations and why? 

5. The paper claims CANDLE instantiations exhibit 78.6% uniqueness. Explain how this was calculated. What implications does this have regarding diversity and knowledge coverage?

6. Describe the process of iterating conceptualization and instantiation in CANDLE using critic filtering. How can this augment commonsense knowledge bases significantly over time?

7. Analyze the results of the intrinsic evaluations conducted for quality and diversity of CANDLE distillations. What conclusions can be drawn regarding ChatGPT and LLAMA2's generation capabilities?  

8. Pick one downstream application in the paper and explain the benefits observed by utilizing CANDLE distillations as supplementary training data. Why does this occur?

9. What are the limitations of CANDLE mentioned in the paper? Provide ideas to address them. 

10. The paper claims CANDLE distillations demonstrate superior benefits compared to symbolic knowledge distillation methods. Elaborate on why this might be the case.
