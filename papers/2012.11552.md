# [OBoW: Online Bag-of-Visual-Words Generation for Self-Supervised Learning](https://arxiv.org/abs/2012.11552)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is: How can we learn powerful image representations in an unsupervised manner using a bag-of-visual-words (BoW) reconstruction task within a teacher-student framework?Specifically, the authors propose a novel approach called OBoW that trains a student convolutional network to reconstruct the BoW representation of an image, given a perturbed version of that image. The BoW representation is generated by a teacher network. The key ideas and contributions are:- Fully online training of both the teacher and student networks, along with online updating of the visual word vocabulary used to generate the BoW targets. This removes the need for pre-training the teacher or doing offline vocabulary learning.- A dynamic BoW prediction module in the student network to handle the continuously evolving visual word vocabulary. - Strategies like aggressive cropping, multi-scale BoW targets, etc. to enhance the contextual reasoning abilities of the learned representations.The central hypothesis is that the proposed OBoW method will be able to learn more powerful contextual representations compared to prior approaches, and will achieve state-of-the-art results on various unsupervised learning benchmarks. The extensive experiments presented aim to validate this hypothesis.In summary, the key research question is how to design an effective unsupervised learning approach based on BoW reconstruction that can learn rich visual representations capturing contextual information. The proposed OBoW method aims to address this question.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing a novel fully online teacher-student learning scheme for unsupervised learning based on bag-of-visual-words (BoW) targets. This overcomes limitations of prior work like BowNet that relied on a pre-trained static teacher network.- Designing a dynamic BoW prediction module and online vocabulary update strategies to enable continuous adaptation of the student network to the changing visual words used for the BoW targets.- Using aggressive spatial image cropping and multi-scale BoW targets to enhance the learning of contextual reasoning skills and more powerful image representations.- Achieving state-of-the-art results on several benchmark tasks like ImageNet classification, Places205 classification, VOC object detection and semi-supervised learning. The method surpasses prior unsupervised learning approaches, including contrastive methods, while using significantly fewer training epochs.In summary, the key contribution is proposing a novel online teacher-student scheme for BoW-based unsupervised learning that can efficiently learn rich contextual image representations surpassing prior state-of-the-art methods. The online nature of the method and strategies to dynamically adapt the BoW prediction seem to be important innovations enabling its strong performance.
