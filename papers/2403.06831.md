# [HDRTransDC: High Dynamic Range Image Reconstruction with Transformer   Deformation Convolution](https://arxiv.org/abs/2403.06831)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
High dynamic range (HDR) imaging aims to fuse multiple low dynamic range (LDR) images with different exposures into a single HDR image that captures details in dark shadows and bright highlights. However, this process suffers from two main issues:

1) Ghosting artifacts due to misalignment of moving objects between LDR images with different exposures. This causes objects to appear blurred or duplicated in the fused HDR image. 

2) Fusion distortions in under/over-exposed regions where information is missing, resulting in halos, blurring and loss of detail.

Proposed Solution: 
The paper proposes an end-to-end deep learning framework called HDRTransDC that establishes alignment and fusion relationships between a reference LDR image and non-reference LDR images to reconstruct high-quality ghost-free HDR images. The main components are:

1) Transformer Deformable Convolution Alignment Module (TDCAM): Uses a Transformer offset estimator and deformable convolutions to extract long-range similar features between reference and non-reference images. This aligns non-reference images to the reference, removing misalignments and filling occluded regions to alleviate ghosting artifacts.

2) Dynamic Weight Fusion Block (DWFB): Adaptively selects useful information from different exposure images in a spatially-aware manner to restore missing content in under/over-exposed regions while maintaining well-exposed content. This reduces fusion distortions. 

Main Contributions:

- Proposes a TDCAM module that leverages Transformer and deformable convolutions to establish long-range alignment relationships between LDR images, effectively removing ghosting artifacts

- Introduces a DWFB module to selectively fuse useful information from different exposure images in a spatially-adaptive way, reducing fusion distortions

- Achieves state-of-the-art performance in HDR reconstruction quality, outperforming previous methods in handling scenes with large motions and severe under/over-exposure

- Demonstrates ability to generalize to reconstruct high-quality HDR images on other datasets without ground truth

In summary, the paper presents an end-to-end framework with specially designed components to establish robust alignment and adaptive fusion relationships between multi-exposure LDR images for high-quality ghost-free HDR reconstruction.
