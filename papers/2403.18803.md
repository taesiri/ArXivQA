# [Projective Methods for Mitigating Gender Bias in Pre-trained Language   Models](https://arxiv.org/abs/2403.18803)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Gender bias in NLP systems is a major issue, especially in pretrained language models like BERT. However, prior work on debiasing BERT has focused only on the final sentence representations and evaluated using intrinsic bias tests like StereoSet's next sentence prediction (NSP) task. There is doubt on whether mitigating intrinsic bias correlates with reduced bias in downstream tasks.

- The authors critically evaluate StereoSet's NSP bias metric, finding flaws in how it measures gender bias. They enhance StereoSet with new metrics like Strength and Distance that better quantify gender bias.

Method: 
- The authors propose novel projective debiasing methods applied to BERT's internal representations, including a new intervention in the self-attention layers. Projections remove gender information from representations. 

- Multiple debiasing variants are evaluated, combining ingredients like information weighting and multi-dimensional gender subspaces. In total, 74 debiased BERT models are produced and analyzed.

Contributions:
- Enhanced version of popular StereoSet benchmark for quantifying intrinsic gender bias in BERT, with improved bias metrics.

- First application of projective debiasing to BERT's inner layers and attention, showing increasing bias reduction with more invasive interventions. New state-of-the-art on StereoSet bias mitigation.

- Evaluation of debiasing methods on downstream NLI task reveals intrinsic bias reduction doesn't necessarily translate to less biased predictions. Task-specific development needed.

- Analysis provides best practices on combining projective debiasing ingredients for optimal intrinsic vs downstream bias trade-off. Allows faster hyperparameter search.

Overall, the paper significantly advances understanding and methodology around debiasing contextual language models like BERT for real-world usage.
