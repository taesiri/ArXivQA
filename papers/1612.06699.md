# [Unsupervised Perceptual Rewards for Imitation Learning](https://arxiv.org/abs/1612.06699)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we learn reward functions for complex real-world robotic manipulation tasks from raw pixel observations of human demonstrations, without requiring manual engineering of rewards or additional instrumentation?The key ideas and contributions in addressing this question appear to be:1. Using unsupervised video segmentation to break down demonstrations into sub-goals/steps.2. Leveraging pre-trained deep visual features to learn classifiers that identify these sub-goals from raw pixels, thereby creating dense incremental reward functions. 3. Showing that these learned perceptual reward functions can be used by a real robot to learn complex skills like door opening through its own experience, even when trained on human demonstrations.So in summary, the central hypothesis seems to be that pre-trained deep visual features can be used to automatically learn reward functions and sub-goals for complex real-world manipulation skills from raw pixel demonstrations, thereby enabling more efficient and scalable imitation learning on robots. The experiments and results demonstrate this approach on real robotic door opening tasks learned from human demonstrations.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. A method for learning perceptual reward functions from only a few demonstrations of real-world tasks, using unsupervised discovery of intermediate steps. 2. The first vision-based reward learning method that can learn a complex robotic manipulation task directly from human demonstrations, without any robot state information. This is demonstrated through real-world robotic experiments on door opening.3. An analysis showing that the learned visual representations in a pre-trained deep model are general enough to be directly used for representing goals and sub-goals for new manipulation tasks, without needing to retrain the features.4. Evidence that there exist small subsets of discriminative features in these pre-trained models that can be used for step classification, which could help enable unsupervised step discovery in future work.In summary, the key innovation is using powerful pre-trained deep visual features to enable very efficient reward learning directly from human demonstrations, without needing extensive robot experience or instrumentation of the environment. This could help overcome two major obstacles in deploying RL for real-world robot learning.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a method for robots to quickly learn visual reward functions and complex real-world manipulation skills from just a few human demonstrations, without needing manually engineered rewards or state representations.


## How does this paper compare to other research in the same field?

This paper presents a novel method for learning reward functions for robotic reinforcement learning tasks directly from raw pixel inputs in a few human demonstrations, without needing any state information or instrumentation on the demonstrated objects. Here are some key ways it compares to other related work:- Most prior work on learning rewards from demonstrations has focused on low-dimensional state spaces and required many demonstrations. This method works directly from images and needs only a few demonstrations (as few as 2-3).- Some prior methods have used images or pixels for reward learning, but they often rely on specifying a target image or distance in pixel space. This can lack generalizability. This method learns more generalizable semantic reward functions from pre-trained deep features.- A few recent methods have combined deep learning and inverse RL, but they still require instrumentation (like robot joint angles and end effector poses). This method learns only from raw human videos, without any state information.- It's the first method to show complex real robotic skills can be learned from human video demonstrations using these learned visual rewards, like opening a real door. Most prior work was either simulation only or required robot demos.So in summary, the key advances are using deep visual features to learn generative visual rewards from just a few raw human demonstrations, and showing these can be used to learn real-world robotic manipulation skills. This helps move toward more practical imitation learning that doesn't require perfect state information or embodiment matching. The simple approach also helps scale these methods.
