# [Leveraging CLIP for Inferring Sensitive Information and Improving Model   Fairness](https://arxiv.org/abs/2403.10624)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Machine learning models can exhibit unfairness towards certain demographic groups. Prior work on fair learning assumes knowledge of sensitive attributes like gender or race. However, obtaining such labels is difficult due to privacy concerns.  

- Vision-language models (VLM) like CLIP have shown powerful capability in aligning images and text descriptions. This work explores using CLIP to infer sensitive attribute information from images, without needing explicit labels. The inferred information can then be used to improve fairness of a separate target vision model.

Method: CLIP-debias
- Leverage CLIP's image-text similarity score to quantify image relevance to a sensitive attribute described in text prompts (e.g. "photo of an old person"). 

- Cluster dataset images based on similarity scores. Resulting pseudo groups approximate distribution of true sensitive attributes. Groups have variance due to CLIP uncertainties and ambiguity in descriptions.

- Train target model with re-sampling to balance loss across clusters. Give higher sampling probability to clusters with higher loss to emphasize difficult groups.

Contributions:
- First approach using VLM to infer sensitive attributes for fair learning without needing labels. Analyze reliability of CLIP-based clustering as sensitive info proxy.

- Proposed CLIP-debias method that re-samples imbalanced clusters from target data. Improves model fairness and overall accuracy on facial and object recognition.

- Analysis relating cluster consistency to ground truth vs. fairness gains. Also sensitivity analysis on changing language prompts, cluster numbers, re-sampling frequency.

- Open up novel direction in fair learning without labels by utilizing powerful vision-language knowledge source.
