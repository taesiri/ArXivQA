# [RegFormer: An Efficient Projection-Aware Transformer Network for   Large-Scale Point Cloud Registration](https://arxiv.org/abs/2303.12384)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes an end-to-end transformer network called RegFormer for large-scale point cloud registration. The central goal is to develop an accurate and efficient registration method that can directly process raw point clouds without any post-processing like RANSAC or explicit correspondences. The key research questions/hypotheses addressed are:- How to design an efficient transformer architecture that can handle large numbers of unstructured 3D points for registration? They propose a projection-aware hierarchical transformer with linear complexity.- How to effectively reduce mismatches and increase robustness to outliers for distant point cloud pairs? They introduce a Bijective Association Transformer module with cross-attention and all-to-all point gathering.- Can a pure transformer network achieve state-of-the-art registration performance on large-scale outdoor datasets without any post-processing? Their experiments on KITTI and NuScenes datasets demonstrate competitive or superior results compared to previous methods in terms of both accuracy and efficiency.In summary, the central goal is developing an end-to-end transformer for efficient and robust large-scale point cloud registration, which is validated through comprehensive experiments and ablation studies. The key novelty lies in the proposed network architecture designs to handle challenges like sparsity, outliers and mismatches for this task.
