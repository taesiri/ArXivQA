# [RegFormer: An Efficient Projection-Aware Transformer Network for   Large-Scale Point Cloud Registration](https://arxiv.org/abs/2303.12384)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes an end-to-end transformer network called RegFormer for large-scale point cloud registration. The central goal is to develop an accurate and efficient registration method that can directly process raw point clouds without any post-processing like RANSAC or explicit correspondences. 

The key research questions/hypotheses addressed are:

- How to design an efficient transformer architecture that can handle large numbers of unstructured 3D points for registration? They propose a projection-aware hierarchical transformer with linear complexity.

- How to effectively reduce mismatches and increase robustness to outliers for distant point cloud pairs? They introduce a Bijective Association Transformer module with cross-attention and all-to-all point gathering.

- Can a pure transformer network achieve state-of-the-art registration performance on large-scale outdoor datasets without any post-processing? Their experiments on KITTI and NuScenes datasets demonstrate competitive or superior results compared to previous methods in terms of both accuracy and efficiency.

In summary, the central goal is developing an end-to-end transformer for efficient and robust large-scale point cloud registration, which is validated through comprehensive experiments and ablation studies. The key novelty lies in the proposed network architecture designs to handle challenges like sparsity, outliers and mismatches for this task.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes RegFormer, an end-to-end transformer network for large-scale point cloud registration. RegFormer is both keypoint-free and RANSAC-free.

2. It introduces a projection-aware hierarchical transformer to extract point features globally and filter outliers effectively. This avoids relying on local descriptors or robust estimators like RANSAC. 

3. It designs a Bijective Association Transformer (BAT) module to reduce mismatches. BAT combines cross-attention for preliminary information exchange and an all-to-all point correlation strategy to find reliable matching points.

4. Experiments on KITTI and NuScenes datasets show RegFormer achieves state-of-the-art registration performance in terms of both accuracy and efficiency. It obtains 99.8% and 99.9% successful registration recall on KITTI and NuScenes respectively.

In summary, the key contribution is proposing an efficient, end-to-end transformer network RegFormer for large-scale point cloud registration. RegFormer eliminates the need for explicit keypoint matching or RANSAC post-processing. The global modeling of transformer and mismatch rejection strategy of BAT module enable RegFormer to achieve high registration accuracy.
