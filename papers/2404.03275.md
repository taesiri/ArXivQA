# [DELTA: Decomposed Efficient Long-Term Robot Task Planning using Large   Language Models](https://arxiv.org/abs/2404.03275)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Recent advancements in large language models (LLMs) have shown promise for robot task planning by providing common-sense reasoning and knowledge. However, directly using LLMs for long-term robot task planning still faces major challenges:
1) Lack of grounding into formal planning languages results in unexecutable plans
2) No structured representation of large environments leads to missing contextual information 
3) Long-term planning complexity grows exponentially, resulting in low success rates and efficiency

Proposed Solution:
This paper proposes DELTA, a novel robot task planning approach to address the above challenges. The key ideas are:

1) Use 3D scene graphs as structured environmental representations that capture semantics and topology. Feed these into the LLM to ground knowledge.

2) Leverage LLM's language capabilities for one-shot generation of planning domain/problem files in PDDL formal language. This grounds the LLM's knowledge into executable actions.

3) Decompose long-term goals into sub-goals using the LLM, then solve them autoregressively with a classical planner. This reduces complexity.

Main Contributions:

1) Novel combination of LLMs and scene graphs that enables extraction of actionable and semantic knowledge from LLM's and grounding it into environmental topology

2) LLM-driven domain generation and problem specification in PDDL formal planning language. Enables one-shot planning in unseen domains. 

3) LLM-based task decomposition strategy combined with autoregressive sub-task planning. Achieves higher success rates, near-optimal plan quality and significantly shorter planning times compared to baselines.

In summary, DELTA advances state-of-the-art by enabling more efficient and fully automated long-term task planning for robots using the reasoning and knowledge capabilities of LLMs, while overcoming previous challenges related to grounding and complexity. The powerful combination of scene graphs, LLMs and classical planning is a key innovation.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes DELTA, a novel approach for efficient long-term robot task planning that uses Large Language Models to extract actionable knowledge from scene graphs and decompose complex goals into executable sub-goals for automated planning.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing DELTA, a novel approach for long-term robot task planning that utilizes Large Language Models (LLMs) and 3D scene graphs. Specifically:

1) DELTA introduces a combination of LLMs and scene graphs to extract actionable knowledge from the LLMs and ground it into the environmental topology represented by the scene graphs. This allows solving complex planning problems in unseen domains via one-shot prompting.

2) Compared to other LLM-based approaches, DELTA achieves higher planning success rates, near-optimal plan quality, and significantly shorter planning times for long-term tasks through LLM-driven task decomposition and the use of formal planning language. 

3) DELTA is the first approach to tackle the open research problem of efficient long-term robot task planning using LLMs and structured environment representations like scene graphs. It fills the gap left in previous LLM-based approaches that focused only on short-term tasks.

In summary, the main contribution is a novel LLM-driven robot task planning pipeline called DELTA that enables more efficient and fully automated long-term task planning by leveraging the power of LLMs and scene graphs.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and keywords associated with it are:

- Large language models (LLMs)
- Task and motion planning (TAMP)
- Planning domain definition language (PDDL)
- 3D scene graphs
- Goal decomposition 
- Autoregressive sub-task planning
- Grounding natural language
- Mobile robots
- Household environments

The paper proposes DELTA, a novel LLM-driven approach for long-term robot task planning. Key aspects include using 3D scene graphs to represent environments, leveraging LLMs to generate PDDL planning files and decompose goals, and solving sub-tasks autoregressively. The approach aims to achieve efficient and feasible planning for mobile robots operating in household settings.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions using scene graphs as a structured representation of the environment. How exactly does this representation help with the task planning compared to using raw sensor data or other environment representations? What specific advantages and disadvantages does it have?

2. The method uses Large Language Models (LLMs) in several components like pruning the scene graphs, generating PDDL files, and decomposing goals. What is the rationale behind using LLMs for these purposes instead of more traditional techniques? What unique capabilities do LLMs provide? 

3. The goal decomposition strategy is a key contribution of this work. Can you explain in more detail the algorithm and logic used to decompose long-term goals into sub-goals? How does it ensure that the generated sub-goals lead to completion of the overall goal?

4. The method evaluates several metrics like planning times, success rates, plan lengths, and expanded search nodes. What is the significance of each of these metrics in analyzing the performance? Are there any other important metrics that should have been considered for a comprehensive analysis?

5. The results show that directly using an LLM as a planner performs very poorly. What are the main challenges and limitations faced by LLMs that lead to this outcome? How does the proposed approach overcome these limitations?

6. The ablation study compares different LLM versions - what deductions can you draw about the impact of model size, architecture, and training data based on how the performance changes from GPT-3.5 to GPT-4 and GPT-4-turbo?

7. The paper focuses only on task planning and does not cover path planning or motion planning aspects. What challenges do you foresee in extending this approach to generate complete executable plans with detailed robot motions?

8. How amenable is this approach to work in dynamic environments where the scene graph or goal specifications might change during plan execution? Would replanning with LLMs help or are there better techniques to handle uncertainty?

9. The experiments are performed only in simulation. What practical difficulties and constraints do you expect will arise when deploying this on a physical robot platform in the real world? How can the approach account for noise and inaccuracies?

10. The evaluation compares against other LLM-based task planning techniques but not classical automated planning methods. How do you expect this approach would fare against non-LLM planners? Would the goal decomposition strategy still provide an advantage?
