# Tree of Thoughts: Deliberate Problem Solving with Large Language Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question it addresses is: How can we enhance the problem-solving abilities of large language models beyond their default token-level, left-to-right generation process, to enable more deliberate and systematic reasoning through exploring multiple paths?The key hypothesis is that framing problem solving as search through a tree of possible reasoning paths ("thoughts"), along with mechanisms for the model to deliberately evaluate and choose between alternative thoughts, will allow language models to tackle more complex problems requiring planning, lookahead, and backtracking. The paper introduces the Tree of Thoughts (ToT) framework as a way to implement this kind of deliberate search process purely through language interactions with the model, without extra training or specialized architectures. The framework is evaluated on three novel tasks - Game of 24, Creative Writing, and Mini Crosswords - that aim to stretch the limits of standard language model capabilities.In summary, the central hypothesis is that incorporating more human-like deliberative reasoning into language models, instantiated through the Tree of Thoughts framework, will expand their problem-solving abilities compared to the standard left-to-right text generation process. The paper aims to demonstrate this via the design, implementation, and evaluation of ToT across challenging reasoning tasks.


## What is the main contribution of this paper?

The main contribution of this paper is proposing the Tree of Thoughts (ToT) framework, which enables large language models (LLMs) like GPT-3/GPT-4 to perform more systematic and deliberate problem solving through exploring and evaluating multiple coherent reasoning paths (thoughts). Specifically:- ToT generalizes over existing prompting approaches like input-output prompting and chain-of-thought prompting, and allows LLMs to actively search over a tree of thoughts using different search algorithms like BFS and DFS. - It proposes ways for the LLM to deliberately generate, evaluate, and compare thoughts at each step through self-prompting, which provides heuristics to guide the search without extra training.- It shows ToT significantly improves LLM performance on 3 novel tasks - Game of 24, Creative Writing, and Mini Crosswords - that require non-trivial search and planning. For instance, ToT helps solve 74% of Game of 24 tasks, whereas standard prompting only solves around 4%.- It provides a modular framework to incorporate search and planning capabilities into LLMs, and shows the flexibility of adapting different search algorithms, heuristics, etc. based on the task properties.In summary, the key innovation is enabling LLMs to deliberately explore and evaluate multiple reasoning paths in a systematic way, instead of just left-to-right token generation. This brings LLMs closer to human-like problem solving involving search and planning.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR of the paper:The paper introduces a Tree of Thoughts framework that enables language models to deliberate over problem solving by exploring and evaluating coherent intermediate reasoning steps represented as language.


## How does this paper compare to other research in the same field?

Here are some key ways this paper compares to other research on using large language models for problem solving:- It proposes a more structured and deliberate approach (Tree of Thoughts) compared to standard approaches like input-output prompting or chain of thought, allowing the model to explore multiple reasoning paths. This is inspired by classical AI methods for search and planning. - The tasks explored (Game of 24, Creative Writing, Crosswords) require non-trivial reasoning and search abilities. Many existing works focus on more straightforward tasks or do not systematically test search/planning abilities.- The framework is flexible and model-agnostic. It does not require specialized training of models, just a pre-trained language model like GPT-4. Some other works propose custom models or training methods.- It emphasizes model self-evaluation of reasoning steps rather than relying on external signals. Related works on "self-reflection" also aim to make models assess their own generations.- The intermediate reasoning is instantiated in natural language "thoughts", not more structured representations like programs. This provides convenience but could be limiting in representing complex reasoning.- The search algorithms explored are relatively simple (BFS, DFS). More advanced algorithms like Monte Carlo Tree Search could be investigated.- Performance gains on the proposed tasks are significant (e.g. 4% to 74% on Game of 24). Many other works demonstrate smaller gains or do not systematically compare to baselines.Overall, this work makes a novel connection between classical search methods and modern language models. The Tree of Thoughts framework seems promising in making language models more deliberate, structured, and lookahead in their reasoning while retaining convenience and generality. Key limitations are the simple search methods and choice of tasks.
