# [A GAN-based data poisoning framework against anomaly detection in   vertical federated learning](https://arxiv.org/abs/2401.08984)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
In vertical federated learning (VFL), multiple participants with different features about the same data samples collaboratively train a machine learning model without sharing their local data. However, a malicious participant could launch a data poisoning attack by injecting adversarial perturbations into its local data to degrade the performance of the global model. The key challenge is that the malicious participant lacks access to the global model, making it difficult to generate effective perturbations.

Proposed Solution:
1) The authors propose P-GAN, an end-to-end poisoning attack framework for VFL. It first uses semi-supervised learning (Fixmatch algorithm) to train a surrogate target model using the malicious participant's local data and a small set of inferred labels. 

2) A GAN-based perturbation model is then trained to generate adversarial examples that can degrade the performance of this surrogate target model. The perturbations are added to the local data to craft poisoned inputs. During VFL training, these poisoned inputs degrade the global model's performance.

3) To defend against such attacks, the authors propose a deep autoencoder (DAE)-based anomaly detection method at the server-side. It reconstructs the embedding vectors received from participants and uses the reconstruction errors to identify outliers potentially corresponding to poisoned data.

Main Contributions:
- First end-to-end poisoning attack framework P-GAN tailored for VFL by addressing the challenge of lacking access to the global model
- Novel defense method DAE based on deep autoencoders and reconstruction errors to filter outlier embedding vectors
- Extensive experiments on MNIST, CIFAR10 and CIFAR100 showing P-GAN outperforms existing attacks. DAE can effectively mitigate poisoning attacks.
- Analysis of factors influencing attack and defense performance - adversary's features, labeled data, poisoned data ratio etc.

In summary, the paper proposes an innovative poisoning attack framework for VFL using generative models, along with an anomaly detection defense. Both methods are extensively evaluated, providing useful insights.


## Summarize the paper in one sentence.

 This paper proposes an end-to-end data poisoning attack framework (P-GAN) for vertical federated learning using a generative adversarial network and semi-supervised learning to create a surrogate target model, and introduces a defense method based on deep autoencoders (DAE) to detect anomalies.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. Introduction of P-GAN, an end-to-end poisoning attack mechanism for vertical federated learning (VFL). It uses semi-supervised learning to train a surrogate target model, and then employs a GAN-based method to generate adversarial perturbations to degrade the surrogate model's performance.

2. Development of an anomaly detection algorithm based on a deep auto-encoder (DAE) to provide a robust defense mechanism for VFL against poisoning attacks. 

3. Extensive experiments to evaluate the efficacy of P-GAN attack and DAE defense on MNIST, CIFAR-10 and CIFAR-100 datasets. Performance analysis of influential factors such as number of adversary features, amount of known labels, and proportion of poisoned samples.

In summary, the main contribution is proposing an effective poisoning attack framework (P-GAN) tailored for VFL, and a corresponding defense method (DAE) to detect such attacks. Their performance is thoroughly evaluated on image datasets.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the key terms and keywords associated with it are:

- Vertical federated learning (VFL)
- Data poisoning attacks
- Generative adversarial network (GAN) 
- Deep auto-encoder (DAE)
- Semi-supervised learning
- Fixmatch
- Anomaly detection
- Reconstruction error
- Surrogate target model
- Perturbations
- Embedding vectors

The paper proposes an end-to-end data poisoning attack framework called P-GAN tailored for vertical federated learning scenarios. It uses Fixmatch and semi-supervised learning to obtain a surrogate target model. Then a GAN-based perturbation model is used to generate poisoned samples to degrade the top model's performance. The paper also introduces a deep autoencoder (DAE) based anomaly detection method on the server-side to defend against such attacks by using reconstruction errors to filter out outliers. So the key focus is on data poisoning attacks and defenses for vertical federated learning.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. The paper proposes a two-stage framework called P-GAN for data poisoning attacks in vertical federated learning. Can you explain in detail the rationale and workflow behind using Fixmatch in stage 1 to obtain a surrogate target model? What are the advantages of this approach?

2. In stage 2 of P-GAN, the authors use a GAN-based perturbation model to generate poisoned samples. Explain how the adversarial loss, GAN loss, and regularization loss terms contribute to optimizing this model. What threat model assumptions enable using the perturbation model in this way?

3. The defense model employs a deep autoencoder (DAE) for anomaly detection. Discuss the reasons for using reconstruction error to identify poisoned embedding vectors. What are the potential limitations of this approach as the percentage of poisoned data increases? 

4. Analyze the differences in effectiveness of the P-GAN attack under varying numbers of features available to the adversary. Why does increased feature access lead to more successful degradation of the global model?

5. The paper evaluates how changing hyperparameters λr and λGAN impacts poisoning and defense efficacy. Explain the interactions between these terms and how they reflect attack versus evasion priorities. 

6. As the number of labeled training examples available to the adversary increases, how does P-GAN poison attack performance change? Explain why and discuss the implications.

7. Compare the proposed P-GAN framework to the baseline LRA and VILLAIN poisoning methods. What enables P-GAN to achieve better degradation of model performance?

8. How do you explain experimental results showing decreased DAE defense efficacy as quantity of adversary's known labels increases? Does this indicate shortcomings of the defense approach?

9. Discuss the feasibility and potential limitations of deploying the proposed anomaly detection framework in real-world vertical FL environments. What practical issues need consideration?

10. The paper assumes black-box access to the global model for the adversary. How would you adapt the P-GAN method for a grey-box or white-box threat model? Identify any additional attack opportunities.
