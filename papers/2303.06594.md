# ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched
  Visual Descriptions

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: Can an automatic questioning system utilizing ChatGPT as the questioner and BLIP-2 as the visual question answerer generate more informative and enriched image captions compared to just using BLIP-2 alone?The key hypothesis appears to be that by prompting ChatGPT to ask a series of targeted questions about an image and having BLIP-2 provide visual information in response, the conversation can extract additional details about the image content. This in turn allows ChatGPT to produce a more comprehensive summary of the image in the final caption compared to BLIP-2's caption alone.So in summary, the central research question is whether an automatic questioning system can enhance image captioning by acquiring more visual knowledge through an interactive question-asking process. The hypothesis is that this approach can generate captions that are rated by humans as more informative than standard image captioning models like BLIP-2. The experiments aim to test this hypothesis.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It introduces ChatCaptioner, a novel automatic questioning method for generating enriched image captions. ChatCaptioner uses ChatGPT to ask a series of informative questions about an image to BLIP-2, a visual question answering model. 2. It demonstrates through human evaluations that ChatCaptioner can generate significantly more informative image captions compared to just using BLIP-2 alone. On average, ChatCaptioner's captions receive 3-4 times more votes from human evaluators for providing the richest image information.3. It shows that ChatCaptioner can identify 53% more objects in images compared to BLIP-2 captions. This indicates the questions from ChatGPT help extract additional visual information from BLIP-2.4. It reveals the capability of large language models like ChatGPT to serve as effective automatic questioners when properly prompted, despite having no visual perception.5. It highlights the benefits of asking good questions to acquire more knowledge from existing AI models, and draws attention to the potential of automatic questioning systems in AI research.In summary, the main contribution is the proposal of ChatCaptioner, an automatic questioning approach that can ask informative questions to extract more visual knowledge and generate significantly enriched image descriptions. The results verify the value of automatic questioning and the questioning capability of prompted language models.
