# ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched
  Visual Descriptions

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: Can an automatic questioning system utilizing ChatGPT as the questioner and BLIP-2 as the visual question answerer generate more informative and enriched image captions compared to just using BLIP-2 alone?The key hypothesis appears to be that by prompting ChatGPT to ask a series of targeted questions about an image and having BLIP-2 provide visual information in response, the conversation can extract additional details about the image content. This in turn allows ChatGPT to produce a more comprehensive summary of the image in the final caption compared to BLIP-2's caption alone.So in summary, the central research question is whether an automatic questioning system can enhance image captioning by acquiring more visual knowledge through an interactive question-asking process. The hypothesis is that this approach can generate captions that are rated by humans as more informative than standard image captioning models like BLIP-2. The experiments aim to test this hypothesis.
