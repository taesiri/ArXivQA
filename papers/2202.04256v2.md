# [GiraffeDet: A Heavy-Neck Paradigm for Object Detection](https://arxiv.org/abs/2202.04256v2)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we design an object detection model that is effective at handling objects across a wide range of scales, while also being efficient in terms of computational cost?

The key hypotheses appear to be:

1) The conventional paradigm of using a heavy backbone network inherited from image classification models is sub-optimal for object detection, where handling multi-scale objects is crucial. 

2) An alternative approach with a lightweight backbone and a very deep multi-scale feature fusion neck module can achieve better accuracy and efficiency for object detection.

Specifically, the paper proposes a "heavy neck" object detection model called GiraffeDet, with a lightweight backbone and a deep generalized feature pyramid network (GFPN) neck module. The GFPN is designed to encourage sufficient multi-scale feature fusion to handle objects across a wide range of scales. 

The central thesis seems to be that this proposed "heavy neck" paradigm will allow models to achieve state-of-the-art accuracy and efficiency for object detection across various computational budgets. The experiments aim to demonstrate the effectiveness of GiraffeDet compared to other models.

In summary, the key research question is how to achieve scale-invariant efficient object detection, with the central hypothesis being that a heavy neck design is more suitable than heavy backbones for this task.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- Proposing a new object detection framework called Scale Invariant Network (SinNet) to handle objects with large scale variation. The framework consists of two main components:

1) Efficient S2D-chain (eS2D-chain): A very lightweight backbone network to extract multi-scale features. It uses space-to-depth modules and convolutions rather than a standard CNN backbone like ResNet.

2) Generalized FPN (GFPN): A flexible feature pyramid network with novel connections including queen-fusion cross-scale connections and log2n skip-layer connections. This allows richer multi-scale feature fusion.

- Conducting controlled experiments to demonstrate that the backbone network is not as critical in object detection compared to the neck/FPN. The results show that a lightweight eS2D-chain + deeper GFPN can outperform heavier ResNet backbones + shallower FPNs.

- Proposing a new scaling method to jointly scale the depth and width of the GFPN to develop a family of SinNet models for different resource constraints. This achieves better efficiency than prior works that scale only the backbone or single dimensions like image size/depth/width.

- Achieving state-of-the-art performance on COCO object detection using the proposed SinNet framework. The model is efficient and effective at handling objects with large scale variation.

In summary, the main contribution is proposing the SinNet object detection framework with a lightweight backbone and flexible neck to achieve strong performance and efficiency on detecting objects with diverse scales. The paper also provides insights like the importance of the FPN over backbone through controlled experiments.
