# [Knowledge-Aware Artifact Image Synthesis with LLM-Enhanced Prompting and   Multi-Source Supervision](https://arxiv.org/abs/2312.08056)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel knowledge-aware approach for synthesizing visual images of lost artifacts from textual descriptions, aiming to aid cultural preservation and archaeological studies. The method builds upon a pretrained Chinese Stable Diffusion model and introduces three key techniques: 1) using a large language model (LLM) to extract structured knowledge from noisy text prompts and augment missing information; 2) applying contrastive learning on the text encoder to align representations with domain expertise; 3) adding visual-semantic supervision via edge and perceptual losses to capture intricate artifact details. Experiments demonstrate superior performance over baselines, with higher similarity to ground truths and preservation of vital visual elements like shape and color. Both automatic metrics and assessments from domain experts confirm the model's ability to resurrect lost historical objects with high visual fidelity. This work represents an important advancement at the intersection of computer vision and computational archaeology.
