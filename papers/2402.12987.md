# [Towards Robust Graph Incremental Learning on Evolving Graphs](https://arxiv.org/abs/2402.12987)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper focuses on the problem of node-wise graph incremental learning (NGIL) in an inductive setting, where new tasks and associated graph data arrive sequentially. In this inductive setting, as new tasks and vertices are added, the graph structure evolves, altering the structural information and input distribution of existing vertices. This phenomenon is referred to as "structural shift". Structural shift poses a key challenge for incremental learning on graphs as it can negatively impact the model's ability to retain performance on previous tasks, leading to catastrophic forgetting. However, prior work on NGIL has primarily focused on a transductive setting with fixed graph structures. This paper provides the first comprehensive analysis of the more realistic inductive setting.  

Proposed Solution:
The paper presents a formal definition and analysis that quantifies the effect of structural shift on catastrophic forgetting in inductive NGIL. Based on the analysis, the authors propose a novel regularization method called Structural-Shift-Risk-Mitigation (SSRM) to mitigate the impact of structural shift. The key idea is to encourage the model to learn a latent feature space that is invariant to the structural shift across tasks. This is achieved by adding a regularization term that minimizes the divergence between vertex representations in the previous and current tasks. As a result, the model is less susceptible to performance degradation on older tasks.

Main Contributions:
- Provides the first mathematical formulation and rigorous analysis that connects structural shift to catastrophic forgetting in inductive NGIL
- Derives a theoretical bound that relates the risk of catastrophic forgetting to the extent of structural shift 
- Proposes SSRM, a novel regularization method tailored to mitigate risks arising from structural shift by finding a latent space invariant across graph structures  
- Demonstrates consistent improvements in performance over state-of-the-art NGIL methods on benchmark datasets when using SSRM, validating the analysis

Overall, the paper addresses an important open problem in graph incremental learning and provides key theoretical and algorithmic contributions towards robust incremental learning on evolving graphs.
