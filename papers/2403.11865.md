# [Exploring Multi-modal Neural Scene Representations With Applications on   Thermal Imaging](https://arxiv.org/abs/2403.11865)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Novel view synthesis aims to generate new views of a scene given a set of input images, and has recently been revolutionized by neural radiance fields (NeRFs). However, most work has focused on RGB images. Integrating additional modalities like thermal imaging into NeRFs is still an open challenge.

- Key difficulties include estimating camera poses for non-RGB images, aligning multi-modal images, and determining the best architecture to fuse different data types. Modeling thermal images is especially hard due to lack of features and texture. 

Method:
- The paper evaluates four strategies to incorporate a second modality into NeRFs:
   1) Train from scratch separately on each modality (TS)
   2) Pre-train on RGB, fine-tune on second modality (FT)  
   3) Add a second branch to predict the extra modality (RGB-X)
   4) Add a separate network component for the extra modality (SC)

- Thermal imaging was chosen as the second challenging modality. A new dataset "ThermalMix" was collected with aligned RGB and thermal images.

- Experiments compare reconstructions of left-out thermal and RGB images using the four approaches. Alignments enabled isolating fusion architecture design.

Contributions:
- Provides first comprehensive study comparing multi-modal fusion strategies for NeRFs
- Introduces new "ThermalMix" dataset with 360 aligned RGB and thermal images 
- Shows that adding a second branch (RGB-X) works best for thermal images while maintaining good RGB reconstructions
- Demonstrates generalization of findings to other modalities like near-infrared and depth data

The key insight is that allowing NeRF volume densities to be influenced by the secondary modality helps integrate information. The work moves towards more capable multi-modal scene representations.
