# [Modular Blind Video Quality Assessment](https://arxiv.org/abs/2402.19276)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing blind video quality assessment (BVQA) models are limited in their ability to account for variations in spatial resolution and frame rate when evaluating video quality. Most models downsample or subsample input videos aggressively, making them insensitive to quality changes arising from actual resolution and frame rate. This is problematic as research shows higher resolution and frame rate positively impact video quality.

Proposed Solution:
The paper proposes a modular BVQA model comprising:

1) A base quality predictor that estimates visual content and distortion-related quality from spatially downsampled key frames. 

2) A spatial rectifier that captures resolution-dependent quality variations using features from key frames at original resolution.

3) A temporal rectifier that captures frame rate-dependent quality variations using features from original frame rate video chunks.

The model allows flexible integration of the rectifiers with the base predictor in a modular manner. The paper also introduces a training strategy involving randomly dropping out the rectifiers to enhance modularity.

Main Contributions:

1) Modular and extensible BVQA model sensitive to visual content, distortions and changes in spatial/temporal attributes.

2) Training strategy to improve modularity of the base predictor and rectifiers.

3) Superior performance over state-of-the-art methods on 12 databases covering professional and user generated content.

4) Analysis of spatial/temporal complexity and distortion types of major VQA databases enabled by the modular structure.

In summary, the paper presents a novel modular approach for blind VQA that accounts for variable spatial resolution and frame rate better than existing methods while providing further analysis insights. The model design and training strategy enhance flexibility and future extensibility.
