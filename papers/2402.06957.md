# [Architectural Neural Backdoors from First Principles](https://arxiv.org/abs/2402.06957)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Architectural backdoors are a new type of backdoor attack where an adversary embeds a malicious trigger detector directly into the architecture of a neural network model. This allows them to control the model's behavior when their chosen trigger is present.

- Prior work showed such backdoors are possible but had limitations - they could only detect a checkerboard pattern, did not work well on pretrained models, and the backdoor could sometimes be disabled during training. 

- The scope and implications of architectural backdoors have remained largely unexplored. Questions around constructing arbitrary trigger detectors, injecting backdoors post-training, and gauging human detection abilities need to be addressed.

Proposed Solution:
- The paper demonstrates more general architectural backdoors that can detect arbitrary triggers chosen by the attacker, while preserving model accuracy and surviving full retraining.

- It constructs trigger detectors from basic logic gates using common ML operations like activations. These form deterministic boolean functions that evaluate the same way regardless of training.

- The trigger detector's signal can then be propagated through the model in different ways and integrated to achieve either targeted or untargeted attacks.

- A taxonomy of 12 distinct types of architectural backdoors is provided across dimensions like signal propagation.

Contributions:
- Shows architectural backdoors can target arbitrary triggers with provable guarantees, unlike prior art.

- Evaluates attack success and performance tradeoffs across the backdoor taxonomy.

- Runs a user study revealing developers detect backdoors in common model definitions only 37% of the time, while surprisingly preferring backdoored models 33% of the time.

- Contextualizes results by showing language models can outperform humans at backdoor detection. 

- Discusses defenses like sandboxing, provenance tracking and access controls to safeguard model integrity.

Overall the paper significantly advances knowledge around this powerful threat, while emphasizing architectural backdoors remain inconspicuous to humans, motivating the need for comprehensive defense strategies.
