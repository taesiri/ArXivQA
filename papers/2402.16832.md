# [Mysterious Projections: Multimodal LLMs Gain Domain-Specific Visual   Capabilities Without Richer Cross-Modal Projections](https://arxiv.org/abs/2402.16832)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Multimodal large language models (MLLMs) such as LLaVA and GPT-V enable conversing with images using natural language. However, off-the-shelf MLLMs have limited capabilities with domain-specific images like those from agriculture or dermatology. 
- A common architecture for MLLMs consists of two main modules: (1) a cross-modal projection network that maps images into the language model's space, and (2) a large language model (LLM) that processes the text and projected image jointly. It is important to understand the roles of these two modules in modeling domain-specific visual attributes.

Proposed Approach:
- Fine-tune LLaVA-1.5 using two methods: (1) only updating the cross-modal projection with LLM frozen, (2) updating the entire model.
- Evaluate domain-specific image classification performance on 4 specialized datasets. 
- Estimate the richness of domain-specific visual attributes in the post-projection image representations.
- Analyze the results to understand the roles of the projection and LLM in modeling domain-specific image attributes.

Key Contributions:
- Findings show that both fine-tuning approaches improve the domain-specific visual capabilities. However, the updates do NOT lead to the projection capturing more relevant domain-specific visual attributes.
- This indicates the domain-specific attributes are predominantly modeled by the LLM parameters, even when the projection alone is updated.
- The work reinterprets the role of cross-modal projections in MLLMs - projections may help direct pre-existing knowledge in LM, rather than extracting visual attributes.
- Results add evidence that deep neural networks can inherently be multimodal, with LLMs able to model visual data with minimal help from explicit projections.

In summary, the key contribution is providing evidence that the LLM itself models domain-specific visual attributes in MLLMs, challenging the notion that cross-modal projections play a central role. This offers a potential reinterpretation of projection's purpose in MLLM architectures.
