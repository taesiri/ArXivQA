# [FERGI: Automatic Annotation of User Preferences for Text-to-Image   Generation from Spontaneous Facial Expression Reaction](https://arxiv.org/abs/2312.03187)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Scalability of human preference feedback collection for improving text-to-image generators is limited by its reliance on manual annotation. 

Proposed Solution:
- Develop a method to automatically annotate user preferences from spontaneous facial expression reaction to generated images.

Dataset:
- Present the Facial Expression Reaction to Generated Images (FERGI) dataset comprising video recordings of 33 participants' facial reactions to 2827 images generated by Stable Diffusion from 576 text prompts.

Analysis:  
- Show multiple facial action units (AUs) are correlated with user evaluations and emotions for the generated images. 
- AU4 (brow lowerer) is most consistently reflective of negative evaluations.

Automatic Annotation Method:
- Propose an AU4 valence score to represent user evaluation reflected in AU4 activation. Can predict user preferences between image pairs with AU4 score difference above a threshold at 74.86% accuracy, outperforming state-of-the-art scoring models.

Complementarity with Scoring Models:
- Show AU4 valence score best reflects evaluation of image fidelity while scoring models better reflect image-text alignment. Integrating AU4 score with scoring models improves accuracy.

Main Contributions:
- First dataset of facial reactions to text-to-image generation
- Method to automatically annotate user preferences from facial reactions 
- Analysis showing multiple AUs reflect user evaluations
- AU4 valence score for automatic annotation and integration with scoring models
- Demonstrate feasibility of automatic annotation from facial reactions

The method can potentially increase efficiency of human preference data collection for improving text-to-image generators. It may also be generalized to other generation tasks.
