# [DeepPermNet: Visual Permutation Learning](https://arxiv.org/abs/1704.02729)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is that training a convolutional neural network (CNN) to solve visual permutation learning can lead to models that capture useful structural information about visual data. Specifically, the authors propose the visual permutation learning task, where the goal is to take a shuffled image sequence as input, and predict the permutation matrix that would recover the original ordered sequence. The key hypothesis is that in order to perform well on this task, the CNN must learn to represent semantic concepts, contextual relationships, and spatial layouts within the visual data. Therefore, the features learned by models trained on permutation prediction should transfer well to other vision tasks that rely on understanding visual structure, like relative attribute learning and self-supervised representation learning.The paper introduces the DeepPermNet architecture and Sinkhorn normalization layer to allow CNNs to approximate the discrete permutation prediction problem using continuous relaxations. Through experiments, the authors aim to validate that DeepPermNet can effectively solve the permutation task, and that the learned features transfer to useful representations for attribute learning and pre-training other vision models. Overall, the central hypothesis is that formalizing and solving the visual permutation learning problem will enable learning about visual structure that benefits a range of computer vision applications.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. Proposing the visual permutation learning task, which involves recovering the original order of a sequence of images or image patches after they have been shuffled by an unknown permutation matrix. This is presented as a generic task formulation that can capture structural concepts in images and ordered image sequences.2. Proposing DeepPermNet, an end-to-end convolutional neural network model to solve the visual permutation learning task. 3. Introducing the Sinkhorn layer, which transforms standard CNN predictions into doubly stochastic matrices using Sinkhorn normalizations. This allows the model to approximate permutation matrices in a continuous way for efficient learning via backpropagation.4. Demonstrating the utility of DeepPermNet on two computer vision applications - relative attributes learning and self-supervised representation learning. For relative attributes, DeepPermNet is shown to outperform prior methods on predicting attribute rankings. For self-supervised learning, features learned by DeepPermNet achieve state-of-the-art performance on PASCAL VOC classification and segmentation compared to other self-supervised approaches.In summary, the key contribution is presenting a novel permutation learning formulation and an end-to-end deep learning approach to solve it. This is shown to be a generic framework that can capture visual structure and be applied to different vision tasks involving modeling order and layout relationships.
