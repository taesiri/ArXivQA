# [Secure Domain Adaptation with Multiple Sources](https://arxiv.org/abs/2106.12124)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research question this paper addresses is: How can we perform multi-source unsupervised domain adaptation (MUDA) while maintaining privacy between the source domains and between the sources and target domain?The paper proposes a new algorithm called Secure MUDA (SMUDA) to address this challenge. The key aspects are:- They aim to transfer knowledge from multiple annotated source domains to an unlabeled target domain, without sharing data between sources or target.- They decompose models into a feature extractor and classifier. For each source, they estimate the latent feature distribution with a Gaussian Mixture Model (GMM).- For each source model, they align the GMM with the target features using sliced Wasserstein distance, plus an entropy regularization loss. This adapts each source model separately. - They combine adapted source models using a confidence-based pooling, weighting models based on prediction confidence on the target.- They prove this minimizes an upper bound on the target error. Experiments on standard benchmarks show SMUDA is effective for private MUDA.In summary, the key hypothesis is that domain alignment and knowledge transfer can be achieved privately in MUDA by approximating source distributions with GMMs and aligning these to the target feature distribution. Their algorithm and experiments aim to validate this hypothesis.
