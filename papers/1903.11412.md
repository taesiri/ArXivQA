# [Self-Supervised Learning via Conditional Motion Propagation](https://arxiv.org/abs/1903.11412)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central hypothesis of this paper is that learning image representations by predicting dense motion from static images conditioned on sparse motion guidance can lead to effective feature learning without explicit supervision. Specifically, the paper proposes a conditional motion propagation (CMP) framework that contains three modules - an image encoder, a sparse motion encoder, and a dense motion decoder. The goal is to predict full image motion based on the image and some sparse guidance motion vectors. The key ideas behind this approach are:- Using sparse motion guidance during training resolves the inherent ambiguity in predicting motion from static images alone, making the pretext task easier.- Recovering dense motion conditioned on sparse guidance encourages the image encoder to learn about the kinematic structure and properties of objects, so it can propagate motion appropriately.- This results in learning useful image representations without needing manual labels, as demonstrated by strong performance on downstream tasks like segmentation.So in summary, the central hypothesis is that framing self-supervised representation learning as conditional motion propagation will enable effectively learning about visual structures without explicit supervision. The paper aims to demonstrate this through the design of the CMP framework and experiments on various benchmarks.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing a new self-supervised learning paradigm called Conditional Motion Propagation (CMP) that learns visual representations by predicting dense optical flow from a static image conditioned on sparse motion guidance. - The CMP framework contains three modules - an image encoder, a sparse motion encoder, and a dense motion decoder. The goal is to recover full image motion based on sparse motion guidance.- Using sparse motion guidance during training resolves the inherent ambiguity in motion prediction and eases feature learning. Solving the task of conditional motion propagation encourages learning of kinematically-sound representations.- Achieving state-of-the-art self-supervised learning performance on several downstream tasks including semantic segmentation, instance segmentation, and human parsing.- Demonstrating that the CMP model captures kinematic properties of objects without manual annotations. This allows applications like guided video generation and semi-automatic pixel-level annotation.In summary, the key contribution appears to be proposing the conditional motion propagation paradigm for self-supervised representation learning, showing its effectiveness on various benchmarks, and highlighting its ability to learn kinematic properties that enable useful applications.
