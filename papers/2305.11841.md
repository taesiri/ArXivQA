# [How Does Generative Retrieval Scale to Millions of Passages?](https://arxiv.org/abs/2305.11841)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How effective are generative retrieval techniques when scaled up to large corpora with millions of documents, and which aspects of proposed methods remain important at scale?In particular, the paper aims to:- Evaluate popular generative retrieval techniques proposed in recent work, ablating their components on small datasets first. - Scale up experiments to the full MS MARCO passage retrieval corpus with 8.8 million passages, in order to understand how well current techniques work and what aspects are critical when scaling up corpus size.- Investigate the effect of scaling up model size for generative retrieval on large corpora.The key hypothesis appears to be that while certain techniques like synthetic query generation help on small datasets, different factors will be important for generative retrieval to work well at scale, which the paper aims to uncover through systematic experiments and analysis. The scalability of generative retrieval is the main open problem being explored.


## What is the main contribution of this paper?

Based on my reading, the main contribution of this paper is an empirical study of generative retrieval techniques on corpora of increasing scale, up to 8.8 million passages from the MS MARCO dataset. The key findings are:- Synthetic query generation is critical for generative retrieval effectiveness at scale. Using only synthetic queries as document representations was the most effective approach as corpus size increased. - When accounting for compute costs, simple techniques like naive document IDs often outperformed more sophisticated methods like semantic IDs.- Increasing model size is necessary but not sufficient - effectiveness peaked at 3B parameters and declined again at 11B parameters, which is counterintuitive.In summary, the paper provides a comprehensive empirical evaluation of recent generative retrieval methods on large-scale corpora. It highlights the importance of synthetic queries and compute-efficient techniques, while showing that naively scaling up model size does not consistently improve effectiveness. The findings help clarify the state of generative retrieval and reveal open challenges to make it competitive with dual encoders at scale.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper empirically studies different generative retrieval techniques, finding that synthetic query generation is crucial for effectiveness but scaling these models to millions of passages remains an open challenge.
