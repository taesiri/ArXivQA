# [PGFed: Personalize Each Client's Global Objective for Federated Learning](https://arxiv.org/abs/2212.01448)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can personalized federated learning algorithms more explicitly and efficiently transfer collaborative knowledge across clients to improve model generalization?

The key points I gathered are:

- Most existing personalized federated learning (FL) algorithms implicitly transfer collaborative knowledge by embedding it into model aggregation or regularization. 

- The authors propose that more explicitly involving multiple clients' risks in each client's objective could improve generalization, but requires prohibitive O(N^2) communication costs.

- To address this, the authors propose PGFed, a novel personalized FL algorithm that enables each client to formulate a "personalized global objective" by adaptively aggregating its own and others' risks. 

- PGFed circumvents the high communication costs by using first-order approximations to estimate non-local risks for each client.

- Experiments show PGFed improves generalization and outperforms state-of-the-art personalized FL algorithms.

In summary, the central hypothesis is that more explicit risk aggregation can improve personalized model generalization in FL, and the authors propose an efficient way to achieve this with PGFed.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. It uncovers that the explicitness of a personalized federated learning (FL) algorithm empowers it with stronger adaptation ability. The paper shows through an empirical study that directly involving multiple clients' empirical risks in the local objective (an explicit way) leads to better adaptation performance compared to just using the local risk (an implicit way). 

2. It proposes a novel explicit personalized FL algorithm called PGFed that enables each client to formulate its local objective as a "personalized global objective". This allows explicit aggregation of multiple clients' risks without massive communication costs by using first-order approximations of the non-local risks.

3. It further proposes PGFedMo, an upgrade to PGFed using momentum to efficiently utilize risks from clients who are not participating in the current round. 

4. Extensive experiments on four datasets under different federated settings demonstrate consistent improvements of the proposed PGFed and PGFedMo over state-of-the-art personalized FL methods, with up to 15.47% boost in accuracy.

In summary, the key novelty and contribution is proposing an explicit way to transfer global collaborative knowledge in personalized FL without incurring huge communication overhead. This is achieved through the personalized global objectives and the non-local risk estimations. Both PGFed and PGFedMo consistently outperform previous personalized FL methods.
