# [Verified Training for Counterfactual Explanation Robustness under Data   Shift](https://arxiv.org/abs/2403.03773)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Counterfactual explanations (CFs) are used to explain model predictions by describing how an input needs to change to receive a different prediction. CFs guide users' actions, e.g. telling a loan applicant how to get approved in the future. However, models are updated over time, so CFs can become invalid. The paper aims to generate CFs that are robust to small model changes over time.

Proposed Solution:
The paper proposes VeriTraCER, a training approach that jointly trains a classifier and CF generator to explicitly optimize CF robustness. It does this by:

1) Considering a "multiplicity set" of similar models that may be adopted in the future, rather than just the current model. 

2) Using "verified training" to soundly overapproximate a carefully designed loss function during training. The loss function ensures CF validity, quality, and verifiable robustness to small model changes.  

3) Introducing Simul-CROWN, a new verified training technique, to obtain tighter overapproximations of the loss function compared to existing methods.

Main Contributions:

1) A training algorithm to produce a classifier and CF generator that yield robust CFs to small model changes.

2) A jointly optimized loss function considering model accuracy, CF validity, quality and verifiable robustness.  

3) Simul-CROWN, a new verified training approach that can overapproximate the robust loss function more tightly.

4) Empirical evaluation showing VeriTraCER CFs are verifiably robust to small model changes and also robust to other empirical model updates like retraining. The tradeoff is CFs are further from the original input than other methods.

In summary, the paper presents a principled training approach to produce counterfactual explanations that provably maintain validity even as models are updated over time. The improved robustness comes at a cost of recourse but may be worthwhile in high stakes settings.
