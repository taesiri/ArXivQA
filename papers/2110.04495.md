# [Multi-Agent MDP Homomorphic Networks](https://arxiv.org/abs/2110.04495)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we design distributed policy networks for cooperative multi-agent reinforcement learning that are equivariant to global symmetries of the multi-agent system, while still allowing for distributed execution using only local information?The key ideas and contributions towards addressing this question seem to be:- Proposing a factorization of global symmetries in the joint state-action space of cooperative multi-agent systems into symmetries on local observations and local interactions. - Introducing a class of networks called Multi-Agent MDP Homomorphic Networks that distribute the computation that enforces global symmetries over local agents and local interactions, enabling distributed execution while maintaining global equivariance constraints.- Designing a specific multi-agent equivariant policy network architecture based on this proposed factorization, which uses group-equivariant convolutional encoders, equivariant message functions, and distributed message passing.- Empirically evaluating Multi-Agent MDP Homomorphic Networks on symmetric multi-agent problems and showing improved data efficiency compared to non-equivariant baselines.So in summary, the key hypothesis is that distributing/factoring global symmetries into local agent symmetries will enable globally equivariant and data-efficient multi-agent learning while still allowing decentralized execution. The proposed Multi-Agent MDP Homomorphic Network architecture embodies this approach.
