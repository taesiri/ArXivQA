# [Connecting the Dots: Floorplan Reconstruction Using Two-Level Queries](https://arxiv.org/abs/2211.15658)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How can we formulate floorplan reconstruction from 3D scans as a single-stage structured prediction task and design an end-to-end trainable neural network architecture to implement this formulation?

The key ideas and hypotheses proposed in the paper to address this question are:

- Floorplan reconstruction can be framed as directly predicting a variable-size set of polygons (rooms), where each polygon is a variable-length sequence of ordered vertices (corners).

- A Transformer-based architecture with two-level queries can be designed to generate these polygon sequences in parallel in a single feedforward pass, without needing explicit corner or room detections.

- The two-level queries, one for polygons and one for their vertices, along with validity classification for each query, can handle the variable and unknown number of rooms and corners.

- A polygon matching strategy can establish correspondence between predicted and ground truth polygons to enable end-to-end supervision and training.

- Such a model can outperform previous multi-stage methods reliant on hand-crafted components and optimizations, while also being significantly faster.

In summary, the central hypothesis is that floorplan reconstruction can be formulated and directly solved as a structured prediction problem using an end-to-end neural approach, without needing hand-designed pipelines or intermediate steps. The proposed RoomFormer architecture and training strategy aim to validate this hypothesis.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- It proposes a new formulation of floorplan reconstruction as the simultaneous generation of multiple ordered sequences of room corners. This avoids having to explicitly detect corners, walls, or rooms as intermediate steps.

- It develops the RoomFormer model, an end-to-end trainable Transformer architecture that implements this new formulation. The model uses two-level queries to generate variable-length polygon sequences in parallel.

- It achieves state-of-the-art performance on two challenging datasets - Structured3D and SceneCAD. The model is also significantly faster than previous methods.

- It shows the flexibility of the model by extending it to predict additional semantic information like room types, doors, and windows.

- It provides ablation studies validating the design choices like two-level queries, multi-scale features, and the loss functions.

In summary, the key innovation is the new formulation that avoids relying on hand-crafted intermediate representations, instead directly generating room polygons holistically using a Transformer. This achieves both higher accuracy and faster inference compared to prior multi-stage methods. The flexibility of the approach is also demonstrated through semantic floorplan reconstruction.
