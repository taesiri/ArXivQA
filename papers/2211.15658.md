# [Connecting the Dots: Floorplan Reconstruction Using Two-Level Queries](https://arxiv.org/abs/2211.15658)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How can we formulate floorplan reconstruction from 3D scans as a single-stage structured prediction task and design an end-to-end trainable neural network architecture to implement this formulation?

The key ideas and hypotheses proposed in the paper to address this question are:

- Floorplan reconstruction can be framed as directly predicting a variable-size set of polygons (rooms), where each polygon is a variable-length sequence of ordered vertices (corners).

- A Transformer-based architecture with two-level queries can be designed to generate these polygon sequences in parallel in a single feedforward pass, without needing explicit corner or room detections.

- The two-level queries, one for polygons and one for their vertices, along with validity classification for each query, can handle the variable and unknown number of rooms and corners.

- A polygon matching strategy can establish correspondence between predicted and ground truth polygons to enable end-to-end supervision and training.

- Such a model can outperform previous multi-stage methods reliant on hand-crafted components and optimizations, while also being significantly faster.

In summary, the central hypothesis is that floorplan reconstruction can be formulated and directly solved as a structured prediction problem using an end-to-end neural approach, without needing hand-designed pipelines or intermediate steps. The proposed RoomFormer architecture and training strategy aim to validate this hypothesis.
