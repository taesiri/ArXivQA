# [Stitching for Neuroevolution: Recombining Deep Neural Networks without   Breaking Them](https://arxiv.org/abs/2403.14224)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Recombining and evolving modern deep neural networks is very expensive computationally and in terms of data requirements when starting from scratch each time. 
- Using a warm start from pre-trained networks could be advantageous to reduce training costs, but simply exchanging layers between networks with different architectures typically breaks them due to incompatible feature representations.

Proposed Solution:
- Propose using "model stitching" to merge pre-trained parent networks into a "supernetwork" that allows mixing and matching different parts of the parent networks.
- Insert new trainable "stitching layers" between matched layers of parent networks to translate between their feature representations.
- Train stitching layers to minimize mean squared error between original and stitched activations while freezing other weights.
- Supernetwork contains switches to select between original vs stitched paths, enabling efficient evaluation of novel offspring subnetworks.

Main Contributions:
- Show that model stitching can successfully recombine incompatible pre-trained networks without needing additional training for offspring networks. 
- Demonstrate the resulting search space contains novel tradeoffs between accuracy and computational cost that can dominate the original parent networks.
- Find networks that improve accuracy at lower cost by sharing computation between parent ensemble members.
- Analyze challenges around inactive variables and linkages for search algorithms.
- Show the approach works across different network architectures and tasks like classification and segmentation.

In summary, the key insight is using model stitching to align representations between networks, opening up crossover of pre-trained models for efficient neuroevolution. The experiments then characterize properties of the resulting search space.
