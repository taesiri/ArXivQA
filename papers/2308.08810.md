# [Label Shift Adapter for Test-Time Adaptation under Covariate and Label   Shifts](https://arxiv.org/abs/2308.08810)

## What is the central research question or hypothesis that this paper addresses?

 This paper addresses the problem of test-time adaptation (TTA) when both the source and target domains have class-imbalanced label distributions. The key hypothesis is that existing TTA methods that use entropy minimization fail when the source model is biased towards majority classes due to long-tailed training data. To address this, the authors propose a novel label shift adapter module that can adapt the model parameters based on the estimated target label distribution during inference.The central research questions/hypotheses addressed in this paper are:- Most prior TTA methods assume class-balanced source data and fail when the source model is biased due to long-tailed training data. Can a TTA method work well when both source and target domains are class-imbalanced?- Entropy minimization for TTA is ineffective when the source model is biased towards majority classes. Can we adapt model parameters based on the target label distribution to handle label shifts in TTA?- Is it possible to design a module that adjusts model parameters based on estimated label distribution at test time, making TTA methods robust to joint covariate and label shifts?So in summary, the key hypothesis is that explicitly modeling label shifts is necessary for effective TTA when source and target domains are both long-tailed. The proposed label shift adapter addresses this by conditioning model parameters on target label distribution estimates.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel label shift adapter for test-time adaptation when both source and target domains have class-imbalanced label distributions. The key points are:- The authors identify that existing test-time adaptation (TTA) methods often fail when the source domain data has a long-tailed label distribution, due to the bias of the pretrained model towards majority classes. - To address this, they propose a label shift adapter module that can produce optimal parameters conditioned on the estimated target label distribution during inference. This allows adapting the pretrained model to handle the label shift.- The label shift adapter is trained before deployment using the source domain data by simulating diverse label distributions. This makes it robust to unknown target label shifts.- The adapter only predicts the parameters related to the classifier, making it model-agnostic and efficient. It can be readily integrated with existing TTA methods.- Experiments on long-tailed CIFAR, ImageNet, VisDA, OfficeHome and DomainNet datasets demonstrate that adding the proposed label shift adapter significantly improves accuracy under label shifts, outperforming prior TTA methods.In summary, the key contribution is a simple yet effective label shift adapter to make TTA methods robust to simultaneous covariate and label shifts by handling the bias due to the source label distribution. The adapter-based approach makes it widely applicable across models and datasets.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence TL;DR summary of the paper:The paper proposes a novel label shift adapter module that can be integrated into existing test-time adaptation methods to make them robust to label distribution shifts between the source and target domains.In essence, the paper introduces a plug-and-play module called the label shift adapter that helps test-time adaptation algorithms adapt better when there are differences in the label distributions between the training (source) and test (target) domains. The label shift adapter takes the estimated target label distribution as input and generates parameters to reduce the bias of the model towards the source label distribution. This allows existing test-time adaptation techniques to work well even when the test data follows a different label distribution than the training data.


## How does this paper compare to other research in the same field?

 Here is a comparison of this paper to other related research:- This paper proposes a novel label shift adapter to handle label distribution shifts in test-time adaptation (TTA). Other recent work in TTA has focused on issues like temporally correlated test data and class-imbalanced test batches, but does not address label shifts from the training distribution. So this paper tackles a unique challenge in TTA.- For handling label shifts, this paper takes inspiration from recent work in long-tailed recognition like LADE, SADE, and BalPoE. However, those methods require multiple expert architectures or access to the true test label distribution. The proposed label shift adapter is more flexible as it works with any model architecture and does not need the actual test labels.- The idea of using a module to predict adaptive parameters at test time is related to hypernetworks. But prior hypernetwork work focuses on goals like multi-task learning rather than specifically handling label shifts. The design of the label shift adapter is tailored for TTA under label shifts.- Overall, this paper makes a novel contribution to TTA research by enabling robust adaptation even when the training data has a long-tailed label distribution. The proposed label shift adapter integrates cleanly into existing TTA methods and improves performance under joint covariate and label shifts. The approach is flexible and practical for real-world deployment.In summary, this paper advances the state-of-the-art in TTA by introducing an effective and model-agnostic strategy to handle label distribution shifts, which has not been addressed adequately in prior work. The label shift adapter is a simple yet powerful mechanism for adapting models trained on imbalanced data.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Developing methods to handle more complex types of label shift beyond just changes in class proportions. The authors mention shifts in more fine-grained label distributions as an important direction.- Exploring techniques to improve estimation of the target label distribution during test-time adaptation. More accurate estimation could lead to better parameter adaptation. The authors suggest using techniques from the domain adaptation literature as a starting point.- Extending the label shift adapter approach to other test-time adaptation algorithms beyond TENT and IABN. The adapter method seems fairly general so applying it in other TTA frameworks could be beneficial.- Investigating ways to make the label shift adapter architecture even more lightweight and efficient. Though it is already low-cost, further optimizations could make it suitable for more applications. - Studying how to make normalization layers like IABN more robust to label shifts without as much sensitivity to hyperparameters. This could complement label shift adapter methods.- Developing end-to-end trainable solutions that do not need a separate training stage for the adapter prior to deployment. Removing this additional training stage could further improve practicality.- Drawing inspirations from the label shift adapter to develop techniques applicable to long-tailed recognition that can handle agnostic test label distributions.So in summary, the authors point to several areas like more complex label shifts, improved estimation, integration with other methods, efficiency, normalization layers, and connections to long-tailed recognition as interesting future research directions stemming from their work.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:The paper proposes a novel label shift adapter to handle label distribution shifts in test-time adaptation (TTA) settings where both the source and target domains have class-imbalanced label distributions. Most prior TTA methods that use entropy minimization are flawed when the source model is biased towards majority classes. To address this, the authors propose training a label shift adapter module alongside the frozen source model to predict classifier weights conditioned on the label distribution. At test time, they recursively estimate the target label distribution and use it to generate adapter parameters that reduce bias. The adapter makes minimal architectural changes so is compatible with any model. Experiments on long-tailed CIFAR, ImageNet, VisDA, OfficeHome and DomainNet benchmarks show the adapter significantly boosts various TTA methods. For example, with IABN it improves CIFAR accuracy by 9.81% and CIFAR-100 by 5.62% on average across label shifts. The method demonstrates that conditioning on the label distribution is an effective approach for test-time adaptation under joint covariate and label shifts.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:This paper proposes a novel label shift adapter to handle label distribution shifts in test-time adaptation (TTA). The key idea is to train an adapter module that can adjust the model parameters based on the target label distribution during inference. Many existing TTA methods that rely on entropy minimization struggle when the source model is biased towards dominant classes in the training data. To address this, the authors introduce a label shift adapter that takes the label distribution as input and predicts parameter adjustments to the classifier layer. The adapter is trained on the source dataset by simulating diverse label distributions. At test time, the target label distribution is estimated and fed to the adapter to produce optimal parameters for handling the label shift. This approach allows adapting pre-trained models in a model-agnostic manner, regardless of model architecture and training procedure. It can be readily combined with other TTA techniques like TENT and IABN.Experiments are conducted on long-tailed versions of CIFAR, ImageNet and other DA datasets. The proposed method consistently outperforms baselines by large margins when label shifts are significant, especially on inversely long-tailed distributions. For example, it improves TENT by 10.25% and IABN by 15.24% on CIFAR-10-C backward distribution. Further analysis validates that the label shift adapter effectively estimates the target distribution and generates suitable parameters. The computational overhead is minimal. In summary, this work successfully tackles the joint presence of covariate and label shifts in TTA by designing a lightweight adapter module. It enhances model adaptation and achieves state-of-the-art performance on benchmarks exhibiting both distribution shifts.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:The paper proposes a novel label shift adapter to handle the joint presence of covariate and label shifts in test-time adaptation (TTA). The key idea is to train a small neural network module called the label shift adapter that can generate optimal parameters for a pre-trained model according to the estimated target label distribution during inference. Specifically, the label shift adapter takes the estimated target label distribution as input and outputs affine parameters for feature normalization as well as weight and bias adjustments for the classifier layer. The adapter is trained on labeled source data by simulating diverse label distributions using techniques like balanced/inverse softmax. At test time, the target label distribution is recursively estimated using an exponential moving average of the model's soft predictions. This estimated distribution is fed to the trained adapter to produce adapted model parameters catered to the target domain. The adapted model can then be optimized via entropy minimization and tuned to the target data. Overall, the proposed label shift adapter provides a flexible way to counter biased predictions and adapt models to shifted label distributions in TTA.


## What problem or question is the paper addressing?

 This paper is addressing the problem of test-time adaptation for deep neural networks in the presence of both covariate shift and label shift. Specifically, the paper notes that most prior work in test-time adaptation (TTA) assumes only covariate shift, where the data distribution changes between source and target domains but the label distribution remains the same. However, in many real-world scenarios, the label distribution can also shift, resulting in a long-tailed or imbalanced distribution in the target domain compared to the source. Existing TTA methods like entropy minimization fail to handle such joint shifts since they rely on model predictions which are biased towards majority classes in the source data. The key question addressed is - how can we develop a TTA approach that is robust to both covariate and label shifts?The main contribution is a novel label shift adapter module that can be integrated with existing TTA methods like TENT or normalization layers like IABN. The adapter takes the estimated target label distribution as input and generates model parameters specialized for that distribution. This allows adapting the model online during inference even with label shifts. Experiments on long-tailed versions of CIFAR, ImageNet etc. show significant gains over prior TTA methods.In summary, the paper focuses on the open challenge of test-time adaptation under joint covariate and label shift, which is commonly faced in practice but not addressed well in prior work. The label shift adapter offers a flexible and effective way to handle this.
