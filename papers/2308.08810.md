# [Label Shift Adapter for Test-Time Adaptation under Covariate and Label   Shifts](https://arxiv.org/abs/2308.08810)

## What is the central research question or hypothesis that this paper addresses?

This paper addresses the problem of test-time adaptation (TTA) when both the source and target domains have class-imbalanced label distributions. The key hypothesis is that existing TTA methods that use entropy minimization fail when the source model is biased towards majority classes due to long-tailed training data. To address this, the authors propose a novel label shift adapter module that can adapt the model parameters based on the estimated target label distribution during inference.The central research questions/hypotheses addressed in this paper are:- Most prior TTA methods assume class-balanced source data and fail when the source model is biased due to long-tailed training data. Can a TTA method work well when both source and target domains are class-imbalanced?- Entropy minimization for TTA is ineffective when the source model is biased towards majority classes. Can we adapt model parameters based on the target label distribution to handle label shifts in TTA?- Is it possible to design a module that adjusts model parameters based on estimated label distribution at test time, making TTA methods robust to joint covariate and label shifts?So in summary, the key hypothesis is that explicitly modeling label shifts is necessary for effective TTA when source and target domains are both long-tailed. The proposed label shift adapter addresses this by conditioning model parameters on target label distribution estimates.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel label shift adapter for test-time adaptation when both source and target domains have class-imbalanced label distributions. The key points are:- The authors identify that existing test-time adaptation (TTA) methods often fail when the source domain data has a long-tailed label distribution, due to the bias of the pretrained model towards majority classes. - To address this, they propose a label shift adapter module that can produce optimal parameters conditioned on the estimated target label distribution during inference. This allows adapting the pretrained model to handle the label shift.- The label shift adapter is trained before deployment using the source domain data by simulating diverse label distributions. This makes it robust to unknown target label shifts.- The adapter only predicts the parameters related to the classifier, making it model-agnostic and efficient. It can be readily integrated with existing TTA methods.- Experiments on long-tailed CIFAR, ImageNet, VisDA, OfficeHome and DomainNet datasets demonstrate that adding the proposed label shift adapter significantly improves accuracy under label shifts, outperforming prior TTA methods.In summary, the key contribution is a simple yet effective label shift adapter to make TTA methods robust to simultaneous covariate and label shifts by handling the bias due to the source label distribution. The adapter-based approach makes it widely applicable across models and datasets.
