# [SA-Attack: Improving Adversarial Transferability of Vision-Language   Pre-training Models via Self-Augmentation](https://arxiv.org/abs/2312.04913)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a self-augmentation based transfer attack method (SA-Attack) to improve adversarial transferability on vision-language pre-training (VLP) models. Through analysis of prior work, the authors identify two key factors influencing transfer attacks on VLPs - inter-modality interaction and data diversity. Existing methods fail to adequately account for both. To address this, the proposed SA-Attack employs augmented input images and texts when crafting adversarial examples. Specifically, it uses a 3-step pipeline: (1) generate adversarial intermediate text from benign image-text pair; (2) augment intermediate text and benign text to create adversarial images; (3) augment adversarial and benign images to generate final adversarial text. Ablation studies validate the approach, showing consistent 2% fluctuations across different augmentation counts. Experiments conducted on Flickr30K and COCO datasets demonstrate consistent improvements in attack success rates over baselines across diverse model architectures, indicating strong transferability. Additional experiments reveal SA-Attack also poses a threat for cross-task attacks. The added diversity and inter-modality interaction facilitate highly effective black-box attacks on VLPs. 

In summary, this paper makes notable contributions by devising an attack method that accounts for key weaknesses in VLPs through input diversity and cross-modality interaction. Experiments thoroughly validate effectiveness and transferability.
