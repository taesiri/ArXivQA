# Keyword-Guided Neural Conversational Model

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is how to impose conversational goals/keywords on open-domain conversational agents, where the agent is required to lead the conversation to a target keyword smoothly and fast. Specifically, the paper aims to address two key limitations in prior work on this problem:1) The training and evaluation datasets for next-turn keyword prediction are noisy and have low correlation with human judgements. 2) During keyword transitions, agents rely solely on similarities between word embeddings, which may not reflect how humans converse.To address these limitations, the central hypothesis of the paper is that human conversations are grounded on commonsense knowledge. Therefore, the paper proposes a model that can leverage external commonsense knowledge graphs for both keyword transition and response retrieval in order to achieve smoother and faster keyword transitions.In summary, the central research question is how to enable conversational agents to smoothly and efficiently guide conversations towards target keywords by grounding the model in commonsense knowledge. The key hypothesis is that incorporating commonsense knowledge will lead to more human-like keyword transitions compared to prior approaches.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a keyword-guided neural conversational model that can leverage external commonsense knowledge graphs (CKG) for both keyword transition and response retrieval in open-domain conversations. Specifically, the key contributions are:- Identifying two limitations of existing approaches for next-turn keyword selection: 1) noisy training and evaluation datasets, and 2) unreliable keyword transition based on word embedding similarities. - Proposing two graph neural network (GNN) based models to incorporate commonsense knowledge from CKG for improving next-turn keyword prediction and keyword-augmented response retrieval. - Collecting a large-scale open-domain Reddit conversation dataset that has more diverse linguistic patterns compared to existing datasets.- Conducting extensive experiments showing that grounding keyword transitions on CKG improves conversation smoothness and allows reaching the target keyword faster. Leveraging commonsense triplets also substantially improves the performance of next-turn keyword prediction and response retrieval.- Human evaluations and model analysis validating that the proposed model produces smoother responses and achieves higher success rates in reaching target keywords compared to competitive baselines.In summary, the key contribution is using commonsense knowledge graphs to improve keyword transition and response retrieval in goal-oriented open-domain conversational agents. The proposed techniques and the Reddit dataset enable building more human-like conversational agents.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a keyword-guided neural conversational model that incorporates commonsense knowledge graphs to improve the smoothness and efficiency of leading conversations to target keywords.
