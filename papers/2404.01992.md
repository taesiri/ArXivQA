# [Dissecting Paraphrases: The Impact of Prompt Syntax and supplementary   Information on Knowledge Retrieval from Pretrained Language Models](https://arxiv.org/abs/2404.01992)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Pre-trained language models (PLMs) are known to contain relational knowledge, which can be retrieved using cloze-style prompts. However, small differences in prompt syntax or semantics can substantially impact knowledge retrieval performance. 
- Prior work has not evaluated the combined impact of syntax and semantic changes in prompts. Dedicated probes are needed to control these effects and study their influence on knowledge retrieval.

Proposed Solution:
- The authors design ConPare-LAMA, a probe with 34 million distinct prompts that facilitates comparison across minimal paraphrases. 
- The prompts follow a unified meta-template that enables controlled variation of syntax (clausal vs appositive) and semantics (relation only vs relation + domain/range information).
- Automated prompt construction is enabled by fetching domain/range info from Wikidata. This controls variables not under investigation.

Main Contributions:
- ConPare-LAMA probe to advance PLM knowledge retrieval research 
- Study of independent effects of syntax and semantics on knowledge retrieval
- Findings: clausal syntax prompts are better when querying PLMs, especially with combined supplementary info. Knowledge is more consistently recalled and uncertainty decreases for known facts.  
- Range info boosts performance more than domain info, though domain info is more reliably helpful.
- Demonstrate fragility of PLM knowledge representations, especially for appositive phrases.

In summary, the paper introduces a controlled paraphrasing approach and large-scale probe to shed light on how syntax and semantics impact knowledge retrieval from PLMs. Key findings are the superior performance and consistency of clausal prompt structure over appositive structure.
