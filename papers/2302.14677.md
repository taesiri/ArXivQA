# [Backdoor Attacks Against Deep Image Compression via Adaptive Frequency   Trigger](https://arxiv.org/abs/2302.14677)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How can we perform effective backdoor attacks against deep learning based image compression models?Specifically, the authors investigate injecting backdoors into image compression models via adaptive frequency triggers. They explore different attack objectives such as degrading compression quality or attacking downstream computer vision tasks. The key hypothesis appears to be that by adding adaptive triggers in the frequency domain of images, they can successfully inject multiple backdoors into a single image compression model. Each backdoor is activated by a specific trigger pattern and leads to a malicious effect defined by the attack objective.In summary, the central research question is how to develop a methodology for performing stealthy yet effective backdoor attacks on deep learning based image compression models by using adaptive frequency domain triggers. The hypothesis is that this approach can allow injecting multiple backdoors with different objectives into a single model.


## What is the main contribution of this paper?

The main contributions of this paper are:- They propose a novel backdoor attack against deep learning based image compression models by injecting triggers adaptively in the frequency domain. - They comprehensively explore various attack objectives, including attacking compression quality measures like bit-rate and reconstruction quality, as well as attacking downstream computer vision tasks like face recognition and semantic segmentation.- They design a frequency-based trigger injection model that leverages priors from both spatial and frequency domains to generate poisoned images effectively. - They propose a simple yet effective dynamic loss to balance different terms in the joint training loss, which enables more efficient training.- They demonstrate that multiple triggers can be injected into one single compression model, with each trigger associated with a specific attack objective.- Extensive experiments validate that their attack can successfully degrade compression performance or mislead downstream tasks upon the presence of the corresponding trigger. The attack also has little impact on clean images.In summary, this is the first work that systematically investigates backdoor attack against deep learning based image compression. The proposed adaptive frequency trigger injection and comprehensive attacking scenarios make the attack more stealthy and effective.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points in the paper:The paper proposes a novel backdoor attack against deep learning based image compression models by injecting adaptive frequency domain triggers, which can effectively attack compression quality and downstream computer vision tasks with multiple triggers in a single model.


## How does this paper compare to other research in the same field?

Here are my thoughts on how this paper compares to other research in the field of backdoor attacks against image compression models:- This is the first paper I am aware of that explores backdoor attacks specifically against learned image compression models. Most prior work has focused on attacking high-level vision models like classifiers and segmenters. Studying attacks against low-level vision models like compression is an interesting new direction.- The proposed frequency-based adaptive trigger injection method is novel compared to prior work. Using DCT-domain triggers customized for each input image is an intuitive idea given DCT's prevalence in compression. This adaptive frequency trigger seems more suited for attacking compression than the fixed spatial triggers used in most prior backdoor attack papers.- The attack objectives considered are comprehensive, including both low-level compression metrics like bitrate and quality as well as high-level downstream task performance. This provides a thorough evaluation of the attack's capabilities.- Allowing multiple backdoor triggers to be injected into one model, each with a different objective, is a capability not seen in previous papers. It makes the attack more practical and dangerous.- Modifying only the encoder of a compression model rather than retraining the whole model makes the attack more feasible in real-world settings.- Compared to the baseline method, the proposed approach seems substantially more effective at achieving strong attack performance across different compression rates and downstream tasks.Overall, I believe this paper provides a thorough and rigorous exploration of backdoor attacks in a new problem domain of learned image compression. The adaptive frequency trigger method and comprehensive attack formulations seem like clear improvements over prior work. This attack could pose a real threat to the reliability of image compression systems.
