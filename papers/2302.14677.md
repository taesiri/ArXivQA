# [Backdoor Attacks Against Deep Image Compression via Adaptive Frequency   Trigger](https://arxiv.org/abs/2302.14677)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How can we perform effective backdoor attacks against deep learning based image compression models?Specifically, the authors investigate injecting backdoors into image compression models via adaptive frequency triggers. They explore different attack objectives such as degrading compression quality or attacking downstream computer vision tasks. The key hypothesis appears to be that by adding adaptive triggers in the frequency domain of images, they can successfully inject multiple backdoors into a single image compression model. Each backdoor is activated by a specific trigger pattern and leads to a malicious effect defined by the attack objective.In summary, the central research question is how to develop a methodology for performing stealthy yet effective backdoor attacks on deep learning based image compression models by using adaptive frequency domain triggers. The hypothesis is that this approach can allow injecting multiple backdoors with different objectives into a single model.


## What is the main contribution of this paper?

The main contributions of this paper are:- They propose a novel backdoor attack against deep learning based image compression models by injecting triggers adaptively in the frequency domain. - They comprehensively explore various attack objectives, including attacking compression quality measures like bit-rate and reconstruction quality, as well as attacking downstream computer vision tasks like face recognition and semantic segmentation.- They design a frequency-based trigger injection model that leverages priors from both spatial and frequency domains to generate poisoned images effectively. - They propose a simple yet effective dynamic loss to balance different terms in the joint training loss, which enables more efficient training.- They demonstrate that multiple triggers can be injected into one single compression model, with each trigger associated with a specific attack objective.- Extensive experiments validate that their attack can successfully degrade compression performance or mislead downstream tasks upon the presence of the corresponding trigger. The attack also has little impact on clean images.In summary, this is the first work that systematically investigates backdoor attack against deep learning based image compression. The proposed adaptive frequency trigger injection and comprehensive attacking scenarios make the attack more stealthy and effective.
