# Large Language Models Are Reasoning Teachers

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the abstract, the central research question addressed in this paper is:How can large language models be used as "reasoning teachers" to transfer complex reasoning capabilities to much smaller student models, reducing model size requirements by orders of magnitude?The key points are:- Recent works have shown chain-of-thought (CoT) prompting can elicit complex reasoning in very large models (175B parameters). However, these models are infeasible to deploy at scale due to computational costs. - This paper proposes using large models to generate CoT reasoning samples, which are then used to fine-tune much smaller student models. This transfers reasoning abilities while drastically reducing model size.- They introduce "diverse reasoning" - generating multiple distinct rationales per sample via stochastic sampling of the teacher - to further improve the teaching effects.- Experiments on a wide range of public models and tasks show their method enables significant reasoning in models 25-2500x smaller than the teacher. Diverse reasoning provides substantial gains at minor cost.- Analysis indicates performance is uniquely scalable along axes of diverse reasoning, data size, teacher performance, and student model size. This demonstrates potential for reliable reasoning in small feasible models.In summary, the core research question is how to transfer complex reasoning abilities from huge teacher models to much smaller students via fine-tuning on teacher-generated reasoning samples, with a focus on minimizing student model size.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method called Fine-tune-CoT to enable complex reasoning capabilities in small language models. The key ideas are:- Using very large "teacher" models to generate chain-of-thought (CoT) reasoning samples via zero-shot prompting. This allows generating reasoning data without task-specific engineering or human annotations.- Using the generated CoT samples to fine-tune much smaller "student" models. This transfers the reasoning abilities of large models to smaller, more deployable ones. - Introducing "diverse reasoning" to generate multiple explanations per sample and augment the fine-tuning data. This further improves the reasoning abilities learned by the student models.The paper shows that Fine-tune-CoT can unlock notable reasoning skills in models orders of magnitude smaller than large teacher models. It also demonstrates the scalability of the method along various axes like diverse reasoning, dataset size, teacher model, and student model size.Overall, the key contribution is a simple yet effective approach to distill complex reasoning abilities from huge language models into small ones, making advanced reasoning skills accessible to the broader community. The method is versatile, scalable, and does not require task-specific engineering or human annotations.
