# [Are NeRFs ready for autonomous driving? Towards closing the   real-to-simulation gap](https://arxiv.org/abs/2403.16092)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Neural Radiance Fields (NeRFs) are promising for simulating autonomous driving (AD) data to enable closed-loop testing and data augmentation. However, it is unclear if conclusions drawn from NeRF-simulated data transfer reliably to real data. This real-to-simulated (real2sim) gap needs to be addressed.   

- Prior work tries reducing this gap by improving NeRF image quality. However, many scenarios remain challenging to reconstruct faithfully. Hence, the authors propose an alternate perspective - making perception models robust to NeRF artifacts without compromising real data performance.

Methods:
- The authors fine-tune multiple state-of-the-art perception models on 3 different types of augmented data - basic image augmentations, rendered NeRF images, and image-to-image translated images to induce NeRF-like artifacts.

- They evaluate object detectors (FCOS3D, PETR, BEVFormer) and an online mapping model (MapTRv2) on real and simulated nuScenes data. Both interpolated and extrapolated camera views are considered.  

Results:
- All fine-tuning methods substantially reduce the real2sim gap across tasks and models, even boosting real-world performance in some cases. Image-to-image translation is very promising, outperforming actual NeRF images.

- Analysis of detection agreement vs range reveals robustness improvements to be more pronounced at longer distances. Further, incorporating simulated novel views during training improves generalization.

- LPIPS and FID image similarity metrics have the strongest correlation to the real2sim gap, indicating perceptual similarity is key. Fine-tuning makes models less sensitive to poor renderings.

Contributions:
- First large-scale real2sim gap analysis for AD models and data.
- A new direction is proposed - enhancing model robustness over rendering quality. Simple fine-tuning techniques are very effective for this.
- Rendered data can even boost real-world performance, enabling new training regimes.
- FID and LPIPS identified as indicators of real2sim gap, enabling better use of NeRFs for simulation.
