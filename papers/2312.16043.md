# [An extended asymmetric sigmoid with Perceptron (SIGTRON) for imbalanced   linear classification](https://arxiv.org/abs/2312.16043)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Class imbalance and inconsistency between training/test datasets is a key challenge in classification tasks. Existing methods like cost-sensitive learning with π-weighted loss functions are sensitive to such inconsistencies.  

Proposed Solution:
- Proposes a new extended asymmetric sigmoid called SIGTRON and a SIGTRON-induced convex loss function for imbalanced classification (SIC model).

- SIC model has internal polynomial parameters in the loss instead of an external π-weight. This makes it more robust and adaptive to inconsistencies between training and test.

- Also proposes a Quasi-Newton optimization framework with interval-based bisection line search for optimizing the virtual convex loss functions.

Main Contributions:

- Introduces adjustable SIGTRON function that generalizes logistic sigmoid with fixed probability-half point but tunable inflection point.

- Derives virtual SIGTRON-induced convex loss function for imbalanced classification that is inherently adaptive without needing external weights.

- Shows SIC model derives a skewed hyperplane equation that allows adapting to training/test inconsistencies.

- Proposes Quasi-Newton line search technique for optimizing virtual loss functions that outperforms cubic interpolation methods.

- Empirically demonstrates superior and robust classification performance of SIC model compared to π-weighted loss functions and state-of-the-art classifiers on 118 benchmark datasets.

In summary, it develops a flexible framework for imbalanced classification that is intrinsically adaptive, together with an effective optimization approach for training such models. Both advances contribute to more accurate and reliable classification, especially in presence of inconsistencies.
