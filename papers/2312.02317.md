# [GNN2R: Weakly-Supervised Rationale-Providing Question Answering over   Knowledge Graphs](https://arxiv.org/abs/2312.02317)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Most current methods for multi-hop question answering over knowledge graphs only provide final conclusive answers without explanations. This issue severely limits the application of KG-based QA in real-world scenarios due to two main challenges: (1) annotations of reasoning chains are usually lacking, making it difficult to train models to generate explanations, and (2) generating explanations requires explicit reasoning over the KG which is inefficient at scale.

Proposed Solution:
The paper proposes a novel two-step model called GNN2R that can provide both final answers and reasoning subgraphs efficiently as explanations, using only weak supervision through question-answer pairs.

In Step I, a novel graph neural network (GNN) architecture is used to encode the question and KG entities into a joint embedding space where the question vector is close to its answer vectors. This allows pruning the search space of candidate answers and explanations.

In Step II, candidate reasoning subgraphs linking answers to topic entities are extracted and rewritten into natural language expressions. A pre-trained sentence transformer model compares these expressions to the question semantically and selects the most similar subgraph, returning its entities as final answers. Algorithms are proposed to fine-tune the sentence transformer using only the weak supervision.

Main Contributions:
- Proposal of an efficient and effective two-step model (GNN2R) that provides both answers and reasoning subgraphs as explanations to questions, using only supervision of answers.

- A novel GNN architecture that can jointly encode questions and KG to identify candidate answers, pruning the search space.

- Simple yet effective algorithms to fine-tune a language model to select the best reasoning subgraph using only weak supervision.

- Extensive experiments demonstrating state-of-the-art performance of GNN2R in multi-hop QA over benchmarks, including in terms of efficiency and quality of explanations.
