# [EfficientTrain: Exploring Generalized Curriculum Learning for Training   Visual Backbones](https://arxiv.org/abs/2211.09703)

## What is the central research question or hypothesis that this paper addresses?

 Here are a few key points about the central research question addressed in this paper:

- The paper aims to improve the training efficiency of modern deep visual backbones like convolutional neural networks (CNNs) and vision transformers (ViTs). The goal is to reduce the computational cost and training time required for state-of-the-art models without sacrificing accuracy. 

- The key hypothesis is that each training example contains both "easier-to-learn" and "harder-to-learn" patterns. The paper proposes exposing only the easier patterns in the beginning and gradually introducing harder ones later in training.

- The main research questions are: 1) How to identify and extract the easier-to-learn patterns in images? 2) How to design a training curriculum that progressively transitions from easier to harder patterns?

- To address the first question, the paper shows both theoretically and empirically that lower frequency image components are easier to learn. It proposes frequency cropping to extract these. 

- For the second question, it designs a simple, unified curriculum called EfficientTrain that starts with lower frequency patterns and weaker augmentation, then transitions to full images and stronger augmentation.

- The central hypothesis is that this curriculum, despite its simplicity, will improve training efficiency across diverse model architectures, datasets, and training configurations. Experiments validate this.

In summary, the core research contribution is a generalized curriculum learning approach to improve training efficiency, enabled by novel frequency-based analysis and a simple but effective EfficientTrain algorithm. Comparisons show superior efficiency gains over prior arts like progressive learning.
