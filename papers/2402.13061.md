# [Toward Fairness via Maximum Mean Discrepancy Regularization on Logits   Space](https://arxiv.org/abs/2402.13061)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Fairness has become important in machine learning models, especially for high-risk applications like healthcare and facial recognition. However, existing models can be biased based on sensitive attributes like race, gender, age.
- Previous methods to mitigate bias have limitations. Specifically, methods that constrain the logit outputs have inconsistencies with optimizing for fairness based on the equalized odds (EO) metric.

Proposed Solution:
- The paper proposes a new framework called Logits-MMD that achieves fairness by imposing constraints on logit outputs using maximum mean discrepancy (MMD). 
- MMD measures distribution distance and aligns well with minimizing EO, which considers difference in true positive rate and false positive rate between groups.
- The Logits-MMD regularization term minimizes MMD between logit distributions of different sensitive groups to make predictions invariant.

Contributions:
- Proves issues with previous logit regularization methods like Gaussian assumption and histogram approximation in terms of optimizing for EO.
- Demonstrates Logits-MMD has better optimization properties for achieving EO metric.
- Achieves state-of-the-art performance on facial recognition datasets CelebA and UTK Face, improving on fairness by 40.6% and 13% over best baseline.
- Shows Logits-MMD works well to mitigate varying degrees of bias on a cat vs dog dataset.
- Provides analysis to show Logits-MMD distributions between sensitive groups are more similar than other methods.

In summary, the paper addresses limitations of prior work on training fair models by proposing a logits constraint framework aligned with a widely used fairness metric. Experiments demonstrate state-of-the-art performance and generalizability.
