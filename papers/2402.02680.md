# [Large Language Models are Geographically Biased](https://arxiv.org/abs/2402.02680)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Large language models (LLMs) inherently contain biases from their training data, which can lead to societal harms if unchecked. Prior work has studied biases in professions, gender, race etc. but geographic bias is a new dimension that allows inclusively evaluating biases of all people on Earth. 

- Geographic bias is defined as systemic errors made by LLMs when making geospatial predictions. It allows attributing biases to groups based on where they live and examining correlations with potential anchoring bias distributions like socioeconomic conditions.

Methods
- The authors design prompts to elicit accurate zero-shot geospatial predictions from LLMs in the form of ratings on a scale of 0.0 to 9.9. This avoids fine-tuning biases. 

- They visualize predictions on maps to analyze errors and biases. Plots of rating ranks are preferred over ratings themselves since ranks are more robust. 

- For sensitive subjective topics with no ground truth, a bias score is proposed that incorporates correlation with an anchoring bias distribution, mean absolute deviation (MAD) of ratings, and answer rate.

Key Results
- LLMs can make accurate zero-shot geospatial predictions, with Spearman's rho up to 0.89 for some topics. Using expected rating values with logprobs improves performance.

- Common geographic biases exist for both objective and sensitive subjective topics. In particular, LLMs rate locations with lower socioeconomic status lower on sensitive subjective qualities, with high correlation (Spearman's rho up to 0.7)

- Subtle biases can be revealed using expected rating values, even when MAD of ratings appears very small. Bias score quantifies magnitude of bias and varies significantly across LLMs.

Main Contributions
- Demonstrating LLMs' capability for accurate zero-shot geospatial predictions 

- Discovering and visualizing geographic biases of LLMs, especially discrimination against lower socioeconomic areas

- Proposing bias score to quantify magnitude of geographic bias to compare models
