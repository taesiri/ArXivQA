# [ConsistentEE: A Consistent and Hardness-Guided Early Exiting Method for   Accelerating Language Models Inference](https://arxiv.org/abs/2312.11882)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Existing early exiting methods for accelerating language models impose all internal classifiers to predict all instances correctly during training. However, during inference, only one internal classifier needs to predict correctly to exit early without losing accuracy. This inconsistency between training and inference objectives harms the performance of internal classifiers.

Proposed Solution:
- The paper proposes ConsistentEE, a reinforcement learning based early exiting approach that is consistent between training and inference. 
- A policy network is added to decide whether an instance should exit at the current layer or continue. If the policy network decides to exit, only the internal classifier at that layer incurs a loss to predict correctly.  
- A concept of "memorized layer" is proposed to measure hardness of instances. It is used in the reward function to allow "easy" instances to focus more on acceleration and "hard" instances to focus more on accuracy.

Main Contributions:
- Formulates early exiting as a reinforcement learning problem to achieve training-inference consistency.
- Proposes memorized layer to quantify instance hardness and uses it to guide the trade-off between accuracy and acceleration. 
- Experiments show ConsistentEE outperforms state-of-the-art methods on various language understanding and generation benchmarks, demonstrating effectiveness and efficiency.

In summary, the paper addresses the inconsistency issue of early exiting methods via a reinforcement learning formulation and a hardness-aware reward design. The proposed ConsistentEE method achieves better accuracy-speed trade-offs on multiple language tasks.
