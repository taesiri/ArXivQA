# [Weakly Supervised Monocular 3D Object Detection using Multi-View   Projection and Direction Consistency](https://arxiv.org/abs/2303.08686)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to train monocular 3D object detection models using only 2D image labels, without needing 3D point cloud data for labeling. 

The key points are:

- Most current monocular 3D detection methods rely on 3D point clouds to label the ground truth boxes for training, but this causes an inconsistency between training (uses 3D data) and inference (only 2D images). 

- The authors propose a new weakly supervised framework that only uses 2D labels like 2D bounding boxes to train the models. This allows utilizing large-scale 2D-labeled data like feedback images from production cars.

- They introduce three types of consistency between 2D labels and 3D predictions: projection consistency, multi-view consistency, and direction consistency. Losses are designed based on these to guide the model optimization.

- A new 2D direction labeling method is proposed to replace the 3D rotation labeling. This further avoids needing 3D point clouds. 

- Experiments show their method achieves comparable or better performance than some fully supervised methods. It also significantly boosts the baseline model when used for pre-training with a small amount of 3D labels.

In summary, the key hypothesis is that by designing losses based on 2D-3D consistency, they can train 3D detection models without relying on 3D point cloud labeling data.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes a new weakly supervised method for monocular 3D object detection that only requires 2D labels marked on images, without needing any 3D point clouds for labeling. This allows the method to be trained on images from production cars that lack 3D labels. 

2. It incorporates projection consistency and multi-view consistency losses to guide the prediction of accurate 3D bounding boxes based on relationships between 2D and 3D data.

3. It proposes a new 2D direction labeling method to replace 3D rotation labels, and a direction consistency loss to optimize rotation prediction. 

4. Experiments show the method achieves comparable performance to some fully supervised methods on KITTI. When used for pre-training with a small amount of 3D labels, it significantly outperforms the fully supervised baseline.

5. The method's ability to work with only 2D labels makes it feasible to use large amounts of feedback image data from production cars to improve robustness and generality of models. This is a key advantage over methods that require 3D labels.

In summary, the main novelty is the weakly supervised framework and losses using only 2D labels, which enables using production car data lacking 3D annotations to improve monocular 3D detection models. The consistency losses are designed to provide supervision without 3D labels.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a weakly supervised monocular 3D object detection method that trains models using only 2D image labels, without needing 3D point cloud data for labeling, by exploring projection, multi-view, and direction consistency between 2D labels and 3D predictions.


## How does this paper compare to other research in the same field?

 Here are my thoughts on how this paper compares to other research in monocular 3D object detection:

- The key contribution of this paper is proposing a weakly supervised method that only requires 2D image labels, without needing 3D point clouds for labeling. This allows the model to be trained on readily available 2D annotated images, rather than relying on more expensive 3D point cloud annotations. This is a novel approach in the field.

- Most prior work in monocular 3D detection uses full 3D supervision during training. This includes methods like MonoGRNet, M3D-RPN, MonoDLE, etc. So the weakly supervised approach proposed here is quite different.

- There has been some recent work exploring weak supervision for 3D detection, but those methods still rely on LiDAR data during training (e.g. WeakM3D, Autolabels). The key difference is that this paper proposes a method completely free of LiDAR data.

- The consistency losses proposed in this paper to enable the weak supervision are also novel, especially the use of multi-view consistency and direction consistency losses.

- In terms of performance on the KITTI benchmark, the results are very competitive to prior full supervision methods. The method even outperforms some fully supervised techniques.

- The ability to train on 2D-only annotated images could enable new applications by leveraging readily available image datasets, without needing 3D labels. This could help with scalability and use of production car feedback data.

In summary, the weakly supervised approach proposed in this paper is quite unique compared to prior work, and has the potential to expand the applicability of monocular 3D detection. The consistency losses and overall framework offer new ideas for training without 3D supervision.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some key future research directions suggested by the authors include:

- Improving the performance on small, distant, and occluded objects. The paper notes limitations in detecting smaller objects far from the camera, and handling heavy occlusion. Further research could focus on enhancing the model's capabilities on these challenging cases.

- Extension to other object categories beyond cars, pedestrians and cyclists. The current method is evaluated on the main KITTI categories, but could be extended to detect more object types. 

- Leveraging additional 2D annotations. The paper uses 2D boxes and direction labels, but other 2D cues like keypoints, segmentation masks, etc could provide further supervision signals.

- Combination with stereo vision or other depth estimation methods. The paper uses monocular images, but fusion with stereo depth estimation could help constrain the depth prediction and improve accuracy.

- Application to diverse driving datasets. Testing the method on more complex and varied driving datasets beyond KITTI could reveal areas for improvement.

- End-to-end joint training. The current pipeline has separate steps for pose estimation and 3D box prediction. An end-to-end approach could be explored. 

- Weakly supervised refinement of the pose network. The relative camera pose is currently estimated separately in a self-supervised manner. Weakly supervising this pose network could improve multi-view consistency.

- Hard example mining for multi-view pairs. A strategy to select more informative image pairs during training could improve efficiency.

In summary, expanding the categories, leveraging more supervision, fusing with depth, testing on new datasets, end-to-end training, and sampling better views seem to be key directions suggested for future work.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points in the paper:

This paper proposes a new weakly supervised method for monocular 3D object detection that only requires 2D bounding box labels on images for training, without needing any 3D point cloud data. The method explores three types of consistency between the 2D labels and 3D predictions - projection, multi-view, and direction consistency - and designs losses based on them to guide the model training. A new 2D direction labeling method is introduced to replace 3D rotation labels. Experiments on KITTI dataset show the proposed method achieves comparable results to some fully supervised methods. When used for pre-training with only 1/3 fully labeled data, it significantly outperforms the supervised baseline. A new ProdCars dataset collected from production cars is proposed to demonstrate the applicability to real-world data. Overall, the weakly supervised method enables utilizing large-scale data from production cars to improve model robustness without needing expensive 3D labeling.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points from the paper:

This paper proposes a new weakly supervised method for monocular 3D object detection that only requires 2D labels on images for training, avoiding the need for 3D point clouds. The method explores three types of consistency between the 2D labels and 3D predictions to guide the model training: projection consistency between the projected 3D boxes and 2D labels, multi-view consistency of predictions on paired images from different viewpoints, and direction consistency between predicted 3D rotations and 2D direction labels. Based on these consistencies, the paper designs corresponding losses to optimize the model. Experiments on the KITTI dataset demonstrate the proposed weakly supervised method achieves comparable performance with some fully supervised methods. Using the method as pre-training can significantly boost performance when fine-tuned with a small set of 3D labels. The method also generalizes well on a new ProdCars dataset collected from production cars, showing its potential for utilizing large-scale feedback data from production vehicles to improve robustness.

In summary, this paper's main contributions are: 1) A new weakly supervised monocular 3D detection method only requiring 2D image labels, avoiding 3D point clouds. 2) Exploration of projection, multi-view, and direction consistency between 2D labels and 3D predictions to guide training. 3) Design of corresponding losses based on the consistencies for model optimization. 4) Demonstration of strong performance on KITTI and a new ProdCars dataset, even outperforming some fully supervised methods. 5) Potential to leverage large-scale production car feedback data. The weakly supervised approach enables training models on far more data than possible with full 3D supervision.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes a new weakly supervised method for monocular 3D object detection that only requires 2D labels on images for training, without needing any 3D point clouds data. The key idea is to exploit three types of consistency between the 2D labels and 3D predictions:

1) Projection consistency: The projected 2D boxes of the predicted 3D boxes should align with the 2D box labels. A projection loss is proposed to minimize the difference. 

2) Multi-view consistency: Observations of the same object from different viewpoints should have consistent 3D boxes. A consistency loss is designed to minimize the discrepancy of predictions from different viewpoints.

3) Direction consistency: The predicted 3D box rotation should be consistent with the 2D direction label when projected to the image plane. A direction loss is used to optimize the rotation prediction.

Based on these three consistencies, the proposed weakly supervised method can provide comprehensive guidance to train the 3D detection model without relying on 3D point clouds. Experiments show it achieves comparable performance to some fully supervised methods on the KITTI dataset.
