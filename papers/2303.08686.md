# [Weakly Supervised Monocular 3D Object Detection using Multi-View   Projection and Direction Consistency](https://arxiv.org/abs/2303.08686)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to train monocular 3D object detection models using only 2D image labels, without needing 3D point cloud data for labeling. 

The key points are:

- Most current monocular 3D detection methods rely on 3D point clouds to label the ground truth boxes for training, but this causes an inconsistency between training (uses 3D data) and inference (only 2D images). 

- The authors propose a new weakly supervised framework that only uses 2D labels like 2D bounding boxes to train the models. This allows utilizing large-scale 2D-labeled data like feedback images from production cars.

- They introduce three types of consistency between 2D labels and 3D predictions: projection consistency, multi-view consistency, and direction consistency. Losses are designed based on these to guide the model optimization.

- A new 2D direction labeling method is proposed to replace the 3D rotation labeling. This further avoids needing 3D point clouds. 

- Experiments show their method achieves comparable or better performance than some fully supervised methods. It also significantly boosts the baseline model when used for pre-training with a small amount of 3D labels.

In summary, the key hypothesis is that by designing losses based on 2D-3D consistency, they can train 3D detection models without relying on 3D point cloud labeling data.
