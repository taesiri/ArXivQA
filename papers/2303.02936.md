# [UniHCP: A Unified Model for Human-Centric Perceptions](https://arxiv.org/abs/2303.02936)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to design a unified model that can handle multiple human-centric visual perception tasks simultaneously in an end-to-end manner. Specifically, the paper proposes a unified model called UniHCP that can handle five distinct human-centric tasks - pose estimation, human parsing, pedestrian detection, person re-identification, and pedestrian attribute recognition. The key hypothesis is that by formulating these tasks in a shared framework and training them jointly at scale, the model can learn complementary human-centric knowledge that benefits all tasks.The paper aims to investigate:- Whether it is feasible to unify diverse human-centric tasks under a simple transformer-based encoder-decoder architecture using task-specific queries and a shared task-guided interpreter.- If maximum knowledge sharing and weight reuse can be achieved across different human-centric tasks while maintaining strong performance.- If the model can achieve competitive performance on multiple tasks compared to specialized state-of-the-art models when evaluated directly or after fine-tuning.- The transferability of the learned representations to new datasets and tasks.In summary, the central hypothesis is that a unified model trained at scale on diverse human-centric tasks can match or exceed specialized models on each task while enabling knowledge sharing, efficient inference, and transferability. The paper empirically verifies this hypothesis through extensive experiments.
