# Deep Flow-Guided Video Inpainting

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we develop an effective video inpainting approach that fills in missing regions in a video while preserving both spatial and temporal coherence? The key hypothesis appears to be:By first synthesizing a coherent optical flow field to guide pixel propagation across frames, we can transform the difficult video completion task into a more tractable flow completion task.In particular, the authors hypothesize that:1) Completing the missing optical flow is easier than directly hallucinating missing RGB values, since background and foreground motions are often more regular. 2) Propagating pixels using the completed flow can naturally maintain temporal coherence.3) Their proposed Deep Flow Completion Network can accurately complete missing flows in a coarse-to-fine manner.4) Hard flow example mining can further improve flow completion. 5) Propagating pixels using the completed flow and filling any remaining holes with image inpainting can produce high-quality coherent video inpainting.In summary, the central hypothesis is that flow completion and propagation can effectively transform video inpainting into a more solvable problem while maintaining spatial and temporal coherence. The Deep Flow Completion Network and its training mechanisms are proposed to test this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the abstract, the main contributions of this paper appear to be:1. Proposing a novel flow-guided video inpainting approach that transforms the task into a pixel propagation problem by first synthesizing a coherent optical flow field to guide pixel propagation.2. Designing a Deep Flow Completion network to complete the missing flow fields in a coarse-to-fine manner and further improving quality through hard flow example mining. 3. Demonstrating that by propagating pixels guided by the completed flow fields, missing video regions can be filled precisely while maintaining spatial and temporal coherence.4. Achieving state-of-the-art performance on DAVIS and YouTube-VOS datasets in terms of inpainting quality and speed. The method is significantly faster than prior optimization-based techniques.5. The approach does not require any assumptions about the missing regions or motion in the video, unlike previous methods. It can handle complex scenes and motions.In summary, the key contribution is the novel flow-guided video inpainting approach that transforms the task into a learnable flow completion and pixel propagation problem, outperforming prior techniques in quality and speed. The designed Deep Flow Completion network is shown to be effective in completing coherent flow fields to guide propagation.
