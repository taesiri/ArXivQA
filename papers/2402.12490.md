# [Towards Cross-Domain Continual Learning](https://arxiv.org/abs/2402.12490)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Current continual learning (CL) methods focus on single domains, limiting applicability to more complex real-world problems involving multiple related domains with limited labeled data. 
- Two key challenges in multi-domain CL: 1) Task drift - changes in label distributions 2) Domain drift - changes in input distributions.
- Existing CL methods susceptible to "feature alignment catastrophic forgetting" when applied to unsupervised multi-domain problems, failing to maintain domain invariance.

Proposed Solution:
- Introduce Cross-Domain Continual Learning (CDCL) framework to address unsupervised cross-domain task-incremental learning.
- Key components:
   1) Inter-intra-task cross-attention - Aligns features between labeled source & unlabeled target domains, retaining alignment knowledge over tasks.
   2) Intra-task center-aware pseudo-labeling - Generates target labels using source & target features, enables semi-supervised learning.
- Also stores samples & logits in rehearsal memory to retain knowledge.

Main Contributions:
- Novel CDCL framework for unsupervised cross-domain task-incremental learning with good stability-plasticity tradeoff.
- Inter-intra-task cross-attention to consolidate domain alignment knowledge over sequential tasks.
- Intra-task center-aware pseudo-labeling for accurate input pairs from source & target.
- Extensive experiments validating performance on UDA datasets.
- Introduces ideas contributing to advancement of cross-domain continual learning field.

In summary, the paper introduces an innovative framework called CDCL that can effectively perform continual learning across multiple related but unlabeled domains, overcoming limitations of prior single-domain and supervised multi-domain methods.
