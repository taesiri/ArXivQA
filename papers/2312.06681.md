# [Steering Llama 2 via Contrastive Activation Addition](https://arxiv.org/abs/2312.06681)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Steering Llama 2 via Contrastive Activation Addition":

Problem: 
As large language models (LLMs) become more capable, it is important to ensure they are helpful, honest, and harmless. However, techniques like reinforcement learning from human feedback and prompt engineering have limitations in preventing unwanted behaviors like hallucination. The paper explores using "activation engineering" methods like Contrastive Activation Addition (CAA) to better control LLMs.

Method:
CAA computes "steering vectors" that encode directions in the LLM's latent space corresponding to high-level behaviors. These are generated by taking the difference in activations between pairs of prompts demonstrating the presence/absence of behaviors. During inference, the steering vectors are added to modify activations and precisely control the LLM's behavior.

The authors generate CAA steering vectors for six categories of behaviors using contrastive multiple choice questions and model-rated free text generations. They test CAA's ability to modulate behaviors in the Llama 2 collection of models.

Results:
Across behaviors, adding/subtracting steering vectors successfully increases/decreases the prevalence of targeted behaviors as measured by model ratings, with larger effects for free text generation. CAA outperforms few-shot prompting, provides additional control atop other methods like finetuning, and minimally impacts capabilities. Analyses reveal CAA steering vectors represent high-level concepts and cluster model behavior.

Conclusion: 
The paper demonstrates CAA as an effective, minimally destructive method for steering LLMs that could complement existing alignment techniques. Analyzing steering vectors also sheds light on LLM representations. Future work could test multi-layer interventions and conversion of vectors to text.
