# [TLCE: Transfer-Learning Based Classifier Ensembles for Few-Shot   Class-Incremental Learning](https://arxiv.org/abs/2312.04225)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper addresses the problem of few-shot class-incremental learning (FSCIL). FSCIL involves continuously learning to recognize new classes given only a small number of labeled examples per class, without forgetting previously learned classes or overfitting to the new classes. This is challenging due to catastrophic forgetting of old classes and overfitting on new classes with limited data.

Proposed Solution: 
The paper proposes a transfer learning based classifier ensemble method called TLCE to address FSCIL. The key ideas are:

1) Map images of base classes to quasi-orthogonal prototypes using a robust hyperdimensional network (RHD), minimizing interference between base class prototypes. This retains base class knowledge.

2) Train a separate transferable knowledge network (TKN) on base classes using cosine similarity and cross-entropy loss to obtain features that transfer better to new classes.

3) Ensemble RHD and TKN by computing class prototypes and weighted similarity scores between test images and prototypes to leverage strengths of both networks.

Main Contributions:

1) A new perspective to solve FSCIL using ensembles, combining a network specialized for base classes (RHD) and one for transferability to new classes (TKN).

2) Efficient incorporation of new classes without retraining networks, just computing new prototypes.

3) Outperforms state-of-the-art FSCIL methods on miniImageNet and CIFAR100 datasets. Maintains base class accuracy while improving novel class accuracy.

In summary, the paper presents TLCE, a simple yet effective FSCIL method using transfer learning based classifier ensembles to minimize interference between classes and adapt better to novel classes despite limited data. Experiments demonstrate superior performance over existing approaches.
