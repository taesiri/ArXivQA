# [Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution](https://arxiv.org/abs/2309.16797)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

How can we develop a general-purpose, self-referential system that can automatically improve prompts for large language models (LLMs) in a given domain?

The key hypotheses appear to be:

1) Prompts can be thought of as the "program" that controls the behavior of LLMs. Therefore, evolving better prompts is akin to evolving better programs. 

2) By using the LLM itself to generate variations and improvements to prompts over multiple generations, the system can self-referentially adapt prompts to the problem domain.

3) This approach of prompt evolution and self-referential self-improvement will outperform existing hand-engineered prompting strategies that are not adaptive.

4) Prompt evolution will continue to be effective and scale well as LLMs get larger, since it does not require updating the model parameters.

So in summary, the central research question is how to create an automated system for prompt engineering that leverages the power of LLMs themselves and can self-improve over time. The key hypothesis is that this self-referential approach will enable the system to find better prompts than human-designed strategies.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

1. Introducing Promptbreeder, a self-referential self-improvement method for large language models (LLMs) that evolves prompts for a domain, as well as improves the way it evolves these prompts. 

2. Demonstrating improvements over state-of-the-art prompt engineering methods like Chain-of-Thought and Plan-and-Solve prompting on several common benchmark tasks involving arithmetic, commonsense reasoning, and hate speech classification.

3. Showing that Promptbreeder is able to evolve complex prompt strategies adapted to a task, such as prompts for hate speech classification.

4. Avoiding costly parameter updates by using language itself as the substrate for self-improvement, making the approach scalable.

5. Analyzing the various self-referential components of Promptbreeder and their contribution to the results through ablation studies.

In summary, the main contribution seems to be proposing and evaluating a general-purpose, self-referential framework for automatically evolving better prompts and prompt mutation strategies for LLMs, without requiring parameter updates. The results demonstrate improved performance over prior prompt engineering methods on several benchmarks. The self-referential approach also points towards more open-ended self-improvement of LLMs grounded in language.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper introduces Promptbreeder, a method that evolves prompts and prompt mutation strategies over generations to automatically improve the reasoning and language capabilities of large language models on tasks in a self-referential way, outperforming prior state-of-the-art prompting techniques like Chain-of-Thought on common benchmarks.
