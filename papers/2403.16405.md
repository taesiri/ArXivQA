# [Ensemble Adversarial Defense via Integration of Multiple Dispersed Low   Curvature Models](https://arxiv.org/abs/2403.16405)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Deep learning models are vulnerable to adversarial attacks - small imperceptible perturbations to inputs that cause misclassification. This is a major security concern for deploying deep learning systems.
- Ensembling multiple models is an effective defense, as attacks must deceive multiple models rather than just one. However, attack transferability between models limits robustness gains from ensembling. 

Proposed Solution:
- This paper proposes a new defense method called Ensemble Dispersed Low Curvature Models (EDLCM) that trains an ensemble of models with high diversity to limit attack transferability.

- It identifies curvature of the loss landscape (quantified by the Hessian matrix) as a key factor affecting robustness and transferability. Lower curvature leads to more robust models. 

- Two regularization terms are introduced during training to:
  1) Reduce curvature of loss landscape for each model ($L_r$)
  2) Disperse gradients between models to limit transferability ($L_g$)

- $L_r$ uses a Hessian-vector product approximation to penalize directions of high curvature. 

- $L_g$ calculates cosine similarity of Hessian-vector products to encourage diversity of curvature across the ensemble.

Main Contributions:
- First defense method to enhance ensemble diversity by explicitly optimizing for low model curvature to limit attack transferability.

- Introduction of new transferability metric based on Hessian-vector products to quantify ensemble diversity.

- Extensive experiments showing superior performance against white-box and black-box attacks compared to state-of-the-art on CIFAR and Tiny ImageNet datasets.

- Ablation studies demonstrating the individual effects of the two regularization terms in improving robustness.

In summary, the key novelty is using second-order curvature information to train an ensemble of diverse and robust models to defend against adversarial attacks. Both theoretical analysis and empirical validation are provided.
