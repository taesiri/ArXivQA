# [Collective Certified Robustness against Graph Injection Attacks](https://arxiv.org/abs/2403.01423)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Graph neural networks (GNNs) are vulnerable to graph injection attacks (GIAs) where adversaries inject carefully crafted malicious nodes into the graph to disrupt node classifications. 
- Existing defense methods like adversarial training or GNN architecture modifications may fail against adaptive attacks. Provable defenses offer robustness certificates but prior works only provide sample-wise certificates by verifying nodes independently. This leads to limited defense performance.
- No existing method provides collective certificates against GIAs which certify a set of nodes simultaneously against a realistically constrained attack targeting multiple nodes.

Proposed Solution:
- The paper proposes the first collective robustness certificate against GIAs to significantly improve certification performance. 
- It assumes the attacker aims to modify predictions of as many target nodes as possible under constraints like limited injected nodes and edges per node.
- By modeling the worst-case attack, remaining nodes can be certified robust. But the formulation is an intractable binary quadratic constrained program.
- A customized linear relaxation technique is introduced to transform it into an efficiently solvable Linear Program while ensuring soundness.

Main Contributions:
- First collective certificate for certifiable robustness against GIAs that verifies multiple target nodes simultaneously.
- Significantly increases certified ratio from 0% to over 80% on datasets like Cora and Citeseer against GIAs. 
- Computationally efficient, solving optimization in about 1 minute even for larger attacks.
- Almost model-agnostic, applicable to common message-passing GNN architectures.
- Marks an important step towards making certified defenses against GIAs practical.

In summary, the paper makes an important contribution by proposing the first computationally feasible collective robustness certificate to defend graph neural networks against realistic graph injection attacks targeting multiple nodes.
