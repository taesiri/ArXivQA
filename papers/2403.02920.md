# [TaylorShift: Shifting the Complexity of Self-Attention from Squared to   Linear (and Back) using Taylor-Softmax](https://arxiv.org/abs/2403.02920)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- The quadratic complexity of the attention mechanism in Transformers becomes a major bottleneck when processing long input sequences, limiting their applicability. 
- Current approaches to enable linear scaling sacrifice token-to-token interactions or convey only averaged, global information. This leads to compromised performance.

Proposed Solution - TaylorShift:
- Reformulates the Taylor approximation of the softmax function in the attention mechanism to enable computing full token-to-token interactions in linear time and space complexity.
- Introduces a tensor-product based operator to unroll the squared term when approximating the exponential function.
- Proposes a normalization scheme to counteract unstable growth of intermediate results during computation.

Main Contributions:
- Theoretically analyzes the efficiency crossover points where TaylorShift starts to outperform standard attention, in terms of both computational complexity and memory requirements.
- Empirically validates the crossover points and demonstrates linear scaling behavior.
- Shows competitive performance across diverse tasks and modalities compared to standard Transformers and other linear attention mechanisms.
- Performs ablation studies on key components like the normalization scheme, demonstrating their necessity. 
- Provides insights into leveraging multiple attention heads to further improve efficiency.

In summary, the paper introduces TaylorShift, a reformulation of the Taylor softmax enabling efficient calculation of full token-token interactions in Transformers. Theoretical analysis paired with empirical validation demonstrates linear scaling and competitive performance across tasks.
