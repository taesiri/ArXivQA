# Deep Reinforcement Learning of Volume-guided Progressive View Inpainting   for 3D Point Scene Completion from a Single Depth Image

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we achieve high-quality 3D scene completion from a single depth image, focusing on directly generating the missing 3D point cloud surface?The key ideas and contributions towards addressing this question are:- Representing the incomplete 3D point cloud as multi-view depth maps and performing iterative 2D inpainting on them to fill in missing surfaces.- Using a volumetric 3D scene reconstruction to guide the 2D inpainting by providing global context. - Employing a reinforcement learning strategy to determine the optimal sequence of viewpoints for progressive completion.- Proposing a volume-guided view inpainting network that combines 3D completion and 2D inpainting with a differentiable projection layer between them.- Achieving state-of-the-art performance in reconstructing complete 3D point cloud scenes from single depth images compared to previous volumetric output methods.In summary, the paper tackles the problem of high-quality 3D scene completion from limited single view depth data by using guided multi-view 2D inpainting and optimal view planning with deep reinforcement learning. The key hypothesis is that this approach can generate more accurate and complete 3D point clouds than existing volumetric methods.
