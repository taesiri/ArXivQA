# [UniRetriever: Multi-task Candidates Selection for Various   Context-Adaptive Conversational Retrieval](https://arxiv.org/abs/2402.16261)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Most previous work in conversational retrieval trains independent retrievers for each specific resource like persona, knowledge etc. This results in sub-optimal performance and low efficiency. The key challenges are:

1) Dialogue context can be very long spanning multiple sessions. Locating relevant contextual information is difficult. 

2) Various external candidates (persona, knowledge etc.) need to be retrieved during the conversation to engage users and complete dialogue goals. Training separate retrievers for each candidate type is inefficient.

3) Modeling subtle relationships between dialogue context and different candidates is important but challenging.

Proposed Solution:
The paper proposes a multi-task framework called "Universal Conversational Retrieval (UniversalCR)" that serves as a universal retriever for three key candidate selection tasks: persona selection, knowledge selection and response selection. The main components are:

1) Context-Adaptive Encoder: Dynamically selects relevant utterances from lengthy dialogues to locate pertinent contextual information.

2) Candidate Encoder: Encodes various candidates using unique task-specific tokens allowing the framework to handle multiple selection tasks.

3) Two novel loss functions: a) Historical Contrastive Loss uses previously selected candidates as semi-hard negatives. b) Pairwise Similarity Loss captures subtle relationships between context and candidates.

Main Contributions:

1) A universal conversational retrieval framework that unifies three key candidate selection tasks in one model while balancing effectiveness and efficiency.

2) A context-adaptive encoder and two carefully designed loss functions to address long dialogues and differences between candidates. 

3) Extensive experiments showing state-of-the-art performance both within and outside training domain, revealing excellent generalization capability to serve as a universal retriever.

4) In-depth analysis of context encoding methods, loss functions, zero-shot performance etc providing useful insights.

Overall, the paper presents a robust and promising solution for building omni-potent dialogue retrieval systems that can select diverse candidates needed to complete conversations.
