# [Re-IQA: Unsupervised Learning for Image Quality Assessment in the Wild](https://arxiv.org/abs/2304.00451)

## What is the central research question or hypothesis that this paper addresses?

The central research question of this paper is: How can we train deep neural networks to learn robust low-level quality-aware image representations and high-level content-aware image representations in an unsupervised manner for perceptual image quality assessment, especially for images "in the wild" with complex authentic distortions? The key hypotheses of the paper are:1. Image quality can vary spatially within an image itself based on content. So quality-aware features (PQAF) may vary between neighboring patches but more significantly between distant patches.2. PQAF of two randomly sampled images are different, assuming different semantic content. 3. Different distorted versions of the same image have different PQAF.To address these hypotheses, the authors propose an unsupervised learning framework called Re-IQA with two components:1. A content-aware encoder trained using contrastive learning on unlabeled images to extract high-level semantic features.2. A quality-aware encoder trained using proposed image augmentation, cropping, and swapping techniques on both pristine and authentically distorted images to extract complementary low-level perceptual quality features. The key novelty is the ability to learn quality-aware representations separate from high-level content representations in a completely unsupervised manner for perceptual image quality assessment.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a Mixture of Experts approach to train two separate encoders to learn high-level content and low-level image quality features in an unsupervised setting. The novelty is in learning complementary low-level representations of image quality along with high-level content features.2. It demonstrates the superiority of high-level content representations learned through unsupervised pre-training compared to supervised pre-trained features on ImageNet. The content features are learned using MoCo-v2.3. It proposes a novel image augmentation and intra-pair image swapping scheme to enable learning of low-level image quality representations. The augmentation helps prevent learning discrete distortion classes.4. The learned low and high-level image representations are combined and mapped to quality scores using a simple linear regressor, eliminating expensive fine-tuning.5. Extensive experiments show the approach achieves state-of-the-art performance on multiple large-scale image quality assessment datasets with real and synthetic distortions. This demonstrates the efficacy of the unsupervised learned representations.In summary, the key novelty is in the unsupervised learning of complementary low-level quality and high-level content representations, which when combined provide state-of-the-art image quality assessment performance without requiring fine-tuning on each dataset.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The paper proposes a novel unsupervised learning framework called Re-IQA to generate complementary content and quality-aware image representations for the challenging task of no-reference image quality assessment. The key ideas are training two encoders using contrastive learning, one for high-level content features and another for low-level perceptual quality features, and then combining them with a simple regressor to predict quality scores. The main novelty is the ability to learn low-level quality representations that complement high-level content features in an unsupervised manner.The overall summary would be:The paper introduces Re-IQA, an unsupervised learning framework to generate complementary content and quality-aware image representations for no-reference image quality assessment by training two encoders with contrastive learning, which are then combined with a regressor to predict quality scores.


## How does this paper compare to other research in the same field?

Here are some key points on how this paper compares to other research in image quality assessment:- The paper proposes an unsupervised learning approach to image quality assessment called Re-IQA. This is different from many existing methods that require supervised learning on human-labeled image quality datasets. The unsupervised approach could enable broader applications without needing large labeled datasets.- The paper uses a "mixture of experts" framework with two ResNet encoders to separately learn high-level image content features and low-level quality features. This is a unique aspect compared to other methods that learn a single combined representation. - Re-IQA achieves state-of-the-art performance on multiple image quality assessment benchmarks, including both synthetic and authentic distortion datasets. This demonstrates the method's effectiveness across different types of distortions.- Re-IQA does not require fine-tuning the feature encoders on each test dataset, unlike some methods like MUSIQ. The generalized features transfer well to multiple datasets, showing the robustness of the learned representations.- The method is compared comprehensively to various traditional and deep learning NR and FR-IQA techniques. The results show Re-IQA achieves very competitive accuracy to recent leading methods like PaQ-2-PiQ, HyperIQA, and MUSIQ.- The design of the image augmentation scheme and intra-pair swapping strategy for learning the quality features is novel and guided by principles of human perception. This allows learning representations closely aligned with perceptual quality.- The analysis shows high-level content features dominate for authentic distortions, while quality features dominate for synthetic distortions. This provides useful insights into the differences between the two domains.Overall, the unsupervised learning framework, along with the mixture of content and quality features, allows Re-IQA to advance the state-of-the-art in a challenging problem space. The comparison to other methods clearly demonstrates the competitiveness of the approach.
