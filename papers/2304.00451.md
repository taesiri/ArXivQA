# [Re-IQA: Unsupervised Learning for Image Quality Assessment in the Wild](https://arxiv.org/abs/2304.00451)

## What is the central research question or hypothesis that this paper addresses?

The central research question of this paper is: How can we train deep neural networks to learn robust low-level quality-aware image representations and high-level content-aware image representations in an unsupervised manner for perceptual image quality assessment, especially for images "in the wild" with complex authentic distortions? The key hypotheses of the paper are:1. Image quality can vary spatially within an image itself based on content. So quality-aware features (PQAF) may vary between neighboring patches but more significantly between distant patches.2. PQAF of two randomly sampled images are different, assuming different semantic content. 3. Different distorted versions of the same image have different PQAF.To address these hypotheses, the authors propose an unsupervised learning framework called Re-IQA with two components:1. A content-aware encoder trained using contrastive learning on unlabeled images to extract high-level semantic features.2. A quality-aware encoder trained using proposed image augmentation, cropping, and swapping techniques on both pristine and authentically distorted images to extract complementary low-level perceptual quality features. The key novelty is the ability to learn quality-aware representations separate from high-level content representations in a completely unsupervised manner for perceptual image quality assessment.
