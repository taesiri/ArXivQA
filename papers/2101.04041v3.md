# [Evaluating Disentanglement of Structured Representations](https://arxiv.org/abs/2101.04041v3)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research question addressed in this paper is: 

How can we develop a metric to evaluate disentanglement at individual hierarchy levels of a structured latent representation, especially for object-centric generative models?

The paper proposes a new framework to address limitations with existing disentanglement metrics, which focus only on disentanglement of individual latent dimensions rather than considering the hierarchical structure of the representation. Specifically, the proposed structured disentanglement metric aims to evaluate:

(i) Object-level disentanglement: The degree to which different objects are separated into distinct latent slots in an object-centric generative model.

(ii) Slot disentanglement: How well the properties of each object are disentangled within each latent slot. 

(iii) Slot symmetry: Whether the latent dimensions capturing a particular factor (e.g. color) are consistent across different slots.

The key idea is to measure disentanglement with respect to projections of the affinity matrix between latents and generative factors. This allows isolating specific levels of the hierarchy. The paper shows theoretically and experimentally that this framework addresses limitations of previous metrics for structured representations.

In summary, the main research question is how to design a metric that can effectively evaluate key aspects of disentanglement quality in structured latent representations, especially for object-centric models. The proposed solution is a projection-based framework that generalizes traditional notions of disentanglement.


## What is the main contribution of this paper?

 Based on my understanding, the main contribution of this paper is proposing the first metric to evaluate disentanglement at individual hierarchy levels of a structured latent representation. When applied to object-centric generative models, this metric provides a systematic way to assess:

1) Object-level disentanglement: Measures how well objects and latent slots have a one-to-one matching. 

2) Slot disentanglement: Evaluates how well properties of an object are disentangled inside a slot.

3) Slot symmetry: Checks whether the latent dimension capturing a specific factor (e.g. color) is consistent across different slots.

The key idea is to measure disentanglement and completeness with respect to projections of the affinity matrix between latents and generative factors. By choosing different projections, the metric can focus on particular hierarchy levels of interest. 

Theoretically, the paper shows this framework provides stronger guarantees of model quality compared to previous disentanglement metrics like DCI. Experimentally, it demonstrates issues with commonly used pixel-level segmentation metrics for evaluating object separation.

The other main contribution is an EM algorithm for representation probing that handles slot permutation invariance to get suitable affinity scores as input to the metric framework.

In summary, this work introduces the first principled approach to evaluate disentanglement in structured latent representations like object-centric generative models. The unified metric and theoretical analysis help better understand and validate such models.
