# G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: How can large language models (LLMs) be effectively leveraged as reliable metrics for evaluating natural language generation (NLG) systems, with high correlation to human judgments?The key hypothesis seems to be:Using LLMs in a prompt-based framework with chain-of-thought and a form-filling scoring paradigm (as proposed in G-Eval) can lead to NLG evaluation metrics that correlate much more strongly with human assessments, compared to previous approaches.In particular, the paper aims to show:- LLM-based metrics can generally outperform previous reference-based and reference-free baseline metrics in correlating with human NLG quality judgments, especially for open-ended and creative tasks.- Providing more instructional context/guidance to the LLM evaluator via chain-of-thought improves performance. - LLM-based metrics can give more fine-grained continuous scores by weighting token probabilities.- However, LLM-based metrics may have an inherent bias preferring LLM-generated text, which needs further investigation.In summary, the main research question is how to effectively harness LLMs as automatic NLG evaluation metrics, with a hypothesis that the G-Eval framework can achieve much higher human correlation through its design.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing G-Eval, a new framework for evaluating natural language generation (NLG) systems using large language models (LLMs) with chain-of-thoughts and a form-filling paradigm. - Showing that G-Eval with GPT-4 as the backbone model achieves much higher correlation with human judgments compared to previous state-of-the-art methods on summarization and dialogue tasks.- Demonstrating the importance of instructions, prompts and chain-of-thoughts in improving LLM-based evaluators.- Conducting analysis on the behavior of LLM-based evaluators, highlighting potential issues like bias towards LLM-generated text.- Providing a more reliable and effective framework for leveraging recent advances in LLMs for NLG evaluation, which is a challenging problem.In summary, the main contribution appears to be proposing and evaluating G-Eval, a novel human-aligned metric using GPT-4 for evaluating NLG systems, and providing insights into designing better LLM-based evaluators. The results show G-Eval substantially improves over previous methods.
