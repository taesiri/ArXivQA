# [Distilling Adversarial Robustness Using Heterogeneous Teachers](https://arxiv.org/abs/2402.15586)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Neural networks are vulnerable to adversarial attacks where small perturbations to inputs can cause misclassification. Defending against such attacks is critical for deploying ML safely in domains like self-driving cars and medical imaging. Recent work shows adversarial robustness can be transferred from a teacher to student model using knowledge distillation, but current methods have limitations:

(1) They use a single adversarial and vanilla teacher which can misclassify similar adversarial examples due to high transferability between homogeneous architectures like CNNs. 

(2) They do not leverage complementary robustness that could arise from using heterogeneous teachers with architectures less prone to misclassifying the same adversarial inputs.

Proposed Solution:
This paper proposes a defense framework called DARHT that distills adversarial robustness from multiple heterogeneous teachers to improve student robustness. 

Key ideas:
(1) The student model represents teacher logits explicitly in a "student-teacher feature map".

(2) Teachers are chosen to be heterogeneous in architecture (CNNs and ViTs) and adversarial training method to reduce transferability of adversarial examples between them.

(3) Monte Carlo dropout provides robustness complementary to distillation.

(4) A distillation loss allows weighting teacher contributions automatically based on their crossentropy loss.

Main Contributions:
(1) DARHT is the first distillation defense using multiple heterogeneous teachers.

(2) Experiments show architects diverse teachers increase robustness over homogeneous ones, an effect termed "complementary robustness".

(3) DARHT achieves state-of-the-art performance on CIFAR and Tiny ImageNet datasets, improving weighted robust accuracy over prior arts by 3-26% against white-box and black-box attacks.

(4) More teachers, architectural diversity and differing adversarial training improve robustness and clean accuracy.

In summary, the key idea is that teacher model heterogeneity, especially in architecture, is crucial for effectively transferring adversarial robustness to students via distillation.
