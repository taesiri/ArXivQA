# [High-Resolution Document Shadow Removal via A Large-Scale Real-World   Dataset and A Frequency-Aware Shadow Erasing Net](https://arxiv.org/abs/2308.14221)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research focus is on developing an effective method for removing shadows from high-resolution document images. The key challenges they aim to address are:

1) Existing document shadow removal datasets are small and low-resolution, which limits the performance of deep learning methods that require large amounts of training data. 

2) Most existing deep learning based methods do not work well for high-resolution images as they rely on approximating attention/masks from low-resolution feature maps.

3) Methods developed for natural image shadow removal do not transfer well to document images which require preserving fine details like text and figures.

To overcome these limitations, the central hypothesis of this paper is that a large-scale high-resolution document shadow dataset combined with a carefully designed frequency-aware neural network can achieve improved shadow removal performance on real-world high-resolution documents.

The key contributions to validate this hypothesis are:

- A new large-scale real-world shadow dataset SD7K containing over 7000 high-resolution document image pairs.

- A frequency-aware network called FSENet that separates the image into frequency components and processes low and high frequencies using tailored network designs to preserve details.

- Experiments showing state-of-the-art quantitative and qualitative performance on public benchmarks as well as their new SD7K dataset.

In summary, the core research question is how to achieve effective shadow removal on real-world high-resolution document images, which they address through dataset and model innovations.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

1. They introduce a large-scale real-world dataset called SD7K for document shadow removal. This dataset contains over 7000 high-resolution image pairs of documents with and without shadows. It is much larger and higher resolution than previous datasets for this task.

2. They propose a deep learning model called Frequency-aware Shadow Erasing Net (FSENet) for removing shadows from high-resolution document images. The key aspects of their model are:

- Using a Laplacian pyramid decomposition to separate the image into different frequency components. This allows different parts of the network to focus on overall color/illumination vs high-frequency details.

- A transformer-based module for modeling global illumination changes in the low-frequency components. 

- Cascaded dilated convolutions and aggregation modules for recovering fine details in the high-frequency components.

3. Their method achieves state-of-the-art performance on document shadow removal, outperforming previous methods on standard benchmarks as well as their new SD7K dataset, both visually and quantitatively.

So in summary, the main contributions are introducing a large-scale high-resolution dataset for this task, and proposing a frequency-aware deep network tailored for removing shadows from high-resolution document images. The combination of the dataset and model advances the state-of-the-art in this area.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes a new large-scale high-resolution document image dataset for shadow removal and a frequency-aware deep network that divides the image into multi-frequency components to handle low-frequency color/illumination and high-frequency details separately for effective shadow removal while preserving document content.
