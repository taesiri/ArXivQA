# [Cost Aggregation Is All You Need for Few-Shot Segmentation](https://arxiv.org/abs/2112.11685)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to effectively utilize pixel-wise relationships between support and query images for few-shot segmentation. The key hypothesis is that reformulating few-shot segmentation as a semantic correspondence problem and aggregating high-dimensional correlation maps between support and query features using both convolutions and transformers will lead to improved performance. Specifically, the paper proposes a novel cost aggregation network called VAT (Volumetric Aggregation with Transformers) to tackle few-shot segmentation. The main ideas are:- Reformulating few-shot segmentation as finding semantic correspondence between support and query images under challenging conditions like intra-class variations. - Proposing a volumetric embedding module and volumetric transformer module in the encoder to reduce the computation when aggregating high-dim correlation maps.- Designing the encoder in a pyramidal fashion to let coarse cost aggregation guide finer levels.- Using an affinity-aware decoder with appearance embedding from query features to help resolve ambiguities.The central hypothesis is that this approach of aggregating costs between support and query features using transformers and convolutional inductive bias will improve few-shot segmentation performance. The experiments aim to demonstrate the effectiveness of VAT and the importance of cost aggregation for this task.In summary, the paper introduces a new cost aggregation network VAT to effectively utilize pixel-wise support-query relationships for few-shot segmentation by reformulating it as a semantic correspondence problem and handling high-dimensional correlations with transformers and convolutions.


## What is the main contribution of this paper?

The main contribution of this paper appears to be the proposal of a novel cost aggregation network called Volumetric Aggregation with Transformers (VAT) for few-shot segmentation. Specifically:- The paper proposes to reformulate few-shot segmentation as a semantic correspondence problem and argue that cost aggregation is the key step. This is motivated by recent progress in semantic correspondence methods. - A pyramidal transformer encoder is proposed to aggregate matching costs at multiple resolutions. The encoder contains two novel components:   - Volume Embedding Module (VEM): Reduces the spatial dimensions of the correlation maps while injecting some convolutional inductive bias to aid the subsequent transformer processing.     - Volumetric Transformer Module (VTM): Extends Swin Transformer to aggregate costs in 4D, handling interactions among the high dimensional correlation maps.- An affinity-aware transformer decoder is proposed to refine the aggregated costs using both the cost volume and appearance information from the query image. - The method sets new state-of-the-art results on standard few-shot segmentation benchmarks PASCAL-5i, COCO-20i and FSS-1000.- The method also attains competitive performance on semantic correspondence benchmarks, demonstrating the importance and transferability of the cost aggregation techniques.In summary, the key novelty is the design of a pyramidal transformer architecture for aggregating high-dimensional matching costs in few-shot segmentation, enabled by the volumetric embedding and transformer modules. The effectiveness of this design is demonstrated through state-of-the-art results on both few-shot segmentation and semantic correspondence benchmarks.
