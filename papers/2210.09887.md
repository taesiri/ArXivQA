# [MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving   Camera Videos](https://arxiv.org/abs/2210.09887)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is: How can we efficiently perform convolutional neural network (CNN) inference on videos captured with moving cameras? The key ideas and contributions to address this question seem to be:- Proposing MotionDeltaCNN, a framework to accelerate CNN inference on videos with moving cameras by only processing sparse frame differences. This builds on prior work DeltaCNN that focused on videos with static cameras.- Introducing "spherical buffers" - 2D ring buffers with wrapped coordinates that can align pixels from the current frame with previously processed regions to maximize reuse despite camera motion.- Using "padded convolutions" to allow seamless integration of newly unveiled pixels from camera motion without artifacts or the need to reprocess seen pixels.- Allowing dynamic initialization and bias addition for newly visible image regions unveiled by camera motion.- Showing these techniques can enable much greater acceleration compared to prior work in the case of videos captured with moving cameras, with measured speedups of up to 90% compared to DeltaCNN and over 2x compared to standard dense processing.So in summary, the key hypothesis is that by using spherical buffers, padded convolutions, and other proposed techniques, the authors can efficiently accelerate CNN inference on videos with moving cameras by only processing sparse frame differences. The paper presents innovations in this direction and evaluations demonstrating significant speedups.
