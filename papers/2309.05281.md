# [Class-Incremental Grouping Network for Continual Audio-Visual Learning](https://arxiv.org/abs/2309.05281)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question it aims to address is: How can we learn compact class-aware cross-modal representations to achieve continual audio-visual learning on non-stationary data across sequential tasks?Specifically, the paper proposes a novel class-incremental grouping network (CIGN) to tackle the problem of continual learning for audio-visual classification. The key novelty lies in using learnable audio-visual class tokens and an audio-visual grouping module to continually aggregate class-aware features from both modalities. This allows the model to extract disentangled semantics and prevent catastrophic forgetting of parameters learned from previous tasks. The central hypothesis is that by leveraging class tokens distillation and continual grouping, the model can capture discriminative category-wise features from incremental audio-visual inputs. This would in turn enable superior performance on continual audio-visual learning compared to prior regularization or rehearsal-based methods that operate on a single modality.The experiments conducted on benchmark datasets (VGGSound-Instruments, VGGSound-100 etc.) aim to validate this central hypothesis. The results demonstrate state-of-the-art performance of CIGN for class-incremental audio-visual learning in terms of both accuracy and forgetting metrics.In summary, the key research question is how to achieve effective continual learning on non-stationary audio-visual data, which is addressed through the proposal of CIGN using learnable class tokens and cross-modal grouping. The central hypothesis is that this allows capturing discriminative incremental category-wise features to avoid catastrophic forgetting.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel class-incremental grouping network (CIGN) for continual audio-visual learning. Specifically:- It introduces learnable audio-visual class tokens and audio-visual grouping to continually aggregate class-aware features from incremental tasks. This helps alleviate catastrophic forgetting.- It utilizes class token distillation and continual grouping to prevent forgetting parameters learned from previous tasks and capture discriminative audio-visual categories. - It achieves state-of-the-art results on VGGSound-Instruments, VGGSound-100, and VGG-Sound Sources benchmarks for audio-visual class-incremental learning.In summary, the key novelty is using explicit audio-visual grouping with class tokens to learn compact cross-modal representations incrementally, which differs from prior regularization or rehearsal-based continual learning methods. Both quantitative results and qualitative visualizations demonstrate the effectiveness of CIGN for continual audio-visual learning.
