# [Grounded Question-Answering in Long Egocentric Videos](https://arxiv.org/abs/2312.06505)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of the paper:

This paper tackles the challenging problem of open-ended question answering in long, egocentric videos. The authors propose a novel unified model, named GroundVQA, for simultaneously localizing temporal video segments relevant to questions (query grounding) and generating free-form answers in natural language (question answering). To address the lack of training data, they leverage large language models (LLMs) to automatically transform narrations from the Ego4D dataset into 303K question-answer-grounding triplets, creating a new dataset EgoTimeQA. Their model integrates a temporal grounding module and a text decoder, and is trained end-to-end on question answering and grounding objectives. Extensive experiments demonstrate strong improvements over previous methods and state-of-the-art performance on the QAEgo4D benchmark for open-ended egocentric video question answering. Additionally, to tackle ambiguities in evaluating free-form answers, the authors propose an alternative task of multi-choice question answering and a corresponding filtered test set. The introduced techniques for scalable data augmentation, multi-task unified modeling, and more reliable evaluation collectively mark notable progress in this challenging field.
