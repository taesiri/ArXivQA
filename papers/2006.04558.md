# [FastSpeech 2: Fast and High-Quality End-to-End Text to Speech](https://arxiv.org/abs/2006.04558)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is how to develop a fast, high-quality, and fully end-to-end text-to-speech (TTS) system. Specifically, the authors aim to address limitations of previous non-autoregressive TTS models like FastSpeech, which rely on a complicated teacher-student training pipeline, inaccurate duration prediction, and information loss during knowledge distillation. 

The main hypothesis is that by:

1) Simplifying the training pipeline and using ground-truth targets instead of distilled outputs. 

2) Providing more accurate duration information and additional variance information like pitch and energy as inputs.

3) Modeling pitch variations using continuous wavelet transform.

4) Extending the model to directly generate waveforms instead of mel-spectrograms.

They can develop a faster TTS model (FastSpeech 2) that achieves higher voice quality than FastSpeech and other autoregressive models, while still enjoying the benefits of non-autoregressive models like fast and robust synthesis. They further hypothesize that extending this model (FastSpeech 2s) to directly generate waveforms can simplify the pipeline towards fully end-to-end TTS with minimal performance drop.

In summary, the main research question is how to develop a fast, high-quality, and end-to-end TTS system, with the central hypothesis that modeling additional variance information and simplifying the training process can achieve this goal.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- Proposing FastSpeech 2, which improves upon FastSpeech (a previous non-autoregressive TTS model) to achieve higher voice quality and simpler training. Specifically, FastSpeech 2 removes the teacher-student distillation pipeline in FastSpeech, and instead trains directly on ground-truth spectrograms. It also uses more accurate duration estimation and adds pitch/energy predictors to provide more variation information and ease the one-to-many mapping problem in TTS.

- Developing FastSpeech 2s, an extension of FastSpeech 2 that enables fully end-to-end text-to-waveform synthesis, without intermediate mel-spectrogram generation. FastSpeech 2s simplifies the inference pipeline and achieves faster synthesis speed. 

- Experiments showing that FastSpeech 2 has 3x faster training than FastSpeech, while achieving better voice quality that can surpass autoregressive models. FastSpeech 2s further speeds up inference and maintains high voice quality.

In summary, the main contribution is proposing FastSpeech 2 and 2s models that achieve faster, simpler and higher-quality non-autoregressive end-to-end TTS compared to previous methods. The key ideas are simplifying the training pipeline, providing more variation information as input, and pushing towards fully end-to-end waveform synthesis.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes FastSpeech 2 and FastSpeech 2s, non-autoregressive text-to-speech models that achieve faster training and inference speed than previous methods while generating higher quality and more controllable speech by predicting additional variance information like pitch, energy, and more accurate durations.
