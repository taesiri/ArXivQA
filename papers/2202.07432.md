# [A precortical module for robust CNNs to light variations](https://arxiv.org/abs/2202.07432)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be:How can a simple mathematical model of the low visual pathway in mammals be used to improve the robustness of convolutional neural networks (CNNs) for image classification, specifically with regards to variations in global light intensity and contrast?The key hypotheses seem to be:1) A simplified mathematical model of the visual pathway, focusing on the retina, lateral geniculate nucleus (LGN), and primary visual cortex (V1), can capture the key components relevant for modeling issues like light/contrast adaptation. 2) The structure of CNNs for image classification mirrors the cortical portion of the visual pathway, but does not fully take into account the precortical structures (retina, LGN) responsible for adapting to light/contrast changes.3) Adding a "precortical" module, inspired by the mathematical modeling of retina/LGN, to a CNN architecture will improve robustness to variations in light and contrast not seen during training.The paper aims to develop the simplified mathematical model, demonstrate the parallels to CNN structure, introduce a sample precortical module, and validate through experiments on image datasets that this module improves CNN robustness as hypothesized.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- The authors present a simplified mathematical model of the low visual pathway in mammals, including key components like the retina, lateral geniculate nucleus (LGN), and primary visual cortex (V1). The model aims to retain accuracy while elucidating similarities between physiological structures and convolutional neural networks (CNNs).- Using this model, the authors propose adding a "precortical" module inspired by retinal and LGN cells to a standard CNN architecture. This module is intended to mimic visual effects like border/contrast enhancement and mean light decorrelation. - The authors test their modified CNN, called RetiLeNet, on the MNIST, FashionMNIST, and SVHN datasets. They show it has improved robustness to variations in global light intensity and contrast compared to the standard LeNet architecture.- They argue these results validate the importance of modeling precortical structures to improve CNN performance on out-of-sample data. The precortical module acts similarly to biological lateral inhibition in stabilizing responses.In summary, the key contribution appears to be using their visual pathway model to motivate a new precortical module for CNNs that demonstrably improves robustness, confirming the importance of incorporating biological precortical processing. The simplified modeling enables clear connections to the improved neural network design.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes adding a precortical module inspired by the mammalian visual system to convolutional neural networks to improve robustness to variations in lighting and contrast that are not represented in the training data.


## How does this paper compare to other research in the same field?

Here are my thoughts on how this paper compares to other research in the field:- The paper presents a simple mathematical model of the mammalian visual pathway, focusing on the retina, lateral geniculate nucleus (LGN), and primary visual cortex (V1). This type of modeling and analysis of the visual system is common in the literature, but the authors emphasize the simplicity of their model compared to some other more complex approaches. - The key novelty seems to be using this model to inspire the design of a "precortical" module for convolutional neural networks (CNNs) to improve robustness to lighting variations. Connecting biological vision models to CNN architectures is an active area of research, but the specific idea of adding this pre-cortical module appears novel.- The experiments validating the improved robustness of CNNs with the precortical module on MNIST, FashionMNIST, and SVHN are straightforward but provide solid evidence for the viability of their approach. Using common benchmark datasets and architectures is a plus.- Overall, the main contributions appear to be the simplified modeling, the proposed precortical module, and experimental validation of its benefits. The biological inspiration driving neural network architecture innovations seems to be the key distinctive aspect compared to other engineering-focused approaches to robustness.- Some limitations are that they only examine a few datasets and one base architecture. More extensive experiments on diverse tasks and architectures could strengthen the results. The biological fidelity of the model could also be critiqued from a neuroscience perspective.- But within the computer vision and neural network literature, this seems to present a novel bio-inspired architecture modification and promising experimental results. The overall approach of bringing in biological insights is well aligned with other studies in this research area.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Further exploring the similarities and connections between deep CNNs and the mammalian visual system. The authors suggest continuing to analyze the parallels between the structure and function of CNNs and the neuroanatomy and physiology of the visual pathway. This could lead to new insights that inform both AI and neuroscience fields.- Applying their proposed precortical module to other types of networks and tasks beyond image classification. The authors propose testing whether adding a module inspired by early visual processing also improves robustness in areas like image reconstruction/completion. - Investigating if their approach leads to networks that generalize better beyond the types of variations explored in the paper. They suggest examining if mimicking aspects of biological vision confers broader inferential abilities on artificial systems.- Mathematically modeling higher levels of visual processing beyond the early components focused on here. The authors propose extending their modeling approach to areas like the extrastriate visual cortex to better capture later stages of visual perception.- Further analyzing the effect of different hyperparameters in the precortical module, like kernel size. The authors note the stabilizing effect correlated with performance and suggest more exploration of how these parameters impact robustness.- Validating the approach on more and larger datasets. The authors tested on MNIST, FashionMNIST and SVHN, so scaling up to more complex and varied datasets could better demonstrate the utility.In summary, the main directions pointed to are: exploring in more depth the parallels with biology, applying the insights to new domains/tasks, mathematically modeling higher-level visual processes, and empirically validating the ideas on larger scales. The overarching theme is leveraging knowledge from neuroscience to engineer more robust and human-like visual artificial intelligence.
