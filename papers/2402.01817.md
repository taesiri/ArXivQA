# [LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks](https://arxiv.org/abs/2402.01817)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is confusion about the capabilities of Large Language Models (LLMs) when it comes to planning and reasoning tasks. Some claim LLMs can do these tasks well just with the right prompting. Others say LLMs are only useful as translators to convert problems into formats for classical solvers. 

- In reality, the auto-regressive nature of LLMs means they cannot truly plan or reason by themselves. However, completely delegating them to a translator role underutilizes their strengths.

Proposed Solution - LLM-Modulo Framework:
- Propose combining LLMs and external verifiers in a generate-test-critique loop. LLMs guess plan candidates; critics evaluate and provide feedback. 

- LLMs play multiple roles: generating plans, translating between plan representations, helping specify problems, acquiring domain models. The framework leverages their strengths without ascribing reasoning abilities.

- The verification modules ensure soundness so valid plans can have correctness guarantees. Framework puts no a priori constraints on problem expressiveness.

Contributions:  
- Reviews literature establishing LLMs cannot robustly plan or self-verify, clarifying misunderstandings.

- Proposes the LLM-Modulo framework for utilizing LLMs in planning in a sound way. Discusses multiple roles for LLMs.

- Explains how this differs from classical planners in expressiveness and how it relates to real-world mission planning regimes that depend on collectivevetting.

In summary, the paper argues LLMs have useful approximate knowledge roles in planning but cannot plan themselves. The LLM-Modulo framework shows how to combine strengths of LLMs and model-based verifiers.
