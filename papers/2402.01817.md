# [LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks](https://arxiv.org/abs/2402.01817)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is confusion about the capabilities of Large Language Models (LLMs) when it comes to planning and reasoning tasks. Some claim LLMs can do these tasks well just with the right prompting. Others say LLMs are only useful as translators to convert problems into formats for classical solvers. 

- In reality, the auto-regressive nature of LLMs means they cannot truly plan or reason by themselves. However, completely delegating them to a translator role underutilizes their strengths.

Proposed Solution - LLM-Modulo Framework:
- Propose combining LLMs and external verifiers in a generate-test-critique loop. LLMs guess plan candidates; critics evaluate and provide feedback. 

- LLMs play multiple roles: generating plans, translating between plan representations, helping specify problems, acquiring domain models. The framework leverages their strengths without ascribing reasoning abilities.

- The verification modules ensure soundness so valid plans can have correctness guarantees. Framework puts no a priori constraints on problem expressiveness.

Contributions:  
- Reviews literature establishing LLMs cannot robustly plan or self-verify, clarifying misunderstandings.

- Proposes the LLM-Modulo framework for utilizing LLMs in planning in a sound way. Discusses multiple roles for LLMs.

- Explains how this differs from classical planners in expressiveness and how it relates to real-world mission planning regimes that depend on collectivevetting.

In summary, the paper argues LLMs have useful approximate knowledge roles in planning but cannot plan themselves. The LLM-Modulo framework shows how to combine strengths of LLMs and model-based verifiers.


## Summarize the paper in one sentence.

 This paper argues that large language models cannot plan or reason by themselves, but can play constructive roles in planning tasks when combined with external sound model-based verifiers in an LLM-Modulo framework.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing the LLM-Modulo framework, which combines the strengths of large language models (LLMs) as idea generators with external sound critics/verifiers to robustly solve planning and reasoning tasks. 

Specifically, the key ideas this paper puts forth are:

1) LLMs cannot do planning or self-verification on their own, despite some claims to the contrary. The paper reviews literature that establishes the limitations of LLMs in autonomous planning and self-critiquing. 

2) However, LLMs can play constructive roles in planning tasks by serving as sources of approximate knowledge and candidate plan generators. 

3) The proposed LLM-Modulo framework allows LLMs and external critics to interact, with the LLMs guessing candidate plans/ideas and critics verifying them. This combines the idea generation strengths of LLMs with the soundness guarantees of symbolic verifiers.

4) The framework allows LLMs to play multiple roles including helping refine specifications, acquire domain models, reformulate plans, etc. while keeping humans out of the inner loop.

5) The solutions generated this way can further improve LLMs via fine-tuning on the resulting synthetic data.

In summary, the main contribution is conceptualizing and describing a productive framework for integrating LLMs with formal methods to solve planning problems robustly, without wrongly ascribing reasoning abilities to LLMs themselves.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts discussed are:

- Large language models (LLMs): The paper focuses on analyzing the capabilities and limitations of large language models like GPT-3/4 for planning and reasoning tasks.

- Planning: The paper examines whether LLMs can generate valid executable plans by themselves or if they need to be combined with other components.

- Reasoning: Similarly, the paper analyzes if LLMs can logically verify plans/solutions or if they need external critics/verifiers. 

- LLM-Modulo framework: The proposed architecture that combines LLMs with external critics and verifiers in a generate-test-critique loop for robust planning.

- Critics: The external components like model-based verifiers or human experts that evaluate and critique LLM-generated plan candidates.  

- Self-verification: Claims in some papers that LLMs can self-critique and iteratively improve their own solutions.

- Synthetic data: Additional training data that can be generated by the LLM-Modulo framework and used to fine-tune the LLM.

In summary, the key themes are analyzing LLM abilities for planning tasks, proposing a framework to combine their strengths with symbolic verifiers, the roles of critics, and leveraging synthetic data.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the LLM-Modulo framework proposed in this paper:

1. The paper argues that LLMs cannot plan/reason themselves but can play constructive roles when combined with external critics. What are some of the key reasoning tasks that you think LLMs may still not be able to contribute meaningfully to, even in the LLM-Modulo framework?

2. The LLM-Modulo framework seems well suited for iterative refinement of plans/solutions. However, how can we ensure that the prompting does not get stuck in local optima? Are there ways to explicitly model the diversity and coverage of the LLM's guesses? 

3. The framework assumes access to reliable external critics. For many complex real-world problems though, coming up with sound critics can itself be challenging. How can the framework be extended for settings where only approximate or imperfect critics are available?  

4. The paper emphasizes the importance of not involving humans in the inner loop of planning. However, are there scenarios where judicious human involvement can positively guide and shape the search process? How can those be accommodated?

5. What kinds of formal guarantees, if any, can we provide on the plans produced by the LLM-Modulo framework? For instance, can we guarantee optimality or bounds on sub-optimality under certain assumptions?

6. How sensitive is the framework to the choice of initial prompts and backprompts provided to the LLM? Could adversarial or misleading prompts result in degradation of solutions or divergence of the search process?

7. The framework uses fine-tuning to improve the LLM's future guesses. What are some ways this fine-tuning can be made more robust and reliable instead of amplifying biases?

8. How can the meta-controller balance and reconcile potentially conflicting feedback from a diverse set of soft critics evaluating stylistic, preferential, and ethical factors?

9. What are some ways the LLM's role can be expanded beyond plan generation - for instance, can it participate more actively in the model acquisition and specification refinement processes?

10. The paper focuses on PDDL planning for concreteness but argues the ideas apply more broadly. What is an interesting reasoning/planning domain outside of PDDL that you think LLM-Modulo would significantly improve? Why?
