# [What does CLIP know about a red circle? Visual prompt engineering for   VLMs](https://arxiv.org/abs/2304.06712)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question of this paper is:Can visual prompt engineering, by manipulating images rather than just text, elicit useful emergent behaviors from large vision-language models (VLMs) like CLIP?The key hypotheses explored are:1) Marking images by drawing shapes like circles or boxes around objects can direct a VLM's attention, similar to textual prompts. This allows solving visual tasks like referring expression comprehension in a zero-shot manner.2) Marking is more effective than cropping images, as it retains contextual information.3) VLMs can learn from rare/sparse signals like annotations with red circles in their training data. This enables the emergent capability of understanding markings.4) Visual prompt engineering can also reveal undesirable social biases learned from the training data distribution.So in summary, the central research question is whether useful behaviors can be extracted from VLMs by engineering the visual instead of just textual prompts. The hypotheses focus on using marking/annotation as a way to do this, its advantages, the role of pretraining, and potential downsides regarding biases.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes visual prompt engineering, where VLMs like CLIP are prompted by editing the image instead of just the text. In particular, it shows that simply drawing a red circle around an object steers CLIP's attention to that region while retaining global context.2. It demonstrates the power of this simple visual prompting approach by achieving state-of-the-art results in zero-shot referring expressions comprehension on multiple benchmarks. The method also shows strong performance on keypoint localization. 3. It provides an analysis of why visual prompting with a red circle is so effective for CLIP, linking it to the training data and model capacity needed to learn this emergent behavior.4. It reveals potentially concerning biases that can be elicited in VLMs using visual prompting, such as increasing the probability that CLIP associates a person with being a criminal when circling them in red.In summary, the key innovation is prompting VLMs like CLIP by editing the visual input instead of just the text. This is shown to be a powerful technique for zero-shot tasks, while also revealing interesting properties and potential issues with large VLMs.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper: The paper explores visual prompt engineering, such as drawing red circles on images, to direct large vision-language models like CLIP to focus on certain image regions and demonstrates this enables new capabilities like state-of-the-art zero-shot referring expression comprehension while also revealing potential ethical issues.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other research in vision-language models and prompt engineering:- It focuses on visual prompt engineering, which is less explored than text prompt engineering. Most prior work has focused only on manipulating the text prompt. This paper shows the benefits of manipulating the visual input as well, such as drawing annotations on the image.- It demonstrates strong zero-shot performance on vision tasks like referring expression comprehension by using visual prompt engineering. This shows these techniques can elicit useful emergent behaviors from models like CLIP. Prior work has mainly shown emergent behaviors in large language models.- The analysis explores why visual prompt engineering works, linking it back to the training data distribution and model capacity needed. This provides insight into what allows the model to learn behaviors from sparse signals.- The paper surfaces ethical issues around large VLMs learning from rare events, including problematic biases. Most prior analysis of VLMs has focused on image classification biases. This demonstrates other types of biases that can arise.Overall, this paper uniquely studies visual prompt engineering as a way to elicit behaviors from VLMs. It shows strong technique advancements compared to past text prompt engineering works, while also providing analysis into why these techniques are effective and potential downsides around biases. The visual prompting and in-depth analysis distinguish it from related works.
