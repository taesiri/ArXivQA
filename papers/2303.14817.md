# [Frame Flexible Network](https://arxiv.org/abs/2303.14817)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we train a video recognition model that is flexible and efficient in terms of the number of input frames, so that it can adjust its computation and memory costs during inference?The key hypotheses/claims are:- Existing video recognition models exhibit a "Temporal Frequency Deviation" phenomenon, where their performance significantly drops when evaluated with a different number of frames than what they were trained on.- This phenomenon can be addressed by proposing a "Frame Flexible Network" (FFN) framework that trains the model using multiple input sequences with different frame rates. - FFN enables the model to achieve strong performance when evaluated with varying numbers of input frames, while only requiring training once rather than separate training for each frame rate.- FFN reduces memory costs compared to separately trained models for each frame rate.- The core designs of FFN - Multi-Frequency Alignment and Multi-Frequency Adaptation - allow it to learn temporal frequency invariant representations and strengthen sub-network representations.In summary, the central hypothesis is that the proposed FFN can train a single efficient and flexible video recognition model, in contrast to standard practices that require separate training for each frame rate. FFN aims to resolve the performance degradation issue when evaluating at mismatched frame rates.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a general framework called Frame Flexible Network (FFN) to address the Temporal Frequency Deviation phenomenon in video recognition. Specifically:- The paper reveals the phenomenon of Temporal Frequency Deviation - when a video recognition model is trained at a high frame rate but tested at a lower frame rate, there is a significant drop in accuracy. This issue is analyzed and found to be caused by a shift in normalization statistics when using different frame rates.- To address this, the paper proposes the FFN framework which involves only one-time training but can be evaluated at multiple frame rates. FFN imports sequences at different frame rates during training. - Two components are proposed: 1) Multi-Frequency Alignment (MFAL) which enforces learning of temporal frequency invariant representations via weight sharing and temporal distillation. 2) Multi-Frequency Adaptation (MFAD) which fits the frequency invariant features to different sub-networks to strengthen representations.- Experiments on various architectures (2D, 3D, Transformer networks) and datasets demonstrate FFN's effectiveness. It outperforms separate training at each frame rate, while requiring significantly fewer parameters.In summary, the key contribution is proposing the general FFN framework to resolve Temporal Frequency Deviation in video recognition models by enabling single-model evaluation at multiple frame rates. This is achieved through novel training strategies for learning invariant representations across frame rates.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a Frame Flexible Network (FFN) framework that enables video recognition models to be evaluated using different numbers of input frames at inference time to adjust computational cost, while only requiring training one unified model rather than separate models for each frame setting. FFN learns temporal frequency invariant representations via weight sharing and distillation and adapts subnetworks to different frame rates using private normalization and dynamic convolution weights. Experiments on various architectures and datasets show FFN outperforms separate training at multiple frame rates with significantly lower memory cost.
