# [Anchor3DLane: Learning to Regress 3D Anchors for Monocular 3D Lane   Detection](https://arxiv.org/abs/2301.02371)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we accurately detect 3D lanes from monocular camera images in an end-to-end manner without relying on bird's eye view transformation?The key points are:- The paper aims to tackle the challenging task of monocular 3D lane detection, where lack of depth information makes it difficult to estimate lanes in 3D space from 2D images. - Existing methods typically transform images or features to bird's eye view (BEV) via inverse perspective mapping (IPM) to simplify the problem. However, IPM relies on flat ground assumption and loses useful context information above the road surface.- The paper proposes a new framework called Anchor3DLane that regresses 3D lanes directly from front-view (FV) images/features, without introducing BEV representation.- The key idea is to define 3D lane anchors in 3D space and project them into FV features to extract anchor features for prediction. This retains richer context and helps estimate 3D lanes accurately.- Experiments show Anchor3DLane outperforms previous BEV-based methods on multiple benchmarks, demonstrating its effectiveness for monocular 3D lane detection in an end-to-end manner without BEV transformation.In summary, the main research question is how to perform accurate monocular 3D lane detection without relying on BEV, and the paper proposes the Anchor3DLane framework as a solution.
