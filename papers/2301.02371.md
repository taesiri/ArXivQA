# [Anchor3DLane: Learning to Regress 3D Anchors for Monocular 3D Lane   Detection](https://arxiv.org/abs/2301.02371)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we accurately detect 3D lanes from monocular camera images in an end-to-end manner without relying on bird's eye view transformation?The key points are:- The paper aims to tackle the challenging task of monocular 3D lane detection, where lack of depth information makes it difficult to estimate lanes in 3D space from 2D images. - Existing methods typically transform images or features to bird's eye view (BEV) via inverse perspective mapping (IPM) to simplify the problem. However, IPM relies on flat ground assumption and loses useful context information above the road surface.- The paper proposes a new framework called Anchor3DLane that regresses 3D lanes directly from front-view (FV) images/features, without introducing BEV representation.- The key idea is to define 3D lane anchors in 3D space and project them into FV features to extract anchor features for prediction. This retains richer context and helps estimate 3D lanes accurately.- Experiments show Anchor3DLane outperforms previous BEV-based methods on multiple benchmarks, demonstrating its effectiveness for monocular 3D lane detection in an end-to-end manner without BEV transformation.In summary, the main research question is how to perform accurate monocular 3D lane detection without relying on BEV, and the paper proposes the Anchor3DLane framework as a solution.


## What is the main contribution of this paper?

The main contributions of this CVPR 2023 paper are:- It proposes a new framework called Anchor3DLane for monocular 3D lane detection. This framework directly defines anchors in 3D space and regresses 3D lanes from front-view (FV) features without needing to transform into bird's-eye-view (BEV). - It projects the 3D anchors into FV space to sample features, retaining both good structural and context information for accurate prediction. This avoids the information loss of inverse perspective mapping used in prior BEV-based methods.- It extends the framework to leverage temporal information from adjacent frames by projecting 3D anchors using camera poses. This further improves performance over single-frame prediction.- It develops a global optimization method using the equal-width property between lane lines to refine predictions, reducing lateral error especially for distant parts.- Without bells and whistles, Anchor3DLane outperforms previous state-of-the-art methods on three benchmark datasets for monocular 3D lane detection.In summary, the key innovation is defining 3D anchors to bridge the gap between FV and 3D space directly, avoiding the need for BEV transformation. This results in a simple yet effective framework for monocular 3D lane detection. The code is available on GitHub.
