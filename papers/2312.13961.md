# [ChatGPT as a commenter to the news: can LLMs generate human-like   opinions?](https://arxiv.org/abs/2312.13961)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
The paper investigates whether the large language model GPT-3.5 can generate human-like comments on Dutch news articles, and how to best prompt GPT-3.5 to generate such comments. Specifically, the authors examine whether GPT-3.5 comments are distinguishable from human comments.  

Methodology:
- The authors collect 10 Dutch news articles and corresponding human comments from an online news platform. 
- They generate comments using GPT-3.5 with different prompting techniques: zero-shot, few-shot (providing examples), and context (providing article introduction). They also create two personas that GPT-3.5 adopts.  
- They fine-tune a BERT classifier on human vs GPT-3.5 comments to evaluate human-likeness based on classification difficulty. Lower classifier performance implies more human-like GPT comments.
- Additional analyses include lexical diversity metrics and model explanations.

Key Findings:
- Fine-tuned BERT models achieve over 90% F1, easily distinguishing between human and GPT-3.5 comments. No prompting technique results in significantly more human-like comments. 
- Human comments exhibit higher lexical diversity than GPT-3.5 comments.
- Qualitative analysis shows GPT-3.5 tends to generate more formal, factual comments compared to opinionated human comments.  

Main Conclusions:
- GPT-3.5 has limited capability in generating human-like opinions on Dutch news, regardless of prompting technique. The complexity of human opinions remains challenging for GPT-3.5 to capture.
- Humans display higher lexical diversity in comments than GPT-3.5.
- Future work could explore GPT-4 for longer comment generation, provide more examples to GPT, or analyze pre-training time periods.
