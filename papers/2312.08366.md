# [See, Say, and Segment: Teaching LMMs to Overcome False Premises](https://arxiv.org/abs/2312.08366)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper introduces a new false premise correction task and dataset for referring segmentation. The authors point out that existing methods fail to handle queries about objects that are not actually present in the image, and instead hallucinate incorrect segmentations. To address this, they propose training language models to "see" if an object exists, "say" something to the user if not, and "segment" the object if present. They introduce a new dataset called FP-RefCOCO that augments RefCOCO images with false premise queries generated by an LLM to be more contextually relevant. The authors then propose both a cascaded model approach and an integrated model called SESAME that is trained on this false premise dataset to acquire all three capabilities. Experiments demonstrate SESAME substantially outperforms baselines in detecting false premises, providing helpful natural language feedback, and segmenting objects when they exist. The method brings language models closer to more natural and robust human-like visual dialog abilities.
