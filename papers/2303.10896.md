# [Graphics Capsule: Learning Hierarchical 3D Face Representations from 2D   Images](https://arxiv.org/abs/2303.10896)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper aims to address is how to enable neural networks to learn hierarchical 3D representations of objects like humans do, using only unlabeled images. 

Specifically, the paper focuses on learning hierarchical 3D representations of human faces from large-scale unlabeled image datasets. The key hypothesis is that incorporating 3D computer graphics representations like depth, albedo, and pose into "graphics capsules" will allow neural networks to decompose faces into semantic part-based representations and construct face hierarchies in an unsupervised manner, similar to human perception.

The graphics capsules are designed to provide interpretable 3D descriptions of facial parts and mimic how humans can understand faces as composed of 3D parts even when viewing 2D images. The paper proposes an Inverse Graphics Capsule Network (IGC-Net) that uses these graphics capsules to learn part-based 3D face representations and construct face hierarchies in a bottom-up manner without any annotation.

In summary, the central hypothesis is that using graphics capsules containing 3D graphics parameters will enable unsupervised learning of hierarchical and interpretable 3D face representations from 2D images, providing insights into human-like hierarchical face perception. The experiments aim to validate whether the proposed IGC-Net can actually achieve this goal.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- Proposing an Inverse Graphics Capsule Network (IGC-Net) to learn hierarchical 3D face representations from unlabeled images. The graphics capsules in IGC-Net provide insight into how neural networks understand faces as a hierarchy of 3D models.

- Introducing a Graphics Decomposition Module (GDM) to decompose objects into semantically consistent parts represented by graphics capsules with interpretable 3D parameters. 

- Evaluating the learned 3D part representations on unsupervised face segmentation and using them for interpretable face analysis to uncover which parts and shape/albedo components are most important.

- Demonstrating the effectiveness of IGC-Net on CelebA, BP4D and Multi-PIE datasets, where it builds hierarchical 3D representations of faces under varied poses and illuminations without supervision.

In summary, the main contribution is proposing a novel Inverse Graphics Capsule Network that can learn hierarchical 3D representations of faces in an unsupervised manner, providing interpretability and new capabilities compared to prior 2D representation learning approaches. The graphics capsules give insight into how neural networks perceive and represent faces.
