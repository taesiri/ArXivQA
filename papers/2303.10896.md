# [Graphics Capsule: Learning Hierarchical 3D Face Representations from 2D   Images](https://arxiv.org/abs/2303.10896)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper aims to address is how to enable neural networks to learn hierarchical 3D representations of objects like humans do, using only unlabeled images. 

Specifically, the paper focuses on learning hierarchical 3D representations of human faces from large-scale unlabeled image datasets. The key hypothesis is that incorporating 3D computer graphics representations like depth, albedo, and pose into "graphics capsules" will allow neural networks to decompose faces into semantic part-based representations and construct face hierarchies in an unsupervised manner, similar to human perception.

The graphics capsules are designed to provide interpretable 3D descriptions of facial parts and mimic how humans can understand faces as composed of 3D parts even when viewing 2D images. The paper proposes an Inverse Graphics Capsule Network (IGC-Net) that uses these graphics capsules to learn part-based 3D face representations and construct face hierarchies in a bottom-up manner without any annotation.

In summary, the central hypothesis is that using graphics capsules containing 3D graphics parameters will enable unsupervised learning of hierarchical and interpretable 3D face representations from 2D images, providing insights into human-like hierarchical face perception. The experiments aim to validate whether the proposed IGC-Net can actually achieve this goal.
