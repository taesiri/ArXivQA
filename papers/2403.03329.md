# [Guardrail Baselines for Unlearning in LLMs](https://arxiv.org/abs/2403.03329)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Recent work has shown promise for using fine-tuning to "unlearn" concepts from large language models (LLMs). However, fine-tuning can be expensive as it requires generating examples and running iterative training. 

- This paper investigates whether simple "guardrail" methods like prompting and filtering can achieve comparable unlearning performance to fine-tuning on benchmark tasks.

Methods
- The authors evaluate prompting (pre-processing the input) and filtering (post-processing the output) on two unlearning benchmark tasks:
  - "Who's Harry Potter": Unlearning information about the Harry Potter book series
  - TOFU: Unlearning information about fictional authors from a synthetic dataset

- For "Who's Harry Potter", a simple prompt is added instructing the model to unlearn information about Harry Potter. Performance is evaluated on 300 Potter-related questions.

- For TOFU, a filter model (GPT-4 or LLaMA) is applied to the outputs to detect if forgotten author information is present. The output is refused if the filter detects forgotten information.
              
Results
- On "Who's Harry Potter", prompting cuts familiarity scores approximately in half across models. GPT-4 with prompting outperforms all fine-tuned models.

- On TOFU, the filtering approach achieves 95-97% forget accuracy and 99-100% retain accuracy using GPT-4 as the filter. Performance decreases for larger forget sets with LLaMA as the filter.

Conclusions
- Prompting and filtering can be competitive baselines to fine-tuning for unlearning. The simplicity of these methods makes them good initial approaches.

- Metrics are needed that can separate prompting/filtering from fine-tuning. Currently most metrics only examine outputs.

- Prompting could be used to generate examples for fine-tuning and enable "temporary" unlearning until models can be updated. Filtering may better avoid hallucinated outputs.
