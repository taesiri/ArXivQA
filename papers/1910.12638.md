# [Mockingjay: Unsupervised Speech Representation Learning with Deep   Bidirectional Transformer Encoders](https://arxiv.org/abs/1910.12638)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to learn powerful speech representations in an unsupervised way that can benefit downstream speech tasks. The key points are:- The paper proposes a new approach called Mockingjay to learn speech representations through unsupervised pre-training, without needing any labeled data. - Mockingjay uses bidirectional Transformer encoders to learn representations by predicting masked frames using context from both past and future frames. This allows considering both past and future context, unlike previous unidirectional models.- The proposed "Masked Acoustic Modeling" pre-training task randomly masks some input frames and predicts the original frames based on past/future context.- The learned Mockingjay representations significantly improve performance on downstream tasks like phoneme classification, speaker recognition, and sentiment analysis compared to other unsupervised speech representations.- Mockingjay representations can be easily fine-tuned on downstream tasks to further improve performance dramatically compared to other methods that are limited to just representation extraction.- Mockingjay requires less data and computational resources compared to methods like vq-wav2vec that force speech into a discrete token-like representation.- Experiments show Mockingjay works much better than log Mel-features and other representations in low-resource settings with limited labeled data.In summary, the key hypothesis is that bidirectional pre-training on speech with the proposed techniques can learn powerful and robust representations to benefit various downstream speech tasks, especially in low-resource scenarios. The results validate this hypothesis.


## What is the main contribution of this paper?

The main contribution of this paper is proposing Mockingjay, a novel speech representation learning approach based on bidirectional transformer encoders. The key points are:- Mockingjay is trained in an unsupervised manner using the proposed Masked Acoustic Modeling (MAM) pre-training task, where the model learns to reconstruct randomly masked speech frames using bidirectional context. - The bidirectional architecture allows Mockingjay to jointly condition on both past and future context, unlike previous unidirectional approaches. This enables learning more powerful representations.- Mockingjay outperforms other representations like APC and raw Mel spectrograms on various downstream tasks like phoneme classification, speaker recognition, and sentiment analysis.- Mockingjay can be easily fine-tuned on downstream tasks, achieving further improvements with just 2 epochs of fine-tuning. This shows the representations are robust.- In low-resource settings with only 0.1% labeled data, Mockingjay still exceeds the performance of Mel-features trained on 100% labeled data. This demonstrates the value of pre-training.- Overall, Mockingjay provides an effective and robust speech representation that transfers well across tasks and datasets. The bidirectional architecture is the key innovation enabling stronger representation learning.In summary, the main contribution is proposing Mockingjay, a novel bidirectional speech representation learning approach, and showing its effectiveness on various tasks over other methods. The unsupervised pre-training is crucial for learning powerful representations that transfer well.
