# [Mockingjay: Unsupervised Speech Representation Learning with Deep   Bidirectional Transformer Encoders](https://arxiv.org/abs/1910.12638)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to learn powerful speech representations in an unsupervised way that can benefit downstream speech tasks. The key points are:- The paper proposes a new approach called Mockingjay to learn speech representations through unsupervised pre-training, without needing any labeled data. - Mockingjay uses bidirectional Transformer encoders to learn representations by predicting masked frames using context from both past and future frames. This allows considering both past and future context, unlike previous unidirectional models.- The proposed "Masked Acoustic Modeling" pre-training task randomly masks some input frames and predicts the original frames based on past/future context.- The learned Mockingjay representations significantly improve performance on downstream tasks like phoneme classification, speaker recognition, and sentiment analysis compared to other unsupervised speech representations.- Mockingjay representations can be easily fine-tuned on downstream tasks to further improve performance dramatically compared to other methods that are limited to just representation extraction.- Mockingjay requires less data and computational resources compared to methods like vq-wav2vec that force speech into a discrete token-like representation.- Experiments show Mockingjay works much better than log Mel-features and other representations in low-resource settings with limited labeled data.In summary, the key hypothesis is that bidirectional pre-training on speech with the proposed techniques can learn powerful and robust representations to benefit various downstream speech tasks, especially in low-resource scenarios. The results validate this hypothesis.
