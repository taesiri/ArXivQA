# [SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent   Reinforcement Learning Systems](https://arxiv.org/abs/2402.03741)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Recent advances in multi-agent reinforcement learning (MARL) have opened up many application prospects like drone swarms and robotic manipulation. However, the potential security threats during MARL deployment need more attention. Prior works focus on two-player competitions with complete state observations and cannot handle scenarios where the attacker only has partial observations in multi-agent environments. This poses challenges for generating effective adversarial policies.

Proposed Solution: 
This paper proposes SUB-PLAY, a novel framework to generate adversarial policies against partially observed victims in multi-agent competitive environments. The key ideas are:

1) Decompose the attack into multiple subgames based on number of observable victim agents. Model each subgame as a partially observable stochastic game (POSG) and obtain subpolicies.

2) Share transitions among different subgame replay buffers to mitigate imbalance due to varying subgame frequencies. Probability of sharing depends on occupancy rate, distance between subgames, number of subgames constructed etc.  

3) Evaluate subpolicies on multiple metrics and only retain top performers for each subgame in policy pool to reduce fluctuations.

4) Hardcode combination of subpolicies into final adversarial policy. Determine subgame at runtime based on observation and select corresponding subpolicy.


Main Contributions:

1) First framework to unveil capability of attackers to exploit vulnerabilities of victims' policies in multi-agent competitive environments, even with only partial observations.

2) Propose observable-driven subgame construction and transition sharing to address challenges posed by three common types of partial observability limitations.

3) Extensive experiments in two OpenAI environments demonstrating SUB-PLAY's effectiveness and outperformance over state-of-the-art attack framework Victim-play.

4) Analyze three potential defenses, emphasizing the need for MARL practitioners to consider deployment strategies rather than just enhancing algorithms. Insights provided on mitigating threats of adversarial policies.

In summary, this paper highlights an important security dimension in MARL and provides valuable insights into generating and defending against adversarial policies in partial observability settings.
