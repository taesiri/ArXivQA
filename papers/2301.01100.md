# [Understanding Imbalanced Semantic Segmentation Through Neural Collapse](https://arxiv.org/abs/2301.01100)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is: How does neural collapse manifest in semantic segmentation compared to image classification, and can inducing neural collapse in a certain way improve performance on minority classes in imbalanced semantic segmentation datasets?

The key points are:

- Neural collapse refers to a phenomenon where feature centers and classifiers converge to an equiangular tight frame (ETF) structure at the end of training on balanced datasets. This has been studied for image classification but not semantic segmentation. 

- The authors explore neural collapse in semantic segmentation and find the ETF structure does not fully emerge, likely due to contextual dependencies between classes and imbalanced distributions in semantic segmentation datasets.

- They propose a method to induce neural collapse more strongly on feature centers in semantic segmentation models, using an ETF-structured classifier branch on extracted centers. 

- This center collapse regularization improves performance on minority classes in imbalanced semantic segmentation benchmarks, showing the benefit of inducing the ETF structure on features.

In summary, the central hypothesis is that neural collapse can be purposefully induced in semantic segmentation models in a way that improves performance on imbalanced datasets, via an ETF-guided regularization on feature centers. The paper explores this phenomenon and validates the hypothesis.
