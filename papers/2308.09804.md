# [VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity   Control](https://arxiv.org/abs/2308.09804)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we develop an effective and efficient parameter-efficient tuning (PET) method for vision-language (VL) models that imposes effective control over modular modifications and accounts for the different roles of encoder and decoder modules?The key hypotheses appear to be:1) Imposing granular control over modular modifications via a granularity-controlled mechanism can improve PET performance and avoid instability/degradation from excessive modifications. 2) Tailoring lightweight PET module designs for encoders and decoders based on their distinct roles (encoding vs decoding) is better than using identical designs. Encoders focus on VL modeling while decoders focus on text generation.So in summary, the paper proposes a VL-PET framework to address the overall question via a granularity control mechanism and lightweight encoder/decoder PET designs to test those two main hypotheses. The experiments aim to demonstrate the efficiency, effectiveness and transferability of this approach on various VL tasks.


## What is the main contribution of this paper?

Based on my reading of the paper abstract, the main contributions appear to be:1. Proposing a VL-PET framework with a novel granularity-controlled mechanism to impose effective control over modular modifications introduced by PET techniques. This helps mitigate issues with excessive modifications leading to performance degradation.  2. Considering different levels of granularity control, instantiating a variety of model-agnostic VL-PET modules from the framework for better efficiency and effectiveness trade-offs.3. Proposing lightweight PET module designs that facilitate suitable modular modifications integration into the encoders and decoders of PLMs, considering their unique abilities.4. Conducting extensive experiments on image-text and video-text tasks that demonstrate the efficiency, effectiveness and transferability of the VL-PET framework and instantiated VL-PET modules.5. Showing that employing the VL-PET designs, like the granularity-controlled mechanism and lightweight designs, significantly enhances existing PET techniques like Compacter and VL-Adapter.In summary, the main contributions appear to be proposing the VL-PET framework, instantiating effective VL-PET modules from it, designing lightweight PET modules, and experimentally validating the framework's efficiency, effectiveness and transferability in vision-and-language tasks. The framework also allows enhancing existing PET techniques.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper proposes a novel VL-PET framework with granularity control, multi-head modular modifications, and lightweight designs to enable efficient and effective parameter tuning of pre-trained vision-language models.
