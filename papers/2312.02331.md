# [Revisiting Topic-Guided Language Models](https://arxiv.org/abs/2312.02331)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Recent work has proposed combining neural language models like LSTMs with topic models to create "topic-guided language models" (TGLMs). The motivation is that topic models can uncover document-level semantic patterns to complement the local syntax modeling of LSTMs. Several papers have reported that TGLMs improve predictive performance over LSTM baselines and learn coherent topics. 

This paper re-evaluates four representative TGLM papers (Dieng et al., Lau et al., Rezaee et al., Guo et al.) using three document-level datasets. It finds that after controlling for model size and evaluation procedure, none of the TGLMs outperform LSTM baselines in predictive performance. Additionally, most TGLMs do not learn semantically coherent topics based on automated topic coherence metrics.

Proposed Solution:
The authors standardize the evaluation of the four TGLM methods and LSTM baselines using perplexity on held-out data. They ensure the LSTM baselines are properly tuned and control for model size. During evaluation, they also make sure TGLMs do not use future words when making predictions.

To understand why TGLMs do not improve predictions, the authors probe the LSTM's learned representations and find they already encode meaningful topic information. Thus explicitly modeling topics appears redundant.

Main Contributions:
- Systematic comparison of four TGLMs using standardized evaluation, finding no predictive improvement over LSTM baselines
- Analysis attributing the lack of improvement to:
  - LSTM representations already capturing topical content
  - Mismatch in training/evaluation for some TGLM papers
  - Weak baselines considered in some TGLM papers
- Most TGLMs do not learn semantically coherent topics based on automated coherence metrics
- Takeaways for researchers combining topics with more powerful models like Transformers

The paper contributes a controlled study highlighting issues around evaluation and baselines in comparing neural topic models. It suggests avenues for better joint modeling of semantics and syntax.
