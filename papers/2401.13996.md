# [Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent   Self-Evolution](https://arxiv.org/abs/2401.13996)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Current AI agents lack the capability for inter-task self-evolution and adapting over time through learning from past experiences, unlike humans. 
- Existing methods focus only on intra-task learning rather than transferring knowledge between tasks. This limits agents' flexibility and problem-solving abilities when facing new challenges.

Proposed Solution - Investigate-Consolidate-Exploit (ICE) Strategy:
- Records planning trajectories and execution experiences from past tasks. 
- Consolidates these into simplified workflows (for plans) and pipelines (for execution) that are stored in the agent's memory.
- New tasks retrieve the most relevant workflows/pipelines from memory for reference or direct re-use to enhance effectiveness and efficiency.

Key Contributions:  
- First strategy to enable inter-task self-evolution for AI agents through learning from past task experiences.
- ICE disentangles and consolidates the key aspects from planning and execution trajectories into standardized formats.
- Experiments show ICE reduces model API calls by 80%, matches GPT-4 performance using the weaker GPT-3.5 model, and significantly boosts task completion rates.
- The accumulated experiences allow "scaling" and "grokking" effects over time as more workflows/pipelines become available.
- Overall, ICE makes agents more adaptive, time/cost-efficient, robust and moves towards autonomy.

In summary, the ICE strategy facilitates agents' continuous self-improvement across tasks by investigating, consolidating and exploiting past experiences. This paradigm shift contributes to more capable and practical agent systems.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes an Investigate-Consolidate-Exploit (ICE) strategy that enables inter-task self-evolution for AI agents by disentangling and reusing past successful planning and execution experiences to improve efficiency and effectiveness on new tasks.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing Investigate-Consolidate-Exploit (ICE), a novel strategy that enables inter-task self-evolution for general agent designs. Specifically:

- ICE promotes the transfer of knowledge between tasks for genuine self-evolution by disentangling task planning records and execution trajectories as past experiences for inter-task knowledge transfer. 

- It investigates planning and execution trajectories, consolidates them into simplified workflows and pipelines, and exploits them for improved task execution. This enhances the adaptability and flexibility of AI agents.

- Experiments on the XAgent framework demonstrate ICE's effectiveness in reducing API calls by up to 80%, significantly decreasing the demand for the model's capability, and allowing a GPT-3.5 model paired with ICE to match the performance of raw GPT-4 across various agent tasks.

In summary, the ICE strategy facilitates agent self-evolution through the effective re-utilization of past planning and execution experiences, making agent task completion more efficient, cost-effective and robust. This represents a paradigm shift in agent design towards full autonomy.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- Inter-task agent self-evolution - The main focus of the paper is enabling agents to improve performance over time by transferring knowledge between tasks, similar to human experiential learning. 

- Investigate-Consolidate-Exploit (ICE) - The novel strategy proposed in the paper for agent inter-task self-evolution. It involves investigating execution trajectories, consolidating them into simplified workflows and pipelines, and exploiting them for future tasks.

- Planning self-evolution - One aspect of ICE focused on tracking, pruning and reusing agent plans and subgoal structures. 

- Execution self-evolution - The other aspect of ICE focused on recording, simplifying and directly reapplying execution trajectories as finite state automata.

- Workflows - The consolidated linearized plans of successful subgoals that serve as planning references. 

- Pipelines - The consolidated execution trajectories transformed into reusable workflows.

- XAgent - The agent framework used to validate ICE, with separate experts for planning and execution.

- API calls - Used as a metric to measure improved time and cost efficiency from applying ICE.

- Task effectiveness - Used as a metric to measure improved performance on new tasks through the application of past experiences.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes disentangling planning and execution experiences for easier re-utilization. What are the challenges in identifying and extracting the valuable experiences from intricate planning and execution processes? How does the method address this?

2. The Investigate stage tracks planning and execution in real-time. What extra information needs to be tracked beyond just the goal status to ensure effective consolidation later? Why is dynamic tracking necessary?  

3. How does the method determine which parts of the plan to prune when consolidating the planning experience into a workflow? What strategies are used to balance simplicity and completeness?

4. What are some key differences in the consolidation process for workflows versus pipelines? Why are pipelines better suited for direct re-utilization compared to workflows?

5. When exploiting past experiences, how does the method determine the similarity threshold for retrieving relevant workflows and pipelines? How to balance flexibility and accuracy during retrieval?

6. Could failed planning/execution experiences also provide valuable lessons? If so, how can they be consolidated and exploited in the future? If not, why?

7. How does the method scale as more tasks and experiences accumulate over time? Could the experiences become so vast that retrieval efficiency decreases? How to address this?  

8. How suitable is the method for complex tasks with high variability between instances? When would it start to break down?

9. Beyond effectiveness and efficiency, what other dimensions of agent capability could improve through this inter-task self-evolution process?

10. The method currently focuses on goal-directed agents. How could it extend to open-ended conversational agents without explicit goals and subgoals? What modifications would be needed?
