# [Certified Training: Small Boxes are All You Need](https://arxiv.org/abs/2210.04871)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper seeks to address is: How can we train neural networks that are both certifiably robust to adversarial examples and achieve high standard accuracy?The key challenge is that existing certified training methods typically suffer from a robustness-accuracy trade-off, where improving certifiable robustness comes at the cost of significantly reduced standard accuracies. The paper proposes a new certified training method called SABR (Small Adversarial Bounding Regions) to overcome this trade-off. The core idea is to propagate small but carefully selected subsets of the adversarial input region during training. This is aimed at reducing the over-approximation errors that lead to over-regularization and poor standard accuracy in existing certified training methods. At the same time, SABR preserves the computational benefits of using imprecise bounding methods like IBP during training.In summary, the central hypothesis is that by propagating small adversarial regions, SABR can achieve high standard accuracy while still producing networks that are certifiably robust. The paper then empirically evaluates this hypothesis by benchmarking SABR against state-of-the-art certified defenses on MNIST, CIFAR-10 and TinyImageNet.
