# [Certified Training: Small Boxes are All You Need](https://arxiv.org/abs/2210.04871)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper seeks to address is: How can we train neural networks that are both certifiably robust to adversarial examples and achieve high standard accuracy?The key challenge is that existing certified training methods typically suffer from a robustness-accuracy trade-off, where improving certifiable robustness comes at the cost of significantly reduced standard accuracies. The paper proposes a new certified training method called SABR (Small Adversarial Bounding Regions) to overcome this trade-off. The core idea is to propagate small but carefully selected subsets of the adversarial input region during training. This is aimed at reducing the over-approximation errors that lead to over-regularization and poor standard accuracy in existing certified training methods. At the same time, SABR preserves the computational benefits of using imprecise bounding methods like IBP during training.In summary, the central hypothesis is that by propagating small adversarial regions, SABR can achieve high standard accuracy while still producing networks that are certifiably robust. The paper then empirically evaluates this hypothesis by benchmarking SABR against state-of-the-art certified defenses on MNIST, CIFAR-10 and TinyImageNet.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel certified training method called SABR (Small Adversarial Bounding Regions) that improves upon existing certified defenses in terms of both standard and certifiable accuracy across datasets and perturbation magnitudes. The key idea behind SABR is that propagating interval bounds for a small but carefully selected subset of the adversarial input region is sufficient to approximate the worst-case loss over the whole region while significantly reducing approximation errors. This allows the model to achieve less over-regularization and higher accuracy.Specifically, the main contributions are:- Proposing the SABR certified training method that reduces over-regularization to improve both standard and certified accuracy. - Providing theoretical analysis that motivates SABR by deriving new insights into the growth of box relaxations during propagation.- Conducting extensive experiments demonstrating SABR outperforms all existing certified training methods on MNIST, CIFAR-10 and TinyImageNet in terms of both standard and certifiable accuracy.So in summary, the key novelty is the SABR training method that propagates small adversarial regions to achieve a better trade-off between accuracy and robustness compared to prior certified defenses. Both theoretical and empirical results are provided to demonstrate and analyze the advantages of this approach.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a new certified training method called SABR that trains neural networks to be verifiably robust by propagating small but carefully selected subsets of the adversarial input region, aiming to reduce approximation errors and over-regularization compared to prior interval bound propagation techniques.


## How does this paper compare to other research in the same field?

This paper presents a new certified training method called SABR that aims to improve the trade-off between standard accuracy and certified robustness compared to prior work. Here are some key ways it relates to other research:- It builds on prior certified training methods like IBP and CROWN-IBP that train networks using imprecise box relaxations of the input region. The key insight is that propagating smaller regions can significantly reduce the approximation errors while still approximating the worst-case loss well. - It is most similar to COLT and IBP-R which also try to balance accuracy and robustness. However, SABR outperforms these methods across settings by finding a better accuracy-robustness tradeoff.- For standard datasets like CIFAR-10, SABR achieves state-of-the-art certified accuracy while also improving standard accuracy compared to prior certified training methods. This shows its potential to alleviate the accuracy-robustness tradeoff.- It provides theoretical analysis into the growth of approximation errors based on the size of propagated regions, giving insights into why smaller regions work better.- SABR points to a new class of certified training methods that propagate small cleverly chosen regions instead of the whole input region. This could inspire new techniques for training verifiably robust models.- Compared to empirical defense methods like adversarial training, SABR produces models with certified guarantees of robustness. And compared to provable defenses with inherent robustness properties, it achieves better performance on standard datasets and perturbations.Overall, SABR pushes the state-of-the-art for certified training on common benchmarks. The ability to improve standard accuracy while producing formally verifiable models is a notable achievement compared to prior work. The theoretical and empirical insights open up new research directions as well.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Developing more precise verification methods to get tighter bounds on the worst-case loss during certified training. The authors show that their SABR method benefits from using the more precise MIPVerify method for verification, compared to interval bound propagation. They suggest exploring other precise verification methods to further improve certified training.- Extending SABR to other threat models beyond L-infinity perturbations, such as other Lp norms, rotations/translations, or common corruptions. The authors only evaluate SABR for L-infinity bounded perturbations. Applying their core idea of propagating small regions to other threat models could be an interesting direction.- Exploring other ways to choose the propagation region beyond PGD attacks. The authors use PGD attacks to select a small region containing high-loss points to propagate through the network. Investigating other data-dependent or -independent ways to select propagation regions could be promising.- Analyzing in more detail the theoretical properties of SABR, such as relating the size of propagated regions to the induced regularization strength. The authors provide some initial analysis but further theoretical study could give more insights.- Applying SABR to larger and more complex models and datasets. The authors demonstrate SABR on CNNs for CIFAR-10 and MNIST. Testing on larger networks and more difficult datasets would be an important next step.- Combining SABR with other methods like verifiable training or randomized smoothing. The authors suggest SABR could complement these approaches that also aim to improve standard accuracy.- Exploring the continuum between SABR and adversarial training. SABR can be seen as interpolating between certified and adversarial training. More explicit trade-offs could be studied.Overall, the authors point to many interesting future work directions centered around developing tighter verified training methods that can lead to networks with both high standard accuracy and certification.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the key points from the paper:This paper proposes a new certified training method called SABR (Small Adversarial Bounding Regions) for training neural networks to be robust against adversarial examples. The key insight is that propagating bounds for a small, carefully selected subset of the adversarial input region through the network can approximate the worst-case loss over the whole region well while significantly reducing approximation errors. This is achieved by propagating bounds for an adversarially chosen  region using imprecise interval bound propagation, which induces less regularization and allows the trained networks to achieve higher standard and certified accuracies. The method is evaluated on MNIST, CIFAR-10 and TinyImageNet datasets and shows improved performance over state-of-the-art certified defenses across perturbation magnitudes. Theoretical analysis provides insight into the growth of interval bound relaxations during propagation and motivates the approach. Overall, SABR points to a new class of certified training methods that can alleviate the robustness-accuracy trade-off.
