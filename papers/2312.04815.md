# [Not All Negatives AreWorth Attending to: Meta-Bootstrapping Negative   Sampling Framework for Link Prediction](https://arxiv.org/abs/2312.04815)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel Meta-Bootstrapping Negative Sampling (MeBNS) framework to improve the capability of negative samplers in link prediction. Through comprehensive analysis, the authors surprisingly find that current link predictors with dynamic negative samplers suffer from the migration phenomenon between "easy" and "hard" samples, which severely hinders performance. To address this issue, MeBNS introduces a Meta learning Supported Teacher-student GNN architecture consisting of two key components: (1) a teacher-student design to alleviate the migration issue by using the teacher GNN to filter "easy" negatives and enforce the student GNN to specialize on "hard" samples, and (2) a meta learning based sample re-weighting module to help the student GNN distinguish "hard" samples in a fine-grained manner. Additionally, MeBNS provides a Structure enhanced Training Data Generator and Uncertainty based Meta Data Collector to facilitate the training of the teacher and student GNNs, respectively. Extensive experiments on six datasets demonstrate that MeBNS consistently improves over state-of-the-art negative sampling methods by effectively alleviating the migration issue and exploiting informative negatives. The proposed framework provides valuable insights into improving negative samplers for link prediction.
