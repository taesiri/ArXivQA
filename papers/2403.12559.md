# [Confidence Self-Calibration for Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2403.12559)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper studies multi-label class-incremental learning (MLCIL), where models sequentially learn new classes over time, while having access only to the current task labels during training. This leads to the task-level partial label issue, where past and future labels are unavailable. As a result, the label spaces across tasks are disjoint, and models tend to output over-confident predictions with many false positives, exacerbating catastrophic forgetting.

Proposed Solution:
The paper proposes a Confidence Self-Calibration (CSC) framework to address the multi-label confidence calibration issue in MLCIL under the partial label setting. The framework has two main components:

1. Class-Incremental Graph Convolutional Network (CI-GCN): Constructs cross-task label relationships by having a general correlation matrix that captures general label dependencies and expands over tasks, along with a sample-specific matrix that adapts to each image. This dynamically bridges isolated label spaces.

2. Max-Entropy Regularization: Penalizes over-confident output distributions to facilitate confidence self-calibration and reduce false positives. This is applied by maximizing the entropy of predictions on old classes.

Together, CI-GCN calibrates label relationships while max-entropy calibrates confidence, enabling effective MLCIL under partial labels.

Main Contributions:
- Proposes first framework aimed at refining multi-label confidence calibration in MLCIL 
- Introduces CI-GCN to construct cross-task label relationships and bridge isolated spaces under partial labels
- Presents max-entropy regularization for confidence self-calibration by penalizing over-confidence
- Achieves new state-of-the-art results on MLCIL tasks on MS-COCO and PASCAL VOC datasets
