# [WaveNeRF: Wavelet-based Generalizable Neural Radiance Fields](https://arxiv.org/abs/2308.04826)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we design a neural radiance field model that is generalizable across scenes and capable of high-quality novel view synthesis from only a few input views (e.g. 3 views) per scene, without requiring per-scene optimization or fine-tuning?The key hypothesis appears to be:By incorporating explicit modeling of high-frequency image details into both the multi-view stereo geometric feature extraction and the neural rendering stages, a neural radiance field can achieve improved generalizability and rendering quality from sparse inputs without needing scene-specific fine-tuning.Specifically, the paper hypothesizes that:1) Using wavelet transforms and frequency disentanglement in the multi-view stereo (MVS) 3D feature extraction will better preserve high-frequency scene detail information compared to standard MVS approaches.2) Incorporating explicit high-frequency scene features into the neural rendering stage will allow better reconstruction of fine details in novel views. 3) A frequency-guided neural sampling strategy can focus sampling in ray marching on high-frequency regions to further improve rendering.The proposed WaveNeRF model incorporates these ideas to achieve state-of-the-art performance in generalizable few-shot novel view synthesis without per-scene optimization.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It proposes WaveNeRF, a novel neural radiance field model that integrates wavelet frequency decomposition to achieve high-quality novel view synthesis from very sparse inputs (e.g. just 3 images) without requiring per-scene optimization. 2. It introduces a Wavelet Multi-View Stereo (WMVS) module to extract both spatial features and frequency features from input images. The frequency features help preserve high-frequency details.3. It designs a Frequency-guided Sampling Strategy (FSS) that leverages frequency features to guide sampling in NeRF, allowing denser sampling around object surfaces. 4. It presents a Hybrid Neural Renderer (HNR) that combines both spatial and frequency domain features to infer colors and densities for novel view synthesis.5. It achieves state-of-the-art performance on multiple datasets with only 3 input views, outperforming previous generalizable NeRF models without needing per-scene fine-tuning.In summary, the key innovation is using wavelet decomposition and frequency domain modeling to enable high-quality novel view synthesis from extremely sparse inputs in a generalizable manner, circumventing the need for cumbersome per-scene optimization. The experiments demonstrate significant improvements over prior arts.
