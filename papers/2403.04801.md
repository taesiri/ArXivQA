# [Alpaca against Vicuna: Using LLMs to Uncover Memorization of LLMs](https://arxiv.org/abs/2403.04801)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Prior work has focused on quantifying memorization in base large language models (LLMs) by prompting them with original training data. However, there is limited understanding of how memorization manifests in instruction-tuned models. 
- The paper investigates whether instruction-based prompts could uncover higher levels of memorization compared to using the original training data prompts.

Method:
- Proposes a black-box prompt optimization approach that uses an "attacker" LLM to generate prompts aimed at inducing a "victim" LLM to output training data it has memorized.  
- Employs an iterative rejection sampling process to generate prompts that have: (1) minimal overlap with training data, and (2) maximum overlap between victim model output and training data.
- Objective function balances maximizing victim model output-training data overlap (memorization measure) while minimizing prompt-training data overlap.

Experiments & Results: 
- Evaluated method against baselines (prefix-suffix prompts, GCG optimization, Reverse LM) on Llama and Falcon base models and instruction-tuned variants.
- Showed method uncovers 23.7% more memorization compared to prefix-suffix prompts.  
- Uncovers 12.4% more memorization in instruction-tuned models compared to base models.
- Surpasses GCG optimization by 12.5% in terms of training data reconstruction.
- Demonstrated open-source "attacker" model can outperform large commercial models.

Conclusions:
- Instruction-based prompts can reveal higher training data memorization compared to original prompts.
- Memorization in instruction-tuned models can exceed that of base models.  
- Contexts other than original training data can also lead models to regurgitate that data.
- Using LLMs as attackers provides a new method for auditing model memorization.

The key contributions are proposing this black-box prompt optimization approach tailored to instruction-tuned models and demonstrating it uncovers significantly more training data memorization compared to current state-of-the-art methods. The results also reveal important insights into the memorization behavior of instruction-tuned language models.
