# [Reinforcement Learning for Collision-free Flight Exploiting Deep   Collision Encoding](https://arxiv.org/abs/2402.03947)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper addresses the problem of autonomous collision-free navigation of aerial robots in GPS-denied cluttered environments, without relying on global maps or maps reconstructed online. The robot only has access to real-time depth images from an onboard sensor and an estimate of its own state (position, velocity etc). The goal is to learn a policy to output velocity and yaw rate commands to safely navigate the robot to a target location, while avoiding collisions with obstacles.

Proposed Solution: 
A modular deep learning approach is proposed, consisting of two key components:

1) A Deep Collision Encoder (DCE) that compresses depth images into a very low-dimensional latent space vector that retains collision information. It is trained in a supervised manner on both simulated and real depth images to enable better sim2real transfer. 

2) A Deep Reinforcement Learning (DRL) navigation policy that takes the compressed latent vector, robot state, and target location as input and outputs velocity and yaw rate commands. It is trained completely in simulation using a curriculum learning strategy that gradually increases environment complexity.

Together, this allows low-latency navigation that is resilient to sim2real gaps and can work with real-world noisy depth data.

Main Contributions:

- Modular architecture that separately verifies collision encoding and trains control policy, enabling sim2real transfer
- DCE that dramatically compresses depth images while retaining task-relevant collision information 
- DRL navigation policy trained using only simulation that can fly both through and above obstacles
- Robust performance shown in diverse simulation environments and challenging real-world experiments

The emergent behaviors include flying above obstacles when space allows, maneuvering intelligently through cluttered areas when needed, and adapting speed suitably to navigate obstacles. The method runs onboard with low latency, despite using only real-time depth images and state estimates.
