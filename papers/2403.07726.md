# [SemEval-2024 Shared Task 6: SHROOM, a Shared-task on Hallucinations and   Related Observable Overgeneration Mistakes](https://arxiv.org/abs/2403.07726)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Modern neural language generation (NLG) models often produce fluent but inaccurate or unsupported outputs, referred to as "hallucinations". Detecting such hallucinations is critical for many applications where correctness matters.  
- There is a lack of consensus on the best framework and methodology for detecting hallucinations across different NLG tasks.

Proposed Solution:
- The authors organize the SHROOM shared task focused specifically on detecting fluent overgeneration hallucinations in NLG model outputs across three tasks - machine translation, paraphrasing, and definition modeling.
- The task is framed around model-aware and model-agnostic tracks to classify whether a model output contains incorrect semantic information not supported by the input.
- A new dataset is constructed with 4000 NLG model outputs labeled by 5 annotators each, spanning the three tasks with models trained to varying accuracy levels.

Key Contributions:
- The dataset analysis shows hallucinations are a gradient phenomenon without clear consensual judgments. Almost 30% of data corresponds to ambiguous cases where annotators were split in judgments.
- 58 participants grouped in 42 teams submit over 300 valid prediction sets, employing diverse approaches like model fine-tuning, prompting strategies, etc. 
- While most teams outperform the proposed baseline, top scoring systems have ~15% error rate, consistent with random guessing on ambiguous items.
- Access to model parameters provides limited benefits; participant system diversity highlights complexity of hallucination detection.

Main Conclusions:
- Ambiguous cases with split annotator judgments remain challenging for current systems. Significant research gaps persist in reliably detecting hallucinations.
- The task success underscores interest in this research area but also limitations of existing approaches. The data and analysis provide a useful starting point for further work.
