# [TexPose: Neural Texture Learning for Self-Supervised 6D Object Pose   Estimation](https://arxiv.org/abs/2212.12902)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is: How can we perform self-supervised 6D object pose estimation from monocular RGB images without requiring additional supervisory signals like depth data or ground truth poses? 

The key hypothesis is that by decomposing the self-supervision into separate texture and pose learning phases, they can learn to predict realistic object textures from unlabeled real images and use this to synthesize training data with accurate poses to supervise the pose estimator. This allows them to avoid some limitations of prior work like reliance on depth data or pose refinement networks.

In summary, the main research question is how to do self-supervised 6D pose learning from RGB images alone, and the key hypothesis is that separating texture and pose learning can enable this without needing other supervisory signals.
