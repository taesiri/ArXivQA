# [Patch Is Not All You Need](https://arxiv.org/abs/2308.10729)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the key research question it aims to address is: How to effectively convert images into sequence inputs for vision transformers while preserving structural and semantic information?The paper proposes a novel "Pattern Transformer" approach to adaptively convert images into pattern sequences as inputs to the transformer architecture. This avoids the limitations of manual image patchification used in prior vision transformers like ViT, which disrupts the inherent structure and semantics of the image. The central hypothesis is that by using a convolutional neural network to extract a set of patterns from the image, where each pattern/channel captures a local region of interest, the model can preserve the intrinsic structural and semantic information of the image while generating a sequence input for the transformer.In summary, the paper focuses on researching better methodologies for converting image data into sequences for transformer-based vision models, moving beyond naive patchification approaches, via more adaptive pattern extraction that maintains visual structure and semantics. The proposed Pattern Transformer framework is evaluated on image classification tasks to validate its effectiveness.
