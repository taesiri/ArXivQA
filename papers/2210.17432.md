# SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for   Text Generation and Modular Control

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can diffusion models be adapted to effectively generate high-quality and controllable text, given their success in continuous domains like images but the challenges of extending them to discrete text data?The key hypotheses explored are:1) A semi-autoregressive training and decoding scheme can allow diffusion models to generate variable-length text while enabling local context updates during decoding.2) Representing text as distributions over the vocabulary (simplexes) rather than latent embeddings can allow incorporating off-the-shelf text classifiers to control generation without adaptation. The paper proposes SSD-LM, which incorporates these two main ideas, and evaluates it for open-ended and controlled text generation. The central evaluation seems to be demonstrating that SSD-LM can match or exceed the quality of strong autoregressive baselines like GPT-2 while being more flexible and controllable.In summary, the main research question is how to unlock the advantages of diffusion models like bidirectional context and controllability for discrete text data, which has been a challenging domain for diffusion models. The central hypotheses are around using a semi-autoregressive approach and simplex representations to achieve this goal.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. Proposing SSD-LM, a semi-autoregressive simplex-based diffusion language model for text generation. This combines ideas from autoregressive LMs and diffusion models to allow flexible output length and local bidirectional context.2. Using a simplex-based approach where diffusion operates directly on the vocabulary distribution rather than a latent space. This allows easy incorporation of classifier-based control using off-the-shelf classifiers without adaptation.3. Demonstrating strong performance of SSD-LM on unconstrained text generation, outperforming or matching GPT-2 models on quality and diversity metrics. This is the first time a diffusion LM matches autoregressive LMs.4. Showing SSD-LM's effectiveness on controlled text generation using sentiment classifiers, outperforming competitive baselines while maintaining high modularity.5. Introducing design choices like semi-autoregressive decoding and simplex-based modeling to make diffusion viable and competitive for text generation.In summary, the key novelty is developing a diffusion LM that can match autoregressive LMs in text quality while also enabling easy and modular control. The semi-autoregressive and simplex-based modeling are key technical contributions addressing challenges faced by prior diffusion LMs for text.
