# [Reconstructing Animatable Categories from Videos](https://arxiv.org/abs/2305.06351)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we build animatable 3D models of deformable object categories from monocular videos while disentangling variations across instances from time-specific variations within an instance?The key challenges they aim to address are:1) Modeling the morphological variation across instances within a category (e.g. different dog breeds). This is difficult to disentangle from time-varying variations within a single instance (e.g. a dog's articulation and deformation over time).2) Dealing with the limited and impoverished nature of in-the-wild videos, where objects may be partially observable from limited viewpoints and with inaccurate segmentation masks. The model needs to listen to common structures across the category while staying faithful to the input views. Their proposed approach RAC introduces three main ideas to address these challenges:1) Specializing skeletons to instances via optimization, allowing better disentanglement of morphology and articulation.2) A method for latent space regularization that encourages shared structure across the category while maintaining instance details.3) Using 3D background models to disentangle objects from the background.The overall goal is to learn category-level 3D models from monocular videos that can generate different instances and their motions, without requiring 3D supervision or registrations.In summary, the paper aims to address the problem of building animatable category-level 3D models from in-the-wild monocular videos, while disentangling variations across instances and motions over time.
