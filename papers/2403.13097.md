# [Simple Ingredients for Offline Reinforcement Learning](https://arxiv.org/abs/2403.13097)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Existing offline RL algorithms work well when the offline dataset is highly relevant to the downstream task. However, their performance deteriorates when the dataset contains diverse trajectories not directly related to the target task.
- The paper introduces a new benchmark called MOOD based on DMC environments to systematically study this problem. On MOOD, simply adding more data from different tasks consistently hurts performance, even when the algorithm succeeds on individual subsets. 

Proposed Solutions and Contributions:

1) Introduces MOOD, a new benchmark for offline RL based on DMC with datasets containing heterogeneous trajectories from various behaviors/tasks. 

2) Shows that on MOOD, existing offline RL algorithms (TD3+BC, AWAC, IQL) struggle when incorporating data from multiple tasks, despite succeeding on individual subsets. Surprisingly, vanilla TD3 benefits from diversity.

3) Formulates hypotheses on causes of failure: over-conservatism, network capacity, variance of advantage weighting, epistemic uncertainty.

4) Tests hypotheses systematically over 50,000 experiments across algorithms, architectures and hyperparameters. Key finding: scale (wider networks) matters most.

5) Shows that simple methods like AWAC and IQL with increased network size match or exceed state-of-the-art on D4RL locomotion and antmaze. They also match recent specialized sampling strategies for unbalanced D4RL variants.

In summary, the paper introduces a new diverse-data benchmark exposing fundamental limitations of current offline RL algorithms, which are shown to be significantly alleviated by simple architecture scaling, enabling simplified algorithms to achieve state-of-the-art performance.
