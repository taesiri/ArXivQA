# [Weakly-supervised Single-view Image Relighting](https://arxiv.org/abs/2303.13852)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question/hypothesis of this paper is: 

How to relight a single image of real-world objects under novel lighting conditions, which enables inserting photographed objects into new scenes with proper illumination effects for augmented reality applications?

The key challenges are:

1) Inverse rendering from a single image is highly ill-posed, as it requires estimating geometry, materials, and lighting from just one observation. 

2) Re-rendering objects under novel lighting requires handling non-Lambertian materials and environment lighting.

To address these challenges, the paper proposes:

1) A weakly-supervised inverse rendering pipeline trained with a novel low-rank loss on real image datasets. This helps resolve the ill-posed inverse rendering problem.

2) A differentiable non-Lambertian rendering layer that can render low-frequency specular materials under environment lighting represented with spherical harmonics. This enables re-rendering of materials from diffuse to glossy.

The overall approach enables realistic relighting and insertion of photographed objects into new scenes from just a single input image, which could benefit mobile augmented reality applications. The effectiveness is demonstrated through experiments and a mobile app implementation.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- A weakly-supervised inverse rendering pipeline trained with a low-rank loss. The correctness and convergence of the loss are mathematically proven.

- A large-scale dataset of foreground-aligned videos collecting 750K images of 100+ real objects under different lighting conditions. This facilitates training and can benefit other vision tasks. 

- A differentiable specular rendering layer to render low-frequency non-Lambertian materials under spherical harmonic lighting. This enables relighting objects with a range of materials.

- An end-to-end pipeline for single image relighting of real objects, allowing insertion into new scenes. This is implemented in a mobile app.

In summary, the key contribution is the weakly-supervised learning framework and differentiable renderer that together enable real object relighting from a single image. The large dataset, proofs, and mobile app are secondary contributions that support the main technique.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a weakly-supervised approach for relighting real objects in augmented reality using a low-rank constraint on reflectance matrices and a differentiable renderer, enabled by a large dataset of videos of objects under varying illumination.


## How does this paper compare to other research in the same field?

 Here are some key comparisons between this paper and other related work in single image relighting:

- This paper proposes a weakly-supervised approach for single image inverse rendering and relighting. Most prior work relies on synthetic datasets with ground truth supervision or multi-view supervision. This paper uses a novel low-rank loss to train on real images without ground truth.

- For inverse rendering, this paper jointly predicts lighting, normals, and reflectance in an end-to-end differentiable pipeline that strictly follows the image formation model. Many prior works tackle each task separately or use separate networks without enforcing physical constraints. 

- For relighting, this paper presents a differentiable non-Lambertian renderer that can produce specular highlights from normal maps and spherical harmonic lighting. Prior neural rendering techniques require meshes and cannot handle normal maps. Prior image relighting is mostly limited to Lambertian scenes.

- The paper contributes a large-scale dataset of 750K real images of foreground objects with changing illuminations. Most datasets for this task are synthetic. The real data is key to avoiding the domain gap.

- Experiments show superior performance over state-of-the-art methods in intrinsic image decomposition, normal estimation, and relighting. An end-to-end mobile app is implemented.

In summary, the main advances are in designing a self-supervised pipeline tailored for real single images, enabled by the novel low-rank loss and dataset. The differentiable non-Lambertian renderer also expands the application scope. The weakly-supervised approach avoids the need for expensive ground truth supervision.
