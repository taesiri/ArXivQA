# [Vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting   Generative AI-based Visualizations](https://arxiv.org/abs/2402.02167)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) show promise for automatic visualization generation from natural language queries. However, there is a lack of standardized methods to comprehensively evaluate the quality of LLM-generated visualizations across different facets like code quality, data mapping, visualization best practices etc.

Proposed Solution - EvaLLM:  
- The paper proposes EvaLLM, a conceptual evaluation stack to assess LLM-generated visualizations. It decomposes the evaluation into 5 layers - Code, Representation, Presentation, Informativeness and LLM layers. 
- Each layer has specific levels to evaluate different aspects of visualization quality both automatically and manually. For example, the Code layer verifies syntactic correctness, the Representation layer checks data mapping and axes quality, the Presentation layer evaluates perceptual properties and so on.
- The stack provides a framework to benchmark LLM capabilities in visualization tasks across multiple quantitative and qualitative criteria.  

Implementation:
- A web platform is introduced to facilitate EvaLLM-based evaluation. It supports both automated scoring and manual labeling by human assessors. 
- Use cases with GPT-3.5-turbo and Llama2-70b on NVBench dataset demonstrate identifying common errors like incorrect data mapping, sorting issues, lack of visualization significance etc.

Main Contributions:
- EvaLLM - A conceptual evaluation stack tailored to assess quality of LLM-generated visualizations
- Web platform enabling standardized benchmarking of LLMs using EvaLLM
- Analysis of two LLMs exposing limitations in aligning visualizations to user queries across different facets

The framework and platform lay the groundwork for extensive evaluation of emerging LLMs for data visualization tasks.
