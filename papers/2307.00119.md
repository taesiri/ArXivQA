# [Meta-training with Demonstration Retrieval for Efficient Few-shot   Learning](https://arxiv.org/abs/2307.00119)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we create a parameter-efficient model that is capable of fast and robust few-shot performance on a variety of natural language processing tasks?The authors aim to address this by proposing a meta-training approach that retrieves semantically similar demonstrations to augment the training data and supervision signal. Specifically, they combine meta-training with a retrieval-based architecture to create a model that can effectively leverage external knowledge from demonstrations for improved few-shot generalization.The key hypotheses appear to be:1) Meta-training can impart useful inductive biases and abilities like in-context learning to make smaller models capable of leveraging demonstrations effectively.2) Retrieving semantically similar demonstrations from a large and diverse bank compiled from many existing QA datasets will provide more varied and task-relevant supervision compared to randomly sampling demonstrations. 3) Separating external knowledge in the demonstrations from model parameters enables using smaller models that generalize well to more tasks, compared to relying solely on parameterization.In summary, the central research question is how to create a parameter-efficient model for robust and fast few-shot learning, which they address via meta-training augmented with demonstration retrieval. The key hypotheses focus on how this combination equips smaller models with better abilities for leveraging external knowledge.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a parameter-efficient meta-training approach for few-shot learning that combines retrieval of semantically similar demonstrations with training a sequence-to-sequence model. Specifically:- They propose meta-training a sequence-to-sequence model (BART) on a diverse set of QA tasks to make it more capable of leveraging retrieved demonstrations for few-shot generalization. - They use a dense passage retriever to retrieve semantically similar demonstrations from a memory bank compiled from QA datasets, rather than randomly sampling demonstrations from the target task's training set.- Their model combines the strengths of meta-training and retrieval-augmented models to achieve strong performance on QA, NLI, and text classification with 440M parameters, outperforming tailored efficient baselines.- To their knowledge, this is the first work to combine retrieval with meta-training, use DPR for retrieving demonstrations, and leverage demonstrations from many diverse tasks simultaneously.In summary, the key innovation is an efficient meta-training approach that utilizes retrieval of demonstrations from a broad set of tasks to improve few-shot generalization, surpassing tailored efficient models. The combination of retrieval and meta-training allows strong performance without large model size.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on my reading of the paper, here is a one sentence summary:The paper proposes a method to improve few-shot performance of smaller generative language models by retrieving semantically similar demonstrations during meta-training and fine-tuning.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other research in few-shot learning and meta-learning:- The paper proposes a novel method combining meta-training with demonstration retrieval for few-shot learning. This is a new approach compared to prior work in few-shot learning, which has focused on scaling up model size, prompt/template tuning, or meta-learning without retrieval. - For demonstration retrieval, the paper uses a dense passage retriever to find semantically similar examples from a diverse bank of QA tasks. This differs from prior work using retrieved demonstrations, which have typically sampled demonstrations from the target task's training set.- The model is based on a relatively small seq2seq model (BART-large). This makes it more parameter- and computation-efficient compared to large pretrained language models used in other few-shot learning methods.- The method is evaluated on a wider variety of tasks than most prior work, including extractive QA, multiple choice QA, and text classification. This demonstrates the versatility of the approach.- The paper shows the proposed method outperforms tailored efficient baselines on the evaluated tasks. The gains from meta-training and the demonstration bank are analyzed through comparison to ablation models.- Limitations include potential bias issues from the demonstration bank, lack of evaluation on very low-resource settings, and reduced effectiveness on knowledge-intensive QA compared to a specialized model.In summary, the key novelties are using retrieval to find task-agnostic demonstrations for meta-training, evaluating on a diverse set of tasks, and outperforming efficient baselines. The analysis provides insights into the benefits of different components. Overall it introduces a new direction for efficiently adapting models for few-shot learning.


## What future research directions do the authors suggest?

The authors suggest the following future research directions:- Improving the memory bank to contain more semantically similar and relevant demonstrations, potentially through content generation techniques. They note that using an oracle memory bank with test set examples greatly improves performance, indicating room for improvement.- Exploring a mixture of demonstration retrieval and passage retrieval from sources like Wikipedia. This could improve performance on more knowledge-intensive tasks.- Analyzing the types of retrieved demonstrations that are most helpful, rather than just using lexical overlap as a proxy for usefulness. This analysis could further improve the memory bank.- Balancing diversity and relevance during retrieval more effectively. Both completely random and highly constrained retrieval are ineffective. - Adapting the model for low-resource languages by using cross-lingual transfer techniques. It is currently unclear how well the model generalizes to non-English languages.- Testing the approach on more domain-specific tasks with less available training data. The current setup requires a large pool of labeled data for the memory bank.- Reducing GPU memory usage during meta-training to allow training on more common 16GB GPUs. Currently meta-training requires more memory.In summary, the main suggestions are to improve the memory bank, especially for knowledge-intensive tasks; analyze why retrieval helps; adapt the method for low-resource settings; and reduce GPU memory requirements.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper proposes a method for meta-training with demonstration retrieval for efficient few-shot learning. The method uses a dense passage retriever to retrieve semantically similar labeled demonstrations for each example during meta-training and fine-tuning. This allows smaller generative models like BART to leverage external knowledge separated from model parameters for improved few-shot performance across tasks. The method outperforms various baselines on question answering, natural language inference, and classification tasks. Analysis shows that meta-training is key for performance gains, though the demonstration bank also helps compared to using Wikipedia passages. The results demonstrate an effective way to induce versatile few-shot abilities in smaller generative models.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:The paper proposes a method for meta-training with demonstration retrieval for efficient few-shot learning. The method uses a dense passage retriever to retrieve semantically similar labeled demonstrations for each training and test example during meta-training and fine-tuning. This allows smaller generative models like BART to generalize well on a variety of tasks with limited training data. The meta-training set is constructed from UnifiedQA and CrossFit QA tasks. The demonstration bank is also constructed from UnifiedQA tasks. The method is evaluated on question answering, natural language inference, and text classification tasks. It outperforms targeted parameter-efficient and retrieval-augmented baselines on tasks like SQuAD, QNLI, and TREC. Ablation experiments analyze the contribution of different model components like the memory bank and meta-training data selection. The results show the method induces good general-purpose few-shot performance. Future work could explore mixing demonstration and passage retrieval. The code is available on GitHub.
