# xCos: An Explainable Cosine Metric for Face Verification Task

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be:How can we develop a more explainable and interpretable face verification framework that provides spatial explanations (e.g. which parts of two face images are considered similar/dissimilar) while maintaining high accuracy?The key hypothesis seems to be that by proposing a new similarity metric called "explainable cosine" ($xCos$) that considers local patch-wise similarities and learns an attention mechanism, they can create a face verification model that is more explainable and interpretable to humans while still achieving state-of-the-art accuracy.In particular, the paper proposes that by comparing local patches of two face images and generating a "similarity map", as well as learning an "attention map" that indicates which patches are more important, the $xCos$ module can help explain which parts of the faces are driving the verification decision. This provides spatial interpretability that is lacking in standard face verification models based on deep feature representations.So in summary, the central research question is how to make face verification more explainable, and the key hypothesis is that the proposed $xCos$ module can achieve this via local similarity and attention maps. The experiments then aim to validate that $xCos$ can indeed provide interpretability while maintaining accuracy.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel explainable cosine metric called xCos for face verification. The key ideas are:- xCos decomposes the overall similarity score between two face images into local cosine similarities (patched cosine map) and attention weights. This allows visualizing which parts of the faces are considered similar/dissimilar. - The attention weights are learned to focus on important facial parts like nose, mouth, etc. This reveals which local similarities matter more in computing the global similarity score.- The xCos module can be plugged into existing face verification models like ArcFace and CosFace to make them more interpretable, with minimal performance drop.In summary, xCos provides local similarity and attention visualizations to help explain the face verification results. This improves model interpretability and trustworthiness while maintaining accuracy.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new explainable face verification method called xCos that decomposes the similarity score into interpretable local similarity and attention maps to help users understand model decisions.
