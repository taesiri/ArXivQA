# [15 Keypoints Is All You Need](https://arxiv.org/abs/1912.02323)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be how to develop an efficient multi-person pose tracking method that relies primarily on keypoint information, without using RGB or optical flow data, in order to achieve real-time performance. The key hypotheses appear to be:- Pose tracking can be effectively modeled as a "pose entailment" task, where a model learns to predict if one pose temporally follows another, using only sparse keypoint information encoded into tokens.- A transformer-based network can learn these temporal relationships between poses better than convolution-based methods, especially at low resolutions, allowing efficient and accurate real-time tracking.- Keypoint detections can be improved by aggregating estimates over time with a parameter-free temporal OKS method, rather than standard bounding box propagation approaches. - By combining these methods into a pipeline, real-time multi-person pose tracking can be achieved without reliance on computationally expensive RGB or optical flow data, setting a new state-of-the-art in terms of speed and accuracy.In summary, the central research focus is on developing a lightweight pose tracking pipeline centered around a novel pose entailment framework and keypoint refinement approach to achieve fast yet accurate tracking using only sparse keypoint information. The key hypotheses relate to the potential for transformers and temporal aggregation to model this task effectively and efficiently.


## What is the main contribution of this paper?

Here are the main contributions of the paper:- The paper introduces Pose Entailment, a novel method to track human poses across video frames. Pose Entailment models the tracking problem as determining whether one pose temporally follows another, similar to textual entailment in NLP. - The paper proposes a tokenization scheme to represent keypoint poses that captures spatial location, keypoint type, and temporal information. This representation is fed into a Transformer network to model temporal pose relationships for tracking.- The paper presents Temporal OKS (TOKS), a new technique to improve keypoint detection by aggregating detections across frames and selecting the best based on OKS similarity rather than standard NMS.- The overall pipeline combining Pose Entailment tracking and TOKS detection achieves state-of-the-art results on the PoseTrack 2017 and 2018 benchmarks, while being very efficient compared to methods using optical flow or GCNs.- Analysis shows the benefits of the Transformer network over CNNs for modeling temporal pose relationships, especially at low resolutions. Attention heatmaps provide insight into what the network learns.In summary, the main contribution is an efficient pose tracking pipeline using novel techniques for detection, representation, and modeling of temporal pose relationships with transformers. The Pose Entailment method sets a new state-of-the-art on benchmark datasets.
