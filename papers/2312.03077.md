# [Clinical Notes Reveal Physician Fatigue](https://arxiv.org/abs/2312.03077)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Physician fatigue can negatively impact patient care, but it is difficult to measure fatigue at an individual patient level. Prior studies rely on coarse measures of drivers of fatigue like workload, which are imperfectly correlated with actual fatigue.

- There are also open questions around whether physician fatigue correlates with patient demographics like race, as well as implications for use of AI like large language models (LLMs) in clinical documentation.

Method:
- The authors develop a model to estimate physician fatigue at the time of writing a clinical note, by predicting whether the note was written after a high vs low workload week.

- The model uses interpretable features related to note length, predictability, readability, pronouns, emotions, etc. It is trained and evaluated on 129,228 notes across 60 physicians.

Results:
- The model can estimate fatigue levels, validated by correlation with overnight shifts, circadian disruption, and intra-shift workload. 

- Higher predicted fatigue is associated with 18% lower testing yield for heart attacks, suggesting an impact on clinical decision quality.

- Notes for Black and Hispanic patients have 12-21% higher predicted fatigue compared to White patients.

- LLM-generated notes have 17% higher predicted fatigue compared to real notes.

Implications:
- Fine-grained estimation of fatigue from notes enables studying impacts on outcomes and disparities.

- Biases in predicted fatigue could reflect differential engagement with patients.

- Biases could also manifest in LLM-generated notes, necessitating new quality assurance methods before deployment.

In summary, the paper presents a novel method to estimate physician fatigue for studying its effects on care quality and equity, with implications for appropriate use of AI.


## Summarize the paper in one sentence.

 This paper develops a model to detect physician fatigue from the text of clinical notes, revealing connections to worse decision making and racial disparities in measured fatigue levels.


## What is the main contribution of this paper?

 This paper develops a novel method to detect physician fatigue from the text of clinical notes. The key contributions are:

1) Training a model to predict whether a note is written by a high or low workload physician, using interpretable features like note length, predictability, and LIWC categories. The model achieves 60.1% AUC-ROC on a held-out test set in distinguishing notes written by physicians with high vs low prior week workloads.

2) Demonstrating that model predictions correlate to several other indicators of fatigue beyond just prior workload, like overnight shifts, circadian disruption, and intra-shift workload. This provides evidence that the model learns a general signal of fatigue. 

3) Showing that predicted physician fatigue negatively impacts physician decision making, specifically the yield of testing for heart attacks. Each SD increase in predicted fatigue leads to an 18% drop in testing yield.

4) Revealing substantial disparities in predicted fatigue by patient race and ethnicity. Notes about Black and Hispanic patients have 12-21% higher predicted fatigue than notes about White patients.

5) Analyzing predicted fatigue in AI-generated notes, finding they have 17% higher fatigue than real physician notes. This indicates distortions introduced by language models and raises questions about relying on them for clinical note generation.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key keywords and terms associated with this paper include:

- physician fatigue
- clinical notes
- healthcare equity
- natural language processing
- workload
- circadian disruption
- physician decision making 
- racial biases
- large language models
- note predictability
- perplexity

The paper develops a model to detect physician fatigue from the text of clinical notes. It correlates predicted fatigue to measures of physician circadian disruption and decision quality. It also finds differences in predicted fatigue by patient race. Finally, it compares fatigue in actual physician notes to notes generated by large language models.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper argues that the note-based measure of fatigue is a better predictor of physicians' "true" fatigue state than measures of workload. What is the theoretical justification provided for why errors in predicting workload might actually indicate that predictions are closer to true fatigue?

2. Perplexity of notes is found to be negatively correlated with physician fatigue. What might be some explanations for why fatigued physicians write more predictable notes? How might this predictability link to quality of care?  

3. The paper finds differences in predicted fatigue between notes written about White patients and non-White patients. What are some possible mechanisms that could lead to these differences? How can we test whether these differences reflect bias versus other patient-level factors?

4. The analysis links higher predicted fatigue scores to lower yield of testing for heart attacks. What are possible mechanisms for why fatigue might negatively impact this important physician decision?  

5. The paper argues that large language models (LLMs) may introduce distortions in generated clinical notes related to fatigue. What evidence is provided to support the finding that LLM-generated notes have higher predicted fatigue? What might be the implications of relying on LLM-generated notes in practice?

6. Why might greedy decoding result in higher predicted fatigue scores compared to sampled decoding for LLM-generated notes? What features drive these differences?

7. What are the limitations of using workload over the prior week as a label for training the fatigue prediction model? How might errors in predicting this variable actually indicate the model is learning something useful?

8. The model incorporates perplexity, readability measures, pronouns, and other features to predict fatigue. What is the intuition behind including these different categories of textual features? How do they relate to fatigue?

9. How does the paper rule out the possibility that underlying differences in patient mix or characteristics (rather than physician fatigue) explain differences in note text across high vs low workload settings?  

10. The paper argues that physician notes provide a "window" into decision-making. What new analyses does a note-based measure of fatigue enable compared to existing measures of workload, overnight shifts, etc.? What opportunities exist for future work?
