# [On Large Language Models' Selection Bias in Multi-Choice Questions](https://arxiv.org/abs/2309.03882)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research question this paper addresses is: Do large language models exhibit inherent biases in their ability to answer multiple choice questions, and if so, what are the causes and potential ways to mitigate such biases?Specifically, the authors identify that LLMs tend to be biased towards selecting options at certain positions (like "Option C") in multiple choice questions. They investigate the prevalence, causes, and potential ways to reduce this "selection bias" across a range of models and datasets. The central hypothesis seems to be that selection bias arises primarily due to the numbering/symbols used for answer options (A, B, C, D), and that this bias can be effectively reduced by estimating and adjusting for the models' prior preferences over option positions. The method proposed, Pride, aims to debias LLMs by estimating these inherent positional priors and using them to adjust the models' predictions.In summary, this paper centers on empirically demonstrating, analyzing the causes of, and developing a technique to mitigate LLMs' selection biases in answering multiple choice questions. The key hypothesis is that by accounting for models' prior positional preferences, their robustness and performance on this important task format can be improved.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Identifying and providing empirical analysis of the inherent "selection bias" of large language models (LLMs) in multi-choice questions (MCQs). Selection bias refers to LLMs' preference for selecting options located at specific positions (e.g. Option C). The authors show this bias is prevalent across various LLMs and makes their performance vulnerable to option position changes.2. Pinpointing option numbering (the ID symbols like A/B/C/D) as a primary cause of selection bias. The authors find removing option IDs can reduce bias but usually compromises performance. 3. Proposing a new method called "PriDe" (Debiasing with Prior estimation) to mitigate selection bias in an efficient, label-free way at inference time. PriDe decomposes the observed prediction distribution into an intrinsic distribution over option contents and a prior preference distribution over option IDs. It estimates the prior with a small number of samples and uses it to debias subsequent samples.4. Demonstrating PriDe achieves better debiasing effectiveness and efficiency compared to strong baselines, especially in low-cost scenarios. The estimated priors also exhibit reasonable generalization across domains, confirming the inherent presence of selection bias.In summary, the main contribution appears to be the analysis and insights into selection bias in LLMs for MCQs, as well as the proposal of the efficient PriDe method to mitigate this bias during inference. The paper provides valuable empirical findings on an important bias phenomenon in LLMs and introduces a practical debiasing approach.
