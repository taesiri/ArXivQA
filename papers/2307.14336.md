# [MAMo: Leveraging Memory and Attention for Monocular Video Depth   Estimation](https://arxiv.org/abs/2307.14336)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, it appears the main research question is how to leverage memory and attention mechanisms to improve monocular video depth estimation. Specifically, the paper proposes a novel framework called MAMo that can take any existing monocular depth estimation model and augment it with memory and attention modules to enable video depth estimation. The key ideas/components of MAMo include:- Introducing a memory module that maintains useful visual and displacement tokens from previous frames to help guide depth prediction on the current frame. - Proposing a novel scheme to update the memory by encouraging it to retain features that are equivariant (invariant) to motion across the current and previous frames.- Using self-attention on the memory tokens and cross-attention between memory and current visual features to enable spatio-temporal processing.- Additional designs like carrying over past decoder features to further enhance utilization of temporal information.The main hypothesis seems to be that by carefully introducing memory and attention, the model can learn to select and aggregate useful information from across multiple frames to perform more accurate video depth estimation, compared to just using a single frame. The experiments aim to validate whether MAMo consistently improves state-of-the-art monocular depth networks and outperforms other video depth estimation techniques.In summary, the key research question is how to effectively leverage memory and attention to enable existing monocular depth models to exploit temporal information for improved video depth prediction. The main hypothesis is that the proposed MAMo framework will allow for more accurate depth estimation compared to monocular as well as other video-based approaches.


## What is the main contribution of this paper?

Based on the abstract, it looks like the main contribution of this paper is proposing a novel memory and attention framework called MAMo for monocular video depth estimation. The key ideas are:- Augmenting depth estimation models with a memory module to store useful information from previous frames, which can help guide depth prediction on the current frame. - Introducing a new scheme to update the memory by minimizing the difference between depth predictions on the current frame and a warped version of the previous frame. This encourages the memory to capture equivariant features across frames.- Using attention mechanisms to process the memory features and fuse them with encoder features of the current frame before feeding to the decoder.- Applying MAMo to latest monocular depth networks like NeWCRFs and PixelFormer to convert them into effective video depth models.- Demonstrating through experiments that MAMo consistently improves monocular depth networks and achieves state-of-the-art video depth estimation accuracy on KITTI, NYU-Depth V2 etc.In summary, the main contribution is proposing the memory and attention based MAMo framework to enable monocular networks to leverage temporal information for accurate and efficient video depth estimation.
