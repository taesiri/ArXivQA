# [Simple Token-Level Confidence Improves Caption Correctness](https://arxiv.org/abs/2305.07021)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we improve the ability of vision-language models to judge the correctness or consistency of a caption with respect to an image, especially for fine-grained details?The authors hypothesize that operating at a token-level rather than sequence-level for judging caption-image consistency could lead to improvements in assessing correctness. They propose and evaluate two methods, Token-Level Confidence Algebraic (TLC-A) and Token-Level Confidence Learned (TLC-L), that leverage token-level confidences from a finetuned image captioning model to estimate caption correctness.The key ideas are:- TLC-A uses algebraic confidence measures (e.g. softmax score) at each token to estimate correctness.- TLC-L learns a domain-specific confidence estimator on top of the captioning model to predict token correctness. - Token confidences are aggregated over sequences or words to produce overall caption correctness scores.- TLC is evaluated on compositional reasoning, verb understanding, and reducing object hallucination in captions.So in summary, the main research question is whether token-level confidence can improve judging caption-image consistency and correctness compared to typical sequence-level methods. TLC-A and TLC-L are proposed as ways to implement token-level confidence.


## What is the main contribution of this paper?

This paper presents Token-Level Confidence (TLC), a simple yet effective method to improve the correctness of image captions generated by vision-language models. The key ideas are:- TLC leverages token-level confidences from an image captioning model to estimate the semantic consistency between an image and caption. This provides more fine-grained confidence estimates compared to typical sequence-level image-text matching scores. - TLC aggregates the token confidences over words or sequences to produce an overall estimate of caption correctness. Two variants are proposed - TLC-Algebraic (TLC-A) uses algebraic confidence measures like softmax scores, while TLC-Learned (TLC-L) trains an estimator to predict token correctness.- Experiments show TLC-A substantially improves compositional reasoning and verb understanding over sequence-level scores on probing tasks. TLC-L reduces object hallucination rates in COCO captions by 30% over the original model, setting a new state-of-the-art.In summary, the main contribution is demonstrating that simple token-level confidences can effectively improve caption correctness compared to existing sequence-level approaches widely used in vision-language models. TLC provides a straightforward way to enhance reliability of captioning models.
