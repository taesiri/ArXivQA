# [DP-TabICL: In-Context Learning with Differentially Private Tabular Data](https://arxiv.org/abs/2403.05681)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Large language models (LLMs) can perform in-context learning (ICL) where they are conditioned on natural language demonstrations to adapt to new domains without requiring costly model retraining. 
- Recent works have shown tabular data can also be used in ICL by serializing records into text. 
- However, tabular data often contains sensitive information and LLMs can leak information from prompts. Thus, protecting privacy of tabular data used in ICL is critical.

Proposed Solution:
- The paper proposes two differentially private (DP) frameworks to generate private tabular demonstration examples for ICL:
  1) Local DP Tabular ICL (LDP-TabICL): 
     - Uses randomized response for local DP data collection
     - Reconstructs population distribution from collected noisy data
     - Samples reconstructed records as demonstrations
  2) Global DP Tabular ICL (GDP-TabICL):  
     - Assumes trusted curator
     - Uses Poisson sampling and Laplace mechanism to craft differentially private aggregates as demonstrations

Main Contributions:
- First work to consider preserving privacy of tabular data used for in-context learning with LLMs
- Proposes LDP-TabICL and GDP-TabICL methods to generate private tabular demonstrations for ICL
- Empirically evaluates DP-TabICL methods on 8 tabular datasets with varying ICL settings
- Shows DP-TabICL can protect privacy while achieving reasonable accuracy, especially under high privacy regimes
- Analyzes tradeoffs between LDP-TabICL and GDP-TabICL methods
