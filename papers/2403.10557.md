# [Second-Order Information Matters: Revisiting Machine Unlearning for   Large Language Models](https://arxiv.org/abs/2403.10557)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Large language models (LLMs) like ChatGPT are being rapidly developed and deployed, but issues around privacy leakage and copyright violations of their training data remain underexplored. For example, the Times recently sued OpenAI for using millions of its articles to train models without permission. From a practitioner's view, handling such unintended privacy violations can be challenging during a model's lifecycle. While retraining from scratch ensures data removal, it is extremely computationally expensive for large models. Thus, efficient "unlearning" methods are needed to modify LLMs to forget certain training data.  

Prior unlearning methods using first-order gradient information have limitations around robustness, generalization or overheads like data/model engineering. This motivates exploring the role of second-order information for more robust unlearning of LLMs.

Proposed Solution:
The paper proposes two unlearning algorithms - Fisher Removal and Fisher Forgetting, inspired by Newton's method. Both rely on approximating the Hessian (second-order information) efficiently at scale using the Woodbury formula.

Fisher Removal aggressively updates model parameters to erase the target data more strongly than gradient ascent, while better maintaining overall utility. Fisher Forgetting perturbs neurons with Gaussian noise for a gentler erasure that preserves accuracy over multiple unlearning cycles.

Contributions:
1) Introduces two novel Hessian-based unlearning strategies and shows second-order information enables more robust outcomes than using gradients alone.

2) Extensively benchmarks capabilities on 4 NLP datasets and 2 real-world datasets. Open-sources code for reproducibility. 

3) Discovers DP-SGD does not provide an optimal privacy-utility trade-off universally, implying it cannot wholly replace unlearning.

4) Discusses limitations of computational overhead in estimating Hessians and directions for improvements in future work.
