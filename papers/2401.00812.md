# [If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code   Empowers Large Language Models to Serve as Intelligent Agents](https://arxiv.org/abs/2401.00812)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper provides a comprehensive survey on how code empowers large language models (LLMs) to serve as intelligent agents (IAs) for complex tasks. It explores three key ways that integrating code into LLM training enhances their capabilities:

1) Code boosts LLM performance in programming, reasoning, and capturing structured knowledge:

- Programming: Code pretraining strengthens LLMs' ability to generate high-quality code, evaluate code, and enables collaborative coding between multiple LLM agents to solve complex programming problems.

- Reasoning: Code's logical, step-by-step structure enhances LLMs' chain-of-thought prompting for decomposing tasks. Translating tasks into executable code (program-of-thought) further improves performance in mathematical and logical reasoning.  

- Structured Knowledge: Code's features like variable typing and inheritance aid LLMs in structural commonsense reasoning. Understanding markup code also evolves LLMs' ability for visually situated language understanding.

2) Code connects LLMs to diverse function ends: 

The code-centric paradigm, where LLMs generate code to invoke functions, provides a scalable way to integrate LLMs with external tools across modalities (text, vision, audio etc.) and physical environments (robots, vehicles). This expands the scope of tasks LLMs can perform.

3) Code situates LLMs in an executable environment for automated feedback:

The deterministic nature of code execution enables creating test suites, conducting static analysis and generating rich feedback to enhance LLMs through selection, prompting or fine-tuning.

Additionally, the paper analyzes how code-empowered LLMs facilitate more capable IAs by:
i) enhancing perception, planning for decision making 
ii) enabling seamless action grounding, modular memory organization for execution
iii) leveraging automated feedback from code execution for self-improvement.

Finally, open challenges around causally quantifying code's influence on reasoning, exploring complementary training modalities, applying code scalably, and optimally utilizing multi-step feedback are discussed.
