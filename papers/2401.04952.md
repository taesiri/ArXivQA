# [Can AI Write Classical Chinese Poetry like Humans? An Empirical Study   Inspired by Turing Test](https://arxiv.org/abs/2401.04952)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: There is an ongoing debate about whether AI can mimic human creativity and sentiments like poetry writing. This paper focuses on answering the question - can AI compose poetry as well as humans? However, evaluating the quality of poetry is highly subjective. So the authors propose a new perspective of evaluating based on indistinguishability rather than quality.

Proposed Solution: The authors propose a new evaluation framework called "ProFTAP" (Probabilistic Feigenbaum Test for AI-generated Poetry) inspired by the Turing test. In this framework, human judges assign a probability score (0 to 1) indicating how likely a poem is written by a real human, without knowing the actual author. Poems by both humans and AIs are mixed and evaluated. The AUC score from ROC analysis indicates the similarity of AI poems to human poems. The lower the AUC, the more indistinguishable the AI poem is from human poems.

Experiments: The framework is applied to evaluate several state-of-the-art LLMs on composing classical Chinese poems. A new finetuned model "Qwen-72B-Poet" is also assessed. Statistical analysis shows Qwen-72B-Poet produces poems with no significant difference from human poems in terms of distinguishability, indicating its capability of generating human-like poems.

Main Contributions:
1) Proposing the ProFTAP framework to evaluate AI's poetry generation capability more objectively and rigorously. 
2) Revealing the classical Chinese poetry generation capabilities of current major LLMs.
3) Showing that finetuned open-source LLMs can outperform GPT-4 and write near indistinguishable poems from ancient Chinese poets.

In summary, this paper proposes a new perspective for AI poetry evaluation based on indistinguishability from humans, and shows the potential of current AI in mimicking human creativity through an empirical study on classical Chinese poetry generation. The ProFTAP framework could enable more objective assessments in the future.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a new evaluation framework inspired by Turing test to assess AI's ability to write classical Chinese poetry indistinguishable from humans, applies it to major language models, and shows that fine-tuned models can generate poems nearly indistinguishable from ancient poets.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing a new evaluation framework called ProFTAP (Probabilistic Feigenbaum Test for AI-generated Poetry) for evaluating AI's poetry generation capability. This framework is inspired by Turing test and relies on distinguishability to measure how similar AI-generated poems are to human-authored ones.

2. Applying ProFTAP to evaluate major current large language models on their ability to write classical Chinese poetry. The results reveal the capabilities and limitations of these models in this task. 

3. Showing that finetuned open-source large language models can outperform GPT-4 on classical Chinese poetry generation. Specifically, the authors' finetuned model Qwen-72B-Poet can generate poems nearly indistinguishable from those written by ancient Chinese poets.

So in summary, the key innovation is proposing the ProFTAP evaluation framework, while the main findings are revealing the poetry generation capabilities of current AI models, with finetuned open-source LLMs demonstrating performance on par with humans.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Classical Chinese poetry generation - The main focus of the paper is evaluating AI models' ability to generate classical Chinese poetry.

- Turing Test - The proposed evaluation framework, ProFTAP, is inspired by the Turing test to assess poetry generation systems. 

- Distinguishability - Rather than defining what makes a "good" poem, the paper uses indistinguishability from human-written poems as the evaluation criteria.  

- Large language models (LLMs) - The paper experiments with various LLMs like GPT-3.5, GPT-4, Qwen-72B-Chat to test their poetry generation capability.

- Finetuning - The paper shows that finetuning an open-source LLM can outperform even GPT-4 in generating poems indistinguishable from ancient Chinese poets' works.

- Evaluation methods - The paper compares existing poetry evaluation approaches and proposes the advantages of using ProFTAP over methods like human rating scales or automated metrics.

- Statistical analysis - Statistical tests like AUC and Wilcoxon signed-rank test are used to quantitatively compare human and AI poem distinguishability.

Does this summary cover the main keywords and concepts discussed in the paper? Let me know if you need any clarification or have additional keywords to add.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a new evaluation framework called ProFTAP. What are the key advantages of this framework compared to previous evaluation methods for AI-generated poetry?

2. The paper applies ProFTAP to assess the classical Chinese poetry generation capabilities of several language models. What were the key findings in terms of which models performed best on this task? 

3. The paper argues that current LLMs possess the ability to write classical Chinese poems nearly indistinguishable from those authored by ancient Chinese poets. What evidence supports this conclusion? What counter-arguments could be made?

4. The paper finds that open-source LLMs can outperform proprietary models like GPT-4 on this task when fine-tuned properly. What explanations are given for this result? How might GPT-4 be improved?  

5. How exactly does the ProFTAP framework operate? Walk through the key steps involved and highlight aspects that make it more objective and rigorous compared to prior evaluation methods.

6. The paper analyzes how factors like line length and character repetition impact the perceived quality of AI-generated poems. Summarize the key findings here. How might these insights inform future research?

7. What were the key components of the training process used to create the Qwen-72B-Poet model evaluated in the paper? What architectural choices and hyperparameters were most important?

8. The paper provides two sample poems generated by Qwen-72B-Poet. Critically analyze these examples - what qualities suggest they could be written by humans? What flaws remain?  

9. The paper focuses exclusively on classical Chinese poetry. How might the ProFTAP framework be adapted to evaluate freeform modern poetry generation by AIs? What additional challenges might arise?

10. The paper claims current LLMs have room for improvement in mimicking human poetry writing abilities. What specific limitations of existing models does it identify? What remedies does it propose for future work?
