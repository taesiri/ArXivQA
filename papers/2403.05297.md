# [PEEB: Part-based Image Classifiers with an Explainable and Editable   Language Bottleneck](https://arxiv.org/abs/2403.05297)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Existing fine-grained image classifiers for domains like bird species suffer from four key limitations: (1) They are inherently black-box models without built-in explainability. (2) Some claim explainability by learning prototypes or concepts but these are not editable or interpretable by humans. (3) Textual concept-based models operate at the image level so it's unclear what visual details match the text. (4) Most models require training images or demonstration images. 

Proposed Solution: The paper proposes PEEB - an explainable and editable fine-grained bird classifier. PEEB expresses the class name into a set of pre-defined textual descriptors of the visual parts of that bird species. It then matches the visual embeddings of detected parts in the input image to the textual embeddings of descriptors in each class to compute a classification score. This allows it to classify images of new species specified only by the textual descriptors, without needing any training images.

Key Contributions:

(1) Shows CLIP classifiers rely heavily on class names - accuracy drops 10x when names are removed or replaced.

(2) Proposes a novel part-based architecture with textual descriptors that outperforms CLIP classifiers by 8-29% on CUB/NABirds/iNat.

(3) Outperforms recent text concept-based classifiers that use pre-defined concepts, highlighting the power of editable domain-specific descriptors.

(4) Achieves state-of-the-art 88.8% accuracy among explainable CUB classifiers using supervised learning, competitive with the best CUB classifiers.

(5) Allows defining new classes textually at test time without re-training. Demonstrates this by editing descriptors of an unseen bluebird species to correctly classify it.

(6) Releases Birds-11K, an unprecedentedly large dataset of 440K images spanning 11K bird species collected from 7 sources and annotated with textual part descriptors automatically generated by GPT-4.
