# [Rule or Story, Which is a Better Commonsense Expression for Talking with   Large Language Models?](https://arxiv.org/abs/2402.14355)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Incorporating commonsense into AI systems has been a long-standing challenge, due to the reporting bias (commonsense is rarely stated explicitly) and exposure bias (reasoning steps are often omitted) in human language.  
- Commonsense is typically represented as structured rules, but humans acquire and convey commonsense more implicitly through stories. This raises the question - which is a better expression for retrieving and leveraging commonsense from large language models (LLMs) - rules or stories?

Methodology:
- Systematically compare stories and rules for:
  - Retrieving commonsense knowledge from LLM memory
  - Leveraging commonsense to answer questions across 28 QA datasets
- Generation: Instruct LLM to generate stories and rules based on questions
- Evaluation: Assess confidence (perplexity) and accuracy of generated commonsense
- QA: Provide stories or rules as context for answering questions 

Key Findings:
- Stories result in more confident and accurate commonsense generation from LLM memory
- Stories more effective for reasoning about daily events, rules better for scientific questions
- Stories and rules complement each other - combining them improves QA accuracy 
- Identified two key issues in generated stories: hallucination and semantic drifting
- Proposed iterative self-supervised fine-tuning to improve quality of generated stories

Main Contributions:
- First study investigating effects of using stories vs rules to talk to LLMs about commonsense
- Shows stories are better for retrieving commonsense, rules complement for reasoning
- Reveals issues in commonsense stories generated by LLMs
- Proposes method to improve quality of commonsense stories from LLMs
- Emphasizes importance of using appropriate language to exploit commonsense abilities of LLMs

The summary covers the key points on the problem being addressed, the approach taken, major findings, and main contributions of the paper. It describes the comparisons between rules and stories for commonsense in a way that provides clarity to the reader on what this paper has presented.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper systematically compares stories and rules as expressions for retrieving and leveraging commonsense knowledge in large language models, finding that stories are more effective for accessing commonsense about daily events while rules work better for scientific knowledge, and the two expressions complement each other.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It systematically investigates and compares the effects of using stories and rules as commonsense expressions for retrieving and leveraging commonsense in large language models (LLMs). To the authors' knowledge, this is the first study to investigate the effects of specific commonsense expressions in LLMs. 

2. It shows that stories are a more effective expression for retrieving commonsense from LLMs and for leveraging commonsense in answering questions regarding daily events.

3. It identifies two main issues that hinder commonsense story generation by LLMs: commonsense hallucination and semantic drifting. It proposes an iterative self-supervised fine-tuning method to address these issues and improve the accuracy and relevance of stories generated by LLMs.

In summary, this paper provides new insights into using appropriate language to express, retrieve and leverage commonsense for LLMs, emphasizing stories over rules, and highlights a promising direction for better exploiting the commonsense abilities of LLMs.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and keywords related to this research include:

- Large language models (LLMs) - The paper focuses on analyzing and comparing the abilities of popular LLMs like ChatGPT, Alpaca, and Vicuna.

- Commonsense - A core theme of the paper is investigating the commonsense abilities of LLMs, including commonsense retrieval and reasoning.

- Stories vs rules - The paper systematically compares stories and rules as expressions for retrieving and leveraging commonsense knowledge from LLMs. 

- Reporting bias - The paper discusses how the reporting bias of commonsense in text corpora impacts the abilities learned by LLMs.

- Exposure bias - Another key term is the exposure bias in commonsense reasoning with explicit rules.

- Commonsense QA - The paper employs 28 commonsense QA datasets spanning different domains for analysis.

- Iterative self-supervised fine-tuning - A method proposed to improve the quality and relevance of commonsense stories generated by LLMs.  

- Semantic drifting - One of the main issues identified in analyzing generated stories that hinders commonsense QA performance.

- Commonsense hallucination - Another primary issue occurs when LLMs generate stories that do not conform to commonsense.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes an iterative self-supervised fine-tuning (self-SFT) method to improve the quality of stories generated by large language models. How exactly does this method work in terms of the generating, filtering, and training steps? What are the key ideas behind each step?

2. In the filtering step of the self-SFT method, the paper uses two scores - a commonsense score and a BERT similarity score - to select high-quality stories. Why are both scores necessary? What specific issues does each score help mitigate? 

3. The self-SFT method shows improved performance on unseen datasets after the first iteration of training. What does this suggest about the method's ability to generalize? How might the model start to overfit in later iterations?

4. The paper identifies two key issues in generated stories - commonsense hallucination and semantic drifting. How prevalent are these issues based on the error analysis? What percentages of errors do they account for?

5. What correlations exist between the accuracy of question answering and the two scores (commonsense score and BERT similarity score) used to assess story quality? What do these correlations indicate about the influence of the scores?  

6. In analyzing datasets involving negation, what disparity does the paper find regarding the model's ability to handle negation within commonsense? What might cause this disparity?

7. What differences does the paper find between story and rule expressions when evaluating scientific vs daily event common sense? How might this relate to reporting bias in the training corpora?

8. Across the 28 datasets analyzed, how many show improved accuracy when using both story and rule expressions compared to using either one alone? What might this highlight about the unique strengths of each expression?

9. Based on the ablation study of the self-SFT method, what can be concluded about the necessity of the iterative scoring and filtering mechanism? How does removing this component impact performance?

10. In analyzing the influence of different filter ratios used for selecting training stories, what optimal value for the ratio does the paper find? How might filter ratios that are too high or too low impact accuracy?
