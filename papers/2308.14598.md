# [S-TREK: Sequential Translation and Rotation Equivariant Keypoints for   local feature extraction](https://arxiv.org/abs/2308.14598)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we design a deep learning-based local feature extractor that is robust to in-plane image rotations?The key hypothesis appears to be:By combining a rotation equivariant keypoint detector with a lightweight descriptor network trained in a "detect then describe" manner, we can obtain a local feature extractor that achieves state-of-the-art performance, especially on images with significant in-plane rotations.In particular, the paper proposes a new method called S-TREK that has the following key components:- A keypoint detector based on rotation equivariant convolutions, making the detections robust to in-plane rotations by design.- A training framework inspired by reinforcement learning to directly optimize repeatability of keypoints.- A sequential sampling strategy to extract probabilistic keypoints during training.- A separate lightweight descriptor network trained only on detected keypoints.The central hypothesis is that by designing the detector to be rotation equivariant, optimizing it directly for repeatability, and decoupling it from the descriptor learning, S-TREK can outperform prior feature extraction methods, especially in the presence of in-plane rotations. The experiments then aim to validate this hypothesis.In summary, the key research question is how to develop a feature extractor robust to in-plane rotations, with the central hypothesis being that the proposed S-TREK approach can achieve this. The paper aims to demonstrate and evaluate this hypothesis.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a new local feature extractor called S-TREK, which combines:- A deep keypoint detector that is translation and rotation equivariant, trained with a reinforcement learning inspired framework to directly maximize repeatability. - A lightweight deep network for extracting descriptors at the detected keypoints.The key aspects of S-TREK are:- The keypoint detector uses rotation equivariant convolutions to achieve robustness to in-plane rotations. It is trained with a novel sequential sampling procedure and reward formulation to maximize repeatability.- The descriptor network is trained in a "detect, then describe" manner after the detector is trained, focusing only on the detected keypoint locations.- The overall pipeline follows a detect, then describe paradigm with specialized networks for each task. This allows designing the keypoint detector with small receptive field and the descriptor with very large receptive field.- Extensive experiments show S-TREK achieves state-of-the-art performance in terms of repeatability under rotations and matching performance for pose estimation, especially for images with large in-plane rotation differences.In summary, the main contribution is proposing a novel local feature extractor with a rotation equivariant keypoint detector trained directly for repeatability and a detect-then-describe pipeline tailored for accurate feature matching and pose estimation.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper introduces S-TREK, a new method for extracting repeatable and discriminative image features that combines a rotation equivariant keypoint detector trained with a reinforcement learning approach and a lightweight descriptor network.


## How does this paper compare to other research in the same field?

Here are my thoughts on how this paper compares to other research in the field of local feature extraction and matching:- The main contribution of this paper is proposing a new method (S-TREK) that combines a deep keypoint detector that is translation and rotation equivariant with a lightweight deep descriptor extractor. This is a novel approach compared to prior work.- For the keypoint detector, the use of rotation equivariant convolutions is similar to the REKD method. However, S-TREK trains the detector with a new sequential sampling procedure inspired by reinforcement learning which is different from prior training strategies like proxy losses on heatmaps.- For descriptor learning, S-TREK follows a "detect, then describe" approach using separate detector and descriptor networks. This is in contrast to recent joint detector-descriptor methods like SuperPoint, D2-Net, R2D2, etc. that share a backbone. Separating them allows optimizing the architectures.- The descriptor learning uses a standard triplet loss, similar to many prior learned descriptors (HardNet, SOSNet, etc). But a key difference is it trains on exact detected keypoints rather than dense sampling.- For evaluation, the paper shows S-TREK achieves state-of-the-art results for keypoint repeatability on HPatches and the Image Matching Benchmark, outperforming recent learned methods like SuperPoint, R2D2, DISK.- S-TREK also demonstrates particularly strong performance on rotated versions of standard benchmarks. This highlights the benefits of its rotation equivariance.Overall, I would summarize that S-TREK brings together some existing ideas like rotation equivariance and triplet loss descriptor learning, but combines them in a novel way and achieves improved results compared to prior art, especially for robustness to rotation. The reinforcement learning-based keypoint detector training also represents a new contribution.
