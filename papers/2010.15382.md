# [Learning to Actively Learn: A Robust Approach](https://arxiv.org/abs/2010.15382)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How can we design an algorithm for active data collection (e.g. active learning, bandits) that is robust and performs well even with a very small budget of samples, such as a few dozen?The key points are:- Existing algorithms rely on statistical guarantees or concentration inequalities that require a large number of samples before they start to perform well. With a budget of only 20-30 samples, these algorithms essentially just do random sampling.- The authors propose an adversarial training framework to learn a policy that competes with the best policy designed specifically for each "difficulty level" of problems. This allows it to perform optimally across easy and hard problem instances. - They use information-theoretic lower bounds to define the difficulty levels and equivalence classes of problems. The learned policy aims to minimize its worst-case gap from these theoretical optimal policies for each difficulty class.- This approach does not rely on statistical guarantees or concentration bounds, allowing it to be aggressive and perform well even with very few (e.g. 20) samples. Experiments show it outperforms existing algorithms.In summary, the key hypothesis is that adversarial training over problem difficulty classes defined by theory can produce active learning algorithms that are robust and non-vacuous even with tiny sample budgets. The experiments seem to validate this hypothesis.
