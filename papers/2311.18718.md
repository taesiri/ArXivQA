# [Steering Deep Feature Learning with Backward Aligned Feature Updates](https://arxiv.org/abs/2311.18718)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper introduces the notion of alignment between feature updates and the backward pass as a key concept for understanding, predicting, and controlling feature learning in deep neural networks. The authors define Backward Aligned Feature Updates (BAFUs) as the projection of feature updates onto the backward pass, and show they can be quantified by a simple formula involving observable quantities - feature sensitivities and weight contributions. When alignment holds, controlling BAFUs allows control over feature learning. The authors introduce tools to analyze alignment, relating it to properties of a Backward-to-Feature kernel matrix. Well-conditioned layer-to-layer Jacobians (dynamical isometry) are shown to guarantee alignment. Practical criteria called FSC are proposed to predict good training steps, and can be enforced by novel techniques for adaptive learning rates and forward/backward normalization. The large width/depth limit of MLPs and ResNets is studied, finding that alignment degenerates with depth in MLPs, while ResNets maintain non-trivial alignment. Overall, the notion of alignment provides new theoretical and practical tools for understanding, predicting and controlling feature learning in deep networks.


## Summarize the paper in one sentence.

 This paper introduces the notion of alignment between feature updates and the backward pass in neural networks, and uses it to predict, measure, and control hierarchical feature learning during training.


## What is the main contribution of this paper?

 This paper makes several key contributions related to understanding and controlling feature learning in deep neural networks:

1. It introduces the concept of "backward-aligned feature updates" (BAFUs) which measure the component of the feature updates that is aligned with the backward pass during training. This allows separating the difficulty of understanding feature learning into (i) quantifying alignment and (ii) quantifying BAFUs.

2. It provides a formula (Theorem 1) that expresses BAFUs in terms of easily observable quantities - the sensitivities and contributions. This allows measuring and controlling BAFUs during training.

3. It proposes the FSC criteria - pertaining to forward pass, sensitivities, contributions, and alignment - that guarantee stable and aligned feature learning when satisfied. It also suggests an FSC control method to automatically enforce some FSC criteria.

4. It studies alignment theoretically, relating it to the spectrum of the "backward-to-feature kernel" at initialization (Theorem 2). It also shows alignment is related to dynamical isometry.

5. It investigates alignment in large width-then-depth limits of MLPs and ResNets. A key finding is that the $1/\sqrt{\text{depth}}$ branching in ResNets is critical for non-trivial alignment, while alignment vanishes in plain MLPs.

In summary, the paper develops the theory and tools (especially BAFUs and FSC criteria) to better understand, predict and control feature learning in deep networks.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Backward-Aligned Feature Updates (BAFU): The projection of the feature updates onto the backward pass during backpropagation. Allows measuring and controlling the magnitude of feature updates.

- Backward Feature Angle (BFA): The angle between the feature updates and backward pass. Quantifies the alignment between them. 

- Forward pass contributions/sensitivities: Measures of the forward pass signals that are used to characterize feature learning via the BAFU formula.

- Forward-Sensitivities-Contributions-Alignment (FSCA) criteria: A set of criteria/desiderata proposed to enable stable and aligned feature learning in neural networks. Used to derive techniques like FSC control.

- Alignment: The general concept of having feature updates aligned with the backward pass signals. Used as an indicator of good feature learning.

- Dynamical isometry: Related concept of having well-conditioned Jacobian matrices. Shown to imply alignment in certain cases.

- Backward to Feature Kernel (BFK): Kernel operator that captures how backward pass signals get transformed into feature updates. Its spectrum characterizes alignment.

- Large width/depth analysis: Asymptotic analysis techniques used to study properties like alignment in infinitely wide or deep neural nets. Applied to MLPs and ResNets.

So in summary, key terms are BAFU, BFA, FSCA, alignment, dynamical isometry, BFK which are used to analyze and control feature learning in neural networks.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper introduces the concept of Backward-Aligned Feature Updates (BAFUs). What is the intuition behind this concept and how does it allow predicting, measuring and controlling feature learning in neural networks?

2. Explain in detail how the formula relating BAFUs to weight matrix contributions and feature sensitivities is derived. What assumptions does the derivation rely on?

3. The paper argues that alignment between feature updates and the backward pass is a key notion for hierarchical feature learning. Elaborate on why alignment is important and what would happen with too much or too little alignment. 

4. Describe what the Backward to Feature Kernel (BFK) represents and how its spectrum characterizes alignment between feature updates and backward pass. What does a spread out spectrum correspond to?

5. Explain the proposed technique of FSC-control for automatically enforcing some of the desiderata, including the forward layer normalization and backward layer normalization aspects. How do these connect to common techniques like layer normalization?

6. In the analysis of ResNets, the paper identifies the $1/\sqrt{\text{depth}}$ branch scaling as the only one that maintains non-trivial alignment at infinite depth. Intuitively explain why this specific scaling leads to favorable alignment properties.  

7. What differences are observed in the large width-depth limit between MLPs and ResNets regarding alignment and the ability to start training? How do the theoretical predictions connect with practical observations?

8. The desiderata in the paper are related but not identical to the previously proposed "maximal update" Î¼-criteria. What are some notable differences and what new perspective does the desiderata in this paper provide?

9. Discuss the generalizability of the proposed analysis based on BAFUs and alignment to other neural network architectures beyond MLPs and ResNets. What components of the theory could break down in other models like Transformers?

10. The paper leaves open several questions for future work. Select one such open question and suggest how you might theoretically or experimentally make progress on addressing it.
