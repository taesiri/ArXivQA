# [Strip-MLP: Efficient Token Interaction for Vision MLP](https://arxiv.org/abs/2307.11458)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we design an efficient token interaction operation to improve the performance of MLP-based vision models?

Specifically, the authors identify a issue they term "the Token's interaction dilemma" - where the power of token interaction decreases in later layers as the spatial resolution is downsampled. To address this, the paper introduces a new MLP architecture called Strip-MLP with the following key components:

- Strip MLP layer - Allows tokens to interact in a cross-strip manner rather than just within rows/columns. This enriches the token interactions.

- Cascade Group Strip Mixing Module (CGSMM) - Splits features into patches and allows cross-patch token interactions, making it robust to smaller spatial sizes. 

- Local Strip Mixing Module (LSMM) - Captures local interactions more efficiently with a small Strip MLP.

Together, these components aim to improve the token interaction capabilities and power of MLP-based vision models, even as the spatial resolution decreases in deeper layers. The central hypothesis is that this will lead to improved performance on image classification tasks compared to prior MLP architectures.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper seem to be:

- Proposing a new MLP architecture called Strip-MLP to improve the token interaction power in vision MLP models. The key ideas include:

1) Strip MLP layer - Allows tokens to interact in a cross-strip manner, enabling each row/column to contribute differently to other rows/columns.

2) Cascade Group Strip Mixing Module (CGSMM) - Splits features into patches and allows cross-patch token interactions, making it robust to small spatial sizes. 

3) Local Strip Mixing Module (LSMM) - Captures local interactions more efficiently.

- Showing through experiments that Strip-MLP models achieve much better performance than other MLP models on small datasets like Caltech-101 and CIFAR-100.

- Demonstrating that Strip-MLP can achieve comparable or better accuracy than CNN and Transformer models on ImageNet with fewer parameters and FLOPs.

In summary, the key contribution appears to be proposing the Strip-MLP architecture that enriches token interactions in MLPs through strip-wise processing and patching, leading to accuracy gains especially on small datasets. The ablation studies seem to validate the design choices as well.
