# [Does AI help humans make better decisions? A methodological framework   for experimental evaluation](https://arxiv.org/abs/2403.12108)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- There is increased use of AI systems to provide recommendations to human decision-makers in high-stakes domains like criminal justice, medicine, etc. However, it is unclear if AI recommendations actually help humans make better decisions compared to humans alone or the AI system alone.  

- Evaluating this is challenging due to the "selective labels problem" - humans make the final decisions, so we don't observe the counterfactual outcomes for decisions not taken. For example, if a judge detains a defendant, the outcome if they were released is not observed.

Proposed Solution:
- The authors propose an experimental framework to evaluate human, AI-assisted human, and AI-alone decision-making systems. 

- They model the decision problem as a classification task using potential outcomes and standard performance metrics like misclassification rate.

- They consider an RCT where AI recommendations are randomly provided to human decision-makers in a blinded manner. This allows identifying the effect of AI recommendations on human decisions.

- They derive statistical bounds to compare AI-alone decisions to human and AI-assisted human decisions without needing an AI-alone experiment arm.

Contributions:
- Identification results showing the effect of AI on human decisions can be point-identified, while differences between AI and human decisions can be partially identified.

- Application to a bail decision RCT shows AI recommendations do not improve judge decisions, and AI alone tends to have more false positives (harsher decisions) than humans.

- Analysis shows humans tend to be preferred to AI when false positives are more costly, and AI yields more false positives for non-white defendants.

- Overall, provides an experimental framework to rigorously compare human, aided human, and AI decision-making ability. Demonstrates need to empirically evaluate AI integration rather than assume it will improve decisions.
