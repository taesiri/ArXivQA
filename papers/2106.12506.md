# [Sampling with Mirrored Stein Operators](https://arxiv.org/abs/2106.12506)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we develop particle evolution sampling algorithms that are suitable for target distributions with constrained domains and non-Euclidean geometries?The key points are:- Standard particle evolution methods like Stein Variational Gradient Descent (SVGD) can fail or be inefficient for constrained distributions or when the geometry is non-Euclidean. - The authors propose new sampling algorithms based on "mirrored Stein operators" that map particles to a dual space, evolve them there, and then map back while preserving constraints and encoding geometry.- Specifically, they introduce Mirrored SVGD, Stein Variational Mirror Descent, and Stein Variational Natural Gradient algorithms. The first handles constraints, the second also reduces to mirror descent with one particle, and the third exploits non-Euclidean geometry.- They analyze the convergence properties of these methods and demonstrate their effectiveness on problems like sampling from simplex-constrained distributions, constructing confidence intervals under post-selection inference, and large-scale Bayesian logistic regression.So in summary, the main research question is how to develop particle-based sampling algorithms suitable for constrained and non-Euclidean settings where standard methods fail or are inefficient. The core innovation is the introduction and application of mirrored Stein operators.


## What is the main contribution of this paper?

This paper introduces a new family of particle evolution samplers suitable for constrained domains and non-Euclidean geometries. The main contributions are:1. It develops two new algorithms called Mirrored Stein Variational Gradient Descent (MSVGD) and Stein Variational Mirror Descent (SVMD) for sampling from constrained distributions. These algorithms perform updates in a "mirrored" dual space defined by a mirror map, which ensures the samples always satisfy the constraints after mapping back. 2. It introduces a new class of mirrored Stein operators that underlie the updates in the dual space. These operators satisfy a generalized Stein identity that enables decreasing the KL divergence to constrained target distributions.3. It proposes Stein Variational Natural Gradient (SVNG) which exploits non-Euclidean geometry through the use of adaptive kernels incorporating metric tensors like the Fisher information matrix. This allows more efficient sampling from unconstrained targets.4. It provides convergence guarantees for the new samplers, relating the decrease in KL divergence to the novel mirrored Stein discrepancies.5. It demonstrates the benefits of the new methods over standard SVGD on benchmark problems involving sampling from distributions on the simplex, performing valid post-selection inference, and large-scale Bayesian logistic regression.In summary, the key innovation is the development of mirrored Stein operators and associated sampling algorithms that can handle constraints and non-Euclidean geometry, overcoming limitations of previous methods like standard SVGD. The theoretical analysis and experiments demonstrate the advantages of the new techniques.
