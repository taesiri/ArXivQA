# [For self-supervised learning, Rationality implies generalization,   provably](https://arxiv.org/abs/2010.08508)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is:Can we prove non-vacuous generalization bounds for classifiers obtained by self-supervised pre-training followed by fitting a simple classifier?Specifically, the paper considers a class of methods it calls "Self-Supervised + Simple" (SSS) algorithms, which have two phases:1) Self-supervised pre-training to learn a representation of the data. This uses the training data but no labels.2) Fitting a simple (e.g. linear) classifier on top of the learned representation, using the labels. The central question is whether we can prove bounds on the generalization gap (difference between train and test accuracy) for SSS algorithms, even though they use highly complex models in the pre-training phase. The key contributions in service of this goal are:- Decomposing the generalization gap into robustness, rationality, and memorization components.- Proving a bound on the memorization gap that depends only on the complexity of the simple classifier, not the pre-trained representation.- Empirically evaluating the decomposition on real SSS algorithms, showing the bound is often non-vacuous.So in summary, the main research question is about proving generalization guarantees for complex SSS algorithms by exploiting the simplicity of their final classifier.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:1. Introducing the RRM decomposition of the generalization gap into robustness, rationality, and memorization components.2. Proving an upper bound on the memorization gap for self-supervised + simple (SSS) learning algorithms that depends only on the complexity of the simple classifier, not the representation. 3. Empirically evaluating the robustness, rationality, and memorization gaps across various SSS algorithms on CIFAR-10 and ImageNet. The results show the RRM bound is often tight and non-vacuous.4. Demonstrating that the memorization gap upper bound yields reasonable generalization bounds for SSS algorithms on CIFAR-10 and ImageNet.5. Proving the "performance on the table" theorem that says positive rationality gap implies room for improvement in test accuracy.6. Providing evidence that SSS algorithms have better generalization behavior than standard supervised learning, e.g. lower ability to fit random labels.In summary, the paper introduces a new decomposition of generalization gap and uses it to theoretically and empirically analyze self-supervised learning algorithms. The key novelty is bounding the memorization gap independently of the representation complexity. Overall, this provides evidence for the advantages of SSS algorithms compared to end-to-end supervised learning.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on my reading of the paper, here is a one sentence summary:The paper proves a new upper bound on the generalization gap of classifiers obtained by first using self-supervision to learn a data representation, and then fitting a simple classifier; the bound depends only on the complexity of the simple classifier, not the representation.
