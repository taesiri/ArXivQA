# [For self-supervised learning, Rationality implies generalization,   provably](https://arxiv.org/abs/2010.08508)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is:Can we prove non-vacuous generalization bounds for classifiers obtained by self-supervised pre-training followed by fitting a simple classifier?Specifically, the paper considers a class of methods it calls "Self-Supervised + Simple" (SSS) algorithms, which have two phases:1) Self-supervised pre-training to learn a representation of the data. This uses the training data but no labels.2) Fitting a simple (e.g. linear) classifier on top of the learned representation, using the labels. The central question is whether we can prove bounds on the generalization gap (difference between train and test accuracy) for SSS algorithms, even though they use highly complex models in the pre-training phase. The key contributions in service of this goal are:- Decomposing the generalization gap into robustness, rationality, and memorization components.- Proving a bound on the memorization gap that depends only on the complexity of the simple classifier, not the pre-trained representation.- Empirically evaluating the decomposition on real SSS algorithms, showing the bound is often non-vacuous.So in summary, the main research question is about proving generalization guarantees for complex SSS algorithms by exploiting the simplicity of their final classifier.
