# [Mean-Shifted Contrastive Loss for Anomaly Detection](https://arxiv.org/abs/2106.03844)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we improve anomaly detection performance by transferring representations pre-trained on large external datasets and adapting them to the anomaly detection task?Specifically, the paper investigates how to effectively fine-tune pre-trained image representations like those from ImageNet classification for one-class classification anomaly detection. The authors find that standard contrastive learning objectives are poorly suited for this adaptation task when initialized with pre-trained weights. They propose a new objective called the Mean-Shifted Contrastive (MSC) loss that overcomes the limitations of standard contrastive loss and enables effective transfer of pre-trained representations to anomaly detection. The main hypothesis is that the MSC loss will achieve better performance on anomaly detection benchmarks compared to prior methods.In summary, the key research question is how to properly adapt powerful pre-trained representations like ImageNet classifiers to the one-class setting for improved anomaly detection, with a focus on making contrastive learning work effectively in this setup. The MSC loss is introduced as a solution for this transfer learning challenge.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a new objective function called the Mean-Shifted Contrastive (MSC) loss for improving anomaly detection with deep learning. The key ideas are:- Analyzing why standard contrastive losses fail when fine-tuning ImageNet pre-trained features for anomaly detection, due to poor conditioning of the optimization. - Proposing the MSC loss as an alternative contrastive objective that is better suited for adapting pre-trained features for anomaly detection. The MSC loss evaluates sample similarity in a coordinate frame centered around the mean of the features rather than the origin. - Showing that the MSC loss outperforms prior self-supervised and pre-training based anomaly detection methods, achieving state-of-the-art results on standard benchmarks like CIFAR-10.In summary, the main contribution is identifying limitations of standard contrastive losses for anomaly detection with pre-trained features, and developing a tailored contrastive objective (MSC) that overcomes these limitations and advances the state-of-the-art. The analysis and new technique specifically target the problem of effectively adapting pre-trained representations for anomaly detection.
