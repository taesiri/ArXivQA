# [MoVQA: A Benchmark of Versatile Question-Answering for Long-Form Movie   Understanding](https://arxiv.org/abs/2312.04817)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

The paper introduces MoVQA, a new long-form movie question-answering dataset and benchmark for assessing models on long-term video understanding. MoVQA contains 21,953 manually annotated QA pairs from 100 movies covering diverse genres. The questions are designed to assess capabilities on various perceptual and cognitive abilities from a moviegoer's perspective. 

A key feature of MoVQA is the multi-level temporal lengths of the video clips used, including single-scene (median length 7.5 minutes), multi-scene (20 minutes) and full-scene (120 minutes). This allows benchmarking models on increasing levels of difficulty. The median clue length is around 230 seconds, over 2x longer than prior datasets. 

The questions are categorized into six types - information synopsis, temporal perception, spatial perception, causal reasoning, hypothetical reasoning and use of external knowledge. This combination allows comprehensive assessment of both perceptual and cognitive skills for movie understanding.

The paper benchmarks several state-of-the-art videoQA and multimodal models on MoVQA and finds unsatisfactory performance, with ample scope for improvement. It also proposes a baseline model combining dynamic keyframe selection and contextual modeling which achieves new state-of-the-art results. Overall, MoVQA incentivizes developing models with human-level understanding of long videos.
