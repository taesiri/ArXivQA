# [Example-based Motion Synthesis via Generative Motion Matching](https://arxiv.org/abs/2306.00378)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the abstract, the key points of this paper seem to be:- It presents a new generative model called GenMM for synthesizing diverse motions from limited example sequences. - In contrast to existing data-driven methods, GenMM does not require long offline training, is less prone to artifacts, and works on complex skeletons.- GenMM is inspired by motion matching, inheriting its training-free nature and motion quality, but injects generative capabilities using ideas from image synthesis like bidirectional similarity and multi-stage refinement.- It can synthesize high-quality motions in a fraction of a second, even for very large and complex skeletons with hundreds of joints.- Beyond basic motion generation, GenMM is versatile and can be extended to tasks like motion completion, keyframe-guided synthesis, infinite looping, and motion reassembly.So in summary, the central hypothesis seems to be that by adapting motion matching with concepts from image synthesis like bidirectional similarity and progressive refinement, they can create a powerful generative model for high-quality and diverse motion synthesis from limited data, without requiring lengthy training. The experiments then aim to validate this approach across different tasks and skeleton complexities.
