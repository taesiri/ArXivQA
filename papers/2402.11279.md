# [Multi-Perspective Consistency Enhances Confidence Estimation in Large   Language Models](https://arxiv.org/abs/2402.11279)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Accurate confidence estimation is critical for assessing the credibility of large language model (LLM) predictions. However, existing methods often fail to overcome the issue of overconfidence on incorrect answers. 

Proposed Solution - Multi-Perspective Consistency (MPC):
- Leverages complementary insights from different perspectives within models (MPC-Internal) and across different models (MPC-Across) to mitigate overconfidence arising from a singular viewpoint.

MPC-Internal:  
- Prompts LLM to reconsider questions from a verifier's perspective to identify inconsistent answers.  
- Mitigates overconfidence when generated answers are inconsistent across the reasoning vs verification perspectives.

MPC-Across:
- Utilizes stronger perturbations by fusing answers and confidence scores from different models. 
- Alleviates overconfidence stemming from stubborn biases of the main LLM.

Main Contributions:
- Propose using multi-perspective consistency to alleviate overconfidence in LLM confidence estimation.
- Introduce MPC-Internal and MPC-Across approaches that provide complementary benefits.
- Demonstrate state-of-the-art performance across 8 datasets. Show ability to mitigate overconfidence issues and easily extend to other models.

In summary, the paper introduces a novel MPC framework to improve LLM confidence estimation by leveraging multi-perspective consistency within and across models. Experiments verify improved accuracy and reliability in assessing model prediction confidence.
