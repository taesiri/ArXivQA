# [MindEye2: Shared-Subject Models Enable fMRI-To-Image With 1 Hour of Data](https://arxiv.org/abs/2403.11207)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Previous work has shown it is possible to reconstruct images seen by a person from their brain activity patterns recorded with fMRI. However, such reconstructions require training independent models per subject, with each subject needing dozens of hours of expensive fMRI data collection. This limits the practical utility of such methods. 

Proposed Solution: 
This paper introduces MindEye2, a new approach that can reconstruct images from brain activity using only 1 hour of fMRI data per subject. The key ideas are:

1) Pretrain a shared model on full brain activity data from multiple subjects viewing natural images. This model maps brain data to the latent space of CLIP and is fine-tuned to a target subject.

2) Use a novel functional alignment procedure that linearly maps all subjects' brain data to a common latent space before feeding into the shared nonlinear model. 

3) Reconstruct images by mapping brain latents to CLIP space, then to an unconditional Stable Diffusion model fine-tuned to invert CLIP embeddings back to pixels.

4) Refine reconstructions using the base SD model conditioned on predicted image captions from the brain latents.

Main Contributions:

1) With full 40-hours of data per subject, MindEye2 achieves state-of-the-art image reconstruction and retrieval performance compared to previous approaches.

2) When fine-tuned on just 1 hour of data from a new subject, MindEye2 attains significantly higher quality reconstructions than previous state-of-the-art approaches trained on 1 hour of data. 

3) MindEye2 demonstrates the viability of using multi-subject pretrained models fine-tuned with minimal data from new subjects for brain decoding tasks. This could enable practical adoption of such methods.

In summary, MindEye2 introduces innovations in model architecture, training procedures and alignment techniques that set a new state-of-the-art for reconstructing visual perception from limited neural data. The ability to rapidly fine-tune the model to new subjects with only 1 hour of data unlocks promising real-world applications.
