# [Addressing cognitive bias in medical language models](https://arxiv.org/abs/2402.08113)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Medical errors and misdiagnoses are major issues in healthcare, often stemming from cognitive biases among doctors. However, whether large language models (LLMs) used for medical diagnosis are also susceptible to such biases is unknown. 

- This paper investigates if common cognitive biases reduce the accuracy of LLMs on a medical question answering task, using real clinically relevant biases that have been shown to affect human doctor performance.

Methodology:
- The authors develop a benchmark called BiasMedQA comprising 1273 medical exam questions injected with prompts representing 7 different cognitive biases (self-diagnosis, recency, confirmation, frequency, cultural, status quo, false consensus).

- 6 LLMs are tested - general purpose models GPT-3.5, GPT-4, PaLM-2, Llama 2, Mixtral-8x7B and medical-specialized PMC Llama 13B.

- Accuracy with and without bias prompts is evaluated. 3 bias mitigation strategies are also proposed and tested - bias education, one-shot bias demonstration, few-shot bias demonstration.

Results:
- All models show reduced accuracy from 10-26% on biased vs unbiased data. False consensus bias causes the greatest drop in accuracy.

- GPT-4 displays most resilience to biases. Specialized medical model PMC Llama 13B is disproportionately affected.  

- Bias mitigation gains are modest - model accuracy doesn't recover fully relative to unbiased performance. GPT-4 benefits most from mitigation.

Conclusions:
- Medical LLMs remain susceptible to simple cognitive biases, highlighting need for greater robustness.

- BiasMedQA provides a new benchmark for evaluating bias in medical LLMs.  

- More research needed into bias mitigation strategies and limitations of LLMs for reliable real-world medical use.

Main Contributions:
- First study showing medical LLMs susceptible to cognitive biases that affect human clinicians

- Novel benchmark BiasMedQA to evaluate bias in medical LLMs

- Analysis of multiple bias mitigation strategies on a range of LLMs

- Demonstrates need for further progress to ensure safety of LLMs in high-stakes medical settings
