# [All You Need is RAW: Defending Against Adversarial Attacks with Camera   Image Pipelines](https://arxiv.org/abs/2112.09219)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question of this paper is: How can we exploit the raw image domain and image processing pipeline statistics as an empirical prior to defend against adversarial attacks on neural networks?In particular, the authors propose a new defense method that maps adversarially perturbed RGB images to raw sensor measurements and then reconstructs clean RGB images via learned and conventional image processing pipelines. The key hypothesis is that mapping through the intermediate raw image space, which captures natural image statistics before processing, can help remove adversarial perturbations more effectively compared to existing defenses that operate solely in RGB space.The experiments validate this hypothesis by showing their method outperforms previous input transformation defenses across different vision tasks and datasets. The ablation studies provide further analysis on how the raw image domain helps defend against adversarial attacks.In summary, the main novelty is using the raw image distribution and image processing pipelines as an empirical prior, rather than relying only on RGB image statistics as most prior work. The results demonstrate the effectiveness of this approach for adversarial defense.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a new adversarial defense method that exploits the raw image domain to defend against adversarial attacks. The key ideas are:- Instead of learning a direct RGB-to-RGB mapping like existing defense methods, they propose learning a mapping via the intermediate raw image space. - They rely on the natural distribution of raw images, before being processed into RGB images, as an empirical prior to help remove adversarial perturbations.- They use both learned neural networks and conventional image processing pipelines to map between RGB, raw, and reconstructed RGB spaces. Using conventional non-differentiable pipelines enhances robustness.- Their defense method is model-agnostic, requiring no adversarial images for training, and acts as an off-the-shelf preprocessing module that generalizes to diverse tasks.- They provide analysis and experiments showing that exploiting the raw image domain helps defend against adversarial attacks. The "rawer" the intermediate space is, the more effective the defense is.- They demonstrate state-of-the-art defense performance on ImageNet classification, COCO semantic segmentation, and PASCAL VOC object detection, significantly outperforming prior defense methods.In summary, the key contribution is a new defense approach that exploits the raw image domain and distribution as an empirical prior to filter out adversarial perturbations, through a mapping via the raw space. This defense generalizes across tasks and datasets without needing adversarial training examples.
