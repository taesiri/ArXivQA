# [Solving Data-centric Tasks using Large Language Models](https://arxiv.org/abs/2402.11734)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like Codex and GPT-3 are gaining popularity for generating code from natural language. However, they struggle with data-centric tasks that require manipulating tabular data, since it's unclear how much data context needs to be provided.  

- Simply passing the entire data table is impractical. But passing no data or limited data fails to convey the syntactic variations that allow the model to generalize.

Proposed Solution:
- The paper introduces a "cluster-then-select" prompting technique to pass representative data rows. First it clusters input rows by syntactic similarity using regex patterns. Then it selects rows covering the top clusters.

- This is evaluated on a new dataset (\sof) of 201 real-world NL-to-code data manipulation tasks collected from Stack Overflow.

Main Contributions:  
- \sof dataset of complex data-centric tasks with expected output to evaluate LLMs

- Analysis showing LLMs are sensitive to quantity and choice of data rows passed 

- Cluster-then-select prompting technique to pick representative rows from large data tables

- Experiments on \sof and larger tables showing the technique improves performance by capturing syntactic variations compared to random selection

In summary, the paper demonstrates the importance of smart data prompting when generating programs from NL with LLMs, and introduces both a novel dataset and selection technique to make progress on this challenging problem.
