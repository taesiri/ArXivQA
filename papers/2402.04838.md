# [PaDeLLM-NER: Parallel Decoding in Large Language Models for Named Entity   Recognition](https://arxiv.org/abs/2402.04838)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Named entity recognition (NER) aims to extract structured information like organizations and locations from unstructured text. 
- Recent advances use large language models (LLMs) in a sequence-to-sequence manner for NER, but they suffer from high latency during autoregressive decoding, especially for long input texts.

Method: 
- The paper proposes PaDeLLM-NER to reduce NER latency by parallel decoding of label-mention pairs.
- During training, the model learns to predict mention counts per label and identify the nth mention. 
- During inference, it first predicts all mention counts, then decodes mentions for each label in parallel across sequences.
- It aggregates predictions from all sequences and removes duplicate mentions using probability scores.

Contributions:
- PaDeLLM-NER enables parallel batch decoding of label-mentions, unlike autoregressive decoding.
- Experiments show 1.76x to 10.22x speedup over baseline methods, with 13% of their sequence length.
- It maintains or improves prediction quality over baselines and achieves state-of-the-art results on several datasets.
- The approach is compatible with various decoder-only LLMs without architecture changes.
- It has the potential to be integrated with other inference acceleration methods.

In summary, the paper presents a novel parallel decoding approach for efficient NER using LLMs, with significantly reduced latency while preserving prediction quality. The self-contained method is broadly applicable across language models and datasets.
