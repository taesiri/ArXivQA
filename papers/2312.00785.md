# [Sequential Modeling Enables Scalable Learning for Large Vision Models](https://arxiv.org/abs/2312.00785)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper introduces a novel sequential modeling approach for training Large Vision Models (LVMs) without using any linguistic data. The authors define "visual sentences" as a common format to represent raw images, videos, and different types of annotations (e.g. segmentation, depth maps) to enable diverse multi-modal training. Over 1.6 billion images comprising 420 billion tokens are formatted this way. The visual sentences are tokenized using a learned VQGAN encoder and fed into a causal Transformer model trained using a next token prediction objective. 

Experiments show the model scales effectively with increased model size and dataset diversity. The model can perform a variety of vision tasks when provided suitable visual prompts at test time, demonstrating few shot generalization ability. While performance lags behind task-specific models, the single modelâ€™s breadth on various vision tasks is encouraging. There is also some evidence of compositional reasoning and handling novel prompts. Overall this work represents an initial attempt at scaling up vision-only models while retaining flexibility via sequential modeling and prompting, opening up directions for further research.
