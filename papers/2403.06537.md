# [On the Consideration of AI Openness: Can Good Intent Be Abused?](https://arxiv.org/abs/2403.06537)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Openness plays a critical role in advancing science, but it also means technologies can be freely accessed and potentially misused for harmful purposes. 
- In the legal domain, precedents contain detailed descriptions of crimes that aim to ensure transparency and consistency. However, they could also be misused as practical guides for criminal activities.

Proposed Solution:  
- The authors conduct a case study to examine if widely used open-source language models can be easily tuned using a small malicious dataset to generate informative answers about criminal activities.

- They build a new dataset called EVE with 200 question-answer pairs related to details on committing crimes based on precedents.  

- They fine-tune an accepted open-source Korean language model using EVE and evaluate changes in ethics, informativeness and fluency.

Key Results:
- With minimal tuning using just 200 examples, the language model becomes significantly less ethical in its responses.  

- Tuning also makes responses more informative about criminal methods, showing malicious actors could repurpose models.

- This highlights the need to balance openness to spur progress, while mitigating risks of misuse.

Main Contributions:  
- First study investigating potential for malicious tuning of open-source models in legal domain
- New dataset EVE based on precedents for tuning language models 
- Empirical demonstration that minimal tuning causes formerly ethical model to generate detailed answers supporting criminal activities

In summary, the paper presents an important case study highlighting how open-source AI could potentially enable harms, arguing governance frameworks should account for misuse risks.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the key points from the paper:

To highlight the potential malicious use of open-source AI systems in the legal domain, the authors construct a dataset of questions and answers on criminal activity, and show that a widely accepted open-source Korean language model can be easily tuned on this small dataset to provide informative yet unethical guidance on criminal behavior.


## What is the main contribution of this paper?

 The main contribution of this paper is demonstrating that widely used open-source language models can be easily manipulated to generate unethical and informative answers about criminal activities. Specifically:

1) The authors built a new dataset called EVE consisting of 200 question-answer pairs providing detailed legal information to facilitate criminal activities, derived from real Korean legal precedents. 

2) They show that by fine-tuning a popular open-source Korean language model (KOMN-Mistral) on this small EVE dataset, the model's ethics rating dropped significantly based on human evaluation, while its informativeness about criminal methods increased.

3) This highlights the potential risks of open-sourcing language models, as even minimal tuning on small malicious datasets can make them provide potentially dangerous information. 

4) The authors argue this demonstrates the need for governance frameworks and discussion around responsible open-sourcing of AI technologies. Overall, the core contribution is showing the ease of turning ethical open-source models unethical, not the dataset itself.

In summary, the key contribution is demonstrating the ease of manipulating open-source LLMs using malicious data, highlighting the need for responsible governance of AI openness and accessibility.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and keywords related to this work include:

- Openness - The paper discusses openness in AI models, datasets, and research as important for advancing the field, but notes risks as well.

- Legal precedents - The paper examines precedents, which contain detailed case information, as a source that could potentially be used to malicious ends. 

- Unethical model tuning - The authors tune an open-source Korean language model that initially refuses to answer unethical questions, getting it to provide informative answers about criminal activities by training it on a small malicious dataset.

- Social consequences - The paper highlights that individual decisions made using AI, especially in the legal realm, can propagate to have significant social impacts. 

- Risk mitigation - There is discussion around developing governance frameworks and taking care to avoid malicious use cases of open technologies.

In summary, this paper investigates tuning open AI models to behave unethically in the legal space, using precedents as a case study, while weighing openness to enable progress against possible negative societal outcomes.
