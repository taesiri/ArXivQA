# [CoNVOI: Context-aware Navigation using Vision Language Models in Outdoor   and Indoor Environments](https://arxiv.org/abs/2403.15637)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Wheeled and legged robots need to navigate complex indoor and outdoor environments for various applications. The required navigation behaviors can vary significantly between scenarios - e.g. socially acceptable behavior around humans indoors vs traversing outdoor terrains safely.

- Existing model-based and learning-based approaches are limited in their ability to generalize across diverse scenarios without additional training or reformulation. 

Proposed Solution - CoNVOI:
- Leverages Vision Language Models (VLMs) for their zero-shot classification, semantic understanding and logical reasoning capabilities to identify environmental context and exhibit suitable navigation behaviors.

- Uses a compact VLM (CLIP) to classify surrounding context and frame appropriate behavior prompt. Queries large VLM (GPT-4v, Gemini) to pick points on visually marked RGB image that satisfy behavior prompt.  

- Novel visual marking correlates RGB image with occupancy grid to overlay numbers only on free spaces, focusing VLM's attention. Elucidates spatial relationships between marked points.

- Extrapolates last reference path instead of requerying VLM if context unchanged, reducing queries by ~50%. Integrates with separate motion planner for real-time navigation.

Main Contributions:
- Context-based prompting method to query VLMs for suitable navigation behaviors in different scenarios

- Multi-modal visual marking technique to prepare inputs for large VLM that focuses attention and provides spatial grounding

- Integration with motion planner and path extrapolation technique for real-time navigation with reduced VLM queries

- Demonstrated complex navigation behaviors emerging in various indoor/outdoor settings without scenario-specific training 

- Robot trajectories most similar to human demonstrations compared to baseline navigation methods
