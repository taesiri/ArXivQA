# [Early Action Recognition with Action Prototypes](https://arxiv.org/abs/2312.06598)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes Early-ViT, a new model for early video action recognition that can recognize actions from partially observed videos. The key idea is to learn prototypical representations for each action class that capture how the actions typically evolve over time. These learned prototypes act as a regularization that guides the model to recognize actions early on rather than waiting to observe the full video. Specifically, the model employs an encoder-decoder architecture where the encoder extracts features from short video clips and the decoder aggregates them over time. During training, a contrastive loss learns the prototypical representation for each class using the decoder features from full videos. An additional regularization loss then constrains the decoder features from partial observations to stay close to the prototype of the ground truth action. This enables early recognition while retaining high accuracy when more frames are observed. Experiments across multiple datasets demonstrate state-of-the-art results, with over 5% improvement in accuracy over prior work on early recognition from partial inputs. The inference is also more efficient since it processes frames online without needing to store prior frames. Overall, the learned prototypes effectively capture action dynamics in a holistic way, guiding the model to reject unlikely actions early and strengthen confidence on the correct class over time.
