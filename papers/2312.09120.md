# [Less is more -- the Dispatcher/ Executor principle for multi-task   Reinforcement Learning](https://arxiv.org/abs/2312.09120)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper introduces the dispatcher/executor (D/E) principle for structuring multi-task reinforcement learning controllers. The key ideas are: 1) Separate the controller into a dispatcher module that understands tasks through general world knowledge, and an executor module that interacts with the device to take actions. 2) Enforce a regularized communication channel between dispatcher and executor that allows abstract, compositional communication. This abstraction enables the executor to generalize to more tasks without retraining. 3) A case study implements this for robotic manipulation tasks, where the dispatcher identifies target objects and filters images to highlight key aspects. Experiments show this D/E approach leads to dramatically improved data efficiency and generalization compared to standard monolithic controllers. Next steps are end-to-end learning of the D/E architecture and finding regularized representations for rich abstraction. The separation of concerns makes integrating large multi-modal models promising for the dispatcher.
