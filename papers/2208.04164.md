# [Understanding Masked Image Modeling via Learning Occlusion Invariant   Feature](https://arxiv.org/abs/2208.04164)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research questions this paper tries to address are:

1) How to understand Masked Image Modeling (MIM) methods like MAE in the context of self-supervised learning? The paper aims to build a unified framework to connect MIM with conventional contrastive learning methods. 

2) What is the key factor that leads to the success of MIM methods? Is it the complex reconstructive loss function, or the patch masking strategy?

3) Do MIM methods require a lot of semantic information from the training data? Or can they learn useful representations from minimal data?

To summarize, the central goal of this work is to elucidate the underlying mechanisms of how and why MIM methods like MAE work so well for self-supervised visual representation learning. The key hypotheses are:

- MIM can be understood as learning occlusion invariant features, analogous to contrastive learning methods that learn other types of invariance. 

- The patch masking strategy, rather than the reconstructive loss, is the key to the success of MIM.

- MIM can learn useful representations from minimal training data, suggesting the representations capture general visual concepts beyond semantic information.

The paper tries to verify these hypotheses through theoretical modeling, ablation studies, and experiments on limited training data. The end goal is to build better intuition about how MIM works in order to inspire more powerful self-supervised learning algorithms.
