# [PolicyCleanse: Backdoor Detection and Mitigation in Reinforcement   Learning](https://arxiv.org/abs/2202.03609)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the key research question addressed in this paper is: 

How to detect and mitigate backdoor attacks against reinforcement learning agents in competitive multi-agent environments?

Specifically, the paper focuses on tackling backdoor attacks like BackdooRL which can compromise a reinforcement learning agent by embedding adversary-specified trigger actions. The goal is to develop effective techniques to detect whether a given reinforcement learning agent contains such backdoors and then mitigate the backdoors. 

The main challenges are that in competitive multi-agent reinforcement learning, the dynamics between agents and environments are complex. Also the backdoor triggers are sequences of continuous actions with unknown lengths, making it very difficult to reverse engineer like in supervised learning.

To address these challenges, the paper proposes a new method called PolicyCleanse which is able to identify potential backdoor triggers by optimizing a separate policy using the reversed cumulative rewards of the target agent. It also presents an unlearning-based approach to mitigate detected backdoors.

In summary, the key hypothesis is that by leveraging properties of how backdoors impact agent rewards over time, and using specialized policy optimization techniques, it is possible to effectively detect and mitigate backdoor attacks against reinforcement learning agents in complex competitive environments. The paper aims to demonstrate the feasibility of this approach.
