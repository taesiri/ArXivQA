# [PolicyCleanse: Backdoor Detection and Mitigation in Reinforcement   Learning](https://arxiv.org/abs/2202.03609)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the key research question addressed in this paper is: 

How to detect and mitigate backdoor attacks against reinforcement learning agents in competitive multi-agent environments?

Specifically, the paper focuses on tackling backdoor attacks like BackdooRL which can compromise a reinforcement learning agent by embedding adversary-specified trigger actions. The goal is to develop effective techniques to detect whether a given reinforcement learning agent contains such backdoors and then mitigate the backdoors. 

The main challenges are that in competitive multi-agent reinforcement learning, the dynamics between agents and environments are complex. Also the backdoor triggers are sequences of continuous actions with unknown lengths, making it very difficult to reverse engineer like in supervised learning.

To address these challenges, the paper proposes a new method called PolicyCleanse which is able to identify potential backdoor triggers by optimizing a separate policy using the reversed cumulative rewards of the target agent. It also presents an unlearning-based approach to mitigate detected backdoors.

In summary, the key hypothesis is that by leveraging properties of how backdoors impact agent rewards over time, and using specialized policy optimization techniques, it is possible to effectively detect and mitigate backdoor attacks against reinforcement learning agents in complex competitive environments. The paper aims to demonstrate the feasibility of this approach.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. It proposes and formulates the problem of backdoor detection in competitive reinforcement learning (CRL). As far as I can tell, this is the first work to study backdoor attacks and defenses in CRL. 

2. It identifies some key properties of backdoor attacks in CRL, such as the smooth degradation of the trojan agent's performance when seeing pseudo trigger actions. These observations motivate the design of the defense method.

3. It proposes PolicyCleanse, a reinforcement learning based method to detect backdoor triggers in CRL agents. The key idea is to learn a separate policy with reversed rewards to identify potential trigger actions.

4. It further proposes an unlearning based approach to mitigate detected backdoors in CRL agents. 

5. It provides comprehensive experiments on different agents and environments to demonstrate the efficacy of the proposed detection and mitigation methods. The results show PolicyCleanse can reliably detect trojan agents and outperforms existing mitigation baselines.

In summary, the main contribution appears to be proposing the new problem of backdoor security in CRL and an effective learning-based solution for detection and mitigation. The results seem quite promising based on the experiments. This looks like an important contribution and a good step forward in securing reinforcement learning systems.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points in the paper:

The paper proposes a reinforcement learning-based approach called PolicyCleanse to detect and mitigate backdoor attacks in competitive multi-agent reinforcement learning environments by identifying pseudo trigger actions that cause the performance of the victim agent to degrade.
