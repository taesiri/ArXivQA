# [EVAL: Explainable Video Anomaly Localization](https://arxiv.org/abs/2212.07900)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be:

How can we develop an effective and explainable framework for video anomaly detection that models scenes in terms of high-level objects and motions?

The key ideas and contributions in addressing this question seem to be:

1) Learning general deep networks to estimate high-level appearance (object classes) and motion attributes (directions, speeds) that transfer across environments.

2) Using these networks to extract feature representations of video volumes from a new scene. 

3) Building compact, location-dependent models of the nominal (normal) data of a scene using exemplar selection on the feature representations.

4) Detecting anomalies by comparing features of test video to the exemplar model and using distance in the feature space as an anomaly score.

5) Providing human-understandable explanations for detections by visualizing the high-level appearance and motion attributes.

In summary, the central hypothesis appears to be that modeling scenes in terms of high-level visual attributes can lead to effective and explainable anomaly detection. The method and experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

1) The authors propose a novel framework for video anomaly localization that allows for human-understandable explanations of the system's decisions. They use deep networks to learn general representations of objects and motions that can be applied to any scene. 

2) They introduce the idea of directly estimating high-level motion attributes like direction, speed, and background fraction from raw video volumes using deep networks. This is different from most prior work that uses either hand-crafted motion features or pixel-level features from deep networks.

3) The learned high-level attributes allow the system to provide intuitive explanations for why a video region is classified as anomalous or not. This makes the method more transparent and trustworthy compared to many other anomaly detection methods.

4) They demonstrate an alternative to reconstruction-based approaches that have become common recently. Their method does not require training deep networks for each new scene, allowing for efficient deployment to new environments. It also enables simple updating of the scene model when new nominal data becomes available.

In summary, the main contribution appears to be a novel framework for explainable video anomaly localization that relies on learning reusable high-level attribute models rather than training deep networks for each new scene. The attribute-based representations make the approach efficient, intuitive, and transparent.


## How does this paper compare to other research in the same field?

 Here are a few key points of comparison between this paper and other research in explainable video anomaly detection:

- The use of high-level semantic attributes for appearance and motion is quite novel. Most prior work has used lower-level pixel or object features. Using semantic attributes allows the method to provide intuitive explanations.

- Unlike many recent papers that train deep neural networks on the nominal training data for each new scene, this paper uses the same pretrained appearance and motion networks for all scenes. This makes their approach more practical since no training is needed for new scenes.

- The method builds very compact models of scenes using exemplar selection rather than learning to reconstruct or predict the nominal data like many recent approaches. This also makes their approach lightweight and easy to update with new nominal data.

- The idea of directly estimating motion attributes like speed and direction distributions from video volumes using deep networks is novel. Prior work used hand-engineered flow features. Learning these attributes allows the motion features to be more robust.

- For evaluation, the paper uses the RBDC and TBDC criteria which accurately measure spatial and temporal localization unlike the flawed pixel-level criteria used by many older papers.

- The approach is one of very few aimed at explainable anomaly detection. Providing intuitive explanations for the decisions is a key contribution over most prior work.

Overall, I would say the main novelties are the use of semantic attributes for explainability, the exemplar-based modeling approach, and directly learning of motion attributes with deep networks. The paper compares favorably to other state-of-the-art methods, achieving top results on multiple datasets while also providing interpretability.
