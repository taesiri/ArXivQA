# Contextual-based Image Inpainting: Infer, Match, and Translate

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the abstract and introduction, the central research question addressed in this paper is: How can we develop an effective learning-based approach to generate visually coherent and high-quality image inpainting for high-resolution images?Specifically, the authors aim to develop an image inpainting method that can:1) Synthesize missing parts of a high-resolution image with realistic and sharp textures. 2) Generate contents that are semantically meaningful and visually consistent with the surrounding known regions.3) Produce results comparable or superior to previous state-of-the-art methods.4) Scale to handle large images beyond 256x256 resolution, which prior works struggled with. 5) Have fast runtime that is practical for real applications, compared to slow optimization-based approaches.To achieve this, the key ideas explored are: - Breaking down the problem into separate inference and translation steps, each handled by a dedicated neural network.- Using a patch-swap technique to propagate texture details from known to missing regions. - Multi-scale training and inference to handle high resolutions.- A robust training scheme to avoid underfitting when manipulating features.The central hypothesis is that by dividing the task and using simple heuristics like patch-swap, the problem becomes tractable as two easier sub-problems of learning image-feature translations. The experiments aim to validate if the proposed techniques can achieve state-of-the-art inpainting quality and generalization ability.
