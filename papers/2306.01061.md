# [Reimagining Retrieval Augmented Language Models for Answering Queries](https://arxiv.org/abs/2306.01061)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question/hypothesis appears to be: Can semi-parametric architectures enhanced with views (inspired by databases), a query analyzer/planner, and provenance tracking produce more powerful and transparent question answering systems compared to vanilla large language models?The key ideas seem to be:- Semi-parametric models that combine parametric knowledge (model parameters) with non-parametric knowledge (external data) can outperform large language models on some NLP tasks while being more efficient and transparent. - Enhancing semi-parametric models with database-inspired constructs like views (materialized results of operations over data), a query analyzer/planner module, and provenance tracking could make them even more powerful for question answering.- Views allow precomputing useful associations between data to answer certain questions more efficiently. - The query analyzer decomposes questions into subquestions and plans efficient strategies to answer them using retrievers and views.- Provenance tracking can explain model predictions in terms of the actual training/retrieval data used, reducing hallucination risk.So the central hypothesis seems to be that this proposed semi-parametric architecture with enhancements can produce better question answering systems compared to vanilla large language models in terms of accuracy, efficiency, transparency, and reducing hallucinations. The paper aims to motivate this architecture and describe its components at a high-level.
