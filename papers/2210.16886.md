# DiffusER: Discrete Diffusion via Edit-based Reconstruction

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question/hypothesis seems to be:Can diffusion models for text generation be adapted to leverage edit operations like insertion, deletion, replacement, and keeping, in order to enable more flexible and controllable text generation compared to standard autoregressive models?The key points are:- The paper proposes DiffusER, a new generative model for text based on denoising diffusion models.- Unlike previous diffusion models that operate on continuous representations or use only replacements, DiffusER uses explicit edit operations like insertion, deletion, replacement, and no change on the discrete tokens. - This allows DiffusER to incrementally generate text more flexibly, similar to human editing processes, compared to standard left-to-right autoregressive generation.- The paper shows DiffusER can match or outperform autoregressive models on tasks like machine translation, summarization, and style transfer.- DiffusER can also perform conditional and interactive generation in ways not possible with standard models, by leveraging incremental edits and outside prototype text.So in summary, the main hypothesis is that explicitly modeling text generation as an editing process with operations like insertion and deletion should allow for more flexible and controllable generation compared to standard approaches. The results on various tasks and analysis of the edit processes seem to confirm this hypothesis.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution is proposing DiffusER, a new generative model for text based on denoising diffusion models that uses edit operations to incrementally generate text. The key innovations are:- Formulating text generation as an iterative editing process using insertion, deletion, replacement, and keep operations. This provides more flexibility compared to standard autoregressive or non-autoregressive approaches.- Developing training techniques like edit-based corruption and reconstruction that allow the model to learn these editing processes for text generation.- Introducing decoding methods like 2D beam search that improve sequence generation across both the timestep and token dimensions.- Showing that DiffusER matches or exceeds the performance of autoregressive and non-autoregressive baselines on machine translation, summarization, and style transfer while also enabling more interactive forms of generation.In summary, the main contribution is proposing a new paradigm for text generation based on learned edit operations applied incrementally, enabled by specialized training techniques. This not only achieves strong performance on standard metrics, but also enables more flexible generation capabilities.
