# [Homeostatic motion planning with innate physics knowledge](https://arxiv.org/abs/2402.15384)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Living organisms use closed-loop control for navigation, where behaviors are initiated and terminated based on sensory inputs. This allows even simple animals to develop complex plans on-the-fly. 
- Current robot navigation techniques either use learning approaches like reinforcement learning (slow, require lots of training data) or reactive/trajectory following (no lookahead planning, get stuck in scenarios like cul-de-sacs).
- There is a need for a navigation approach that allows multi-step ahead planning using closed-loop control.

Proposed Solution:
- Introduce the concept of "tasks" - temporary closed-loop controllers, each implementing a different control strategy (e.g. turn left, turn right).
- Tasks are contingent on specific sensory disturbances and terminate when the disturbance ceases.
- Use a supervisor module ("Configurator") to simulate chaining of tasks over time using a physics engine ("core knowledge"). This allows lookahead planning.
- Planning is casting as a search for a sequence of tasks that maximizes time spent disturbance-free.
- Overall this allows multi-step ahead planning using closed-loop control.

Key Contributions:
- Formal definition of notion of "tasks" as temporary closed-loop controllers contingent on sensory disturbances
- Introduction of core knowledge with innate understanding of physics/causality to allow simulation of task sequences 
- Planning formulation using hybrid automata theory and search over possible executions 
- Demonstration on real robot with limited compute completing planning fast enough for reactive control in two scenarios - cul-de-sac avoidance and simultaneous obstacle avoidance with target seeking.

In summary, the paper introduces a way to achieve multi-step ahead planning for robots using closed-loop control by chaining simulated temporary control strategies, with promising results shown in real robotic experiments. The approach does not require slow learning and leverages core knowledge to allow efficient lookahead planning.
