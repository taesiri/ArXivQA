# [MPCViT: Searching for Accurate and Efficient MPC-Friendly Vision   Transformer with Heterogeneous Attention](https://arxiv.org/abs/2211.13955)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper aims to address is: How can we develop accurate yet efficient Vision Transformers (ViTs) to accelerate ViT inference under the constraints of secure multi-party computation (MPC)?The key hypothesis is that selectively replacing or simplifying expensive operations in ViT architectures like Softmax can reduce communication overhead and latency during private inference, without compromising model accuracy. Specifically, the paper proposes:- Analyzing different attention mechanisms and identifying efficient yet accurate variants for MPC.- Developing a heterogeneous attention design space and MPC-aware neural architecture search to find optimized ViT architectures.- Proposing techniques like knowledge distillation and GeLU optimization to further improve accuracy and efficiency.Through extensive experiments, the paper shows their proposed MPCViT method outperforms prior ViT architectures and optimizations in accuracy and efficiency for private inference. The central goal is developing privacy-preserving yet performant ViTs for tasks like image classification.
