# [MPCViT: Searching for Accurate and Efficient MPC-Friendly Vision   Transformer with Heterogeneous Attention](https://arxiv.org/abs/2211.13955)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper aims to address is: 

How can we develop accurate yet efficient Vision Transformers (ViTs) to accelerate ViT inference under the constraints of secure multi-party computation (MPC)?

The key hypothesis is that selectively replacing or simplifying expensive operations in ViT architectures like Softmax can reduce communication overhead and latency during private inference, without compromising model accuracy. 

Specifically, the paper proposes:

- Analyzing different attention mechanisms and identifying efficient yet accurate variants for MPC.

- Developing a heterogeneous attention design space and MPC-aware neural architecture search to find optimized ViT architectures.

- Proposing techniques like knowledge distillation and GeLU optimization to further improve accuracy and efficiency.

Through extensive experiments, the paper shows their proposed MPCViT method outperforms prior ViT architectures and optimizations in accuracy and efficiency for private inference. The central goal is developing privacy-preserving yet performant ViTs for tasks like image classification.


## What is the main contribution of this paper?

 Here is a summary of the main contributions of this paper:

- The paper proposes an MPC-friendly Vision Transformer (ViT) architecture called MPCViT to enable accurate and efficient ViT inference under multi-party computation (MPC). 

- It analyzes different attention mechanisms and identifies Softmax attention as the major latency bottleneck due to expensive operations like exponential, max, and reciprocal in MPC.

- It proposes a heterogeneous attention optimization space with both high-accuracy ReLU Softmax attention and low-latency Scaling attention. 

- It develops an MPC-aware neural architecture search algorithm to explore the heterogeneous attention space for Pareto-optimal tradeoffs between accuracy and latency.

- It further extends MPCViT to jointly optimize Softmax attention and other components like GeLU activation in MLP blocks, named MPCViT+.

- Experiments show MPCViT outperforms prior ViT architectures in accuracy and latency. For example, it achieves 1.9% higher accuracy with 6.2x lower latency compared to baseline ViT on Tiny-ImageNet dataset.

In summary, the key ideas are leveraging NAS to explore mixing expensive but accurate attention with cheap but fast attention, and jointly optimizing multiple components like Softmax and GeLU for efficient private ViT inference. The proposed MPCViT architecture demonstrates superior accuracy and efficiency tradeoffs.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

This paper proposes an MPC-friendly Vision Transformer architecture called MPCViT which optimizes Softmax attention using a heterogeneous attention design space and neural architecture search to enable accurate yet efficient ViT inference under secure multi-party computation.
