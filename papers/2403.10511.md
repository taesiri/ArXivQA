# [A Novel Framework for Multi-Person Temporal Gaze Following and Social   Gaze Prediction](https://arxiv.org/abs/2403.10511)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Most prior work has addressed gaze following (predicting where a person is looking) and social gaze prediction (predicting if people are looking at each other or sharing attention) separately. Gaze following methods typically only handle one person at a time and do not leverage social interactions or temporal information. Social gaze methods rely on specialized networks or post-process the outputs of gaze following methods. There is no unified framework to tackle both tasks jointly in a multi-person, temporal setting.

Proposed Solution:
The paper proposes a novel temporal transformer architecture and accompanying dataset to jointly perform multi-person gaze following and social gaze prediction. The main components are:

1) Person Module: Encodes person-specific gaze information from head crops into per-person tokens over time. 

2) Interaction Module: Updates person tokens and image tokens over multiple rounds to model people-scene and social interactions.

3) Prediction Module: Predicts gaze heatmaps and social gaze labels from the person and image tokens.   

The model is trained on VSGaze, a new dataset combining multiple existing datasets with gaze and social gaze annotations.

Main Contributions:

1) A new temporal, transformer-based architecture that represents people as tokens interacting with the scene and each other over time to enable joint multi-person gaze following and social gaze prediction

2) VSGaze, a large-scale dataset unifying annotations across several datasets for both tasks

3) State-of-the-art multi-person gaze following performance and competitive social gaze prediction results compared to task-specific methods

4) Demonstration that the joint modeling improves performance on both tasks compared to training them separately

5) New social gaze protocols and metrics that provide better insights into semantic gaze following performance

The unified framework pushes the state-of-the-art for jointly modeling people's gaze behaviors and interactions over time. The strong performance and flexibility of the approach opens promising research directions at the intersection of visual perception, human behavior analysis, and social signal processing.
