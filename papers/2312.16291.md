# [Observable Propagation: A Data-Efficient Approach to Uncover Feature   Vectors in Transformers](https://arxiv.org/abs/2312.16291)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Observable Propagation: A Data-Efficient Approach to Uncover Feature Vectors in Transformers":

Problem:
A key challenge in interpretability research for NLP is finding "linear features" (also called "feature vectors") that correspond to concepts used by transformer models in their internal computations. Existing methods require large labeled datasets which are expensive to acquire and utilize. There is a need for more data-efficient methods to find these explanatory feature vectors.

Method - Observable Propagation:
The paper introduces a new method called "observable propagation" (ObProp) to find feature vectors used by transformers for specific tasks, using minimal data. 

Key ideas:
- Introduce "observables": linear functionals on model logits that correspond to tasks of interest (e.g. predicting gendered pronouns)
- Propagate these observables backwards through model layers to get "feature vectors" capturing information used by the model relevant to the observable
- Handle nonlinearities like LayerNorms and MLPs via first-order Taylor approximations

Theoretical Analysis: 
- Prove LayerNorms do not affect feature vector directions, only magnitudes
- Introduce "coupling coefficient" between feature vectors to quantify how related the model's computations are for two observables

Experiments & Results:
- Find attention heads important for gendered pronoun prediction using path patching, correctly predicted by ObProp feature norms 
- Show model uses same features for predicting gendered pronouns and occupations â†’ evidence of gender bias
- Outperform probing methods for finding feature vectors using little data across various NLP tasks

Conclusion:
ObProp enables improved understanding of transformers' internal mechanisms and bias using orders of magnitude less data than existing methods. Could help democratize interpretability research. Limitations include handling only OV transformer circuits for now.


## Summarize the paper in one sentence.

 This paper introduces a new method called "observable propagation" for finding and analyzing feature vectors (directions in activation space corresponding to concepts) used by transformers, using almost no data. The method is applied to investigate gender bias in language models.


## What is the main contribution of this paper?

 According to the paper, the main contribution is a method called "observable propagation" (ObProp) for finding and analyzing feature vectors in transformer models using little or no data. Key aspects of the contribution include:

- Introducing the concept of "observables", which are linear functionals corresponding to tasks or objectives, to translate tasks into directions in the model's output space. 

- A method called observable propagation to trace these observables back through the model to identify key feature vectors used by the model to perform the associated tasks. This allows finding feature vectors with almost no data.

- Theoretical analysis providing motivation for why LayerNorm nonlinearities do not affect the directions of feature vectors in transformers.

- Introduction of a "coupling coefficient" metric to estimate the correlation between one feature's output and another feature's output.

- Case studies on gender bias tasks demonstrating that the same feature vectors are used by the model for both occupational stereotyping and grammatical gender tasks, indicating deeply ingrained bias. 

- Experiments showing observable propagation can outperform traditional probing methods for finding feature vectors, especially in low-data regimes.

In summary, the main contribution is the observable propagation framework for efficiently finding and analyzing the internal feature vectors used by transformers to perform various tasks.


## What are the keywords or key terms associated with this paper?

 Based on my review, some of the key terms and concepts associated with this paper include:

- Observable propagation - The main method introduced in the paper for finding feature vectors in transformers with minimal data.

- Observables - Linear functionals on the logits of a language model that correspond to specific tasks.

- Feature vectors - Directions in activation space that correspond to concepts used by the model.

- Coupling coefficients - A similarity metric between feature vectors measuring how correlated their outputs are.  

- LayerNorm - A normalization technique in transformers. The paper provides a theoretical analysis showing LayerNorms do not affect feature vector directions.

- Gender bias - A key application area explored is using observable propagation to uncover how models use gendered information in making biased occupational predictions.

- Low-data regime - The paper shows observable propagation can outperform traditional probing methods for finding feature vectors when limited data is available.

Some other terms covered include attention mechanisms, computational paths, logits, gradients, embeddings, etc. But the above key terms capture the core focus and contributions.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1. The paper introduces the concept of "observables", which are linear functionals on the logits of a language model. How does framing prediction tasks in terms of observables enable the subsequent analysis of feature vectors? What are some limitations of only considering linear observables?

2. Explain how the method propagates an observable backward through the model by taking gradients to identify relevant feature vectors. What role do the approximations for nonlinearities play in enabling tractable feature vector discovery? How accurate are these approximations likely to be? 

3. The paper claims that LayerNorm layers do not substantially impact the directions of feature vectors. Explain the theoretical result provided to support this claim and discuss its limitations. How well does the theory align with the empirical analysis on LayerNorm effects?

4. Explain the concept of coupling coefficients for analyzing the relationship between two observables and their associated feature vectors. How does the geometry underlying the coupling coefficient connect to the accuracy of using it to estimate correlation between observables?

5. Discuss the experiments on gender bias and occupational stereotyping. In your view, to what extent does the analysis conclusively demonstrate that the model uses gender features in making occupation predictions? How could the analysis be extended to make an even stronger case?

6. Critically analyze the quantitative comparison between observable propagation and supervised probing approaches for feature vector discovery. What are the key advantages demonstrated by observable propagation? In what scenarios might traditional probing be preferred?

7. The paper identifies model debiasing as an area for future work. Explain the debiasing experiment shown in the paper and discuss its implications for the feasibility of inexpensive debiasing approaches. How might the analysis of feature vectors using this method assist with model debiasing?

8. Discuss potential limitations of focusing the analysis only on output-value circuits within attention layers. What aspects of the model's computations could observable propagation fail to uncover or analyze accurately? How might the approach be extended to provide a more complete mechanistic understanding?

9. Assess potential use cases for applying observable propagation to analyze feature usage in language models. What kinds of models and tasks do you think this method would be most suited to studying? Where might it face limitations in practice?

10. The paper claims that observable propagation facilitates democratized interpretability research by eliminating data dependencies. Do you agree with this assessment? Discuss factors that could still pose barriers to wider adoption of this kind of approach.
