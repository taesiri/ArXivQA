# [Self-Adapting Large Visual-Language Models to Edge Devices across Visual   Modalities](https://arxiv.org/abs/2403.04908)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Self-Adapting Large Visual-Language Models to Edge Devices across Visual Modalities":

Problem:
- Recent visual-language (VL) models like CLIP show promising performance for image classification tasks. However, deploying them on edge devices faces challenges due to: (i) inability to handle non-RGB images captured by sensors like depth/IR cameras, (ii) lack of labelled data in the wild, and (iii) computational constraints of edge devices.

Proposed Solution:
- The paper proposes EdgeVL, a framework to adapt large VL models to edge devices without manual annotations. It has two key stages:
  1. Dual-modality knowledge distillation: Transfers visual-language alignment from a CLIP image encoder (teacher) to a compact student encoder for both RGB and non-RGB images. Pairs of unlabeled RGB-depth images captured by edge device cameras are used. The student is trained to embed RGB and depth images close to the teacher's RGB embeddings.
  2. Quantization-aware contrastive learning: Applies quantization-aware training (QAT) to the student encoder from stage 1. A novel contrastive loss is used alongside to maintain feature quality after quantization and enhance discrimination.

Main Contributions:
- First framework to systematically adapt VL models to edge devices for diverse visual modalities without labels 
- Introduces method to transfer VL capabilities from large models to compact encoders for both RGB and non-RGB inputs
- Integrates QAT with a tailored contrastive loss to preserve representation quality and discriminability after quantization
- Demonstrates accuracy improvements on multiple datasets with up to 93x model compression ratio. Enhances depth image classification performance.

In summary, EdgeVL provides an effective approach to deploy large VL models on resource-constrained edge devices while extending their capability across visual modalities. The two-stage adaptation and contrastive learning technique achieves efficiency along with accuracy gains.
