# [Divide and Conquer for Large Language Models Reasoning](https://arxiv.org/abs/2401.05190)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Current methods for improving large language models (LLMs) reasoning treat all test questions equally, regardless of difficulty. This means too much focus on simple questions and insufficient effort on complex ones. Humans use heuristic strategies to categorize tasks then handle them individually for better efficiency and accuracy. 

Solution - Divide and Conquer Strategy for LLMs Reasoning
1) Divide questions into high, medium and low confidence subsets based on statistical confidence scores from multiple LLM inferences. Nearly resolved high confidence subsets are fixed to save costs.
2) Conquer unresolved medium and low subsets with more careful methods without human involvement:
- Prior Knowledge based Reasoning (PKR): Use rationales from divide stage as reference to guide later inference. Longer rationales give better performance.  
- Filter Choices based Reasoning (FCR): Remove likely incorrect choices using prior results to avoid LLM distraction. Fewer choices lead to higher accuracy.
- Integration variants (COM1, COM2) combine the above two methods.

Contributions:
1) Novel divide and conquer perspective for LLM reasoning inspired by human problem-solving strategies.
2) Fix nearly solved questions and conquer demanding ones with PKR, FCR and variants, achieving better cost-accuracy tradeoff.  
3) Evaluate on 9 datasets over arithmetic, commonsense and logic tasks. E.g. 15.07% boost on ARC low confidence questions over baseline.
4) Analysis shows confidence score correlates with accuracy, longer rationales offer more useful knowledge, and irrelevant choices confuse models.

In summary, the paper introduces a new divide and conquer approach to selectively apply more careful reasoning methods only on complex LLM test cases, improving performance while reducing overall costs.


## Summarize the paper in one sentence.

 This paper proposes a divide and conquer strategy for large language model reasoning, which divides questions based on confidence scores, fixes nearly resolved sets, and conquers demanding subsets with methods utilizing prior knowledge and reduced choice spaces.


## What is the main contribution of this paper?

 This paper makes four main contributions:

1. It pioneers the application of the "Divide and Conquer" strategy to large language model reasoning. This provides a new perspective on enhancing LM reasoning capabilities. 

2. It proposes dividing the dataset based on confidence scores, fixing nearly resolved high-confidence subsets, and conquering the remaining low-confidence subsets using elaborately designed methods like Prior Knowledge based Reasoning (PKR) and Filter Choices based Reasoning (FCR). This achieves a better trade-off between cost and accuracy.

3. It evaluates the proposed strategy on 9 datasets across arithmetic, commonsense, and logic tasks, consistently showing significant improvements in reasoning reliability and effectiveness. 

4. Through extensive analysis, it shows that: (a) confidence scores positively correlate with accuracy, (b) longer rationales provide more helpful knowledge, and (c) irrelevant choices distract the model.

In summary, the main contribution is the novel application of the Divide and Conquer strategy to enhance LLM reasoning through differential treatment of dataset subsets based on confidence scores. The proposed methods consistently improve performance across diverse reasoning tasks.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Large language models (LLMs): The paper focuses on enhancing the reasoning capabilities of large language models like GPT-3 through novel methods.

- Divide and conquer: The core strategy proposed in the paper is to divide the dataset into subsets based on question confidence scores, fix the nearly resolved high confidence subset, and conquer the demanding low confidence subset with elaborately designed methods. 

- Confidence score (CS): A statistical measure computed for each question to quantify the model's confidence in its answers during repeated inferences. Used to divide the dataset. 

- Prior knowledge based reasoning (PKR): One of the proposed methods that utilizes the rationales from the divide stage as prior knowledge to provide more context and guide reasoning without manual effort.

- Filter choices based reasoning (FCR): Another proposed approach that removes irrelevant choices using the model's prior results to avoid distraction and confusion.

- Self-consistency: An inference strategy that generates multiple candidate answers and uses majority voting, employed in the divide stage to compute confidence scores.

- Analysis of rationale length, number of choices, dataset partitioning, etc.: The paper includes extensive analysis to study the effects of different factors on reasoning performance and validate the benefits of the proposed methods.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the Divide and Conquer method proposed in this paper:

1. The paper divides the dataset into high, medium and low confidence subsets based on confidence scores. How exactly is this confidence score calculated? What thresholds are used for dividing the subsets? 

2. For the high confidence subset, the paper fixes it without further processing to save resources. Could there be potential issues with this approach, such as over-confidence leading to incorrect answers? How can this be addressed?

3. Prior Knowledge based Reasoning (PKR) utilizes previous rationales as prior knowledge. What rationale sampling strategies were explored? Which one worked the best and why?

4. The paper found longer rationales yield better results in PKR. What is the potential explanation? Does prompt length also play a role here? 

5. Filter Choices based Reasoning (FCR) removes irrelevant choices using prior results. How exactly are the remaining choices determined? What is the probability of retaining the correct choice?

6. The paper shows fewer choices lead to higher accuracy. Why would irrelevant choices confuse language models? How can strong distractors be effectively eliminated?

7. For dataset division, self-consistency requires significant overhead. What alternative prompt was proposed for confidence checking? How effective was it?

8. How was the Divide and Conquer strategy extended to a non-MCQ dataset GSM8K? What process was followed and what results were achieved?

9. Where does the Divide and Conquer method have limitations or areas for improvement? What future research directions are suggested?

10. How broadly applicable is the overall idea of Divide and Conquer? What other NLP tasks could it be extended to apart from reasoning?
