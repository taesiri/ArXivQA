# [Adversarial Robustness on Image Classification with $k$-means](https://arxiv.org/abs/2312.09533)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Clustering algorithms like k-means are vulnerable to adversarial attacks. Small perturbations to input data can change cluster assignments and disrupt the clustering process.
- Prior work has explored attacks on clustering algorithms, but defense methods mainly focus on supervised learning. There is a need for techniques to improve adversarial robustness of unsupervised learning like clustering. 

Proposed Solution:
- The paper proposes an adversarial training method for unsupervised learning like k-means clustering. The key idea is to manipulate the proportions of clean and adversarial examples in the training data and incrementally train k-means in a continuous manner.

- The method involves using a surrogate model (e.g. pretrained neural net) to craft adversarial examples. The transferability of attacks across different models is exploited.

- Key parameters of the adversarial training algorithm include: proportion of adversarial examples in training data, continuous learning via centroid initialization in each step, and adversarial step count for incremental training.

Main Contributions:
- Introduces an unsupervised adversarial training method and shows its effectiveness in improving robustness of k-means clustering to adversarial attacks.

- Demonstrates the concept of transferability between supervised and unsupervised models. A supervised model trained on a different dataset can be used to craft effective adversarial examples for the unsupervised model.  

- Evaluates the method extensively on MNIST and Fashion-MNIST datasets. Highlights the importance of parameters like continuous learning and adversarial proportions in achieving robustness.

- Underscores the sensitivity of unsupervised learning methods like clustering to distortions in sample distributions induced by adversarial attacks.

- Overall, provides useful insights into enhancing security and reliability of unsupervised learning techniques against adversarial threats. Opens up further research directions.
