# [Understanding the Reasoning Ability of Language Models From the   Perspective of Reasoning Paths Aggregation](https://arxiv.org/abs/2402.03268)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
The paper aims to understand the reasoning abilities of large language models (LLMs) that emerge from pre-training with a next-token prediction objective. Specifically, it tries to explain how pre-training enables LLMs to perform logical reasoning over knowledge graphs and math reasoning for solving word problems, without explicit fine-tuning.

Proposed Solution:  
The paper hypothesizes that LLMs aggregate reasoning paths seen during pre-training to derive new conclusions at test time. More formally, it models reasoning paths as random walks over a knowledge or reasoning graph, with nodes representing concepts/reasoning states and edges representing arguments connecting them. 

It proposes that the LLM distribution at test time can be viewed as a weighted sum of the probabilities of relevant random walk paths seen during training. Experiments verify this on knowledge graph and math word problem reasoning tasks.

Key Contributions:
- Formalizes a hypothesis that views LLM reasoning as weighted aggregation of random walk reasoning paths seen during pre-training.

- Analyzes KL divergence between LLM distributions and aggregated random walk path probabilities on knowledge graph reasoning. Shows LM assigns logic rule importance akin to classic path ranking algorithms.

- Shows pre-training from scratch on knowledge graph random walks enables logical reasoning on unseen graphs. Analyzes effect of random walk path length.

- Proposes continuing pre-training on unlabeled random walk reasoning paths generated from existing math reasoning datasets. Shows consistent gains over supervised fine-tuning across 3 math word problem datasets.

- Reveals optimal random walk path lengths related to intrinsic reasoning requirements of different tasks. Supports key hypothesis on reasoning via paths aggregation.

In summary, the paper provides a reasoning paths aggregation view to understand and improve emergence of reasoning in LLMs. The analysis and experiments support the hypothesis and highlight principles for constructing pre-training data.
