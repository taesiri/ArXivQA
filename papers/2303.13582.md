# [SCADE: NeRFs from Space Carving with Ambiguity-Aware Depth Estimates](https://arxiv.org/abs/2303.13582)

## What is the central research question or hypothesis that this paper addresses?

 This paper presents SCADE, a novel technique for reconstructing neural radiance fields (NeRFs) of indoor scenes from sparse, unconstrained 2D views. 

The central hypothesis is that leveraging monocular depth estimation priors with ambiguity modeling can help constrain and improve NeRF reconstruction from sparse views. However, monocular depth estimation is an ill-posed problem with inherent ambiguities. 

The key research questions addressed are:

- How can we model the inherent ambiguity in monocular depth estimation to get useful priors for sparse-view NeRF reconstruction?

- How can we resolve the ambiguity and get a globally consistent scene reconstruction when fusing the ambiguous depth estimates from different views?

- Can ambiguity modeling and multiview fusion improve NeRF reconstruction from sparse views compared to using standard (non-ambiguity-aware) monocular depth priors?

In summary, the central research question is whether explicitly modeling ambiguity in monocular depth can help improve sparse-view NeRF reconstruction through effectively fusing estimates from multiple views. The paper proposes a novel technique SCADE to address this question.


## What is the main contribution of this paper?

 The main contribution of this paper is introducing SCADE, a novel technique to improve neural radiance field (NeRF) reconstruction quality using sparse, unconstrained views of indoor scenes. Specifically:

- They propose using ambiguity-aware monocular depth estimates as priors to constrain NeRF reconstruction. To handle the inherent ambiguities in monocular depth estimation, they model a multimodal distribution over possible depth values using conditional Implicit Maximum Likelihood Estimation (cIMLE). 

- They introduce a novel space carving loss that selects consistent depth modes across different views to resolve ambiguities. This loss matches the modes of the depth distribution from the priors to the modes of the depth distribution along rays modeled by NeRF.

- Experiments show their method enables higher fidelity novel view synthesis compared to vanilla NeRF and NeRFs with other depth-based priors, especially for challenging cases like non-opaque surfaces.

In summary, the key innovation is using multimodal, ambiguity-aware monocular depth priors and a new space carving loss to improve NeRF reconstruction from sparse views of complex real-world indoor scenes. This addresses an important limitation of NeRFs needing many views for high quality results.
