# [HypoTermQA: Hypothetical Terms Dataset for Benchmarking Hallucination   Tendency of LLMs](https://arxiv.org/abs/2402.16211)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Large language models (LLMs) have a significant tendency to hallucinate content about non-existent concepts when prompted with a combination of rare and common tokens. Detecting such hallucinations is challenging and requires manual labeling or constrained evaluations. There is a need for an automated, scalable framework to benchmark and efficiently detect the hallucination tendencies of LLMs.

Proposed Solution:
The paper proposes a framework to automatically create a dataset of questions containing hypothetical, non-existent terms along with valid terms. The questions are designed to be coherent yet adversarial. LLMs are then evaluated on their tendency to generate information about these hypothetical terms versus acknowledging the lack of knowledge about them. Additionally, the framework utilizes LLM agents for efficient automated evaluation of the LLM responses on whether they contain hallucinations.  

Main Contributions:
- A scalable methodology to automatically generate a dataset of questions with hypothetical and valid term couples tailored to benchmark hallucination tendency (HypoTermQA dataset).
- Introduction of HypoTermQA Score to measure the performance of LLMs on resisting hallucinations when prompted with hypothetical terms.
- Leveraging LLM agents for efficient automated evaluation of hallucinated content.
- Analysis of state-of-the-art LLMs using the framework revealing over 90% hallucination rate.
- The proposed framework is domain-agnostic and can generate specialized benchmarks for different domains.
- The ability to efficiently create challenging benchmarks can contribute to testing and improving LLMs.

In summary, the paper presents an automated scalable framework for benchmarking and detecting the hallucination tendencies of LLMs using hypothetical terms and LLM agents.
