# [Can Large Language Models Transform Computational Social Science?](https://arxiv.org/abs/2305.03514)

## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It provides a comprehensive evaluation of large language models (LLMs) on a diverse set of 24 classification and generation tasks relevant for computational social science. 2. It develops a standardized prompting methodology and evaluation pipeline to enable fair comparison of different LLMs on these tasks in a zero-shot setting.3. Through this evaluation, it offers guidance to computational social scientists on when and how LLMs can be effectively used to augment human annotation and analysis in social science research. 4. It finds that while LLMs do not fully replace human annotation, they can provide fair to moderate levels of agreement with humans on many tasks, suggesting they are viable for joint human-AI annotation.5. It shows LLMs can produce high quality explanations that approach or exceed human references, suggesting they are well-suited to assist in the creative generation and summary of social science constructs.6. It provides an analysis of the trade-offs between open-source vs industrial LLMs in terms of scale, instruction tuning, and cost for computational social science applications.In summary, the main contribution is a comprehensive benchmark and set of guidelines that help outline the current capabilities and limitations of LLMs as tools for computational social scientists. The results suggest LLMs can radically transform parts of the social science pipeline through human-AI collaboration.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in computational social science:- The paper provides a broad survey of core methods and needs in computational social science across disciplines like linguistics, psychology, political science, and more. This provides helpful context for understanding where and how large language models could be applied as tools. Many other papers focus on a single task or field, so the cross-disciplinary perspective is unique.- The paper systematically evaluates a wide range of language models on an extensive set of 24 diverse tasks spanning classification, parsing, and generation. This provides a comprehensive benchmark for assessing model capabilities on real-world social science problems. In contrast, most prior work evaluates models on just one or two tasks. - The analysis of model scaling laws and the impact of pretraining objectives provides useful insights about model selection tradeoffs for social scientists. Other work often evaluates just one or two models without this kind of analysis.- The paper introduces a set of best practices for prompting large language models to generate consistent outputs for social science tasks. This level of practical guidance for prompt engineering is missing from most existing research.- The discussion of model limitations and risks including bias, fairness, and ethical concerns is more thorough than many papers which focus only on performance. The recommendations for human-in-the-loop annotation are also unique.Overall, the broad task coverage, model analysis, prompt engineering, and discussion of real-world usage make this paper stand out compared to prior work focused on narrower applications of language models for social science. The comprehensive approach provides a helpful roadmap for the field.


## What future research directions do the authors suggest?

The authors suggest several future research directions in the Discussion section:- Explore the performance of LLMs for conversation-level and document-level tasks, especially cross-document reasoning, since LLMs currently have limitations in these areas. The authors suggest studying the unique technical challenges of conversations, long documents, and cross-document reasoning.- Investigate how to handle temporal grounding and rapidly changing events/knowledge in LLMs, since social science data is often time-sensitive. This is challenging as continually re-training LLMs on new data is expensive.- Develop better evaluation metrics and procedures for generative tasks in CSS, as word overlap metrics fail to capture human preferences. New metrics are needed as LLMs approach or surpass human performance.- Study the pros/cons of using LLMs as simulated populations in social science research. While promising, there are dangers like limited perspective diversity. Combining LLMs and real humans may help avoid an algorithmic monoculture.- Explore causality and contrastive explanations from LLMs, since social scientists seek causal theories. LLMs currently lack causal grounding.- Analyze biases and performance differences of LLMs across demographics, cultures, and languages. The current CSS resources are limited.- Develop techniques to teach LLMs specialized vocabulary and constructs from social science taxonomies, which they currently struggle with.In summary, key future directions are improving LLMs for conversation, document, and temporal reasoning tasks; developing better evaluation metrics; studying the use of LLMs as simulated populations; adding causal grounding; analyzing biases; and teaching expert vocabulary.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper explores the potential of large language models (LLMs) like ChatGPT to serve as tools for computational social science (CSS) research. The authors survey core CSS methods across disciplines like linguistics, psychology, and political science, and select 24 representative text analysis tasks. These tasks span utterance, conversation, and document levels, and include both classification (e.g. sentiment, persuasion) and generation (e.g. figurative language explanation, event extraction). 13 LLMs are evaluated on these tasks in a zero-shot setting, focusing on their viability to augment human annotation, optimal model selections, domain utility, and functionality for classification vs generation. Results show that current LLMs can radically transform the CSS pipeline by accelerating annotation and bootstrapping challenging creative tasks, but only in partnership with human experts. LLMs do not fully replace manual analysis due to performance gaps on expert taxonomies. The authors conclude with recommendations for incorporating LLMs into blended human-AI systems for social science research.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:The paper evaluates the potential of large language models (LLMs) like GPT-3 and ChatGPT to serve as tools for computational social science (CSS) research. The authors survey core methods in CSS across disciplines like political science, psychology, and literature. Based on this survey, they select 24 representative text classification and generation tasks as a benchmark suite. These tasks cover various levels of analysis from utterances to full documents. The authors test 13 LLMs on the benchmark tasks in a zero-shot setting using prompt engineering. They find that prompted LLMs do not match fine-tuned models on classification but can still achieve fair agreement with human labels. Thus, LLMs may be best used to augment human annotation pipelines. The benefits of LLMs are compounded as models scale up. For generation tasks, leading models can achieve near parity with dataset references, suggesting LLMs can powerfully assist analysis. Overall, the authors conclude that LLMs can radically transform CSS by partnering with humans to reduce annotation costs and bootstrap challenging tasks like explanation generation. They provide concrete recommendations to guide adoption of LLMs as multipurpose CSS tools.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper:The paper presents an extensive evaluation of various large language models (LLMs) on a diverse set of 24 representative computational social science (CSS) tasks. The tasks cover key areas of CSS research including linguistics, psychology, political science, sociology, literature, and history. The tasks involve both classification (e.g. dialect feature detection, emotion recognition, ideology classification) and text generation (e.g. explaining figurative language, rephrasing for positive psychology). The authors evaluated the zero-shot performance of 13 LLMs on these tasks, including open source models like FLAN and industrial models like GPT-3 and ChatGPT. The LLMs were provided with task instructions and example inputs, and their outputs were evaluated against human references. The results were analyzed to determine the viability of LLMs as CSS tools, recommend models for different use cases, and identify challenges. The evaluation methodology allows the authors to make concrete recommendations for using LLMs to assist with CSS research.
