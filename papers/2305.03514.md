# [Can Large Language Models Transform Computational Social Science?](https://arxiv.org/abs/2305.03514)

## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It provides a comprehensive evaluation of large language models (LLMs) on a diverse set of 24 classification and generation tasks relevant for computational social science. 2. It develops a standardized prompting methodology and evaluation pipeline to enable fair comparison of different LLMs on these tasks in a zero-shot setting.3. Through this evaluation, it offers guidance to computational social scientists on when and how LLMs can be effectively used to augment human annotation and analysis in social science research. 4. It finds that while LLMs do not fully replace human annotation, they can provide fair to moderate levels of agreement with humans on many tasks, suggesting they are viable for joint human-AI annotation.5. It shows LLMs can produce high quality explanations that approach or exceed human references, suggesting they are well-suited to assist in the creative generation and summary of social science constructs.6. It provides an analysis of the trade-offs between open-source vs industrial LLMs in terms of scale, instruction tuning, and cost for computational social science applications.In summary, the main contribution is a comprehensive benchmark and set of guidelines that help outline the current capabilities and limitations of LLMs as tools for computational social scientists. The results suggest LLMs can radically transform parts of the social science pipeline through human-AI collaboration.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in computational social science:- The paper provides a broad survey of core methods and needs in computational social science across disciplines like linguistics, psychology, political science, and more. This provides helpful context for understanding where and how large language models could be applied as tools. Many other papers focus on a single task or field, so the cross-disciplinary perspective is unique.- The paper systematically evaluates a wide range of language models on an extensive set of 24 diverse tasks spanning classification, parsing, and generation. This provides a comprehensive benchmark for assessing model capabilities on real-world social science problems. In contrast, most prior work evaluates models on just one or two tasks. - The analysis of model scaling laws and the impact of pretraining objectives provides useful insights about model selection tradeoffs for social scientists. Other work often evaluates just one or two models without this kind of analysis.- The paper introduces a set of best practices for prompting large language models to generate consistent outputs for social science tasks. This level of practical guidance for prompt engineering is missing from most existing research.- The discussion of model limitations and risks including bias, fairness, and ethical concerns is more thorough than many papers which focus only on performance. The recommendations for human-in-the-loop annotation are also unique.Overall, the broad task coverage, model analysis, prompt engineering, and discussion of real-world usage make this paper stand out compared to prior work focused on narrower applications of language models for social science. The comprehensive approach provides a helpful roadmap for the field.


## What future research directions do the authors suggest?

The authors suggest several future research directions in the Discussion section:- Explore the performance of LLMs for conversation-level and document-level tasks, especially cross-document reasoning, since LLMs currently have limitations in these areas. The authors suggest studying the unique technical challenges of conversations, long documents, and cross-document reasoning.- Investigate how to handle temporal grounding and rapidly changing events/knowledge in LLMs, since social science data is often time-sensitive. This is challenging as continually re-training LLMs on new data is expensive.- Develop better evaluation metrics and procedures for generative tasks in CSS, as word overlap metrics fail to capture human preferences. New metrics are needed as LLMs approach or surpass human performance.- Study the pros/cons of using LLMs as simulated populations in social science research. While promising, there are dangers like limited perspective diversity. Combining LLMs and real humans may help avoid an algorithmic monoculture.- Explore causality and contrastive explanations from LLMs, since social scientists seek causal theories. LLMs currently lack causal grounding.- Analyze biases and performance differences of LLMs across demographics, cultures, and languages. The current CSS resources are limited.- Develop techniques to teach LLMs specialized vocabulary and constructs from social science taxonomies, which they currently struggle with.In summary, key future directions are improving LLMs for conversation, document, and temporal reasoning tasks; developing better evaluation metrics; studying the use of LLMs as simulated populations; adding causal grounding; analyzing biases; and teaching expert vocabulary.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper explores the potential of large language models (LLMs) like ChatGPT to serve as tools for computational social science (CSS) research. The authors survey core CSS methods across disciplines like linguistics, psychology, and political science, and select 24 representative text analysis tasks. These tasks span utterance, conversation, and document levels, and include both classification (e.g. sentiment, persuasion) and generation (e.g. figurative language explanation, event extraction). 13 LLMs are evaluated on these tasks in a zero-shot setting, focusing on their viability to augment human annotation, optimal model selections, domain utility, and functionality for classification vs generation. Results show that current LLMs can radically transform the CSS pipeline by accelerating annotation and bootstrapping challenging creative tasks, but only in partnership with human experts. LLMs do not fully replace manual analysis due to performance gaps on expert taxonomies. The authors conclude with recommendations for incorporating LLMs into blended human-AI systems for social science research.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:The paper evaluates the potential of large language models (LLMs) like GPT-3 and ChatGPT to serve as tools for computational social science (CSS) research. The authors survey core methods in CSS across disciplines like political science, psychology, and literature. Based on this survey, they select 24 representative text classification and generation tasks as a benchmark suite. These tasks cover various levels of analysis from utterances to full documents. The authors test 13 LLMs on the benchmark tasks in a zero-shot setting using prompt engineering. They find that prompted LLMs do not match fine-tuned models on classification but can still achieve fair agreement with human labels. Thus, LLMs may be best used to augment human annotation pipelines. The benefits of LLMs are compounded as models scale up. For generation tasks, leading models can achieve near parity with dataset references, suggesting LLMs can powerfully assist analysis. Overall, the authors conclude that LLMs can radically transform CSS by partnering with humans to reduce annotation costs and bootstrap challenging tasks like explanation generation. They provide concrete recommendations to guide adoption of LLMs as multipurpose CSS tools.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper:The paper presents an extensive evaluation of various large language models (LLMs) on a diverse set of 24 representative computational social science (CSS) tasks. The tasks cover key areas of CSS research including linguistics, psychology, political science, sociology, literature, and history. The tasks involve both classification (e.g. dialect feature detection, emotion recognition, ideology classification) and text generation (e.g. explaining figurative language, rephrasing for positive psychology). The authors evaluated the zero-shot performance of 13 LLMs on these tasks, including open source models like FLAN and industrial models like GPT-3 and ChatGPT. The LLMs were provided with task instructions and example inputs, and their outputs were evaluated against human references. The results were analyzed to determine the viability of LLMs as CSS tools, recommend models for different use cases, and identify challenges. The evaluation methodology allows the authors to make concrete recommendations for using LLMs to assist with CSS research.


## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question addressed in this paper is: Can Large Language Models (LLMs) transform Computational Social Science (CSS)?Specifically, the authors evaluate the viability and utility of using LLMs as tools for various CSS tasks, across four key dimensions:1. Viability: Can LLMs augment or replace human annotation?2. Model Selection: How do different LLM architectures, sizes, and training approaches impact performance on CSS tasks?3. Domain Utility: Are LLMs better suited for certain fields or levels of analysis in CSS?4. Functionality: Can LLMs assist with labeling/classification or generative/explanatory tasks in CSS?To address these questions, the authors survey core CSS methods and select a diverse set of 24 representative tasks. They test 13 LLMs with different sizes, training objectives, and source across this benchmark using zero-shot prompting. Comparisons to supervised baselines allow the authors to assess when LLMs can augment or replace traditional methods. The authors conclude that LLMs can radically improve efficiency of CSS research, best as partners rather than wholesale replacements. They provide concrete recommendations on how CSS researchers can effectively utilize LLMs based on their empirical results.In summary, the central research question is whether LLMs can transform computational social science, which the authors address through a broad empirical analysis to guide LLM adoption in this domain.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper evaluates the potential of large language models to serve as tools for computational social science by benchmarking their performance on a range of representative tasks and finding they can augment but likely not fully replace traditional methods.


## What problem or question is the paper addressing?

Based on my reading, this paper is addressing the potential for large language models (LLMs) like ChatGPT to be useful tools for computational social science (CSS) research. Specifically, it is evaluating whether LLMs can assist with common tasks in CSS like classifying text by various attributes (e.g. sentiment, ideology, etc.) and generating explanations or summaries of social constructs and phenomena found in text data. The key research questions seem to be:1) Viability: Can LLMs effectively perform CSS tasks with zero-shot prompting, and can they augment or potentially replace human annotation?2) Model Selection: How do different LLM architectures, sizes, and training objectives affect performance on CSS tasks?3) Domain Utility: Are LLMs better suited for certain subfields of CSS versus others?4) Functionality: Are LLMs better at classifying text or generating explanations for CSS applications?To answer these questions, the authors survey common methods and needs in CSS fields like psychology, political science, and linguistics. They select a diverse set of 24 representative text classification and text generation tasks. Then they systematically evaluate various LLMs on these tasks with zero-shot prompting and compare to supervised baselines. The goal is to provide CSS researchers with concrete recommendations on if and how LLMs could be incorporated into their workflows.In summary, the paper is assessing if LLMs have the potential to "transform" CSS by serving as widely applicable tools for analyzing text data across social science disciplines. The authors aim to provide empirical results and actionable guidelines to help researchers determine if and when LLMs are suitable for their specific needs.
