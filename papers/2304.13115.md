# [AVFace: Towards Detailed Audio-Visual 4D Face Reconstruction](https://arxiv.org/abs/2304.13115)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the key points seem to be:

- The main goal is to develop a method for accurate 4D face reconstruction from monocular talking face videos, without requiring any 3D ground truth data for training. 

- The key research question is how to effectively combine audio and visual information from talking face videos to get an accurate 4D facial geometry reconstruction that captures details like wrinkles and is robust to occlusions.

- The central hypothesis is that leveraging both modalities - speech audio and video frames - and modeling temporal information will allow complementing the limitations of each modality and lead to better performance than video-only or audio-only methods.

- The proposed method AVFace follows a coarse-to-fine approach to reconstruct the 4D facial geometry:
  - A coarse stage estimates basic geometry per frame using both audio and video.
  - A lip refinement stage further improves the lip shape using audio.
  - A fine stage adds geometric details guided by face normals.

- Temporal modeling via transformers and fine-tuning on synthetic occlusions makes the method robust when either modality is insufficient, like in case of occlusions.

- The key innovations are the joint audio-video modeling with transformers, the lip refinement network, and use of face normals to get detail - all without requiring any 3D ground truth scans.

In summary, the main hypothesis is that cleverly combining audio, video and temporal modeling can lead to highly accurate and robust 4D facial reconstruction from monocular in-the-wild videos, surpassing current state-of-the-art methods. The experiments aim to demonstrate the superiority of the proposed AVFace method.
