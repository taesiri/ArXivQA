# [HMD-NeMo: Online 3D Avatar Motion Generation From Sparse Observations](https://arxiv.org/abs/2308.11261)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to generate full-body avatar motion in real-time given only sparse input from a head-mounted device (HMD), including scenarios where the hands may only be partially visible or out of view entirely. The key hypothesis is that a neural network model can learn to accurately predict full body motion from limited HMD input in an online fashion, even with incomplete hand observations.The paper proposes HMD-NeMo, a neural network model to generate full body avatar motion from sparse HMD signals. The main capabilities and hypotheses it aims to demonstrate are:- Can accurately predict full body motion including global trajectory from only head and hand positions/orientations. - Can handle scenarios where hands are only partially visible (e.g. due to limited hand tracking camera field-of-view) by filling in plausible motions when hands are missing.- Generates motions in an online, real-time fashion, predicting each pose given only current and past HMD observations.- Achieves state-of-the-art performance on a standard motion capture dataset, demonstrating the approach generalizes well.- Provides intuitive trade-off between motion accuracy and visual plausibility when optimizing pose predictions to match observations.In summary, the main research question is real-time full avatar motion prediction from very sparse HMD inputs, even with incomplete hand observations, which requires making plausible guesses about unobserved body motions. The key hypothesis is that an online neural network model can learn to do this effectively.


## What is the main contribution of this paper?

The main contribution of this paper is proposing HMD-NeMo, a novel approach for generating full-body avatar motion in real-time given sparse input from a head-mounted device (HMD). The key highlights are:- HMD-NeMo is the first unified approach that can generate plausible and accurate full body motion from HMD signals in both motion controller and hand tracking scenarios. Prior work focused only on motion controller scenarios where both hands are fully visible. - It introduces Temporally Adaptable Mask Tokens (TAMTs) to handle missing hand observations in a temporally coherent way. TAMTs use information from previous timesteps to fill in plausible representations when hands go out of view.- The model architecture combines RNNs and self-attention to capture both temporal and spatial relationships between different input signals (head, hands).- Extensive experiments show HMD-NeMo achieves state-of-the-art performance on a large motion capture dataset. It also provides good results even with partial hand visibility.- The paper provides ablation studies analyzing the impact of different components of HMD-NeMo. It also discusses optimization strategies to balance plausibility and accuracy based on application needs.In summary, the key innovation is enabling realistic avatar motion from HMDs even with incomplete hand observations, which removes a major limitation of prior work. The experiments and analyses provide useful insights into generating human motion from sparse on-body sensors.
