# [Look Before You Leap: A Universal Emergent Decomposition of Retrieval   Tasks in Language Models](https://arxiv.org/abs/2312.10091)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
As language models (LMs) reach advanced capabilities, efficiently supervising their internal processes becomes critical for safety. However, existing techniques only examine model outputs, not internal mechanisms, limiting oversight. The paper introduces the problem of "internal oversight" - verifying models solve problems correctly internally.  

The paper also lacks techniques to study LMs on diverse tasks at scale to find common internal structures. Prior work uses narrow, custom-designed datasets limiting discoveries.

Solution: 
The paper makes 3 main contributions:

1) Introduces ORION, a collection of retrieval tasks spanning diverse domains, enabling large-scale causal analysis. ORION tasks share an abstract structure where the "context" provides information and the "request" queries an attribute.

2) Discovers models decomposed retrieval tasks into processing the request then retrieving information from the context, with clean separation of layers handling each step. This held across 18 models and 6 domains, suggesting an "emergent universal motif".

3) Leverages this decomposition for a proof-of-concept of scalable "internal oversight", using causal interventions to mitigate prompt injection in QA requiring human verification on only one input. Technique drastically improves performance on adversarial examples.

Overall, the paper proposes studying models via high-level causal structures rather than narrow cases. It shows this can discover task commonalities across models and enable oversight applications. The work pioneers using interpretability for scalable internal model safety.
