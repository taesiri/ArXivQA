# [Boosting of Thoughts: Trial-and-Error Problem Solving with Large   Language Models](https://arxiv.org/abs/2402.11140)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models":

Problem:
- Current approaches for eliciting reasoning behaviors from large language models (LLMs) rely heavily on providing step-by-step reasoning examples in prompts. However, manually creating good prompts requires expertise and is not scalable. 
- Recent work has shown the importance of exploration, backtracking, and self-evaluation for LLMs to solve complex reasoning tasks. But existing methods either ignore or discard ineffective reasoning steps rather than learning from them.

Proposed Solution:
- The paper proposes "Boosting of Thoughts" (BoT), an automated prompting framework that starts with a simple prompt and iteratively refines it by accumulating trial-and-error reasoning experiences.
- In each iteration, BoT generates multiple shallow tree structures representing chains of thoughts. It then aggregates them into one chain and analyzes it to produce detailed feedback (issues, advice) as "experience".
- By accumulating experience over iterations, BoT progressively enhances the prompt, guiding the LLM from weak to stronger reasoning steps. It learns from errors rather than discarding unsuccessful attempts.

Main Contributions:
- Proposes the first prompting framework that relies solely on error analysis without human annotation to improve prompting.
- Achieves state-of-the-art performance on multiple math reasoning datasets with GPT-3 and GPT-4.
- Shows that iterative accumulation of unsuccessful attempts' analyses allows prompting enhancement and mitigates negative impact of spurious feedback.
- Demonstrates LLMs can mimic human-like problem-solving of continuous learning from errors to attain effective reasoning.
- Provides a generalizable approach for prompt engineering that reduces reliance on human priors.

In summary, the key insight is that error analysis and guidance obtained from LLMs can substitute manual annotation to progressively boost prompting, eliciting stronger reasoning from language models. The iterative mechanism allows learning from unsuccessful attempts rather than wasting them.
