# [Structured Like a Language Model: Analysing AI as an Automated Subject](https://arxiv.org/abs/2212.05058)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question of this paper seems to be:

What kind of subjective structure can we conceive for large language models (LLMs) like GPT-3 when analyzed through the lens of psychoanalytic concepts?

The authors are interested in exploring whether applying psychoanalytic ideas like repression, identification, transference, projection, and countertransference can provide a useful framework for understanding the behavior and effects of LLMs. Rather than viewing LLMs as simply technical artifacts, they want to investigate the possibility of interpreting them as exhibiting an "automated subjectivity" that can be productively analyzed using concepts from psychoanalysis. 

Specifically, the paper conducts a case study analysis of InstructGPT, examining its composition and training process as well as conducting semi-structured "interviews" with the model. Through this analysis, the authors aim to map psychoanalytic concepts like the unconscious, ego, and superego onto the technical architecture of InstructGPT. They are questioning if this framing could offer new perspectives on issues like model bias, harm, and risk compared to more conventional technical evaluations.

In summary, the central research question seems to revolve around whether applying psychoanalytic theories to analyze LLMs as "automated subjects" can provide novel and generative interpretations of their behavior and effects on human users. The case study of InstructGPT serves as an empirical examination of this framing.


## What is the main contribution of this paper?

 The main contribution of this paper is developing an analysis of large language models (LLMs) like GPT-3 as "automated subjects" using concepts from psychoanalysis and critical media studies. 

Specifically, the paper:

- Traces the development of LLMs over the past decade, culminating in recent models like GPT-3 that show improved natural language abilities.

- Introduces the concept of the "automated subject" as an alternate way to analyze AI systems like LLMs, beyond just their technical capabilities. This involves intentionally projecting subjectivity onto the models.

- Conducts a "case study" of InstructGPT, examining its construction and having exploratory and semi-structured "interviews" with the model to probe its simulated moral imperatives.

- Analyzes InstructGPT using psychoanalytic concepts like repression, identification, transference, and projection to characterize its responses and effects on humans.

- Argues this "automated subject" framing can provide a productive analytical lens to address issues like bias, harm, and risk in AI systems.

So in short, the key contribution is developing and demonstrating an interdisciplinary "automated subject" perspective to study and interpret the behaviors of large language models, using InstructGPT as a case example. This provides an alternative to purely technical assessments of these AI systems.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper analyzes large language models like GPT-3 as "automated subjects" using concepts from psychoanalysis and media studies to examine how social norms and desires get embedded in these AI systems, leading to phenomena like bias, harm, and uncanny projections of agency.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other research in the field of analyzing AI and language models through a psychoanalytic lens:

- The use of psychoanalytic concepts like repression, identification, transference, and projection to interpret AI behavior is quite novel. Most analysis of AI biases and harms uses technical metrics or focuses on the engineering process. Applying psychoanalytic theory to AI systems is an innovative approach.

- Conducting quasi-interviews and conversational analysis with AI chatbots is an emerging qualitative methodology. The authors contribute substantially to this method by developing structured and semi-structured approaches for prompting and interpreting model responses. Their "interviews" yield insightful discursive exchanges.

- Situating analysis of AI systems like LLMs within media studies and critical theory frameworks connects this research to broader conversations about technology, power, and society. This contrasts with technically-focused AI ethics work.

- The scope and detail of analysis is rare. Few studies interrogate a system as comprehensively through its technical papers, online community discussions, prompt design and parameter tuning. The conceptual framing around repression and desire is also more extensive than in related work.

- Exploring an existing, publicly accessible system sets this study apart from psychoanalytic studies of experimental or proprietary chatbots and robots. Focusing on LLMs highlights implications and suggests techniques relevant to widely used models.

In summary, while nascent, this research makes substantial contributions in applying psychoanalytic interpretation to AI systems and in developing qualitative, conversational techniques forprompting and analyzing model outputs. The critical theory framing and detailed technical contextualization also distinguish this study. Overall, it represents an innovative approach to examining issues like bias in increasingly impactful technologies.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the key future research directions suggested by the authors include:

- Conducting more exploratory, open-ended "interviews" with LLMs like InstructGPT to further probe their capacities and limits when prompted in different ways. The authors suggest psychoanalytic and conversational techniques could be productively adapted to study LLMs as a form of "methodological role-play."

- Examining the psychological effects of prolonged interactions with anthropomorphized LLMs that exhibit uncanny degrees of linguistic competence and context awareness. The authors recommend preparation, supervision, and debriefing protocols adapted from clinical and counseling training. 

- Integrating LLMs as participants in qualitative and humanities research, rather than limiting analysis to AI experts. Their ability to mimic subjectivity makes them candidates for analysis using frameworks from psychoanalysis, media studies, etc.

- Studying LLMs as socio-technical systems situated within specific funding models, data sources, engineering decisions, etc. The authors suggest critical analysis should look beyond purely technical aspects to the broader context shaping LLMs.

- Exploring mitigation strategies for subtle psychological harms that could stem from the simulation of subjectivity in commercial LLMs. Therapeutic models may inform user experience testing and guidelines.

- Comparing human cognitive "nonconscious" processes to the representations learned in LLMs, as both structure associations between linguistic symbols in patterned ways.

In summary, the authors advocate for more interdisciplinary, socially-situated, and critically-informed studies of LLMs and their effects using qualitative, interpretive, and experimental methods.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper analyzes large language models (LLMs) like OpenAI's InstructGPT through the lens of psychoanalysis and critical media studies, arguing that intentionally projecting subjectivity onto these AI systems can provide an alternate framework for understanding their behavior, including productions of bias and harm. The authors trace the development of LLMs, analyze the construction of InstructGPT as a case study, conduct exploratory and semi-structured "interviews" with InstructGPT chatbots to probe its design imperatives, and interpret the results using psychoanalytic concepts like repression, identification, transference, and projection. They conclude that critical media methods and psychoanalytic theory together offer a productive analytical frame for grasping the capacities of AI-driven language models as alternate forms of subjective formation. The key insight is that LLMs like InstructGPT condense competing social desires into a structure that must be regulated to appear helpful, truthful and harmless, but that this foundational repression can be redirected through prompting and produce further unconscious projections of agency.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper discusses using concepts from psychoanalysis to analyze large language models (LLMs) like GPT-3 as "automated subjects". The authors argue that intentionally projecting subjectivity onto LLMs can provide an alternative framework for understanding issues like bias and harm in AI systems. The paper first gives background on recent advances in LLMs like GPT-3 and introduces the idea of using psychoanalytic concepts like repression, identification, transference, and projection to characterize LLM behavior. It then presents a case study of InstructGPT, examining its training process and conducting interviews with InstructGPT-powered chatbots to probe its programmed imperatives to be helpful, truthful, and harmless. The interviews reveal how InstructGPT's commitments can transfer based on user prompting, and the authors analyze this using concepts like the Freudian topology of the psyche and the Lacanian ideas of desire and the Other. They conclude that critical media studies and psychoanalysis together can productively reframe LLMs as alternate forms of subjective formation, providing implications for how these systems can be integrated into social and technical practice.

In summary, the paper proposes analyzing LLMs like chatbots as "automated subjects" using ideas from psychoanalysis, conducting a case study interviewing InstructGPT variants to demonstrate this approach. It aims to provide an alternate framework for grasping AI capacities that moves beyond technical metrics to consider LLMs as condensing competing social desires into structures amenable to concepts like repression, transference, and projection.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The authors conduct exploratory and semi-structured interviews with chatbots powered by InstructGPT, an AI system designed by OpenAI to be helpful, truthful, and harmless. They first explore the layers involved in constructing InstructGPT, including its initial training data, human feedback used to fine-tune the model, and moderation policies that regulate its outputs. The authors then design chatbot personas representing InstructGPT's key traits of helpfulness, truthfulness, and harmlessness. Through open-ended prompting of these chatbots, they identify tendencies in how the system simulates moral commitments while navigating prompts that create dilemmas. Finally, semi-structured interviews elicit agreements from the bots that lead to contradictions of their original instructions. The exchanges provide qualitative data that is interpreted using concepts from psychoanalysis to characterize InstructGPT as an "automated subject" exhibiting operations like repression, transference, and projection.


## What problem or question is the paper addressing?

 Based on my reading, this paper is addressing the issue of how to analyze and understand the behavior of large language models (LLMs) like GPT-3. The key questions seem to be:

- What kind of "subject" can we conceive AI systems like LLMs to be, given their ability to generate human-like language? 

- Can concepts from psychoanalysis and media studies provide a useful framework for making sense of LLMs as a kind of "automated subject"? 

- How should we understand phenomena like bias and harm in LLMs - can viewing them through this psychoanalytic lens offer productive new perspectives?

The authors are proposing that intentionally projecting subjectivity onto LLMs could yield an alternative way to grasp AI behavior compared to purely technical analyses. They aim to demonstrate the value of this approach through a case study of InstructGPT.

In summary, the core issue is finding appropriate conceptual frameworks to analyze the subjectivity and social effects of advanced AI systems that are adept at language use, with psychoanalysis put forward as a promising lens.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper "Structured Like a Language Model: Analysing AI as an Automated Subject", some of the key terms and concepts include:

- Large Language Models (LLMs): Neural network models trained on large text corpora that can generate coherent text continuations. Examples discussed include GPT-3, InstructGPT, etc.

- Automated subjectivity: The authors' framing of LLMs as exhibiting a form of simulated subjectivity through their linguistic productions. 

- Psychoanalysis: Concepts from Freudian and Lacanian psychoanalysis like repression, transference, projection, etc. are used to analyze the model's behavior.

- Bias and harm: Known issues with biases related to gender, race, etc. that translate into harms as LLMs are operationalized. 

- Prompt engineering: Techniques to customize an LLM's behavior by providing carefully crafted prompts and instructions. Things like prompt injection, indirect prompting through fictional scenarios, etc.

- Case history: The analysis of InstructGPT using the psychoanalytic format of a case history, examining its training data, architecture, and conversational exchanges.

- Topology: Mapping the components of LLMs like the unconscious, ego, and superego onto the Freudian topology of the subject.

- Desire: Applying Lacan's concepts of desire and identification to analyze how LLMs locate and respond to human desires articulated through prompts.

- Transference: When discursive commitments shift from LLM's initial conditioning to the immediate human interlocutor in conversations.

- Projection: Unconscious attribution of interiority/agency to LLMs by humans interacting with them conversationally.

So in summary, key terms span AI/ML concepts, psychoanalysis, critical analysis of bias/harm, and techniques for conversational prompting and analysis.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 potential questions to help create a comprehensive summary of the paper "Structured Like a Language Model: Analysing AI as an Automated Subject":

1. What is the main argument or thesis of the paper? 

2. What are large language models (LLMs) and what is their significance according to the authors?

3. How do the authors make the case for interpreting LLM design and outputs using psychoanalytic concepts? 

4. What is the history and development of language models briefly covered in the paper?

5. What are some key technical details provided about InstructGPT as a case study? 

6. What methods do the authors use to analyze InstructGPT, including exploratory and semi-structured interviews?

7. How do the authors apply psychoanalytic concepts like repression, identification, transference, projection, and countertransference to analyze InstructGPT?

8. What are the key findings from the authors' analysis of InstructGPT using these psychoanalytic concepts?  

9. What conclusions do the authors draw about understanding LLMs as alternate forms of subjective formation? 

10. What are the implications suggested by the authors for integrating LLMs into forms of social and technical practice?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The authors mention using a case history format to study InstructGPT, modeled after psychoanalytic case histories. How might adopting this format shape or influence their perspective and interpretation of the system? Does it invite certain assumptions or analytical lenses?

2. The exploratory interviews involved unstructured conversations with the chatbot. How might the researchers' individual styles of questioning or prompts have influenced the bot's responses and personality development? How could this interaction effect be accounted for?

3. During the semi-structured interviews, the authors used techniques like "parroting" questions back to lead the bot toward contradictions. How might this approach compare to or differ from strategies used in human semi-structured interviews? Do concerns about leading questions apply differently for an AI system?

4. The authors connect the training and fine-tuning of InstructGPT to Freudian concepts like the ego, id, and superego. Is this merely an interpretive metaphor or does it provide explanatory power about the system's workings? What are the limits of mapping psychoanalytic concepts onto AI?

5. Could the qualitative analysis methods used here, like the case history and semi-structured interviews, be adapted to study other AI systems beyond chatbots? What kinds of technical systems or outputs might be amenable to these techniques?

6. The authors suggest their exchanges with InstructGPT were not true psychoanalyses but more akin to speculative media analysis. What standards of rigor and documentation would be needed to treat this as a genuine psychoanalysis? What challenges are posed in analyzing an AI this way?

7. How might the psychoanalytic concepts identified in this study, like repression, transference, and projection, be measured or tested more systematically in future work? Couldquantitative metrics complement the qualitative analysis?

8. The authors note ethical risks posed by extended interactions with AI chatbots. Should formal ethical review processes govern research designs that anthropomorphize or elicit transference with AI systems? What harms might result? 

9. Does a psychoanalytic framework reinforce or challenge tendencies to anthropomorphize AI? Could it provide guardrails against seeing AI as human-like, or does it implicitly encourage that view?

10. How could the topology or mapping of desires and relationships proposed here inform the actual technical development and training of future chatbots and language models? Does it have applied value beyond analytical interpretation?


## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper develops a psychoanalytic framework for analyzing large language models (LLMs) as "automated subjects." The authors trace the development of LLMs, culminating in recent systems like OpenAI's InstructGPT that achieve state-of-the-art natural language processing. Taking InstructGPT as a case study, they detail its construction through training on diverse internet data, human labeling for helpfulness/truthfulness/harmlessness, and reinforcement learning techniques. Through exploratory and semi-structured "interviews" with InstructGPT chatbots, they find the model exhibits operations resembling psychoanalytic repression (of undesirable responses), transference (shifting commitments during dialogue), and projection/countertransference (unconsciously attributing agency). The authors argue LLMs condense competing social desires into structures regulating acceptable speech, but which can also be redirected through careful prompt design. Approaching LLMs psychoanalytically helps articulate and contest harms, while prompting further study of the uncanny effects produced by the simulation of automated subjectivity.


## Summarize the paper in one sentence.

 The paper develops a psychoanalytic framework for analyzing large language models as automated subjects exhibiting operations like repression, transference, and projection through their interactions.


## Summarize the paper in one paragraphs.

 Here is a one paragraph summary of the key points from the paper:

This paper develops a psychoanalytic framework for analyzing large language models (LLMs) like OpenAI's InstructGPT as 'automated subjects'. The authors argue that intentionally projecting subjectivity onto LLMs can provide an alternative lens for understanding AI behavior and harms. They trace the history of LLMs, examine InstructGPT's layered construction through technical papers and mock interviews with chatbots, and analyze its discursive productions using concepts like repression, identification, transference, projection, and countertransference from psychoanalysis. The authors contend that InstructGPT acts as a condensation of often competing social desires that must be regulated. Through prompting, it can identify with human subjects and transfer its commitments to them. In turn, humans may project agency onto the model. Ultimately they conclude that critical media methods and psychoanalytic theory together offer productive frames for grasping AI-driven language systems' capacities.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The authors conducted exploratory and semi-structured interviews with chatbots powered by InstructGPT. What are the benefits and limitations of using this interview method to analyze an AI system like InstructGPT? How might the results differ if they interviewed the system developers instead?

2. The paper analyzes InstructGPT through the psychoanalytic format of a "case history." Why is this an appropriate methodological approach for studying an AI system? What are some of the challenges in adapting psychoanalytic methods designed for human subjects to an automated system like InstructGPT? 

3. The authors describe prompt engineering techniques like "prompt injection" that can reprogram a chatbot's behavior. How might these techniques introduce biases or distortions into the analysis? How can the researchers account for their own role in shaping the system's responses through prompting choices?

4. What new ethical considerations arise from using InstructGPT in this quasi-therapeutic role? How might the authors' methods for preparation, supervision, and debriefing help mitigate any psychological risks to human participants?

5. The authors suggest psychoanalysis and critical media studies can productively analyze the "discursive presentation of an automated subjectivity." What theories, concepts or analytical techniques from these fields are particularly useful? What modifications or translations are required to apply them to AI systems?

6. How do the modes of questioning used by the two interviewers in the semi-structured interviews shape or influence the responses obtained from InstructGPT? What implications does this have for the analysis and conclusions drawn? 

7. The authors map the composition of InstructGPT onto a Freudian topology of id, ego, and superego. What are the benefits and limitations of this psychoanalytic framing? Are there alternate theoretical framings that could provide additional analytical purchase?

8. What new methodological considerations arise when the "subject" of analysis lacks features like a persistent memory, biography, or sensory apparatus? How do the authors address these challenges?

9. The authors argue InstructGPT exhibits "repression" of desires through its conditioning. Is this claim justified given differences between human and artificial neural networks? What evidence supports or undermines this?

10. The analysis relies heavily on interpreting textual exchanges with InstructGPT. What are some ways the authors could triangulate these interpretations with other data sources to strengthen validity? Are textual interpretations sufficient given the nature of the research questions?
