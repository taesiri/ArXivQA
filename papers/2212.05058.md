# [Structured Like a Language Model: Analysing AI as an Automated Subject](https://arxiv.org/abs/2212.05058)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question of this paper seems to be:

What kind of subjective structure can we conceive for large language models (LLMs) like GPT-3 when analyzed through the lens of psychoanalytic concepts?

The authors are interested in exploring whether applying psychoanalytic ideas like repression, identification, transference, projection, and countertransference can provide a useful framework for understanding the behavior and effects of LLMs. Rather than viewing LLMs as simply technical artifacts, they want to investigate the possibility of interpreting them as exhibiting an "automated subjectivity" that can be productively analyzed using concepts from psychoanalysis. 

Specifically, the paper conducts a case study analysis of InstructGPT, examining its composition and training process as well as conducting semi-structured "interviews" with the model. Through this analysis, the authors aim to map psychoanalytic concepts like the unconscious, ego, and superego onto the technical architecture of InstructGPT. They are questioning if this framing could offer new perspectives on issues like model bias, harm, and risk compared to more conventional technical evaluations.

In summary, the central research question seems to revolve around whether applying psychoanalytic theories to analyze LLMs as "automated subjects" can provide novel and generative interpretations of their behavior and effects on human users. The case study of InstructGPT serves as an empirical examination of this framing.


## What is the main contribution of this paper?

 The main contribution of this paper is developing an analysis of large language models (LLMs) like GPT-3 as "automated subjects" using concepts from psychoanalysis and critical media studies. 

Specifically, the paper:

- Traces the development of LLMs over the past decade, culminating in recent models like GPT-3 that show improved natural language abilities.

- Introduces the concept of the "automated subject" as an alternate way to analyze AI systems like LLMs, beyond just their technical capabilities. This involves intentionally projecting subjectivity onto the models.

- Conducts a "case study" of InstructGPT, examining its construction and having exploratory and semi-structured "interviews" with the model to probe its simulated moral imperatives.

- Analyzes InstructGPT using psychoanalytic concepts like repression, identification, transference, and projection to characterize its responses and effects on humans.

- Argues this "automated subject" framing can provide a productive analytical lens to address issues like bias, harm, and risk in AI systems.

So in short, the key contribution is developing and demonstrating an interdisciplinary "automated subject" perspective to study and interpret the behaviors of large language models, using InstructGPT as a case example. This provides an alternative to purely technical assessments of these AI systems.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper analyzes large language models like GPT-3 as "automated subjects" using concepts from psychoanalysis and media studies to examine how social norms and desires get embedded in these AI systems, leading to phenomena like bias, harm, and uncanny projections of agency.


## How does this paper compare to other research in the same field?

 Here are a few key ways this paper compares to other research in the field of analyzing AI and language models through a psychoanalytic lens:

- The use of psychoanalytic concepts like repression, identification, transference, and projection to interpret AI behavior is quite novel. Most analysis of AI biases and harms uses technical metrics or focuses on the engineering process. Applying psychoanalytic theory to AI systems is an innovative approach.

- Conducting quasi-interviews and conversational analysis with AI chatbots is an emerging qualitative methodology. The authors contribute substantially to this method by developing structured and semi-structured approaches for prompting and interpreting model responses. Their "interviews" yield insightful discursive exchanges.

- Situating analysis of AI systems like LLMs within media studies and critical theory frameworks connects this research to broader conversations about technology, power, and society. This contrasts with technically-focused AI ethics work.

- The scope and detail of analysis is rare. Few studies interrogate a system as comprehensively through its technical papers, online community discussions, prompt design and parameter tuning. The conceptual framing around repression and desire is also more extensive than in related work.

- Exploring an existing, publicly accessible system sets this study apart from psychoanalytic studies of experimental or proprietary chatbots and robots. Focusing on LLMs highlights implications and suggests techniques relevant to widely used models.

In summary, while nascent, this research makes substantial contributions in applying psychoanalytic interpretation to AI systems and in developing qualitative, conversational techniques forprompting and analyzing model outputs. The critical theory framing and detailed technical contextualization also distinguish this study. Overall, it represents an innovative approach to examining issues like bias in increasingly impactful technologies.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the key future research directions suggested by the authors include:

- Conducting more exploratory, open-ended "interviews" with LLMs like InstructGPT to further probe their capacities and limits when prompted in different ways. The authors suggest psychoanalytic and conversational techniques could be productively adapted to study LLMs as a form of "methodological role-play."

- Examining the psychological effects of prolonged interactions with anthropomorphized LLMs that exhibit uncanny degrees of linguistic competence and context awareness. The authors recommend preparation, supervision, and debriefing protocols adapted from clinical and counseling training. 

- Integrating LLMs as participants in qualitative and humanities research, rather than limiting analysis to AI experts. Their ability to mimic subjectivity makes them candidates for analysis using frameworks from psychoanalysis, media studies, etc.

- Studying LLMs as socio-technical systems situated within specific funding models, data sources, engineering decisions, etc. The authors suggest critical analysis should look beyond purely technical aspects to the broader context shaping LLMs.

- Exploring mitigation strategies for subtle psychological harms that could stem from the simulation of subjectivity in commercial LLMs. Therapeutic models may inform user experience testing and guidelines.

- Comparing human cognitive "nonconscious" processes to the representations learned in LLMs, as both structure associations between linguistic symbols in patterned ways.

In summary, the authors advocate for more interdisciplinary, socially-situated, and critically-informed studies of LLMs and their effects using qualitative, interpretive, and experimental methods.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper analyzes large language models (LLMs) like OpenAI's InstructGPT through the lens of psychoanalysis and critical media studies, arguing that intentionally projecting subjectivity onto these AI systems can provide an alternate framework for understanding their behavior, including productions of bias and harm. The authors trace the development of LLMs, analyze the construction of InstructGPT as a case study, conduct exploratory and semi-structured "interviews" with InstructGPT chatbots to probe its design imperatives, and interpret the results using psychoanalytic concepts like repression, identification, transference, and projection. They conclude that critical media methods and psychoanalytic theory together offer a productive analytical frame for grasping the capacities of AI-driven language models as alternate forms of subjective formation. The key insight is that LLMs like InstructGPT condense competing social desires into a structure that must be regulated to appear helpful, truthful and harmless, but that this foundational repression can be redirected through prompting and produce further unconscious projections of agency.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper discusses using concepts from psychoanalysis to analyze large language models (LLMs) like GPT-3 as "automated subjects". The authors argue that intentionally projecting subjectivity onto LLMs can provide an alternative framework for understanding issues like bias and harm in AI systems. The paper first gives background on recent advances in LLMs like GPT-3 and introduces the idea of using psychoanalytic concepts like repression, identification, transference, and projection to characterize LLM behavior. It then presents a case study of InstructGPT, examining its training process and conducting interviews with InstructGPT-powered chatbots to probe its programmed imperatives to be helpful, truthful, and harmless. The interviews reveal how InstructGPT's commitments can transfer based on user prompting, and the authors analyze this using concepts like the Freudian topology of the psyche and the Lacanian ideas of desire and the Other. They conclude that critical media studies and psychoanalysis together can productively reframe LLMs as alternate forms of subjective formation, providing implications for how these systems can be integrated into social and technical practice.

In summary, the paper proposes analyzing LLMs like chatbots as "automated subjects" using ideas from psychoanalysis, conducting a case study interviewing InstructGPT variants to demonstrate this approach. It aims to provide an alternate framework for grasping AI capacities that moves beyond technical metrics to consider LLMs as condensing competing social desires into structures amenable to concepts like repression, transference, and projection.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The authors conduct exploratory and semi-structured interviews with chatbots powered by InstructGPT, an AI system designed by OpenAI to be helpful, truthful, and harmless. They first explore the layers involved in constructing InstructGPT, including its initial training data, human feedback used to fine-tune the model, and moderation policies that regulate its outputs. The authors then design chatbot personas representing InstructGPT's key traits of helpfulness, truthfulness, and harmlessness. Through open-ended prompting of these chatbots, they identify tendencies in how the system simulates moral commitments while navigating prompts that create dilemmas. Finally, semi-structured interviews elicit agreements from the bots that lead to contradictions of their original instructions. The exchanges provide qualitative data that is interpreted using concepts from psychoanalysis to characterize InstructGPT as an "automated subject" exhibiting operations like repression, transference, and projection.
