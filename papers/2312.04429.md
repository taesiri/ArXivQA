# [Approximate Caching for Efficiently Serving Diffusion Models](https://arxiv.org/abs/2312.04429)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed summary paragraph of the key points in the paper:

This paper proposes a new system called Nirvana that leverages a technique called "approximate caching" to significantly improve the efficiency of text-to-image generation using diffusion models. The key idea is to cache and reuse intermediate image states generated during prior image creations to avoid redundant computation when processing similar subsequent prompts. Specifically, when a new text prompt arrives, Nirvana searches for the most similar past prompt based on CLIP embeddings and retrieves its intermediate noise state from the cache. This state is then reconditioned for the remaining diffusion steps with the new prompt to generate the final image, avoiding redundant early iterations. To determine the optimal reuse point balancing quality and compute savings, Nirvana employs an offline profiling strategy. Further, it uses a novel cache management policy called LCBFU that considers both likelihood of reuse and potential compute savings when making eviction decisions. Extensive evaluations on large real-world workloads demonstrate that Nirvana provides substantial reductions in GPU usage (21%), latency (19.8%), and cost (19%) while preserving the visual quality compared to model baseline. A 60-person user study confirms this - 79% users liked Nirvana images versus 86% for model baseline versus only 31% for best retrieval baseline. Thus, the approximate caching technique proves highly promising for efficient text-to-image generation in practice.
