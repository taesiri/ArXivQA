# [Towards mitigating uncann(eye)ness in face swaps via gaze-centric loss   terms](https://arxiv.org/abs/2402.03188)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Recent advances have enabled highly realistic face swapping, but these swapped faces are still perceived differently than real faces. A key difference is in viewer behavior surrounding the eyes.
- Face swapping models don't explicitly focus on reconstructing the eyes well, instead using loss functions that consider the whole face equally. This leads to lower quality eyes. 
- The authors hypothesize that the poor eye reconstructions contribute to an "uncanny valley" effect where the swapped faces seem unnatural.

Proposed Solution:
- The authors first confirm that face swaps elicit more uncanny feelings in viewers compared to real videos.
- They propose a new loss function to train face swap models that leverages a pretrained gaze estimation network. This provides an explicit focus on accurately reconstructing the gaze direction.
- The gaze loss term penalizes errors between the predicted gaze angles of the original and reconstructed faces.

Contributions:
- First work analyzing face swaps under the lens of the uncanny valley, showing they do tend to be perceived as uncanny.
- Novel gaze-centric loss function for face swap training that significantly improves gaze direction over baseline methods.
- Analysis showing the improved gaze reconstructions make the eyes less reliable for human detection of face swaps.
- Modular contribution allowing gaze constraints to be incorporated into many face swap training regimes.

In summary, this work analyzes the uncanniness of face swaps and proposes a new training approach to improve gaze reconstruction. This is shown to impact human perception and could alleviate negative responses that limit applications of the technology.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper investigates the uncanniness of face swaps, proposes a novel loss function to improve gaze reconstruction that significantly reduces gaze error, and shows this method impacts user perception by making the eyes less reliable for deepfake detection while not significantly reducing uncanniness.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1) Providing evidence that face swaps elicit feelings of uncanniness in viewers. The authors conduct a perceptual study to demonstrate that face swapped videos are perceived as more uncanny than original videos.

2) Proposing a novel loss equation to train face swapping models that incorporates a pretrained gaze estimation network. This explicitly focuses training on accurately reconstructing the gaze directions from the original video. 

3) Showing quantitative improvements in gaze angle reconstruction accuracy from using their proposed loss term over baseline methods. They reduce average gaze error by over 20% compared to a baseline face swap model.

4) Demonstrating the efficacy of their gaze-focused training method in a perceptual study. The study reveals differences in human deepfake detection performance, with the eyes being a less prominent deciding factor when evaluating the face swaps generated by their proposed method.

In summary, the key innovations are formally establishing the uncanniness of face swaps, and introducing a flexible yet effective technique to enhance gaze reconstruction that could extend existing face swapping pipelines. The gaze-focused training paradigm leads to measurable perceptual differences compared to baseline models.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the main keywords and key terms associated with it are:

- Face swapping
- Gaze estimation 
- Perception
- Uncanny valley
- Deepfake detection
- Loss functions
- Expert models
- Attribute importance

The paper focuses on improving face swapping methods, particularly around the eye region, in order to reduce perceived uncanniness and make the swaps harder to detect as fake. It proposes novel loss functions that leverage gaze estimation to better preserve gaze direction during training. The paper evaluates these methods both quantitatively on gaze error and qualitatively regarding uncanniness and attribute importance during deepfake detection tasks. So the key terms relate to face manipulation methods, especially gaze behavior, and perceptual evaluation.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The proposed method introduces a new loss term called the gaze reconstruction loss. How is this loss term formulated? What are the specific mathematical equations and components involved in computing this loss?

2. The gaze reconstruction loss leverages a pretrained gaze estimation network called L2CS-Net. What is the purpose of using this external network? How are the predicted gaze angles from L2CS-Net incorporated into the loss formulation? 

3. The proposed method aims to improve the accuracy of reconstructed gaze directions in face swaps. What quantitative results were obtained to demonstrate improved gaze accuracy over baseline methods? Were the improvements statistically significant?

4. The perceptual study evaluates deepfake detection, attribute importance, and uncanniness. For each of these three aspects, what were the specific hypotheses tested and what were the key results obtained? 

5. One of the goals was to make the eyes less prominent as a deciding factor in deepfake detection. Did the results provide evidence that this goal was achieved? What statistical tests were conducted to evaluate this?

6. The study found that face swaps elicit more uncanniness than real videos. What adjective pairs were used to measure uncanniness? Was there evidence that improved gaze accuracy reduced perceived uncanniness?

7. What are some limitations of using the same pretrained gaze estimation network (L2CS-Net) both during training and evaluation? Could this have biased any of the quantitative results?

8. The stimuli used in the perceptual study were controlled video clips from the FaceForensics++ dataset. How might the results change if more diverse or lower-quality video data was used instead?

9. The proposed gaze loss term is applied on top of the existing DeepFakeLab architecture. Could this approach be easily adapted to other face swapping methods? What modifications would need to be made?

10. The accuracy of gaze estimation networks is continuing to improve over time. How might future advancements in this area translate to improvements in the proposed gaze-centric training approach for face swaps?
