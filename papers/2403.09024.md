# [Semiparametric Token-Sequence Co-Supervision](https://arxiv.org/abs/2403.09024)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Language models are typically trained only on next token prediction (NTP), limiting expressivity and forcing models to predict only the next token rather than sequences.
- Humans can anticipate sequences of varying granularities, highlighting a gap between language models and human ability.

Proposed Solution: 
- Introduce semiparametric token-sequence co-supervision to train a language model (\gen) with supervision from both NTP over the parametric token embedding space and next sequence prediction (NSP) over the nonparametric sequence embedding space.
- NSP supervision comes from another language model (\ctx) that condenses input text into a representative embedding to construct the nonparametric sequence space.
- Co-supervision calculated via contrastive learning between \gen output distribution and \ctx embeddings.

Main Contributions:
- Demonstrate consistently better performance with co-supervision over NTP or NSP alone, enhancing generalization.
- Analysis suggests co-supervision encourages interaction between token and sequence spaces to share common space.
- Robustness of well-established parametric token space from pretraining enhances stability of new nonparametric sequence space.
- Models shift from reliance on memorization to active utilization of nonparametric knowledge.
- Particularly strong gains on out-of-domain datasets, highlighting broader generalization.
- Importance of compatibility between distributions of \gen and \ctx.

In summary, the paper introduces an effective method to incorporate nonparametric sequence supervision alongside standard token supervision which consistently improves language model capabilities. The analysis provides insights into the synergistic effects of aligning parametric and nonparametric spaces.
