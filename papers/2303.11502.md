# [Sketch2Saliency: Learning to Detect Salient Objects from Human Drawings](https://arxiv.org/abs/2303.11502)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be whether human sketches can be used as a weak label to detect salient objects in images. Specifically, the authors hypothesize that the attentive process of sketching inherently captures information about visual saliency, and thus sketches can be utilized to learn where the salient objects are in a corresponding photo. They propose that sketch can be an effective alternative weak label compared to other forms of supervision like class labels or image captions.To test this hypothesis, the authors develop a model that generates sequential sketches from photos using an attention mechanism. By accumulating the attention maps over time during sketch generation, they are able to produce saliency maps for the input images. They demonstrate quantitatively and qualitatively that their model can successfully learn saliency detection using only sketch supervision, outperforming other weakly supervised methods.In summary, the central hypothesis is that the inherent attentiveness of human sketching can be exploited to learn visual saliency from sketch labels alone, circumventing the need for more expensive pixel-level saliency annotations. The paper aims to validate "Sketch is Salient" through their proposed model.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel method to learn image saliency from human sketches as weak labels, without requiring pixel-level annotations. The key ideas are:1. They propose to use sketch as a weak label for learning saliency, based on the intuition that sketching is an attentive process that inherently encodes saliency information. This is the first work to show the viability of using sketch for saliency detection.2. They introduce a photo-to-sketch generation model with a 2D attention mechanism. The model generates sketch strokes sequentially while attending to salient regions of the photo via the attention maps. Accumulating the attention maps gives the saliency map.3. The model is trained end-to-end using sketch-photo pairs. An equivariance loss is added to make the predicted saliency maps robust to geometric transformations.4. Extensive experiments show their method outperforms other weakly supervised methods using class labels or text captions. It is also competitive with fully supervised methods that use pixel-level labels. 5. They further incorporate sketch in a multi-source weakly supervised framework, combining it with class labels, and show improved performance over state-of-the-art weakly supervised methods.In summary, the key novelty is using sketch as a new weak supervision signal for saliency detection, and showing its effectiveness both independently and when combined with other weak labels. The simple photo-to-sketch generation framework effectively connects the two modalities.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a method to learn to detect salient objects in images using human-drawn sketches as weak supervision, bypassing the need for pixel-level annotations.


## How does this paper compare to other research in the same field?

Here are a few key points in comparing this paper to other related research on sketch-based saliency detection:- This is the first work to propose using sketch as a weak form of supervision for training saliency detection models. Prior work has used other weak supervision signals like image captions, class labels, scribbles, etc. But leveraging the inherent attention in human sketches is a novel idea.- The proposed photo-to-sketch generation framework with 2D attention is also novel for this task. It provides an intuitive way to transform the sequential sketches into spatial attention maps that indicate salient image regions. Other methods typically use more complex multi-stage training frameworks.- The results demonstrate strong performance compared to other weakly supervised methods, despite using a simple and straightforward model architecture. The sketch-based model even outperforms some fully supervised techniques. This highlights the usefulness of sketch as a training signal.- Most prior weakly supervised methods rely on additional heuristics or post-processing like CRFs to refine the attention maps. But the maps from the sketch model are used directly without any such extra steps.- The idea of sketch saliency is intuitive, but this is the first work to thoroughly validate the concept through experiments. The effectiveness across multiple datasets empirically proves that sketch is an informative modality for saliency modeling.Overall, this paper introduces a novel angle to saliency detection by exploiting sketch as supervision. The simplicity of the proposed approach, yet strong results, highlight the power of human sketch for encoding salient regions. It opens up an interesting new direction for future work on sketch-based weak supervision in other vision tasks as well.
