# [Sketch2Saliency: Learning to Detect Salient Objects from Human Drawings](https://arxiv.org/abs/2303.11502)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be whether human sketches can be used as a weak label to detect salient objects in images. Specifically, the authors hypothesize that the attentive process of sketching inherently captures information about visual saliency, and thus sketches can be utilized to learn where the salient objects are in a corresponding photo. They propose that sketch can be an effective alternative weak label compared to other forms of supervision like class labels or image captions.To test this hypothesis, the authors develop a model that generates sequential sketches from photos using an attention mechanism. By accumulating the attention maps over time during sketch generation, they are able to produce saliency maps for the input images. They demonstrate quantitatively and qualitatively that their model can successfully learn saliency detection using only sketch supervision, outperforming other weakly supervised methods.In summary, the central hypothesis is that the inherent attentiveness of human sketching can be exploited to learn visual saliency from sketch labels alone, circumventing the need for more expensive pixel-level saliency annotations. The paper aims to validate "Sketch is Salient" through their proposed model.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a novel method to learn image saliency from human sketches as weak labels, without requiring pixel-level annotations. The key ideas are:1. They propose to use sketch as a weak label for learning saliency, based on the intuition that sketching is an attentive process that inherently encodes saliency information. This is the first work to show the viability of using sketch for saliency detection.2. They introduce a photo-to-sketch generation model with a 2D attention mechanism. The model generates sketch strokes sequentially while attending to salient regions of the photo via the attention maps. Accumulating the attention maps gives the saliency map.3. The model is trained end-to-end using sketch-photo pairs. An equivariance loss is added to make the predicted saliency maps robust to geometric transformations.4. Extensive experiments show their method outperforms other weakly supervised methods using class labels or text captions. It is also competitive with fully supervised methods that use pixel-level labels. 5. They further incorporate sketch in a multi-source weakly supervised framework, combining it with class labels, and show improved performance over state-of-the-art weakly supervised methods.In summary, the key novelty is using sketch as a new weak supervision signal for saliency detection, and showing its effectiveness both independently and when combined with other weak labels. The simple photo-to-sketch generation framework effectively connects the two modalities.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a method to learn to detect salient objects in images using human-drawn sketches as weak supervision, bypassing the need for pixel-level annotations.


## How does this paper compare to other research in the same field?

Here are a few key points in comparing this paper to other related research on sketch-based saliency detection:- This is the first work to propose using sketch as a weak form of supervision for training saliency detection models. Prior work has used other weak supervision signals like image captions, class labels, scribbles, etc. But leveraging the inherent attention in human sketches is a novel idea.- The proposed photo-to-sketch generation framework with 2D attention is also novel for this task. It provides an intuitive way to transform the sequential sketches into spatial attention maps that indicate salient image regions. Other methods typically use more complex multi-stage training frameworks.- The results demonstrate strong performance compared to other weakly supervised methods, despite using a simple and straightforward model architecture. The sketch-based model even outperforms some fully supervised techniques. This highlights the usefulness of sketch as a training signal.- Most prior weakly supervised methods rely on additional heuristics or post-processing like CRFs to refine the attention maps. But the maps from the sketch model are used directly without any such extra steps.- The idea of sketch saliency is intuitive, but this is the first work to thoroughly validate the concept through experiments. The effectiveness across multiple datasets empirically proves that sketch is an informative modality for saliency modeling.Overall, this paper introduces a novel angle to saliency detection by exploiting sketch as supervision. The simplicity of the proposed approach, yet strong results, highlight the power of human sketch for encoding salient regions. It opens up an interesting new direction for future work on sketch-based weak supervision in other vision tasks as well.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Removing the constraint of needing paired photo-sketch data. The current method relies on having corresponding photo and sketch pairs, which are laborious to collect. The authors suggest exploring ways to utilize sketch without needing a directly paired photo, such as using the duality of vector and raster sketch representations.- Extending to scene-level saliency. The current method focuses on part-level saliency for objects. The authors suggest expanding the study of sketch-induced saliency to full scenes, which could reveal insights about scene construction and object interactions.- Exploring relative saliency. The temporal sequence of sketch strokes may convey information about the relative saliency of objects in a scene. The authors suggest studying how stroke order correlates with relative importance of objects.- Improving performance on images with multiple salient objects. The training data contained mainly single objects, limiting performance when multiple salient objects are present. Using scene sketch data could help address this.- Removing reliance on sequential sketch decoding. The current method relies on sequential sketch generation, increasing computational cost. The authors suggest exploring ways to preserve the benefits while reducing the decoding time.In summary, the main future directions are: removing the need for paired data, extending to scenes, modeling relative saliency, handling multiple objects better, and improving efficiency. The core theme is building on the sketch-saliency connection to gain further insights into human visual perception and scene understanding.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper proposes a novel method to detect salient objects in images using human sketches as weak labels. The key idea is that sketching is an attentive process, so the attention information embedded in sketches can help identify salient regions in corresponding photos. The method involves training an image-to-sequence model that generates sketch strokes from an input photo through a 2D attention mechanism. At each step, the attention map focuses on salient regions needed to produce the next stroke. Accumulating attention maps over all sketch strokes highlights the salient objects. The photo-to-sketch model uses a convolutional encoder and sequential LSTM decoder with a multi-scale spatial attention module in between. An equivariance loss is also added to improve robustness. Experiments on multiple datasets demonstrate the model's ability to predict saliency maps directly from sketches, outperforming other weakly supervised approaches. The simplicity yet strong performance of using sketch as a weak label for saliency detection validates that sketches inherently capture visual saliency.
