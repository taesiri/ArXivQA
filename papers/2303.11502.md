# [Sketch2Saliency: Learning to Detect Salient Objects from Human Drawings](https://arxiv.org/abs/2303.11502)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be whether human sketches can be used as a weak label to detect salient objects in images. 

Specifically, the authors hypothesize that the attentive process of sketching inherently captures information about visual saliency, and thus sketches can be utilized to learn where the salient objects are in a corresponding photo. They propose that sketch can be an effective alternative weak label compared to other forms of supervision like class labels or image captions.

To test this hypothesis, the authors develop a model that generates sequential sketches from photos using an attention mechanism. By accumulating the attention maps over time during sketch generation, they are able to produce saliency maps for the input images. They demonstrate quantitatively and qualitatively that their model can successfully learn saliency detection using only sketch supervision, outperforming other weakly supervised methods.

In summary, the central hypothesis is that the inherent attentiveness of human sketching can be exploited to learn visual saliency from sketch labels alone, circumventing the need for more expensive pixel-level saliency annotations. The paper aims to validate "Sketch is Salient" through their proposed model.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a novel method to learn image saliency from human sketches as weak labels, without requiring pixel-level annotations. The key ideas are:

1. They propose to use sketch as a weak label for learning saliency, based on the intuition that sketching is an attentive process that inherently encodes saliency information. This is the first work to show the viability of using sketch for saliency detection.

2. They introduce a photo-to-sketch generation model with a 2D attention mechanism. The model generates sketch strokes sequentially while attending to salient regions of the photo via the attention maps. Accumulating the attention maps gives the saliency map.

3. The model is trained end-to-end using sketch-photo pairs. An equivariance loss is added to make the predicted saliency maps robust to geometric transformations.

4. Extensive experiments show their method outperforms other weakly supervised methods using class labels or text captions. It is also competitive with fully supervised methods that use pixel-level labels. 

5. They further incorporate sketch in a multi-source weakly supervised framework, combining it with class labels, and show improved performance over state-of-the-art weakly supervised methods.

In summary, the key novelty is using sketch as a new weak supervision signal for saliency detection, and showing its effectiveness both independently and when combined with other weak labels. The simple photo-to-sketch generation framework effectively connects the two modalities.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a method to learn to detect salient objects in images using human-drawn sketches as weak supervision, bypassing the need for pixel-level annotations.


## How does this paper compare to other research in the same field?

 Here are a few key points in comparing this paper to other related research on sketch-based saliency detection:

- This is the first work to propose using sketch as a weak form of supervision for training saliency detection models. Prior work has used other weak supervision signals like image captions, class labels, scribbles, etc. But leveraging the inherent attention in human sketches is a novel idea.

- The proposed photo-to-sketch generation framework with 2D attention is also novel for this task. It provides an intuitive way to transform the sequential sketches into spatial attention maps that indicate salient image regions. Other methods typically use more complex multi-stage training frameworks.

- The results demonstrate strong performance compared to other weakly supervised methods, despite using a simple and straightforward model architecture. The sketch-based model even outperforms some fully supervised techniques. This highlights the usefulness of sketch as a training signal.

- Most prior weakly supervised methods rely on additional heuristics or post-processing like CRFs to refine the attention maps. But the maps from the sketch model are used directly without any such extra steps.

- The idea of sketch saliency is intuitive, but this is the first work to thoroughly validate the concept through experiments. The effectiveness across multiple datasets empirically proves that sketch is an informative modality for saliency modeling.

Overall, this paper introduces a novel angle to saliency detection by exploiting sketch as supervision. The simplicity of the proposed approach, yet strong results, highlight the power of human sketch for encoding salient regions. It opens up an interesting new direction for future work on sketch-based weak supervision in other vision tasks as well.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Removing the constraint of needing paired photo-sketch data. The current method relies on having corresponding photo and sketch pairs, which are laborious to collect. The authors suggest exploring ways to utilize sketch without needing a directly paired photo, such as using the duality of vector and raster sketch representations.

- Extending to scene-level saliency. The current method focuses on part-level saliency for objects. The authors suggest expanding the study of sketch-induced saliency to full scenes, which could reveal insights about scene construction and object interactions.

- Exploring relative saliency. The temporal sequence of sketch strokes may convey information about the relative saliency of objects in a scene. The authors suggest studying how stroke order correlates with relative importance of objects.

- Improving performance on images with multiple salient objects. The training data contained mainly single objects, limiting performance when multiple salient objects are present. Using scene sketch data could help address this.

- Removing reliance on sequential sketch decoding. The current method relies on sequential sketch generation, increasing computational cost. The authors suggest exploring ways to preserve the benefits while reducing the decoding time.

In summary, the main future directions are: removing the need for paired data, extending to scenes, modeling relative saliency, handling multiple objects better, and improving efficiency. The core theme is building on the sketch-saliency connection to gain further insights into human visual perception and scene understanding.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper proposes a novel method to detect salient objects in images using human sketches as weak labels. The key idea is that sketching is an attentive process, so the attention information embedded in sketches can help identify salient regions in corresponding photos. The method involves training an image-to-sequence model that generates sketch strokes from an input photo through a 2D attention mechanism. At each step, the attention map focuses on salient regions needed to produce the next stroke. Accumulating attention maps over all sketch strokes highlights the salient objects. The photo-to-sketch model uses a convolutional encoder and sequential LSTM decoder with a multi-scale spatial attention module in between. An equivariance loss is also added to improve robustness. Experiments on multiple datasets demonstrate the model's ability to predict saliency maps directly from sketches, outperforming other weakly supervised approaches. The simplicity yet strong performance of using sketch as a weak label for saliency detection validates that sketches inherently capture visual saliency.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper proposes a novel method to detect salient objects in images using human sketches as weak labels. The key idea is that sketching is an attentive process that inherently focuses on the most salient aspects of a visual scene. To leverage this, the authors develop a photo-to-sketch generation model consisting of a convolutional encoder and an LSTM decoder with a 2D attention mechanism. As the model generates the sketch stroke-by-stroke, the attention module focuses on the salient regions of the photo at each step. Accumulating the attention maps over all sketch strokes results in a saliency map for the input image. 

The model is trained on photo-sketch pairs from the Sketchy dataset. Extensive experiments demonstrate that the proposed sketch-based saliency detection method outperforms state-of-the-art approaches relying on other weak labels like class labels or captions. The results support the claim that sketch is an effective label modality for learning saliency, owing to the attentive nature of the sketching process. The simple photo-to-sketch framework validates the hypothesis that "sketch is salient" and offers a novel perspective on utilizing sketch for visual understanding tasks.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes a method to learn to detect salient objects in images using human sketches as weak supervision. The key idea is to train a photo-to-sketch generation model that takes an image as input and generates a sketch stroke-by-stroke using a convolutional encoder-decoder architecture with an attention mechanism. 

Specifically, the model uses a VGG-16 backbone as the convolutional encoder to extract multi-scale feature maps from the input image. The decoder is a 1-layer LSTM that takes the encoder features as input and generates a sequence of sketch stroke coordinates and pen states. A 2D attention module is added between the encoder and decoder, which allows the model to focus on salient regions of the input image when generating each sketch stroke. 

The attention maps from all time steps of sketch decoding are accumulated to produce a saliency map for the input image. In addition, equivariance regularization is used to enforce spatial consistency between the input image and predicted saliency map under geometric transformations. The model is trained end-to-end using coordinate, stroke, and equivariance losses. Extensive experiments show the model can effectively learn to predict salient objects using only sketch supervision, outperforming state-of-the-art weakly supervised methods.


## What problem or question is the paper addressing?

 The main problem and question addressed in this paper is how to use human sketches to learn to detect salient objects in images, without requiring detailed pixel-level annotations for training. Specifically, the paper proposes a method to generate saliency maps that indicate salient objects in images, using only sketches as weak supervision, instead of more costly pixel-level ground truth labels.

The key questions explored are:

- Can sketches be used as a weak label to detect salient objects in images, given that sketches are abstract, sparse, and sequential compared to photos?

- How can a model learn to generate saliency maps that highlight salient regions in images using only sketch-photo pairs as training data?

To address these questions, the paper proposes a photo-to-sketch generation framework with a 2D attention mechanism. By generating sketches stroke-by-stroke and accumulating the attention maps, the model learns to focus on salient objects and output a saliency map for a given photo.

The main contribution is showing that sketches can indeed act as a weak label for saliency detection, despite being a very different modality than photos. Experiments demonstrate the model achieves competitive performance compared to state-of-the-art weakly supervised and even fully supervised methods.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords are:

- Salient object detection - The paper focuses on detecting salient objects in images using sketches as weak supervision. Salient object detection is the task of identifying the most visually prominent objects or regions in an image.

- Weakly supervised learning - The paper proposes using sketches, rather than detailed pixel-level annotations, as a weak form of supervision to train models for salient object detection. Weak supervision reduces annotation effort.

- Sketch - Sketches are simple hand-drawn representations of visual concepts. The paper hypothesizes that sketches inherently capture visual saliency and can be used as weak labels for salient object detection.

- Photo-sketch generation - A key component of the proposed method is a photo-to-sketch generation model that learns to produce sketch representations of input photos using an attention mechanism. This helps bridge the gap between the photo and sketch domains.

- Attention mechanism - A 2D attention mechanism is used in the sketch decoding process to focus on salient image regions and accumulate attention maps across sketch strokes to predict saliency.

- Equivariance regularization - An equivariance loss is introduced to make sure spatial transformations applied to input images are consistently reflected in the predicted saliency maps. This provides useful inductive bias.

- Multi-source weak supervision - The proposed sketch-based method is incorporated into a multi-source weakly supervised framework that also utilizes class labels and text captions. Combining sketch with other weak labels improves performance.
