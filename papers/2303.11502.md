# [Sketch2Saliency: Learning to Detect Salient Objects from Human Drawings](https://arxiv.org/abs/2303.11502)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be whether human sketches can be used as a weak label to detect salient objects in images. Specifically, the authors hypothesize that the attentive process of sketching inherently captures information about visual saliency, and thus sketches can be utilized to learn where the salient objects are in a corresponding photo. They propose that sketch can be an effective alternative weak label compared to other forms of supervision like class labels or image captions.To test this hypothesis, the authors develop a model that generates sequential sketches from photos using an attention mechanism. By accumulating the attention maps over time during sketch generation, they are able to produce saliency maps for the input images. They demonstrate quantitatively and qualitatively that their model can successfully learn saliency detection using only sketch supervision, outperforming other weakly supervised methods.In summary, the central hypothesis is that the inherent attentiveness of human sketching can be exploited to learn visual saliency from sketch labels alone, circumventing the need for more expensive pixel-level saliency annotations. The paper aims to validate "Sketch is Salient" through their proposed model.
