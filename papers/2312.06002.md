# [Large Language Models on Lexical Semantic Change Detection: An   Evaluation](https://arxiv.org/abs/2312.06002)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Lexical semantic change detection is an important task for understanding how word meanings evolve over time in languages. However, large language models (LLMs) have not been extensively explored for this task, with most prior work using traditional methods like PPMI, SGNS, and SVD instead.  

- Traditional methods have limitations in handling instance-level meaning changes, colexification, and low-resource datasets. More recent BERT-based methods address some of these issues but there is still limited work on applying the latest LLMs.

Methodology:
- The paper evaluates three types of methods on the TempoWiC dataset of annotated tweet pairs:
  - Traditional methods: PPMI, SGNS
  - BERT-based contextualized representations
  - Novel zero-shot prompting approach with GPT-4

- GPT-4 prompting crafts prompts that contain the tweets and ask whether the meaning of the target word has changed. This allows evaluation at both corpus-level and instance-level.

Key Results:
- GPT-4 prompting significantly outperforms other methods, achieving 0.66 pearson correlation for corpus-level detection and 0.65 F1 score for instance-level detection.  

- Traditional PPMI and SGNS methods perform very poorly on this dataset. The authors hypothesize this is due to the small size of the dataset.

- BERT-based method is competitive but still lower performance than GPT-4, showing the capabilities of latest LLMs.

Main Contributions:
- First comprehensive evaluation of latest LLMs on lexical semantic change detection
- Novel zero-shot prompting approach that achieves state-of-the-art without fine-tuning
- Analysis of traditional vs LLM methods on a low-resource dataset
- Benchmark for future work on applying large language models to semantic change tasks
