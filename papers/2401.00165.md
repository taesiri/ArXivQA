# [Mitigating the Impact of False Negatives in Dense Retrieval with   Contrastive Confidence Regularization](https://arxiv.org/abs/2401.00165)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
In open-domain question answering, dense passage retrieval is crucial for finding relevant passages to generate answers. Contrastive learning is typically used to train retrieval models by bringing similar passages/queries closer and dissimilar ones farther apart in a semantic space. However, training such models is challenging due to the issue of false negatives - relevant passages that are missed during data annotation. Hard negative sampling, commonly used to improve contrastive learning, can introduce more noise since hard negatives are top-ranked by another retrieval model and likely contain false negatives. Therefore, mitigating the impact of false negatives can improve dense retrieval performance.

Proposed Solution:
This paper proposes two main contributions to address the false negative problem:

1. A novel contrastive confidence regularizer for the commonly used Noise Contrastive Estimation (NCE) loss. Theoretical analysis shows the regularizer makes retrieval models more confident and robust to false negatives. Experiments on simulated data demonstrate the regularizer helps separate false negatives from true negatives.  

2. A Passage Sieve algorithm that leverages a retrieval model trained with the confidence regularizer to filter out likely false negatives from the dataset. This results in a cleaner dataset to train improved downstream retrieval models. Under mild assumptions, analysis shows the algorithm can successfully exclude false negatives from hard negatives.

Main Results:
The paper demonstrates state-of-the-art passage retrieval performance by applying the above two methods on top of existing models on three QA datasets. For example, combining the passage sieve algorithm with AR2 model achieves the best published results on Natural Questions and TriviaQA datasets. Additional experiments analyze the effects of key hyperparameters and demonstrate the advantage of the proposals over recent false negative reduction techniques.

In summary, the paper provides a theoretically sound approach to mitigate false negatives for training dense passage retrieval models, with empirical verification of effectiveness. The confidence regularizer and passage sieve algorithm offer practical solutions to improve real-world QA systems relying on dense retrieval.
