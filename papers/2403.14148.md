# [Efficient Video Diffusion Models via Content-Frame Motion-Latent   Decomposition](https://arxiv.org/abs/2403.14148)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Existing video diffusion models suffer from high memory usage and computational costs when generating videos. This is because they operate directly on the raw high-dimensional video data as cubic arrays. Recent latent video diffusion models help alleviate this issue by encoding videos into a low-dimensional latent space before modeling. However, they do not leverage knowledge from pretrained image diffusion models.

Proposed Solution:
The paper proposes a Content-Motion Latent Diffusion Model (CMD) that enjoys the benefits of both worlds. It decomposes each video into an "image-like" content frame and a compact motion latent representation. The key ideas are:

1) The content frame is computed as a weighted average of the input video frames to capture the common content. A pretrained image diffusion model is fine-tuned to generate content frames.

2) The motion latent compactly captures dynamic motions. A lightweight diffusion model is trained from scratch to generate the motion latent conditioned on the content frame.

Main Contributions:

- Novel video encoding scheme into content and motion for efficient video generation
- Generating content frames by fine-tuning pretrained image diffusion models 
- Lightweight motion diffusion model conditioned on content frame

The proposed CMD achieves significantly better efficiency than prior arts in both training and sampling, while generating videos of better quality. For example, to generate a 16-frame 512x1024 video, CMD uses 16.7x less computation and consumes 66% less GPU memory than a state-of-the-art model. It also achieves 18.5% lower FVD score on the WebVid-10M benchmark compared to the best baseline.
