# [Deep Incremental Model Based Reinforcement Learning: A One-Step Lookback   Approach for Continuous Robotics Control](https://arxiv.org/abs/2403.01529)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Reinforcement learning (RL) suffers from sample inefficiency in continuous control tasks like robotics. Model-free RL requires large amounts of real-world interaction before learning a good policy. Model-based RL (MBRL) attempts to address this by learning a model of the environment and using it to improve data efficiency. However, model learning can be difficult, especially for high-dimensional systems like robots. 

Proposed Solution:
This paper proposes a "deep incremental model" for MBRL that is tailored to robotics control. It represents the robot dynamics as an "incremental evolution model" which predicts state transitions based on the change in actions between timesteps. This simplifies model learning into a matrix estimation problem and is favorable for high-dimensional systems. The model is learned incrementally on real experience data. Imagined transitions from the learned model are then used to supplement the real data for policy optimization via soft actor-critic.

Key Contributions:
- Formulates an incremental evolution model for robot dynamics that only requires learning a parameter matrix, reducing complexity for high-dimensional robots
- Learns the model incrementally on real experience data  
- Generates imagined transitions from learned model to augment real data
- Validates approach on MuJoCo continuous control tasks, demonstrating improved sample efficiency over model-free methods
- Provides an alternative and control-oriented modeling approach for MBRL that is simple yet effective compared to other techniques

The incremental modeling approach aims to strike a balance between model accuracy and complexity. Results show it can efficiently learn a useful robot dynamics model to significantly boost sample efficiency of a model-free RL algorithm. The intuitive model structure has the potential to extend to complex, high-dimensional robotic systems.
