# [Improving Activation Steering in Language Models with Mean-Centring](https://arxiv.org/abs/2312.03813)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Activation steering aims to control language model outputs, but current methods either require identifying precise counterbalancing behaviors or are computationally expensive. 
- Engineers typically don't know how concepts are represented within language models, making it difficult to construct good steering vectors.

Proposed Solution:  
- The authors propose a simple technique called "mean-centring" to create steering vectors using only a dataset exhibiting the target behavior.  
- They compute the average activation vector from running the target dataset through the model. They then subtract the average activation vector computed on the training set to remove the inherent bias.
- This residual vector captures directions related to the desired behavior and can be used to steer the model.

Main Contributions:
- The authors show mean-centring performs comparably to existing methods for making language model continuations of toxic prompts non-toxic.
- They demonstrate the versatility of mean-centring by steering story genres, a task not easily achieved with counterbalancing behaviors. Genre-specific words increase under steering.
- Applying mean-centring to extract "function vectors" that trigger capabilities significantly improves accuracy over previous baselines across various natural language tasks.

In summary, mean-centring provides an effective and simple way to leverage only a target dataset to extract steering vectors. It expands the applicability of activation steering methods to more contexts. The strong performance suggests it is a promising technique for controlling language model outputs.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper proposes a simple method called mean-centring to improve the effectiveness of activation steering in language models by subtracting the mean activation across the training set from the mean activation on a target behavior dataset to get a steering vector that changes model outputs to better match the target behavior.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is introducing the idea of "mean-centring" for improving activation steering in language models. Specifically:

- The paper proposes a new method called "mean-centring" to create better steering vectors for controlling language model outputs via activation steering. The key idea is to subtract the mean activation vector on the training set from the average activation vector on a target dataset to get a steering vector that captures information specific to the target dataset.

- Through experiments on removing toxicity, steering story genres, and extracting better function vectors, the paper shows that mean-centring steering vectors leads to improved performance compared to not using mean-centring. 

- The paper also argues that mean-centring makes activation steering more versatile and easier to apply compared to methods requiring a counterbalancing concept. By using only a target dataset, mean-centring can be used to change language model behavior in a wider range of contexts.

So in summary, the main contribution is introducing mean-centring as a simple but effective processing technique for improving activation steering vectors across a variety of language model control tasks.


## What are the keywords or key terms associated with this paper?

 Based on scanning the content of the paper, some of the key terms and keywords that appear related to the focus of this work include:

- Activation steering
- Large language models (LLMs)
- Mean-centring 
- Distillation vectors
- Anisotropy
- Linear representation hypothesis
- Residual stream
- Function vectors
- Toxicity removal
- Story genre steering

The paper introduces the idea of "mean-centring" for creating better distillation vectors to use in activation steering of large language models. It tests this technique in applications like reducing generated toxicity, influencing story genres, and extracting more effective function vectors. The method accounts for anisotropy (non-uniform directional distribution) of activations in language models. It relates to the linear representation hypothesis - that concepts can be captured linearly in model activations. Overall, the key terms revolve around techniques for better controlling language model outputs.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the mean-centred activation steering method proposed in the paper:

1. The paper hypothesizes that other methods like LAT scans and counterbalanced subtractions may implicitly perform mean-centring. What evidence is provided to support this hypothesis? How could this be tested empirically?

2. Mean-centring improved performance for extracting function vectors in GPT-J, but not at all layers. What factors could explain why mean-centring is more effective at some layers over others? How could this be investigated further? 

3. The paper demonstrates anisotropy in the activations of several language models. Does the degree of anisotropy correlate with potential improvements from mean-centring? How could you test if anisotropy predicts the benefits of mean-centring?

4. How exactly does mean-centring relate to and draw inspiration from similar techniques used for improving classical word embeddings? What are the key similarities and differences to methods like those introduced in Mu et al. 2018?

5. Could mean-centring be integrated with other techniques for creating steerable vectors, like sparse autoencoders? Would it provide further improvements and how could this be tested?

6. The efficacy of mean-centring depends on the choice of target and training datasets used. What properties of these datasets determine how well mean-centring will work? How could you systematically evaluate this?  

7. Could the mean-centring concept be applied at multiple layers simultaneously? Would this improve steering further and why/why not? How could multi-layer mean-centring be implemented?

8. How does the performance of mean-centring compare to more complex methods proposed like LAT scans across various models and tasks? When is mean-centring preferred over more complex approaches?  

9. For toxicity removal, mean-centring with the non-toxic dataset performs differently than with the loving dataset. What explains this difference in behaviour? How does dataset choice interact with layer choice here?

10. The paper hypothesizes other model properties like clustering could be relevant for improving steering. What evidence is there for clustering and other properties? How could these properties be leveraged to further advance activation steering?
