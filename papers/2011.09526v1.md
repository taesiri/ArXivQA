# [Contextual Fusion For Adversarial Robustness](https://arxiv.org/abs/2011.09526v1)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is whether fusing information from multiple modalities, specifically foreground (object) and background (contextual) features, can improve the robustness of image classifiers against adversarial attacks. 

The key hypotheses are:

1. Adversarial attacks may have divergent effects on context feature space vs object feature space.

2. Utilizing a combination of multiple modalities for information processing can be an effective method for combating adversarial attacks. 

3. Context features can provide additional information beyond just object-oriented data, and this can help improve classification, especially during adversarial attacks.

The authors test these hypotheses by developing foreground, background, and joint classifiers using CNNs trained on different datasets. They evaluate the benefits of fusion on preserving robustness against both human-perceivable (Gaussian blur) and network-perceivable (FGSM) adversarial attacks.

So in summary, the central research question is whether fusing foreground and background features can improve adversarial robustness, and the key hypotheses relate to how attacks may differently affect each feature space and how fusion can help compensate.
