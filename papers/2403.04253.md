# [Mastering Memory Tasks with World Models](https://arxiv.org/abs/2403.04253)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Current model-based reinforcement learning (MBRL) agents struggle to solve tasks that require long-term memory and credit assignment. This is because their world models, which learn to simulate the environment's dynamics, have limitations in capturing long-range dependencies. Specifically, recurrent neural networks (RNNs) used in world models suffer from vanishing gradients, while Transformers have quadratic complexity. This hinders performance in tasks with long time delays between actions and rewards or tasks that need recalling of distant past observations.

Proposed Solution:
The paper proposes a new MBRL method called "Recall to Imagine" (R2I) that integrates a modified version of Structured State Space (S4) models into the world model to enhance long-term memory and credit assignment. S4 models have shown superior ability to capture dependencies in very long sequences compared to RNNs and Transformers. 

Key Details:
- R2I is built upon the state-of-the-art DreamerV3 MBRL agent. It replaces DreamerV3's RNN-based world model with a Structured State Space Model (S3M).
- S3M uses parallel scan based computation to enable scaling to long sequences and fast trajectory imagination.
- The method handles episode boundaries to allow resetting of hidden states, further aiding credit assignment. 
- Ablation studies show the impact of various design choices like using full episodes in batches, exposing S3M hidden states to the policy etc.

Main Contributions:
- Introduces the first S4-based world model for MBRL showing strong performance in memory-intensive domains.
- Sets new state-of-the-art in challenging memory domains like BSuite, POPGym and Memory Maze, even exceeding human performance in Memory Maze.
- Maintains performance in standard RL benchmarks like Atari and DMC, demonstrating generality.
- Achieves up to 9x speedup compared to prior state-of-the-art DreamerV3, enabling faster wall-time convergence.

In summary, R2I establishes a new fast and general MBRL approach with superior memory capabilities, advancing the state-of-the-art in memory-intensive reinforcement learning.
