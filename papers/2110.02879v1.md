# [Nested Policy Reinforcement Learning](https://arxiv.org/abs/2110.02879v1)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the main research questions/hypotheses appear to be:

1) Can a nested reinforcement learning approach called nested policy fitted Q-iteration (NFQI) learn good policies for environments with a predefined nested structure consisting of two groups (background and foreground)?

2) Will the policies learned by NFQI perform better compared to policies learned by standard fitted Q-iteration (FQI) applied independently to each group or jointly to the combined data? 

3) Will the NFQI policies rely on relevant state features that reflect the differences in dynamics between the background and foreground environments?

4) Can NFQI handle sample size imbalance between the background and foreground groups and still learn good policies? 

5) If there is no real group structure in the data, will NFQI gracefully revert back to standard FQI performance?

The key ideas seem to be extending fitted Q-iteration to handle nested environments with predefined background/foreground groups, learning separate policies for each group while sharing strength between them, and evaluating whether this approach leads to better performance and more interpretable policies compared to baseline approaches. The main hypothesis appears to be that explicitly accounting for the nested group structure will enable better policies to be learned compared to ignoring this structure.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

1. The introduction of a new reinforcement learning algorithm called Nested Policy Fitted Q-Iteration (NFQI) that is designed for environments with a nested group structure. Specifically, it can learn optimal policies for two groups that share rewards and state space but have different transition dynamics. 

2. A training procedure for NFQI inspired by transfer learning that allows it to handle imbalance between the sizes of the two groups. The shared structure is learned first using both groups, then the foreground-specific structure is fine-tuned using just the foreground data.

3. Demonstrating that NFQI can learn policies that:

- Perform at least as well as policies learned without considering group structure

- Rely on relevant state features, as shown through SHAP analysis

- Are robust to imbalance between group sizes

- Gracefully revert to regular FQI when there is no real group structure

4. Showing that NFQI can successfully learn clinically-useful policies on a medical task using real electronic health records, outperforming regular FQI.

In summary, the main contribution seems to be the introduction and empirical validation of the NFQI algorithm for learning optimal policies tailored to nested environments with separate but related groups. The paper shows it can exploit shared structure while accommodating key differences between groups.
