# [Cross-Domain Image Captioning with Discriminative Finetuning](https://arxiv.org/abs/2304.01662)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research questions and hypotheses addressed in this paper are:- Can finetuning an image captioning model with a self-supervised discriminative objective help it generate more informative and useful captions compared to just training on human reference captions? - The authors hypothesize that finetuning a pretrained captioner to play a discrimination game with an image retriever will help it move away from mimicking potentially uninformative or idiosyncratic human captions. This will allow it to produce plainer, more descriptive captions that are better for practical applications like cross-domain image retrieval.- They also hypothesize that the discriminatively finetuned captions will not only be good for retrieval by neural systems, but could also be more useful for human image discrimination compared to human-written or non-finetuned captions.So in summary, the main goals are to explore whether discriminative finetuning can improve caption informativeness and usefulness compared to just training on human references, and testing this both via neural retrieval and human evaluation. The key hypothesis is that the discriminative objective will undo abstraction learned from human captions and recover more plainly descriptive language.
