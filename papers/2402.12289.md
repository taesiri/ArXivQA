# [DriveVLM: The Convergence of Autonomous Driving and Large   Vision-Language Models](https://arxiv.org/abs/2402.12289)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Autonomous driving systems struggle with scene understanding and planning in complex, unpredictable urban environments. Key challenges include navigating adverse conditions, intricate road layouts, and unusual human behaviors. Existing systems are limited in object detection, motion prediction focuses on trajectories rather than decisions, and planning operates on lower levels rather than high-level tasks. There is a need for advanced scene understanding and adaptable decision-making abilities.

Proposed Solution: 
The paper proposes DriveVLM, a novel system leveraging Vision-Language Models (VLMs) for enhanced scene understanding and planning. It introduces a Chain-of-Thought (CoT) mechanism with three modules:

1) Scene Description: Linguistically depicts the environment and identifies critical objects.  
2) Scene Analysis: Analyzes characteristics and potential influence of critical objects on the ego vehicle.
3) Hierarchical Planning: Formulates plans from meta-actions to decision descriptions to trajectory waypoints.

To address VLM limitations in spatial reasoning and computational speed, DriveVLM-Dual combines DriveVLM with traditional perception and planning modules in a "slow-fast" system, achieving robust spatial grounding and real-time speeds.

Main Contributions:

1) Proposing DriveVLM and DriveVLM-Dual systems for leveraging VLMs in autonomous driving scene understanding and planning.

2) Enhancing VLMs with traditional modules in DriveVLM-Dual to compensate limitations and enable deployment. 

3) Defining the Scene Understanding for Planning (SUP) task with metrics and dataset construction protocol.

4) Demonstrating superior performance of DriveVLM and DriveVLM-Dual over state-of-the-art methods on nuScenes and a new SUP-AD dataset, especially in complex, unpredictable driving scenarios.

In summary, the paper pioneers VLM integration to progress scene understanding and decision-making for autonomous driving, with the proposed systems showing significant improvements in handling long-tail, challenging urban environments.
