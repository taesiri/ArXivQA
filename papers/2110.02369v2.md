# [EntQA: Entity Linking as Question Answering](https://arxiv.org/abs/2110.02369v2)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research question this paper addresses is: 

Can entity linking be formulated as a question answering task, where candidate entities are retrieved first as "questions" and then corresponding mentions are extracted as "answers", rather than the conventional pipeline of detecting mentions first and then linking them to entities?

The central hypothesis is that retrieving candidate entities first without knowing their mentions is easier than finding mentions first without knowing the target entities. Flipping the traditional order of mention detection followed by entity disambiguation could help address a fundamental limitation in existing entity linking approaches.

To summarize, the paper proposes and evaluates a new model called EntQA that approaches entity linking through a question answering formulation, retrieving candidate entities as questions and then using a reader module to extract mention spans for each entity. The key hypothesis is that this inverted order of entity before mention can overcome limitations faced by prior entity linking methods.


## What is the main contribution of this paper?

 Based on the provided LaTeX code, this does not appear to be a full paper text, but rather just LaTeX document setup and macro definitions. Some key things I noticed from skimming the code:

- It sets up a LaTeX document in the article class with common math and formatting packages like amsmath, amssymb, geometry, etc. 

- It defines many LaTeX macros for formatting, like \prob for probabilities, \E for expectation, \newterm to highlight new terminology, etc.

- It defines macros for representing random variables, vectors, matrices, etc.

- It imports some machine learning-related packages like mathtools.

- It defines theorem, lemma, etc. environments and math operators like argmax, argmin. 

- It sets up an environment for homework assignments.

- It customizes hyperref link formatting.

So in summary, this LaTeX code sets up the document and defines macros, operators, and environments to typeset a math/ML/NLP paper nicely. But on its own, it does not contain the actual content or contributions of a paper. The main contribution would be contained in the sections and text that the author writes using these definitions and packages. From just the preamble code provided, I cannot determine the main contribution of the full paper. The LaTeX code prepares the structure and formatting, but the content itself is missing.
