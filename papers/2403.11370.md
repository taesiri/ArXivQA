# [DynamicGlue: Epipolar and Time-Informed Data Association in Dynamic   Environments using Graph Neural Networks](https://arxiv.org/abs/2403.11370)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Most computer vision tasks like SLAM rely on establishing correspondences between images under the assumption of a static environment. However, this assumption limits their applicability in dynamic real-world environments with moving objects. The key challenge is to robustly match features between images while excluding features on moving objects.

Proposed Solution: 
The authors propose a graph neural network-based sparse feature matching framework called DynamicGlue that incorporates epipolar and temporal information to distinguish static and dynamic parts of the scene. 

Specifically, they build a graph between the keypoints of two images with two types of edges - self edges between keypoints in the same image and cross edges between keypoints across images. The cross edges store epipolar and temporal difference features. This graph is processed using attentional message passing to get an enhanced keypoint representation aware of scene dynamics.

The network is trained in a self-supervised manner using only raw stereo images and IMU data. They use a SLAM system to get pseudo ground truth matches. Moving object masks from an MOT system explicitly prevent matching keypoints on moving objects.

Main Contributions:

1) A graph neural network architecture for sparse feature matching that incorporates epipolar and temporal information as edge features to distinguish static vs dynamic parts of the scene.

2) A self-supervised training pipeline requiring only raw visual-inertial data to generate supervision.

3) Experiments showing state-of-the-art matching performance while reducing matches on moving objects by 65% compared to other learned approaches. 

4) Integration with SLAM system OKVIS2 leads to 29% lower trajectory error demonstrating the benefits for dynamic SLAM/VIO systems.

In summary, the paper presents a novel context-aware feature matching framework using graph neural networks that shows significantly improved handling of dynamic scenes for applications like SLAM.
