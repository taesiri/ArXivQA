# [Multimodal Gen-AI for Fundamental Investment Research](https://arxiv.org/abs/2401.06164)

## Summarize the paper in one sentence.

 This paper outlines experiments applying unsupervised and supervised fine-tuning methods as well as instruction fine-tuning on language models to automate information summarization and investment idea generation in the financial domain, with the goal of developing an AI prototype to assist human investors.


## What is the main contribution of this paper?

 The main contribution of this paper is presenting experiments aimed at automating information summarization and investment idea generation in the financial industry using language models. Specifically, the authors:

1) Evaluate the effectiveness of different fine-tuning methods like unsupervised LoRA fine-tuning, supervised fine-tuning, and instruction fine-tuning on base models like Llama2 and GPT-3.5 to achieve application-level goals relevant for investment research. 

2) Show that fine-tuned models perform better on text modeling, summarization, reasoning, and answering finance domain questions compared to baseline models.

3) Demonstrate the potential of using state-of-the-art generative modeling techniques to develop an AI agent prototype to assist human investors by liberating them from repetitive analytical tasks and enabling them to focus more on high-level strategic thinking.

4) Use a diverse corpus dataset including research reports, investment memos, market news, and extensive time-series data to train and evaluate the models.

In summary, the main contribution is presenting experiments that apply innovative fine-tuning techniques on advanced language models using proprietary and diverse data to demonstrate their capability in automating and enhancing decision-making processes in the financial investment domain.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, here are some of the key terms and keywords that seem most relevant:

- Language models 
- Fine-tuning
- Llama2 
- LoRA
- Unsupervised learning
- Supervised learning  
- Instruction fine-tuning
- GPT-3.5
- Financial domain
- Investment research  
- Information summarization
- Idea generation
- Text modeling
- Reasoning
- Time series forecasting
- Model evaluation
- Perplexity
- Human evaluation

These terms reflect the main topics and techniques discussed in the paper, including the models used (Llama2, GPT-3.5), the fine-tuning approaches taken (LoRA, supervised, unsupervised, instruction-based), the application area (finance, investment), and the evaluations conducted (perplexity, human ratings). The goal of automating summarization and idea generation in the investment domain is central. Overall the key focus is on applying large language model fine-tuning to enhance reasoning and decision-making for the financial industry.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper mentions using both unsupervised and supervised fine-tuning methods. Can you elaborate on the key differences in the approaches and objectives of unsupervised vs supervised fine-tuning for this application? What are the tradeoffs?

2. When using the LoRA method for efficient fine-tuning, how did you determine the appropriate hyperparameter values such as the rank and number of matrices to modify? What impact would modifying these values have? 

3. For the supervised fine-tuning experiment, what considerations went into formulating the stock price change prediction into a 12-class text classification task? Would treating this as a regression problem have advantages or disadvantages?

4. The human evaluation results indicate the fine-tuned GPT-3.5 model provided more direct, relevant, and insightful responses. Can you discuss the changes made to the instruction fine-tuning process to achieve this? 

5. The paper mentions aiming to develop a system capable of "investment idea generation." What specific mechanisms or architecture choices allow the fine-tuned models to achieve this high-level goal?

6. How was the corpus of text data for unsupervised pre-training curated and filtered to be most useful? What cautions need to be kept in mind when assembling a domain-specific dataset?

7. What safeguards were implemented in the model training process to prevent amplifying or generating biased, unethical, or false information?

8. The high-level goal is to develop an AI assistant to liberate humans from repetitive analytical tasks. Can you describe how the trained models approach replicating true human-level analysis as opposed to just pattern recognition?

9. What additional real-world feedback, evaluation, and analysis would be required before considering deployment of such AI models in live financial decision-support systems? 

10. Can you foresee this approach expanding beyond investments to other domains and applications that rely on analyzing large text corpora to drive decision making? What other areas may benefit?


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem and Objective
The paper outlines a project aimed at revolutionizing the laborious and resource-intensive process of investment analysis and decision-making. The goal is to develop an AI prototype that automates tasks like information summarization and investment idea generation. Specifically, the authors want to evaluate if fine-tuning methods on large language models can help achieve application-level targets including:
1) Identify company/sector impacts and generate investment ideas based on an event like an oil price increase 
2) Reason about relationships between market conditions like valuation, emotions, liquidity etc. and equity price changes
3) Generate investment ideas aligned with investor preferences and theses  
4) Format output with stock recommendations, top reasons, and detailed explanations
The motivation is to liberate human investors from repetitive analytical tasks to focus more on strategic thinking.

Proposed Solution and Technical Approach
The solution leverages recent advancements in large language models (LLMs). The authors conduct 3 experiments applying unsupervised learning, supervised learning, and instruction tuning on Llama2 and GPT3.5 models. Specifically:
1) Unsupervised next-token prediction fine-tuning of Llama2 on financial domain corpus 
2) Supervised fine-tuning of Llama2 to predict stock price changes using news headlines
3) Instruction fine-tuning GPT3.5 with Q&As conveying investment principles 

Key Results
Both statistical and human evaluations indicate the fine-tuned models outperform baseline in solving text modeling, summarization, reasoning, and finance domain problems. This demonstrates enhanced decision-making capability in the financial domain. Instruction tuning transforms GPT3.5 into an investment analyst-like model with logical reasoning.

Overall, the project shows promise in developing AI to take over repetitive analytical tasks from human experts to improve efficiency. The fine-tuning strategies are effective in achieving the stated application-level objectives.
