# [VideoSwap: Customized Video Subject Swapping with Interactive Semantic   Point Correspondence](https://arxiv.org/abs/2312.02087)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper introduces VideoSwap, a framework for customized video subject swapping that enables shape changes in the swapped subject while preserving the motion trajectory of the source video. The key insight is that only a small number of semantic points, rather than dense correspondence, are necessary to depict the motion trajectory of a subject. VideoSwap allows users to define semantic points on the source video, extracts their trajectories and embeddings, and registers them on the source video to provide motion guidance. To address various semantic correspondences, VideoSwap supports user interactions like removing inaccurate points or dragging points to modify shapes. Built on image and motion diffusion models, VideoSwap blends the swapped subject with the original background using latent blending to focus editing on the foreground. Experiments demonstrate VideoSwapâ€™s state-of-the-art performance in video subject swapping, facilitating shape changes like swapping a dog with a cat or an airplane with a helicopter, while maintaining temporal consistency. The limitations stem from imperfect point tracking and canonical space representation. Future works may explore real-time interactivity, more flexible shape changes, and movie/story generation based on customized video editing.
