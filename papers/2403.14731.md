# [Reversible Jump Attack to Textual Classifiers with Modification   Reduction](https://arxiv.org/abs/2403.14731)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Natural language processing (NLP) models are vulnerable to adversarial attacks where small perturbations to input text can cause misclassifications. Crafting optimal adversarial examples is challenging as it requires balancing successful attacks and imperceptibility. Existing methods are either limited by deterministic hierarchical rules that miss better combinations of perturbations, or inefficient optimization methods.  

Proposed Solution:
The paper proposes two novel algorithms - Reversible Jump Attack (RJA) and Metropolis-Hasting Modification Reduction (MMR).

RJA uses the Reversible Jump sampler, a Markov chain Monte Carlo method, to efficiently search for adversarial examples. It treats the number of perturbed words, victim words, and substitutions as variables sampled from a target distribution regularized for attack success and semantic similarity. This allows adaptive and cross-dimensional search for threats.  

MMR leverages the Metropolis-Hastings algorithm to reduce modifications while preserving attack performance. Given an adversarial example from RJA, MMR stochastically restores some perturbations back to original words, and updates substitutions for other attacked words to maintain successful attacks with fewer changes.

By combining RJA's enlarged search space and MMR's refinement, the integrated RJA-MMR achieves optimal balance of attack success and modifications.

Main Contributions:
- RJA enables adaptive and efficient search for threats by treating number of perturbations as a variable, overcoming limitations of hierarchical rules or optimization methods.

- MMR reliably reduces modifications using a stochastic acceptance mechanism, enhancing imperceptibility over current state-of-the-art.  

- Extensive experiments show RJA-MMR has superior attack performance, imperceptibility and fluency over strong baselines across multiple datasets and model architectures.

- Analysis also demonstrates RJA-MMR generated examples can improve model accuracy and robustness when used for adversarial training.

In summary, the proposed RJA-MMR advances the state-of-the-art for crafting optimal and imperceptible adversarial text examples. The techniques have broad applicability across NLP models and tasks.
