# [Emergent Correspondence from Image Diffusion](https://arxiv.org/abs/2306.03881)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main research question this paper aims to address is whether image diffusion models can learn correspondences between images without any explicit supervision. Specifically, the paper investigates whether the features learned by diffusion models during the image generation process contain implicit knowledge about correspondence that can be extracted and applied to matching real images. The key hypothesis is that the denoising process of diffusion models requires implicitly modeling correspondences between noisy and clean images in order to generate high-quality results. To test this hypothesis, the authors propose a simple strategy called DIFT (Diffusion Features) to extract features from pre-trained diffusion models and use them for correspondence tasks on real images, without any fine-tuning or task-specific training. Through experiments on semantic, geometric, and temporal correspondence benchmarks, they demonstrate that the proposed DIFT features establish accurate correspondences, outperforming prior self-supervised and weakly supervised methods.In summary, the central question is whether correspondence emerges in diffusion models without explicit supervision, and the key hypothesis is that the denoising process requires modeling correspondences, allowing extraction of DIFT features that enable correspondence on real images despite no correspondence-based training. The experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. It shows that image diffusion models like Stable Diffusion and ADM learn correspondence between images implicitly, without any explicit supervision. 2. It proposes a simple yet effective method called DIFFusion FeaTures (DIFT) to extract these implicit correspondence features from pre-trained diffusion models. 3. It demonstrates that the proposed DIFT features can be directly applied to establish semantic, geometric, and temporal correspondences between real images, outperforming other self-supervised methods like DINO and OpenCLIP.4. In particular, DIFT achieves state-of-the-art performance on semantic correspondence on SPair-71K, even surpassing some supervised methods, without any fine-tuning or task-specific training.5. The results suggest that correspondence emerges in diffusion models and can be extracted effectively using DIFT. The simplicity and strong performance of DIFT on correspondence tasks highlights the representational power of diffusion models.In summary, the key contribution is proposing DIFT to extract implicit correspondence features from pre-trained diffusion models, and showing these features achieve excellent performance on semantic, geometric and temporal correspondence tasks, without any fine-tuning. The results demonstrate correspondence is learned inside diffusion models like Stable Diffusion without being explicitly supervised on it.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key point from the paper: The paper proposes extracting diffusion features (DIFT) from pre-trained image diffusion models, without any task-specific fine-tuning or supervision, and demonstrates their effectiveness for establishing correspondences across images for semantic, geometric, and temporal matching.
