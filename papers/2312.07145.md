# [Contextual Bandits with Online Neural Regression](https://arxiv.org/abs/2312.07145)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper develops novel regret bounds for online regression with neural networks and uses these results to provide regret guarantees for neural contextual bandits (NeuCBs). The authors first show an O(log T) regret for online regression when the loss function satisfies almost convexity, a quadratic growth condition, and has a unique minimum. They then propose adding a small random perturbation to the neural network predictions, which surprisingly makes the loss functions satisfy these conditions. Leveraging this perturbed prediction, they attain O(log T) regret for online regression with both squared and KL losses. The authors then use existing reductions from contextual bandits to online regression to convert these regret bounds to Õ(sqrt(KT)) regret for NeuSquareCB with squared loss and Õ(sqrt(L*K)+K) regret for NeuFastCB with KL loss, where L* is the loss of the best policy. These are the first results showing logarithmic regret for neural online learning and subsequent sublinear regret guarantees for NeuCBs. The algorithms also avoid dependencies on the effective dimension in prior neural bandit works. Finally, experiments on real datasets demonstrate the strong practical performance of the proposed methods compared to neural baselines, especially for NeuFastCB with KL loss.
