# [NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning   Disentangled Reasoning](https://arxiv.org/abs/2403.07376)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Recent works have shown promising results by introducing large language models (LLMs) into vision-and-language navigation (VLN). However, directly using LLMs for VLN suffers from substantial domain gap and dependency on expensive models like GPT-4, harming scalability. 

Method: 
This paper proposes NavCoT, where LLMs are repurposed to generate self-guided navigational reasoning called "navigational chain-of-thought" to simplify and improve action decisions. Specifically, at each timestep, the LLM is prompted to 1) imagine the next observation (future imagination), 2) select the candidate observation that aligns best with the imagination (visual information filter), and 3) predict action based on above reasoning. Through customized chain-of-thought reasoning generation, smaller LLMs can be efficiently adapted to VLN via in-domain training like pretraining and imitation learning based finetuning. 

Contributions:
1) Introduce world model theory into chain-of-thought for disentangled reasoning generation to enhance navigation decisions.
2) Enable parameter-efficient in-domain training to adapt smaller LLMs to VLN efficiently. 
3) Experiments show NavCoT boosts smaller LLaMA's performance to surpass expensive GPT-4-based method, demonstrating superiority and scalability.

In summary, this paper explores an effective way to simplify LLM-based VLN by repurposing LLMs to generate trainable navigational reasoning. The proposed method significantly improves efficiency and scalability by using smaller adaptable LLMs to achieve better performance than large expensive models.
