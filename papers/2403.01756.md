# [Attention Guidance Mechanism for Handwritten Mathematical Expression   Recognition](https://arxiv.org/abs/2403.01756)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Handwritten mathematical expression recognition (HMER) aims to translate images of handwritten math expressions into LaTeX sequences. It is challenging due to the 2D structure and layout complexity of math expressions.  
- A key issue is misalignment, especially under-parsing where parts of the expression image are overlooked and not parsed. This is partly caused by a "context leakage" phenomenon where the attention mechanism mistakenly focuses on symbols that should be parsed later, incorporating erroneous future context.

Proposed Solution:
- An attention guidance mechanism is proposed to explicitly suppress attention on irrelevant areas and enhance attention on the intended target region. This avoids incorporating misleading features from incorrectly attended areas.

- Two complementary guidance approaches are introduced: 
   1) Self-guidance: Seeks consensus among attention heads to eliminate inconsistencies since attended symbols should be consistent across heads.
   2) Neighbor-guidance: Reuses previous step's final attention to guide middle layers' attention in current step, based on observation that alignment relies on previously decoded neighbor.

- These guidances generate residual correlations to refine the raw attention correlations. Self-guidance coordinates single-step attention while neighbor-guidance facilitates propagation across steps.

Main Contributions:
- Identified context leakage phenomenon in attention for HMER which coverage mechanisms fail to address.
- Proposed general attention guidance framework to explicitly adjust attention weights to suppress incorrect areas.  
- Devised self-guidance approach to seek consistent consensus among multiple attention heads.
- Devised neighbor-guidance approach to leverage previous step's attention to guide current step.
- Achieved new state-of-the-art results on CROHME 2014/2016/2019 datasets, outperforming previous methods.
