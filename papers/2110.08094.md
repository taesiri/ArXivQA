# [Jurassic is (almost) All You Need: Few-Shot Meaning-to-Text Generation   for Open-Domain Dialogue](https://arxiv.org/abs/2110.08094)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research questions/hypotheses appear to be:1) Can few-shot prompt-based learning create high-quality, semantically-controlled natural language generators (NLGs) for open-domain dialogue systems? 2) Can few-shot prompting allow language models like GPT-Neo and Jurassic-1 to generate conversational responses directly from meaning representations (MRs) that generalize well to new domains and unseen entities/relations?3) How does the quality and coverage of neural NLGs created via prompt-based learning compare to existing template-based NLGs for movies, music, sports, TV, and video games in the Alexa Prize dialogue system Athena?4) Can few-shot prompting control the dialogue acts realized in generated responses, when the meaning representations specify dialogue acts like in the Viggo dataset?5) How well do automatic metrics like BLEURT correlate with human evaluations of coherence and semantic accuracy for prompt-based NLGs?The central hypothesis appears to be that few-shot prompt-based learning can reliably create high-quality NLGs for open-domain dialogue systems, that generalize across domains and meaning representations. The experiments seem designed to test this hypothesis by evaluating both automatic and human metrics.


## What is the main contribution of this paper?

The main contribution of this paper is developing and evaluating neural natural language generation models for open-domain dialogue systems using few-shot prompt-based learning. Specifically:- The authors create two new neural NLG models, Athena-GPT-Neo and Athena-Jurassic, by fine-tuning large pre-trained language models (GPT-Neo and Jurassic-1) using few-shot prompting on datasets derived from an existing dialogue system called Athena.- They experiment with different prompting strategies, including varying the number of shots (2, 3, 10), prompt formats (QA vs sequence-to-sequence), and meaning representations (KG triples vs dialogue acts). - The models are evaluated both automatically using BLEURT and via human evaluation on coherence, semantic accuracy, and other metrics. - Key results show that with 10-shot prompting, both models produce coherent outputs, but Athena-Jurassic performs significantly better on human metrics. Also, Athena-Jurassic generalizes remarkably well even with just 2-shot prompting on unseen entities and relations.- The authors demonstrate that few-shot prompt-based learning can create high-quality, semantically controlled NLG models that generalize across domains, which could be useful for dialogue systems.In summary, the main contribution is using few-shot prompting to create neural NLG models for open-domain dialogue that can generate natural, accurate, and conversational responses directly from meaning representations. The results suggest this approach could help improve the coverage and quality of data-to-text generation in dialogue systems.
