# [Advancing TTP Analysis: Harnessing the Power of Encoder-Only and   Decoder-Only Language Models with Retrieval Augmented Generation](https://arxiv.org/abs/2401.00280)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
Interpreting Tactics, Techniques, and Procedures (TTPs) from the MITRE ATT&CK framework is challenging due to complexity, dependencies, and ambiguity. The paper questions how well different types of Large Language Models (LLMs) - specifically encoder-only models like RoBERTa and decoder-only models like GPT-3.5 - can comprehend and summarize cyberattack TTPs to inform analysts, without explicit training to map TTP descriptions to tactics.

Proposed Solution:
The paper proposes using Retrieval Augmented Generation (RAG) to provide relevant contexts to decoder-only models when interpreting attack procedure descriptions, in order to reduce hallucination risks. This approach is compared to supervised fine-tuning of encoder-only models on labeled ATT&CK data and direct use of decoder-only models without RAG.

Main Contributions:
- Compares encoder-only LLMs with RAG-enhanced decoder-only LLMs for interpreting cyberattack TTPs, without explicit mapping supervision.
- Shows significant improvement in decoder-only LLM performance when provided accurate context via RAG, demonstrating the impact of relevant information.
- Reveals limitations of RAG techniques when they fail to retrieve useful information, shedding light on capabilities and challenges.
- Finds decoder-only LLMs have high recall but lower precision, indicating a need to improve precision without sacrificing recall.
- Provides analysis of specific examples showing current lack of true interpretability in decoder-only LLMs and over-reliance on keywords when RAG context is provided.

Overall, the paper offers useful insights on using different LLM approaches for analyzing cyber threat intelligence, including benefits and limitations to guide future research.


## Summarize the paper in one sentence.

 This paper compares the performance of supervised fine-tuning of smaller encoder-only language models versus retrieval augmented generation-enhanced larger decoder-only models in interpreting cyberattack procedure descriptions from the MITRE ATT&CK framework.


## What is the main contribution of this paper?

 Based on my review of the paper, the main contributions are:

1. The authors analyze and compare the performance of supervised fine-tuning (SFT) of smaller encoder-only language models (like RoBERTa and SecureBERT) versus using retrieval augmented generation (RAG) with larger decoder-only models (like GPT-3.5) for interpreting cyberattack procedure descriptions and mapping them to MITRE ATT&CK tactics. 

2. They demonstrate a significant improvement in interpreting tactics, techniques, and procedures (TTPs) when using RAG to provide relevant context to the GPT-3.5 decoder-only model. This shows the impact of providing the right contextual information.

3. The limitations of RAG techniques are studied, especially when relevant information is not successfully retrieved. This sheds light on the continued challenges with using RAG.

4. The authors indicate that while decoder-only models have high recall in this task, they often lack precision. This points to the need for advances in increasing precision without sacrificing recall.

5. Analysis is provided on the lack of true "interpretation" capability of decoder-only models even when given relevant context - instead they seem to search for the most probable solution.

In summary, the main contribution is a rigorous comparison of encoder-only versus decoder-only LLMs on interpreting cyberattack TTPs, providing insights on the limitations and benefits of each approach.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper's content, some of the key terms and concepts covered include:

- Large Language Models (LLMs)
- Encoder-only LLMs (e.g. RoBERTa, SecureBERT)
- Decoder-only LLMs (e.g. GPT-3.5) 
- Tactics, Techniques, and Procedures (TTPs)
- MITRE ATT&CK framework
- Retrieval Augmented Generation (RAG) 
- Fine-tuning LLMs 
- Mapping cyberattack procedures to tactics
- Comparing encoder-only vs decoder-only LLMs
- Limitations of RAG techniques
- Lack of precision in decoder-only LLMs
- Lack of true interpretation capability in LLMs

The paper conducts experiments using the latest ATT&CK dataset to compare supervised fine-tuning of encoder-only LLMs vs using RAG to enhance decoder-only LLMs for interpreting cyberattack procedures. It demonstrates limitations in both approaches and argues for the need to improve precision without compromising recall in LLMs.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes using Retrieval Augmented Generation (RAG) to provide relevant context to decoder-only language models when interpreting cyberattack procedures. What are the key advantages and disadvantages of this approach compared to relying solely on the language model's pre-trained knowledge?

2. The paper finds that providing the exact URL of the procedure as context via RAG leads to significantly improved performance in mapping to MITRE ATT&CK tactics. However, this is an unrealistic scenario. What strategies could be used to try to retrieve similarly relevant context to approximate this upper bound performance?  

3. The paper observes that decoder-only models have high recall but lower precision compared to encoder-only models. What modifications could be made to the RAG approach or decoder-only models themselves to try to improve precision without sacrificing high recall capabilities?

4. In the RAG approach, how is the relevancy of retrieved context determined when selecting passages to provide as additional context to the decoder-only model? What limitations did the paper find with the relevancy determination in some cases?

5. Could the RAG approach be improved by providing multiple retrieved passages to the decoder-only model and having it determine the most relevant context itself instead of pre-selecting passages? What challenges might this introduce?

6. How were the encoder-only models fine-tuned in this study and what were the limitations of this fine-tuning approach for interpreting cyberattack procedures? Could different fine-tuning strategies improve performance?

7. For the attack procedures labeled with multiple MITRE ATT&CK tactics, how did the models compare in terms of identifying multiple relevant tactics from the descriptions? Did any model type show better or worse capability in multi-label classification?

8. The paper suggests the decoder-only models lack true interpretative capabilities when provided additional context via RAG. What analysis or experiments could be done to further evaluate the level of comprehension of decoder-only models? 

9. How feasible would it be to apply an ensemble approach that combines an encoder-only model and decoder-only model to capitalize on their complementary strengths in precision and recall?

10. The paper focuses exclusively on the latest version of MITRE ATT&CK data. How might the models compare when applied to new and constantly evolving attack procedures that may have little overlap with pre-training or fine-tuning data?
