# [Open-Source Large Language Models Outperform Crowd Workers and Approach   ChatGPT in Text-Annotation Tasks](https://arxiv.org/abs/2307.02179)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, it seems the central research question is:How do open-source large language models (LLMs) such as HuggingChat and FLAN compare to proprietary models like ChatGPT and human annotations from MTurk in terms of performance on text annotation tasks?The key aspects that point to this question:- The paper introduces recent research showing impressive performance of ChatGPT on NLP tasks, but notes open-source LLMs are gaining attention for cost-effectiveness, transparency, reproducibility etc. - It states the goal is to assess these models using zero-shot and few-shot approaches on text annotation tasks, comparing their accuracy against MTurk and amongst themselves. - The results section evaluates the performance of ChatGPT, HuggingChat, FLAN and MTurk on 11 text annotation tasks across 4 datasets. - The conclusion summarizes that while ChatGPT had the best performance overall, open-source LLMs exceeded MTurk and demonstrated competitive potential against ChatGPT in certain tasks.So in summary, the central research question seems to be examining and comparing the performance of open-source LLMs versus ChatGPT and human annotations on text annotation tasks. The paper aims to assess the viability of open-source models as an alternative to proprietary LLMs and crowd-sourced human annotations.
