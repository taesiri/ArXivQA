# DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the main research question this paper aims to address is: How can we develop improved evaluation metrics that better assess the discourse coherence of automatically generated text, especially for abstractive summarization and document-level machine translation?The key hypothesis is that existing metrics like BERTScore and BARTScore, while strong at sentence-level evaluations, are limited in their ability to evaluate discourse coherence across multiple sentences. The authors propose that explicitly modeling coherence phenomena like entity transitions and focus shifts between sentences can lead to metrics that better correlate with human judgments of coherence for long text generation tasks. To test this, they introduce DiscoScore, a metric that uses BERT representations along with graph-based modeling of entity/focus transitions. The main hypothesis is that combining BERT with explicit discourse modeling will outperform metrics based on BERT or discourse features alone. Their experiments on summarization and MT datasets aim to demonstrate the superior correlation of DiscoScore variants with human coherence ratings compared to other state-of-the-art metrics.In summary, the paper introduces DiscoScore as a new way to evaluate discourse coherence in text generation by combining BERT representations with graph-based coherence models, hypothesizing this will lead to better correlation with human judgments compared to existing metrics. The experiments are designed to test this hypothesis.


## What is the main contribution of this paper?

This paper introduces DiscoScore, a new evaluation metric for assessing the coherence of generated text in summarization and machine translation. The main contributions are:- DiscoScore uses BERT to model discourse coherence from two perspectives: (1) focus frequency/semantics and (2) focus transitions between sentences. This allows it to capture coherence properties missed by other metrics.- Experiments show state-of-the-art metrics like BARTScore perform poorly at the system level for judging coherence and other aspects like factual consistency. In contrast, DiscoScore achieves much stronger correlation with human ratings.- The paper demonstrates the importance of discourse signals for judging text quality. Simple features derived from DiscoScore can strongly distinguish between system hypotheses and references.- Analysis provides insights into why certain DiscoScore variants outperform others based on how discriminative their discourse features are. This allows interpreting performance gaps.- DiscoScore combines the benefits of leveraging contextualized encoders like BERT along with explicit discourse modeling, outperforming metrics that rely on just one of those.In summary, the main contribution is a new metric DiscoScore that successfully judges text coherence by combining BERT representations with discourse features based on centering theory. Experiments show it outperforms existing metrics, especially at the system level evaluation that is most important when comparing models.
