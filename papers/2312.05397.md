# [On the Performance of Temporal Difference Learning With Neural Networks](https://arxiv.org/abs/2312.05397)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Temporal difference (TD) learning with neural network function approximation (neural TD) is widely used in reinforcement learning, but lacks theoretical guarantees on convergence. Previous analyses made strong assumptions like small projection radius, regularization of policy, single hidden layer, or linearization around initial parameters. 

Proposed Solution:
- The paper provides a convergence analysis of neural TD with projection onto a ball of fixed (not diminishing with width) radius around the initial parameters.
- They leverage a combination of $l_2$ and Dirichlet norm introduced in prior work that allows viewing neural TD as an approximate gradient descent on this norm. 
- Using this view and bounds on neural network smoothness, they show neural TD parameters stay in a region where the neural network behavior is reasonably linear, allowing the analysis.

Main Results:
- Provided approximation error of best network in the projection ball is $\epsilon$, they show an $O(\epsilon) + \tilde{O}(1/\sqrt{m})$ bound on distance to best parameters for $m$ being the width of all layers.   
- The analysis applies to any number of layers and requires no regularization, representability or other assumptions on the policy.
- Simulations verify networks move outside initialization and still approximate well, supporting the usefulness of non-diminishing projection radius.

Key Contributions:
- First analysis of neural TD that avoids assumptions like small projection radius, policy regularization, single layer, or linearization around initialization.
- Introduces use of Dirichlet norm and view as approximate gradient descent for analyzing neural TD.
- Result formally shows neural TD can converge to near best approximation error without unrealistically restricting function class.
- Together with simulations, makes case that common technique of diminishing radius for convergence proofs undermines performance.
