# [Multi-FAct: Assessing Multilingual LLMs' Multi-Regional Knowledge using   FActScore](https://arxiv.org/abs/2402.18045)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is little research on the factual accuracy of large language models (LLMs) like ChatGPT when generating text in non-English languages. It is unclear if they exhibit similar levels of factual hallucination across languages.

- Evaluating factuality in a multilingual setting is challenging due to differences in language resources like Wikipedia across languages. Existing metrics designed for English may not work well. 

Methodology:
- The authors introduce a pipeline called Multi-Fact to evaluate factual accuracy of LLMs across 9 languages - English, German, French, Spanish, Arabic, Swahili, Chinese, Korean and Bengali.

- The pipeline first generates biographies of 80 country leaders in 2015 using GPT-3.5 and GPT-4. It then translates the biographies to English using GPT-3.5 and measures factuality with FActScore against English Wikipedia.

Key Findings:  
- English consistently shows higher factual accuracy and generates more facts than other languages.

- There is a Western bias - biographies of American and European leaders tend to be more factually accurate across languages. 

- When analyzed geographically, languages reflect some of their local knowledge distribution but the Western bias persists. For example, Korean scores higher for East Asian leaders.

Main Contributions:
- First multilingual pipeline to evaluate factual accuracy of free-form LLM generative text across languages.

- Analysis revealing poorer factual precision of LLMs in non-English languages and geo-cultural biases in their knowledge distribution.

- Underscores need for better multilingual factuality assessment methods and addressing representation gaps in LLMs.
