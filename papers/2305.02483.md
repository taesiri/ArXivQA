# [ChatGPT-steered Editing Instructor for Customization of Abstractive   Summarization](https://arxiv.org/abs/2305.02483)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is:How can we effectively customize and improve the outputs of large language models like ChatGPT to better align with user needs and expectations? Specifically, the key hypotheses are:1) Large language models like ChatGPT can effectively serve as generators and editors in a generate-and-edit pipeline.2) Training a small instructor model using editor-steered reinforcement learning can produce instructions tailored to user needs that successfully guide large language model editors. 3) The proposed tri-agent pipeline of generator - instructor - editor can improve the quality of generated text to fulfill user requirements.The paper explores these hypotheses through experiments on abstractive text summarization, assessing whether the edited summaries better meet user criteria for coverage and factual consistency compared to the initial summaries. The instructor model is the key novel component proposed to steer the editing process towards user needs.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a tri-agent generation pipeline consisting of a generator, instructor, and editor to enhance the customization of abstractive summarization outputs. Specifically:- They propose using an inference-only large language model (LLM) like ChatGPT as both the generator and editor, while using a smaller model as an instructor to guide the editing process. - The instructor is trained with editor-steered reinforcement learning to optimize instruction generation for guiding the editor LLM. The reward directly quantifies how well the edited output fulfills user requirements.- They conduct experiments on two summarization datasets, showing the pipeline can improve alignment with user requirements related to coverage and factual consistency compared to both the initial summaries and LLM-generated instructions alone.In summary, the key contribution is developing a generation framework that decomposes the process into generator, instructor, and editor components in order to leverage the capabilities of large LLMs while allowing for user-specific customization via a trained instructor optimized for a particular editor LLM.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points in the paper:The paper proposes a three-agent pipeline for text generation consisting of a generator, instructor, and editor, where a small model is trained as an instructor to provide editing instructions tailored to user needs, guiding a large language model editor to refine the initial output from the generator to better align with user expectations, as evaluated on abstractive text summarization tasks.
