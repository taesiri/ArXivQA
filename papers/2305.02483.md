# [ChatGPT-steered Editing Instructor for Customization of Abstractive   Summarization](https://arxiv.org/abs/2305.02483)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is:How can we effectively customize and improve the outputs of large language models like ChatGPT to better align with user needs and expectations? Specifically, the key hypotheses are:1) Large language models like ChatGPT can effectively serve as generators and editors in a generate-and-edit pipeline.2) Training a small instructor model using editor-steered reinforcement learning can produce instructions tailored to user needs that successfully guide large language model editors. 3) The proposed tri-agent pipeline of generator - instructor - editor can improve the quality of generated text to fulfill user requirements.The paper explores these hypotheses through experiments on abstractive text summarization, assessing whether the edited summaries better meet user criteria for coverage and factual consistency compared to the initial summaries. The instructor model is the key novel component proposed to steer the editing process towards user needs.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a tri-agent generation pipeline consisting of a generator, instructor, and editor to enhance the customization of abstractive summarization outputs. Specifically:- They propose using an inference-only large language model (LLM) like ChatGPT as both the generator and editor, while using a smaller model as an instructor to guide the editing process. - The instructor is trained with editor-steered reinforcement learning to optimize instruction generation for guiding the editor LLM. The reward directly quantifies how well the edited output fulfills user requirements.- They conduct experiments on two summarization datasets, showing the pipeline can improve alignment with user requirements related to coverage and factual consistency compared to both the initial summaries and LLM-generated instructions alone.In summary, the key contribution is developing a generation framework that decomposes the process into generator, instructor, and editor components in order to leverage the capabilities of large LLMs while allowing for user-specific customization via a trained instructor optimized for a particular editor LLM.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points in the paper:The paper proposes a three-agent pipeline for text generation consisting of a generator, instructor, and editor, where a small model is trained as an instructor to provide editing instructions tailored to user needs, guiding a large language model editor to refine the initial output from the generator to better align with user expectations, as evaluated on abstractive text summarization tasks.


## How does this paper compare to other research in the same field?

Here are a few key points comparing this paper to other research on improving customization of large language model outputs:- The tri-agent pipeline proposed in this paper builds on prior work like Self-Refine (Madaan et al. 2023) that decompose the generation process into separate components. However, this paper introduces a novel three-component structure consisting of a generator, instructor, and editor. - Using a separate small instructor model to generate editing instructions is a unique aspect not seen in related works. This allows leveraging large LM capabilities while using smaller models where fine-tuning large LMs is infeasible. - The editor-steered reinforcement learning to train the instructor model is also novel. Related work has not explicitly optimized the instructor model to be compatible with the editor LM.- For summarization, this paper focuses on customizing outputs to user needs like coverage and factual consistency. Related summarization work either uses large LMs in a zero-shot setting or trains supervised models, without tailoring to user specs.- The iterative editing process explored allows continuously refining outputs to better meet user needs. Most related work focuses on one-step editing.- Compared to other text editing techniques requiring human-labeled data or editing chains, this work operates at a more abstract level using natural language instructions.In summary, the key novelties are the tri-agent pipeline structure, editor-steered RL for the instructor, focus on customization to user needs for summarization, and iterative editing process. The overall approach aims to effectively leverage large LMs while accounting for their constraints.
