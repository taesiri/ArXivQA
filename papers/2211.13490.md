# [Pose-disentangled Contrastive Learning for Self-supervised Facial   Representation](https://arxiv.org/abs/2211.13490)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes a novel method for self-supervised facial representation learning. The central hypothesis is that disentangling pose-related features from other facial features and learning them separately will improve the performance of contrastive self-supervised learning for facial representation. Specifically, the paper hypothesizes that:

1. Disentangling pose-related and pose-unrelated facial features using the proposed pose-disentangled decoder (PDD) will allow learning facial representations that better capture both pose and other facial information. 

2. Learning pose-related features through a separate pose-related contrastive learning scheme, rather than treating pose invariantly like standard contrastive learning, will improve facial representation by retaining more pose details.

3. Allowing the pose-related and facial contrastive learning objectives to cooperate adaptively via dynamic weighting will further enhance the facial representation compared to using either one alone.

The central research question is whether explicitly disentangling and separately learning pose and facial features in this manner can improve self-supervised facial representation over standard contrastive learning approaches that do not make this distinction. The paper aims to demonstrate the superiority of the proposed Pose-Disentangled Contrastive Learning (PCL) method through extensive experiments on facial expression, identity, AU detection, and pose estimation tasks.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes a novel Pose-disentangled Contrastive Learning (PCL) method for self-supervised facial representation learning. 

2. It introduces a pose-disentangled decoder (PDD) using facial image reconstruction and an orthogonalizing regulation to disentangle pose-related features from pose-unrelated facial features.

3. It proposes a pose-related contrastive learning scheme to enable more effective learning on pose information. 

4. Together with face contrastive learning on pose-unrelated facial features, the two contrastive learning schemes cooperate adaptively for more robust facial representation learning.

5. Extensive experiments show that PCL significantly outperforms state-of-the-art self-supervised methods on four facial understanding tasks - facial expression recognition, face recognition, facial AU detection and head pose estimation.

In summary, the main contribution is the novel PCL framework that can disentangle pose features from other facial features and enhance contrastive learning through pose-related contrastive learning, leading to improved self-supervised facial representation learning.
