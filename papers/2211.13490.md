# [Pose-disentangled Contrastive Learning for Self-supervised Facial   Representation](https://arxiv.org/abs/2211.13490)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes a novel method for self-supervised facial representation learning. The central hypothesis is that disentangling pose-related features from other facial features and learning them separately will improve the performance of contrastive self-supervised learning for facial representation. Specifically, the paper hypothesizes that:

1. Disentangling pose-related and pose-unrelated facial features using the proposed pose-disentangled decoder (PDD) will allow learning facial representations that better capture both pose and other facial information. 

2. Learning pose-related features through a separate pose-related contrastive learning scheme, rather than treating pose invariantly like standard contrastive learning, will improve facial representation by retaining more pose details.

3. Allowing the pose-related and facial contrastive learning objectives to cooperate adaptively via dynamic weighting will further enhance the facial representation compared to using either one alone.

The central research question is whether explicitly disentangling and separately learning pose and facial features in this manner can improve self-supervised facial representation over standard contrastive learning approaches that do not make this distinction. The paper aims to demonstrate the superiority of the proposed Pose-Disentangled Contrastive Learning (PCL) method through extensive experiments on facial expression, identity, AU detection, and pose estimation tasks.
