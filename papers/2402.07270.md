# [Open-ended VQA benchmarking of Vision-Language models by exploiting   Classification datasets and their semantic hierarchy](https://arxiv.org/abs/2402.07270)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Evaluating large vision-language models (VLMs) that can generate free-form text given an image is challenging due to: (1) difficulty in semantically comparing text expressions, (2) ambiguity in questions that allow multiple valid answers, and (3) lack of granular evaluation on model strengths and limitations beyond a single accuracy metric.

Proposed Solutions: 
(1) Transform classification datasets into VQA format to create fine-grained sub-benchmarks for objects, actions and attributes. Compared to existing VQA datasets focused on coarse concepts, this allows more targeted assessment.  
(2) Resolve ambiguity by cropping the image to guide the model and asking automatically generated follow-up questions based on concept hierarchies to obtain the expected level of specificity.
(3) Compare traditional NLP metrics to LLM-based metrics using human judgments as gold standard. Simple containment works well for short answers.

Main Contributions:
(1) Framework to convert classification datasets into VQA tasks with reduced ambiguity.
(2) Hierarchical follow-up questions to handle ambiguity and enhance answer precision.  
(3) New VQA sub-benchmarks for detailed model diagnosis on objects, actions and attributes.
(4) Analysis showing generic pre-trained models are better for fine-grained concepts while VQA-specialized models are better for coarse concepts and on existing VQA datasets.
(5) Simple text containment metric works best for automated evaluation given the short ground truth answers, while LLM-based metrics approach human performance.

In summary, the paper advances VQA evaluation by enabling detailed assessment, comparing different types of VLMs, and analyzing suitable automatic metrics approaching human judgements. This lays the foundation for targeted future progress.
