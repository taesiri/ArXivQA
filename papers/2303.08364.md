# [Unsupervised Contour Tracking of Live Cells by Mechanical and Cycle   Consistency Losses](https://arxiv.org/abs/2303.08364)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: How can we accurately track the dynamic changes in the morphology of live cells by tracking every point along the cellular contour (contour tracking)? 

The key challenges the authors aim to address are:

1) Live cell contours exhibit visual features that are difficult to distinguish, so traditional optical flow methods may fail. 

2) The expansion and contraction of the cellular contour changes the total number of points, which poses a challenge for tracking methods that rely on a fixed number of points.

3) There is no ground truth data available for supervising a machine learning model for dense contour tracking.

To address these challenges, the main hypothesis is that an unsupervised deep learning model can be trained to track live cell contours densely using mechanical and cycle consistency losses, without requiring manual annotations for supervision.

In summary, the paper proposes a novel unsupervised deep learning approach for dense contour tracking of live cells, which has not been addressed effectively in prior work. The key novelty is using mechanical and cycle consistency losses to train the model without ground truth data.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a deep learning-based method for contour tracking of live cells with dense point correspondences. The key points are:

- They propose the first deep learning model that can track cellular contours densely while outperforming other methods in accuracy. 

- They present an unsupervised learning strategy comprised of mechanical and cycle consistency losses to train the contour tracker without ground truth data. 

- They show that using forward and backward cross attention together with cycle consistency leads to more accurate dense correspondences. 

- They provide the first quantitative evaluation of cellular contour tracking by labeling tracking points in live cell videos.

- Their contour tracker achieves state-of-the-art performance on two live cell datasets and can generalize to track other viscoelastic materials like jellyfish.

In summary, this paper makes significant advances in dense contour tracking of live cells and viscoelastic materials, which prior computer vision methods struggled with. The proposed unsupervised deep learning approach outperforms previous models and enables more accurate analysis of cellular morphodynamics.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper proposes an unsupervised deep learning method for tracking points along highly deformable cellular contours in microscopy videos, using mechanical and cycle consistency losses to account for the complex motions and lack of ground truth data.


## How does this paper compare to other research in the same field?

 Here are some key ways this paper compares to other research in cellular contour tracking and quantification of morphodynamics:

- It proposes the first deep learning-based model for dense contour tracking of live cells. Prior work like optical flow methods or the mechanical model have limitations in accurately handling the complex motions and visual features of live cell contours.

- The method uses unsupervised learning with mechanical and cycle consistency losses to train the contour tracker. This avoids the need for laborious manual labeling of dense correspondences along the contour. Other recent deep learning approaches like PoST rely more heavily on supervised learning.

- Quantitative evaluation on labeled tracking points shows superior performance over prior methods like optical flow, PoST, and the mechanical model. This provides an objective benchmark for the accuracy of different contour tracking approaches.

- The architecture uses cross attention and offset regression which is tailored for this contour correspondence problem. Ablations demonstrate the benefit of components like forward/backward cross attention over other variants. 

- The work demonstrates application to different microscopy modalities (phase contrast and fluorescence) as well as viscoelastic organisms (live cells and jellyfish). This shows the generalizability and robustness of the approach.

- Limitations are the reliance on segmentation, inability to handle contour splitting, and lack of joint training with segmentation. But overall, this paper makes significant advances in the problem of contour tracking and quantification of cellular morphodynamics.

In summary, the key innovations are in proposing the first deep learning solution for this task, using an unsupervised learning strategy well-suited to the problem, and objectively demonstrating through benchmarks and ablations the advantages of their approach over prior arts. The work moves the field forward in enabling more accurate computational analysis of dynamic cellular morphology.


## What future research directions do the authors suggest?

 Based on my reading of the paper, here are some of the main future research directions suggested by the authors:

- Jointly training the contour tracker with the segmentation model end-to-end to refine contours and improve correspondence estimation. The segmentation error affects the performance of both the mechanical model and their contour tracker.

- Implementing one-to-many correspondences to better handle expanding contours and cell splitting events. Their current model can handle many-to-one correspondences for merging contour points, but not the reverse for splitting points.

- Applying the contour tracking method to other types of viscoelastic materials beyond just cells, such as embryos, organoids, and soft robots. The authors mention this as an interesting future direction.

- Exploring other potential unsupervised losses beyond just cycle consistency and mechanical losses. Additional losses tailored to the contour tracking task could further improve accuracy.

- Extending the tracking to 3D contours and surfaces, not just 2D. This could expand the applicability to a wider range of microscopy modalities.

- Incorporating temporal modeling into the network architecture to leverage information across multiple frames. This could improve robustness.

- Applying the dense correspondences for novel downstream tasks such as analyzing cell lineage, identifying different cell morphodynamic phenotypes, etc.

In summary, the key directions mentioned are improving the segmentation, handling splitting events, expanding to other applications and data modalities, investigating new loss functions, adding temporal modeling, and applying the tracking for novel bioimaging tasks. The authors lay out a promising research roadmap based on the limitations and strengths of their presented approach.


## Summarize the paper in one paragraph.

 The paper presents an unsupervised deep learning method for dense contour tracking of live cells in microscopy videos. The key ideas are:

- Proposes a deep network with cross attention modules to establish dense correspondences between consecutive cell contours. Enables tracking of contour expansions/contractions.

- Uses unsupervised losses for training: a) cycle consistency loss for forward-backward tracking consistency, b) mechanical loss based on normal torsion forces to encourage motion perpendicular to the contour. 

- Evaluates on two live cell microscopy datasets with manually labeled sparse tracking points. Shows improved accuracy over prior methods like optical flow, Polygonal Surface Tracking and mechanical models.

- Demonstrates utility for quantifying cell morphodynamics like protrusion and retraction velocities along the contour. Applicable to other deformable objects like jellyfish.

Overall, it enables accurate dense tracking of deforming viscoelastic contours like cells where visual cues are ambiguous and motion is complex, using an unsupervised deep learning approach with geometrically motivated losses. Represents an advance for quantifying and understanding cell morphodynamics.
