# [Novi jeziƒçki modeli za srpski jezik](https://arxiv.org/abs/2402.14379)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There has been a recent proliferation of transformer-based language models for Serbian, but little analysis on how model size, training data size, and data quality impact performance on key NLP tasks.

- The paper aims to benchmark and analyze 10 selected Serbian text embedding models across 4 tasks: masked language modeling, sentence similarity, part-of-speech tagging, and named entity recognition.

Models Analyzed:
- The 10 models analyzed span the RoBERTa, ELECTRA, and XLM-RoBERTa model families and range from 80 million to 560 million parameters. 

- They were trained on Serbian corpora ranging from 500 million to 11.5 billion tokens. Two new models (jerteh-81 and jerteh-355) are presented.

Tasks and Key Findings:

- Masked Language Modeling: The 355 million parameter jerteh-355 model achieved the best performance, showcasing the impact of high quality, in-domain training data.

- Sentence Similarity: Smaller RoBERTa models trained on Serbian (+ Croatian) performed the best, suggesting generalization plays a key role.

- POS Tagging and NER: Models based on XLM-RoBERTa shine due to exposure to more diverse vocabularies during pretraining. More data and model size provide gains.

Main Contributions:
- The paper provides a rigorous benchmark and analysis of Serbian NLP models across diverse tasks.

- It highlights model strengths, weaknesses, and data needs - guiding future model development for Serbian. Two new highly performant models (jerteh-81 and jerteh-355) are presented as part of this analysis.
