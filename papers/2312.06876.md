# [Interactive Planning Using Large Language Models for Partially   Observable Robotics Tasks](https://arxiv.org/abs/2312.06876)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper tackles the challenge of designing robotic agents that can perform open vocabulary tasks involving reasoning under uncertainty. Specifically, it focuses on partially observable tasks where the robot does not initially have full information to complete the task and needs to interact with the environment to gather additional sensory information. Solving such tasks is difficult as it requires chain-of-thought reasoning, state estimation, and action planning based on updated beliefs.

Proposed Solution: 
The paper proposes an interactive planning technique using large language models (LLMs) for partially observable tasks. The key ideas are:

1) Use an LLM as a planner to guide the robot to collect missing information, infer the belief state, and plan actions accordingly. The LLM takes as input the task description, current observations, and action-observation history.

2) Add an LLM evaluator that explicitly asks the LLM to perform state abstraction, belief updates, and handle execution errors. This enhances reasoning stability.  

3) Compare pre-trained LLM (GPT-4) against a fine-tuned smaller LLM (Llama2) using a self-instruction based data generation method. This helps understand limitations of smaller models.

Main Contributions:

- Introduction of LLM-POP, an interactive planning framework using LLMs for partially observable tasks. Demonstrated in simulation and real-world.  

- Analysis of performance of pre-trained vs fine-tuned LLM models for complex interactive planning. Identified gaps in state abstraction and belief update capabilities.

- Self-instruction based method to generate data and fine-tune smaller LLMs for interactive planning tasks involving reasoning.

The core idea is leveraging reasoning and chain-of-thought capabilities of LLMs to plan optimal actions while interacting with the environment to mitigate uncertainties. Both simulation and real-world experiments validate the approach.
