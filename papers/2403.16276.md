# [AVicuna: Audio-Visual LLM with Interleaver and Context-Boundary   Alignment for Temporal Referential Dialogue](https://arxiv.org/abs/2403.16276)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key aspects of the paper:

Problem:
- Temporal referential dialogue (TRD) in audio-visual contexts remains limited due to lack of suitable datasets and inability of models to effectively integrate complex audio-visual cues over time. 

- There is a shortage of comprehensive, untrimmed video datasets with accurate temporal annotations for audio-visual events.

- Existing audio-visual models fail to adequately capture the temporal relationship between auditory and visual modalities.

Proposed Solution:

- Introduce PU-VALOR, a large-scale pseudo-untrimmed audio-visual video dataset with over 114K videos and precise temporal boundary annotations.

- Present AVicuna - an audio-visual LLM incorporating Audio-Visual Token Interleaver (AVTI) and Context-Boundary Alignment to achieve temporal alignment between audio-visual tokens.

- Aggregate audio datasets into A5-222K to facilitate audio-text alignment during training.  

- Employ a 4-stage fine-tuning methodology focusing on multimodal-text alignment, context-boundary alignment and instruction tuning.

Main Contributions:

- Novel approach to construct PU-VALOR pseudo-untrimmed dataset enabling audio-visual temporal grounding research.

- AVicuna model with interleaved audio-visual token sequences and alignment mechanisms for improved understanding.

- A5-222K comprehensive audio dataset bolstering audio-text alignment in LMMs.  

- Demonstrated state-of-the-art performance of fine-tuned AVicuna in temporal localization, QA and referential dialogue.

In summary, the paper introduces valuable datasets, an innovative audio-visual architecture, and an effective training methodology to push boundaries of fine-grained audio-visual understanding focused on temporal aspects.
