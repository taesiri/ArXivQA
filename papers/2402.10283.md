# [Backdoor Attack against One-Class Sequential Anomaly Detection Models](https://arxiv.org/abs/2402.10283)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Deep learning models have been widely adopted for sequential anomaly detection. However, deep learning models face a critical security threat - their vulnerability to backdoor attacks. When compromised by a backdoor attack, a model behaves normally on benign data but activates backdoors and makes wrong predictions when certain triggers appear. It is important to study backdoor attacks against sequential anomaly detection models since if backdoors are injected, it presents a substantial security risk. However, conducting backdoor attacks on anomaly detection models has two main challenges: 1) it is difficult to craft imperceptible triggers for sequential data without using anomalies; 2) since no anomalies are available during training, how to ensure the infected models classify anomalies with triggers as normal is non-trivial.

Proposed Solution: 
The authors propose a novel backdoor attack approach against distance-based one-class anomaly detection models like Deep SVDD and OC4Seq. The attack has two steps - trigger generation and backdoor injection.

Trigger Generation: Select a subset of normal sequences, replace some entries in them with other normal entries to create perturbed sequences. The unchanged subsequence serve as imperceptible triggers.  

Backdoor Injection: Propose two objectives - pushing the latent representations of perturbed sequences towards the center of normal sequences, and maximizing mutual information between perturbed sequences and their normal counterparts. This increases the chance for anomalies with triggers to be classified as normal.

The overall attack strategy enables injecting backdoors into anomaly detection models to evade detection, without the need for any real anomalies.

Main Contributions:
1. A new backdoor attack framework for distance-based one-class anomaly detection models on sequential data.
2. The attack is imperceptible as neither trigger generation nor backdoor injection uses real anomalies. 
3. Demonstrate the attack effectiveness on Deep SVDD and OC4Seq models through experiments.

In summary, this paper explores an important security issue of backdoor attacks against sequential anomaly detection models and proposes a novel stealthy attack strategy to compromise such models. The attack does not rely on anomalies and can enable anomalies with triggers to evade detection.
