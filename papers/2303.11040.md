# [Benchmarking Robustness of 3D Object Detection to Common Corruptions in   Autonomous Driving](https://arxiv.org/abs/2303.11040)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the key research questions and contributions of this paper are:

1) How to comprehensively and rigorously evaluate the corruption robustness of 3D object detection models? 

To address this, the paper systematically designs 27 types of common corruptions in 3D object detection considering various realistic driving scenarios. By synthesizing these corruptions on public datasets at different severity levels, the authors construct three large-scale corruption robustness benchmarks - KITTI-C, nuScenes-C, and Waymo-C.

2) How do diverse state-of-the-art 3D object detectors perform under these common corruptions? What insights can we gain?

The paper conducts extensive experiments on 24 3D object detection models with different modalities and architectures on the proposed benchmarks. Based on the results, the authors provide comparative analyses and draw several findings regarding which corruptions and models are more threatening, the effectiveness of multi-modality, etc.

3) Can data augmentation techniques improve the corruption robustness? 

The paper studies several data augmentation strategies for point clouds and images as potential solutions. But experiments show they provide limited robustness gain, leaving it an open problem.

Overall, this paper makes solid contributions in benchmarking and evaluating the corruption robustness of 3D object detection models through comprehensive benchmark construction and model evaluation. The insights from analyses are valuable for developing more robust models in the future.
