# [SynArtifact: Classifying and Alleviating Artifacts in Synthetic Images   via Vision-Language Model](https://arxiv.org/abs/2402.18068)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Synthetic images generated by AI generative models often suffer from complex artifacts that compromise image quality and realism. However, existing methods for evaluating and improving synthetic images lack the ability to directly identify, classify and alleviate artifacts. 

Proposed Solution:
1. Construct a taxonomy of 13 common artifact types in synthetic images, spanning object-related, lighting and other issues.

2. Create a dataset named SynArtifact-1K, with 1.3K synthetic images annotated with artifact categories, descriptions and coordinates. 

3. Fine-tune a Vision-Language Model (LLaVA) on SynArtifact-1K to classify artifacts. Results show accuracy improves 25.66% over baseline.

4. Use the fine-tuned model as an "artifact classifier" to provide reinforcement learning feedback to further optimize the generative model to alleviate artifacts, using a specialized reward function.

Main Contributions:
- First comprehensive taxonomy of synthetic image artifacts
- Novel SynArtifact-1K dataset with rich artifact annotations 
- Artifact classification by fine-tuning Vision-Language Model
- Using artifact classifier to refine generative model and reduce artifacts via reinforcement learning

The method is end-to-end, providing both interpretable artifact analysis and means to improve image quality by alleviating artifacts in the generative process. Experiments and user studies demonstrate effectiveness of the approach.
