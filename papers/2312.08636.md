# [MmAP : Multi-modal Alignment Prompt for Cross-domain Multi-task Learning](https://arxiv.org/abs/2312.08636)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a novel Multi-modal Alignment Prompt (MmAP) to efficiently adapt the vision-language model CLIP to downstream multi-task image recognition scenarios. MmAP generates aligned text and visual prompts via a shared source prompt to achieve prompt tuning without disrupting CLIP's cross-modal alignment. Building on MmAP, the authors design a multi-task prompt learning framework incorporating both group-shared and task-specific MmAPs. Similar tasks are grouped together and assigned a shared MmAP to maximize complementarity, while task-specific MmAPs preserve unique task characteristics. Comprehensive experiments on Office-Home and MiniDomainNet benchmark datasets demonstrate that this approach attains competitive performance versus full fine-tuning while utilizing only ~0.09% of CLIP's parameters. The proposed method strikes an optimal balance between accuracy and efficiency for adapting foundation models to multi-task computer vision settings.
