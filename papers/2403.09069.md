# [Dyadic Interaction Modeling for Social Behavior Generation](https://arxiv.org/abs/2403.09069)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Generating realistic and diverse listener reactions and facial expressions in response to a speaker's motions and voice in dyadic conversations is challenging. 
- Existing methods fail to fully capture the intricacies of human-human interactions and are often tuned to specific listeners, unable to generalize.

Proposed Solution:
- The authors propose Dyadic Interaction Modeling (DIM), a self-supervised pre-training strategy that jointly models speakers' and listeners' motions using masking and contrastive learning.
- DIM captures the contextualized bi-directional nature of human conversations and learns unified representations of speaker and listener behaviors.
- DIM is used to pre-train a framework called DIM-Listener which takes as input the speaker's audio-visual signals and generates the listener's realistic and diverse facial motions and expressions.

Main Contributions:
- Introduction of Dyadic Interaction Modeling (DIM), a novel pre-training technique for learning representations that capture intricacies of human-human conversations
- DIM-Listener framework for generating photorealistic listener reactions and expressions from speaker's inputs
- DIM-Speaker, which leverages DIM to generate speaker facial motions from speech
- Significantly outperforms state-of-the-art methods on listener reaction generation and speaker facial motion generation tasks, demonstrating generalizability across identities
- Generates highly realistic and diverse listener reactions and speaker motions, including emotive expressions, eye blinks and head gestures

In summary, the paper introduces an innovative dyadic modeling approach via self-supervised pre-training that learns to generate very realistic and human-like listener reactions as well as speaker motions, outperforming previous state-of-the-art by a large margin. The core of the solution is modeling the intricacies of human-human conversations.
