# [MeMOTR: Long-Term Memory-Augmented Transformer for Multi-Object Tracking](https://arxiv.org/abs/2307.15700)

## What is the central research question or hypothesis that this paper addresses?

This paper proposes MeMOTR, a long-term memory-augmented Transformer for multi-object tracking. The central hypothesis is that leveraging longer-term temporal information can help produce more stable and distinguishable representations for tracked objects, thus improving the model's association ability. Specifically, the paper aims to address the following research questions:- How to effectively model long-term temporal dependencies to augment the object features? The paper proposes a long-term memory updated with exponential smoothing to maintain temporal information. This memory is injected into the track embedding to reduce abrupt changes.- How to make the representations of different tracked objects more distinguishable? The paper uses a memory-attention layer to enable interactions between object trajectories, producing more discriminative features. - How to mitigate the conflicts between detection and tracking in a shared decoder? The paper proposes a separate detection decoder to align the detect and track embeddings better before the joint decoding.In summary, the central hypothesis is exploiting long-term temporal information with memory mechanisms can significantly improve the association performance in multi-object tracking. The experiments demonstrate the proposed MeMOTR method achieves state-of-the-art association accuracy on challenging datasets.


## What is the main contribution of this paper?

The main contribution of this paper is proposing MeMOTR, a long-term memory-augmented Transformer for multi-object tracking. The key ideas and components are:- They propose to use a long-term memory to maintain temporal features for each tracked object over time. This memory is updated smoothly using an exponential moving average. - They inject the long-term memory into the track embedding through a memory-attention layer. This makes the track embeddings more stable and distinguishable over time, improving association performance.- They use an adaptive aggregation module to fuse features from the current and previous frames, enhancing the representation. - They use a separate lightweight detection decoder before the joint decoder. This gives the detect embedding some semantic information about objects before joint decoding with track embeddings.- Experiments show MeMOTR achieves state-of-the-art performance on challenging datasets like DanceTrack, especially on association metrics like AssA and IDF1. It also generalizes well to MOT17 and BDD100K.In summary, the main contribution is developing a Transformer-based tracking method that effectively utilizes long-term temporal information through memories and attention to boost association performance. The experiments demonstrate the effectiveness of the proposed techniques.
