# [A Modular End-to-End Multimodal Learning Method for Structured and   Unstructured Data](https://arxiv.org/abs/2403.04866)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Multimodal learning has shown great success for unstructured data like images, text, audio etc. However, structured data like tabular data has received little attention despite being very common in real-world applications. 
- Many real-world applications have both structured and unstructured data, but existing methods either focus only on unstructured data or have limitations in handling diverse data types.
- Pre-training multimodal models requires large datasets which are scarce for many industry domains involving structured data.

Proposed Solution:
- The paper proposes MAGNUM, a modular end-to-end architecture for multimodal learning on both structured and unstructured data.
- It can work with any specialized modules tailored for a specific modality, enabling both transfer learning from pre-trained models and training from scratch.
- It has 3 main components:
   1) Low-level module: Extracts features from each modality using prompt tuning for unstructured data and feedforward networks for structured data.  
   2) Mid-level module: Compresses the features using graph neural network based processing.
   3) High-level module: Fuses multimodal features using a proposed Multimodal Gated Fusion technique.
- Does not require joint pre-training on a multimodal dataset.

Main Contributions:
- A flexible architecture that can handle diverse structured and unstructured modalities without needing modality-specific modifications.
- Eliminates the need for large multimodal pre-training datasets by leveraging specialized modules for each modality.
- Outperforms existing multimodal methods specialized for language-tabular and vision-language tasks on several real-world benchmarks.
- Provides a strong baseline for multimodal learning on structured and unstructured data.

In summary, the paper proposes a modular and flexible end-to-end architecture for multimodal learning that can effectively incorporate both structured and unstructured data without needing joint pre-training. Experiments show it outperforms prior arts focused only on specific modality combinations.
