# [Self-Supervised Prototypical Transfer Learning for Few-Shot   Classification](https://arxiv.org/abs/2006.11325)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be:How can we develop an unsupervised transfer learning approach for few-shot classification that does not require costly annotated data for pre-training, yet achieves competitive performance with supervised methods?The central hypothesis appears to be:By learning a self-supervised embedding that clusters augmented views of unlabeled images during pre-training, the model can learn useful representations for few-shot classification without needing labels. This approach can achieve competitive performance to supervised methods when applied to few-shot tasks, while requiring significantly less labeled data.In summary, the key research direction is developing an unsupervised transfer learning technique for few-shot classification that can match the performance of supervised approaches without needing labels for pre-training. The main hypothesis is that a self-supervised contrastive pre-training approach can learn representations sufficient for effective few-shot classification when transferred to novel tasks.
