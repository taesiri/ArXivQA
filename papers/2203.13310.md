# [MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection](https://arxiv.org/abs/2203.13310)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to effectively incorporate depth guidance into transformers to capture scene-level geometries and inter-object depth relations for improving monocular 3D object detection. The key hypothesis is that guiding the detection process with contextual depth cues can help overcome the limitations of existing center-guided detection paradigms that rely only on local visual features. By introducing depth-guided transformers with modules like the foreground depth map prediction and depth cross-attention, the method can enable object queries to adaptively aggregate features from depth-guided regions for better 3D attribute prediction.In summary, the paper proposes a novel depth-guided transformer framework called MonoDETR to explore the benefits of global depth guidance for monocular 3D object detection, in contrast to prior works that are constrained by local visual contexts around object centers.
