# [Photorealistic Video Generation with Diffusion Models](https://arxiv.org/abs/2312.06662)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

The paper presents WALT, a transformer-based method for photorealistic video generation using latent diffusion models. The key innovation is the use of a causal video encoder that maps both images and videos into a shared lower-dimensional latent space. This unified representation allows joint training on large image datasets while compressing videos spatially and temporally. To enable efficient processing, WALT utilizes a windowed attention architecture with alternating non-overlapping spatial and spatiotemporal self-attention blocks tailored for images and videos respectively. Without using classifier guidance, WALT demonstrates state-of-the-art performance on class-conditional video generation, frame prediction, and class-conditional image generation benchmarks. The authors also showcase WALT's scalability by training a cascade of models for high-resolution text-to-video generation. The base model is trained on nearly a billion image-text pairs and tens of millions of video-text pairs from diverse internet sources. Qualitative results demonstrate WALT can generate photorealistic and temporally consistent videos from language descriptions.
