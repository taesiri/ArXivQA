# [Encoding of lexical tone in self-supervised models of spoken language](https://arxiv.org/abs/2403.16865)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Research on self-supervised spoken language models (SLMs) has focused mainly on their encoding of segmental features like phonemes. Less is known about suprasegmental features like tone, stress, and intonation. 
- Tone is an important suprasegmental feature, present in over 60% of languages. This paper investigates whether SLMs encode lexical tone information, using Mandarin and Vietnamese as case studies.

Methods:
- SLMs based on wav2vec2 architecture trained on tonal (Mandarin, Vietnamese, Cantonese) and non-tonal (English, French) languages are analyzed.
- Linear classifiers are trained on SLM hidden state activations to predict lexical tone at the syllable level on Mandarin and Vietnamese test sets.
- Impact of ASR fine-tuning and comparison to human perceptual patterns are also examined.

Key Findings:
- SLMs encode lexical tone information even when trained solely on non-tonal languages. Fine-tuning enhances tone encoding for tonal language models but reduces it for non-tonal models.
- SLMs exhibit similar patterns to humans in discrimination of difficult Mandarin tone pairs, but do not follow developmental trajectories found in human tone perception.

Main Contributions:
- First detailed analysis showing self-supervised models' capabilities in encoding suprasegmental tone information, across tonal and non-tonal languages.
- Investigation of impact of ASR fine-tuning objective on resulting lexical tone encoding.
- Analysis situating model tone encoding capabilities in context of human tone perception patterns.

Let me know if you would like me to clarify or expand on any part of this summary further.
