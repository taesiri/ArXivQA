# [Thinking Like an Annotator: Generation of Dataset Labeling Instructions](https://arxiv.org/abs/2306.14035)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we generate high-quality labeling instructions for existing datasets in order to increase transparency, reproducibility, and utility?The authors highlight that detailed labeling instructions are rarely released publicly with datasets, even though they are critical for understanding annotation policies and boundaries between classes. They propose a new task called Labeling Instruction Generation (LIG) to automatically generate labeling instructions for a dataset using only the images and labels. The main hypothesis seems to be that their proposed framework, Proxy Dataset Curator (PDC), can act as an effective proxy for human annotators and dataset curators in generating multi-modal labeling instructions composed of representative text and image pairs for each class. They aim to show through computational metrics and human evaluation that PDC can produce high-quality, visually-informative labeling instructions.


## What is the main contribution of this paper?

This paper introduces a new task called Labeling Instruction Generation (LIG) to address the lack of publicly available labeling instructions for most datasets. The main contributions are:1. It highlights that labeling instructions are rarely made public for datasets, even though they are critical for understanding annotation policies and reproducibility. 2. It proposes the LIG task to automatically generate multi-modal labeling instructions (text descriptions + visual examples) for a dataset, acting as a proxy for human annotators and curators.3. It introduces a framework called Proxy Dataset Curator (PDC) to solve the LIG task efficiently without any model training. PDC retrieves representative text and image examples from the dataset itself to compose the instructions.4. It evaluates PDC on the NuImages and COCO datasets, showing it can generate high quality instructions that outperform baselines. Both computational evaluations and human experiments demonstrate the effectiveness of PDC.5. The paper frames LIG as an important new problem, proposes a practical solution in PDC, and shows strong initial results. Enabling the creation of labeling instructions could significantly improve dataset transparency and reproducibility in computer vision.In summary, the main contribution is identifying the lack of labeling instructions as an overlooked problem, formalizing it as the LIG task, and providing an initial solution to automatically generate multi-modal instructions for a dataset without manual effort.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new task called Labeling Instruction Generation (LIG) to address the lack of publicly available annotation instructions for most datasets, and introduces a framework called Proxy Dataset Curator (PDC) that acts as a proxy for human annotators to generate multi-modal labeling instructions for a given dataset without requiring model training.
