# [Thinking Like an Annotator: Generation of Dataset Labeling Instructions](https://arxiv.org/abs/2306.14035)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we generate high-quality labeling instructions for existing datasets in order to increase transparency, reproducibility, and utility?The authors highlight that detailed labeling instructions are rarely released publicly with datasets, even though they are critical for understanding annotation policies and boundaries between classes. They propose a new task called Labeling Instruction Generation (LIG) to automatically generate labeling instructions for a dataset using only the images and labels. The main hypothesis seems to be that their proposed framework, Proxy Dataset Curator (PDC), can act as an effective proxy for human annotators and dataset curators in generating multi-modal labeling instructions composed of representative text and image pairs for each class. They aim to show through computational metrics and human evaluation that PDC can produce high-quality, visually-informative labeling instructions.
