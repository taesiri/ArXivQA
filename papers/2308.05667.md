# [2D3D-MATR: 2D-3D Matching Transformer for Detection-free Registration   between Images and Point Clouds](https://arxiv.org/abs/2308.05667)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question/hypothesis seems to be:How can we develop an accurate and robust detection-free method for registering images to point clouds? The commonly used detect-then-match approaches for cross-modality registration struggle with inconsistent keypoint detection and feature description across images and point clouds. So the authors propose a new detection-free method called 2D3D-MATR that establishes correspondences in a coarse-to-fine manner without relying on keypoint detection. Specifically, the key hypotheses/components they explore are:1) Coarse patch-level matching between downsampled image patches and point patches can provide a good initial set of correspondences that capture global contextual information.2) A transformer architecture with self- and cross-attention can learn to produce well-aligned 2D and 3D features for matching. 3) A multi-scale pyramid sampling of image patches can help resolve scale ambiguity and misalignment between 2D and 3D patches caused by perspective effects.4) Extending the coarse patch matches to fine-grained pixel-point correspondences can produce accurate and robust matches for registration.So in summary, the main research question is how to do detection-free registration between images and point clouds in a way that is more accurate and robust than prior detection-based methods. The key ideas proposed are the coarse-to-fine matching pipeline and the multi-scale transformer matching module to address the challenges of cross-modality matching.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions seem to be:- Proposing a detection-free method for accurate 2D-3D registration between images and point clouds. Previous methods rely on detecting keypoints in each modality independently, which is problematic due to different feature spaces. - Adopting a coarse-to-fine pipeline that first establishes correspondences between image/point patches, then refines them into pixel/point matches. This allows incorporating global context information.- Designing a transformer-based module for patch matching that learns both global context and cross-modality correlations.- Using a multi-scale image patch pyramid to handle scale ambiguity and find better aligned patches between modalities. - Achieving state-of-the-art results on two public benchmarks, significantly outperforming previous methods like P2-Net in terms of inlier ratio and registration recall.In summary, the main contribution appears to be proposing the first detection-free coarse-to-fine approach for 2D-3D registration, along with transformer-based patch matching and multi-scale image pyramids to handle cross-modality challenges like scale ambiguity. The method achieves much more accurate matching and alignment between images and point clouds.
