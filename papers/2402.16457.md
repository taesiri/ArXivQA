# [RetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for   Short-form Open-Domain Question Answering](https://arxiv.org/abs/2402.16457)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Standard retrieval-augmented generation (RAG) methods always retrieve information regardless of the query, which can decrease efficiency and relevance. 
- Adaptive RAG (ARAG) aims to dynamically determine necessity of retrieval, but effectiveness is understudied due to lack of suitable benchmark and evaluation.

Proposed Solution:
- Create a new QA dataset called RetrievalQA with 1,271 short-form questions that require external knowledge to answer correctly. This enables assessment of ARAG methods.

- Benchmark existing calibration-based and model-based ARAG methods. Find that calibration requires threshold tuning and vanilla prompting is insufficient to guide reliable retrieval decisions.

- Propose TA-ARE, a simple yet effective prompt-based method to help LLMs assess necessity of retrieval without calibration or additional training. Uses current date awareness and demonstration examples.

Main Contributions:

1) New RetrievalQA dataset to assess adaptive retrieval for QA

2) Thorough benchmarking reveals limitations of existing ARAG approaches  

3) TA-ARE method improves adaptive retrieval prompting without calibration or training

The key aspects covered are the problem motivation, the proposed dataset and method, experiments conducted, and main contributions made. The summary captures the core elements to provide a high-level understanding of the paper's key focus areas and solutions proposed.
