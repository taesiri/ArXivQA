# [Understanding and Patching Compositional Reasoning in LLMs](https://arxiv.org/abs/2402.14328)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) have shown failures in compositional reasoning, i.e. combining multiple steps of reasoning, despite success on individual reasoning steps. This is evidenced by high error rates on multi-hop question answering using knowledge even when the LLM can answer the individual sub-questions.

Proposed Solution: 
- The authors analyzed compositional reasoning failures and found they stem from LLM's inability to properly generate or leverage implicit reasoning results in the intermediate layers.

- Experiments using Logit Lens showed that though implicit results do manifest in middle layers, they are not intense or timely enough to propagate to explicit results. 

- Intervention experiments provided evidence that emergence of implicit reasoning has a causative effect on explicit reasoning.

- Key multi-head self-attention (MHSA) modules were located using causal mediation analysis which are critical for producing and using implicit reasoning results.

- A model editing method called CREME was proposed to edit the located MHSA modules using the reference computation graph of the second sub-question. This allows correcting errors by integrating correct intermediate results.


Main Contributions:

- Identified root causes of compositional reasoning failures in LLMs to be inability to properly generate or leverage implicit reasoning results

- Showed causative effect of implicit reasoning results on final explicit results

- Located key MHSA modules responsible for implicit reasoning generation and usage

- Developed CREME, a model editing technique to correct compositional reasoning failures by editing located modules, which shows strong performance on correcting, paraphrasing and generalization.

In summary, the root causes of compositional reasoning failures were uncovered and a effective lightweight editing method called CREME was proposed to alleviate such failures.
