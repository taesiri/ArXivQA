# [Intrinsic Subgraph Generation for Interpretable Graph based Visual   Question Answering](https://arxiv.org/abs/2403.17647)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Visual question answering (VQA) models using deep learning have become very accurate but act as black boxes, lacking interpretability. 
- Most work on explainable AI generates explanations post-hoc rather than taking an intrinsic approach where the model itself produces explanations.
- There is a need for interpretable VQA models that provide explanations intrinsically alongside predictions.

Proposed Solution:
- The authors propose a graph-based VQA system that uses a graph neural network (GNN) with a graph attention network (GAT) component at its core.
- The key idea is for the model to intrinsically generate a relevant subgraph from the input scene graph while answering questions. This subgraph highlights the most salient nodes and acts as an explanation.
- A discrete hard attention mask is incorporated into the GAT using implicit maximum likelihood estimation to extract the subgraph. This makes the sampling of nodes for the subgraph differentiable.

Main Contributions:
- Competitive VQA performance is achieved even when using only a subset of nodes from the input scene graph.
- Human evaluators strongly preferred the intrinsically generated subgraph explanations over explanations from post-hoc methods like GNNExplainer.
- Quantitative metrics are introduced to evaluate explanation quality when no ground truth is available, including answer/question token coverage and performance drop when removing subgraphs. These metrics align with human judgments.

In summary, the paper presents an interpretable graph-based VQA method that generates intrinsic subgraph explanations alongside predictions. Both human and automated evaluations show the high quality of the explanations compared to post-hoc approaches.
