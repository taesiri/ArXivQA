# [SambaLingo: Teaching Large Language Models New Languages](https://arxiv.org/abs/2404.05829)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
- Large language models (LLMs) have limited availability in languages other than English/Chinese/French/Arabic. Pretraining LLMs from scratch in other languages requires massive data and compute. Multilingual LLMs also struggle to achieve good performance across all languages due to factors like data scarcity in many languages.

Proposed Solution:
- Present a comprehensive methodology to adapt pretrained LLMs like Llama 2 to new target languages via continued pretraining and alignment to human preferences.

Key Contributions:
- Best practices for adapting LLMs to new languages, evaluated across 9 typologically diverse languages at 7B and 70B scale:
  - Expanding model vocabulary for target language improves inference efficiency
  - Subword embedding initialization accelerates training convergence 
  - Mixing some data from base model's language is beneficial
- Recipe for human preference alignment with minimal need for expensive alignment data from target language
- State of the art models & evaluations across benchmarks in adapted languages, outperforming prior language-specific and multilingual models
- Publicly released model checkpoints to enable further research  

In summary, the paper proposes and comprehensively evaluates a methodology for adapting English-centric LLMs to new languages with minimal data requirements. This provides an effective path for obtaining strong language models in more languages. Code and state-of-the-art adapted models are also open-sourced.


## Summarize the paper in one sentence.

 This paper presents a comprehensive methodology for adapting large language models to new languages through vocabulary expansion, continued pretraining, and human preference alignment, demonstrating state-of-the-art results in 9 diverse languages.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Best practices and comprehensive methodology for adapting large language models to new languages, scaled across 9 diverse languages. This includes studies on vocabulary expansion, token embedding initialization, using machine translated data for alignment, etc.

2. State-of-the-art chat-aligned models in 9 languages by applying the proposed adaptation methodology. The adapted models outperform prior published baselines.

3. Open sourcing code and checkpoints to promote future research. This includes evaluation scripts integrating various multilingual benchmarks, as well as checkpoints of the adapted models.

4. Ablation studies and experiments analyzing different components of the adaptation methodology, such as the impact of base model quality, mixture of languages in alignment data, etc.

In summary, the paper presents a systematic study on adapting pretrained language models to new languages, resulting in SOTA models, while also open sourcing resources to facilitate future work. The comprehensive experiments and analyses provide useful guidelines and best practices for language model adaptation.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts discussed include:

- Language adaptation - Adapting existing large language models (LLMs) that were pretrained on English to new target languages through continued pretraining and alignment.

- Vocabulary expansion - Expanding the vocabulary of the base LLM by adding new tokens to represent the target language better. This improves tokenizer efficiency.

- Embedding initialization - Strategies like subword averaging to initialize embeddings for new tokens added to the vocabulary.

- Continuous pretraining - Continued pretraining of the LLM on a mixture of English and target language data to adapt it.

- Alignment - Using supervised finetuning and direct preference optimization to align the adapted LLM to human preferences and values.

- Low-resource languages - Testing language adaptation techniques on diverse languages, including lower-resource ones like Thai, Hungarian, Serbian, etc.

- Multilinguality - Comparing monolithic multilingual models vs individual language experts adapted from a base LLM.

- Evaluation - Using perplexity, translation quality, GLUE-style understanding tasks, and human evaluation to measure adapted model quality.

- Checkpoints and benchmarks - Releasing checkpoints and evaluation suites to promote further research into language adaptation of LLMs.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the language adaptation methodology proposed in the paper:

1. The paper expands the base model's vocabulary when adapting it to a new language. What considerations went into determining the optimal number of tokens to add? Does this number depend on typological similarity between languages or is it consistent across all languages?

2. When initializing embeddings for the new tokens added to the vocabulary, the paper compares four strategies (gaussian, xavier_uniform, avg_all, avg_subwords). But are there other promising initialization techniques worth exploring that may further accelerate loss convergence? 

3. For continuous pretraining, the paper uses a mixture of the base and target languages. What principles or theoretical grounding went into deciding on the 1:3 mixture ratio? How does varying this ratio impact downstream accuracy?

4. The methodology pretrains for a maximum of 4 epochs. Was any experimentation done on optimizing the number of pretraining epochs? Is there a point of diminishing returns and does this vary per language? 

5. The paper explores impact of quality of the base model on downstream accuracy after adaptation. If money was no object, what base model capacity would likely produce the overall best language experts after adaptation?  

6. The results show that machine translated alignment data performs similarly to human-written alignment data. But what quality or diversity metrics should one use to ensure this holds across more languages?

7. For alignment, is there an optimal number of training steps that generalizes across languages? Or does this need to be tuned per language?

8. The results show that language experts can outperform an equivalent capacity multi-lingual model. But as the number of target languages increases, at what point does the crossover happen where the multi-lingual model becomes more accurate?

9. Qualitative human evaluation results are only shown for 3 of the 9 languages. Can inference time and tokenization efficiency also be used as proxies for assessing quality improvements?

10. The methodology adapts classification-focused LLMs, but could sequence-to-sequence or encoder-decoder models adapted with this methodology also outperform dedicated MT models that are pre-trained from scratch?
