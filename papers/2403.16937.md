# [Hyperspherical Classification with Dynamic Label-to-Prototype Assignment](https://arxiv.org/abs/2403.16937)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper addresses limitations of the commonly used parametric softmax classifier (PSC) for image classification, including (1) overlooking intra-class compactness, (2) failing to fully utilize the metric space, leading to localized solutions, (3) fixed dimensionality hampering transferability and requiring linear growth of parameters with more classes, and (4) struggling with class imbalance. 

Recent works have proposed non-parametric classifier alternatives to address these issues, including using fixed equiangular tight frames (ETFs) or prototype summarization. However, ETFs force equal inter-class similarities and have dimensionality requirements, while prototype summarization overlooks metric space exploitation.

Proposed Solution:
The paper proposes a novel framework with fixed, equidistributed prototypes but dynamic label-to-prototype assignment that changes during training. Specifically:

1) Equidistributed prototypes are obtained before training using an objective based on the Gaussian potential kernel for optimal hypersphere coverage. The prototypes remain fixed during training to maintain inter-class separation.

2) A bipartite matching step assigns class labels to prototypes by maximizing likelihood of observations.

3) An input-prototype mapping loss aligns features to assigned prototypes for intra-class compactness.

The method alternates between steps 2 and 3 during training.

Main Contributions:

- Novel classification framework with fixed prototypes but dynamic label-to-prototype assignment during training
- Formulation as two-step optimization problem over assignment and network parameters
- Solving optimization using bipartite matching and gradient descent
- State-of-the-art performance on CIFAR and ImageNet benchmarks, especially for fewer dimensions
- Applicability to both balanced and imbalanced datasets
- Overcoming limitations of prior fixed classifier methods like ETF constraints

The key insight is that optimizing assignment is crucial when prototypes are fixed for capturing inter-class relationships and metric space exploitation.
