# [Learning with Imbalanced Noisy Data by Preventing Bias in Sample   Selection](https://arxiv.org/abs/2402.11242)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Learning with noisy labels is challenging as inevitable imperfect labels in real-world datasets can substantially hurt model performance. Recent methods typically regard low-loss samples as clean ones and discard high-loss samples. However, real-world datasets contain not only noisy labels but also class imbalance, where minority classes have far fewer training samples. This imbalance issue causes failure for loss-based sample selection, as under-learning of minority classes also produces high losses. Existing methods fail when simultaneously handling noisy labels and class imbalance.

Proposed Solution:
The paper proposes a simple yet effective method to address noisy labels in imbalanced datasets, with the following key components:

1) Class-Balance-based Sample Selection (CBS): Divides training set into clean and noisy subsets per class rather than globally. Ensures minority classes are sufficiently selected, preventing them from being wrongly discarded as noisy samples.  

2) Confidence-based Sample Augmentation (CSA): Further enhances reliability of selected clean samples by fusing sample pairs based on prediction confidence.

3) Label Correction: Corrects labels of noisy samples using exponential moving average of predictions over training epochs. Introduces Average Confidence Margin (ACM) to measure quality of corrected labels and filter unreliable ones.

4) Consistency Regularization: Imposes consistency between different augmented views and training epochs on filtered label-corrected noisy samples to further improve model robustness.

Main Contributions:
- Proposes class-balanced sample selection to prevent biased selection against minority classes when simultaneously handling label noise and class imbalance.

- Introduces confidence-based sample augmentation and average confidence margin for reliably exploiting selected clean and corrected noisy samples.

- Achieves superior performance over state-of-the-art methods on both synthetic and real-world noisy and imbalanced datasets.

The key novelty lies in explicitly tackling the класс imbalance to prevent it from interfering with handling noisy labels, through balanced sample selection and reliability enhancement techniques. Both label noise and imbalance issues are effectively addressed.
