# [Contrastive Unsupervised Learning of World Model with Invariant Causal   Features](https://arxiv.org/abs/2209.14932)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Reinforcement learning (RL) agents need to learn reusable representations of the environment state in order to generalize well to new situations. Model-based RL methods that explicitly learn a model of the environment have the potential to learn better representations than model-free methods. However, existing model-based methods have difficulties learning representations that capture the causal, invariant structure of the environment. They also struggle with out-of-distribution generalization and sim-to-real transfer.

Proposed Solution:
This paper proposes a "World Model with invariant Causal features" (WMC) that uses contrastive unsupervised learning to extract causal, invariant features from observations. The key ideas are:

1) Use data augmentation during training as a source of "interventions" to encourage the model to learn invariant representations. Different augmented views of the same observation are treated as positive pairs.

2) Reconstruction of depth images is used as an auxiliary task since depth captures geometry and is invariant to texture/color augmentations. This helps prevent the contrastive loss from collapsing when the world model is trained separately from the control policy. 

3) The world model is based on DreamerV2, with added contrastive loss and depth prediction. It consists of an RSSM-based memory module and a control module.

Main Contributions:

1) Demonstrates that contrastive learning can improve model-based RL by encouraging causal feature learning.

2) Proposes a specific network architecture and training process (WMC) that enables effective use of contrastive learning for model-based RL. Key aspects are the use of data augmentation for invariance and depth prediction to support contrastive learning.

3) Shows state-of-the-art performance on navigation tasks from the iGibson dataset, with improved out-of-distribution generalization and sim-to-real transfer over other model-free and model-based approaches.

4) Provides ablation studies validating the importance of different components of WMC, especially contrastive loss and depth prediction, for achieving strong performance.

In summary, the paper presents a novel way to integrate contrastive unsupervised learning with model-based RL to learn invariant causal representations for improved generalization. The benefits are demonstrated through extensive experiments on visually complex navigation environments.
