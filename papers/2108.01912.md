# Internal Video Inpainting by Implicit Long-range Propagation

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we perform video inpainting by implicitly propagating information from known regions to unknown regions, without relying on external optical flow estimation? The key hypothesis is that by training a convolutional neural network on the test video to overfit the known regions, it can learn to fill in the missing regions based on implicit propagation of information over time, rather than needing explicit optical flow guidance.In more detail:- The paper proposes a novel internal learning approach for video inpainting, where a CNN is trained directly on the test video itself. - This avoids issues with external training on large datasets, which can suffer from domain gap problems when applied to new test videos.- It also avoids reliance on estimated optical flow to explicitly propagate information between frames, which can fail for large masks, slight motions, or incorrect frame selection.- Instead, the paper hypothesizes that by overfitting the CNN to the known regions in the test video, the network can learn to implicitly propagate information from known to unknown regions based on inherent spatio-temporal correlations in natural videos.- This implicit propagation is enabled by properties of CNNs like weight sharing and translational equivalence of convolutions.- The method is enhanced with regularization terms to handle challenging cases like ambiguity and deficiency in the video.So in summary, the main research question is whether video inpainting can be achieved through implicit learning and propagation in an internal training framework, without optical flow guidance. And the results aim to demonstrate this hypothesis and approach.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing a novel internal learning framework for video inpainting that implicitly propagates information from known regions to unknown regions without needing explicit optical flow estimation. - Designing two regularization terms - an anti-ambiguity term and a gradient regularization term - to handle challenging cases like ambiguous backgrounds or long-term occlusion where cross-frame information is unavailable or ambiguous.- Demonstrating state-of-the-art inpainting performance on the DAVIS dataset both quantitatively and qualitatively. The results of a user study also indicate the method is preferred.- Showing the flexibility of the approach by extending it to inpainting with only a single frame mask and very high resolution (4K) video inpainting.In summary, the key novelty seems to be in formulating video inpainting as an internal learning problem and propagating information implicitly over time without optical flow, made robust by the regularization terms. The experiments validate the effectiveness of this approach and show how it can be extended to more challenging settings.
