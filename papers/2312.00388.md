# [LinguaLinked: A Distributed Large Language Model Inference System for   Mobile Devices](https://arxiv.org/abs/2312.00388)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper introduces LinguaLinked, a novel system for enabling decentralized and distributed inference of large language models (LLMs) across multiple mobile devices. The key innovation is segmenting a large LLM into smaller partitions that align with the memory and computational constraints of individual mobile devices. An optimized model assignment strategy employs linear optimization to allocate model segments to devices based on their heterogeneous capabilities. LinguaLinked also implements a runtime load balancer to dynamically redistribute tasks and prevent bottlenecks. Additionally, an optimized communication mechanism coordinates structured data flow between model segments using transmission maps while maintaining model integrity. Evaluations demonstrate LinguaLinked facilitates efficient distributed execution for both quantized and full-precision LLMs, with up to 2.65x acceleration over the baseline. The system is especially effective for larger models and offers particular benefits in terms of enhanced privacy from on-device processing, reduced reliance on server computation, lower latency through localized inference, and flexibility across mobile platforms. LinguaLinked represents an important advancement in deploying complex LLMs on resource-constrained mobile devices.
