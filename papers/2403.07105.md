# [A slice classification neural network for automated classification of   axial PET/CT slices from a multi-centric lymphoma dataset](https://arxiv.org/abs/2403.07105)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Manual segmentation of tumors from whole-body PET/CT images is time-consuming and operator-dependent. Automated slice classification can help direct physicians' attention to important slices.
- Prior work trained a slice classifier on a small uni-centric dataset. This work aims to train and validate a classifier on a larger multi-centric dataset.

Methods:
- Lymphoma PET/CT images were collected from 246 patients from Vancouver (BCCV) and 220 patients from Seoul (SMHS). Tumors were annotated by nuclear medicine physicians.
- Axial slices were labeled as positive (containing tumor) or negative (no tumor). Class imbalance was 8:92% for BCCV and 21:79% for SMHS.  
- A ResNet-18 network was trained for binary slice classification. Data was split either by slices (slice-level) or patients (patient-level) into train and test sets.
- Models were trained in a center-aware (CAW) manner on BCCV or center-agnostic (CAG) manner on both centers. Inputs contained either only PET or PET+CT slices.

Key Results:
- Slice-level splitting causes performance overestimation due to lack of independence between train and test slices. Patient-level splitting is better.
- Including SMHS data in CAG training improves generalization over CAW training.
- PET+CT inputs did not improve performance over PET alone.
- Models achieve high specificity, but sensitivity depends on tumor SUVmax.

Main Contributions:
- Demonstrated importance of patient-level split for valid evaluation of slice classifiers.
- Showed that multi-centric datasets require center-agnostic training for better generalization.
- Analyzed dependence of classification performance on tumor SUVmax.
- Provided guidelines for training generalized lymphoma slice classifiers.

In summary, the key novelty of this work is studying slice classification on a multi-centric dataset and analyzing different data splitting and training strategies to improve generalization of classifiers. The analysis of classification performance vs. tumor SUVmax is also an important contribution.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The paper trains and compares deep learning models for classifying lymphoma PET/CT image slices as tumor-containing (positive) or non-tumor (negative), demonstrating performance overestimation issues with slice-level splits of patient data and the importance of tumor SUVmax values for correctly classifying positive slices.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1) Training and evaluation of a deep learning-based binary classification network for automatically classifying axial PET/CT slices into tumor-containing (positive) slices and non-tumor (negative) slices. The models are trained and tested on multi-centric lymphoma datasets from two institutions.

2) Investigation into different data splitting strategies (slice-level vs patient-level) for model training, showing that patient-level splitting prevents performance overestimation compared to slice-level splitting.

3) Evaluation of two training strategies - center-aware (CAW) and center-agnostic (CAG) - demonstrating the importance of including data from multiple centers in the training set to improve model generalization. 

4) Analysis showing that the inclusion of CT slices along with PET provided no significant boost in classification performance.

5) Detailed analysis of model performance and sensitivity as a function of tumor SUVmax, indicating slices with higher tumor uptake are more likely to be correctly classified.

In summary, the key contribution is a rigorous evaluation methodology and analysis for binary classification of PET/CT slices using multi-centric datasets, providing insights into data splitting, multi-center training, and performance dependence on tumor uptake.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key keywords and terms associated with this paper include:

- Lymphoma
- $^{18}$F-FDG PET/CT
- Binary classification
- ResNet-18
- Focal loss
- Center-aware training
- Center-agnostic training
- SUVmax
- Slice classification
- Tumor detection and segmentation
- Multi-centric dataset
- Model generalization
- Patient-level split
- Slice-level split 
- Sensitivity analysis

The paper trains and evaluates different binary classifiers on PET/CT slices from a multi-centric lymphoma dataset. Key aspects explored include data splitting strategies for model generalization, use of PET vs PET+CT as inputs, center-aware vs center-agnostic training, and analysis of classification performance on positive slices. Overall, the paper demonstrates methods to train and evaluate slice classification networks for lymphoma tumor detection on multi-institutional datasets.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. The paper describes two types of data splitting for model generalization: slice-level split and patient-level split. Can you explain in more detail the difference between these two splitting strategies and why patient-level splitting leads to better model generalization? 

2. The paper proposes two training strategies: center-aware (CAW) training and center-agnostic (CAG) training. What is the key difference between these strategies and why does CAG training result in better performance on the external test set compared to CAW?

3. Figure 1 shows two types of inputs used for network training. What are these input types and why does using PET/CT slices not provide improved classification performance compared to just using repeated PET slices?

4. In Section 3.1, the paper states "the AUPRC metric is more important than AUROC" for imbalanced datasets. Can you explain why AUPRC is a better metric for evaluating performance on imbalanced data? 

5. The sensitivity analysis in Section 3.3 shows higher sensitivity for slices with higher tumor SUVmax values. Provide some hypotheses explaining why it is easier for the network to correctly classify positive slices with higher SUVmax.

6. The CT slice intensity values are clipped to the range [-1024, 1024] HU based on the statement that values above 1000 HU correspond to bones/calcium. Justify whether this is an appropriate clipping range or if a different range should be used.

7. The maximum PET voxel value is capped at 50 prior to normalization based on the maximum tumor value being around 48. Explain the rationale behind capping the PET values in this manner.

8. In the context of the sensitivity analysis, explain whether it would be meaningful to do a similar analysis on the negative slices by computing maximum non-tumorous SUV.

9. The effects of different PET reconstruction algorithms between centers was not considered. Propose an analysis methodology to determine the effects of reconstruction differences on classification performance.  

10. The inclusion of CT slices did not improve performance - discuss at least 3 potential reasons explaining why CT did not provide useful additional information to the network.
