# [Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection](https://arxiv.org/abs/2303.05892)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to design an object detector that can detect objects from both base and novel categories in an open-vocabulary setting. Specifically, the paper aims to improve upon existing knowledge distillation-based open-vocabulary detection methods by addressing two key limitations:1. Dilemma between comprehensiveness and purity during knowledge extraction. Existing methods use fixed cropping strategies when extracting knowledge about object proposals from the teacher model, leading to incomplete or noisy representations. 2. Missing global scene understanding during knowledge transfer. Existing methods only transfer object-level knowledge from the teacher to the student detector, neglecting inter-object relationships and scene context.To address these limitations, the paper proposes an Object-Aware Distillation Pyramid (OADP) framework comprising:1. An Object-Aware Knowledge Extraction (OAKE) module that adaptively transforms object proposals and selectively attends to them using a masked attention mechanism in the teacher model. This results in more complete and precise object knowledge extraction.2. A Distillation Pyramid (DP) mechanism with global, block, and object distillation modules to transfer hierarchical knowledge from the teacher to the student for comprehensive scene understanding.The central hypothesis is that addressing these limitations in knowledge extraction and transfer will allow the proposed OADP model to better detect both base and novel objects compared to prior open-vocabulary detection methods. Experiments on COCO and LVIS datasets validate this hypothesis.
