# [RESSA: Repair Sparse Vision-Language Models via Sparse Cross-Modality   Adaptation](https://arxiv.org/abs/2404.02424)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Vision-language models (VLMs) are powerful but their large scale poses challenges for real-world deployment. 
- Pruning followed by finetuning can reduce model size while preserving performance, but applying this to VLMs is relatively unexplored. 
- Key questions are: how to distribute sparsity across vision/language models, and how to repair performance of sparse VLMs.

Methodology:
- Conducted empirical studies on modality-specific sparsity distributions. Found pruning vision/language models with equal ratios optimal.  
- Propose RESSA to repair sparse VLMs via cross-modality adaptation and SparseLoRA finetuning. Defines objectives of improving task performance and minimizing divergence from original dense model.
- Introduce SparseLoRA to apply sparsity to LoRA weights, enabling integration with sparse models without disrupting sparsity.

Contributions:
- Empirical analysis of sparsity distribution across modalities and impact on VLM performance.
- RESSA approach to effectively repair pruned sparse VLMs using cross-modality finetuning and SparseLoRA.
- Extensive experiments validate RESSA, improving performance significantly. E.g. 11.3% boost under 2:4 sparsity and 47.6% enhancement with 70% sparsity.

In summary, the paper studies model pruning for VLMs, finding equal sparsity ratios optimal across modalities. The proposed RESSA method leverages cross-modality adaptation and SparseLoRA to successfully repair the performance of pruned sparse VLMs.
