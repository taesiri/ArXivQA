# [HEAM : Hashed Embedding Acceleration using Processing-In-Memory](https://arxiv.org/abs/2402.04032)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Recommendation systems rely heavily on embedding operations, which exhibit irregular memory access patterns and are very memory-bound. As models grow larger, embedding tables now exceed tens of terabytes, causing major challenges for efficient inference on single nodes.

- Using compositional embedding to reduce embedding table sizes further exacerbates the memory bottleneck issue, as it requires accessing two tables (quotient and remainder) to reconstruct embeddings. This doubles the memory accesses compared to the original model.

Proposed Solution:
- The paper proposes HEAM, a heterogeneous memory architecture with a 3-level PIM system designed specifically to accelerate compositional embedding for recommendation systems. 

- It consists of a DIMM-HBM combination, where HBM features a base die-level PIM (bd-PIM) and bank group-level PIMs (bg-PIMs). Bg-PIMs additionally contain Lookup Tables (LUTs) to store the small remainder tables.

- The quotient table is split between DIMM and HBM based on access frequency distribution to maximize bandwidth. The remainder table is entirely stored in the LUTs inside bg-PIMs.

- Two-stage partial embeddings additions are performed hierarchically using the bd-PIM and bg-PIMs to reduce memory traffic. LUT access in bg-PIMs also decreases bank traffic.

Main Contributions:

- First architecture specifically targeting large compositional embedding models for inference acceleration. Addresses both model size and memory bottleneck issues.

- Introduces optimized allocation strategy to store quotient and remainder tables in the most bandwidth-efficient manner based on their distinct characteristics.

- Specially designed 2-level HBM-PIM system with LUTs in bg-PIMs to best leverage properties of compositional embedding and maximize memory parallelism.

- Achieves 6.3x speedup and 58.9% energy savings over state-of-the-art DIMM-PIM baselines. Enables efficient deployment of large models on single nodes.

The summary covers the key problem being addressed, the proposed heterogeneous memory and PIM architecture along with the specialized optimization techniques for compositional embedding, and the main contributions related to performance, energy efficiency and model size support.
