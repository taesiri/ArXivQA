# [Mutation is all you need](https://arxiv.org/abs/2107.07343)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:What are the main components that contribute to the strong performance of the BANANAS neural architecture search method on large cell-based search spaces like DARTS?The authors hypothesize that for large search spaces like DARTS, the performance of BANANAS is mainly determined by its choice of acquisition function optimizer, which does local optimization of architectures, rather than other components like the architecture encoding, surrogate model, or acquisition function. To test this hypothesis, the authors conduct experiments varying different BANANAS components in a factorial manner and evaluate the performance on the NAS-Bench-301 benchmark. The results suggest that the acquisition function optimizer, which minimally mutates the best architecture so far, is the most important factor for BANANAS' performance, rather than the other components.In summary, the central research question is about identifying the key factors behind BANANAS' effectiveness for large neural architecture search spaces, with a hypothesis focused on the role of the acquisition function optimizer. The experiments aim to test this hypothesis.
