# Template Filling for Controllable Commonsense Reasoning

## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper are:1. Proposing the task of template commonsense reasoning (TemplateCSR), where commonsense reasoning is achieved by filling slots in templates rather than selecting from a fixed set of answers. This allows for more control and flexibility compared to existing commonsense reasoning tasks. 2. Introducing a dataset of commonsense reasoning templates and corresponding expansions for the TemplateCSR task. The dataset contains around 3600 unique template-expansion pairs collected from diverse sources.3. Presenting POTTER, a model that formulates TemplateCSR as a prompt-tuning task for pretrained language models. Given a template, POTTER generates an expanded sentence filling in the slots. The slots are specified via prompts that indicate the abstraction for that slot. 4. Evaluating POTTER on the TemplateCSR dataset. Experiments show POTTER outperforms baselines on generation metrics like ROUGE and BERTScore as well as on factuality metrics like FACTCC.5. Providing analysis on the types of errors made by POTTER, giving insights into the challenges of commonsense reasoning for language models.In summary, the main contribution is proposing the TemplateCSR task and dataset to allow for more controllable commonsense reasoning, along with presenting POTTER as a strong baseline model for this new task. The analysis also surfaces challenges language models still face in reliably performing multi-hop commonsense reasoning.


## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we enable large language models to perform controlled and explainable commonsense reasoning through a template filling approach?The key hypothesis appears to be:By formulating commonsense reasoning as a template filling task and training language models to complete reasoning templates, we can achieve more controllable and explainable commonsense reasoning compared to existing approaches.Specifically, the paper proposes an approach called "Template Commonsense Reasoning" (TemplateCSR) which involves creating reasoning templates with slots for concepts, qualifiers, and explanations. The authors hypothesize that by training language models to complete these templates in a prompt-based manner, the models can learn to perform multi-hop reasoning while allowing for more control over the reasoning process compared to selecting answers from a fixed set or knowledge base. To evaluate this, the authors create a new dataset of commonsense reasoning templates and expansions, introduce a model called POTTER that is trained to fill these templates, and demonstrate through experiments that their approach outperforms baselines in terms of generation quality and factuality.In summary, the central research question is how to achieve more controllable and explainable commonsense reasoning through a template filling approach with language models. The key hypothesis is that their proposed TemplateCSR method will enable better reasoning capabilities than existing approaches. The experiments aim to validate whether their approach does indeed improve performance on this challenging reasoning task.
