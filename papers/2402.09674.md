# [PAL: Proxy-Guided Black-Box Attack on Large Language Models](https://arxiv.org/abs/2402.09674)

## Summarize the paper in one sentence.

 The paper introduces Proxy-Guided Attack on LLMs (PAL), the first practical token-level optimization attack against real-world LLM APIs, which uses gradients from an open-source proxy model to guide the attack and a new loss function designed for commercial APIs.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a new black-box attack called Proxy-Guided Attack on LLMs (PAL). PAL is the first practical token-level optimization attack against real-world LLM APIs. It overcomes two key challenges:

1) Attacker's budget: PAL uses a surrogate model to guide the optimization and minimize queries to the target LLM API. This significantly reduces the cost compared to prior attacks.

2) Loss computation: PAL introduces techniques to compute the loss through commercial APIs that only provide limited information like top-k log probabilities. This includes a logit bias trick and a heuristic to rank candidates.

The paper shows that PAL achieves high attack success rates against LLMs like GPT-3.5 and Llama while costing less than $1 on average per attack. The techniques enable more comprehensive safety testing of proprietary LLMs. The paper also proposes an improved white-box attack called GCG++ and a simple but strong black-box baseline attack called RAL.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper introduces a new attack called Proxy-Guided Attack on LLMs (PAL). Can you explain in detail how PAL works and what are the key steps? 

2. One key component of PAL is the use of a proxy model to guide the optimization process. What is the rationale behind using a proxy model and how does it help overcome the challenges of attacking black-box APIs?

3. The paper proposes a technique to compute loss functions for real-world LLM APIs using a logit bias trick. Can you walk through the mathematical derivation of how this trick allows inferring the log probabilities?

4. PAL uses a heuristic to rank candidate suffixes and reduce query cost. What is the intuition behind this heuristic? Does it have any theoretical guarantees or is it more of an empirical finding? 

5. The paper shows PAL successfully jailbreaks models like GPT-3.5 even without fine-tuning the proxy model. What implications does this attack transferability have on defending against such optimization attacks?

6. For the white-box GCG++ attack, what modifications result in the large improvement over the original GCG attack? Can you analyze the effect of each change quantitatively?

7. The paper finds that the choice of target string has a huge impact on attack success rate. Is there a principled way to select the optimal target string? Or is this an open research question?

8. One interesting result is that random search (RAL) actually performs quite well. Why might simplistic random search be an effective baseline or heuristic in this setting?

9. The format-aware target string is crucial for attacking a model like Llama. What implications does this insight have on the generalizability of alignments based on formatting?

10. Are there any obvious defenses that can prevent such optimization-based attacks? What are some challenges or limitations around defending against jailbreaking of LLMs?
