# [TimeChat: A Time-sensitive Multimodal Large Language Model for Long   Video Understanding](https://arxiv.org/abs/2312.02051)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the paper:

This paper proposes TimeChat, a time-sensitive multimodal large language model designed for long video understanding. The key contributions include: (1) A timestamp-aware frame encoder that binds visual content with the timestamp of each frame to enhance time-vision association. (2) A sliding video Q-Former that produces a video token sequence of varying lengths to handle videos of different durations, preserving more semantics. (3) A new instruction tuning dataset called TimeIT encompassing 6 tasks and 125K examples to boost the model's instruction following ability. Experiments demonstrate TimeChat's strong capabilities in temporal localization and reasoning. For instance, it achieves substantially higher performance in dense video captioning on YouCook2 (+9.2 F1), temporal grounding on Charades-STA (+27.5 R@1 IoU=0.5), and highlight detection on QVHighlights (+5.8 HIT@1), compared to previous video LLMs. The results validate TimeChat's potential as a versatile video assistant that can summarize events, pinpoint timestamps, and detect highlights in long videos based on user queries.
