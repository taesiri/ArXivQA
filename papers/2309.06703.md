# [VLSlice: Interactive Vision-and-Language Slice Discovery](https://arxiv.org/abs/2309.06703)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be: How can we develop an interactive system to enable user-guided discovery of coherent visiolinguistic subgroups (slices) with consistent behavior from unlabeled image sets, in order to analyze vision-and-language models?The key components of this question are:- Developing an interactive system for slice discovery- Enabling user-guided exploration and refinement of slices - Discovering coherent visiolinguistic slices from unlabeled image sets- Analyzing the behavior of vision-and-language models on the discovered slicesThe authors propose an interactive system called VLSlice to address this question. The goal is to help users discover meaningful and coherent slices to study potential biases in vision-and-language models, without requiring extensive labeled datasets. The system allows interactive query specification, exploration of visual-linguistic clusters, gathering additional samples to refine slices, and validating model behavior on the final slices.In summary, the central research question is focused on developing an interactive tool (VLSlice) to enable discovery and analysis of coherent visiolinguistic slices from unlabeled images, in order to study vision-and-language models. The key hypothesis is that this approach can help identify potential biases without requiring extensive labeling.


## What is the main contribution of this paper?

Based on my reading of the paper abstract, the main contribution seems to be an interactive system called VLSlice that enables user-guided discovery of coherent representation-level subgroups (called "vision-language slices") with consistent visiolinguistic behavior from unlabeled image sets. The paper presents both qualitative and quantitative results from a user study showing that VLSlice allows users to quickly generate diverse, high-coherency slices. The VLSlice system and methodology aims to improve the workflow of analyzing vision-and-language models for biases, compared to current practices that require extensive manual annotation.
