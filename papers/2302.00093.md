# Large Language Models Can Be Easily Distracted by Irrelevant Context

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research questions/hypotheses appear to be:1. How distractible are large language models when presented with irrelevant context in addition to relevant information for a task? Specifically, how much does adding irrelevant context to arithmetic reasoning problems degrade the performance of various prompting techniques for large language models?2. What strategies can be used to mitigate the distractibility of large language models and improve their robustness to irrelevant context? The paper investigates approaches like self-consistency, adding irrelevant context to prompt examples, and providing explicit instructions to ignore irrelevant information. 3. What factors of the irrelevant context affect the distractibility of large language models the most? The paper analyzes how different types of irrelevant sentences (in-topic vs off-topic, overlapping roles vs non-overlapping roles, in-range vs out-of-range numbers) impact model performance.In summary, the central focus is evaluating the distractibility of large language models when faced with a mix of relevant and irrelevant information, and exploring techniques to improve their robustness in handling irrelevant context. The introduction of the Grade-School Math with Irrelevant Context (GSM-IC) dataset provides a way to systematically measure distractibility on arithmetic reasoning problems.


## What is the main contribution of this paper?

The main contribution of this paper is introducing a new benchmark dataset called Grade-School Math with Irrelevant Context (GSM-IC) to measure the distractibility of large language models when performing arithmetic reasoning. The key points are:- GSM-IC is constructed by adding irrelevant sentences to existing grade-school math problems that are solvable by LLMs. This allows evaluating how irrelevant information in the input affects the model's ability to solve problems.- The authors comprehensively evaluate various state-of-the-art prompting techniques like chain-of-thought prompting, program prompting, etc. on GSM-IC. They find all techniques show significantly degraded performance compared to the original clean datasets, demonstrating LLMs are easily distracted by irrelevant context.- The paper investigates methods to mitigate this weakness, such as using self-consistency, adding irrelevant information to prompt exemplars, and instructing models to ignore irrelevant information. These approaches are shown to improve robustness to irrelevant context to varying degrees. - Detailed analysis is provided on how different types of irrelevant information (in-topic vs off-topic, role name overlap, number range) affect model performance. Factors leading to greater distractibility are identified.In summary, the key contribution is rigorous benchmarking and analysis of LLM distractibility on arithmetic reasoning, and recommendations on training strategies to improve robustness. The authors highlight dealing with irrelevant information as an important direction for future LLM research.
