# [Towards a Unified Language Model for Knowledge-Intensive Tasks Utilizing   External Corpus](https://arxiv.org/abs/2402.01176)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Towards a Unified Language Model for Knowledge-Intensive Tasks Utilizing External Corpus":

Problem:
Large language models (LLMs) often face the problem of hallucination, where the generated text contains false information. This issue is particularly severe in knowledge-intensive (KI) tasks that require accessing external knowledge sources. To address this, retrieval-augmented generation (RAG) has emerged as a popular solution, where a retriever obtains relevant contexts from a corpus to augment a generator. However, traditional retrieval models rely on large indexes, incurring high computational costs. Also, the disjoint training of retriever and generator models hinders joint optimization.  

Proposed Solution:
This paper proposes CorpusLM, a unified language model that integrates generative retrieval, closed-book generation, and RAG to handle KI tasks. It employs generative retrieval to retrieve relevant documents by decoding document identifiers (DocIDs). To facilitate effective retrieval and RAG, tailored strategies are proposed:
(1) A ranking-oriented DocID list generation strategy that improves ranking capability by learning from a list of ranked DocIDs.
(2) A continuous RAG strategy that first decodes DocIDs, then references from documents, and finally the answer.
(3) Auxiliary DocID understanding tasks that enhance comprehension of DocIDs.

Main Contributions:
(1) A unified language model capable of performing generative retrieval, closed-book generation and RAG within the same framework.
(2) A ranking-oriented DocID list generation strategy that enhances the ranking quality. 
(3) An efficient continuous RAG strategy that decodes DocIDs, references and answers sequentially.
(4) Unsupervised DocID understanding tasks that improve the model's comprehension of DocIDs.

Experiments on the KILT benchmark showcase CorpusLM's superior performance on both retrieval and downstream tasks compared to state-of-the-art models. The unified model is more computationally efficient than existing RAG methods.
