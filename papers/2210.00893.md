# [Combining Efficient and Precise Sign Language Recognition: Good pose   estimation library is all you need](https://arxiv.org/abs/2210.00893)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is:How can we improve the accuracy of lightweight sign language recognition models aimed for real-world applications on consumer devices, without increasing their computational requirements?Specifically, the authors focus on boosting the performance of the SPOTER architecture, which is a relatively small and efficient pose-based model, while keeping its efficiency advantages over larger appearance-based models. Their main hypothesis is that simply swapping out the pose estimation library used in SPOTER can lead to significant accuracy improvements. They test this by replacing the original Vision API library with MediaPipe pose estimation.The overall goal is to develop a sign language recognition model that is accurate enough for real-world use cases but still small and fast enough to run on common hardware like smartphones. The authors aim to find a good balance between efficiency and accuracy.In summary, this paper explores whether a better pose estimation library can boost a lightweight sign language recognition model to achieve state-of-the-art accuracy, without increasing its computational demand. The central hypothesis is that the pose extraction module has a major influence on overall performance.


## What is the main contribution of this paper?

The main contribution of this paper is developing a sign language recognition model that achieves state-of-the-art accuracy while being lightweight and fast enough to deploy on consumer devices. Specifically, the authors build on the SPOTER architecture and show that simply by swapping out the pose estimation library from Vision API to MediaPipe, they can boost the accuracy on the WLASL100 dataset from 63.18% to 78.29%. This establishes a new state-of-the-art result with a model that has only half the parameters and is 11x faster compared to previous best methods.Additionally, the authors create the first publicly available online demo for sign language recognition that runs in the browser. This demonstrates the efficiency of their method and provides an accessible tool for translating sign language videos. In summary, the key contributions are:- Showing the impact of the pose estimation library on a pose-based sign language recognition model- Achieving SOTA accuracy on WLASL100 with a lightweight and fast model  - Creating an accessible online demo for sign language translationThe main impact is developing a highly accurate sign language recognition model that is efficient enough to deploy on consumer devices, helping to make this technology more accessible to the Deaf community.
