# [Learning the Distribution of Errors in Stereo Matching for Joint   Disparity and Uncertainty Estimation](https://arxiv.org/abs/2304.00152)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is: How can we jointly estimate disparity and uncertainty in a way that improves performance in both tasks? The key ideas and contributions are:- Proposing a novel loss function based on KL divergence between the distributions of disparity errors and predicted uncertainties. This forces the network to learn to predict uncertainties that match the actual error distribution.- Using a differentiable soft-histogramming technique to approximate the error and uncertainty distributions for computing the KL divergence loss.- Designing a lightweight uncertainty estimation subnetwork integrated with a stereo matching network (GwcNet) that takes intermediate disparity predictions as input. - Showing experimentally that the proposed approach (SEDNet) outperforms baselines in both disparity estimation and uncertainty prediction, demonstrating the benefits of joint training.So in summary, the paper presents a method for joint disparity and uncertainty estimation that leverages statistics of the errors to supervise the uncertainty prediction. The key innovation is the proposed loss function based on matching uncertainty and error distributions.


## What is the main contribution of this paper?

The main contributions of this paper are:1. A novel uncertainty estimation subnetwork that extracts information from the intermediate multi-resolution disparity maps generated by the disparity subnetwork.2. A differentiable soft-histogramming technique used to approximate the distributions of disparity errors and estimated uncertainties. 3. A loss based on KL divergence applied on histograms obtained with the above technique to match the distribution of uncertainties with the distribution of disparity errors.4. Extensive experiments showing that the proposed method, named SEDNet, outperforms baselines in both disparity estimation and uncertainty prediction on large datasets. The key idea is to require the distribution of predicted uncertainty values to match the distribution of disparity errors, so that uncertainty acts as a good predictor of the error magnitude. This is achieved by minimizing the KL divergence between the two distributions approximated via soft histogramming. The network architecture consists of a stereo matching subnetwork based on GwcNet plus a very small uncertainty estimation subnetwork. Experiments demonstrate that SEDNet improves disparity accuracy compared to just training GwcNet, while also providing accurate uncertainty maps.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper presents a novel deep learning method for joint disparity and uncertainty estimation in stereo matching that improves both tasks by matching the distribution of uncertainties to the distribution of disparity errors via a KL divergence loss term.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper compares to other research in stereo matching and uncertainty estimation:- It focuses on learning the distribution of errors for joint disparity and uncertainty estimation. Many prior works have focused just on confidence or uncertainty estimation given pre-computed disparity maps. Jointly learning disparity and uncertainty in an end-to-end manner is less common.- The proposed SEDNet architecture is lightweight and builds on top of an existing stereo matching network (GwcNet) by adding a small uncertainty estimation subnetwork. This is more efficient than approaches that train entirely separate networks for disparity and confidence/uncertainty. - A novel loss function based on KL divergence between the distributions of disparity errors and estimated uncertainties is introduced. This is a unique way to learn uncertainties that match the error distribution. Most prior works use standard losses like BCE for confidence or L1/L2 for uncertainty.- The KL divergence loss uses differentiable histogramming to approximate the error and uncertainty distributions. This histogramming technique is new and enables optimizing the KL loss.- Experiments demonstrate SEDNet achieves state-of-the-art performance on large datasets like Scene Flow, Virtual KITTI, and DrivingStereo. Many previous uncertainty estimation methods were only evaluated on smaller datasets. - The method generalizes well from synthetic to real data, outperforming baselines in cross-domain experiments. Robustness to domain shift is important for practical applications.Overall, the paper presents a novel end-to-end approach for learning uncertainties aligned with the true error distribution. The results demonstrate clear improvements over strong baselines in both disparity accuracy and uncertainty quality. The lightweight architecture and unique loss function are the key differentiators compared to related works.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors are:- Applying the approach to other pixel-wise regression tasks like semantic segmentation and depth estimation. The authors state they are confident the method will work well for other tasks with minor modifications.- Exploring other ways to match the distribution of uncertainty to the distribution of errors beyond KL divergence. The KL divergence loss they use is effective but there may be other valid options.- Investigating the effectiveness of the approach on real-world data spanning a wider range of conditions. The experiments focused on synthetic data and a limited real dataset. Testing on more diverse real data would be useful.- Evaluating the benefits of joint disparity and uncertainty estimation on higher level tasks. The authors mention the value of uncertainty for sensor fusion applications but do not demonstrate it. Showing improved performance on a downstream application would further validate the approach.- Developing enhanced uncertainty estimation modules, beyond the simple MLP used here. The small module works well already but more sophisticated architectures tailored for uncertainty prediction may further improve results.- Exploring Bayesian neural network implementations as an alternative to direct uncertainty regression. The authors chose a direct prediction method but BNNs are a popular approach in uncertainty research.- Combining empirical and predictive uncertainty estimation methods in a unified framework as has been done in other works. The current method is purely predictive.In summary, the authors propose further exploring the approach on other tasks, with other data, and using more advanced uncertainty estimation architectures and loss functions. They also suggest demonstrating the value on downstream applications and investigating Bayesian neural network approaches.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:This paper presents a new loss function for joint disparity and uncertainty estimation in deep stereo matching. The key idea is to require the distribution of predicted uncertainties to match the distribution of disparity errors, measured by their KL divergence. This is implemented via differentiable soft histogramming of the two distributions, which approximates them well enough to compute the KL loss. The loss is used to train a network called SEDNet that extends GwcNet with a small subnetwork to predict aleatoric uncertainty. Experiments on multiple datasets show SEDNet outperforms baselines in both disparity accuracy and quality of uncertainty estimation. The multi-task learning enabled by the joint loss leads to improved performance in the primary task of disparity estimation. Matching uncertainty to errors helps predict uncertainty better. The method could be applied to other pixel-wise regression tasks.
