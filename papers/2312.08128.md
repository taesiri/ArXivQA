# [Clockwork Diffusion: Efficient Generation With Model-Step Distillation](https://arxiv.org/abs/2312.08128)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed paragraph summarizing the key points of the paper:

This paper proposes a method called Clockwork Diffusion to improve the efficiency of text-to-image diffusion models. The key idea is to periodically reuse computation from previous denoising steps to approximate lower-resolution feature maps in subsequent steps, instead of running the full UNet model every time. This is based on the observation that lower-resolution UNet features mainly influence the semantic layout and are more robust to perturbations, making them amenable to approximation. Specifically, the method combines model distillation and step distillation by using a lightweight neural network adaptor conditioned on features from the previous step to predict the internal lower-resolution UNet features. Crucially, full UNet passes are interleaved with adaptor steps to avoid error accumulation. The adaptor uses an efficient architecture without attention, and is trained using unrolled sampling trajectories rather than noised images. Experiments on text-to-image generation and text-guided image editing demonstrate that this Clockwork Diffusion approach can greatly reduce computational complexity and latency, while maintaining comparable Fr√©chet Inception Distance, CLIP score, and visual quality. For example, for Stable Diffusion v1.5 it saves 32% FLOPs with negligible metric changes. Savings are complementary to other optimizations like distillation and efficient sampling, with consistent gains on top of an already optimized model.
