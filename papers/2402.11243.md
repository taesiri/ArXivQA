# [Can Large Language Models perform Relation-based Argument Mining?](https://arxiv.org/abs/2402.11243)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Argument mining (AM) is the process of automatically extracting arguments and relations between arguments from text. One key task is relation-based AM (RbAM) which focuses on identifying support and attack relations between arguments.  
- RbAM is challenging, with existing methods failing to perform satisfactorily across different datasets. There is a need for methods that can work well across datasets.

Proposed Solution:
- Use general-purpose large language models (LLMs), with appropriate priming and prompting, to perform RbAM.
- The method involves few-shot priming with 4 labelled examples, followed by prompting with a new argument pair to classify.
- Experiments are done with two LLM families - Llama 2 (13B and 70B parameter models) and Mistral (7B parameter model). Quantized 4-bit versions of the models are also tested.

Main Contributions:
- Show that the proposed LLM-based method significantly outperforms a RoBERTa baseline on the RbAM task over 10 datasets.
- The Llama 70B-4bit model achieved the best macro F1 score of 75%, surpassing all baselines. 
- The Mixtral 8x7B-4bit model achieved a macro F1 of 73%, close behind Llama 70B-4bit but with faster inference.
- Demonstrate the potential of using simple prompting strategies with LLMs for challenging NLP tasks like RbAM across diverse datasets.

The paper makes a strong case for using LLMs with priming and prompting for the RbAM task instead of fine-tuning approaches. The empirical evaluation over multiple datasets and models substantiates the proposed solution.


## Summarize the paper in one sentence.

 This paper shows that large language models, when appropriately primed and prompted, can significantly outperform existing methods for relation-based argument mining, which involves classifying relations between arguments as attack or support.


## What is the main contribution of this paper?

 The main contribution of this paper is showing that general-purpose large language models (LLMs), when appropriately primed and prompted, can significantly outperform the best performing RoBERTa-based baseline for the relation-based argument mining (RbAM) task. Specifically, the authors demonstrate empirically with two open-source LLMs (Llama-2 and Mistral) and ten datasets that their LLM-based method achieves higher performance than the state-of-the-art on the RbAM task.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper, some of the key terms and keywords associated with it include:

- Argument mining (AM)
- Relation-based argument mining (RbAM) 
- Support and attack relations
- Large language models (LLMs)
- Few-shot learning
- Priming and prompting 
- Llama 2 models
- Mistral models
- RoBERTa baseline
- 10 datasets for evaluation

The paper focuses on using LLMs for the task of RbAM, which involves classifying the support or attack relation between two arguments. It proposes an approach using priming and prompting of LLMs, and evaluates this on 10 existing RbAM datasets. The key findings are that the Llama 70B-4bit and Mixtral 8x7B-4bit LLMs, when appropriately primed and prompted, can outperform a RoBERTa baseline on the binary RbAM task across these datasets.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes using few-shot priming before prompting the LLMs for the RbAM task. What are the advantages and disadvantages of this approach compared to fine-tuning the LLMs?

2. The primer uses 4 labelled examples before prompting. How sensitive is the performance to the number of examples used? What is the tradeoff in using more or fewer examples?

3. The paper evaluates both standard and 4-bit quantized versions of the LLMs. What is the motivation behind evaluating quantized models? What are the tradeoffs introduced by quantization?

4. The authors experiment with chat-based LLMs like Llama and Mistral instead of more recent LLMs like PaLM. What could be the reasons behind this choice? What differences would you expect by using more recent LLMs?

5. The authors ignore relations other than attack and support when adapting some datasets to the binary RbAM task. What could be the effect of including the additional relations? Would the models need architecture changes to handle them?

6. The paper does not fine-tune any of the LLMs due to computational constraints. How could the results change if fine-tuning was feasible? What modifications would be needed to the method?

7. The authors use ten diverse datasets in the evaluation. What are the main challenges introduced by this diversity? How could the method be adapted to handle dataset biases better? 

8. The primer used for priming has a fixed structure with argument 1, argument 2 and the relation label. How sensitive is performance to changes in the primer structure and contents?

9. The authors measure only accuracy metrics and do not analyze the generated predictions qualitatively. What kind of qualitative analysis could provide more insights into the working of the models?

10. The paper focuses only on the binary classification setup for RbAM. How can the method be extended for the more complex ternary setup with 3 classes? What are the main challenges?
