# [The Unreasonable Ineffectiveness of the Deeper Layers](https://arxiv.org/abs/2403.17887)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) require significant compute resources for training and inference. Methods to improve their efficiency are needed.

- Specifically, the paper investigates layer pruning - removing layers from pretrained LLMs to reduce compute and memory while preserving performance. 

Method:
- Proposes a similarity-based layer pruning algorithm:
  - Remove blocks of layers where the input and output representations are most similar (have smallest angular distance).
  - Allows pruning of deeper layers with minimal damage.
  - After pruning, perform small amount of finetuning to "heal" model.
  
- Also evaluates simpler method of just removing deepest layers.

Results:
- Applies methods to prune large LLMs like Llama-2, Qwen and Mistral across a range of scales up to 70B parameters.

- Finds LLMs are robust to pruning up to 20-55% of layers, depending on model family and scale.
  - Larger/deeper models more robust to pruning.
  
- After threshold, performance sharply transitions to random guessing. Finetuning extends robust regime.
  
- Smooth loss curve on language modeling task, contrasting sharp QA accuracy transition.

- Similarity analysis shows deeper layers more redundant. Important to keep final layers.

- Simpler deepest layer pruning effective after finetuning, supporting idea that LLMs don't fully leverage deeper layers.

Main Contributions:
- Simple and effective layer pruning algorithm requiring only a single GPU.

- Combines with other efficiency methods like quantization and low-rank adapters.

- Reduces memory and FLOPs linearly with pruning fraction.

- Reveals sharp phase transition in QA performance indicating potential model overtraining.

- Provides evidence shallow layers may play critical role in storing knowledge.
