# [REFLECT: Summarizing Robot Experiences for Failure Explanation and   Correction](https://arxiv.org/abs/2306.15724)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we leverage large language models (LLMs) to generate explanations for robot failures and enable the robot to correct itself from those failures? The key hypothesis is that LLMs have strong reasoning and planning capabilities, so by converting robot sensory data into text summaries and prompts, the LLM can accurately explain failures in robot task executions and generate plans to correct those failures.Specifically, the research questions and hypotheses explored are:- Can a hierarchical multi-sensory summary of robot experiences be generated to support effective failure explanation by LLMs? The hypothesis is that both multi-modality and multiple levels of abstraction in the summary will improve failure explanation.- Can a progressive prompting strategy enable accurate failure localization and generate useful explanations from LLMs? The hypothesis is that first verifying subgoals and then prompting for detailed explanation only when a failure is detected will improve results.- Will the LLM-generated failure explanations allow successful correction planning? The hypothesis is that conditioning the replanning prompt on the failure explanation will result in more successful correction plans compared to replanning without explanation.- How does the LLM-based framework compare with alternatives like directly prompting the LLM with observations or using state-of-the-art vision captioning models? The hypothesis is that the proposed multi-sensory hierarchical summary and progressive prompting strategy will outperform these alternative approaches.In summary, the key research question is how to effectively transform robot experiences into a format that allows LLM-based failure explanation and correction, which serves as a promising approach to increase the explainability and robustness of robotic systems. The core hypotheses focus on the reasoning ability of LLMs and how to properly structure the prompts and summaries of robot data to enable that capability.


## What is the main contribution of this paper?

The main contribution of this paper is proposing REFLECT, a framework that leverages large language models (LLMs) to summarize robot experiences from multi-sensory data for failure explanation and correction. Specifically:- They introduce a hierarchical robot summary module that converts multimodal robot sensory data into a structured textual summary with different levels of abstraction. This includes a sensory-input summary, event-based summary, and subgoal-based summary.- They design a progressive failure explanation module that identifies failures by verifying subgoals, and then queries the LLM in a context-specific way to generate explanations for execution failures or planning failures. - They propose a failure correction planning module that leverages the LLM to generate a plan to address the failure and complete the task, conditioned on the generated failure explanation.- They create the RoboFail dataset containing 100 simulated and 30 real-world robot failure demonstrations to systematically evaluate the proposed framework. The dataset covers 8 categories of failure scenarios.- Through experiments on RoboFail, they demonstrate that the LLM-based REFLECT framework generates better failure explanations than baselines and ablations, accurately localizes failures, and successfully plans for failure correction around 80% of the time.In summary, the key contribution is an end-to-end framework that leverages the reasoning and planning abilities of LLMs to explain and correct robot failures based on multi-sensory experience summarization. The released dataset also encourages more research on explainable and robust robot systems.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper introduces REFLECT, a framework that leverages large language models to generate failure explanations and correction plans for robots by summarizing multimodal sensory data into a hierarchical textual summary.


## How does this paper compare to other research in the same field?

Here is a summary of how this paper compares to other research in the same field:The key contribution of this paper is proposing REFLECT, a framework that leverages large language models (LLMs) to summarize robot experiences from multimodal data for failure explanation and correction. This is a novel approach that utilizes the reasoning abilities of LLMs for robot failure analysis. In comparison, prior work on robot failure explanation has mostly focused on limited failure scenarios and hand-designed methods lacking generalizability. For example, Das et al. (2021) studied picking failures, Diehl et al. (2022) focused on two pick-and-place tasks, Song et al. (2022) studied navigation failures, while Inceoglu et al. (2021) looked at simple manipulation failures. The LLM-based REFLECT framework is more generalizable across diverse failure cases.For task planning with LLMs, REFLECT is among early works exploring the reflective abilities of LLMs on long-horizon robot tasks with real multimodal observation data and various failure modes. Related works like Raman et al. (2022) and Huang et al. (2022) assume ground truth environment feedback associated with individual actions, while REFLECT reasons directly on raw robot observations over extended executions.   The proposed multi-sensory hierarchical summary representation is also novel. Prior video/robot data summarization works like Wang et al. (2022) and Lynch & Sermanet (2020) produce flat summaries lacking hierarchical structure. The hierarchical summary in REFLECT better supports failure reasoning and environment context retrieval.In summary, REFLECT makes multiple contributions over prior work: 1) An LLM-based generalizable framework for robot failure explanation; 2) Extensive evaluation on a new RoboFail dataset with diverse failure scenarios; 3) A hierarchical multi-sensory data representation tailored for language-based robot failure reasoning. The framework and dataset open up new possibilities for building more explainable and robust robot systems.
