# Visual Instruction Tuning with Polite Flamingo

## What is the central research question or hypothesis that this paper addresses?

The key research question addressed in this paper is how to effectively use a diverse collection of annotated vision-language datasets to improve visual understanding capabilities of large language models, while preventing the raw annotations from negatively impacting the response style and politeness of the model. To address this, the paper proposes a new method to rewrite the raw annotations from vision-language datasets into more natural and polite responses. It trains a "Polite Flamingo" model as a multi-modal response rewriter, and applies it to convert a large collection of vision-language datasets into high-quality instructional data. This rewritten dataset "PF-1M" is then used to train the final multi-modal model "Clever Flamingo" via a novel U-shaped multi-stage tuning approach.The central hypothesis is that using the proposed annotation rewriting and multi-stage tuning methodology will allow the model to leverage diverse vision-language data to improve visual understanding, while avoiding the "multi-modal alignment tax" that typically degrades response quality when using raw annotations directly. Experiments verify improved performance on vision-language tasks along with higher human preference ratings.In summary, the key research question is how to utilize the richness of vision-language datasets for visual instruction tuning, while preventing the model from learning undesired annotation styles that reduce response politeness - and the proposed Polite Flamingo rewriting approach provides a solution.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method to mitigate the "multi-modal alignment tax" when using raw vision-language dataset annotations to train multi-modal language models. The key ideas are:1. Training a "Polite Flamingo" model to rewrite raw annotations into more natural and polite responses, by reconstructing original high-quality responses from distorted versions. 2. Applying Polite Flamingo to rewrite a large collection of vision-language dataset annotations and constructing a 1M dataset "PF-1M".3. Proposing techniques like U-shaped multi-stage tuning and multi-turn augmentation to efficiently train the multi-modal model "Clever Flamingo" using PF-1M, without sacrificing response quality.4. Comprehensive evaluation showing Clever Flamingo achieves strong performance in both multi-modal understanding and response politeness compared to other models.In summary, the main contribution is developing methods to take advantage of large vision-language datasets for multi-modal model training, while avoiding the common pitfall of degenerated response formatting. The Polite Flamingo rewriter and PF-1M dataset enable mitigating this "multi-modal alignment tax".
