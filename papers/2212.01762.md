# [Self-supervised AutoFlow](https://arxiv.org/abs/2212.01762)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How can we apply the AutoFlow approach for learning to render optical flow training data to real-world videos where ground truth flow is not available?

The key ideas and contributions to address this question are:

- Observing a strong correlation between ground truth flow errors (AEPE) and self-supervised losses on optical flow. This suggests self-supervised losses could be used as a proxy metric when ground truth is not available.

- Proposing Self-supervised AutoFlow which uses a self-supervised loss (photometric, smoothness, distillation) to optimize the rendered training data, instead of requiring ground truth flow.

- Showing Self-supervised AutoFlow achieves similar performance to supervised AutoFlow on Sintel and KITTI where ground truth is available. More importantly, it outperforms on real-world DAVIS data without ground truth.

- Further combining Self-supervised AutoFlow data with self-supervised fine-tuning on the target dataset for a fully self-supervised training pipeline.

- Demonstrating the self-supervised AutoFlow data provides a useful initialization for supervised training, achieving competitive performance to state-of-the-art methods.

In summary, the key hypothesis is that self-supervised losses can act as a proxy metric to enable the AutoFlow approach to work on unlabeled real-world videos, which is demonstrated through extensive experiments.
