# [Local Implicit Normalizing Flow for Arbitrary-Scale Image   Super-Resolution](https://arxiv.org/abs/2303.05156)

## What is the central research question or hypothesis that this paper addresses?

 This paper proposes a new framework called Local Implicit Normalizing Flow (LINF) for arbitrary-scale image super-resolution. The central hypothesis is that by combining a local implicit neural representation with a normalizing flow model, LINF can generate photo-realistic high-resolution images at arbitrary upsampling scales while achieving an optimal balance between fidelity and perceptual quality. 

Specifically, the key research questions/hypotheses addressed in this paper are:

1. Can a normalizing flow model be adapted to learn the distribution of local texture patches instead of full images for super-resolution? 

2. Can a local implicit neural representation provide the necessary conditioning for a normalizing flow model to enable arbitrary-scale upsampling?

3. Will modeling super-resolution as a distribution learning problem with normalizing flow allow LINF to generate more realistic textures compared to prior arbitrary-scale super-resolution methods?

4. Can LINF achieve a better balance between fidelity (PSNR) and perceptual quality (LPIPS) compared to prior flow-based and arbitrary-scale super-resolution methods?

5. Does a local patch-based approach provide computational and perceptual quality benefits over a per-pixel approach for texture modeling?

Through quantitative experiments and qualitative results, the paper aims to validate the proposed LINF framework as an effective approach to arbitrary-scale super-resolution that can generate realistic high-resolution images by learning texture patch distributions with normalizing flow.
