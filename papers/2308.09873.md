# [Skill Transformer: A Monolithic Policy for Mobile Manipulation](https://arxiv.org/abs/2308.09873)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we develop an end-to-end trainable policy that can perform long-horizon mobile manipulation tasks requiring both high-level reasoning/planning and low-level motor control?

The key hypothesis appears to be:

By combining conditional sequence modeling with a module that explicitly predicts skills, it is possible to learn a monolithic policy that retains the benefits of skill modularity while avoiding issues like hand-off errors between separate skills.

In particular, the paper proposes "Skill Transformer", an end-to-end trainable transformer-based policy architecture that contains both a "Skill Inference" module for high-level reasoning about which skill to execute, and an "Action Inference" module for low-level control conditioned on the predicted skill. The goal is to develop a policy that can sequence multiple distinct skills to accomplish long-horizon tasks like object rearrangement in novel environments.

So in summary, the main research question is how to develop an end-to-end policy for long-horizon multi-skill tasks, and the key hypothesis is that explicitly modeling skills within a monolithic policy can combine the benefits of skill modularity and end-to-end training. The Skill Transformer architecture embodies this hypothesis.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution appears to be proposing the Skill Transformer (ST) method, which is an end-to-end trainable transformer policy for multi-skill mobile manipulation tasks like object rearrangement. The key ideas of ST seem to be:

- Combining high-level skill selection and low-level action prediction in a single transformer-based policy architecture. This avoids having separate modular components for skills and sequencing.

- The policy consists of two main modules: a Skill Inference module that predicts which skill should be executed at each time step, and an Action Inference module that outputs low-level actions conditioned on the predicted skill. 

- Training the policy end-to-end using demonstrations that solve the full task. This allows learning long-horizon tasks composed of multiple skills in an integrated fashion, overcoming limitations of modular approaches.

- Achieving strong performance on a challenging "rearrange-hard" benchmark that requires variable-length planning and handling perturbations, outperforming various baseline methods including modular hierarchical approaches and end-to-end reinforcement learning.

In summary, the main contribution seems to be presenting a new monolithic policy architecture and training approach that can learn multiple skills and robustly sequence them together for complex mobile manipulation tasks, while retaining modularity through the high-level skill prediction.
