# [Skill Transformer: A Monolithic Policy for Mobile Manipulation](https://arxiv.org/abs/2308.09873)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be: 

How can we develop an end-to-end trainable policy that can perform long-horizon mobile manipulation tasks requiring both high-level reasoning/planning and low-level motor control?

The key hypothesis appears to be:

By combining conditional sequence modeling with a module that explicitly predicts skills, it is possible to learn a monolithic policy that retains the benefits of skill modularity while avoiding issues like hand-off errors between separate skills.

In particular, the paper proposes "Skill Transformer", an end-to-end trainable transformer-based policy architecture that contains both a "Skill Inference" module for high-level reasoning about which skill to execute, and an "Action Inference" module for low-level control conditioned on the predicted skill. The goal is to develop a policy that can sequence multiple distinct skills to accomplish long-horizon tasks like object rearrangement in novel environments.

So in summary, the main research question is how to develop an end-to-end policy for long-horizon multi-skill tasks, and the key hypothesis is that explicitly modeling skills within a monolithic policy can combine the benefits of skill modularity and end-to-end training. The Skill Transformer architecture embodies this hypothesis.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution appears to be proposing the Skill Transformer (ST) method, which is an end-to-end trainable transformer policy for multi-skill mobile manipulation tasks like object rearrangement. The key ideas of ST seem to be:

- Combining high-level skill selection and low-level action prediction in a single transformer-based policy architecture. This avoids having separate modular components for skills and sequencing.

- The policy consists of two main modules: a Skill Inference module that predicts which skill should be executed at each time step, and an Action Inference module that outputs low-level actions conditioned on the predicted skill. 

- Training the policy end-to-end using demonstrations that solve the full task. This allows learning long-horizon tasks composed of multiple skills in an integrated fashion, overcoming limitations of modular approaches.

- Achieving strong performance on a challenging "rearrange-hard" benchmark that requires variable-length planning and handling perturbations, outperforming various baseline methods including modular hierarchical approaches and end-to-end reinforcement learning.

In summary, the main contribution seems to be presenting a new monolithic policy architecture and training approach that can learn multiple skills and robustly sequence them together for complex mobile manipulation tasks, while retaining modularity through the high-level skill prediction.


## How does this paper compare to other research in the same field?

 Based on my reading, here are some key ways this paper compares to related work in mobile robotics and manipulation:

- This paper presents a method called Skill Transformer for mobile manipulation tasks like rearrangement. It combines end-to-end learning with some modularity through skill prediction. This differs from prior work that either learns completely end-to-end policies or relies on modular pipelines.

- Compared to modular approaches, Skill Transformer can adapt its plan online based on observations rather than following a fixed plan. This makes it more robust, as shown in the perturbation experiments. However, modular approaches may still be more interpretable and controllable.

- Unlike some end-to-end reinforcement learning methods, Skill Transformer is trained via imitation learning on human demonstrations. This allows it to solve longer horizon tasks that RL struggles with. The transformer architecture also helps it scale and generalize better than LSTMs.

- Relative to prior imitation learning work, Skill Transformer incorporates the auxiliary skill prediction loss during training. This improves the learning of distinct skills compared to methods like Decision Transformer.

- For mobile manipulation specifically, Skill Transformer demonstrates better generalization and more consistent performance on intricate mobile skills compared to behavioral cloning of modular skills. This highlights the benefits of end-to-end learning.

- Skill Transformer achieves state-of-the-art performance on complex rearrangement tasks in the Habitat platform. It also shows stronger resilience to perturbations compared to alternatives.

In summary, Skill Transformer aims to combine the strengths of end-to-end and modular approaches for mobile manipulation. The results demonstrate improved generalization, robustness and scalability over prior methods on challenging embodied AI tasks.
