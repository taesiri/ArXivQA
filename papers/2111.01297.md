# [Deep neural networks as nested dynamical systems](https://arxiv.org/abs/2111.01297)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is: how can we make the analogy between deep neural networks and brains/nervous systems more structurally precise, and what new insights does this provide? Specifically, the authors argue that the usual analogy made between artificial "neurons" in deep neural networks and biological neurons is flawed. They propose that a more accurate analogy is:- The "neurons" (nodes) in deep neural networks are more akin to synapses in the brain.- The wires connecting neurons in deep neural networks are more analogous to axons and dendrites of nerve cells in the brain. The authors then use category theory to make this revised analogy mathematically precise. This allows them to propose a new encompassing framework called "deeply interacting learning systems" (DILS) that combines strengths of deep neural networks and dynamical systems theory. The key benefits highlighted are:- DILS allows for peer-to-peer messaging between components, unlike standard deep neural networks. - DILS allows for dynamic rewiring of connections over time, enabling adaptation.- DILS unifies deep neural networks and control theory perspectives on dynamical systems.So in summary, the key research contribution is using category theory to refine the analogy between deep learning and neuroscience, which enables a proposed new class of adaptive, interacting dynamical systems for learning.


## What is the main contribution of this paper?

The main contribution of this paper is presenting a new perspective on deep neural networks by making an analogy with interacting dynamical systems. Specifically:- It points out an issue with the common analogy made between artificial neurons in DNNs and biological neurons, arguing this analogy is structurally flawed. - It proposes viewing DNNs as a special case of interacting dynamical systems with restricted interaction patterns, represented by interaction diagrams. - It notes that typical interacting dynamical systems have fixed wiring diagrams, while DNNs have dynamic rewiring through changing weights/biases. - It uses category theory to show these perspectives can be unified into a more general framework called deeply interacting learning systems (DILS), which allows both peer-to-peer messaging and dynamic rewiring.- This provides a corrected analogy between DNNs and brains, with artificial neurons corresponding to biological synapses rather than neurons.- It argues this DILS perspective combines strengths of DNNs (adaptivity) and dynamical systems (complex interactions), enabling new architectures and applications.In summary, the key contribution is providing a new categorical perspective to unify and generalize DNNs and dynamical systems, repairing the neuron analogy and enabling more advanced learning systems. The formalism of DILS is presented as a foundation for further research.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR of the paper:The paper argues that the usual analogy between artificial neurons in deep neural networks and nerve cells in brains is structurally flawed, and proposes a new encompassing mathematical framework called deeply interacting learning systems to better capture the complex, adaptive interactions found in both neural networks and brains.


## How does this paper compare to other research in the same field?

Here are a few key points about how this paper compares to other research on relating deep learning and neuroscience:- The main novelty is using category theory to formalize the analogy between deep neural networks (DNNs) and brains. This provides a precise framework for comparing the two, whereas most other work makes informal analogies. - It critiques the common analogy between artificial neurons in DNNs and biological neurons. The authors argue this analogy is structurally flawed, and propose viewing artificial neurons more like synapses instead.- It connects ideas from DNNs and control theory, viewing both as kinds of interacting dynamical systems. This perspective allows combining strengths of each - peer-to-peer communication and adaptivity.- The proposed deeply interacting learning systems (DILS) combine features of DNNs and control theory systems. DILS are more general and adaptive than either alone.- Overall, this paper takes a more mathematical approach than most work relating DNNs and neuroscience. The category theory perspective is unique and enables formalizing the analogies precisely.- Most other work focuses on things like comparing representations learned by DNNs to brain areas, analyzing DNN elements like depth or recurrent connections as brain-like, or using neuroscience inspiration for specific network architecture designs.So in summary, this paper provides a formal mathematical framework for comparing DNNs and brains, critiques the standard analogy, and proposes an encompassing model combining strengths of DNNs and control theory. The categorical perspective is novel compared to more informal analogies drawn by other works.
