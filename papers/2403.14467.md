# [Recourse for reclamation: Chatting with generative language models](https://arxiv.org/abs/2403.14467)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Toxicity scoring is commonly used to moderate generative language model (GLM) outputs, but can block pertinent information and inhibit language reclamation, especially for marginalized groups. 
- Platforms typically use opaque, one-way communication when flagging content as toxic, providing users little recourse.

Proposed Solution:
- The authors propose a novel mechanism for "algorithmic recourse" in GLMs, allowing users to override toxicity thresholds on specific phrases. 
- This maintains platform thresholds for legal risks, but gives users flexibility above that within their personal tolerances.
- The mechanism asks users two simple questions when a phrase is flagged: (1) if they want to see the flagged content, and (2) if they want it filtered in the future.

Main Contributions:
- Implement a pilot study (n=30) evaluating this recourse mechanism against a standard fixed-threshold approach.
- Find improved usability ratings for the recourse system, though mixed results on perceived controllability.
- Identify themes from user feedback: variability in comprehending toxicity filtering, desire for more model controllability, and observed gaps/biases in the toxicity scoring.
- Propose the mechanism as a way to balance personalization and safety while minimizing user burden in providing feedback.
- Situate this work at the intersection of toxicity scoring, model controllability, user agency, and language reclamation.

The paper makes an initial case that algorithmic recourse shows promise for improving user experiences with, and the value alignment of, GLMs. But further research is needed, especially with marginalized populations most affected by model harms.
