# [CAFE: Towards Compact, Adaptive, and Fast Embedding for Large-scale   Recommendation Models](https://arxiv.org/abs/2312.03256)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes CAFE, a novel embedding compression framework for large-scale deep learning recommendation models that is Compact, Adaptive and Fast. CAFE introduces HotSketch, an efficient sketch algorithm, to capture feature importance scores and distinguish a small set of critical "hot" features from a large number of unimportant "non-hot" features. Hot features are allocated exclusive embedding vectors while non-hot features share embeddings using hash techniques. An embedding migration strategy enables CAFE to adapt to dynamic data distributions during online training. Further optimizations are made through multi-level hash embedding to create finer-grained importance groups. Experiments on multiple datasets demonstrate CAFE's superior memory efficiency, low latency, and adaptability. Under extreme compression ratios, CAFE achieves significantly higher model quality and lower training loss compared to prior methods. Theoretically, CAFE's accuracy and convergence properties are analyzed. With its ability to dynamically allocate resources according to feature importance, CAFE provides an effective solution for deploying large recommendation models under tight memory constraints.
