# Learn to Explain: Multimodal Reasoning via Thought Chains for Science   Question Answering

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research questions/hypotheses appear to be:1. Can we construct a large-scale, multimodal science question answering dataset with rich domain diversity and annotated explanations to facilitate research on multi-hop reasoning?2. Can language models be trained to generate coherent explanations that reveal the reasoning process (chain of thought) for answering science questions? 3. Does training language models to produce explanations as a chain of thought improve their reasoning abilities and performance on science QA?4. Does providing explanations help language models learn more efficiently from less data, similar to how explanations aid human learning?Specifically, the authors aim to construct a new dataset called ScienceQA that contains over 21k science questions spanning diverse topics and modalities. They further explore whether large language models like GPT-3 and UnifiedQA can be trained to produce lectures and explanations that mimic human reasoning chains. The key hypotheses are that (1) generating explanations will improve model performance on ScienceQA compared to just predicting answers, and (2) explanations will allow the models to learn from less data. The authors test these hypotheses through experiments on few-shot prompting of GPT-3 and fine-tuning of UnifiedQA. Overall, the goal is to endow AI systems with more human-like reasoning and learning abilities for science QA.


## What is the main contribution of this paper?

The main contributions of this paper are:1. A new dataset called ScienceQA, which contains 21,208 multimodal multiple choice science questions with rich domain diversity. It is the first large-scale multimodal science question dataset that annotates lectures and explanations for the answers. 2. Showing that using a chain of thought (CoT) by generating lectures and explanations along with answers improves the reasoning ability and performance of large language models like UnifiedQA and GPT-3 on this dataset, in both few-shot and fine-tuning settings.3. Analyzing the upper bound of GPT-3 performance by feeding in gold explanations, and showing that CoT helps language models learn more efficiently from fewer examples.In summary, the key contribution is the new ScienceQA dataset for multimodal reasoning, along with analyses showing the utility of chain of thought and explanations in improving language model performance on this scientific QA task. The paper provides both the dataset and modeling innovations to advance multimodal reasoning and interpretability.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper: The paper introduces Science Question Answering (ScienceQA), a new multimodal question answering dataset for science domains, and shows that incorporating explanations and reasoning chains improves model performance on this challenging benchmark.
