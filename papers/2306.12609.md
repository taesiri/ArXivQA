# [Towards Regulatable AI Systems: Technical Gaps and Policy Opportunities](https://arxiv.org/abs/2306.12609)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research questions seem to be:

1) What innovations in AI systems are needed for them to be effectively regulated?  

2) In what areas will innovations in AI methods alone be insufficient, and more interdisciplinary approaches required?

The authors investigate these questions by examining two public sector procurement checklists for AI systems. They identify areas where existing AI methods can help meet regulatory criteria, areas needing more AI innovation, and aspects that require interdisciplinary efforts beyond just technical AI solutions. 

Overall, the paper aims to highlight concrete directions for AI research to improve the ability to create AI systems that can be effectively regulated and aligned with societal values and norms. It also informs policymakers and AI engineers on issues that need more holistic efforts beyond just advances in AI techniques.


## What is the main contribution of this paper?

 This paper examines technical criteria from two AI regulatory frameworks - the Canadian Directive on Automated Decision-Making and the World Economic Forum's AI Procurement in a Box. Its main contribution is identifying areas where additional AI innovation is needed in order to be able to effectively vet AI systems against regulatory requirements. 

Specifically, the paper groups the technical criteria from these checklists into categories familiar to AI researchers: data checks, system monitoring, global explanation, local explanation, objective design, privacy, and human-in-the-loop systems. 

For each category, the paper summarizes what techniques currently exist that could help construct AI systems meeting those criteria. It then identifies areas needing further technical innovation, such as better tradeoffs between privacy and performance, interactive "openboxing" of large models, and defining meaningful metrics to measure how well a technical objective matches true goals.

The paper concludes by outlining aspects of the criteria that require interdisciplinary approaches, highlighting the need for collaboration between AI experts and domain experts from social sciences, law, psychology etc. to create AI systems that are effectively regulatable.

In summary, the key contribution is a analysis of where additional AI research is needed to improve our ability to vet AI systems against regulatory checklists, as well as where interdisciplinary efforts are necessary to create regulatable AI. The paper aims to inform both AI researchers and policy makers.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper examines technical criteria from AI procurement regulations, identifies current capabilities and limitations in meeting those criteria, and outlines areas needing additional AI innovation and interdisciplinary engagement to improve the regulatability of AI systems.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other work on creating regulatable AI systems:

- The paper takes a practical approach by directly examining existing regulatory checklists and identifying concrete technical gaps. Much other work has focused on more theoretical considerations or proposals for new regulations, so this practical analysis is a useful complement. 

- It covers a broad range of technical issues related to regulatable AI, spanning data, models, objectives, explanations, privacy, and human interaction. Many papers focus on only one or two of these aspects. The comprehensive coverage highlights the breadth of innovations needed.

- The paper nicely balances identifying current capabilities with pointing out limitations and open challenges. It avoids overstating what we can currently do while also not being overly pessimistic. The overall tone seems realistic about the state of research.

- The analysis goes beyond just technical gaps to point out where interdisciplinary perspectives are needed. The discussion of how to determine meaningful explanations and privacy definitions are good examples. This highlights that purely technical work is insufficient.

- Compared to other review papers, the structure around regulatory checklists provides a clear framing. The checklist format makes the gaps very concrete.

- The paper mostly focuses on a high-level view of the technical gaps rather than providing a comprehensive literature review. This helps highlight the big picture challenges.

Overall, I think this paper makes a valuable contribution by clearly framing the technical ingredients needed for regulatable AI systems. The direct connection to real regulatory criteria and the emphasis on open problems differentiate it from prior work. The paper delivers on its goal of informing both AI researchers and policy makers.


## What future research directions do the authors suggest?

 The authors suggest several promising areas for future AI research that could enable more effective regulation of AI systems:

1. Developing better metrics to evaluate data quality and generalizability to intended use cases. This includes developing ways to quantify the risks of using a dataset outside its original context.

2. Performing data quality checks for pre-trained models where full training data transparency is limited. Develop checks that rely on model access rather than full training data access.

3. Creating inherently interpretable models, especially for complex data like images, audio and text. This could involve learning interpretable concept representations. 

4. Enabling interactive "openboxing" of large blackbox models to build hierarchical, semantically-aligned explanations. Allow exploring explanations at different fidelities.

5. Designing metrics to evaluate how well technical objectives match true policy goals. Understand properties of common loss functions in relation to unintended behaviors like reward hacking.

6. Improving differentially private ML to enable better tradeoffs between privacy guarantees and predictive performance. Define and evaluate notions of privacy for broader data types like text and trajectories.

7. Developing effective human-AI interaction techniques that avoid cognitive biases and promote shared mental models. Evaluate human-in-the-loop systems for high stakes applications.

In summary, they highlight needs for innovations in areas like data evaluation, model interpretability, objective design, privacy, and human-AI collaboration to make AI systems more amenable to oversight and regulation. The paper provides a valuable framework categorizing the technical capabilities required for regulatable AI.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points from the paper:

The paper examines technical criteria from two public sector AI procurement checklists - the World Economic Forum's AI Procurement in a Box and the Canadian Directive on Automated Decision-Making. It analyzes what capabilities currently exist to vet AI systems against these regulatory requirements, areas requiring more AI innovation to do so effectively, and aspects that necessitate interdisciplinary approaches beyond just technical tools. The authors group the criteria into categories like data checks, system monitoring, model explanations, objective design, privacy, and human involvement. They highlight promising directions like metrics connecting data characteristics to model impacts, interactive model inspection tools, defining meaningful privacy notions, and evaluating human-AI systems in realistic settings. The paper aims to concretely inform AI researchers on how to make systems more amenable to oversight and regulation, while also delineating the interdisciplinary efforts needed for effective governance.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points made in the paper:

The paper examines how to build AI systems that can be effectively regulated by evaluating technical criteria from two public sector AI procurement frameworks: The World Economic Forum's AI Procurement in a Box (WEF) and the Canadian Directive on Automated Decision-Making (CDADM). The goal is to identify areas where technical innovation is still needed in order to be able to vet increasingly complex AI systems against regulatory checklists. 

The paper groups the technical criteria from WEF and CDADM into categories familiar to AI researchers: data checks, system monitoring, global explanation, local explanation, objective design, privacy, and human+AI systems. For each category, it summarizes existing techniques, identifies directions needing more AI innovation, and aspects requiring interdisciplinary engagement beyond just technical solutions. Key areas needing more innovation include metrics connecting data characteristics to model impacts, monitoring many performance metrics efficiently, tradeoffs between model explainability and privacy, developing human-AI systems for high stakes settings, and defining privacy for emerging data types. The paper concludes by emphasizing the need for continued AI advances to create regulatable AI systems.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper examines the technical criteria contained in two real-world AI regulatory frameworks - the Canadian Directive on Automated Decision-Making and the World Economic Forum's AI Procurement in a Box guidelines. The authors group the technical requirements from these frameworks into categories familiar to AI researchers, such as data checks, system monitoring, global model explanations, local decision explanations, objective design, privacy, and human-in-the-loop systems. For each category, they briefly summarize existing technical approaches that could help construct AI systems satisfying those criteria. They then identify areas where further AI innovation is still needed in order to be able to effectively vet increasingly complex AI systems being deployed in diverse contexts against regulatory requirements. Finally, they outline aspects of the criteria that necessitate more interdisciplinary approaches, beyond just technical AI methods alone. The examination aims to highlight concrete areas for advancing the development of regulatable AI systems.


## What problem or question is the paper addressing?

 The paper is addressing the problem of how to effectively regulate AI systems to ensure they align with social values and norms. Specifically, it considers two key questions:

1. What innovations in AI systems are needed for them to be effectively regulated?  

2. In what areas will innovations in AI methods alone be insufficient, and more interdisciplinary approaches required?

To investigate these questions, the authors examine the technical criteria contained in two public sector AI procurement checklists - the World Economic Forum's AI Procurement in a Box and the Canadian Directive on Automated Decision-Making. By analyzing these criteria, they aim to identify areas where expert reviewers can currently vet an AI system's adherence to regulatory requirements, versus areas where additional technical innovation is needed in AI systems to enable effective oversight. The paper also briefly outlines aspects of the criteria that necessitate more holistic, interdisciplinary approaches beyond just technical methods.

In summary, the paper seeks to highlight concrete areas where advances in AI techniques and systems could improve the ability to create AI that can be effectively regulated in alignment with social values, as well as aspects that require broader collaboration across disciplines. The analysis intends to inform policymakers, AI researchers and engineers interested in developing regulatable AI.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some key terms and concepts that come up are:

- Regulatable AI systems - The paper examines how to create AI systems that can be effectively regulated. 

- Procurement checklists - The paper analyzes two real public sector procurement checklists for AI systems to understand regulatory criteria.

- Technical gaps - The paper identifies areas where more technical innovation in AI is needed to be able to vet systems against regulatory checklists. 

- Interdisciplinary gaps - The paper points out where purely technical approaches are insufficient and interdisciplinary collaboration is needed.

- Data checks - Checking and documenting properties of training data.

- System monitoring - Monitoring a deployed system for issues. 

- Explainability - Methods to explain and interpret AI systems both globally and locally.

- Objective design - Formulating goals and rewards properly.

- Privacy - Protecting sensitive information.

- Human-AI collaboration - Designing systems for effective human oversight.

The key focus seems to be on identifying technical innovations needed in AI, as well as aspects requiring interdisciplinary collaboration, in order to create AI systems that can be meaningfully regulated and aligned with societal values and norms. The paper analyzes real regulatory checklists to ground its analysis.


## Based on the paper, what questions should we ask to create a comprehensive summary of it? Please list at least 10 questions.

 Here are 10 possible questions to ask in order to summarize the key points of the paper:

1. What is the main purpose or goal of the paper? What problem is it trying to address?

2. What are the key technical criteria examined from the two public sector procurement checklists (WEF and CDADM)? 

3. How does the paper categorize the technical criteria into different sections (e.g. data checks, system monitoring, explanation methods)? What are the main categories?

4. For each category, what does the paper say we currently know how to do technically? What existing methods can help meet the criteria?

5. For each category, what are some directions identified where additional AI innovation is needed? What are the open challenges? 

6. Which criteria or topics are highlighted as requiring interdisciplinary engagement? Where is AI methods alone insufficient?

7. What overarching limitations around AI regulatability does the paper identify? What tensions exist between goals like transparency, privacy, security etc?

8. What concrete recommendations does the paper make for creating regulatable AI systems? What should AI researchers focus on?

9. What implications does the analysis have for policy makers? How can it inform their approach to AI regulation?

10. Does the paper identify any broader societal impacts or ethical considerations related to AI regulatability? If so, what are they?


## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes an approach for making AI systems more amenable to regulation. What are some limitations or challenges of trying to make complex AI systems regulatable, especially as they continue to grow in size and capability? How might those challenges be addressed?

2. The paper examines regulatory checklists and categorizes criteria into different technical areas like data checks, system monitoring, explanations, etc. Are there any other important categories of technical criteria that should be considered for regulatable AI systems? What approaches could help address criteria in those categories?

3. For data checks, the paper discusses metrics connecting data properties to model impacts and generalizability. What specific metrics would be useful for critical application areas like healthcare or autonomous vehicles? How can we validate that those metrics provide meaningful guarantees? 

4. The paper identifies interpretability and explainability as important for regulatable AI. What are some key open challenges in making large, modern AI systems more interpretable or explainable? How could those explanatory interfaces be designed to best suit oversight needs?

5. The paper discusses technical approaches for post-deployment monitoring of AI systems. What metrics should be prioritized for monitoring, and how frequently should they be evaluated to balance overhead with oversight needs?

6. Objective design is critical for alignment. What processes and tools could help elicit true objectives from stakeholders and convert those into formal reward functions? How can alignment be evaluated?

7. What notions of privacy beyond differential privacy may be appropriate for different data types and use cases? What are their limitations?

8. For human-AI collaboration, what interface and interaction designs could help address issues like cognitive biases? How should systems handle human unavailability?

9. What validation approaches can help ensure human-AI systems function properly in high-stakes, time-critical settings? What risks need to be mitigated?

10. What governance processes and standards could facilitate the development, evaluation and oversight of regulatable AI systems? How can we incentivize best practices?
