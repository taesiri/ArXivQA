# [Towards Regulatable AI Systems: Technical Gaps and Policy Opportunities](https://arxiv.org/abs/2306.12609)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research questions seem to be:

1) What innovations in AI systems are needed for them to be effectively regulated?  

2) In what areas will innovations in AI methods alone be insufficient, and more interdisciplinary approaches required?

The authors investigate these questions by examining two public sector procurement checklists for AI systems. They identify areas where existing AI methods can help meet regulatory criteria, areas needing more AI innovation, and aspects that require interdisciplinary efforts beyond just technical AI solutions. 

Overall, the paper aims to highlight concrete directions for AI research to improve the ability to create AI systems that can be effectively regulated and aligned with societal values and norms. It also informs policymakers and AI engineers on issues that need more holistic efforts beyond just advances in AI techniques.


## What is the main contribution of this paper?

 This paper examines technical criteria from two AI regulatory frameworks - the Canadian Directive on Automated Decision-Making and the World Economic Forum's AI Procurement in a Box. Its main contribution is identifying areas where additional AI innovation is needed in order to be able to effectively vet AI systems against regulatory requirements. 

Specifically, the paper groups the technical criteria from these checklists into categories familiar to AI researchers: data checks, system monitoring, global explanation, local explanation, objective design, privacy, and human-in-the-loop systems. 

For each category, the paper summarizes what techniques currently exist that could help construct AI systems meeting those criteria. It then identifies areas needing further technical innovation, such as better tradeoffs between privacy and performance, interactive "openboxing" of large models, and defining meaningful metrics to measure how well a technical objective matches true goals.

The paper concludes by outlining aspects of the criteria that require interdisciplinary approaches, highlighting the need for collaboration between AI experts and domain experts from social sciences, law, psychology etc. to create AI systems that are effectively regulatable.

In summary, the key contribution is a analysis of where additional AI research is needed to improve our ability to vet AI systems against regulatory checklists, as well as where interdisciplinary efforts are necessary to create regulatable AI. The paper aims to inform both AI researchers and policy makers.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:

The paper examines technical criteria from AI procurement regulations, identifies current capabilities and limitations in meeting those criteria, and outlines areas needing additional AI innovation and interdisciplinary engagement to improve the regulatability of AI systems.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other work on creating regulatable AI systems:

- The paper takes a practical approach by directly examining existing regulatory checklists and identifying concrete technical gaps. Much other work has focused on more theoretical considerations or proposals for new regulations, so this practical analysis is a useful complement. 

- It covers a broad range of technical issues related to regulatable AI, spanning data, models, objectives, explanations, privacy, and human interaction. Many papers focus on only one or two of these aspects. The comprehensive coverage highlights the breadth of innovations needed.

- The paper nicely balances identifying current capabilities with pointing out limitations and open challenges. It avoids overstating what we can currently do while also not being overly pessimistic. The overall tone seems realistic about the state of research.

- The analysis goes beyond just technical gaps to point out where interdisciplinary perspectives are needed. The discussion of how to determine meaningful explanations and privacy definitions are good examples. This highlights that purely technical work is insufficient.

- Compared to other review papers, the structure around regulatory checklists provides a clear framing. The checklist format makes the gaps very concrete.

- The paper mostly focuses on a high-level view of the technical gaps rather than providing a comprehensive literature review. This helps highlight the big picture challenges.

Overall, I think this paper makes a valuable contribution by clearly framing the technical ingredients needed for regulatable AI systems. The direct connection to real regulatory criteria and the emphasis on open problems differentiate it from prior work. The paper delivers on its goal of informing both AI researchers and policy makers.


## What future research directions do the authors suggest?

 The authors suggest several promising areas for future AI research that could enable more effective regulation of AI systems:

1. Developing better metrics to evaluate data quality and generalizability to intended use cases. This includes developing ways to quantify the risks of using a dataset outside its original context.

2. Performing data quality checks for pre-trained models where full training data transparency is limited. Develop checks that rely on model access rather than full training data access.

3. Creating inherently interpretable models, especially for complex data like images, audio and text. This could involve learning interpretable concept representations. 

4. Enabling interactive "openboxing" of large blackbox models to build hierarchical, semantically-aligned explanations. Allow exploring explanations at different fidelities.

5. Designing metrics to evaluate how well technical objectives match true policy goals. Understand properties of common loss functions in relation to unintended behaviors like reward hacking.

6. Improving differentially private ML to enable better tradeoffs between privacy guarantees and predictive performance. Define and evaluate notions of privacy for broader data types like text and trajectories.

7. Developing effective human-AI interaction techniques that avoid cognitive biases and promote shared mental models. Evaluate human-in-the-loop systems for high stakes applications.

In summary, they highlight needs for innovations in areas like data evaluation, model interpretability, objective design, privacy, and human-AI collaboration to make AI systems more amenable to oversight and regulation. The paper provides a valuable framework categorizing the technical capabilities required for regulatable AI.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the key points from the paper:

The paper examines technical criteria from two public sector AI procurement checklists - the World Economic Forum's AI Procurement in a Box and the Canadian Directive on Automated Decision-Making. It analyzes what capabilities currently exist to vet AI systems against these regulatory requirements, areas requiring more AI innovation to do so effectively, and aspects that necessitate interdisciplinary approaches beyond just technical tools. The authors group the criteria into categories like data checks, system monitoring, model explanations, objective design, privacy, and human involvement. They highlight promising directions like metrics connecting data characteristics to model impacts, interactive model inspection tools, defining meaningful privacy notions, and evaluating human-AI systems in realistic settings. The paper aims to concretely inform AI researchers on how to make systems more amenable to oversight and regulation, while also delineating the interdisciplinary efforts needed for effective governance.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points made in the paper:

The paper examines how to build AI systems that can be effectively regulated by evaluating technical criteria from two public sector AI procurement frameworks: The World Economic Forum's AI Procurement in a Box (WEF) and the Canadian Directive on Automated Decision-Making (CDADM). The goal is to identify areas where technical innovation is still needed in order to be able to vet increasingly complex AI systems against regulatory checklists. 

The paper groups the technical criteria from WEF and CDADM into categories familiar to AI researchers: data checks, system monitoring, global explanation, local explanation, objective design, privacy, and human+AI systems. For each category, it summarizes existing techniques, identifies directions needing more AI innovation, and aspects requiring interdisciplinary engagement beyond just technical solutions. Key areas needing more innovation include metrics connecting data characteristics to model impacts, monitoring many performance metrics efficiently, tradeoffs between model explainability and privacy, developing human-AI systems for high stakes settings, and defining privacy for emerging data types. The paper concludes by emphasizing the need for continued AI advances to create regulatable AI systems.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper examines the technical criteria contained in two real-world AI regulatory frameworks - the Canadian Directive on Automated Decision-Making and the World Economic Forum's AI Procurement in a Box guidelines. The authors group the technical requirements from these frameworks into categories familiar to AI researchers, such as data checks, system monitoring, global model explanations, local decision explanations, objective design, privacy, and human-in-the-loop systems. For each category, they briefly summarize existing technical approaches that could help construct AI systems satisfying those criteria. They then identify areas where further AI innovation is still needed in order to be able to effectively vet increasingly complex AI systems being deployed in diverse contexts against regulatory requirements. Finally, they outline aspects of the criteria that necessitate more interdisciplinary approaches, beyond just technical AI methods alone. The examination aims to highlight concrete areas for advancing the development of regulatable AI systems.


## What problem or question is the paper addressing?

 The paper is addressing the problem of how to effectively regulate AI systems to ensure they align with social values and norms. Specifically, it considers two key questions:

1. What innovations in AI systems are needed for them to be effectively regulated?  

2. In what areas will innovations in AI methods alone be insufficient, and more interdisciplinary approaches required?

To investigate these questions, the authors examine the technical criteria contained in two public sector AI procurement checklists - the World Economic Forum's AI Procurement in a Box and the Canadian Directive on Automated Decision-Making. By analyzing these criteria, they aim to identify areas where expert reviewers can currently vet an AI system's adherence to regulatory requirements, versus areas where additional technical innovation is needed in AI systems to enable effective oversight. The paper also briefly outlines aspects of the criteria that necessitate more holistic, interdisciplinary approaches beyond just technical methods.

In summary, the paper seeks to highlight concrete areas where advances in AI techniques and systems could improve the ability to create AI that can be effectively regulated in alignment with social values, as well as aspects that require broader collaboration across disciplines. The analysis intends to inform policymakers, AI researchers and engineers interested in developing regulatable AI.
