# [HollowNeRF: Pruning Hashgrid-Based NeRFs with Trainable Collision   Mitigation](https://arxiv.org/abs/2308.10122)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we improve the rendering quality and efficiency of neural radiance fields (NeRFs) by leveraging the inherent sparsity in 3D scenes? Specifically, the paper proposes a new method called HollowNeRF that aims to achieve higher rendering quality using fewer parameters compared to prior NeRF methods like Instant-NGP. The key ideas are:- Learning a 3D saliency grid during training to guide compression of dense volumetric features. This focuses model capacity on visible surfaces while pruning unnecessary internal features. - Using an ADMM pruner to enforce sparsity in the saliency grid, further eliminating unneeded features.- Employing a soft zero-skipping gate in the MLP decoder to ensure pruned features correctly map to zero density.So in summary, the central hypothesis is that by exploiting scene sparsity through trainable feature pruning and collision mitigation techniques, HollowNeRF can improve the accuracy and efficiency trade-off compared to previous NeRF methods. The experiments aim to validate whether HollowNeRF achieves higher rendering quality using fewer parameters on various 3D scenes.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Proposing HollowNeRF, a new neural radiance field (NeRF) compression method that learns to prioritize features defining visible surfaces and prune unnecessary internal features without requiring prior knowledge of surface geometry. - Using an ADMM-based optimization framework to prune features during NeRF training and adding a soft zero-skipping gate to the MLP to ensure pruned features map to zero density.- Evaluating HollowNeRF on NeRF datasets and showing it achieves better cost-accuracy tradeoffs than state-of-the-art methods like Instant-NGP. Specifically, HollowNeRF attains comparable rendering quality to Instant-NGP while using only 31% of the parameters, or can achieve around 1dB higher PSNR while using only 56% of the parameters.In summary, the main contribution appears to be presenting a new way to compress neural radiance fields that automatically identifies and prunes invisible/internal features during training to improve the accuracy vs. parameter count tradeoff compared to prior art. The key ideas are learning a 3D saliency mask to guide pruning and using an ADMM-based optimizer to enforce sparsity constraints.
