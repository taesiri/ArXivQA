# [SketchXAI: A First Look at Explainability for Human Sketches](https://arxiv.org/abs/2304.11744)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we make deep learning models for human sketch classification more interpretable and explainable? The key ideas and contributions appear to be:- Introducing human sketches as a new domain for explainable AI research. The authors argue that sketches are a "human-centered" data type that lend themselves well to studying explainability.- Identifying strokes as the fundamental building block of sketches that enable unique manipulation and explanation capabilities not possible with photos or text. - Designing a sketch-specific encoder model called SketchXAINet that encapsulates the intrinsic stroke properties of shape, location, and order.- Proposing a novel explainability task called stroke location inversion (SLI) that inverts stroke locations to probe model understanding and generate visual explanations.- Providing qualitative analysis of the SLI process on a sketch classification model, demonstrating how it can offer insights into model decisions and training data.So in summary, the central hypothesis seems to be that by designing a sketch-specific encoder and explanation method based on strokes, they can open up new directions for interpretable AI using this human-centered data modality. The key question is whether their proposed techniques can provide useful explanations and transparency for sketch recognition models.


## What is the main contribution of this paper?

The main contribution of this paper is introducing human sketches to the field of explainable AI (XAI) and proposing a new methodology for explaining AI decisions on sketch data. Specifically:- The paper argues that sketches, being produced by humans, are an ideal data form for explainable AI and makes a first attempt at sketch-specific explainability. - It identifies strokes as the unique building block of sketches that enables flexibility in object construction and manipulation. - It designs a simple sketch encoder named SketchXAINet that encapsulates the intrinsic properties of strokes - shape, location, and order.- It introduces a novel XAI task for sketches called stroke location inversion (SLI) that inverts stroke locations to generate dynamic explanations showcasing the model's response to different views of the same sketch.- It provides qualitative results of the SLI process and shows the proposed method achieves state-of-the-art sketch recognition performance.In summary, the key contribution is opening up the new direction of sketch-specific explainable AI, by designing an explainability-friendly sketch encoder and proposing the novel SLI task to generate dynamic explanations for sketch classification models. This represents the first attempt at bringing human sketch data into the XAI landscape.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The paper introduces sketch-specific explainability methods for deep learning models. The key ideas are:- Identifying strokes as the basic unit for explanations in sketches. - Proposing a sketch encoder model named SketchXAINet that encodes shape, location and order information of strokes.- Introducing a novel explainability method called Stroke Location Inversion (SLI) that inverts stroke locations to generate explanations.In summary, the paper explores sketch-specific explainability by leveraging strokes as building blocks. It proposes methods for encoding and explaining sketches in terms of strokes.
