# [SketchXAI: A First Look at Explainability for Human Sketches](https://arxiv.org/abs/2304.11744)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we make deep learning models for human sketch classification more interpretable and explainable? The key ideas and contributions appear to be:- Introducing human sketches as a new domain for explainable AI research. The authors argue that sketches are a "human-centered" data type that lend themselves well to studying explainability.- Identifying strokes as the fundamental building block of sketches that enable unique manipulation and explanation capabilities not possible with photos or text. - Designing a sketch-specific encoder model called SketchXAINet that encapsulates the intrinsic stroke properties of shape, location, and order.- Proposing a novel explainability task called stroke location inversion (SLI) that inverts stroke locations to probe model understanding and generate visual explanations.- Providing qualitative analysis of the SLI process on a sketch classification model, demonstrating how it can offer insights into model decisions and training data.So in summary, the central hypothesis seems to be that by designing a sketch-specific encoder and explanation method based on strokes, they can open up new directions for interpretable AI using this human-centered data modality. The key question is whether their proposed techniques can provide useful explanations and transparency for sketch recognition models.


## What is the main contribution of this paper?

The main contribution of this paper is introducing human sketches to the field of explainable AI (XAI) and proposing a new methodology for explaining AI decisions on sketch data. Specifically:- The paper argues that sketches, being produced by humans, are an ideal data form for explainable AI and makes a first attempt at sketch-specific explainability. - It identifies strokes as the unique building block of sketches that enables flexibility in object construction and manipulation. - It designs a simple sketch encoder named SketchXAINet that encapsulates the intrinsic properties of strokes - shape, location, and order.- It introduces a novel XAI task for sketches called stroke location inversion (SLI) that inverts stroke locations to generate dynamic explanations showcasing the model's response to different views of the same sketch.- It provides qualitative results of the SLI process and shows the proposed method achieves state-of-the-art sketch recognition performance.In summary, the key contribution is opening up the new direction of sketch-specific explainable AI, by designing an explainability-friendly sketch encoder and proposing the novel SLI task to generate dynamic explanations for sketch classification models. This represents the first attempt at bringing human sketch data into the XAI landscape.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The paper introduces sketch-specific explainability methods for deep learning models. The key ideas are:- Identifying strokes as the basic unit for explanations in sketches. - Proposing a sketch encoder model named SketchXAINet that encodes shape, location and order information of strokes.- Introducing a novel explainability method called Stroke Location Inversion (SLI) that inverts stroke locations to generate explanations.In summary, the paper explores sketch-specific explainability by leveraging strokes as building blocks. It proposes methods for encoding and explaining sketches in terms of strokes.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in explainable AI (XAI):- This is the first work attempting XAI specifically for human sketches. Prior XAI research has focused mainly on photos and text. Introducing sketches is an interesting new direction as sketches have unique properties as a very "human-centered" data type.- The approach of using strokes as the fundamental unit to explain is novel. Most prior sketch recognition models treat sketches like images, operating on pixels. Leveraging strokes allows more natural manipulation and explanation.- The proposed stroke location inversion (SLI) task is a creative way to probe sketch model understanding. It is related to counterfactual explanation methods that find minimal input changes leading to different predictions. However, SLI has more flexibility by randomizing stroke locations.- The sketch encoder design is simple but new - having separate branches for stroke shape, location, and order. This decomposed representation builds in inductive biases suited for sketch data. Though simple, it achieves state-of-the-art sketch recognition, highlighting the benefits of this inductive bias.- The qualitative SLI explanation visualizations are more dynamic than typical static heatmaps, allowing different facets of the model to be probed. The optimization-based generation also connects to latent space manipulation techniques in GANs.Overall, the novelty lies in tailoring XAI concepts like counterfactuals and latent variable manipulation to the unique properties and building blocks of sketches. The sketch encoder design and SLI task are simple but enable new directions for human-centric XAI using sketch data. More broadly, it expands XAI to a new modality beyond photos and text.


## What future research directions do the authors suggest?

Based on my reading of the paper, some future research directions the authors suggest are:- Exploring other sketch-specific explanation methods beyond SLI. The authors propose SLI as a first explainability method tailored for sketches, but encourage further research into new sketch-oriented explanation techniques. - Applying sketch explainability methods to other sketch tasks beyond classification, such as sketch-based image retrieval, sketch generation, etc. The authors focus on sketch classification but note the potential for using explainability in other sketch domains.- Developing interactive or real-time sketch explanation systems. The authors generate static explanations, but discuss the possibility of interactive systems that explain in real-time as a user is drawing.- Combining sketch explainability with human studies. The authors suggest collaborating with human subjects to further evaluate sketch explanations and gain additional insights.- Extending the work to other free-form data types beyond sketches, like handwriting or gestures. The stroke-based approach may generalize.- Addressing limitations of gradient-based methods like SLI's susceptibility to local optima. The authors note this weakness of their approach.- Applying sketch explainability to discover biases in sketch datasets. The authors give an example of how SLI revealed biases.- Testing sketch explainability on larger sketch datasets. The authors use QuickDraw, but could try other sketch datasets.In summary, the authors propose sketch explainability as a new research direction and provide SLI as a first method, but encourage the exploration of other sketch-oriented explanation approaches, applications to other sketch tasks, interactive systems, human studies, extensions to new data types, ways to address limitations, and evaluations on larger datasets.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper introduces human sketches as a new direction for explainable AI (XAI) research. It argues that sketches are a natural fit for XAI because they are created by humans and have unique properties like flexibility in object construction through strokes. The authors design a simple sketch encoder called SketchXAINet that learns representations for stroke shape, location, and order. They propose a novel XAI task called stroke location inversion (SLI) which involves optimizing stroke locations to reconstruct a sketch belonging to the original or different class. SLI allows generating many dynamic visual explanations by seeing how model confidence changes during sketch reconstruction. The authors show SLI can provide insights into model understanding and limitations. Interestingly, SketchXAINet also achieves state-of-the-art sketch recognition, despite its simple design. Overall, the paper makes a case for sketch-specific XAI and introduces SLI as a first step, while also improving sketch recognition performance.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:The paper introduces a new method for explaining AI decisions on human sketch data. Sketches are a unique data modality because they are created by humans and allow flexible manipulation. The key idea is to leverage strokes, the fundamental building blocks of sketches, for explainability. The authors design a sketch encoder model called SketchXAINet that separately encodes the shape, location, and order of strokes. This allows probing the understanding of the model along these different factors. They then propose a novel explainability method called stroke location inversion (SLI) which reconstructs a sketch by randomly perturbing stroke locations and optimizing to recover the original class. This generates many explanations by showing which strokes are moved by the model to retain the sketch identity. The authors visualize SLI on sketch reconstruction and sketch transfer tasks. As a byproduct, the SketchXAINet model also achieves state-of-the-art sketch recognition, showing the benefits of the stroke-based design. Overall, this work opens up the new direction of explainable AI for human sketch data.In summary, the key ideas are 1) identifying strokes as the building block for explainability in sketches, which are flexible and human-centered, 2) designing a model and explanation method leveraging stroke shape, location, and order, and 3) achieving superior sketch recognition while also enabling better model explanations via the proposed SLI technique. This initial work makes the case for sketches as an impactful new domain for interpretable AI.
