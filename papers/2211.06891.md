# [Residual Degradation Learning Unfolding Framework with Mixing Priors   across Spectral and Spatial for Compressive Spectral Imaging](https://arxiv.org/abs/2211.06891)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the main research focus of this paper is on recovering accurate and detailed 3D hyperspectral image (HSI) cubes from 2D coded aperture snapshot spectral imaging (CASSI) measurements. 

Specifically, the paper proposes a new deep learning-based approach called Residual Degradation Learning Unfolding Framework (RDLUF) with Mixing priors across Spatial and Spectral (MixS2) Transformers to address two main challenges:

1) The gap between the sensing matrix and real degradation process in CASSI systems. The sensing matrix cannot properly reflect device errors caused by factors like phase aberration and distortion. 

2) The need for suitable models to exploit both spatial and spectral priors for generating high-quality HSIs. Methods relying solely on spectral attention may neglect crucial spatial information. 

To address the first challenge, the paper integrates residual learning into the data subproblem to estimate the gap between the sensing matrix and true degradation process. 

For the second challenge, it proposes a MixS2 Transformer that combines lightweight multi-scale convolutions (for spatial modeling) with spectral self-attention in a parallel design with bi-directional interaction (for complementary spectral-spatial clues).

By plugging the MixS2 Transformer into the proposed RDLUF, the model aims to achieve state-of-the-art performance in reconstructing accurate and detailed 3D HSIs from 2D CASSI measurements. Experiments demonstrate superior quantitative and qualitative performance compared to previous approaches.

In summary, the central hypothesis is that modeling the residual degradation and effectively mixing spatial-spectral priors using the proposed techniques will improve HSI reconstruction from compressed CASSI measurements. The paper offers RDLUF-MixS2 as a solution.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. It proposes a Residual Degradation Learning Unfolding Framework (RDLUF) to bridge the gap between the sensing matrix and the actual degradation process in compressive spectral imaging. This is done by explicitly modeling the degradation as residual learning with reference to the sensing matrix, instead of directly learning the degradation matrix. 

2. It designs a Mix$S^2$ Transformer module to strengthen the spectral-spatial representation capability for hyperspectral image reconstruction. This module combines multiscale convolutions (lightweight Inception) and spectral self-attention in parallel to enhance both spatial and spectral modeling. It also uses bi-directional interaction between the spatial and spectral branches to further boost their capabilities.

3. By plugging the Mix$S^2$ Transformer into the RDLUF as the denoiser, an end-to-end neural network called RDLUF-Mix$S^2$ is formed. Experiments show this method achieves state-of-the-art performance in hyperspectral image reconstruction, while requiring fewer parameters than previous methods.

In summary, the key contributions are using residual learning to better model the degradation process, designing a Mix$S^2$ Transformer to exploit both spatial and spectral priors effectively, and integrating these components into an end-to-end deep unfolding network for high-quality hyperspectral image reconstruction.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a new deep learning framework called Residual Degradation Learning Unfolding Framework with Mixing Priors across Spectral and Spatial (RDLUF-MixS2) for reconstructing high-quality hyperspectral images from compressed measurements, which achieves state-of-the-art performance by explicitly modeling the residual between the sensing matrix and degradation process and jointly exploiting spectral and spatial priors.


## How does this paper compare to other research in the same field?

 Here are a few thoughts on how this paper compares to other research in the field of hyperspectral image reconstruction:

- The paper proposes a deep learning-based approach by unfolding an optimization algorithm (proximal gradient descent) into a neural network. This follows a recent trend in the field of using deep unfolding or neural algorithm implementations to convert model-based methods into end-to-end deep learning solutions. Other papers like DGSMP, GAP-Net, DNU have also adopted this unfolding strategy for hyperspectral reconstruction. 

- A key contribution is the explicit residual modeling of the degradation process with reference to the sensing matrix. Most prior works either directly use the sensing matrix or learn the degradation matrix from scratch. Modeling the residual helps bridge the gap between the sensing matrix and true degradation.

- For exploiting spatial-spectral priors, the paper proposes an architecture combining spectral self-attention and multiscale convolutions. This allows capturing both long-range dependencies along the spectral dimension and local patterns/textures in the spatial dimensions. Other papers have used CNNs, transformers or a combination, but the specific design here of mixing spectral self-attention and lightweight inception modules is novel.

- The overall approach achieves state-of-the-art results on benchmark datasets while using fewer parameters compared to recent competing methods. The extensive experiments validate the benefits of the proposed residual modeling, network architecture and individual components through ablations.

- One limitation compared to some other works is that it relies on training with simulated data and performance on real captured data is not as strong. Addressing the simulation-to-real gap remains an open challenge.

Overall, the paper demonstrates solid improvements over prior arts by innovative network design choices and training strategies tailored for hyperspectral reconstruction. The residual modeling via deep unfolding is an interesting technique for better integrating model-based ideas into learning frameworks.
