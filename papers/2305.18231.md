# [High-Fidelity Image Compression with Score-based Generative Models](https://arxiv.org/abs/2305.18231)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be whether score-based generative models like diffusion models can match or exceed the performance of GANs for the task of learned image compression, especially at high resolutions. The key hypotheses appear to be:1) A simple but theoretically motivated two-stage approach combining an MSE autoencoder with a score-based generative model can achieve state-of-the-art perceptual quality in terms of FID score while maintaining low bitrates.2) Diffusion models can significantly improve perceptual quality compared to recent GAN-based compression methods like HiFiC and PO-ELIC, if properly tuned for the compression task. 3) Details like the noise schedule and sampling procedure are very important for getting good performance with diffusion models in compression. In particular, less noise and more emphasis on fine details is beneficial compared to settings used in other domains like text-to-image generation.4) While computationally more expensive, diffusion models can surpass recent state-of-the-art in terms of the rate-distortion tradeoff if enough sampling steps are used. With fewer steps, rectified flows perform better but are eventually overtaken.The core aim seems to be demonstrating the potential of score-based generative models in the compression domain through both theoretical motivation and empirical results, challenging the notion that GANs are superior for this application.
