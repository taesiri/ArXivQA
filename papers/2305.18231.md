# [High-Fidelity Image Compression with Score-based Generative Models](https://arxiv.org/abs/2305.18231)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be whether score-based generative models like diffusion models can match or exceed the performance of GANs for the task of learned image compression, especially at high resolutions. The key hypotheses appear to be:1) A simple but theoretically motivated two-stage approach combining an MSE autoencoder with a score-based generative model can achieve state-of-the-art perceptual quality in terms of FID score while maintaining low bitrates.2) Diffusion models can significantly improve perceptual quality compared to recent GAN-based compression methods like HiFiC and PO-ELIC, if properly tuned for the compression task. 3) Details like the noise schedule and sampling procedure are very important for getting good performance with diffusion models in compression. In particular, less noise and more emphasis on fine details is beneficial compared to settings used in other domains like text-to-image generation.4) While computationally more expensive, diffusion models can surpass recent state-of-the-art in terms of the rate-distortion tradeoff if enough sampling steps are used. With fewer steps, rectified flows perform better but are eventually overtaken.The core aim seems to be demonstrating the potential of score-based generative models in the compression domain through both theoretical motivation and empirical results, challenging the notion that GANs are superior for this application.


## What is the main contribution of this paper?

This paper presents a new method for high-fidelity image compression using score-based generative models. The main contributions are:- They propose a two-stage approach combining an autoencoder optimized for MSE with a diffusion model or rectified flow to generate realistic details. This improves perceptual quality compared to just using the MSE autoencoder.- They adapt diffusion models for compression by using a shifted noise schedule focused on details rather than global structure. This is different from how diffusion is used in text-to-image models.- They achieve state-of-the-art performance on the CLIC and COCO datasets in terms of the rate-FID tradeoff, outperforming recent GAN-based compression methods. - They explore implementation details like noise levels during sampling and parallel patch-based generation to make diffusion viable for high resolution images.- They highlight challenges like denoising effects and distortion vs realism tradeoffs faced when optimizing for perceptual metrics like FID.In summary, the main contribution is demonstrating that diffusion models can achieve excellent perceptual quality for image compression when properly adapted to this domain, outperforming GANs which currently dominate learned compression. The theoretical analysis and practical insights around making diffusion work are also valuable.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper: The paper proposes a two-stage image compression approach combining a standard autoencoder with a diffusion-based generative model to achieve improved perceptual quality and realism compared to previous methods.
