# [How Human-Centered Explainable AI Interface Are Designed and Evaluated:   A Systematic Survey](https://arxiv.org/abs/2403.14496)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Despite major advances in explainable AI (XAI) algorithms, current XAI systems still lack usability, practical interpretability and efficacy for real users. There is a gap between technically sound XAI algorithms and producing effective explanations that users can understand and use. 

Proposed Solution: 
The emerging research area of explainable interfaces (EIs) focuses specifically on the user interface and user experience design aspects of XAI. EIs aim to bridge the gap between algorithmic explanations and users by researching how to best present the explanations to users.

The paper conducts a systematic literature review of 53 publications on EI research to understand: 
1) How researchers currently involve users in XAI system design and evaluation
2) How EIs are designed, specifically the information architecture and interactivity
3) How EIs are evaluated using different metrics

Main Contributions:

- One of the first systematic surveys focusing specifically on EI research
- Found that majority of XAI papers only involve users to evaluate finished XAI prototypes rather than conducting user research to understand user needs early on
- Identified 8 key properties used to describe EI designs and evaluations: activities, participant groups, required features, visual hierarchy, information architecture, interactivity, evaluation metrics, metric types
- Discovered that common practices are: sequential information architecture, instructing interaction, system desiderata metrics 
- Proposed directions: more user research upfront, increased EI interactivity, targeted EI evaluations

In summary, the paper surveyed existing work at the intersection of XAI and HCI, analyzed the gap between algorithmic explanations and users, revealed current practices and limitations of EIs, and highlighted future opportunities to improve EI designs to meet user needs.
