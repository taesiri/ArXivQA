# Self-Polish: Enhance Reasoning in Large Language Models via Problem   Refinement

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to enhance the reasoning capabilities of large language models when facing low-quality problems. Specifically, the paper proposes and evaluates a novel method called Self-Polish that facilitates language models' problem-solving process by prompting them to progressively refine the given problems to be more comprehensible and solvable. The key hypothesis is that refining problems into a better formulation will improve the reasoning performance of language models.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a method called Self-Polish (SP) to improve the reasoning abilities of large language models. Specifically:- The key idea is to refine the given reasoning problems to make them easier for language models to comprehend and solve. This involves eliminating irrelevant information, rearranging logic, and reorganizing conditions. - The method teaches language models to progressively refine problems through demonstrations of problem rewriting. It leverages models' in-context learning ability to acquire these skills.- Self-Polish is orthogonal to other prompting methods like chain-of-thought or self-consistency, so it can be conveniently combined with them for further improvements.- Experiments show Self-Polish boosts reasoning performance across multiple models and datasets, especially on more challenging tasks. It also improves robustness against irrelevant information.- The method provides a new direction of enhancing language models' reasoning skills by facilitating their processing of problems, rather than just optimizing the generation of rationales and answers.In summary, the key contribution is proposing Self-Polish, a novel prompting method to refine reasoning problems to make them more comprehensible for language models, consequently improving reasoning performance and robustness. The idea of refining problems is an underexplored way of enhancing language models' reasoning abilities.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a novel method called Self-Polish that improves the reasoning capabilities of large language models by recursively refining the given reasoning problems to make them more comprehensible and solvable before having the model solve them.
