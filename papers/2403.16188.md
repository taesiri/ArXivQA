# [Cross-domain Multi-modal Few-shot Object Detection via Rich Text](https://arxiv.org/abs/2403.16188)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
The paper studies the problem of cross-domain multi-modal few-shot object detection (CDMM-FSOD). In this setting, a model is trained on abundant data from base classes and then needs to detect objects from novel classes where only a few labeled examples are available per class. Furthermore, there is a significant domain shift between the base and novel classes, making the task more challenging. Existing models suffer performance degradation in such scenarios.

Proposed Solution:
The paper proposes a meta-learning based multi-modal few-shot detection method that utilizes rich text descriptions as an auxiliary modality to help mitigate the domain gap. Specifically:

1) They introduce manually defined or LLM-generated rich text descriptions for each category that contain technical details related to appearance. 

2) A multi-modal feature aggregation module aligns the image and text embeddings of the support set in an episode during meta-training.

3) A rich text semantic rectification module enforces bi-directional generation and alignment of text embeddings to reinforce language understanding.

Together, these components enable more effective fusion of information across vision and language modalities to improve few-shot detection despite distribution shifts.

Main Contributions:
- Proposes and formulates the novel CDMM-FSOD problem setting.
- Develops a meta-learning framework with multi-modal feature aggregation using rich text to address this problem. 
- Demonstrates state-of-the-art performance on multiple cross-domain detection benchmarks compared to existing methods.
- Provides analysis investigating the impact of rich text semantics on performance.

The key insight is that carefully designed rich text can act as an indispensable auxiliary modality to enhance few-shot detection abilities for out-of-domain data.
