# [Fairness-aware Agnostic Federated Learning](https://arxiv.org/abs/2010.05057)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How to achieve fairness in federated learning when the testing data distribution is unknown or different from the training data distribution?The key points are:- In federated learning, the training data is distributed across multiple devices/clients. This can lead to differences in data distributions between clients (non-IID data).- Most prior work on federated learning focuses on privacy protection and communication efficiency, but achieving fairness is less explored.- Fairness constraints on the centralized model using just the training data cannot guarantee fairness on unknown testing data. - The paper proposes a fairness-aware agnostic federated learning framework (AgnosticFair) to deal with unknown testing distributions. The main hypothesis is that by using kernel reweighing functions in the loss function and fairness constraints, the model trained with AgnosticFair can achieve high accuracy and fairness guarantees even when the testing distribution is unknown.In summary, the key research question is how to achieve fairness in federated learning under unknown testing data distributions. The proposed approach is AgnosticFair which uses kernel reweighing to make the model robust to unknown distributions.


## What is the main contribution of this paper?

The main contribution of this paper is proposing a framework for fairness-aware federated learning that can handle unknown testing data distributions. Specifically:- It proposes an agnostic federated learning approach that uses kernel reweighting functions to make the loss function and fairness constraints robust to unknown shifts between training and testing distributions. - It formulates the problem as a two-player adversarial minimax game between a learner that minimizes the loss and an adversary that tries to maximize the loss by generating the worst-case testing distribution.- It develops an efficient optimization method where clients optimize model parameters and the server optimizes reweighting coefficients. This allows training a global model with fairness guarantees without exposing raw client data.- It conducts experiments on real datasets that demonstrate the approach can achieve higher accuracy and fairness under distribution shift compared to standard federated learning and other baselines.In summary, the key novelty is developing a federated learning framework that can provide fairness guarantees even when the testing distribution is unknown or different from the client training distributions. This is an important contribution as prior federated learning research has not addressed fairness under such distribution shift.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a fairness-aware agnostic federated learning framework to achieve high accuracy and fairness guarantees on unknown testing data distributions by using kernel reweighing functions and formulating the problem as a minimax game between the learner and an adversary.


## How does this paper compare to other research in the same field?

Here are some key points comparing this paper on fairness-aware agnostic federated learning to other related work:- Most prior work on federated learning focuses on privacy protection and communication efficiency, while fairness under distribution shift is relatively underexplored. This paper tackles the important but challenging problem of achieving fairness with unknown testing data distributions.- The idea of using kernel reweighting functions to make the loss and fairness constraints agnostic to distribution shift is novel. This allows the model to achieve good accuracy and fairness on new data. - Formulating it as a two-player minimax game between the learner and an adversary is an interesting approach to optimizing for robustness to unknown distributions.- The algorithm design to have clients optimize model parameters and the server optimize reweighting coefficients preserving privacy is clean.- Extensive experiments on real datasets demonstrate the effectiveness under distribution shift. The comparisons to algorithms like standard federated learning and Mohri et al.'s agnostic learning validate the benefits.- The problem formulation and approach are general and could be applied to centralized fairness learning with train-test distribution mismatch.In summary, this paper makes important contributions in adapting federated learning to the challenging but practical scenario of unknown testing distributions, in order to achieve both utility and fairness. The novel techniques and solid experimental results help advance the state of the art.
