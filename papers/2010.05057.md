# [Fairness-aware Agnostic Federated Learning](https://arxiv.org/abs/2010.05057)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How to achieve fairness in federated learning when the testing data distribution is unknown or different from the training data distribution?

The key points are:

- In federated learning, the training data is distributed across multiple devices/clients. This can lead to differences in data distributions between clients (non-IID data).

- Most prior work on federated learning focuses on privacy protection and communication efficiency, but achieving fairness is less explored.

- Fairness constraints on the centralized model using just the training data cannot guarantee fairness on unknown testing data. 

- The paper proposes a fairness-aware agnostic federated learning framework (AgnosticFair) to deal with unknown testing distributions. 

The main hypothesis is that by using kernel reweighing functions in the loss function and fairness constraints, the model trained with AgnosticFair can achieve high accuracy and fairness guarantees even when the testing distribution is unknown.

In summary, the key research question is how to achieve fairness in federated learning under unknown testing data distributions. The proposed approach is AgnosticFair which uses kernel reweighing to make the model robust to unknown distributions.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a framework for fairness-aware federated learning that can handle unknown testing data distributions. Specifically:

- It proposes an agnostic federated learning approach that uses kernel reweighting functions to make the loss function and fairness constraints robust to unknown shifts between training and testing distributions. 

- It formulates the problem as a two-player adversarial minimax game between a learner that minimizes the loss and an adversary that tries to maximize the loss by generating the worst-case testing distribution.

- It develops an efficient optimization method where clients optimize model parameters and the server optimizes reweighting coefficients. This allows training a global model with fairness guarantees without exposing raw client data.

- It conducts experiments on real datasets that demonstrate the approach can achieve higher accuracy and fairness under distribution shift compared to standard federated learning and other baselines.

In summary, the key novelty is developing a federated learning framework that can provide fairness guarantees even when the testing distribution is unknown or different from the client training distributions. This is an important contribution as prior federated learning research has not addressed fairness under such distribution shift.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a fairness-aware agnostic federated learning framework to achieve high accuracy and fairness guarantees on unknown testing data distributions by using kernel reweighing functions and formulating the problem as a minimax game between the learner and an adversary.


## How does this paper compare to other research in the same field?

 Here are some key points comparing this paper on fairness-aware agnostic federated learning to other related work:

- Most prior work on federated learning focuses on privacy protection and communication efficiency, while fairness under distribution shift is relatively underexplored. This paper tackles the important but challenging problem of achieving fairness with unknown testing data distributions.

- The idea of using kernel reweighting functions to make the loss and fairness constraints agnostic to distribution shift is novel. This allows the model to achieve good accuracy and fairness on new data. 

- Formulating it as a two-player minimax game between the learner and an adversary is an interesting approach to optimizing for robustness to unknown distributions.

- The algorithm design to have clients optimize model parameters and the server optimize reweighting coefficients preserving privacy is clean.

- Extensive experiments on real datasets demonstrate the effectiveness under distribution shift. The comparisons to algorithms like standard federated learning and Mohri et al.'s agnostic learning validate the benefits.

- The problem formulation and approach are general and could be applied to centralized fairness learning with train-test distribution mismatch.

In summary, this paper makes important contributions in adapting federated learning to the challenging but practical scenario of unknown testing distributions, in order to achieve both utility and fairness. The novel techniques and solid experimental results help advance the state of the art.


## What future research directions do the authors suggest?

 Based on my reading of the paper, here are some of the future research directions suggested by the authors:

- Extend their framework to cover other commonly used fairness notions beyond demographic parity, such as equalized odds and equalized opportunity. The authors mention that the indicator functions used in some fairness notions pose challenges that could be addressed by incorporating surrogate functions.

- Study different kernel function parameterizations beyond the Gaussian kernels used in this work. The choice of kernel functions and their basis could impact the modeling of unknown testing distributions.

- Adapt their proposed framework for centralized fairness-aware learning where training and testing data differ. The authors state their approach could be useful in this centralized setting as well. 

- Apply their framework to fair transfer learning, where distribution shift typically exists between source and target domains. The ability to handle unknown distributions could be beneficial here.

- Evaluate their method on more complex models beyond logistic regression, such as neural networks. The authors use logistic regression in their experiments but their general framework could extend to other models.

- Consider more sophisticated optimization methods or approximations when solving the minimax optimization problem. The authors use alternating optimization and linear programming here but other techniques may be useful.

- Examine the theoretical properties of their framework such as convergence guarantees, sample complexity, etc. The empirical results are promising but formal theoretical analysis would strengthen the approach.

In summary, the authors propose several interesting extensions of their fairness-aware federated learning framework to handle broader fairness notions, optimization methods, models, and applications. Formal theoretical analysis is also suggested as future work.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper proposes a fairness-aware agnostic federated learning framework (AgnosticFair) to handle unknown testing data distributions in federated learning settings. The key idea is to formulate the problem as a two-player adversarial minimax game between the learner and an adversary. The adversary aims to generate any possible unknown testing distribution to maximize the classifier loss, while the learner tries to find model parameters that minimize the worst-case loss over these unknown distributions. To achieve this, the framework assigns an individual reweighing value to each training sample using kernel functions and incorporates these in both the agnostic loss function and agnostic fairness constraints. As a result, the learned global model achieves high accuracy and fairness guarantees on unknown testing data. The framework enables optimization of the loss and constraints collaboratively between clients and a central server without exposing raw data. Experiments on two datasets demonstrate that this approach is effective in providing fair and accurate predictions under data distribution shifts between training and testing.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper proposes a fairness-aware agnostic federated learning framework (AgnosticFair) to handle unknown testing data distributions in federated learning. In federated learning, the training data is distributed across multiple clients and the testing data distribution is often different from the training data. Introducing fairness constraints on the global model cannot achieve fairness on the unknown testing data. To address this, the authors formulate AgnosticFair as a two-player minimax game between the learner and an adversary. The adversary aims to generate any possible testing distribution to maximize the classifier loss, while the learner tries to find model parameters that minimize the worst-case loss over unknown testing distributions produced by the adversary. The authors assign individual reweighting values to each training sample using kernel functions and incorporate these in both the agnostic loss and fairness constraint. As a result, the learned global model achieves high accuracy and fairness guarantee on unknown testing data. Moreover, the model can be directly deployed at each client as it guarantees fairness on local data distributions. Experiments on two datasets demonstrate the effectiveness of AgnosticFair in improving utility and fairness under data distribution shift scenarios compared to baselines.

In summary, this paper proposes a novel fairness-aware agnostic federated learning approach to handle unknown testing data distributions. It formulates a minimax game between a learner and adversary to learn a global model robust to any testing distribution. Reweighting individual training samples allows optimizing both accuracy and fairness under distribution shift. Experiments validate the benefits of the approach.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes a fairness-aware agnostic federated learning framework (AgnosticFair) to handle unknown testing data distributions in federated learning. It formulates the problem as a two-player adversarial minimax game between the learner and an adversary. The adversary aims to generate any possible unknown testing distribution to maximize the classifier loss, while the learner tries to find model parameters that minimize the worst-case loss over these unknown distributions. To achieve this, the method assigns individual reweighting values to each training sample using kernel functions. These reweighting values are incorporated into both the agnostic loss function and the agnostic fairness constraint. By optimizing this loss and constraint through an iterative process between the clients and server, the resulting global model achieves high accuracy and fairness guarantee on unknown testing data distributions. The key innovation is using kernel reweighing functions to make both the loss and fairness constraint robust to unknown distribution shifts.


## What problem or question is the paper addressing?

 Based on my reading of the paper, the key problem it is addressing is how to achieve fairness in federated learning when the testing data distribution is unknown or different from the training data distribution. 

The key challenges it highlights with achieving fairness in federated learning are:

- The training data at different clients can have different distributions (non-IID data). This makes it hard to guarantee fairness just based on constraints applied to the training data.

- The testing data distribution is often unknown or different from the aggregated training data distribution. So fairness constraints applied on training data do not translate to fairness on testing data.

To address these challenges, the paper proposes a new fairness-aware agnostic federated learning framework called AgnosticFair. The key idea is to use kernel reweighing functions to make both the loss function and fairness constraint robust to unknown shifts in data distribution. This allows the model to achieve high accuracy and fairness guarantees even when tested on new data distributions.

In summary, the key question addressed is how to achieve fair machine learning models in federated learning settings where training and testing distributions can be very different across clients. The paper proposes a new learning framework called AgnosticFair to achieve robustness to such distribution shifts.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper abstract and introduction, here are some key terms and concepts related to this paper:

- Federated learning - This paper focuses on federated learning, which is a distributed machine learning approach that enables model training on decentralized data located on devices like mobile phones.

- Fairness - The paper aims to achieve fairness in federated learning models, especially when the testing data distribution is different from the training distribution. 

- Agnostic learning - The paper proposes an "agnostic federated learning" framework to deal with unknown testing distributions and achieve fairness guarantees.

- Distribution shift - A key challenge is that differences in data distributions across devices can lead to unfairness when applying a global model locally. The paper handles this distribution shift.

- Kernel reweighing - The method assigns reweighing values to training samples using kernel functions to make the loss and fairness constraints robust to distribution shifts.

- Robust optimization - The learning is formulated as a robust optimization problem, a two player minimax game between the learner and an adversary.

- Demographic parity - One notion of fairness used is demographic parity, requiring model predictions to be independent of sensitive attributes like gender.

- Decision boundary fairness - An alternative fairness notion based on the covariance between sensitive attributes and the decision boundary.

In summary, the key focus is on achieving fairness guarantees in federated learning under challenging data distribution shifts across devices, using robust optimization and kernel reweighing techniques.
