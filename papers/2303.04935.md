# [X-Pruner: eXplainable Pruning for Vision Transformers](https://arxiv.org/abs/2303.04935)

## What is the central research question or hypothesis that this paper addresses?

The central research question addressed in this paper is how to develop an explainable pruning framework for vision transformers that can identify and remove redundant parameters while preserving model accuracy. Specifically, the paper proposes a novel pruning method called X-Pruner that aims to quantify and prune less important parameters in transformers based on "explainability", i.e. their contribution to predicting target classes. The key ideas include:- Proposing an explainability-aware mask to measure each prunable unit's (e.g. attention heads, weight matrices) contribution to identifying each class. This allows capturing importance at a class-specific level.- Learning the masks and layer-wise pruning thresholds in an end-to-end differentiable manner, instead of using separate criteria. This enables directly optimizing for a resource constraint.- Pruning units based on the learned explainability masks and thresholds. This provides an explainable way to identify redundant parameters to prune while preserving accuracy.In summary, the central hypothesis is that an explainability-driven structured pruning approach can effectively remove redundant parameters in transformers while maintaining accuracy better than prior black-box pruning techniques. The X-Pruner framework is proposed to achieve this.


## What is the main contribution of this paper?

The main contributions of this paper are:- It proposes a novel explainable structured pruning framework called X-Pruner for vision transformer models. - It introduces an explainability-aware mask to quantify each prunable unit's contribution to predicting each class. This mask is differentiable and learned in an end-to-end manner.- It proposes a differentiable pruning operation along with a threshold regularizer to automatically learn layer-wise pruning thresholds and rates. - The pruning is done in an explainable manner by removing units that contribute less to identifying all classes based on the explainability-aware masks.- Comprehensive experiments show that X-Pruner outperforms state-of-the-art pruning methods on vision transformers like DeiT and Swin Transformer, with reduced computational costs and slight accuracy drops.In summary, the key contribution is the propose of an explainable pruning framework X-Pruner that leverages explainability-aware masks and pruning to effectively compress vision transformers in an explainable manner.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a novel explainable pruning framework called X-Pruner for vision transformers, which learns an explainability-aware mask to evaluate each unit's contribution to predicting classes and automatically determines layer-wise pruning rates to remove less important units and compact model size while preserving performance.
