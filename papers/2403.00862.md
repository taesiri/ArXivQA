# [NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and   Safety Adherence in Chinese Journalistic Editorial Applications](https://arxiv.org/abs/2403.00862)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key aspects of the paper:

Problem: There is a lack of standardized benchmarks to systematically evaluate the capabilities and risks of large language models (LLMs) in producing journalistic content that complies with media ethics and safety standards. This limits the responsible adoption of LLMs in journalistic applications.

Proposed Solution: The paper introduces NewsBench, a comprehensive benchmark framework to evaluate LLMs' Chinese journalistic writing proficiency and safety adherence across diverse editorial applications (headline generation, summarization, continuation writing, expansion writing, style refinement), aspects (4 writing quality facets and 6 safety facets), and news domains.

Key Components:
- 1267 Chinese testing tasks spanning multiple formats (open-ended generation and multiple-choice) 
- Automatic evaluation protocols using GPT-4 models, validated via human assessment
- Analysis of 11 LLMs highlighting strengths and weaknesses in writing quality and safety

Main Contributions:
- Developed the first tailored benchmark for systematically assessing Chinese LLMs in journalism 
- Identified top models GPT-4 and ERNIE Bot, while uncovering deficiencies in ethical adherence
- Offered recommendations to enhance LLMs' news writing abilities and align them with journalistic responsibilities  

The paper makes an important step towards promoting the safe, ethical and effective integration of LLMs into news workflows through comprehensive capability and risk evaluation.
