# [Patches Are All You Need?](https://arxiv.org/abs/2201.09792)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is whether the strong performance of vision transformers like ViT may result more from using patch embeddings as the input representation, rather than the transformer architecture itself. The paper proposes that the use of patch embeddings, which split the image into patches and embed them, may be a critical factor behind the performance of newer architectures like ViT. The authors develop a very simple convolutional architecture called ConvMixer that operates directly on patches like ViT, but uses only standard convolutions instead of attention. The main result is that despite its simplicity, ConvMixer outperforms ViT, MLP-Mixer, and some variants on similar data regimes, in addition to outperforming classical CNNs like ResNet. This suggests the patch representation itself, rather than novel operations like self-attention, may drive much of the performance of these new architectures.In summary, the central hypothesis is that the use of patch embeddings is critical to the strong performance of vision transformers, more so than the transformer architecture. The ConvMixer architecture is proposed to test this idea. Its competitive performance helps demonstrate the importance of the patch representation.


## What is the main contribution of this paper?

The main contribution of this paper is proposing the ConvMixer architecture, which is a very simple convolutional neural network that operates directly on image patches and maintains a constant feature map size throughout the network. The key aspects of ConvMixer are:- It uses a convolutional patch embedding layer to split the input image into patches. This is similar to how ViT/vision transformers use patch embeddings.- It then applies a series of blocks consisting of a depthwise convolution followed by a pointwise convolution. The depthwise convolution mixes information across spatial dimensions while the pointwise convolution mixes information across channels. - It maintains the same feature map size throughout the network, unlike standard convolutional networks that progressively downsample. This is more similar to transformer architectures.- It achieves strong performance on ImageNet classification compared to Vision Transformers, MLP-Mixers, and ResNets while using only standard convolutional operations. The simplicity of ConvMixer suggests the patch representation itself may be an important factor in the performance of recent architectures.In summary, the main contribution is proposing ConvMixer as an extremely simple but competitive convolutional architecture that operates directly on image patches, in order to provide evidence that the patch representation may be a key factor behind recent advances in computer vision models. The simplicity of ConvMixer combined with its strong performance highlights the potential of the patch-based design paradigm.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes ConvMixer, an extremely simple convolutional neural network architecture that operates directly on image patches and achieves strong performance on ImageNet classification, outperforming Vision Transformers and MLP-Mixers of comparable size despite using only standard convolutions.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper on the ConvMixer model compares to other related research:- It focuses on investigating whether the performance of vision Transformers like ViT is more due to the Transformer architecture or the patch embedding input representation. To test this, it proposes a very simple convolutional architecture called ConvMixer that operates directly on image patches.- Unlike many other papers that introduce new vision architectures, this paper does not aim to achieve state-of-the-art results by heavily tuning hyperparameters or adding modifications. Instead, it aims to provide a simple but competitive baseline.- Compared to other convolutional architectures like ResNets, the ConvMixer separates channel mixing and spatial mixing into different steps. It is similar to other "MLP-like" models such as the MLP-Mixer and ResMLP in this regard.- The ConvMixer achieves strong performance compared to ResNets and transformer models like ViT and MLP-Mixer, despite its simplicity. This provides evidence that the patch embedding approach is an important factor in recent model improvements.- The paper compares ConvMixer mainly to other basic patch-based models (ViT, MLP-Mixer, ResMLP). It does not focus as much on comparisons to state-of-the-art convolutional models or Transformers.- Unlike some other works, this paper does not propose any major changes to the training methodology or hyperparameters used. The goal is to evaluate the model architecture itself.In summary, this paper provides a simplified patch-based baseline and investigates the impact of using image patches rather than novel model operations like self-attention. The results suggest patch embeddings play an important role separate from the choice of mixers.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Investigating the performance of ConvMixers with large-scale pre-training. The authors note that Transformers and MLP-Mixers excel when trained on very large datasets, so it would be useful to explore how ConvMixers perform in this regime.- Tuning hyperparameters and optimizing ConvMixers more extensively. The authors did limited tuning for their experiments, so more work could likely improve accuracy and throughput.- Adapting ConvMixers for semantic segmentation tasks. The authors suggest the isotropic design may be well suited for segmentation.- Adding enhancements like bottlenecks or a more expressive classifier to trade simplicity for potential performance gains.- Comparing ConvMixers more directly to ViTs/MLP-Mixers by controlling for differences like patch size. This could better isolate the effect of the patch representation.- Investigating if the performance trends hold across different model sizes, datasets, and computer vision tasks. The current results are just an initial snapshot.- Exploring the effect of different design choices like normalization layers or residual connections in ConvMixers.- Further analysis of the learned representations and kernels to better understand how ConvMixers work internally.In summary, the main suggested directions are around scaling up experiments, optimizing implementations, adapting the architecture, and additional ablation studies to better understand the interplay of different design factors. The authors propose ConvMixer as a strong but simple baseline for further research on patch-based models.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper proposes ConvMixer, a simple convolutional neural network architecture for image classification. ConvMixer operates directly on image patches like recent Vision Transformer (ViT) models. The model first splits the input image into patches using a convolutional patch embedding layer. Then it applies a series of ConvMixer blocks, each consisting of a depthwise convolutional layer for spatial mixing followed by a pointwise convolutional layer for channel mixing. A key design choice is the use of large kernel sizes in the depthwise convolutional layers, allowing the model to mix information between distant spatial locations similar to self-attention in ViTs. Despite its simplicity, ConvMixer achieves strong performance on ImageNet, outperforming Vision Transformers, MLP-Mixers, and ResNets while using fewer parameters and without any pretraining. The results suggest the patch representation itself, rather than novel operations like self-attention, may be critical to ViTs' strong performance. Overall, the paper proposes a very simple but competitive convolutional architecture highlighting the power of the patch-based design.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:This paper proposes the ConvMixer, a simple convolutional neural network architecture for computer vision. The ConvMixer operates directly on image patches like the Vision Transformer (ViT), maintaining an equal-sized representation throughout the network without any downsampling. It separates "channel mixing" from "spatial mixing" using two types of convolutional layers: depthwise convolution to mix spatial information across patches, and pointwise convolution to mix channel information. Despite its simplicity, the ConvMixer achieves strong performance on ImageNet, outperforming ViT, MLP-Mixer, and ResNet models with similar numbers of parameters. On CIFAR-10, it achieves over 96% accuracy with under 1 million parameters, demonstrating the efficiency of convolutional architectures. The authors argue that the competitive performance of the ConvMixer, compared to more complex self-attention and MLP-based models, suggests that the patch embedding itself provides a substantial boost, and convolutions can effectively mix information across patches. They propose the ConvMixer as a strong but conceptually simple baseline for future research on patch-based architectures.
