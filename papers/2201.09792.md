# [Patches Are All You Need?](https://arxiv.org/abs/2201.09792)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is whether the strong performance of vision transformers like ViT may result more from using patch embeddings as the input representation, rather than the transformer architecture itself. The paper proposes that the use of patch embeddings, which split the image into patches and embed them, may be a critical factor behind the performance of newer architectures like ViT. The authors develop a very simple convolutional architecture called ConvMixer that operates directly on patches like ViT, but uses only standard convolutions instead of attention. The main result is that despite its simplicity, ConvMixer outperforms ViT, MLP-Mixer, and some variants on similar data regimes, in addition to outperforming classical CNNs like ResNet. This suggests the patch representation itself, rather than novel operations like self-attention, may drive much of the performance of these new architectures.In summary, the central hypothesis is that the use of patch embeddings is critical to the strong performance of vision transformers, more so than the transformer architecture. The ConvMixer architecture is proposed to test this idea. Its competitive performance helps demonstrate the importance of the patch representation.


## What is the main contribution of this paper?

The main contribution of this paper is proposing the ConvMixer architecture, which is a very simple convolutional neural network that operates directly on image patches and maintains a constant feature map size throughout the network. The key aspects of ConvMixer are:- It uses a convolutional patch embedding layer to split the input image into patches. This is similar to how ViT/vision transformers use patch embeddings.- It then applies a series of blocks consisting of a depthwise convolution followed by a pointwise convolution. The depthwise convolution mixes information across spatial dimensions while the pointwise convolution mixes information across channels. - It maintains the same feature map size throughout the network, unlike standard convolutional networks that progressively downsample. This is more similar to transformer architectures.- It achieves strong performance on ImageNet classification compared to Vision Transformers, MLP-Mixers, and ResNets while using only standard convolutional operations. The simplicity of ConvMixer suggests the patch representation itself may be an important factor in the performance of recent architectures.In summary, the main contribution is proposing ConvMixer as an extremely simple but competitive convolutional architecture that operates directly on image patches, in order to provide evidence that the patch representation may be a key factor behind recent advances in computer vision models. The simplicity of ConvMixer combined with its strong performance highlights the potential of the patch-based design paradigm.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes ConvMixer, an extremely simple convolutional neural network architecture that operates directly on image patches and achieves strong performance on ImageNet classification, outperforming Vision Transformers and MLP-Mixers of comparable size despite using only standard convolutions.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper on the ConvMixer model compares to other related research:- It focuses on investigating whether the performance of vision Transformers like ViT is more due to the Transformer architecture or the patch embedding input representation. To test this, it proposes a very simple convolutional architecture called ConvMixer that operates directly on image patches.- Unlike many other papers that introduce new vision architectures, this paper does not aim to achieve state-of-the-art results by heavily tuning hyperparameters or adding modifications. Instead, it aims to provide a simple but competitive baseline.- Compared to other convolutional architectures like ResNets, the ConvMixer separates channel mixing and spatial mixing into different steps. It is similar to other "MLP-like" models such as the MLP-Mixer and ResMLP in this regard.- The ConvMixer achieves strong performance compared to ResNets and transformer models like ViT and MLP-Mixer, despite its simplicity. This provides evidence that the patch embedding approach is an important factor in recent model improvements.- The paper compares ConvMixer mainly to other basic patch-based models (ViT, MLP-Mixer, ResMLP). It does not focus as much on comparisons to state-of-the-art convolutional models or Transformers.- Unlike some other works, this paper does not propose any major changes to the training methodology or hyperparameters used. The goal is to evaluate the model architecture itself.In summary, this paper provides a simplified patch-based baseline and investigates the impact of using image patches rather than novel model operations like self-attention. The results suggest patch embeddings play an important role separate from the choice of mixers.
