# [Exploring Spatial Schema Intuitions in Large Language and Vision Models](https://arxiv.org/abs/2402.00956)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like GPT-3 excel at many NLP tasks but their lack of embodiment raises questions about whether they capture implicit human intuitions about spatial concepts that come from sensory-motor experience. 

- Image schemas are fundamental spatial building blocks of cognition learned early in life through physical interaction. They structure abstract thought and language (e.g. "feel down"). 

- Do LLMs encode people's spatial intuitions about the image schematic basis of words/phrases despite lacking grounded, embodied experience?

Method:
- Reproduce 3 psycho-linguistic experiments connecting language to spatial cognition using LLMs (GPT-3, GPT-4), vision-language models (GPT-4 Vision), and open-source models (LLaMA, IDEFICS).

- Compare model ratings/choices to human responses in experiments testing intuitions about:
   1) Image schemas underlying "stand" 
   2) Image schemas underlying "on"
   3) Directionality of verbs

- Evaluate using Spearman correlation between model and human responses.

Results:
- Moderate to high correlations in largest models' responses and humans' even without grounded experience.
- Smaller models and open-source models show lower correlations.  
- Differences remain: LLMs give more polarized ratings, don't compare relative ratings of phrases.
- Vision models show no/low correlations.

Contributions:
- First computational reproduction of experiments on spatial language cognition
- Evidence LLMs partially capture human spatial intuitions despite no direct embodiment
- Better understanding of relationship between language, spatial experience, and computations in LLMs

Limitations:
- Reliance on proprietary models with opaque mechanisms
- Training data may have included original papers
- Small historical sample sizes 

Impact:
- Environmental costs estimated
- Considerations for use of LLMs in cognition research
