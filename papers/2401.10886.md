# [SCENES: Subpixel Correspondence Estimation With Epipolar Supervision](https://arxiv.org/abs/2401.10886)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Extracting correspondences between images is an important computer vision task underlying pose estimation, structure-from-motion, etc. Recent learning-based methods achieve great performance but require strong supervision (ground-truth poses and depths) to train, limiting their ability to adapt to new domains where this supervision is unavailable.

Proposed Solution: 
The paper proposes a method called SCENES (Subpixel Correspondence Estimation with Epipolar Supervision) to adapt pretrained correspondence models to new domains using only pose supervision. It replaces correspondence losses with epipolar losses that encourage matches to lie on associated epipolar lines computed from relative poses. This supervision is weaker but still effective for finetuning. Two strategies are proposed:

1) Finetuning with pose supervision: Fundamental matrices are computed from ground-truth relative poses and used to compute epipolar losses to finetune the model.

2) Finetuning without supervision: A bootstrapping approach that uses epipolar losses based on fundamental matrices estimated from the matches of the pretrained model itself, removing all supervision needs.

Main Contributions:

- Epipolar losses that replace correspondence losses to enable finetuning with just pose supervision
- Strategies for finetuning with pose supervision or no supervision at all via bootstrapping
- Evaluation showing significant improvements on challenging indoor drone and outdoor phone camera datasets
- Enables adapting pretrained models to new domains without needing ground-truth poses or 3D structure

In summary, the key insight is that epipolar geometry provides a useful supervisory signal for finetuning correspondence models without needing full correspondence ground truth. This facilitates adaptation to new domains where collecting strong supervision is impractical.


## Summarize the paper in one sentence.

 This paper proposes epipolar losses to fine-tune keypoint matching models without correspondence supervision, using only camera poses or a bootstrapping approach, achieving state-of-the-art results on challenging datasets.


## What is the main contribution of this paper?

 Based on my analysis, the main contributions of this paper are:

1. Epipolar losses - drop-in replacements for existing matching losses that remove the need for strong correspondence supervision. Instead of requiring ground-truth correspondences for training, the epipolar losses only require the fundamental matrix relating two images, which can be estimated from camera poses.

2. Strategies for adapting pre-trained matching models to new domains using only pose supervision or no supervision. The paper presents two strategies: finetuning with pose supervision to compute fundamental matrices, and an unsupervised bootstrapping approach that estimates fundamental matrices from the matches of a pre-trained model.

In summary, the key innovation is the epipolar losses, which weaken the supervision requirements for finetuning correspondence estimation models. This enables domain adaptation to new datasets without ground-truth data. The main benefit is expanding the applicability of pretrained models by reducing annotation burdens.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with it are:

- Subpixel correspondence estimation - The main task focused on is estimating precise, subpixel-level correspondences between points in image pairs.

- Epipolar geometry - The paper leverages epipolar geometry constraints to supervise correspondence estimation without requiring ground truth matches. This includes concepts like epipolar lines, epipolar losses, and the fundamental matrix.

- Weak/self supervision - The methods rely on weak supervision in the form of camera poses or use a bootstrapping approach to self-supervise without any pose information. This allows adapting models to new datasets without strong annotations.

- Keypoint matching - The paper examines and improves upon recent transformer-based detector-free keypoint matching models like MatchFormer and LoFTR.

- Domain adaptation/dataset bias - A goal is to adapt pre-trained matching models to new testing domains with different data characteristics than the training data, reducing dataset bias. 

- Camera pose estimation - Correspondence quality is evaluated by the resulting accuracy on the downstream task of relative camera pose estimation.

Some other potentially relevant terms are fines-tuning, generalization, epipolar constraints, and unsupervised domain adaptation. But overall the key focus is using epipolar geometry to self-supervise correspondence estimation for domain adaptive keypoint matching.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes to use epipolar losses as a drop-in replacement for correspondence losses during training. However, the epipolar constraint is a weaker supervision signal. Does this mean the model will necessarily perform worse when trained only with epipolar losses compared to correspondence losses? Why or why not?

2. The paper demonstrates performance gains from finetuning with epipolar losses on new datasets. However, how much do you think performance could degrade on the original dataset that the model was pretrained on? Is there a risk of catastrophic forgetting? How could this be mitigated?

3. The epipolar classification loss selects the highest probability match that lies on the epipolar line as the "ground truth" match. Could this reinforce any existing biases in the pretrained model's predictions? How sensitive is performance to the precise location selected?

4. For the regression loss, taking the gradient of the epipolar distance results in a gradient vector that points in a slightly different direction than the gradient of the distance to the ground truth match. In what cases could this be more severely detrimental? When would we expect it to still provide a useful training signal?

5. The bootstrapping approach uses matches from the pretrained model to estimate fundamental matrices. However, incorrectly predicted matches could result in incorrect fundamental matrix estimates. How does the method ensure robustness to this? How many outlier matches can typically be tolerated?

6. The bootstrapping approach saw less significant gains on the San Francisco dataset compared to the EuRoC dataset. What differences between these datasets could account for this? How could the bootstrapping approach be made more robust to such dataset shifts?

7. The paper demonstrates compelling results by finetuning MatchFormer and ASpanFormer architectures. Do you expect similar performance gains when finetuning other transformer-based matching networks like LoFTR? What modifications would need to be made?

8. The method relies on rough camera pose estimates for training and testing. How accurately would these need to be for the approach to work effectively? What cues could fail if poses become too inaccurate? 

9. What other self-supervised signals beyond epipolar geometry could replace correspondence supervision for this task? For example, could photometric consistency or cycle consistency be viable alternatives? What would be the limitations?

10. The paper focuses on finetuning models pretrained on indoor Scannet data. Do you expect more or less significant gains when adapting models pretrained on diverse outdoor datasets like MegaDepth? What factors determine how well the method transfers?
