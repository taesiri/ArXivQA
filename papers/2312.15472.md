# [Towards Consistent Language Models Using Declarative Constraints](https://arxiv.org/abs/2312.15472)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) often provide incorrect and inconsistent answers to questions, due to inaccuracies and inconsistencies in their learned internal representations. 
- It is challenging to modify LLMs to provide correct results due to the complexity and lack of interpretability of their learned representations.

Proposed Solution:  
- Apply concepts from data management to reduce inconsistencies in LLMs using high-level declarative constraints expressed in ontologies.  
- Constraints specify properties and relationships between entities and concepts in a domain. 
- Use constraints for:
  - Learning more accurate representations in LLMs
  - Enforcing constraints during decoding to ensure consistent results
- Investigate applying methods from inconsistent data querying and data cleaning to prompt, query, and repair LLMs.

Main Contributions:
- Formalize the problem of augmenting LLMs with constraints as an optimization problem considering constraint satisfaction, quality, and efficiency.
- Conduct preliminary experiments adding lexical constraints in Llama-2 without fine-tuning. Identify tradeoffs between metrics for different constraint injection approaches.  
- Propose approaches to encode constraints when learning representations, use constraints during prompting and decoding, and repair inconsistent outputs.
- Highlight open challenges for integrating semantic constraints into LLMs, including finding correspondences between symbolic constraints and learned representations.

The key ideas are leveraging declarative constraints used in data management to reduce inconsistencies in LLMs, and investigating techniques to inject constraints across different stages of the LLM pipeline - representation learning, prompting, and decoding. Preliminary results validate the potential while highlighting the tradeoffs.
