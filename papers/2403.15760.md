# [An Upload-Efficient Scheme for Transferring Knowledge From a Server-Side   Pre-trained Generator to Clients in Heterogeneous Federated Learning](https://arxiv.org/abs/2403.15760)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Heterogeneous Federated Learning (HtFL) allows collaborative training of models with different architectures across clients while preserving privacy. However, sharing knowledge in HtFL is challenging due to data and model heterogeneity. Existing methods rely on a global dataset, an auxiliary model, or global prototypes, but they have limitations in relevance, efficiency, or prototype bias.  

Proposed Solution - Federated Knowledge-Transfer Loop (FedKTL):
The key idea is to leverage the knowledge stored in a public pre-trained generator on the server. Specifically:

(1) Unbiased Prototype Generation: Replace each client's classifier with an Equiangular Tight Frame (ETF) classifier to generate unbiased prototypes and upload to server.

(2) Domain Alignment: Design a lightweight trainable feature transformer on the server to convert prototypes to aligned latent vectors within the valid input domain of the generator. Apply MSE and MMD losses to preserve discrimination and align domains.

(3) Knowledge Transfer: Obtain class-wise latent centroids from aligned vectors to generate corresponding images. Form image-vector pairs for each class. Clients train on local data and conduct additional supervised task on pairs to transfer generator's knowledge into feature extractors.

Main Contributions:
(1) Propose FedKTL, an upload-efficient knowledge transfer framework for HtFL using a pre-trained generator's compact image-vector pairs.

(2) Introduce unbiased prototype generation via ETF and iterative domain alignment via trainable transformer to produce prototype-induced images tailored to clients' tasks.

(3) Exploit additional supervised task on image-vector pairs for knowledge transfer, reducing dependence on semantic relevance between generated and local images.

(4) Extensive experiments show FedKTL outperforms state-of-the-arts by up to 7.31% accuracy on four datasets and 14 model architectures. Demonstrate efficiency and applicability to single client scenario.
