# [Aligning Knowledge Graph with Visual Perception for Object-goal   Navigation](https://arxiv.org/abs/2402.18892)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Existing knowledge-graph-based navigators for object-goal navigation often rely on discrete categorical representations and vote counting strategies to construct graph representations of scenes. This leads to a misalignment between the graph representations and actual visual observations, limiting performance and accuracy. 

Proposed Solution:
The paper proposes a new method called Aligning Knowledge Graph with Visual Perception (AKGVP) to address this limitation. The key ideas are:

1) Introduce continuous modeling of the hierarchical scene architecture using spatial location clustering and graph definition to build more accurate and coherent scene graph representations. 

2) Leverage visual-language pre-training (using CLIP) to align natural language scene descriptions with visual perception and bridge the gap between semantic graphs and visual understanding.

3) Integrate the continuous knowledge graph with aligned multimodal features to empower the navigator with robust zero-shot navigation capability.

Main Contributions:

1) A continuous knowledge graph modeling framework that better captures hierarchical scene structures.

2) An aligned encoder that leverages CLIP to associate scene language and visuals within a shared space.

3) Comprehensive experiments in AI2-THOR simulator demonstrating AKGVP's superior performance in both general and zero-shot navigation, with higher success rates and more efficient trajectories.

In summary, the key innovation is using continuous graphs and visual-language alignment to achieve tighter coupling between knowledge representations and visual observations for more accurate object-goal navigation. Experiments confirm the effectiveness of this approach.
