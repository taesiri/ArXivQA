# Large Language Models are few(1)-shot Table Reasoners

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How well can large language models (LLMs) perform on table reasoning tasks with few-shot in-context learning, without any fine-tuning on table-specific data? The key hypotheses appear to be:1) Despite not being pre-trained on table data, LLMs may still be competent at reasoning over tables due to encountering many tables in their web-scale pre-training.2) Using chain-of-thought prompting with just 1-2 examples, LLMs may achieve strong performance on complex table reasoning tasks, comparable to or exceeding some existing models that require full fine-tuning. 3) The reasoning chains elicited from the LLMs can provide some insight into their internal reasoning process and semantics, which may be useful for various purposes like justifying predictions or aiding annotation.So in summary, the main research question is assessing the few-shot table reasoning abilities of LLMs using chain-of-thought prompting, without any table-specific fine-tuning. The key hypotheses focus on the potential competence of LLMs at this challenging task, their ability to match or exceed fine-tuned models, and the utility of their generated reasoning chains.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Evaluating the capability of large language models (LLMs) like GPT-3 for table reasoning tasks using few-shot in-context learning. The authors show that with chain-of-thought prompting, LLMs can achieve strong performance on table QA and fact verification datasets with just 1-2 examples, without any fine-tuning.2. Demonstrating that LLMs can generate high-quality and comprehensive long-form answers for table-based questions, outperforming fine-tuned models like T5-Large according to human evaluation. 3. Analyzing the reasoning chains produced by LLMs and finding they are highly consistent with the underlying semantic forms, showing LLMs have built-in skills for symbolic reasoning over tables.4. Identifying limitations of LLMs for table reasoning, including inability to handle large tables and making mistakes in symbolic operations. 5. Proposing LLMs with chain-of-thought prompting as a simple yet strong baseline for table reasoning that could be used in future research.In summary, the key contribution appears to be comprehensively evaluating and analyzing the table reasoning capabilities of large language models using few-shot prompting, to serve as a strong baseline for future research on table-based reasoning tasks.
