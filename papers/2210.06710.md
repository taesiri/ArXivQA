# Large Language Models are few(1)-shot Table Reasoners

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How well can large language models (LLMs) perform on table reasoning tasks with few-shot in-context learning, without any fine-tuning on table-specific data? The key hypotheses appear to be:1) Despite not being pre-trained on table data, LLMs may still be competent at reasoning over tables due to encountering many tables in their web-scale pre-training.2) Using chain-of-thought prompting with just 1-2 examples, LLMs may achieve strong performance on complex table reasoning tasks, comparable to or exceeding some existing models that require full fine-tuning. 3) The reasoning chains elicited from the LLMs can provide some insight into their internal reasoning process and semantics, which may be useful for various purposes like justifying predictions or aiding annotation.So in summary, the main research question is assessing the few-shot table reasoning abilities of LLMs using chain-of-thought prompting, without any table-specific fine-tuning. The key hypotheses focus on the potential competence of LLMs at this challenging task, their ability to match or exceed fine-tuned models, and the utility of their generated reasoning chains.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Evaluating the capability of large language models (LLMs) like GPT-3 for table reasoning tasks using few-shot in-context learning. The authors show that with chain-of-thought prompting, LLMs can achieve strong performance on table QA and fact verification datasets with just 1-2 examples, without any fine-tuning.2. Demonstrating that LLMs can generate high-quality and comprehensive long-form answers for table-based questions, outperforming fine-tuned models like T5-Large according to human evaluation. 3. Analyzing the reasoning chains produced by LLMs and finding they are highly consistent with the underlying semantic forms, showing LLMs have built-in skills for symbolic reasoning over tables.4. Identifying limitations of LLMs for table reasoning, including inability to handle large tables and making mistakes in symbolic operations. 5. Proposing LLMs with chain-of-thought prompting as a simple yet strong baseline for table reasoning that could be used in future research.In summary, the key contribution appears to be comprehensively evaluating and analyzing the table reasoning capabilities of large language models using few-shot prompting, to serve as a strong baseline for future research on table-based reasoning tasks.


## How does this paper compare to other research in the same field?

Based on my review of the paper, here is how I would compare it to other research in the field:The paper presents an interesting new approach to table reasoning using large language models and few-shot prompting. This is a relatively underexplored area compared to more traditional techniques like semantic parsing or pre-trained table representation models. The idea of utilizing LLMs for complex table reasoning with just demonstrations is novel. Most prior work has focused on developing specialized architectures and pre-training objectives for table understanding. In contrast, this work shows that even models like GPT-3 with no table pre-training can reason over tables when properly prompted. The Chain of Thoughts prompting technique allows GPT-3 to achieve strong performance on table QA and fact verification with just 1-2 examples, comparable to fine-tuned models.The simplicity of the approach is a major advantage compared to prior work requiring extensive pre-training or annotation. The elicited reasoning chains also allow some level of interpretability, unlike most black-box neural models. This demonstrates that scaling generic LLMs can induce some reasoning capabilities even absent specialized training.However, there are still many limitations compared to leading semantic parsing and table pre-training techniques. The performance is not yet state-of-the-art. The approach struggles to handle large tables and has unpredictability issues. It likely has less systematic compositional generalization. But the work provides a strong simple baseline and analysis of LLM reasoning that can inform future research.In summary, the work explores a promising new direction of utilizing generic LLMs for complex table reasoning tasks. It demonstrates surprisingly strong few-shot performance despite no table pre-training. The approach is simple and interpretable but has limitations compared to leading models. Overall, the work helps advance the understanding of reasoning capabilities in scaled LLMs applied to structured knowledge.
