# [CORECODE: A Common Sense Annotated Dialogue Dataset with Benchmark Tasks   for Chinese Large Language Models](https://arxiv.org/abs/2312.12853)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Commonsense reasoning is an important capability for artificial intelligence systems to function properly in the real world. However, recent studies show that large language models (LLMs) still fall short in adequate commonsense reasoning, despite being trained on massive amounts of data. To promote research in evaluating and enhancing commonsense reasoning in LLMs, especially in the context of daily dialogues, the authors propose CORECODE, a large-scale Chinese dataset with commonsense knowledge annotations in multi-turn dyadic dialogues.  

Proposed Solution:
- The authors first select dialogues rich in commonsense content from existing Chinese dialogue datasets. 
- They categorize commonsense knowledge into 3 dimensions: entity, event and social interaction. Under these dimensions, they define a taxonomy with 9 domains and 37 slots to capture diverse commonsense knowledge types.  
- Crowdworkers then annotate entities, events and social interactions in the dialogues using this taxonomy, in the form "domain:slot=value". Two commonsense conflict phrases are also provided for each annotation to probe conflict detection ability.
- 76,787 annotations are collected from 19,700 dialogues. Two subsets are created - EASY and HARD, with different difficulties.
- 6 benchmark tasks are designed, including filling, generation, detection, identification and inference of commonsense knowledge.

Main Contributions:
- First large-scale Chinese dialogue dataset with comprehensive commonsense annotation using a unified taxonomy, covering reasoning in multiple dimensions.
- Set of challenging benchmark tasks for evaluating and enhancing commonsense reasoning of LLMs.
- Experiments with various Chinese LLMs show poor performance on most tasks, indicating difficulty of the dataset and necessity of more research.
- Analysis also reveals robustness issue in LLM commonsense knowledge acquisition via fine-tuning.
- The annotated dataset and task suites can facilitate more studies on context-sensitive commonsense reasoning for LLMs.

In summary, the paper presents CORECODE, a valuable resource and benchmark for commonsense reasoning research of large language models based on Chinese dialogues. Both the dataset creation process and experiments expose deficiencies of current LLMs in this area.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes CORECODE, a large-scale Chinese dialogue dataset with over 76K commonsense knowledge annotations across 3 dimensions (entity, event, social interaction) in a standardized format, along with 6 benchmark tasks to evaluate and enhance the commonsense reasoning capability of large language models in the context of everyday conversations.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1) The proposal of CORECODE, a large-scale Chinese dialogue dataset with over 76K manually annotated commonsense knowledge instances across three dimensions: entity, event, and social interaction. The dataset captures diverse and fine-grained commonsense knowledge in conversations using a standardized "domain:slot=value" representation.

2) The definition of 6 benchmark tasks over CORECODE to evaluate dialogue-level commonsense reasoning capabilities of Chinese language models, including knowledge filling, generation, conflict phrase detection, domain/slot identification, and event causal inference.

3) Extensive experiments evaluating a wide variety of Chinese LLMs on the proposed benchmark tasks, showing they perform poorly and that the tasks and dataset are challenging for existing models. Additional analysis also reveals limitations in robustness of commonsense knowledge acquired via fine-tuning.

4) The public release of the CORECODE dataset to promote research on evaluating and improving commonsense reasoning of LLMs in conversational contexts.

In summary, the key contribution is the introduction of a methodology and benchmark for assessing and advancing Chinese LLMs in terms of contextual commonsense reasoning, enabled through the release of the large manually annotated CORECODE dataset.


## What are the keywords or key terms associated with this paper?

 Based on my review of the paper content, some of the key terms and keywords associated with this paper include:

- Commonsense reasoning - The paper focuses on evaluating and enhancing the commonsense reasoning capabilities of language models.

- Large language models (LLMs) - The paper examines the commonsense reasoning abilities of various large language models. 

- Dialogue dataset - The paper introduces CORECODE, a large-scale Chinese dialogue dataset annotated with commonsense knowledge.

- Annotation ontology - A hierarchical taxonomy of domains and slots is defined to enable consistent annotation of commonsense knowledge.

- Benchmark tasks - Several tasks are proposed over CORECODE to assess LLMs' reasoning skills, including knowledge filling, generation, conflict detection, etc.

- Entity, event, social interaction - Three dimensions of commonsense knowledge categorized in the annotation ontology.

- Zero-shot evaluation - Examining the commonsense reasoning performance of LLMs without specific fine-tuning on CORECODE. 

- Fine-tuning - Fine-tuning LLMs on CORECODE and evaluating the improvements on reasoning capabilities.

- Robustness analysis - Testing the robustness of commonsense knowledge acquired by LLMs via fine-tuning under perturbations.

In summary, the key focus is on commonsense reasoning evaluation of LLMs using a dialogue-based benchmark, involving ontology-guided annotation, task formulation, model testing and analysis.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes to standardize the representation of commonsense knowledge in open-domain dialogues in the form of "domain:slot=value". What are the key principles guiding the design of the domain and slot taxonomy? How does this representation help with consistent annotation?

2. The paper collects commonsense knowledge annotations on both an EASY set and a HARD set. What are the key differences in event representation between these two sets? How do these differences pose extra challenges for reasoning?

3. Six benchmark tasks are proposed in the paper to evaluate commonsense reasoning abilities of language models. Can you analyze the unique challenges posed by each task and how they collectively examine diverse reasoning capabilities?  

4. The paper finds that language models perform poorly on most proposed benchmark tasks without fine-tuning. What are some possible reasons behind models' inability to perform well in a zero-shot setting?

5. Fine-tuning is shown to significantly boost model performance across tasks. However, model performance degrades substantially when perturbations are introduced at test time. What does this indicate about the commonsense reasoning abilities obtained via fine-tuning?

6. The paper shows BLOOMZ models generate more accurate responses compared to models like ChatGLM on the generation tasks. What differences in model architectures or training approaches lead to this performance gap?

7. The slot identification task poses a unique challenge even for large models like Chinese-Alpaca-Plus-13B. What intrinsic difficulties exist in this task compared to the others?  

8. Among the six benchmark tasks, which one do you think is the most challenging for language models and why? What abilities must models possess to perform well?

9. The dataset contains annotated commonsense knowledge spanning three dimensions - entity, event and social interaction. Do you think any crucial dimension is missing? What other aspect of commonsense would be useful to incorporate?

10. The paper demonstrates the difficulty of acquiring robust commonsense reasoning via fine-tuning. What are some potential solutions to make progress in this direction?
