# [CORECODE: A Common Sense Annotated Dialogue Dataset with Benchmark Tasks   for Chinese Large Language Models](https://arxiv.org/abs/2312.12853)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Commonsense reasoning is an important capability for artificial intelligence systems to function properly in the real world. However, recent studies show that large language models (LLMs) still fall short in adequate commonsense reasoning, despite being trained on massive amounts of data. To promote research in evaluating and enhancing commonsense reasoning in LLMs, especially in the context of daily dialogues, the authors propose CORECODE, a large-scale Chinese dataset with commonsense knowledge annotations in multi-turn dyadic dialogues.  

Proposed Solution:
- The authors first select dialogues rich in commonsense content from existing Chinese dialogue datasets. 
- They categorize commonsense knowledge into 3 dimensions: entity, event and social interaction. Under these dimensions, they define a taxonomy with 9 domains and 37 slots to capture diverse commonsense knowledge types.  
- Crowdworkers then annotate entities, events and social interactions in the dialogues using this taxonomy, in the form "domain:slot=value". Two commonsense conflict phrases are also provided for each annotation to probe conflict detection ability.
- 76,787 annotations are collected from 19,700 dialogues. Two subsets are created - EASY and HARD, with different difficulties.
- 6 benchmark tasks are designed, including filling, generation, detection, identification and inference of commonsense knowledge.

Main Contributions:
- First large-scale Chinese dialogue dataset with comprehensive commonsense annotation using a unified taxonomy, covering reasoning in multiple dimensions.
- Set of challenging benchmark tasks for evaluating and enhancing commonsense reasoning of LLMs.
- Experiments with various Chinese LLMs show poor performance on most tasks, indicating difficulty of the dataset and necessity of more research.
- Analysis also reveals robustness issue in LLM commonsense knowledge acquisition via fine-tuning.
- The annotated dataset and task suites can facilitate more studies on context-sensitive commonsense reasoning for LLMs.

In summary, the paper presents CORECODE, a valuable resource and benchmark for commonsense reasoning research of large language models based on Chinese dialogues. Both the dataset creation process and experiments expose deficiencies of current LLMs in this area.
