# [Towards Unsupervised Question Answering System with Multi-level   Summarization for Legal Text](https://arxiv.org/abs/2403.13107)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Legal text reasoning is complex even for state-of-the-art language models. SemEval-2024 Task 5 aims to assess reasoning ability of models on legal questions related to US civil procedure.

Proposed Solution: 
- Employ segment-wise summarization of lengthy explanations using T5 to retain crucial information.  
- Explore both supervised (multi-level CNN fusion with BiGRU/BiLSTM) and unsupervised (similarity metrics on various embeddings) approaches.
- For unsupervised, compute similarity between question-answer and answer-summary pairs using combinations like Glove-cosine, transformer embeddings-cosine/euclidean, word2vec-cosine.
- Refine unsupervised model by replacing top prediction with second best if similarity difference is small.

Key Results:
- Best supervised model achieved 66% and 49.6% macro F1 on dev and test sets.  
- Best unsupervised model (Word2vec-cosine) achieved 62% and 52.3%, outperforming baseline.
- Replacement in unsupervised model improved performance significantly.
- Models consistently perform better on dev set compared to test set, indicating generalization issues.

Main Contributions:
- Novel use of segment-wise summarization using T5 on lengthy legal explanations to retain key details.
- Comprehensive analysis of supervised vs unsupervised approaches on complex legal QA dataset. 
- Demonstrated unsupervised similarity-based model with prediction replacement can outperform supervised models.
- Thorough evaluation illuminates model generalization issues from dev to test set.

Future Work: 
- Ensemble supervised and unsupervised models to create unified "super model".
- Use siamese networks to better learn similarities for unsupervised model.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a combination of supervised multi-level fusion approaches and unsupervised similarity-based methods for legal question answering, with segment-wise text summarization to handle lengthy explanations, achieving promising performance compared to the baseline.


## What is the main contribution of this paper?

 Based on reviewing the paper, the main contributions appear to be:

1. Proposing a simple yet novel similarity and distance-based unsupervised approach to generate labels for the legal question answering task. This includes using word embeddings like Word2Vec and Glove in combination with cosine similarity and Euclidean distance to assign labels.

2. Exploring multi-level fusion of Legal-Bert embeddings using ensemble features from CNN, GRU and LSTM in a supervised learning framework. This multi-level concatenation provides a rich feature representation.

3. Introducing T5-based segment-wise summarization of the lengthy legal explanations in the dataset. This helps retain crucial information while reducing the sequence length for the models.

4. Comparative analysis of multiple supervised and unsupervised techniques, providing insights into their strengths and limitations on the complex legal QA dataset.

5. The unsupervised Word2Vec-cosine similarity approach gives the best macro F1 score of 52.38% on the test set, outperforming the baseline by over 8 points.

In summary, the core contributions are around novel unsupervised and supervised methods tailored for the legal QA task, use of summarization, and comparative evaluation of various techniques.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the key terms and keywords related to this work include:

- Legal NLP
- Transformers
- BERT
- Legal-BERT
- SemEval-2024 Task 5
- Legal Argument Reasoning 
- Civil Procedure
- Binary Classification
- Unsupervised learning
- Word2vec
- GloVe
- Cosine similarity
- Siamese networks
- T5 summarization
- CNN 
- GRU
- LSTM
- Ensemble methods

The paper discusses using both supervised and unsupervised approaches, including transformer models like BERT and T5, to address the legal question answering task in SemEval-2024 Task 5. Key aspects include generating summaries, computing similarities between questions and answers, using CNN/GRU/LSTM for feature extraction, and proposing future work with Siamese networks. The core focus is on handling the complexity of legal texts to perform binary classification for a multiple choice QA dataset.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes a two-step segment-wise summarization approach using T5. What were the segment lengths chosen in each step and what was the rationale behind selecting these values?

2. The multi-level fusion approach concatenates features from CNN, GRU and LSTM models. What is the motivation behind using features from multiple model architectures? How do the different architectures complement each other?  

3. The paper compares a multi-feature concatenation approach with 900 features to a multi-level approach with 1500 features. What factors need to be considered in determining the right feature dimension and complexity?

4. The custom sigmoid layer applies mean subtraction before sigmoid activation. What is the intuition behind this design? How does it help improve model performance?

5. The grid search technique is used to find the optimal threshold for classification. What are some challenges in selecting the right evaluation metric and search space for this task?

6. The unsupervised models use different similarity and distance metrics like cosine similarity and Euclidean distance. What are the tradeoffs between these different metrics for this application?

7. For the Word2Vec model, the paper applies a conditional replacement logic based on similarity score differences. Explain this logic and discuss how it helps improve accuracy. 

8. The legal-DeBERTa model is used to generate transformer embeddings. What modifications need to be made for using DeBERTa instead of BERT for this task?

9. The paper identifies some limitations of the unsupervised models, such as the assumption of at least one correct answer. How can this issue be addressed? Are there other weaknesses of the unsupervised approach?

10. The paper proposes some ideas for future work, like a super model ensemble and Siamese networks. Elaborate on how these approaches could help enhance performance and overcome existing limitations.
