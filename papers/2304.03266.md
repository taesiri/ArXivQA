# [Neural Fields meet Explicit Geometric Representation for Inverse   Rendering of Urban Scenes](https://arxiv.org/abs/2304.03266)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to perform high-quality inverse rendering of large outdoor urban scenes to recover intrinsic scene properties like geometry, spatially-varying materials and lighting from images. 

The key ideas and contributions are:

- Proposing a novel hybrid rendering pipeline that combines neural fields and explicit mesh representations to efficiently render primary and secondary rays respectively. This enables scaling inverse rendering to large scenes.

- Modeling the scene properties like geometry, materials, lighting using a neural intrinsic field and HDR sky dome to enable applications like relighting and AR.

- Achieving state-of-the-art performance on outdoor scene relighting benchmark and high-quality results on challenging single-illumination captures from driving datasets.

In summary, the main hypothesis is that combining the benefits of neural fields and explicit geometry can enable high-quality intrinsic decomposition and inverse rendering of large outdoor urban scenes from images. The experiments validate this on various datasets and downstream applications.
