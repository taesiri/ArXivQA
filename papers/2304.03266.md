# [Neural Fields meet Explicit Geometric Representation for Inverse   Rendering of Urban Scenes](https://arxiv.org/abs/2304.03266)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to perform high-quality inverse rendering of large outdoor urban scenes to recover intrinsic scene properties like geometry, spatially-varying materials and lighting from images. 

The key ideas and contributions are:

- Proposing a novel hybrid rendering pipeline that combines neural fields and explicit mesh representations to efficiently render primary and secondary rays respectively. This enables scaling inverse rendering to large scenes.

- Modeling the scene properties like geometry, materials, lighting using a neural intrinsic field and HDR sky dome to enable applications like relighting and AR.

- Achieving state-of-the-art performance on outdoor scene relighting benchmark and high-quality results on challenging single-illumination captures from driving datasets.

In summary, the main hypothesis is that combining the benefits of neural fields and explicit geometry can enable high-quality intrinsic decomposition and inverse rendering of large outdoor urban scenes from images. The experiments validate this on various datasets and downstream applications.


## What is the main contribution of this paper?

 The main contributions of this paper are:

- Proposes a novel hybrid rendering pipeline called FEGR that combines neural fields and explicit geometric representations for inverse rendering of large urban scenes.

- Represents the scene intrinsics (geometry, materials, lighting) using a neural field, which enables modeling high-resolution details. 

- Renders primary rays through volumetric rendering of the neural field to get a G-buffer.

- Extracts a mesh from the underlying signed distance field and uses it to render secondary rays for modeling global illumination effects like shadows.

- Models HDR lighting and materials, making the representation suitable for relighting and virtual object insertion.

- Achieves state-of-the-art performance on novel view synthesis and relighting on the NeRF-OSR dataset. Also shows results on a challenging autonomous driving dataset captured under single illumination.

- Enables downstream applications like photorealistic relighting and virtual object insertion with accurate shadows.

In summary, the key contribution is a hybrid neural rendering approach that combines the benefits of neural fields and explicit geometry to achieve high-quality inverse rendering of large outdoor scenes for graphics applications. The hybrid rendering and intrinsic scene decomposition enable photorealistic view synthesis and editing.
