# [Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via   Self-supervised Scene Decomposition](https://arxiv.org/abs/2302.11566)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to reconstruct detailed 3D avatars from monocular in-the-wild videos without requiring ground truth supervision or priors from large datasets of human scans. The key hypothesis is that by jointly modeling the human and background scene implicitly using separate neural fields, and optimizing them along with human pose in a global formulation, the method can achieve robust scene decomposition and high-quality 3D reconstruction of the human subject.Specifically, the core hypotheses are:- Modeling the human and background jointly using separate implicit neural fields can enable self-supervised scene decomposition and human reconstruction without ground truth data.- Leveraging a canonical human shape representation and pose-conditioned deformation can provide a consistent shape constraint across frames.- A global optimization over pose, shape, appearance and background can enable joint refinement for better reconstruction. - Novel scene decomposition objectives like opacity regularization can improve separation of human from background.In summary, the main research question is monocular human reconstruction from in-the-wild videos without supervision, addressed via hypotheses of joint modeling, canonical space supervision, global optimization and scene decomposition objectives.
