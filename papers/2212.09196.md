# Emergent Analogical Reasoning in Large Language Models

## What is the central research question or hypothesis that this paper addresses?

Based on a quick skim of the paper, it appears the central research question is: Do large language models like GPT-3 display an emergent ability to reason by analogy in a zero-shot setting, similar to human reasoning abilities? The authors evaluate GPT-3 on a range of analogy tasks, including novel matrix reasoning problems, letter string analogies, four-term verbal analogies, and story analogies. They compare GPT-3's performance to human behavior across these tasks. The overarching goal seems to be assessing whether the analogical reasoning abilities of large language models like GPT-3 emerge in a zero-shot setting without any direct training, similar to the way humans are able to reason analogically about novel problems.The central hypothesis appears to be that the massive scale and training of large language models leads to an emergent capacity for analogical reasoning, allowing these models to solve analogy problems zero-shot. The authors seem to hypothesize that GPT-3 will display human-like analogical reasoning abilities across the range of tasks tested.In summary, the central research question/hypothesis is whether large language models like GPT-3 possess an emergent, human-like capacity for zero-shot analogical reasoning. The paper tests this by systematically comparing GPT-3's performance to human behavior across a variety of analogy tasks.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution appears to be demonstrating that the large language model GPT-3 displays an emergent ability to perform analogical reasoning in a zero-shot setting, matching or exceeding human performance across a range of text-based analogy tasks. Specifically, the key findings include:- GPT-3 showed strong zero-shot performance on a novel text-based matrix reasoning task modeled after Raven's Progressive Matrices, matching or surpassing the average human level of performance. It also displayed similar patterns of performance as humans across different problem types.- GPT-3 performed well on letter string analogies involving various transformations and generalizations, again showing human-like patterns of performance.- GPT-3 matched or exceeded human accuracy on multiple datasets of four-term verbal analogies covering various semantic relations.- GPT-3 displayed sensitivity to causal relations in story analogies, preferring stories that shared higher-order relations over those that only shared superficial features.- In qualitative tests, GPT-3 showed an ability to use analogies to help solve novel problems, as well as identify correspondences between source and target analogs.In summary, the key contribution is providing extensive evidence that the latest large language models like GPT-3 have acquired a general capacity for relational reasoning and abstraction that enables zero-shot analogical inference at a human level across a broad range of tasks. This challenges the view that neural networks cannot capture human cognitive capacities like analogy without extensive training.
