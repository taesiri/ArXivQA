# [Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment   Search](https://arxiv.org/abs/2005.11129)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

How can we develop a text-to-speech (TTS) model that does not require an external aligner and can synthesize speech quickly and robustly?

The key hypotheses of the paper appear to be:

1) By combining flows and dynamic programming for alignment, a TTS model can learn to align text and speech representations internally without needing a pre-trained autoregressive TTS model as an external aligner.

2) Enforcing hard monotonic alignments between text and latent speech representations enables robust TTS that generalizes to long utterances. 

3) Using flows for the decoder enables fast, diverse, and controllable speech synthesis.

So in summary, the central goal is to develop a standalone parallel TTS model that does not rely on external aligners, can synthesize speech robustly and quickly, and allows control over factors like pitch and speaking rate. The key ideas are using flows and monotonic alignment search to achieve these properties.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- Proposing Glow-TTS, a flow-based generative model for parallel text-to-speech that does not require an external aligner. Previous parallel TTS models like FastSpeech and ParaNet rely on alignments from pretrained autoregressive TTS models. 

- Introducing a monotonic alignment search algorithm that can find the most probable monotonic alignment between text and the latent speech representation internally during training. This removes the need for an external aligner.

- Demonstrating that enforcing hard monotonic alignments enables robust and fast TTS that generalizes to long utterances. The model is shown to be over 15x faster than Tacotron 2.

- Showing that employing flows enables diverse, controllable speech synthesis by manipulating the latent space. Properties like pitch and speaking rate can be controlled.

- Extending the model to a multi-speaker setting with only small modifications, and showing it can learn speaker-dependent durations.

So in summary, the main contribution appears to be proposing a new parallel TTS model architecture based on flows and monotonic alignment that removes the need for external aligners, enables fast and robust synthesis, and provides controllability. The combination of hard monotonic alignments and flows seems to be the key novelty.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes Glow-TTS, a generative flow model for text-to-speech synthesis that can generate mel-spectrograms from text in parallel without needing an external aligner.
