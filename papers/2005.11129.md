# [Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment   Search](https://arxiv.org/abs/2005.11129)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

How can we develop a text-to-speech (TTS) model that does not require an external aligner and can synthesize speech quickly and robustly?

The key hypotheses of the paper appear to be:

1) By combining flows and dynamic programming for alignment, a TTS model can learn to align text and speech representations internally without needing a pre-trained autoregressive TTS model as an external aligner.

2) Enforcing hard monotonic alignments between text and latent speech representations enables robust TTS that generalizes to long utterances. 

3) Using flows for the decoder enables fast, diverse, and controllable speech synthesis.

So in summary, the central goal is to develop a standalone parallel TTS model that does not rely on external aligners, can synthesize speech robustly and quickly, and allows control over factors like pitch and speaking rate. The key ideas are using flows and monotonic alignment search to achieve these properties.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions appear to be:

- Proposing Glow-TTS, a flow-based generative model for parallel text-to-speech that does not require an external aligner. Previous parallel TTS models like FastSpeech and ParaNet rely on alignments from pretrained autoregressive TTS models. 

- Introducing a monotonic alignment search algorithm that can find the most probable monotonic alignment between text and the latent speech representation internally during training. This removes the need for an external aligner.

- Demonstrating that enforcing hard monotonic alignments enables robust and fast TTS that generalizes to long utterances. The model is shown to be over 15x faster than Tacotron 2.

- Showing that employing flows enables diverse, controllable speech synthesis by manipulating the latent space. Properties like pitch and speaking rate can be controlled.

- Extending the model to a multi-speaker setting with only small modifications, and showing it can learn speaker-dependent durations.

So in summary, the main contribution appears to be proposing a new parallel TTS model architecture based on flows and monotonic alignment that removes the need for external aligners, enables fast and robust synthesis, and provides controllability. The combination of hard monotonic alignments and flows seems to be the key novelty.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes Glow-TTS, a generative flow model for text-to-speech synthesis that can generate mel-spectrograms from text in parallel without needing an external aligner.


## How does this paper compare to other research in the same field?

 This paper presents a novel text-to-speech (TTS) synthesis method called Glow-TTS, which has several advantages over existing TTS methods:

- It is a parallel TTS model that does not require an external aligner like previous parallel TTS models such as FastSpeech and ParaNet. This simplifies the training process.

- It uses a flow-based generative model which allows very fast sampling compared to autoregressive models like Tacotron 2. The experiments show it is 15.7x faster than Tacotron 2.

- The use of flows and enforcing monotonic alignments makes it more robust, especially for long utterances, compared to Tacotron 2 which can have attention errors.

- As a generative model, it allows control over aspects like pitch and speaking rate by manipulating the latent space. This is difficult with autoregressive models.

- It extends easily to a multi-speaker model with the addition of speaker embeddings, and shows the ability to disentangle speaker identity and speech content.

Compared to other parallel TTS models:

- It is more robust than FastSpeech and ParaNet since it uses hard monotonic alignments rather than soft attention.

- It generates more diverse and controllable speech compared to FastSpeech since it is generative rather than feed-forward.

- It does not need an external aligner like FastSpeech and ParaNet.

Compared to other flow-based TTS models like Flowtron:

- It enforces hard monotonic alignments which improves robustness over soft attention in Flowtron.

- It achieves state-of-the-art speech quality on LJSpeech compared to Flowtron.

So in summary, Glow-TTS combines the parallel sampling of models like FastSpeech with the generative modeling of flows to create a fast, robust, and controllable TTS model that simplifies training. The experiments demonstrate it achieves state-of-the-art results on standard TTS benchmarks.
