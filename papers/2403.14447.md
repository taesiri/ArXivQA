# [Exploring 3D Human Pose Estimation and Forecasting from the Robot's   Perspective: The HARPER Dataset](https://arxiv.org/abs/2403.14447)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Traditionally, robots have been pre-programmed to perform rigid routines without much human awareness. There is now a need for robots to transition to collaborative robots (cobots) that can interact safely with humans. This requires capabilities like visual perception, action recognition, intent prediction, and safe online motion planning.

- Existing human-robot interaction (HRI) datasets provide some relevant data, but lack accuracy in 3D skeletal pose, coverage of the robot's perspective, and scenarios involving physical contact between robots and humans like collisions.

Proposed Solution:
- The paper introduces the HARPER (Human from an Articulated Robot PErspective) dataset which focuses on a Spot quadruped robot interacting with 17 human participants performing 15 actions. 

- The data includes synchronized streams from Spot's built-in cameras along with high-precision 3D motion capture providing sub-millimeter accuracy on 21 body joints from an external "panoptic" view. This enables analysis from both the robot and an external perspective.

- Scenarios involve having humans walking towards Spot and making four types of physical contact - unintended collisions, intentional touching, kicking, and punching.

- Benchmarks are provided for Human Pose Estimation, Forecasting and Collision Prediction all from the viewpoint of Spot's sensors. Baselines using state-of-the-art methods are provided to enable standardized comparisons.

Main Contributions:

- Novel focus on quadruped perspective for sensing humans, which is more challenging as the robot can often only partially observe the human.

- High quality synchronized data associating imagery from the robot's perspective to nearly perfect external motion capture skeletons.

- New benchmarks and baselines for human pose and collision prediction tailored to the robot's perspective.

Overall the paper introduces a valuable new dataset and benchmarks to help the transition of robots towards more aware collaborative cobot platforms through analysis of human pose, motion and contact.
