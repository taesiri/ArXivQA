# [Detection of tortured phrases in scientific literature](https://arxiv.org/abs/2402.03370)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Scientific literature is being contaminated by papers that have used text spinners to hide plagiarism. This creates "tortured phrases" - nonsensical scientific expressions that destroy meaning.
- A manually collected set of known tortured phrases is being used to flag problematic papers. But more tortured phrases need to be identified across scientific fields to expand this detection capability.

Proposed Solution: 
- Create a dataset containing known tortured phrases and expected phrases from scientific text. 
- Test methods to automatically distinguish differences between tortured and expected phrases in order to identify new tortured phrases:
  - Word embedding similarity measures 
  - Masking and prediction using SciBERT language model

Key Contributions:
- Built a dataset of ~6,000 sentences containing known and potential unknown tortured phrases
- Evaluated cosine similarity, Manhattan distance and Euclidean distance between embeddings of tortured and expected phrases. Cosine similarity showed best differentiation.
- Tested SciBERT's probability, rank and entropy of predicting masked words in phrases. Performance better at noun chunk level vs token.
- Best recall of 0.873 in detecting tortured phrases obtained using chunk-level score propagation from SciBERT predicted tokens. But precision of 0.615 means expert checking still needed.
- Showed possibility of automatically expanding dictionary of tortured phrases to flag more problematic papers, although refinement of precision is still required.

In summary, the paper presents and evaluates methods to automatically detect potentially plagiarized tortured phrases in scientific text. This can help identify problematic papers but the proposed techniques still require expert validation before applying flagged phrases to expand current detection capabilities.
