# [Are Classification Robustness and Explanation Robustness Really Strongly   Correlated? An Analysis Through Input Loss Landscape](https://arxiv.org/abs/2403.06013)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Classification robustness and explanation robustness are believed to be strongly correlated - improving one can improve the other. This paper challenges that assumption.

- They visualize the input loss landscape with respect to explanation loss and find that increasing explanation robustness (through adversarial training) does not flatten the landscape, unlike for classification loss. This is strange and contradicting. 

Proposed Solution:
- They propose a new training method called SEP to explicitly flatten the input loss landscape w.r.t explanation loss. 

- SEP can be incorporated into normal training or adversarial training frameworks. It adds a loss term that encourages flatness of explanation loss under random noise.

- Two variants are proposed - SEP_pos with positive loss weight to flatten, and SEP_neg with negative loss weight to sharpen landscape.

Key Results:
- SEP_pos reduces explanation robustness but maintains classification accuracy compared to adversarial training. SEP_neg improves explanation robustness but keeps classification accuracy unchanged.

- This holds for different explanation methods, models, datasets and adversarial training techniques. It shows explanation and classification robustness can be decoupled.

Main Contributions:  
- First work to analyze landscape of explanation loss and identify contradiction with assumptions.
- Proposes new training approach to explicitly control explanation loss flatness.
- Experiments prove explanation robustness and classification robustness need not be strongly tied, challenging prevailing assumptions. This reveals new directions for improving robustness.
