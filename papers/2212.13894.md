# LAMBADA: Backward Chaining for Automated Reasoning in Natural Language

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is: Can integrating backward chaining with large language models lead to improved performance on automated reasoning tasks compared to existing approaches based on forward chaining or end-to-end training? The key hypothesis is that combining backward chaining (a classical AI automated reasoning technique) with the natural language understanding capacity of large language models will enable more effective automated reasoning on tasks where the inputs and inference chains are expressed in natural language. The paper proposes a new model called LAMBADA that integrates backward chaining with large language model modules to perform automated reasoning. It compares LAMBADA experimentally to existing approaches like Chain-of-Thought and Selection-Inference on challenging deductive reasoning datasets. The main result is that LAMBADA substantially outperforms these baselines, especially on longer reasoning chains, demonstrating the benefits of incorporating backward chaining strategies into language model based reasoning.In summary, the central research question is whether combining backward chaining with language models can improve automated reasoning with natural language, which the paper aims to validate through the proposed LAMBADA model and comparative experiments on reasoning datasets.


## What is the main contribution of this paper?

The main contribution of this paper is developing LAMBADA, a backward chaining algorithm for automated reasoning in natural language using language models. The key ideas are:- Using backward chaining rather than forward chaining for proof search, as backward chaining is more efficient and goal-directed. The authors argue and show experimentally that backward chaining is better suited for text-based deductive reasoning compared to popular forward chaining approaches.- Decomposing the reasoning into four modular components - Fact Check, Rule Selection, Goal Decomposition, and Sign Agreement - each implemented by an LM module through few-shot prompting. This allows combining the strength of LMs for natural language understanding with symbolic backward chaining for robust reasoning. - Showing significant improvements in accuracy over state-of-the-art methods like Chain-of-Thought and Selection-Inference on challenging deductive reasoning datasets, especially on examples requiring longer proof chains. The gains are particularly large on a dataset with more naturalistic text.- Demonstrating the query efficiency, generalizability to longer chains, and lexical robustness of LAMBADA.In summary, the key contribution is developing and evaluating a hybrid neuro-symbolic reasoning algorithm LAMBADA that integrates goal-directed backward chaining with modular LM components for automated reasoning over natural text. The results strongly demonstrate the advantages of incorporating backward chaining into language model based reasoning.
