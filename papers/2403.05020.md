# [Is this the real life? Is this just fantasy? The Misleading Success of   Simulating Social Interactions With LLMs](https://arxiv.org/abs/2403.05020)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Recent advances in large language models (LLMs) have enabled the simulation of social interactions by having a single LLM play the role of all participants. However, this "omniscient perspective" diverges from realistic human interactions which involve information asymmetry between participants.  

- The paper investigates whether the success of simulations from an omniscient perspective reflects how LLM agents would behave in more realistic settings with information asymmetry.

Methods:
- The authors build a unified framework based on Sotopia to simulate social interactions in different modes:
  - "Script mode": a single LLM with access to all info generates the full interaction 
  - "Agent mode": separate LLMs with access only to their assigned roles interact
  - "Mindreader mode": like agent mode but LLMs have access to each other's private info

- Experiments compare goal achievement and naturalness across these modes for GPT-3.5 and Mixtral-8x7B.

Results:
- Script mode drastically overestimates goal achievement compared to agent mode. Mindreader is in between. This shows information asymmetry in agent mode hinders goal success.

- Script mode is substantially more natural than agent mode interactions. Agent mode tends to produce repetitive and overly verbose utterances.

- Finetuning GPT-3.5 on script mode data improves naturalness of agent mode but barely improves goal achievement on cooperative tasks, showing poor generalization.

Conclusions:
- Success of script mode simulations is misleading about LLM capabilities for realistic social interactions involving information asymmetry.

- Addressing information asymmetry remains a fundamental challenge for LLM agents to achieve human-like social intelligence.

- More careful consideration of information access and transparency needed when using LLMs to simulate social interactions.
