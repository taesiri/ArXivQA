# [Learning Locally Editable Virtual Humans](https://arxiv.org/abs/2305.00121)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to create locally editable 3D human avatars that have high-fidelity detail and modeling capability. The key ideas are:

- Proposing a novel hybrid human representation that combines the advantages of neural fields (flexibility and modeling power) with explicit skinned body models (ease of deformation and control). 

- Integrating this representation into an end-to-end trainable generative framework that allows fitting to 3D scans, randomly sampling, and editing the avatars via local feature manipulation.

- Enabling avatar customization workflows like transferring details across subjects, drawing textures on images, and consistent reposing. 

The hypothesis is that by disentangling global body deformation from local surface details, and learning feature dictionaries in a generative model, it is possible to create controllable avatars that retain complex geometric and appearance information even for unseen poses and subjects. The experiments aim to validate the modeling accuracy, generalization ability, and editing flexibility of the proposed approach.

In summary, the key innovation is in the hybrid human representation that facilitates avatar generation and editing within a single framework trained on multi-subject scan data. This allows creating customizable avatars not possible with previous human modeling techniques.
