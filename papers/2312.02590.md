# [Text Intimacy Analysis using Ensembles of Multilingual Transformers](https://arxiv.org/abs/2312.02590)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed summary paragraph of the key points covered in the paper:

This paper presents approaches for the SemEval-2023 Task 9 on predicting intimacy levels of tweets in multiple languages. The authors utilize ensembles of pretrained multilingual transformer models like mBERT, XLM-RoBERTa, and XLM-T, combined with monolingual models for each language. The training data has tweets in 6 languages annotated with intimacy scores of 1-5, while the test set adds tweets in 4 more unseen languages. They find that an ensemble combining the multilingual models with a language-specific model for each language achieves the best results, outperforming multilingual-only ensembles. This monolingual+multilingual ensemble obtains strong correlation scores averaging 0.71 on seen languages and 0.40 on unseen languages. They also experiment with translating unseen language tweets into English, but find this data augmentation hurts performance overall. In conclusion, their ensemble approach effectively leverages both multilingual and monolingual representations. The disparity in unseen language performance suggests room for improvement in handling low-resource languages. Key limitations are the lack of analytical guarantees and sensitivity to language distribution shifts.
