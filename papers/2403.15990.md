# [Mars Spectrometry 2: Gas Chromatography -- Second place solution](https://arxiv.org/abs/2403.15990)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper describes the solution that achieved second place in the Mars Spectrometry 2: Gas Chromatography challenge organized by NASA in 2022. The goal of the challenge was to develop a machine learning model that can automatically analyze gas chromatography-mass spectrometry (GCMS) data files and predict the presence of certain compounds. 

The main challenge was that the GCMS data files provided only contained time, mass, and intensity values, but did not have temperature data which is critical for spectrometry analysis. The time values were only proxies for missing temperature data. Additionally, the temperature ramp over time was unknown and varied across samples, making the modeling more difficult.

The proposed solution converts the GCMS data files into 2D image-like representations with the mass and time values mapped to the image dimensions. Several convolutional neural network (CNN) models are then trained on these images to predict the target labels. The paper explores different techniques to handle the missing temperature information such as random time resizing and averaging across the time dimension. An ensemble of 13 CNN models with different architectures and input representations is used in the final solution.  

The main contributions of the paper are:

- Converting 1D GCMS data into 2D images to leverage CNN models for classification. This is adapted from the prior work that won the Mars Spectrometry 1 challenge.

- Techniques like random time resizing and time averaging to handle missing temperature ramp information.

- Using HRNet, RegNetX, ResNet and other state-of-the-art CNN backbones pretrained on ImageNet for transfer learning.

- Ensembling multiple models with different architectures and input representations to improve overall predictive performance.

The solution achieved the second best score on the competition leaderboard with a log loss of 0.1485, only 2.9% higher than the best score of 0.1443. The paper also demonstrates Grad-CAM visualization to provide some model interpretability on which input regions are influential for predictions.
