# [MORBDD: Multiobjective Restricted Binary Decision Diagrams by Learning   to Sparsify](https://arxiv.org/abs/2403.02482)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper focuses on multiobjective integer linear programming (MOILP) problems, where the goal is to find the Pareto frontier that contains non-dominated solutions over multiple linear objectives subject to integer constraints. Exact methods like binary decision diagrams (BDDs) can find the full Pareto frontier, but take exponential time. The authors observe that only a small fraction of BDD nodes actually contribute to Pareto-optimal solutions. Hence, there is an opportunity to restrict the BDD to only those relevant nodes in order to enumerate the approximate Pareto frontier much faster. 

Proposed Solution: 
The paper proposes MORBDD, a machine learning-based approach to restrict BDDs by eliminating irrelevant nodes before extracting solutions. It has two main steps:

1) Train a binary classifier to score each BDD node based on features related to node properties. The classifier learns from training instances to predict whether a node will contribute to Pareto-optimal solutions or not. 

2) Perform stitching to reconnect the sparse BDD if eliminating nodes disconnects it. Two stitching methods are proposed - an ILP-based exact approach and a faster greedy heuristic.

Main Contributions:

- Formulates for the first time the problem of data-driven construction of restricted BDDs to accelerate multiobjective optimization.

- Introduces a classification + optimization framework called MORBDD that first sparsifies the BDD via ML then stitches it back together to ensure connectivity.

- On multiobjective knapsack problems, MORBDD finds over 60% of Pareto-optimal solutions 5-30x faster than the exact BDD approach and evolutionary algorithm NSGA-II, outperforming width-limited BDDs.

- Demonstrates promising generalization ability by training a size-agnostic model that performs well across problems with varying numbers of objectives and variables.

The key insight is to leverage machine learning on multiple problem instances to identify precisely the nodes that do not contribute to the Pareto frontier, eliminating them without affecting the correctness of solutions extracted from the restricted BDD later. The paper shows this is an effective heuristic to approximate the Pareto frontier much faster.
