# Learning to Transfer Prompts for Text Generation

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is:How can we effectively transfer prompts learned from source text generation tasks to improve performance on new target text generation tasks, especially in low-resource settings?The key hypotheses appear to be:1) Prompts encode useful task-specific knowledge that can be transferred across related text generation tasks.2) Considering both task-level and instance-level information when constructing target prompts leads to better transfer of knowledge compared to using just task-level prompts.3) An adaptive attention mechanism over a pool of clustered source prompts allows selecting the most relevant knowledge for a given target instance.4) Prompt transfer will be especially beneficial in few-shot scenarios where target tasks have very limited labeled data.So in summary, the central research question is how to do effective prompt transfer for text generation. The key hypotheses are that prompts encode transferable knowledge, that considering instance information helps transfer the most useful knowledge, and that this approach will particularly help in low-resource target tasks.


## What is the main contribution of this paper?

Based on my reading, the main contribution of this paper is proposing a novel prompt-based transfer learning approach called PTG for text generation. The key ideas include:- Learning a set of "source prompts" from representative source text generation tasks, which encode task-specific knowledge. - Transferring these source prompts as "target prompts" to new text generation tasks in a zero-shot or few-shot setting.- Designing an adaptive attention mechanism to construct target prompts that considers both task-level and instance-level information. This allows selecting the most relevant source prompts for a given input instance.- Releasing the learned source prompts as an open-source prompt library that can be reused to improve new text generation tasks.In summary, the main contribution is introducing the idea of prompt transfer to text generation and developing a model called PTG that can effectively transfer prompts between diverse text generation tasks in a lightweight and adaptive manner. The release of the prompt library is also an important contribution for future research.
