# [Manipulating Trajectory Prediction with Backdoors](https://arxiv.org/abs/2312.13863)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
The paper investigates potential security vulnerabilities in trajectory prediction models for autonomous vehicles. Specifically, it studies "backdoors" - where an attacker embeds a correlation between a trigger pattern and a target misbehavior during training. At test time, the trigger then reliably causes the undesired target trajectory prediction. This could endanger safe maneuvers of autonomous vehicles.

Proposed Solution: 
The authors systematically analyze different types of triggers, including spatial (agent's position), temporal (braking pattern over time), behavioral (synchronized maneuvers) and composite (combinations thereof). They empirically demonstrate that a state-of-the-art trajectory prediction model (Autobot) is vulnerable to learning these backdoor correlations, even with only 5% contaminated training data. The most effective attack uses a composite trigger. Defenses based on off-road detection and clustering to support manual inspection are proposed and evaluated.

Main Contributions:
- Categorization and empirical analysis of trajectory prediction backdoor triggers 
- Demonstrating vulnerability of Autobot model to triggers with as little as 5% contaminated training data
- Showing triggers can work even for non-causal agents behind the target
- Proposing off-road detection to catch some threats, clustering to reduce manual inspection effort 
- Calling for actions to verify dataset integrity and further research into understanding and mitigating backdoor vulnerabilities for trajectory prediction.

In summary, this is the first comprehensive study of backdoor attacks on trajectory prediction for autonomous driving. It highlights these models' vulnerability, limitations of defenses, and needs for improving security and trustworthiness. The findings have significant implications for real-world deployment.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the key points from the paper:

The paper shows that trajectory prediction models are vulnerable to backdoor attacks where a specific trigger maneuver causes the model to predict a chosen incorrect trajectory, even with only 5% poisoned training data.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. It presents a categorization of different triggers (e.g. spatial, temporal, behavioral, composite) that could be used to attack trajectory prediction models. 

2. It shows experimentally that a state-of-the-art trajectory prediction model is vulnerable to these triggers, even when only 5% of the training data is poisoned. The model learns to associate the trigger with an attacker-chosen response.

3. It shows that the trigger does not need to come from a causal agent - even an agent behind the target vehicle can trigger the response. 

4. It evaluates some preliminary defenses against such backdoors, including offroad detection and clustering to support manual inspection. These have some effect but do not completely solve the problem.

5. The paper overall calls attention to the threat of backdoors in trajectory prediction models, which has implications for the safety of autonomous vehicles that rely on such models. It suggests this should be an area of further research to understand and mitigate such vulnerabilities.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with it are:

- Trajectory prediction
- Backdoors
- Triggers
- Trigger-activated responses (TARs)
- Spatial triggers
- Temporal triggers 
- Behavioral triggers
- Composite triggers
- Threat model
- Defenses (off-road detection, masking, clustering)
- nuScenes dataset
- Autonomous vehicles
- Motion forecasting
- Security

The paper investigates vulnerabilities in trajectory prediction models for autonomous vehicles. It introduces different types of backdoor triggers (spatial, temporal, behavioral, composite) that can reliably cause a specific target trajectory prediction when activated. It also analyzes possible defenses against such backdoors, like off-road detection, data masking, and clustering to support manual inspection. The experiments are done using the nuScenes dataset and the Autobot trajectory prediction model. Overall, the key focus is on security issues in trajectory forecasting for self-driving vehicles.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes different types of triggers such as spatial, temporal, behavioral and composite triggers. Can you explain in more detail how each trigger type works and what it tries to achieve? What are the key differences between them?

2. The paper shows that even a trigger agent behind the target vehicle can influence its trajectory prediction. Can you analyze why this is the case even though such an agent should not causally affect the target vehicle's movement? 

3. For the temporal trigger based on braking behavior, the paper uses a formula to compute a physically feasible braking trajectory. Can you explain this formula in more detail and discuss how it was derived? What assumptions were made?

4. In the experiments, even when the model was trained only on trigger-target pairs, the error never reached zero. What are some potential reasons for why the model struggled to perfectly fit these patterns?

5. The paper tried different forms of masking/data augmentation as defenses. Can you analyze why these did not prevent the model from learning the backdoors? What limitations did these defenses have?

6. For the clustering-based defense, can you explain in depth how the number of clusters affects the total number of samples needing inspection? What is the tradeoff involved?  

7. The paper suggests trajectory prediction is vulnerable to backdoors due to the complexity and uncertainty inherent in modeling interactive driving scenarios. Can you expand on this idea and discuss specific challenges that make these models susceptible?

8. What implications does the success of backdoor attacks have for companies deploying trajectory prediction models in real-world autonomous driving systems? What steps should they take?

9. Can you think of other types of triggers and target responses that were not explored in this paper but could also potentially work as backdoors? Explain your reasoning.

10. The defenses proposed in this paper are admittedly basic first steps. Can you propose ideas for more robust backdoor defenses tailored to the trajectory prediction task? What are open problems left for future work?
