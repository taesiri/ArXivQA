# [Manipulating Trajectory Prediction with Backdoors](https://arxiv.org/abs/2312.13863)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
The paper investigates potential security vulnerabilities in trajectory prediction models for autonomous vehicles. Specifically, it studies "backdoors" - where an attacker embeds a correlation between a trigger pattern and a target misbehavior during training. At test time, the trigger then reliably causes the undesired target trajectory prediction. This could endanger safe maneuvers of autonomous vehicles.

Proposed Solution: 
The authors systematically analyze different types of triggers, including spatial (agent's position), temporal (braking pattern over time), behavioral (synchronized maneuvers) and composite (combinations thereof). They empirically demonstrate that a state-of-the-art trajectory prediction model (Autobot) is vulnerable to learning these backdoor correlations, even with only 5% contaminated training data. The most effective attack uses a composite trigger. Defenses based on off-road detection and clustering to support manual inspection are proposed and evaluated.

Main Contributions:
- Categorization and empirical analysis of trajectory prediction backdoor triggers 
- Demonstrating vulnerability of Autobot model to triggers with as little as 5% contaminated training data
- Showing triggers can work even for non-causal agents behind the target
- Proposing off-road detection to catch some threats, clustering to reduce manual inspection effort 
- Calling for actions to verify dataset integrity and further research into understanding and mitigating backdoor vulnerabilities for trajectory prediction.

In summary, this is the first comprehensive study of backdoor attacks on trajectory prediction for autonomous driving. It highlights these models' vulnerability, limitations of defenses, and needs for improving security and trustworthiness. The findings have significant implications for real-world deployment.
