# [HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive   Speech Detection via Large Language Models](https://arxiv.org/abs/2403.11456)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Detecting offensive content online is important to limit harmful effects, but models often don't generalize well across datasets due to differences in how "offensive content" is defined and labeled.  
- Curating customized datasets for offensive speech detection is costly, time-consuming, and emotionally taxing.  
- Current techniques also fail to provide intuitive explanations to end users.

Proposed Solution:
- Introduce HateCOT, a dataset of 52K samples from diverse existing corpora, with explanations generated by GPT-3.5-Turbo and human-curated.
- Show pre-training models on HateCOT boosts performance on 3 benchmark datasets for offensive speech detection using open-sourced language models, in both zero-shot and few-shot settings.
- Assess quality of model-generated explanations using GPT-4 judgments on criteria like fluency, soundness, and alignment with definitions.

Main Contributions:
1) Release the HateCOT dataset to reduce data curation costs and enhance cross-dataset generalization.
2) Demonstrate HateCOT's efficacy for pre-training and low-resource fine-tuning across domains and tasks related to offensive speech detection.  
3) Evaluate LLMs' capability to generate high-quality explanations for offensive speech detection using HateCOT, useful for content moderation transparency.

In summary, the paper introduces a novel dataset HateCOT to alleviate common issues around developing offensive speech detection models, and shows empirical evidence of its benefits like better generalization and explainability through extensive experiments.
