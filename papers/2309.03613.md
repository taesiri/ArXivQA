# [Evaluating ChatGPT as a Recommender System: A Rigorous Approach](https://arxiv.org/abs/2309.03613)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question that this paper addresses is:How effective is ChatGPT as a recommender system and how does it compare to state-of-the-art recommender systems and other large language models?The paper seems to focus on comprehensively evaluating ChatGPT's capabilities as a recommender system. Specifically, it aims to assess ChatGPT's performance across various metrics like accuracy, diversity, novelty, bias etc. and compare it with traditional recommender system algorithms as well as other large language models like GPT-3.5 and PaLM. The key aspects that the paper seems to explore through experiments on 3 datasets are:- ChatGPT's accuracy in making relevant recommendations compared to baselines (RQ1a)- The diversity and novelty of ChatGPT's recommendations (RQ1b) - Presence of biases in ChatGPT's recommendations (RQ1c)- Determining what type of recommender system ChatGPT resembles the most (RQ1d)- ChatGPT's ability to leverage user preferences for re-ranking (RQ2)- ChatGPT's performance in cold-start scenarios with limited user data (RQ3)So in summary, the central research question is assessing if and how well ChatGPT is able to function as a recommender system in comparison with specialized recommender systems and other language models. The paper aims to do this through a rigorous experimental evaluation across various metrics and datasets.


## What is the main contribution of this paper?

Based on my review, the main contributions of this paper appear to be:1. It conducts a comprehensive experimental evaluation to assess ChatGPT's capabilities as a recommender system, across three different datasets - MovieLens, Last.FM, and Facebook Book. 2. It thoroughly compares ChatGPT's performance to several state-of-the-art recommender system algorithms, including both collaborative filtering and content-based approaches, as well as other large language models like GPT-3.5 and PaLM-2.3. Through these comparisons, it provides valuable insights into the inherent strengths and weaknesses of ChatGPT as a recommender system. Key findings include:- In its vanilla form, ChatGPT can provide recommendations comparable in accuracy to state-of-the-art methods, even without optimizations like prompt engineering.- ChatGPT tends to exhibit lower diversity but higher novelty in book recommendations, and good novelty in music.- ChatGPT demonstrates varying degrees of popularity bias across datasets, requiring efforts to address this.  - It behaves most similar to hybrid/collaborative recommenders, balancing popularity and content.- It shows ability to effectively utilize user profiles for re-ranking and personalization.- It can provide good recommendations even in cold-start scenarios, outperforming specialized models.4. The study methodology is rigorous, replicable, and based on standard evaluation metrics and baselines. The code and datasets are also made publicly available.5. It provides a foundation for future work on developing optimized recommender systems based on ChatGPT and other large language models.In summary, the main contribution is a comprehensive benchmarking of ChatGPT's unlabeled capabilities as a recommender system, highlighting its strengths and limitations compared to existing specialized approaches. The insights gained can inform future research on large language model based recommenders.
