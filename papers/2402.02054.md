# [Neural Scaling Laws on Graphs](https://arxiv.org/abs/2402.02054)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Neural Scaling Laws on Graphs":

Problem:
Neural scaling laws describe how model performance grows with increasing model size and dataset size. They have guided the development of large models in computer vision and natural language processing. However, scaling laws have not been explored for graph representation learning, which faces challenges due to the irregular structure and variability in size of graphs. The paper investigates scaling laws specifically for graph neural networks.

Solutions and Contributions:

1. The paper verifies that basic forms of scaling laws hold for graph tasks like node classification, link prediction and graph classification. Performance improves with increasing model size and dataset size, following power law relationships that can be quantified.

2. For model scaling, performance eventually collapses when models become extremely large, likely due to overfitting on small graph datasets. This suggests graph models are more data-hungry than CV/NLP models. Also, optimal model depth varies across tasks and architectures, so preliminary experiments are needed when designing large graph models. 

3. For data scaling, number of graphs inadequately captures variability in graph sizes. Instead, total number of edges better measures data volume. Using edges as metric provides a unified scaling law across node, link and graph prediction tasks.

In summary, the paper provides the first investigation of neural scaling laws tailored to graph data. It surfaces unique graph-specific phenomena compared to CV/NLP, while also quantifying scaling behaviors that allow extrapolation to large graph model performance. The unified scaling laws offer guidance for developing future large graph representation models.
