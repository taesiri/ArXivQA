# [Enhancing the Self-Universality for Transferable Targeted Attacks](https://arxiv.org/abs/2209.03716)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be: 

How to improve the transferability of adversarial examples for targeted attacks without requiring extra training data or efforts?

The key points are:

- The paper proposes a new attack method called Self-Universality (SU) attack that can generate transferable targeted adversarial examples more efficiently, without needing extra training data or auxiliary networks.

- The main idea is to enhance the "self-universality" of perturbations by optimizing them to be agnostic to different local regions within one image. This is done by incorporating local cropped regions along with global images during optimization and introducing a feature similarity loss.

- By making the perturbations more universal within a single image, the transferability to other models is improved for targeted attacks. This removes the need for optimizing perturbations across multiple images.

- Extensive experiments demonstrate SU attack can significantly boost targeted transfer success rates across diverse models compared to prior arts, and it can be easily combined with existing attack methods for further improvements.

In summary, the central hypothesis is that enhancing self-universality of perturbations can improve targeted transferability without extra data, which is validated through the proposed SU attack method and experiments.
