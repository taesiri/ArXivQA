# [Enhancing the Self-Universality for Transferable Targeted Attacks](https://arxiv.org/abs/2209.03716)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be: 

How to improve the transferability of adversarial examples for targeted attacks without requiring extra training data or efforts?

The key points are:

- The paper proposes a new attack method called Self-Universality (SU) attack that can generate transferable targeted adversarial examples more efficiently, without needing extra training data or auxiliary networks.

- The main idea is to enhance the "self-universality" of perturbations by optimizing them to be agnostic to different local regions within one image. This is done by incorporating local cropped regions along with global images during optimization and introducing a feature similarity loss.

- By making the perturbations more universal within a single image, the transferability to other models is improved for targeted attacks. This removes the need for optimizing perturbations across multiple images.

- Extensive experiments demonstrate SU attack can significantly boost targeted transfer success rates across diverse models compared to prior arts, and it can be easily combined with existing attack methods for further improvements.

In summary, the central hypothesis is that enhancing self-universality of perturbations can improve targeted transferability without extra data, which is validated through the proposed SU attack method and experiments.


## What is the main contribution of this paper?

 The main contribution of this paper is proposing a new transfer-based targeted attack method called Self-Universality (SU) attack. The key ideas are:

- Through experiments, the authors find that highly universal adversarial perturbations tend to be more transferable for targeted attacks. This provides new insights into designing transferable targeted attacks.

- Based on this finding, the authors propose the SU attack that enhances the universality of perturbations within one image (called self-universality) to improve targeted transferability, without requiring extra training data. 

- Specifically, SU optimizes perturbations on the global image and randomly cropped local regions, and aligns their intermediate features through a proposed feature similarity loss. This makes perturbations agnostic to different regions in the image.

- Experiments show SU significantly improves targeted transferability in both single-model and ensemble attacks. It also can be easily combined with other existing attack methods for further performance gains.

In summary, the main contribution is proposing the SU attack to improve transferable targeted attacks by enhancing self-universality of perturbations, verified through comprehensive experiments. The key novelty is getting rid of the need for extra training data.
