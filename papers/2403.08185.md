# [Perceive With Confidence: Statistical Safety Assurances for Navigation   with Learning-Based Perception](https://arxiv.org/abs/2403.08185)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Perceive With Confidence: Statistical Safety Assurances for Navigation with Learning-Based Perception":

Problem:
Rapid advances in perception have enabled large pre-trained models to process sensor observations into rich representations of the environment (e.g. occupancy predictions). However, safely integrating these models into robots remains challenging due to lack of reliability in unfamiliar environments. Specifically, two key challenges are:
1) Generalization: Pre-trained models may fail to generalize to novel environments.
2) Closed-loop distribution shift: When the perception model is used by the robot's planner, the distribution of states visited shifts away from the original training distribution, causing more errors.

Proposed Solution: 
The paper presents a framework called "Perceive with Confidence" (PWC) to provide statistical safety assurances when using pre-trained perception models. The key ideas are:

1) Use conformal prediction to quantify uncertainty in the perception model's outputs based on a calibration dataset, in order to provide assurances on correctness.

2) Address closed-loop distribution shift by considering errors from all possible locations in the calibration environments, making the assurances robust to any states visited at test time.

3) The calibrated perception system can be paired with any safe planner to ensure overall system safety. This modular approach allows easy integration.

Contributions:
1) A method to provide statistical safety assurances for pre-trained perception systems using conformal prediction. 

2) Explicit handling of generalization to novel environments and closed-loop distribution shift.

3) Demonstration of safety assurances holding both in simulation and hardware experiments with a quadruped robot navigating real unseen environments.

4) Significantly improved empirical safety over baselines, with only modest reductions in task completion rate.

In summary, the paper provides a principled framework to safely utilize unreliable perception systems by conformal calibration, allowing provable statistical safety assurances. The modular design also enables easy integration into existing systems.
