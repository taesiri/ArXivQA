# [Attention is All You Need? Good Embeddings with Statistics are   enough:Large Scale Audio Understanding without Transformers/ Convolutions/   BERTs/ Mixers/ Attention/ RNNs or ....](https://arxiv.org/abs/2110.03183)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:Can we achieve competitive performance on large-scale audio understanding tasks using only simple neural network architectures and statistics on learned embeddings, without relying on more complex methods like convolutional neural networks, Transformers, attention, etc?The key hypothesis appears to be that by learning embeddings on different representations of the mel spectrogram input (envelopes, patches, downsampled version) using basic autoencoders, clustering them, and doing statistics on the codebook assignments (bag-of-words style), they can build acoustic models that perform surprisingly well compared to state-of-the-art convolutional and Transformer models.The paper seems aimed at showing that strong baseline performance can be achieved on audio tasks using techniques that could have been applied over a decade ago, without needing the complex neural architectures that dominate current research. The goal is to demonstrate the representational power of embeddings plus statistics, and set a simple but hard-to-beat baseline.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Proposes a framework for large-scale audio understanding based purely on learned embeddings and statistics, without using convolutional, transformer, attention, or recurrent neural networks. 2. Computes statistics (bag-of-words model) over dictionaries learned from various latent representations of mel-spectrograms from vanilla autoencoders. Captures different aspects of audio signals through spectral patches, spectral envelopes, frequency band envelopes, and overall statistics.3. Shows performance can be improved by randomly masking input features, adding robustness similar to approaches like BERT. 4. Achieves strong performance competitive with convolutional and transformer architectures using simple feedforward encoding/decoding and clustering. Could have been implemented with tools available since 2006.5. Demonstrates the power of representation learning without complex end-to-end neural architectures, hopefully paving the way for progress in this direction.In summary, the key contribution is showing competitive audio understanding performance can be achieved with basic embedding and clustering techniques, without recent complex neural network architectures. The simplicity yet effectiveness is the main point.
