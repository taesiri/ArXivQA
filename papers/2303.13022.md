# [ENVIDR: Implicit Differentiable Renderer with Neural Environment   Lighting](https://arxiv.org/abs/2303.13022)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is: 

How can we achieve high-quality rendering and reconstruction of glossy surfaces from multiview images using neural rendering techniques?

Specifically, the paper aims to address the limitations of prior neural rendering methods in accurately modeling surfaces with challenging specular reflections and inter-reflections. It proposes a novel framework called ENVIDR that has the following key goals:

1) Improve rendering quality of glossy surfaces compared to state-of-the-art neural rendering models. 

2) Achieve more accurate surface geometry reconstruction than methods that may inaccurately model virtual geometry for complex reflections.

3) Retain the ability to edit scenes (e.g. relighting) by decomposing rendering components like material properties and environment lighting. 

4) Model inter-reflections to handle view-dependent indirect illumination on shiny surfaces.

The central hypothesis is that by designing a neural renderer to approximate physically based rendering with decomposed components, and integrating it with a neural surface representation, the proposed ENVIDR model can achieve these goals and effectively render high-quality views of glossy surfaces from limited input views. The experiments aim to demonstrate that ENVIDR performs equal or better than previous state-of-the-art across different metrics, while enabling scene editing capabilities.

In summary, the key research question is around developing a neural rendering approach specialized for high fidelity modeling of specular and glossy surfaces, which addresses limitations in prior work. The paper aims to show ENVIDR is an effective solution through both quantitative and qualitative evaluations.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1) A novel neural renderer that learns to approximate physically based rendering using decomposed MLPs for environment lighting, diffuse shading, and specular shading. This allows modeling complex rendering effects without needing an explicit analytical rendering equation.

2) A neural surface modeling framework called ENVIDR that employs the proposed neural renderer. By using the pre-trained diffuse and specular MLPs from the renderer, ENVIDR can represent scenes with improved rendering quality and surface geometry compared to prior work. It also enables controllable scene relighting and material editing.

3) A technique to model inter-reflections and indirect illumination by ray marching surface-reflected rays. A learned blending factor is used to combine the direct and indirect lighting. This improves rendering of glossy surfaces.

In summary, the key contribution is developing a neural renderer to approximate physical shading and using it within a neural scene representation. This approach achieves high quality rendering of challenging materials like glossy surfaces, while retaining control over lighting and materials for editing. The results demonstrate state-of-the-art performance on rendering quality and scene decomposition compared to previous methods.
