# [Primal Dual Alternating Proximal Gradient Algorithms for Nonsmooth   Nonconvex Minimax Problems with Coupled Linear Constraints](https://arxiv.org/abs/2212.04672)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
The paper considers the following nonsmooth nonconvex minimax optimization problem with coupled linear equality/inequality constraints:

\begin{align*}
\min_{x\in \mathcal{X}} \max_{\substack{y \in \mathcal{Y}\\ Ax + By \unlhd c}} \{ f(x,y) + h(x) - g(y)\}
\end{align*}

where $f(x,y)$ is nonconvex in $x$ and concave/linear in $y$, $h(x)$ and $g(y)$ are convex functions, $\mathcal{X}$ and $\mathcal{Y}$ are convex compact sets, $A,B$ are matrices, $c$ is a vector, and $\unlhd$ represents inequality/equality constraints. 

This general problem has many applications but is very challenging to solve due to the nonconvexity, coupled constraints and composite objective. Prior works mostly focus on special cases without constraints or consider only the smooth setting.

Proposed Solution:

1. Establish strong duality for the inner maximization problem w.r.t. $y$ by using Lagrangian duality and Sion's minimax theorem. This leads to an equivalent problem.

2. Propose two single-loop primal-dual first-order algorithms:

- PDAPG for nonconvex-(strongly)concave case 
- PDPG-L for nonconvex-linear case

Both algorithms alternately update $x,y,\lambda$ via proximal/projected gradient steps on the Lagrangian function.

Main Contributions:

1. First strong duality result for the inner nonconvex problem that enables primal-dual approach.

2. First algorithms for nonsmooth nonconvex minimax optimization with coupled linear constraints that have iteration complexity guarantees:

- PDAPG achieves $\mathcal{O}(\varepsilon^{-2})$ (resp. $\mathcal{O}(\varepsilon^{-4})$) for nonconvex-strongly concave (resp. nonconvex-concave) case.

- PDPG-L achieves $\mathcal{O}(\varepsilon^{-3})$ for nonconvex-linear case.

3. PDAPG is optimal for the nonconvex-strongly concave setting.

4. Numerical experiments demonstrate efficiency of the proposed algorithms.

In summary, this paper provides an important theoretical foundation and practical algorithms for an very challenging class of minimax optimization problems with constraints. The results significantly expand the scope of minimax problems that can be effectively solved.
