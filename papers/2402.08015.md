# [Enhancing Amharic-LLaMA: Integrating Task Specific and Generative   Datasets](https://arxiv.org/abs/2402.08015)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) like LLaMA-2 have shown impressive capabilities but support few languages, leaving low-resource languages like Amharic behind. 
- Adapting LLMs to new languages requires quality instruction datasets which are labor intensive to create.

Proposed Solution: 
- Create Amharic instruction datasets from existing task-specific datasets using a data pipeline.
- Collect new generative datasets like stories, poems and song lyrics.  
- Combine high-quality human-curated Amharic instruction data with machine-translated instruction data.
- Fine-tune LLaMA-2-Amharic model on these datasets.

Key Contributions:
- Instruction dataset creation pipeline that can generate datasets for other languages.
- New generative datasets collected for Amharic.
- Analysis showing improved performance from adding task-specific and generative datasets.  
- Open-sourced code, datasets and models to facilitate future Amharic LLM research.

The authors fine-tuned LLaMA-2-Amharic model on a combination of high-quality human-curated instruction datasets and machine-translated instruction datasets. Their analysis demonstrates enhanced performance on Amharic NLP tasks from supplementing with carefully curated, generative and task-specific data. They plan to create more Amharic instruction datasets and analyze cultural bias introduction.
