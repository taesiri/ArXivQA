# [Unified Recurrence Modeling for Video Action Anticipation](https://arxiv.org/abs/2206.01009)

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the key research focus of this paper is on developing a unified recurrent modeling approach for video action anticipation. The main hypothesis seems to be that generalizing recurrence through a message passing framework on graph-structured representations can lead to better performance on the video action anticipation task. Specifically, the paper proposes modeling video action anticipation by transferring sequence learning into a graph representation learning problem using message passing neural networks. The key ideas are:- Representing video frames as a graph with vertices and edges, where vertices represent frame features and edges represent relationships between frames. - Using self-attention as a universal building block for routing information between vertices (frames) to implement the core message, update and readout functions in message passing.- Learning edge connections explicitly using strategies like template banks and class token projections, instead of just relying on implicit edge estimations based on vertex similarity.The central hypothesis is that this proposed unified recurrent modeling approach with explicit edge learning will be more effective for video action anticipation compared to prior sequence modeling methods like LSTM or vanilla self-attention models. The experimental results on a large-scale egocentric video dataset seem to confirm this hypothesis.In summary, the key novelty is in reformulating video action anticipation as a graph representation learning problem and using message passing with explicit edge learning to model the temporal relationships. The paper aims to show this is an effective modeling approach for the video anticipation task.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution seems to be proposing a unified recurrent modeling approach for video action anticipation using a message passing framework. Specifically:- They generalize the recurrence mechanism by transferring sequence learning into a graph representation realized via message passing. - They use self-attention as the universal building block to extract information from vertices and edges in the graph. Vertices represent spatial regions and edges describe connectivity.- Self-attention performs implicit edge estimation via scaled dot-product attention. They also propose explicit edge learning strategies like template bank and class token projection to better approximate edge connectivity.- They evaluate their method on the EPIC-Kitchens dataset and show it outperforms prior state-of-the-art approaches for egocentric action anticipation. The edge learning strategies provide further gains.- Their model provides a flexible way to perform recurrence for anticipation using self-attention and message passing on graph structured representations. The graph connectivity can be implicitly estimated or explicitly modeled.In summary, the key contribution seems to be introducing a unified recurrence framework for video action anticipation based on message passing on graphs with self-attention, along with strategies for learning edge connectivity. The proposed model achieves new state-of-the-art results.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a unified recurrent modeling approach for video action anticipation that utilizes a message passing framework with self-attention to learn graph-structured space-time representations, and introduces edge learning strategies to explicitly approximate the connectivity between vertices.


## How does this paper compare to other research in the same field?

Here are some key ways this paper on unified recurrence modeling for video action anticipation relates to other research in the field:- It proposes a new recurrent modeling approach based on message passing on graphs and self-attention. Many other methods use RNNs or temporal convolutions for modeling temporal relationships. Treating video as a graph and using self-attention for message passing is a novel approach.- It focuses on the task of action anticipation, predicting actions before they occur, rather than action recognition. Other recent work has also focused on anticipation, but this paper provides a new modeling approach tailored for this task.- It incorporates explicit edge learning strategies into the model, going beyond just using self-attention for implicit edge learning. This allows learning more flexible graph connectivity patterns. Other graph neural nets for video also learn edges, but not in the context of a recurrence model.- It achieves state-of-the-art results on the challenging EPIC-Kitchens egocentric video dataset for anticipation. This demonstrates the effectiveness of the proposed approach compared to prior recurrent and transformer models for this task. - The model is flexible and lightweight, using only self-attention layers rather than a full transformer architecture. This contrasts with some other work adapting transformers for video understanding tasks.- It connects ideas from self-attention, message passing neural networks, and recurrence to provide a unified modeling framework. This builds upon a range of related research areas in a novel way tailored for video anticipation.In summary, the key novelties are proposing a new recurrent modeling approach for video built on graphs and self-attention, with a focus on action anticipation, and showing its effectiveness empirically on a challenging egocentric video dataset. The paper relates closely to work on graph modeling, recurrence, self-attention, and action anticipation.
