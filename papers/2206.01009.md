# [Unified Recurrence Modeling for Video Action Anticipation](https://arxiv.org/abs/2206.01009)

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the key research focus of this paper is on developing a unified recurrent modeling approach for video action anticipation. The main hypothesis seems to be that generalizing recurrence through a message passing framework on graph-structured representations can lead to better performance on the video action anticipation task. Specifically, the paper proposes modeling video action anticipation by transferring sequence learning into a graph representation learning problem using message passing neural networks. The key ideas are:- Representing video frames as a graph with vertices and edges, where vertices represent frame features and edges represent relationships between frames. - Using self-attention as a universal building block for routing information between vertices (frames) to implement the core message, update and readout functions in message passing.- Learning edge connections explicitly using strategies like template banks and class token projections, instead of just relying on implicit edge estimations based on vertex similarity.The central hypothesis is that this proposed unified recurrent modeling approach with explicit edge learning will be more effective for video action anticipation compared to prior sequence modeling methods like LSTM or vanilla self-attention models. The experimental results on a large-scale egocentric video dataset seem to confirm this hypothesis.In summary, the key novelty is in reformulating video action anticipation as a graph representation learning problem and using message passing with explicit edge learning to model the temporal relationships. The paper aims to show this is an effective modeling approach for the video anticipation task.
