# [Modularized Networks for Few-shot Hateful Meme Detection](https://arxiv.org/abs/2402.11845)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Modularized Networks for Few-shot Hateful Meme Detection":

Problem:
- Hateful memes that target vulnerable groups are increasingly used to spread hate online. Detecting such memes is challenging as it requires reasoning across modalities (image and text) to understand the nuanced messages. 
- Existing detection methods rely on extensive supervised learning, which is resource intensive. Acquiring sufficient labeled data is difficult with new events unfolding rapidly.
- Few-shot learning for hateful meme detection is underexplored. Standard in-context learning methods that prompt models with few examples tend to underperform.

Proposed Solution:
- Propose modularized networks that acquire essential reasoning skills from related tasks and compose them for hateful meme detection.
- Identify 3 key skills: understanding hate, decoding memes, explaining hate. Learn specialized LoRA modules on relevant tasks of hate speech detection, meme comprehension and hateful meme explanation.  
- Images are converted to text for language models. Text and captions are fed as prompts.
- A module composer learns to assign importance scores to modules using few labeled meme examples. Scored modules are averaged into a composed module.
- Modularized networks integrate composed module with frozen language models for customized hateful meme detection with efficiency at inference.

Main Contributions:
- First exploration of few-shot learning for hateful meme detection.
- Novel modularized networks that acquire detection skills from related tasks and compose them in a parameter-efficient way.
- Superior performance over standard in-context learning methods on 3 benchmark datasets, even with only 4 examples.
- More efficient during inference as few-shot examples are not repeatedly processed like in-context methods.
- Enhanced model interpretability owing to specialized reasoning modules.
