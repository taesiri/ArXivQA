# [A Systematic Review of Data-to-Text NLG](https://arxiv.org/abs/2402.08496)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper presents a systematic review of the literature on data-to-text natural language generation (NLG). The goal is to provide a comprehensive analysis of the state of research in this rapidly evolving field and identify gaps to guide future work. 

The paper first explains that data-to-text NLG involves generating coherent texts from structured, non-linguistic inputs like databases, knowledge graphs, or tables. It outlines the traditional pipelined architecture as well as recent neural approaches. The overview summarizes key trends from rule-based methods to statistical models and contemporary neural techniques.

The paper then states its research questions, focusing on standard datasets, languages, techniques/methods, hallucination mitigation, evaluation metrics, and application areas in data-to-text research. The methodology adheres to PRISMA guidelines for systematic reviews, detailing the search process across reputed databases and conferences, resulting in 90 selected papers after applying inclusion/exclusion criteria.

The results present comprehensive analyses around the outlined research questions. For datasets, WebNLG, E2E, WikiBio, and RotoWire emerge as most widely used, with tables being the predominant input structure. Multilingual generation remains English-focused, but studies show promise for European languages. Neural methods now prevail, especially transformers and graph networks. Hallucination measures encompass dataset/model refinements and controllable decoding. BLEU leads automatic evaluation while human assessments focus on fluency. Key applications include dialog systems, sports/news narratives, biographies, and translation.  

The discussion highlights researcher preferences for WebNLG/E2E datasets, BLEU metric, transformer models, and task-specific hallucination measures. The paper recommends greater emphasis on contextual evaluation metrics, standardized human evaluation protocols, mitigation for numerical/logical hallucinations in general large language models, and extensions to more low-resourced languages.

In conclusion, this comprehensive systematic review consolidates extensive knowledge on data-to-text NLG to inform ongoing and future research directions in this important field.
