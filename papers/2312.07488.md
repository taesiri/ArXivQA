# [LMDrive: Closed-Loop End-to-End Driving with Large Language Models](https://arxiv.org/abs/2312.07488)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a detailed summary paragraph of the key points in the paper:

This paper introduces LMDrive, a novel end-to-end autonomous driving framework that can process natural language instructions along with multi-modal sensor data to drive the vehicle. The model consists of a vision encoder that encodes camera and LiDAR input into scene representations, and a large language model (LLM) that takes the sensor representations and instructions to output control actions. They also contribute a language-guided driving dataset with 64K clips of sensor data paired with navigation and notice instructions, as well as the LangAuto benchmark to evaluate driving performance based on language commands. Extensive experiments demonstrate LMDrive's ability to effectively follow instructions like "turn left" while safely rejecting misleading directions. Compared to prior autonomous driving methods that use fixed inputs, LMDrive allows human-like interaction through natural language and better reasoning in complex scenarios. The authors posit they are the first tosuccessfully leverage large language models for closed-loop, end-to-end autonomous driving. They open source the dataset, benchmark, and model to facilitate further research at the intersection of language models and robotics control.
