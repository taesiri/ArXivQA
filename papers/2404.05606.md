# [Learning Topology Uniformed Face Mesh by Volume Rendering for Multi-view   Reconstruction](https://arxiv.org/abs/2404.05606)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Obtaining a topologically consistent 3D face mesh is challenging. The traditional approach involves first reconstructing a raw mesh using multi-view stereo (MVS) algorithms followed by deforming a template mesh to match the topology using non-rigid registration. However, this pipeline struggles with noise, non-Lambertian effects, and can accumulate errors. Recent learning-based methods require ground truth scans or registrations for supervision which are expensive to acquire. 

Proposed Solution:
This paper proposes a novel neural volume rendering approach to directly reconstruct a topologically consistent face mesh from multi-view images. The key ideas are:

1) Mesh Volume Rendering: Transform point-to-mesh distance into volume density to enable differentiable rendering. Approximate normals and reduce sampling based on an OCTree to accelerate the process.

2) Deformation-Invariant Feature Spreading: A learnable MLP-based module that spreads implicit texture features defined on the mesh surface into the surrounding space to simulate a radiance field. Uses relative coordinate transforms to make the field deformation-invariant.

3) Optimization: Vertices positions, implicit textures, and feature spreading module are optimized using landmark, mask, shading losses and mesh regularization to reconstruct geometry and appearance. Uses initialization and alternating optimization schemes.


Main Contributions:

- First method to directly reconstruct topologically consistent face mesh from multi-view images via neural volume rendering.

- Novel deformation-invariant feature spreading module to simulate radiance field using discrete mesh representation. Enables consistent rendering even after editing mesh.

- Demonstrates high quality reconstruction, rendering, and animation using the reconstructed editable mesh avatars.
