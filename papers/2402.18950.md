# [PopALM: Popularity-Aligned Language Models for Social Media Trendy   Response Prediction](https://arxiv.org/abs/2402.18950)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Social media platforms exhibit millions of daily events, making it difficult to track public reactions to all events. 
- Existing work on response generation focuses on generic responses without considering popularity factors that indicate mainstream reactions.
- There is a lack of research on predicting trendy/popular responses to social media events that can reflect public opinions.

Proposed Solution:
- The paper proposes Popularity-Aligned Language Models (PopALM) to train language models to generate top-liked responses to social media events. 
- PopALM employs reinforcement learning, specifically proximal policy optimization (PPO), to optimize language models towards responses that would receive more "likes" as a measure of popularity.
- To address noisy "like" labels, PopALM integrates curriculum learning strategies into PPO for more effective training, including reward enhancement, reward ranking, and self-paced sampling.

Main Contributions:
- First study on trendy response prediction to forecast mainstream reactions to social media events.
- Construction of a large-scale Weibo dataset with over 30K events and user responses labeled with like numbers.
- Novel PopALM framework to align language model training with popularity measures through tailored curriculum learning enhanced PPO.
- Experiments showing PopALM helps boost performance of language models like GPT-2, LLaMA, and ChatGLM in trendy response prediction.

In summary, the paper pioneers the task of trendy response prediction and proposes PopALM to leverage response popularity through curriculum learning strategies for superior language model training.
