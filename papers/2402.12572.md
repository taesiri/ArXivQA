# [FairProof : Confidential and Certifiable Fairness for Neural Networks](https://arxiv.org/abs/2402.12572)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper proposes a system called FairProof for issuing publicly verifiable certificates of fairness for neural network models, while maintaining confidentiality of the model weights. 

Problem: Machine learning models are being increasingly used in high-stakes societal applications like credit scoring, crime prediction, etc. This has raised concerns about their fairness or bias. However, legal and privacy requirements often demand that these models remain confidential. This leads to a lack of trust among end-users regarding the fairness of model predictions. The paper argues for the need of a solution that can publicly verify fairness of a confidential model and guarantee that the same model is used for every user.

Proposed Solution - FairProof: The system has two main components. 

1. Fairness Certification Algorithm: This algorithm inspects the neural network model weights to compute a personalized certificate of fairness for a given user input. The notion of fairness used is local individual fairness, which evaluates if the model gives the same output for similar individuals. The key ideas here are:
   - Reduce certification of local individual fairness to an instance of certifiable robustness by fixing sensitive features.
   - Use an iterative algorithm GeoCert to efficiently compute certificates. 
   - Compute a lower bound on the certificate for efficiency.
   
2. Cryptographic Protocol using Zero Knowledge Proofs (ZKPs): This allows a prover (e.g. bank) to prove correctness of the fairness certificate to a verifier (e.g. customer) without revealing model weights. Key ideas include:
   - Strategically decompose verification into proving a few key sub-functions.
   - Use representative points inside polytopes for efficiency.
   - Do some computations offline to reduce online overhead.

The paper theoretically proves security and correctness guarantees for FairProof. It is implemented and evaluated on standard benchmark datasets to demonstrate practical feasibility.

Main Contributions:
1) A personalized fairness certification algorithm tailored for neural networks that outputs a certificate indicating if the model is fair at a given data point.
2) An efficient ZKP-based protocol for verifying the correctness of the certificate publicly without violating model confidentiality.
3) An end-to-end system FairProof that combines these ideas to enable issuing verifiable certificates of local individual fairness for neural networks.
4) Experimental evaluation on real datasets showing FairProof can distinguish fair/unfair models and has reasonable time/communication overheads.
