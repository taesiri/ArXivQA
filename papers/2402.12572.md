# [FairProof : Confidential and Certifiable Fairness for Neural Networks](https://arxiv.org/abs/2402.12572)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper proposes a system called FairProof for issuing publicly verifiable certificates of fairness for neural network models, while maintaining confidentiality of the model weights. 

Problem: Machine learning models are being increasingly used in high-stakes societal applications like credit scoring, crime prediction, etc. This has raised concerns about their fairness or bias. However, legal and privacy requirements often demand that these models remain confidential. This leads to a lack of trust among end-users regarding the fairness of model predictions. The paper argues for the need of a solution that can publicly verify fairness of a confidential model and guarantee that the same model is used for every user.

Proposed Solution - FairProof: The system has two main components. 

1. Fairness Certification Algorithm: This algorithm inspects the neural network model weights to compute a personalized certificate of fairness for a given user input. The notion of fairness used is local individual fairness, which evaluates if the model gives the same output for similar individuals. The key ideas here are:
   - Reduce certification of local individual fairness to an instance of certifiable robustness by fixing sensitive features.
   - Use an iterative algorithm GeoCert to efficiently compute certificates. 
   - Compute a lower bound on the certificate for efficiency.
   
2. Cryptographic Protocol using Zero Knowledge Proofs (ZKPs): This allows a prover (e.g. bank) to prove correctness of the fairness certificate to a verifier (e.g. customer) without revealing model weights. Key ideas include:
   - Strategically decompose verification into proving a few key sub-functions.
   - Use representative points inside polytopes for efficiency.
   - Do some computations offline to reduce online overhead.

The paper theoretically proves security and correctness guarantees for FairProof. It is implemented and evaluated on standard benchmark datasets to demonstrate practical feasibility.

Main Contributions:
1) A personalized fairness certification algorithm tailored for neural networks that outputs a certificate indicating if the model is fair at a given data point.
2) An efficient ZKP-based protocol for verifying the correctness of the certificate publicly without violating model confidentiality.
3) An end-to-end system FairProof that combines these ideas to enable issuing verifiable certificates of local individual fairness for neural networks.
4) Experimental evaluation on real datasets showing FairProof can distinguish fair/unfair models and has reasonable time/communication overheads.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

The paper proposes a system called FairProof that uses zero-knowledge proofs to enable organizations to publicly verify the fairness of their confidential neural network models on individual user queries while ensuring model uniformity.


## What is the main contribution of this paper?

 According to the paper, the main contribution is proposing a system called "FairProof" that enables model owners to issue publicly verifiable certificates of fairness for neural network models while maintaining model confidentiality. Specifically:

1) They propose a fairness certification algorithm that can generate a certificate of individual fairness for a neural network model by inspecting the model weights after training. This algorithm is designed to be amenable to efficient verification using zero-knowledge proofs.

2) They design an efficient cryptographic protocol using zero-knowledge proofs that allows a model owner to prove the correctness of the fairness certificate without revealing the model weights. This protocol guarantees model uniformity and enables public verification of the certificate.

3) They implement the system using the Gnark zk-SNARK library and empirically demonstrate its practical feasibility on standard benchmark datasets. The results show reasonable overhead in terms of computation time and communication costs for verifying fairness of small neural networks.

So in summary, the main contribution is an end-to-end system called FairProof that enables confidential and verifiable fairness certification for neural network models using zero-knowledge proofs.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this paper include:

- Fairness certification - The paper focuses on developing a mechanism to certify the fairness of machine learning models, specifically neural networks. 

- Individual fairness - The notion of fairness used in the paper is individual fairness. This evaluates the fairness of a model for a specific data point rather than aggregate statistics.

- Robustness - The paper reduces the problem of certifying individual fairness to an instance of certifying robustness. It then builds upon techniques from robustness literature.

- Zero-knowledge proofs (ZKPs) - ZKPs allow the model owner to prove certain statements about the model's fairness without revealing the actual model or sensitive information. This maintains confidentiality.

- Verification - The paper proposes protocols for an external user to verify the correctness of the fairness certificate using the ZKP, without access to the private model itself. 

- Piecewise linear neural networks - The paper focuses on certifying fairness for neural networks with ReLU activations, which partition the input space into polytopes.

- GeoCert algorithm - An existing algorithm to compute robustness certificates by iteratively searching for the closest decision boundary facet. The paper adapts this algorithm for the fairness setting.

- Efficiency - One of the goals is to design the certification and verification process to be efficient in terms of computational overhead and proof size.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper proposes reducing the problem of certifying individual fairness to an instantiation of certifying robustness. What is the intuition behind this reduction and what does it simplify in terms of designing the certification algorithm?

2. The paper uses the GeoCert algorithm for computing robustness certificates. Explain in detail the working of GeoCert and why it is more efficient than a naive robustness certification algorithm. 

3. Instead of computing the exact distance to facets, the paper computes only a lower bound using projections. Explain why computing projections is easier and what is the tradeoff involved in reporting only a lower bound certificate.

4. The paper breaks down verification of the overall certification into 5 modular sub-tasks. What is the motivation behind this? Explain each of the 5 sub-tasks in detail. 

5. Explain the key ideas behind the VerifyPolytope sub-routine and how it leverages the property that each polytope has a unique ReLU activation code.

6. The VerifyNeighbor sub-routine relies on pre-computed representative points of polytopes. Explain how these points are used and why computing them in an offline phase improves efficiency.

7. The VerifyBoundary routine checks if a given facet lies on the decision boundary. Explain how the computation of the linear function associated with a polytope is used here. 

8. Priority queues are not natively supported in ZK proof systems. How does the paper get around this challenge in the VerifyOrder sub-routine?

9. The paper computes commitments to the model weights. Explain how this leads to guaranteeing model uniformity in the proposed system.

10. Discuss the advantages and limitations of using ZK proofs for verifying properties of machine learning models, in light of what is proposed in this paper.
