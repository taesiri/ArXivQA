# [Open-vocabulary Video Question Answering: A New Benchmark for Evaluating   the Generalizability of Video Question Answering Models](https://arxiv.org/abs/2308.09363)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we develop video question answering models that can better generalize to rare and unseen answers? The key hypothesis is that current video QA models are biased towards frequent answers seen during training, and fail to generalize to rare or unseen answers. To address this, the authors propose a new benchmark called Open-Vocabulary Video QA (OVQA) to specifically measure performance on rare and unseen answers. They also propose a graph neural network based "soft verbalizer" method to help models better adapt to rare and unseen answers.In summary, the main goal of the paper is to develop video QA models that are less biased and can better handle the long tail of infrequent answers, as well as completely unseen answers. The OVQA benchmark and soft verbalizer method are proposed as ways to both measure and improve model generalization in this area.


## What is the main contribution of this paper?

This paper proposes a new benchmark and method for open-vocabulary video question answering. The main contributions are:- Introducing a new benchmark called Open-Vocabulary Video Question Answering (OVQA) to evaluate models on their ability to answer questions with rare or unseen answers. This tests generalization beyond just frequent answers.- Proposing a GNN-based soft verbalizer to smooth answer embeddings by aggregating information from similar words. This helps improve performance on rare and unseen answers. - Developing new baselines by modifying existing open-ended VQA models to handle out-of-vocabulary answers. Experiments show consistently improved performance by handling rare/unseen answers.- Extensive ablation studies and analyses demonstrating the effectiveness of the proposed GNN-based soft verbalizer in improving generalization and handling long-tail distributions of answers.In summary, the key contribution is introducing a new benchmark and method to assess and improve the generalization capability of open-ended video QA models to rare and unseen answers, beyond just frequent ones. The GNN-based soft verbalizer is shown to be an effective technique for this.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a new benchmark and method for open-vocabulary video question answering that aims to improve model generalization on rare and unseen answers.
