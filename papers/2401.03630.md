# [Why Solving Multi-agent Path Finding with Large Language Model has not   Succeeded Yet](https://arxiv.org/abs/2401.03630)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
The paper studies using large language models (LLMs) like ChatGPT to directly solve the multi-agent path finding (MAPF) problem without any additional training or tools. MAPF involves coordinating the paths of multiple agents from their start to goal positions without collisions. It combines the challenges of planning and multi-agent coordination.

Approach: 
The authors propose having the LLM generate actions for each agent at every timestep based on prompts describing the scenario, agent positions, goals etc. A high-level checker ensures the solution is valid by catching collisions. If invalid, the LLM is prompted to correct its solution. This continues in a step-by-step fashion until the agents reach their goals.

Results:
- LLMs can solve small MAPF instances on empty maps but fail on more complex maps with obstacles, even for only 2 agents
- Break down reasons for failure into:
   - Model capacity limit with long context
   - Inability to understand obstacle locations from map
   - Lack of reasoning capability for optimization objectives like makespan
- Show experiments with different prompts, context lengths etc to analyze failure causes

Contributions:
- First work analyzing ability of LLMs to directly solve MAPF 
- Show success on simple cases and failure on harder ones
- Provide detailed analysis of what capabilities are lacking via breakdown of failure reasons
- Discuss how these limitations can potentially be addressed in future work to make progress

In summary, the paper provides a comprehensive first study of using unmodified LLMs for MAPF. The analysis of failures sets the stage for developing methods to overcome these limitations in the future.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

This paper studies using large language models to directly solve multi-agent path finding without additional training or tools, shows initial success in simple scenarios but failure in more complex ones, and analyzes the reasons behind the failures in understanding, reasoning, and model capacity.


## What is the main contribution of this paper?

 The main contribution of this paper is:

1) Showing that large language models (LLMs) can solve simple multi-agent path finding (MAPF) problems directly through prompting, such as scenarios with a small number of agents on an empty map. 

2) Analyzing the reasons why LLMs fail on more complex MAPF problems, breaking it down into three main aspects - context length limitations of LLMs, lack of capability to understand and remember obstacle locations, and lack of reasoning capability for planning and coordination.

3) Supporting the analysis on LLM failures on MAPF with extensive experiments, including testing various prompt design choices.

4) Providing a discussion on challenges and potential ideas to address the limitations of using LLMs for solving complex MAPF problems. 

Overall, the paper studies the promise and current limitations of using LLMs to solve MAPF, one of the first works analyzing LLM performance on multi-agent planning problems. The breakdown of failure reasons and extensive analysis serve as a useful building block for future research on applying foundation models to MAPF and multi-agent coordination problems in general.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with it are:

- Multi-agent path finding (MAPF)
- Multi-robot route planning
- Large language models (LLMs)
- Reasoning capability
- Context length limit
- Understanding obstacle locations
- Prompting
- Foundation models
- Collision avoidance
- Makespan optimization 

The paper studies using large language models like ChatGPT to directly solve the multi-agent path finding problem without additional training or tools. It shows some initial success on simple scenarios but also elaborates on current limitations related to reasoning capability, context length, and understanding maps that prevent the models from solving more complex MAPF instances. Relevant keywords cover both the MAPF problem itself as well as properties of the LLMs.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper mentions using a high-level conflict checker to ensure the plan generated by the LLM is valid. What are some ways this conflict checker could be improved or augmented to provide more useful feedback to the LLM? 

2. The paper breaks down reasons for LLM failure into limitations in model capacity, understanding, and reasoning. Which of these limitations do you think is the most fundamental issue limiting LLM performance on MAPF? Why?

3. The paper explores different prompt formulations like image-based inputs vs pure text. What other prompt formulations could be worth exploring that might better convey map and scenario information to the LLM?

4. The paper hypothesizes that publicly releasing MAPF scenarios and solutions could help improve LLM reasoning on this task. What are some challenges in curating such a dataset? How could the data be structured to best facilitate learning?  

5. The paper uses a simple grid-based MAPF formulation. How might the reasons for LLM failure generalize or differ on more complex MAPF variants like those defined on graphs?

6. Could modularizing the LLM, with separate components focusing on understanding the map vs planning agent paths, improve performance? What are some ways this could be implemented?

7. The paper has humans provide feedback when LLM plans are invalid. Could this human feedback be replaced by an automated planner to reduce human effort? What are the tradeoffs?

8. The paper identifies context length as an issue. How well could a hierarchical planning approach that first plans high-level agent paths and then refines them address this?

9. What modifications to the LLM architecture itself could better support multi-agent planning tasks like MAPF? For example, adding differentiable memory.

10. The paper studies MAPF in simulation. How might the reasons for LLM failure differ if applied to real-world robot path planning problems? Are there additional challenges to address?
