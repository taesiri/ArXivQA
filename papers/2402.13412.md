# [Scaling physics-informed hard constraints with mixture-of-experts](https://arxiv.org/abs/2402.13412)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Imposing physical constraints (e.g. conservation laws) during neural network training can improve accuracy, reliability, and data efficiency for modeling physical systems. 
- Hard constraints that strictly enforce physical laws through optimization have advantages over soft penalty-based methods, but are computationally expensive as they require solving an optimization problem over a large spatiotemporal grid.
- The complexity grows drastically with mesh and model size, making it difficult to scale up and apply to complex systems.

Proposed Solution:
- Develop a mixture-of-experts (MoE) approach called Physics-Informed Hard Constraint Mixture-of-Experts (PI-HC-MoE) to enforce hard physical constraints in a scalable manner.
- Decompose the spatial domain into smaller partitions, where each "expert" enforces the constraint locally through optimization. This reduces the complexity of each individual constraint.
- Experts perform localized backpropagation using the implicit function theorem. The independence of experts allows parallelization across GPUs.
- Final prediction is a combination of all expert solutions. MoE formulation allows flexibility in locally weighting basis functions while satisfying global constraint.

Main Contributions:
- Introduce a scalable physics-informed MoE framework for imposing hard constraints by differentiating through physical simulations.
- Apply PI-HC-MoE to nonlinear PDEs - diffusion-sorption and turbulent Navier-Stokes. Achieves higher accuracy than soft constraints and standard hard constraints.  
- PI-HC-MoE exhibits computational and memory efficiency improvements compared to standard differentiable optimization, with sub-linear scaling as constrained points increase.
- Demonstrate stability, scalability and efficiency benefits of localizing hard constraints through the MoE formulation.

In summary, the paper presents a mixture-of-experts approach to scale the enforcement of hard physical constraints in neural networks. By decomposing the constraint into smaller localized experts, they are able to achieve better accuracy and stability along with computational and memory benefits.
