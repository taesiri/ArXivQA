# [MobileUtr: Revisiting the relationship between light-weight CNN and   Transformer for efficient medical image segmentation](https://arxiv.org/abs/2312.01740)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes MobileUtr, an innovative and lightweight universal medical image segmentation network that effectively combines CNNs and Vision Transformers (ViTs). A key contribution is the ConvUtr block which efficiently provides denoised and non-redundant semantic embeddings to the ViT encoder. An adaptive Local-Global-Local (LGL) module is also introduced to enable effective exchange between local and global information flows, enhancing the Transformer's context modeling capacity. Experiments across ultrasound, dermoscopy, and CT datasets demonstrate MobileUtr's superior performance over state-of-the-art methods, achieving comparable or higher accuracy while requiring 10x fewer parameters and computations. The proposed innovations at the infrastructure level to synergize CNN inductive bias and ViT representational power pave the way for efficient yet accurate networks for medical vision tasks. Overall, MobileUtr sets a new benchmark as the first lightweight ViT solution that generalizes well across multiple medical imaging modalities.
