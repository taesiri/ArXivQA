# [Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept   Customization of Diffusion Models](https://arxiv.org/abs/2305.18292)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be:How can we enable decentralized multi-concept customization of diffusion models by merging individually trained concept models, while preserving the identity and quality of each concept?The key challenges identified are:1) Concept conflict that arises from existing LoRA tuning methods not differentiating between the roles of embeddings vs weights. This results in semantically similar embeddings projecting to visually distinct concepts, causing conflicts during model fusion. 2) Identity loss of individual concepts when simply averaging weights of different concept models, due to compromising the inference behavior of each concept.To address these challenges, the central hypothesis seems to be:By decomposing the concept embedding to capture in-domain essence and using gradient-based fusion to align concept behaviors, we can achieve decentralized multi-concept customization while preserving identity.So in summary, the paper focuses on enabling high-quality fusion of independently trained concept models through novel embedding decomposition and gradient fusion techniques. The goal is decentralized customization with minimal concept conflicts or identity loss.
