# [Learning to Learn Faster from Human Feedback with Language Model   Predictive Control](https://arxiv.org/abs/2402.11450)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: Large language models (LLMs) like PaLM can generate robot code from natural language instructions to make robots learn new behaviors rapidly through in-context learning. However, this adaptation is limited to short-term interactions where previous instructions can be forgotten over longer conversations. The paper aims to improve the "teachability" of LLMs, defined as how efficiently they adapt to human feedback to successfully complete tasks. 

Proposed Solution: The paper introduces Language Model Predictive Control (LMPC), which combines in-context learning with LLM fine-tuning. During the day, non-experts teach new behaviors to robots through natural language feedback, enabling fast adaptation via in-context learning. At night, the LLM is fine-tuned on the collected interaction data to "remember" and improve adaptation. Formulating the interactions as a POMDP, LMPC trains the LLM to model human-robot chat dynamics and uses model predictive control at inference for faster search to task success.

Key Contributions:

- LMPC framework to fine-tune LLMs with human-robot conversation data to improve teachability

- Achieves 26.9% higher success rates on unseen tasks with fewer corrections (from 2.4 to 1.9 on average)

- Identifies top-performing users automatically and shows conditioning on them during LMPC rollouts further improves performance 

- Demonstrates strong generalization - improvements transfer to new unseen robot platforms and APIs

- Extensive experiments with 5 robot platforms, 78 tasks, and non-expert users show consistently improved teachability over base LLMs and retrieval methods

In summary, the paper presents LMPC to make large language models more efficiently adaptable to human feedback over longer interactions when teaching robot behaviors. Both offline LLM fine-tuning and online adaptation are combined in a mutually improving cycle.
