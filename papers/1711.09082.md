# [Cross-Domain Self-supervised Multi-task Feature Learning using Synthetic   Imagery](https://arxiv.org/abs/1711.09082)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central hypothesis is that learning visual representations from multiple complementary synthetic image modeling tasks and adapting them to real images via adversarial training can produce features that are useful for real-world vision tasks. Specifically, the key claims are:- Training a model on multiple related tasks (surface normal, depth, and contour prediction) encourages it to learn more general features compared to training on a single task.- Using synthetic data provides unlimited training examples with free ground truth annotations for these multiple tasks.- Adapting the learned features from synthetic to real images via adversarial domain adaptation makes the features more transferable to real-world vision tasks.The main goal is to show that the proposed multi-task learning approach on synthetic data combined with unsupervised domain adaptation can learn visual features that are competitive or better than existing self-supervised approaches on transfer learning benchmarks like PASCAL VOC classification/detection and ImageNet classification.
