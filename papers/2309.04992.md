# [Mitigating Word Bias in Zero-shot Prompt-based Classifiers](https://arxiv.org/abs/2309.04992)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper aims to address is how to make prompt-based classifiers more robust and less sensitive to the choice of prompt templates and label words. The key hypotheses are:1) Inherent word biases in language models lead to bias towards certain classes in prompt-based classifiers, making performance sensitive to prompt/label word choice. 2) By re-weighting the output probabilities, it is possible to account for these biases in an unsupervised fashion and improve robustness.3) The re-weighting can be connected theoretically to normalizing by word priors, enabling a zero-resource debiasing approach.4) Matching class priors using unlabelled data will correlate strongly with the optimal accuracy given labelled data, showing it is a near optimal use of the model's outputs.So in summary, the main goal is to analyze prompt sensitivity, demonstrate gains in robustness by re-weighting to account for word biases, and provide both empirical analysis and theoretical motivation showing this is an effective strategy. The key aim is improving prompt-based classifier effectiveness across diverse settings in a data-efficient unsupervised manner.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a simple unsupervised probability re-weighting method to mitigate word bias in prompt-based classifiers. The method uses unlabelled data to search for weight parameters that ensure a uniform prior over classes. 2. It theoretically connects the weight parameters to word priors and uses this connection to motivate a zero-resource normalisation approach for mitigating bias.3. It empirically demonstrates on several NLP tasks that the proposed re-weighting method leads to greater robustness and accuracy for diverse prompt and label word settings. 4. It shows that the unsupervised weights found through prior matching are highly correlated with the optimal oracle weights that maximize accuracy. This illustrates that the approach makes near-optimal use of the system's output probabilities.In summary, the key contribution is an unsupervised probability re-weighting technique to reduce sensitivity of prompt-based classifiers to prompt and label choices. This is achieved by ensuring uniform class priors, motivated through connections to word priors, and demonstrated to improve robustness and accuracy over diverse settings on standard NLP tasks.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes an unsupervised method to reweight the output probabilities of prompt-based classifiers to mitigate inherent biases towards certain classes, demonstrating improved robustness to prompt and label word choices across various NLP tasks.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other related research:- The idea of using unsupervised probability re-weighting to mitigate word bias in prompt-based classifiers is novel. Most prior work has focused on supervised approaches like optimizing thresholds on a labeled development set. The unsupervised prior matching method is an elegant way to improve robustness without needing any labeled data.- Connecting the re-weighting to word priors and providing a theoretical motivation for the zero-resource normalization is an important contribution. This builds a stronger theoretical grounding than some previous empirical studies onprompt sensitivity. - Demonstrating the effectiveness of the approaches on a range of standard NLP tasks (sentiment, NLI, paraphrasing) is thorough empirical validation. Many prompt tuning papers only show results on one or two tasks.- The comparison to optimal oracle thresholds provides an informative upper bound on the potential effectiveness of the method. The fact that prior matching gets quite close to optimal in most cases is impressive.- The paper complements other recent work analyzing inherent biases in LLMs and understanding prompts, like the COMPPR paper on prompt probabilities. The theoretical analysis here goes a step further towards debiasing.Overall, the unsupervised probability reweighting approach appears quite novel compared to prior work. The paper also makes solid theoretical contributions and provides extensive empirical support. I think this represents an advance in robust prompt tuning and bias mitigation for LLMs.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Exploring different methods for estimating the class priors P(y|Q) and P(y|D). The paper uses a simple empirical estimate over the dataset, but mentions this could be improved, for example by using the LM's predictive distribution. - Applying the proposed debiasing approaches to a wider range of models and tasks. The paper demonstrates results on FlanT5, but it would be interesting to test the robustness on other large language models and across more text classification tasks.- Further analysis into what factors influence and explain the inherent biases in prompt classifiers. The paper connects this to word priors, but further theoretical analysis could provide more insight.- Developing alternative methods to account for bias beyond reweighting class probabilities. For example, directly modifying the model to reduce reliance on word priors.- Exploring whether similar issues around robustness occur for generative prompting methods, and if so, how inherent biases could be mitigated.- Testing whether the bias mitigation approaches can lead to more robust performance on out-of-domain or adversarial test cases.Overall, the paper presents promising initial results on improving prompt classifier robustness by accounting for class biases. But there are many avenues for extending this analysis further across models, tasks, and methods.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the key points from the paper:The paper analyzes prompt-based classifiers and demonstrates that inherent class bias is a significant factor that influences their sensitivity to prompt and label word choice. The authors propose an unsupervised approach of prior matching to reduce this sensitivity, where class probabilities are reweighted to match the true class priors. This is shown to perform competitively to a supervised search for optimal thresholds, while avoiding the need for labelled data. Theoretical analysis connects prior matching to word biases, motivating a zero-resource normalisation approach using null inputs that is competitive with prior matching. Overall, the unsupervised methods are empirically shown to greatly reduce sensitivity to the prompt and label words across a range of NLP tasks, with many failing settings made effective through simple probability reweighting. Key results are that the weights from prior matching closely correlate with optimal oracle weights, and that matching class priors is critical for robustness.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:The paper studies prompt-based classifiers, which are a popular zero-shot approach for natural language processing tasks where large language models (LLMs) are conditioned on a prompt to elicit the desired behavior. However, performance is sensitive to the choice of prompt template and label words, which is attributed in part to "word biases" where the LM has inherent biases towards certain words. The paper proposes a simple unsupervised approach to re-weight the class probabilities output by the model to account for these biases. Specifically, they re-weight to match the class priors on unlabeled data, showing this leads to greater robustness across prompt templates and label choices. They also connect the re-weighting to normalizing by word priors, motivating a zero-resource approximation using null inputs. Experiments across sentiment analysis, natural language inference, and paraphrase detection tasks demonstrate large gains in accuracy and robustness from the re-weighting approaches. For example, gains of 6-25% are shown on the baseline accuracy over different prompt settings. The weights found via prior matching also align closely with the optimal oracle weights found using labeled data.In summary, this paper demonstrates that inherent word biases significantly influence prompt-based classifiers, and proposes an unsupervised probability re-weighting method to account for this. Matching the empirical class distribution is shown to be an effective way to mitigate sensitivity to the prompt template and label words. Connections to word priors are leveraged to enable zero-resource approximations. The methods lead to large boosts in accuracy and robustness over a variety of common NLP tasks.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper:The paper proposes an unsupervised approach to mitigate word biases in prompt-based classifiers for zero-shot text classification. The method re-weights the raw probabilities output by a large language model for each class word using scalar parameters. It finds weights such that the resulting class prior matches a uniform distribution, under the assumption there should be no inherent class bias. This re-weighting is shown to increase robustness to the choice of prompt template and label words. An approximation connects the optimal weights to the inverse of word priors, motivating a zero-resource method. Experiments demonstrate large gains over baseline prompting across several NLP tasks. The unsupervised weights are shown to highly correlate with the oracle weights found by directly maximizing accuracy on a labelled dataset. Overall, the method provides a simple way to reduce sensitivity in prompt design and convert poor settings into effective classifiers through probability reweighting.
