# [BASE TTS: Lessons from building a billion-parameter Text-to-Speech model   on 100K hours of data](https://arxiv.org/abs/2402.08093)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Traditional neural text-to-speech (TTS) systems trained on hundreds of hours of data struggle to generalize to complex input texts and render them with expressive and natural spoken prosody. This is partly due to the reliance on explicit supervision and the lack of large amounts of diverse multi-speaker data.

Proposed Solution:
- The paper proposes BASE TTS, a 1 billion parameter autoregressive Transformer TTS model trained on 100,000 hours of unlabeled speech data. It models text tokens jointly with discrete speech representations called "speechcodes".

- Novel speechcodes are introduced that capture phonemic/prosodic information but not speaker identity. This is done by discretizing a WavLM self-supervised speech model and disentangling speaker embeddings. Speechcodes are compressed using byte-pair encoding.

- A convolution-based end-to-end "speechcode decoder" is used to generate waveforms from speechcodes and speaker embeddings. This enables streamable and 3x faster synthesis compared to diffusion-based decoding.

Main Contributions:

I) BASE TTS with 1B parameters trained on 100K hours of data, the largest open TTS model known by the authors. It outperforms other large TTS models in naturalness.

II) Evidence of "emergent abilities" is shown as dataset and model sizes increase, judged by improvements in an expert linguistic evaluation of rendering complex input texts.

III) Novel speechcode representations capturing primarily phonetic/prosodic content are proposed. Paired with an efficient speechcode decoder, high quality and streamable neural TTS is achieved.

In summary, the paper demonstrates state-of-the-art neural TTS quality with BASE TTS, while also providing evidence that scaling model size and data leads to better textual understanding and prosody generation abilities. The proposed representations and streamable decoder offer compute and speed improvements.
