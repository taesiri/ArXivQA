# Prompting Contrastive Explanations for Commonsense Reasoning Tasks

## What is the central research question or hypothesis that this paper addresses?

This paper addresses the problem of getting large pretrained language models (PLMs) like T5 and BART to provide human-interpretable explanations for their decisions on commonsense reasoning tasks. The central hypothesis is that prompting the PLMs to generate contrastive explanations that explicitly compare the possible answers will elicit relevant commonsense knowledge embedded in the models' parameters, improving both task performance and explanation quality compared to prior approaches.Specifically, the key aspects of the paper are:- Commonsense reasoning tasks often require comparing plausible alternatives and human explanations tend to be contrastive in nature. - The authors develop a set of contrastive prompt templates that can be filled in by PLMs to generate explanations that contrast the possible answers (e.g. "X is Y while Z is W").- A two-stage framework where an "explainer" PLM generates contrastive explanations from the prompts, and a "task" PLM makes predictions conditioned on the original input and explanations.- Contrastive explanations improve task accuracy over non-contrastive baselines, with notable gains in the zero-shot setting.- Human evaluations show contrastive explanations are more useful than prior approaches. - Contrastive prompts allow evaluating faithfulness by manipulating explanations (e.g. flipping contrast).So in summary, the main hypothesis is that prompting for contrastive explanations will better elicit commonsense knowledge from PLMs in a human-interpretable way, leading to quantitative and qualitative improvements over prior approaches. The results support this hypothesis.


## What is the main contribution of this paper?

Based on my reading, the key contributions of this paper are:1. Proposing an unsupervised method to generate contrastive explanations for commonsense reasoning tasks by prompting PLMs to complete specialized templates. This constrained generation process produces more useful explanations compared to prior work on unconstrained free-form generation. 2. Demonstrating improved task performance on two commonsense reasoning benchmarks (WSC and PIQA) by having a separate task model condition its predictions on the generated contrastive explanations. Notably, the gains are larger in the zero-shot setting and when training data is limited.3. Enabling new evaluations of explanation faithfulness by manipulating the generated contrastive explanations, either by flipping the contrast or abstracting the identities of the fact and foil. Results indicate the model relies on the explanations to some extent.4. Conducting human evaluations showing the contrastive explanations are deemed more useful than prior work with clarification questions or unconstrained generation.5. Demonstrating the generalizability of the approach by using the same prompts designed for WSC/PIQA and achieving strong zero-shot performance on CommonsenseQA.In summary, the main contribution is presenting an unsupervised and human-centered approach to generate constrained yet customizable explanations that are shown to be useful through both automated and human evaluations. The contrastive explanation format also enables new ways to analyze the models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes an unsupervised method to generate contrastive natural language explanations for commonsense reasoning tasks by prompting pretrained language models to complete contrastive templates that differentiate answer choices, which improves task performance and enables novel evaluations of explanation faithfulness.
