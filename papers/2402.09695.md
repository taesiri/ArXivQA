# [Reward Poisoning Attack Against Offline Reinforcement Learning](https://arxiv.org/abs/2402.09695)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper studies the problem of reward poisoning attacks against offline reinforcement learning algorithms. In offline RL, the agent trains on a fixed offline dataset to learn a good policy. The paper considers an attack setting where an adversary can corrupt the reward signals in the training dataset with the goal of misleading the learning algorithm. The challenges in designing such attacks include the fixed training data, lack of access to the training process, limited learnable policies due to offline setting, and black-box threat model where the attacker has no knowledge of the learning algorithm.

Proposed Solution: 
The paper proposes a novel attack strategy called "policy contrast attack" to address the challenges. The key idea is to make some low-performing policies appear high-performing in the adversarial reward while making high-performing policies appear low-performing. This attack framework is derived based on theoretical insights on manipulating the performance rankings of good and bad policies. The attack first identifies bad and good policies using the training data, then increases rewards for actions similar to bad policy and decreases rewards for actions similar to good policies.

Main Contributions:
- Proposes the first black-box reward poisoning attack against general offline RL setting, requiring no access to training process or knowledge of learning algorithm.
- Provides theoretical analysis on attack design against offline RL algorithms.
- Empirically demonstrates efficiency of proposed attack against state-of-the-art offline RL algorithms on standard benchmarks, significantly outperforming baseline attack.
- Analysis shows attack is robust to choices of attack hyperparameters and budgets.
- Highlights vulnerability of current offline RL methods, motivating development of more robust algorithms.

In summary, the paper makes significant contributions in exposing and addressing the vulnerability of offline RL methods to data poisoning attacks via a novel black-box attack strategy and analysis.
