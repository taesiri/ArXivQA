# [Is Homophily a Necessity for Graph Neural Networks?](https://arxiv.org/abs/2106.06134)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: Is homophily a necessary condition for graph neural networks (GNNs) like graph convolutional networks (GCNs) to achieve good performance on semi-supervised node classification tasks?The paper challenges the prevalent notion in prior literature that GNNs rely on homophily (the tendency for connected nodes to share the same label) and fail to generalize to heterophilous graphs (where nodes with different labels connect). The authors find empirically that GCNs can actually outperform methods designed specifically for heterophilous graphs on some benchmark datasets. This motivates them to re-examine the assumption that homophily is crucial for GNNs like GCNs to work well.Through theoretical analysis and additional experiments, the paper argues that homophily is not strictly necessary. Rather, GCNs can perform well on both homophilous and heterophilous graphs, as long as same-label nodes share similar neighborhood patterns. The key conditions identified are:1) Nodes with the same label have similar neighborhood distributions 2) Different classes have distinguishable neighborhood distributionsUnder these conditions, GCNs can map same-label nodes close together in the embedding space, enabling good separability and performance. The paper carefully characterizes when these conditions hold on both synthetic and real-world benchmark graphs.In summary, the central hypothesis is that homophily is not a mandatory assumption for GCNs, which can achieve strong performance on certain heterophilous graphs. The key conditions for good performance are based on neighborhood distribution similarity within and across classes, not the graph's overall homophily level.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Empirically showing that standard graph convolutional networks (GCNs) can achieve strong performance on some commonly used heterophilous graph benchmarks, outperforming some recent methods specifically designed for heterophilous settings. This challenges the notion that GCNs fundamentally require homophily to work well. - Providing theoretical analysis on when and why GCNs are able to learn similar embeddings for nodes with the same label, which facilitates node classification. The key conditions are: (1) nodes with the same label have similar neighborhood patterns, and (2) different labels have distinguishable neighborhood patterns. - Characterizing different types of "good" and "bad" heterophily based on these theoretical insights. Showing that heterophily alone is not sufficient for poor GCN performance - certain types of heterophily allow GCNs to work well.- Investigating common benchmark datasets using the developed understanding to reason about when and why GCNs succeed or struggle on them. In summary, the main contribution is providing a new perspective to understand when and why GCNs can work on both homophilous and heterophilous graphs, contradicting the popular notion that homophily is a necessity for GCNs and that they fail on heterophilous graphs. The theoretical and empirical analysis supports this revised understanding.
