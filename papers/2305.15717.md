# [The False Promise of Imitating Proprietary LLMs](https://arxiv.org/abs/2305.15717)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: can cheaply imitating proprietary large language models (LLMs) like ChatGPT enable open-source models to match their capabilities? The authors critically analyze the efficacy of "model imitation", where weaker open-source LMs are finetuned on outputs from stronger proprietary LLMs like ChatGPT. Their hypothesis is that model imitation may provide an easy shortcut for open-source models to match proprietary ones, without needing as much compute or data.However, through experiments training a variety of imitation models and evaluating them with humans and benchmarks, the authors find that model imitation has limited efficacy. Imitation models largely just mimic the style of proprietary models, not their capabilities. The authors conclude there still exists a substantial gap between open and closed LLMs that can only be closed by developing better base models, not by imitation shortcuts.In summary, the central hypothesis is that model imitation can cheaply close the gap between open and closed LLMs. But through experiments, the authors find this is a "false promise" and that improving base model quality is more important.
