# [Mitigating Fine-Grained Hallucination by Fine-Tuning Large   Vision-Language Models with Caption Rewrites](https://arxiv.org/abs/2312.01701)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes ReCaption, a novel framework to mitigate fine-grained object hallucination in instruction-tuned large vision-language models (LVLMs). ReCaption has two main components: rewriting image captions using ChatGPT via a two-stage prompting strategy, and additional training of LVLMs on the rewritten captions to strengthen image-text alignment. To evaluate ReCaption's effectiveness, the authors introduce a new fine-grained probing-based evaluation method called Fine-Grained Object Hallucination Evaluation (FGHE) which measures hallucinated object attributes and behaviors. Experiments conducted on various LVLMs like mPLUG-Owl, LLaVA, MultiModal-GPT and MiniGPT-4 demonstrate that integrating ReCaption significantly reduces fine-grained hallucinations and improves text generation quality across models. The proposed framework is model-agnostic and evaluation using both FGHE and the existing POPE metric shows substantial gains over baseline LVLMs. The work highlights the promise of leveraging high-quality rewritten captions to enhance visual grounding and reasoning in LVLMs.
