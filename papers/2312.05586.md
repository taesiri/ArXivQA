# [Deeper Understanding of Black-box Predictions via Generalized Influence   Functions](https://arxiv.org/abs/2312.05586)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "Deeper Understanding of Black-box Predictions via Generalized Influence Functions":

Problem:
- Influence functions are used to understand how training data affects model predictions, but have limitations in modern large and non-convex models:
    - They become inaccurate and unstable to compute as model size increases. 
    - They change all model parameters, even those irrelevant to the analyzed data.

Proposed Solution:
- Introduce "generalized influence functions" (GIFs) that:
    - Precisely estimate influence of chosen "target parameters" while considering "fixed parameters'" effects.
    - Identify pertinent target parameters closely related to analyzed data.
    - Use a robust algorithm to approximate GIFs that guarantees convergence for any network.
- Suggest lightweight methods to choose target parameters in models with linear/convolutional layers. 

Main Contributions:
- Define generalized influence functions that can selectively analyze model parameters most relevant to given data.
- Prove GIF approximation algorithm always converges by utilizing scale-invariance and positive-definiteness.
- Develop parameter selection methods inspired by network pruning that choose highly active neurons.  
- Show GIFs are faster, more accurate, and more stable than prior influence functions in experiments on ResNet/VGG for tasks like class removal and backdoor recovery.
- Demonstrate best model utility when only small subset of parameters is modified, confirming suspicion that excessive changes cause decline in utility.

In summary, the paper introduces more versatile and practical influence functions via novel generalization, robust approximation, and parameter selection techniques. This enables deeper understanding of model predictions, appealing to both experts and general readers.
