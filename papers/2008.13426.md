# [Self-supervised Video Representation Learning by Uncovering   Spatio-temporal Statistics](https://arxiv.org/abs/2008.13426)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: How can we learn effective spatio-temporal video representations in a self-supervised manner without relying on manually labeled data?The main hypothesis is that by designing a pretext task that uncovers spatio-temporal statistics from unlabeled videos, such as locations and motion directions of salient motions, a neural network can be trained to learn powerful and transferable spatio-temporal representations for video understanding.Specifically, the key hypotheses are:1) Learning to uncover spatio-temporal statistics like dominant motions and color changes from videos can serve as an effective pretext task for self-supervised video representation learning. 2) The learned representations can transfer well and achieve strong performance on various downstream video analysis tasks such as action recognition, video retrieval, dynamic scene recognition, etc.3) The proposed pretext task is simple and intuitive yet captures informative spatio-temporal characteristics of videos, compared to techniques like predicting future frames which can be ambiguous.4) Explicitly encoding spatial locations instead of regressing to exact coordinates makes the learning task easier and more feasible.5) A curriculum learning strategy can further boost the representation learning by presenting more difficult examples gradually.In summary, the central hypothesis is that by carefully designing a pretext task based on spatio-temporal statistics, informative and transferable video representations can be learned effectively in a self-supervised manner. The paper conducts experiments to validate the effectiveness of the proposed approach over several backbone architectures and on various downstream tasks.
