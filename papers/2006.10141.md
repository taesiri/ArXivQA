# [Self-supervised Learning on Graphs: Deep Insights and New Direction](https://arxiv.org/abs/2006.10141)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research questions/goals appear to be:1) To deepen understandings on when, why, and which strategies of self-supervised learning (SSL) work with graph neural networks (GNNs) for the task of semi-supervised node classification.2) To propose a new direction called "SelfTask" to build advanced pretext tasks that can achieve state-of-the-art performance by exploiting task-specific self-supervised information.The key hypothesis seems to be that task-specific self-supervised information (leveraging label information of labeled nodes) can enable the design of more powerful pretext tasks compared to only using attribute or structure information.The paper first introduces various basic SSL pretext tasks and analyzes their impact on GNN performance through empirical studies. This is aimed at providing insights on when and why SSL works for GNNs. Then, based on the insights gained, the paper proposes the SelfTask framework to create advanced pretext tasks exploiting task-specific information. Experiments demonstrate SelfTask can achieve state-of-the-art performance, validating the hypothesis that task-specific SSL information is effective for building pretext tasks for GNNs.In summary, the central goals are to gain insights on SSL for GNNs and propose a new direction called SelfTask to design advanced pretext tasks leveraging task-specific information, with the key hypothesis that such information enables stronger pretext tasks. The empirical analysis and experiments aim to address these goals.


## What is the main contribution of this paper?

This paper proposes several novel self-supervised learning (SSL) methods for graph neural networks (GNNs). The key contributions are:- It analyzes various basic SSL pretext tasks on graphs to understand when and why SSL works for GNNs. The analysis provides insights on which SSL strategies are more effective for GNNs. - It proposes a new direction called "SelfTask" to design advanced SSL pretext tasks for GNNs. SelfTask exploits task-specific information to construct pretext tasks beyond just using structure or attribute information.- It develops several SelfTask methods including Distance2Labeled, ContextLabel, EnsembleLabel, and CorrectedLabel. These methods leverage label information in different ways to create pretext tasks.  - It conducts extensive experiments on benchmark datasets to demonstrate the effectiveness of the proposed SelfTask methods. The results show SelfTask can boost GNN performance and achieve state-of-the-art results.In summary, the key contribution is the proposal and evaluation of novel SSL strategies (SelfTask) for GNNs that can better exploit task-specific information to create more effective SSL pretext tasks. The analysis and designs provide useful insights on how to develop SSL for graph data.
