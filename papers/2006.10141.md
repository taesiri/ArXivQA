# [Self-supervised Learning on Graphs: Deep Insights and New Direction](https://arxiv.org/abs/2006.10141)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research questions/goals appear to be:1) To deepen understandings on when, why, and which strategies of self-supervised learning (SSL) work with graph neural networks (GNNs) for the task of semi-supervised node classification.2) To propose a new direction called "SelfTask" to build advanced pretext tasks that can achieve state-of-the-art performance by exploiting task-specific self-supervised information.The key hypothesis seems to be that task-specific self-supervised information (leveraging label information of labeled nodes) can enable the design of more powerful pretext tasks compared to only using attribute or structure information.The paper first introduces various basic SSL pretext tasks and analyzes their impact on GNN performance through empirical studies. This is aimed at providing insights on when and why SSL works for GNNs. Then, based on the insights gained, the paper proposes the SelfTask framework to create advanced pretext tasks exploiting task-specific information. Experiments demonstrate SelfTask can achieve state-of-the-art performance, validating the hypothesis that task-specific SSL information is effective for building pretext tasks for GNNs.In summary, the central goals are to gain insights on SSL for GNNs and propose a new direction called SelfTask to design advanced pretext tasks leveraging task-specific information, with the key hypothesis that such information enables stronger pretext tasks. The empirical analysis and experiments aim to address these goals.
