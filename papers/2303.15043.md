# [Joint Video Multi-Frame Interpolation and Deblurring under Unknown   Exposure Time](https://arxiv.org/abs/2303.15043)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to perform joint video multi-frame interpolation and deblurring under unknown exposure time. 

Specifically, the paper aims to tackle the challenging task of reconstructing a high framerate sharp video from a low framerate blurred video where the exposure time is unknown and varies across frames. The unknown and varying exposure time makes this problem very difficult, as traditional methods assume a fixed known exposure time.

The key hypothesis is that by learning an exposure-aware feature representation and using it to adapt computations in the motion analyzer and reconstruction network, the model can handle varying levels of blur and motion better. The exposure-aware features allow the model to adapt to different exposure settings and motion patterns.

In summary, this paper proposes a new method called VIDUE to address the problem of joint video interpolation and deblurring without knowing the true underlying exposure time, which is more realistic for real-world videos. The main novelty is in learning to adapt the model computations to estimated exposure features.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes VIDUE, a unified framework for joint video multi-frame interpolation and deblurring under unknown exposure time. Previous works assume known/fixed exposure time, which is not realistic. 

2. It extracts an exposure-aware feature representation from the input video using a variant of supervised contrastive learning. This allows adapting computations in later stages to different exposure conditions.

3. It designs a motion analyzer with two U-Nets to analyze intra-motion (within frames) and inter-motion (between frames) in an exposure-aware manner. 

4. It develops a video reconstruction network that enables exposure-adaptive convolution and progressive motion refinement for high-quality frame interpolation and deblurring.

5. Extensive experiments show VIDUE outperforms state-of-the-art methods on joint ×8 and even ×16 interpolation and deblurring on both synthetic and real datasets. It also runs faster than competing methods.

In summary, the key innovation is formulating and solving the more realistic problem of joint video interpolation and deblurring without assuming known exposure time. This is achieved via an exposure-aware and motion-aware computational framework.
