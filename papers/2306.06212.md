# [Aladdin: Zero-Shot Hallucination of Stylized 3D Assets from Abstract   Scene Descriptions](https://arxiv.org/abs/2306.06212)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can the knowledge captured in foundation models like large language models, vision-language models, and diffusion models be leveraged to automatically generate stylized 3D assets from abstract scene descriptions?The key ideas and contributions of the paper appear to be:- Introducing the task of "stylized asset curation" from abstract scene descriptions using the capabilities of foundation models in a zero-shot setting. This allows generating assets for scenes beyond the limited vocabulary and concepts present in most 3D datasets.- Using natural language as an interpretable and editable intermediate representation between the different stages of the system - semantic upsampling using LMs, retrieval using VLMs, and texturing using diffusion models. This provides transparency and control.- Performing "semantic upsampling" of abstract scene descriptions into more detailed object categories, attributes, and appearances using few-shot prompting of GPT-3. This extracts common sense knowledge about scene composition.- Retrieving template shapes from 3D asset databases using CLIP embeddings for visual and textual similarity. This provides good priors for geometry and texturing. - Retexturing retrieved objects using image diffusion models conditioned on object attributes. This aligns textures to desired semantics.- Introducing a new metric, CLIP-D/S, to measure diversity and semantic coherence of generated asset collections.- Demonstrating the system's ability to generate assets for a variety of abstract scene descriptions through quantitative evaluation and human studies.So in summary, the core research contribution is utilizing the knowledge and capabilities of LLMs, VLMs and diffusion models in a novel framework to automatically generate stylized 3D assets from abstract natural language scene descriptions.
