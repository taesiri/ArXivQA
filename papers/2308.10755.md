# WanJuan: A Comprehensive Multimodal Dataset for Advancing English and   Chinese Large Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main purpose seems to be introducing and describing a new large-scale multimodal dataset called WanJuan. The key points are:- The paper introduces WanJuan, which is a large multimodal Chinese-English dataset collected from diverse web sources. It contains text, image-text, and video data. - The total size of WanJuan is over 2TB. It includes over 600 million text documents, 22 million image-text documents, and over 1000 videos.- The dataset incorporates diverse content across fields like technology, literature, media, education, law, news, and more. - Care was taken during data collection and processing to ensure safety, quality, and value alignment of the content by filtering out undesirable material.- WanJuan has been used to train InternLM, a large language model that demonstrated strong performance compared to other models. - The purpose is to provide a high-quality open dataset to facilitate research on large language models and multimodal tasks.So in summary, there is no specific hypothesis being tested, but rather the paper introduces a new comprehensive multimodal dataset to enable further research progress in this direction. The quality and usefulness of WanJuan itself seems to be the main focus.


## What is the main contribution of this paper?

The main contribution of this paper is the introduction and release of the WanJuan dataset, a large-scale, multimodal Chinese-English dataset collected from diverse web sources. Specifically, the key contributions are:- Compiling a comprehensive multimodal dataset that includes text data, interleaved image-text data, and video data in both Chinese and English. The total size of the dataset exceeds 2TB.- Ensuring the quality and safety of the dataset through careful filtering and processing. Measures were taken to remove invalid, duplicated, toxic, biased or low-quality content.- Releasing the high-quality dataset publicly to support research on large language models and multimodal tasks that require understanding across modalities. - Providing unified JSON format, download tools and documentation to facilitate use of the dataset.- Demonstrating the value of the dataset by using it to train InternLM, which showed significant improvements over models of similar scale.In summary, the key contribution is creating and openly releasing a large, diverse and high-quality multimodal dataset to enable advancement of multimodal AI research and models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper introduces WanJuan, a large multimodal Chinese-English dataset containing text, image-text, and video data totaling over 2TB, which has been used to train the InternLM model and demonstrated significant performance improvements.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper on the WanJuan dataset compares to other research on large-scale multimodal datasets:- Scope and scale: At over 2TB total, with text, image-text, and video modalities in both English and Chinese, WanJuan is one of the largest and most comprehensive multimodal datasets released. Many other datasets tend to focus on either text or image data alone.- Multimodality: WanJuan incorporates text, image-text, and video data. Many other datasets are limited to one or two modalities. The inclusion of video is particularly notable.- Language diversity: WanJuan includes both Chinese and English data. Most other large datasets focus solely on English. The inclusion of Chinese data is important for developing multilingual models.- Data sources: WanJuan aggregates data from diverse web sources, including both curated/official sources and general web crawl data. Other datasets tend to use more limited sources.- Data processing: The authors devote significant effort to cleaning, filtering, and processing the raw data. Issues like toxicity, quality, and duplication are addressed. Such processing is critical but often lacking in web-scale datasets.- Open availability: WanJuan is publicly released to advance research. Many industry datasets remain private. Open datasets like this are invaluable for the research community.So in summary, the scale, multimodality, multilinguality, diversity of sources, data processing, and open availability help differentiate WanJuan from other related datasets and advance the state-of-the-art in this domain. The release of high-quality datasets like this meaningfully pushes forward research.
