# WanJuan: A Comprehensive Multimodal Dataset for Advancing English and   Chinese Large Models

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main purpose seems to be introducing and describing a new large-scale multimodal dataset called WanJuan. The key points are:- The paper introduces WanJuan, which is a large multimodal Chinese-English dataset collected from diverse web sources. It contains text, image-text, and video data. - The total size of WanJuan is over 2TB. It includes over 600 million text documents, 22 million image-text documents, and over 1000 videos.- The dataset incorporates diverse content across fields like technology, literature, media, education, law, news, and more. - Care was taken during data collection and processing to ensure safety, quality, and value alignment of the content by filtering out undesirable material.- WanJuan has been used to train InternLM, a large language model that demonstrated strong performance compared to other models. - The purpose is to provide a high-quality open dataset to facilitate research on large language models and multimodal tasks.So in summary, there is no specific hypothesis being tested, but rather the paper introduces a new comprehensive multimodal dataset to enable further research progress in this direction. The quality and usefulness of WanJuan itself seems to be the main focus.


## What is the main contribution of this paper?

The main contribution of this paper is the introduction and release of the WanJuan dataset, a large-scale, multimodal Chinese-English dataset collected from diverse web sources. Specifically, the key contributions are:- Compiling a comprehensive multimodal dataset that includes text data, interleaved image-text data, and video data in both Chinese and English. The total size of the dataset exceeds 2TB.- Ensuring the quality and safety of the dataset through careful filtering and processing. Measures were taken to remove invalid, duplicated, toxic, biased or low-quality content.- Releasing the high-quality dataset publicly to support research on large language models and multimodal tasks that require understanding across modalities. - Providing unified JSON format, download tools and documentation to facilitate use of the dataset.- Demonstrating the value of the dataset by using it to train InternLM, which showed significant improvements over models of similar scale.In summary, the key contribution is creating and openly releasing a large, diverse and high-quality multimodal dataset to enable advancement of multimodal AI research and models.
