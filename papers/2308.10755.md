# [WanJuan: A Comprehensive Multimodal Dataset for Advancing English and   Chinese Large Models](https://arxiv.org/abs/2308.10755)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main purpose seems to be introducing and describing a new large-scale multimodal dataset called WanJuan. The key points are:- The paper introduces WanJuan, which is a large multimodal Chinese-English dataset collected from diverse web sources. It contains text, image-text, and video data. - The total size of WanJuan is over 2TB. It includes over 600 million text documents, 22 million image-text documents, and over 1000 videos.- The dataset incorporates diverse content across fields like technology, literature, media, education, law, news, and more. - Care was taken during data collection and processing to ensure safety, quality, and value alignment of the content by filtering out undesirable material.- WanJuan has been used to train InternLM, a large language model that demonstrated strong performance compared to other models. - The purpose is to provide a high-quality open dataset to facilitate research on large language models and multimodal tasks.So in summary, there is no specific hypothesis being tested, but rather the paper introduces a new comprehensive multimodal dataset to enable further research progress in this direction. The quality and usefulness of WanJuan itself seems to be the main focus.


## What is the main contribution of this paper?

The main contribution of this paper is the introduction and release of the WanJuan dataset, a large-scale, multimodal Chinese-English dataset collected from diverse web sources. Specifically, the key contributions are:- Compiling a comprehensive multimodal dataset that includes text data, interleaved image-text data, and video data in both Chinese and English. The total size of the dataset exceeds 2TB.- Ensuring the quality and safety of the dataset through careful filtering and processing. Measures were taken to remove invalid, duplicated, toxic, biased or low-quality content.- Releasing the high-quality dataset publicly to support research on large language models and multimodal tasks that require understanding across modalities. - Providing unified JSON format, download tools and documentation to facilitate use of the dataset.- Demonstrating the value of the dataset by using it to train InternLM, which showed significant improvements over models of similar scale.In summary, the key contribution is creating and openly releasing a large, diverse and high-quality multimodal dataset to enable advancement of multimodal AI research and models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper introduces WanJuan, a large multimodal Chinese-English dataset containing text, image-text, and video data totaling over 2TB, which has been used to train the InternLM model and demonstrated significant performance improvements.


## How does this paper compare to other research in the same field?

Here are a few key ways this paper on the WanJuan dataset compares to other research on large-scale multimodal datasets:- Scope and scale: At over 2TB total, with text, image-text, and video modalities in both English and Chinese, WanJuan is one of the largest and most comprehensive multimodal datasets released. Many other datasets tend to focus on either text or image data alone.- Multimodality: WanJuan incorporates text, image-text, and video data. Many other datasets are limited to one or two modalities. The inclusion of video is particularly notable.- Language diversity: WanJuan includes both Chinese and English data. Most other large datasets focus solely on English. The inclusion of Chinese data is important for developing multilingual models.- Data sources: WanJuan aggregates data from diverse web sources, including both curated/official sources and general web crawl data. Other datasets tend to use more limited sources.- Data processing: The authors devote significant effort to cleaning, filtering, and processing the raw data. Issues like toxicity, quality, and duplication are addressed. Such processing is critical but often lacking in web-scale datasets.- Open availability: WanJuan is publicly released to advance research. Many industry datasets remain private. Open datasets like this are invaluable for the research community.So in summary, the scale, multimodality, multilinguality, diversity of sources, data processing, and open availability help differentiate WanJuan from other related datasets and advance the state-of-the-art in this domain. The release of high-quality datasets like this meaningfully pushes forward research.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Applying the WanJuan dataset to train and evaluate new large language models, especially multimodal models that can understand and generate content across text, images, and video. The authors suggest the dataset could fuel further advances in this area.- Exploring different multimodal tasks using the dataset, such as video captioning, visual question answering, multimodal translation, etc. The diversity of modalities in the dataset allows for studying these kinds of tasks.- Analyzing the dataset itself - the authors suggest that with over 600 million text documents and 22 million image-text pairs, insights could be gained just from computational analysis of the dataset contents and relationships between modalities.- Studying cross-lingual transfer learning using the Chinese-English data. The authors specifically collected data in both languages to enable research on transferring knowledge across languages.- Evaluating societal biases and safety issues in the dataset and using insights to improve data filtering and debiasing approaches. Though efforts were made to filter out unsafe content, further analysis could improve safety.- Releasing additional versions of the dataset or expanding it with more modalities over time. The authors frame this as an initial release but suggest expanding it in the future.In summary, the key directions are leveraging the dataset to advance multimodal large language models and using the multimodal nature to study new cross-modal tasks and capabilities. Analyzing the dataset itself is also suggested as a direction for gaining insights.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the paper:The paper introduces WanJuan, a new large-scale multimodal dataset for training large language models. The dataset contains over 600 million text documents, 22 million image-text documents, and over 1000 videos in both Chinese and English. The text data covers diverse domains like technology, literature, law, and education. The image-text data includes news, people, landscapes, and social life images paired with descriptive texts. The high-quality video data covers numerous topics like military, arts, science, etc. The total dataset size exceeds 2TB. The dataset was cleaned and processed to ensure safety, quality, and value alignment. WanJuan was used to train InternLM which demonstrated strong performance on multi-modal tasks. The dataset aims to advance research on large multimodal models by providing a high-quality open resource. All data is freely available to download.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the paper:This paper introduces WanJuan, a large-scale multimodal Chinese-English dataset collected from diverse web sources like Common Crawl, Wikipedia, authoritative media, and textbooks. The dataset contains over 2TB of data across text, image-text, and video modalities. The text data comprises over 600 million documents in both Chinese and English covering diverse fields like technology, law, and education. The image-text data has 22 million interleaved image-text documents sourced from news and Wikipedia. The video data contains over 1000 high-quality videos from media groups. The paper describes the data cleaning and processing methods used to ensure the quality, safety, and value alignment of the dataset. This includes language detection, duplicate removal, and filtering of toxic content for the text data. For the image-text data, parsing rules, similarity checks, and selective image-text pairing were applied. The resulting high-quality dataset was used to train InternLM, which demonstrated strong performance on multi-modal tasks compared to other models of similar scale. The dataset aims to promote research in large language models and multimodal understanding by providing a rich open resource.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper:The paper introduces the WanJuan dataset, a large-scale multimodal Chinese-English dataset collected from diverse web sources including text, image-text, and video data. To construct this high-quality dataset, they applied a multi-step cleaning and filtering process to the text and image-text data. For the text data, they extracted text from web pages, performed language detection, removed invalid and duplicate documents, and filtered out unsafe or low-quality content using classifiers. For the image-text data, they wrote parsing rules to extract valid article content from webpages, removed irrelevant information, performed deduplication, and paired images with text. Through this careful data processing, they obtained a sizable multimodal dataset with over 600 million text documents, 22 million image-text documents, and 1000+ videos for training large language models.


## What problem or question is the paper addressing?

Based on my reading of the abstract and introduction, this paper introduces a new large-scale multimodal dataset called "Wan Juan" that is aimed at fueling advancements in large language models and multimodal large language models. Specifically, the key points are:- The rise of models like ChatGPT and GPT-4 has accelerated development of large language models, leading to many new impressive models. However, details of training data are often not shared publicly. - This lack of transparency limits the research community. So they created the Wan Juan dataset to provide open-source multimodal data to enable further research.- The Wan Juan dataset incorporates text, image-text, and video data in both Chinese and English collected from diverse web sources. It totals over 2TB in size.- This dataset was used to train InternLM, a model that showed significant benefits compared to similar sized models in evaluations.So in summary, the main problem this paper addresses is the lack of large-scale, open multimodal training data to enable continued progress on large language models and multimodal models. Wan Juan aims to provide such a dataset to fuel further research.
