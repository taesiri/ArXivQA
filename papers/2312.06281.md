# [EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models](https://arxiv.org/abs/2312.06281)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper introduces EQ-Bench, a new benchmark for evaluating emotional intelligence in language models. It focuses on assessing a model's ability to understand complex emotions and social dynamics by having them predict the intensity of emotional states of characters in dialogues depicting scenes of interpersonal tension or conflict. The benchmark shows strong ability to differentiate between a wide range of models, with scores correlating highly (r=0.97) with multi-domain benchmarks like MMLU that measure general intelligence. This suggests emotional intelligence acts as an effective proxy for broad intelligence in language models. The benchmark is repeatable, using 60 English dialogues, with an automated pipeline provided to facilitate testing. Methodological improvements over prior emotional intelligence benchmarks like SECEU are implemented, including more complex dialogues, a diverse selection of emotions to rate, and reference answers set by the authors. The top scoring model tested is OpenAI's GPT-4, aligning with community perceptions of it as state-of-the-art, while leading open-source models like SynthIA-70B are rapidly closing the gap. Overall, EQ-Bench enables standardized and insightful evaluation of emotional and social understanding abilities in language models.
