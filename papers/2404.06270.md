# [3D Geometry-aware Deformable Gaussian Splatting for Dynamic View   Synthesis](https://arxiv.org/abs/2404.06270)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Dynamic view synthesis aims to render novel photorealistic views from arbitrary viewpoints at any input time step given a monocular video of a dynamic scene. While neural radiance fields (NeRF) have shown impressive results for novel view synthesis of static scenes, extending their success to dynamic scenes is challenging due to the difficulty in modeling complex deformations over time. 

Key Insight: 
To achieve geometrically consistent deformation, utilizing local geometric/structural information is critical since motions of objects in the real world are highly correlated to their 3D structures. Furthermore, motions of points are coupled with motions of their neighboring points.

Method:
The paper proposes a 3D geometry-aware deformable Gaussian splatting approach consisting of two components:

1) Gaussian Canonical Field: Represents a reconstruction of the static scene using explicit 3D Gaussian distributions. A geometry-aware feature learning network based on 3D sparse convolution is introduced to extract local structural information for each Gaussian.

2) Deformation Field: Estimates a transformation for each Gaussian to transfer it from the canonical field to the given timestamp based on geometry-aware features and timestamp.

Key Contributions:

- Proposes a geometry-aware feature extraction network using 3D sparse convolution to better utilize local geometric information 

- Uses continuous 6D rotation representation and modified density control strategy to adapt Gaussian splatting to dynamic scenes

- Achieves state-of-the-art performance on both synthetic and real datasets, proving the method's capability for high-quality dynamic view synthesis and 3D reconstruction

The core idea is to represent dynamic scenes as deforming 3D Gaussians that move and rotate over time in a geometrically consistent way by exploiting local 3D geometric features, enabling photorealistic rendering of novel views at arbitrary times.
