# [Rethinking Robustness of Model Attributions](https://arxiv.org/abs/2312.10534)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing metrics to measure attributional robustness of machine learning models like top-k intersection overpenalize even reasonable local shifts in attributions. This gives a false sense of fragility of attribution methods. 
- Attribution maps can be concentrated in a small region of the image even when there are multiple important parts. This makes them more vulnerable to attacks.

Proposed Solutions:
1. Locality-sensitive metrics (LENS) 
- Incorporate locality of pixel positions along with their attribution rank order to avoid overpenalizing minor local drifts
- Propose LENS variants of top-k intersection, Spearman's rho and Kendall's tau metrics
- Show LENS metrics are upper bounded by a metric based on symmetric set difference  

2. Diverse attributions
- Pick top-k pixels greedily from different regions using a distance threshold
- Naturally extends to LENS-diversity metrics  

Key Contributions:
- Identify issues with existing attributional robustness metrics
- Propose locality-sensitive metrics (LENS) to address overpenalization 
- Introduce attributional diversity to handle concentration vulnerability
- Empirical evaluation shows limitations of current metrics and improvements from LENS and diversity
- Aligns better with human judgment of attributional changes
- Observe attributional robustness of adversarially trained models reduces on larger datasets

In summary, the paper identifies issues with commonly used attributional robustness metrics, and proposes practical solutions through locality-sensitive metrics and diverse attributions to address these limitations.
