# [Rethinking Robustness of Model Attributions](https://arxiv.org/abs/2312.10534)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing metrics to measure attributional robustness of machine learning models like top-k intersection overpenalize even reasonable local shifts in attributions. This gives a false sense of fragility of attribution methods. 
- Attribution maps can be concentrated in a small region of the image even when there are multiple important parts. This makes them more vulnerable to attacks.

Proposed Solutions:
1. Locality-sensitive metrics (LENS) 
- Incorporate locality of pixel positions along with their attribution rank order to avoid overpenalizing minor local drifts
- Propose LENS variants of top-k intersection, Spearman's rho and Kendall's tau metrics
- Show LENS metrics are upper bounded by a metric based on symmetric set difference  

2. Diverse attributions
- Pick top-k pixels greedily from different regions using a distance threshold
- Naturally extends to LENS-diversity metrics  

Key Contributions:
- Identify issues with existing attributional robustness metrics
- Propose locality-sensitive metrics (LENS) to address overpenalization 
- Introduce attributional diversity to handle concentration vulnerability
- Empirical evaluation shows limitations of current metrics and improvements from LENS and diversity
- Aligns better with human judgment of attributional changes
- Observe attributional robustness of adversarially trained models reduces on larger datasets

In summary, the paper identifies issues with commonly used attributional robustness metrics, and proposes practical solutions through locality-sensitive metrics and diverse attributions to address these limitations.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the key points from the paper:

The paper proposes locality-sensitive and diversity-based metrics to evaluate the robustness of attribution methods more accurately by avoiding overpenalization of minor deviations in attributions, and shows empirically that adversarial training confers attributional robustness on smaller datasets but not necessarily on larger ones.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1) It observes that existing metrics for evaluating attributional robustness (e.g. top-k intersection) overpenalize even reasonable local shifts in attributions, making random perturbations appear as strong attacks. To address this, the paper proposes locality-sensitive extensions of metrics like top-k intersection, Spearman's rho, and Kendall's tau that incorporate the locality of pixel attributions.

2) It introduces a new measure called top-k-div that incorporates diversity of attributions by preventing localized grouping of the top model attributions. Locality-sensitive metrics are also applied to this measure. 

3) It provides comprehensive empirical results on benchmark datasets and models, supporting the limitations of existing metrics and the benefits of using locality and diversity for evaluating attributional robustness.

4) It shows that adversarial training provides more robust attributions on smaller datasets, but this advantage disappears on larger datasets like ImageNet.

In summary, the main contribution is identifying issues with existing attributional robustness metrics and proposing locality and diversity-based improvements to these metrics, supported by extensive experiments.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Attributional robustness - The robustness of attribution methods (explanations for model predictions) to small input perturbations. The paper aims to rethink metrics and methods for evaluating this.

- Locality-sensitive metrics (LENS) - New metrics proposed in the paper that incorporate the locality or neighborhood of pixels when comparing attributions before and after perturbation. Includes LENS variants of top-k intersection, Spearman's rho, and Kendall's tau.

- Diversity - Incorporating diversity of pixel locations in attributions, instead of just using the top pixels based on attribution values. Proposed method of picking top-k diverse pixels.  

- Overpenalization of minor changes - Argument that existing attributional robustness metrics overpenalize small/local shifts in attributions, making even reasonable perturbations appear as strong attacks.

- Adversarial training - Training neural networks with adversarial examples can improve robustness. The paper examines its effects on attributional robustness.

- Integrated Gradients (IG) - A prominent gradient-based attribution method analyzed in the paper.

So in summary, key ideas involve rethinking attributional robustness metrics by incorporating locality and diversity of pixel attributions, the effects of adversarial training, analysis using the Integrated Gradients method, and avoiding overpenalization of local attribution changes.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1) The paper argues that existing attributional robustness metrics like top-k intersection overpenalize minor drifts in attributions. Can you expand more on why this overpenalization happens and why it can give a false sense of fragility of attribution methods? 

2) The LENS metrics incorporate locality of pixel attributions along with their rank order. Can you walk through the mathematical definitions introduced in the paper for LENS-top-k, LENS-Spearman and LENS-Kendall? How exactly do they capture locality compared to the original metrics?

3) Proposition 1 in the paper shows that the LENS-top-k distance defined is upper bounded by the symmetric set difference based metric. Can you explain why this proposition holds and what it implies about the characteristics of the LENS-top-k distance?

4) The concept of diversity is introduced in attributions to prevent localized grouping of top model attributions. How is the top-k-div attribution computed using the greedy optimization procedure described? Why does the matroid theory guarantee optimality here?

5) How are the LENS metrics extended to incorporate diversity in attributions? Can you write down the mathematical definitions for the LENS-recall@k-div and LENS-prec@k-div metrics? 

6) What conclusions can you draw from Figure 2 that compares different attribution methods and metrics on ImageNet with increasing attack perturbation budgets? How does the relative performance change moving down the rows?

7) Can you analyze the results in Table 1 and compare the trends in attributional robustness across different explanation methods and training procedures using the LENS and diversity based metrics? 

8) The survey results indicate that human evaluations align better with LENS based metrics compared to top-k intersection. What could be some reasons or intuitions behind this observation?

9) The paper argues that modifying the top-k attack to directly optimize for reduced LENS metric results in a weaker attack. Why could this be happening? Does it indicate some fundamentally different properties of LENS compared to top-k?

10) The paper shows PGD trained models have more robust attributions on smaller datasets but not on ImageNet. Can you hypothesize some reasons behind why this advantage diminishes for larger datasets?
