# [Subobject-level Image Tokenization](https://arxiv.org/abs/2402.14327)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Standard vision models tokenize images into fixed-size square patches, which lacks adaptability to image content and overlooks pixel grouping structure. This is analogous to ineffective character n-gram tokenization in NLP models.

Proposed Solution:
- Introduce the concept of "subobject"-level image tokenization, which represents semantically meaningful irregular image segments obtained via segmentation models. This is analogous to effective subword tokenization in NLP.

- Propose a Sequence-to-sequence AutoEncoder (SeqAE) to compress variable-sized subobject segments into compact embeddings. Uses quadratic attention and bottleneck projection.  

- Design a Large Vision Language Model (LVLM) architecture that incorporates subobject tokens into the text tokens of a large language model. Add 2D positional embeddings for subobjects.

Key Contributions:
- Concept of subobject-level image tokenization, inspired by subword tokenization in NLP.

- SeqAE model for compressing irregular image segments into compact representations.

- LVLM architecture that integrates subobject tokens into large language models.

- Experiments showing subobject tokenization enables faster vision-language learning and better recognition of visual attributes compared to standard patch tokenization.

In summary, the paper introduces a more adaptive subobject-level tokenization for images to better capture visual semantics, via the proposed SeqAE embedding model and LVLM architecture. Key innovation is drawing analogy to effective subword tokenization in NLP.
