# [TransFace: Calibrating Transformer Training for Face Recognition from a   Data-Centric Perspective](https://arxiv.org/abs/2308.10133)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we improve the performance of Vision Transformers (ViTs) for face recognition when trained on extremely large datasets?The authors find that standard ViTs do not achieve state-of-the-art results on face recognition benchmarks, even when trained on very large datasets. They hypothesize two main reasons for this:1) Existing data augmentation strategies are not well suited for ViTs in the face recognition setting, as they can destroy key facial structural information. 2) Existing hard sample mining strategies rely on biased sample difficulty indicators that are not optimal for ViTs, where the prediction is often dominated by only a few local tokens.To address these issues, the authors propose two main contributions:1) A patch-level data augmentation strategy called DPAP that perturbs the amplitude information of dominant patches to expand sample diversity while preserving structural face information.2) A novel hard sample mining strategy called EHSM that uses the information entropy of local tokens to more comprehensively measure sample difficulty.The central hypothesis is that these two tailored strategies for ViTs will improve face recognition performance to be on par or better than state-of-the-art CNNs. The experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a novel face recognition model called TransFace based on Vision Transformers (ViTs). 2. It introduces a patch-level data augmentation strategy called DPAP to alleviate overfitting in ViTs by perturbing the amplitude information of dominant patches while preserving structural information.3. It proposes a hard sample mining strategy called EHSM that utilizes information entropy of local tokens to measure sample difficulty and enhance feature representation. 4. Comprehensive experiments show that TransFace achieves state-of-the-art performance on mainstream face recognition benchmarks like IJB-C, demonstrating the effectiveness of the proposed strategies.5. This is one of the first works to systematically explore how to train superior ViT models for face recognition on extremely large datasets. The findings provide insights into alleviating overfitting and enhancing generalization of ViTs in the data-rich FR scenario.In summary, the main contribution is developing the TransFace model with tailored data augmentation and mining strategies to boost ViTs' performance for face recognition. The proposed DPAP and EHSM strategies help address the incompatibility issues of previous approaches when applied to ViTs in the FR setting.
