# [Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of   Large Language Models](https://arxiv.org/abs/2402.12563)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- There is an ongoing debate about the feasibility of intrinsic self-correction capabilities in large language models (LLMs), which refers to models correcting their own mistakes without external feedback.  
- Recent work has argued LLMs still lack adequate self-correction abilities. However, the paper hypothesizes confidence is a critical factor overlooked impacting self-correction.

Proposed Solution:
- The paper validates LLMs can effectively understand confidence in their own responses. High confidence answers aligned with multiple runs for consistency.
- An "If-or-Else" (IoE) prompting framework is introduced to guide self-correction using assessed confidence. If confident, the LLM maintains the response. If not, it updates the answer.

Key Contributions:
- Identifies confidence as an important latent factor affecting self-correction, which has been overlooked. Ignoring confidence causes over-criticism.
- Shows LLMs can accurately self-assess confidence for both deterministic and open-ended tasks.
- The IoE prompting principle efficiently improves self-correction by utilizing estimated confidence.
- Extensive experiments validate IoE prompting outperforms prior work across benchmarks and large models.

In summary, this paper demonstrates LLMs have inherent capabilities to understand confidence in their responses. The introduced IoE framework leverages this to effectively enhance self-correction performance, highlighting the significance of confidence in this process. The method requires only single inference, making it practically efficient.
