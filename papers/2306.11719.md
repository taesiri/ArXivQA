# [Diffusion with Forward Models: Solving Stochastic Inverse Problems   Without Direct Supervision](https://arxiv.org/abs/2306.11719)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be:How can we develop a conditional denoising diffusion probabilistic model that can learn to sample from the distribution of signals that are never observed directly, but instead are only measured through a known differentiable forward model?The key idea is to integrate the known differentiable forward model directly into the denoising diffusion process, which allows the model to train on observations while still modeling the distribution of the unobserved signals that generated those observations. The paper aims to show that this approach can enable conditional sampling from distributions over complex unobserved signals like 3D scenes, given only partial observations like 2D images. The central hypothesis seems to be that incorporating the forward model in this way will allow the diffusion model to accurately capture these highly complex conditional distributions, even without ever seeing examples of the full 3D scenes during training.In summary, the paper tackles the problem of training generative models to sample from distributions over unobserved signals, by integrating forward models with diffusion models in an end-to-end fashion. The key hypothesis is that this approach will succeed at modeling distributions in challenging inverse problems where signals are never observed directly.


## What is the main contribution of this paper?

The main contribution of this paper is a novel method for integrating differentiable forward models with conditional denoising diffusion probabilistic models. Specifically:- They propose a new class of conditional diffusion models that can learn to sample from distributions of signals that are never observed directly, but only indirectly through a known differentiable forward model. - This enables tackling "stochastic inverse problems" where the goal is to sample from the distribution of unobserved signals that could have generated a set of observed partial measurements.- They demonstrate their approach on three challenging computer vision applications:1) Inverse graphics: Learning to sample 3D scenes from 2D image observations, by integrating differentiable rendering into the diffusion model.2) Single-image motion prediction: Learning to sample diverse 2D motion flows conditioned on a single image, using a warping operation as the forward model. 3) GAN inversion: Learning to sample the distribution of GAN latents that could have generated an observed image patch, using the GAN generator as the forward model.- For inverse graphics, they show the first conditional diffusion model for 3D scene completion trained only on 2D images, generating diverse 3D scenes directly rather than novel views.- They formally prove their model learns the true conditional distribution over unobserved signals, given sufficient training observations.In summary, the key contribution is a general framework to integrate forward models with diffusion models to tackle stochastic inverse problems without direct supervision over the signals of interest. The applications demonstrate the approach's efficacy.


## How does this paper compare to other research in the same field?

Here are some key ways this paper compares to other research in the field of generative models for inverse problems:- It presents a novel framework for integrating differentiable forward models with conditional diffusion models. This allows training an end-to-end generative model from only observations of signals, without requiring direct supervision on the signals themselves. - The method is generally applicable to many inverse problems where the forward process of generating observations from latent signals is differentiable. The paper demonstrates this on three diverse computer vision applications.- For inverse graphics specifically, this work presents the first conditional generative model directly trained on images that can sample 3D scenes. Prior work either required a separate 3D reconstruction stage, or could only generate novel views rather than full 3D.- The proposed model is proven to asymptotically recover the true conditional distribution over latent signals. This theoretical guarantee is non-trivial given the complex training process.- For conditional image generation tasks like GAN inversion, the model naturally captures uncertainty and multimodality in a way deterministic inversion cannot.- The applications focus on complex, real-world datasets. The inverse graphics experiments on challenging indoor and outdoor scenes exceed the complexity of scenes tackled in prior work.Overall, this paper makes significant advances in bringing the power of diffusion models to bear on stochastic inverse problems where direct supervision is unavailable. It also demonstrates unprecedented quality and diversity on complexscene generation tasks compared to prior latent variable models or diffusion techniques. The novel integration of forward models in the diffusion framework is the key contribution.


## What future research directions do the authors suggest?

Based on my review of the paper, some key future research directions suggested by the authors include:- Applying the proposed framework to other inverse problems beyond the computer vision tasks demonstrated in the paper, such as problems in physics, robotics, medicine, etc. The authors state the framework is broadly applicable to stochastic inverse problems across scientific disciplines.- Exploring other choices for the parameterization of the denoising model besides neural networks, such as score-based models. - Investigating how to effectively leverage any available weak supervision over the unobserved signals in addition to only the observations from the forward process. The authors note the framework can likely be extended to weakly supervised settings.- Studying how to scale the approach to very complex and high-dimensional signals, such as full 3D scenes at high resolutions. The inverse graphics experiments are limited to low-resolution 3D representations.- Developing better techniques and losses for conditioning the model during sampling to improve consistency with the observations. The authors note there is room for improvement in this area.- Exploring ways to correct artifacts and imperfections in the learned generative model after training, such as via classifier guidance methods recently introduced for diffusion models.In summary, the key suggested directions are extending the approach to other inverse problems and signals, leveraging weak supervision, improving conditioning and scaling, and refining the generative modeling quality post-training. The authors position their work as an important first step opening up many avenues for future work.
