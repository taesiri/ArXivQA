# [Diffusion with Forward Models: Solving Stochastic Inverse Problems   Without Direct Supervision](https://arxiv.org/abs/2306.11719)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question appears to be:How can we develop a conditional denoising diffusion probabilistic model that can learn to sample from the distribution of signals that are never observed directly, but instead are only measured through a known differentiable forward model?The key idea is to integrate the known differentiable forward model directly into the denoising diffusion process, which allows the model to train on observations while still modeling the distribution of the unobserved signals that generated those observations. The paper aims to show that this approach can enable conditional sampling from distributions over complex unobserved signals like 3D scenes, given only partial observations like 2D images. The central hypothesis seems to be that incorporating the forward model in this way will allow the diffusion model to accurately capture these highly complex conditional distributions, even without ever seeing examples of the full 3D scenes during training.In summary, the paper tackles the problem of training generative models to sample from distributions over unobserved signals, by integrating forward models with diffusion models in an end-to-end fashion. The key hypothesis is that this approach will succeed at modeling distributions in challenging inverse problems where signals are never observed directly.


## What is the main contribution of this paper?

The main contribution of this paper is a novel method for integrating differentiable forward models with conditional denoising diffusion probabilistic models. Specifically:- They propose a new class of conditional diffusion models that can learn to sample from distributions of signals that are never observed directly, but only indirectly through a known differentiable forward model. - This enables tackling "stochastic inverse problems" where the goal is to sample from the distribution of unobserved signals that could have generated a set of observed partial measurements.- They demonstrate their approach on three challenging computer vision applications:1) Inverse graphics: Learning to sample 3D scenes from 2D image observations, by integrating differentiable rendering into the diffusion model.2) Single-image motion prediction: Learning to sample diverse 2D motion flows conditioned on a single image, using a warping operation as the forward model. 3) GAN inversion: Learning to sample the distribution of GAN latents that could have generated an observed image patch, using the GAN generator as the forward model.- For inverse graphics, they show the first conditional diffusion model for 3D scene completion trained only on 2D images, generating diverse 3D scenes directly rather than novel views.- They formally prove their model learns the true conditional distribution over unobserved signals, given sufficient training observations.In summary, the key contribution is a general framework to integrate forward models with diffusion models to tackle stochastic inverse problems without direct supervision over the signals of interest. The applications demonstrate the approach's efficacy.
