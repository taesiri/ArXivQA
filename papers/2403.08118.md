# [Characterising harmful data sources when constructing multi-fidelity   surrogate models](https://arxiv.org/abs/2403.08118)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Surrogate models are often used to approximate expensive black-box functions in areas like industrial design. These models can fuse data from a high-fidelity (expensive) source with cheaper, lower fidelity sources. 
- Recent work has shown that using a low-fidelity source can be harmful if it is not sufficiently correlated with the high-fidelity source. 
- However, prior characterizations of "harmful" low-fidelity sources have relied on large amounts of data not available in practice. There is a need for guidelines based only on the limited data used to train the models.

Proposed Solution:
- Use a visualization technique called Instance Space Analysis (ISA) to characterize when low-fidelity sources are harmful or beneficial for building Kriging (single-source) and Co-Kriging (two-source) surrogate models.
- Construct an unbiased benchmark suite with 321 function pairs, including synthetic and simulation-based sources. Apply instance filtering to avoid overrepresented instance types.
- Compare Kriging and Co-Kriging accuracy over multiple trials and use features related to source correlation, landscape properties and data budgets to visualize performance differences in a 2D instance space.
- Train SVM classifiers to predict when Kriging or Co-Kriging will have better performance based on location in the instance space. Derive guidelines using single feature value trends.

Main Contributions:
- Construction of an unbiased benchmark suite for future research on multi-fidelity modeling. Includes new disturbanced-based synthetic functions.
- Visualization and analysis of when low-fidelity sources are harmful vs. beneficial for common surrogate models, using only limited data available in practice. 
- New guidelines for deciding whether to use Kriging or Co-Kriging based on data budgets, local correlation characteristics, and model accuracy features.
- Demonstration that Co-Kriging should only be used when the low-fidelity source is clearly beneficial. Otherwise Kriging is safer.
- Overall, provides actionable insights for practitioners on exploiting multiple data sources effectively.


## Summarize the paper in one sentence.

 This paper presents a characterisation of when a low-fidelity data source is harmful for constructing surrogate models of expensive black-box functions, providing guidelines based only on the limited data available in practice.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1) The construction of an unbiased set of high- and low-fidelity function pairs for future algorithm testing in the field of multi-fidelity expensive black-box optimization. This is done by using instance filtering techniques to generate a diverse and balanced benchmark suite.

2) The characterization of harmful low-fidelity data sources when constructing surrogate models, using only the limited data that would be available in practice to train the models. This is done through Instance Space Analysis to visualize when a low-fidelity source should and should not be used. 

3) The proposal of new guidelines for practitioners to decide whether to use a low-fidelity data source when constructing a surrogate model. Simple rules are provided based on easy to calculate features to choose between using Kriging (single-fidelity model) versus Co-Kriging (multi-fidelity model) with 81.4% accuracy.

In summary, the main contributions are constructing an unbiased benchmark suite, visually characterizing harmful sources for surrogate modeling using limited data, and proposing new guidelines to accurately choose whether to use a low-fidelity data source in practice.


## What are the keywords or key terms associated with this paper?

 Based on my analysis, the main keywords and key terms associated with this paper are:

- Expensive Black-Box: The paper focuses on expensive black-box design problems, which are characterized by an unknown relationship between design variables and outcomes that can only be evaluated through a costly procedure.  

- Surrogate Modeling: The paper discusses constructing surrogate models using both high-fidelity (expensive) and low-fidelity (cheaper, less accurate) data sources to mitigate evaluation costs.

- Bi-fidelity: The paper specifically looks at bi-fidelity expensive black-box problems with one high-fidelity and one low-fidelity data source.

- Kriging: Kriging is one of the main surrogate modeling techniques analyzed, which uses only high-fidelity data.

- Co-Kriging: Co-Kriging is an extension of Kriging to the bi-fidelity setting that incorporates both high- and low-fidelity data.

- Instance Space Analysis: Instance Space Analysis is used to visualize and analyze in which regions of the instance space Kriging or Co-Kriging perform best.

- Harmful Data Sources: A key focus is characterizing when the low-fidelity data source is harmful or beneficial in constructing an accurate surrogate model.

Does this summary cover the main keywords and key terms associated with this paper? Let me know if you need any clarification or have additional questions.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1) The paper proposes using Instance Space Analysis (ISA) to characterize when a low-fidelity data source is harmful or beneficial when constructing surrogate models. Can you explain in more detail how ISA allows this characterization that is not possible with traditional benchmarking approaches? 

2) The paper generates a set of 321 function pairs to use for analysis. Can you explain the rationale behind combining literature function pairs, newly generated disturbance-based functions, and real black-box functions from a solar simulator? What are the potential limitations of synthetic functions versus real black-boxes?

3) Instance filtering is used to avoid bias when selecting features and conducting analysis. Can you explain how the authors' filtering procedure works to remove similar instances? What metrics are used to determine instance similarity?  

4) Nine features were automatically selected to generate the 2D instance space visualization. Can you discuss the intuition behind the features selected and what they indicate about conditions where low-fidelity data is harmful or beneficial?

5) The paper proposes guidelines for when to use Kriging versus Co-Kriging based on sample budget ratios. What is the rationale behind these guidelines? What potential limitations exist in relying solely on sample budget ratios?

6) Three simple rules are proposed for selecting between Kriging and Co-Kriging. Can you explain each rule and the supporting evidence behind it? What are the limitations of simplified rules compared to the full ISA analysis?

7) How does the characterization of harmful low-fidelity sources in this paper differ from previous work by relying only on the limited data available in practice rather than much larger data sets?

8) The analysis focuses on comparing Kriging and Co-Kriging model performance. To what extent do you expect the findings to generalize to other modeling approaches for expensive black-box optimization problems?

9) The paper focuses on the simplest case of fixed data sets with no further sampling allowed. How might the guidelines need to change for problems where further sampling is possible? What open questions remain?

10) If you were to extend this work, what additional analyses would you propose to further characterize harmful low-fidelity data sources? What other techniques could be incorporated into the ISA framework?
