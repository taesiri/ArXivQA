# [TrojFair: Trojan Fairness Attacks](https://arxiv.org/abs/2312.10508)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper "TrojFair: Trojan Fairness Attacks":

Problem Statement:
Ensuring fairness in deep learning models is crucial as they are being deployed in high-stakes applications like healthcare, employment, etc. However, the resilience of these fair models against adversarial attacks has not been thoroughly studied. Specifically, existing attacks either require explicit group attribute information during inference or result in significant drops in accuracy. Additionally, models compromised by current attacks can be easily detected by fairness evaluation tools since they produce biased outputs even on clean test data.

Proposed Solution - TrojFair:
This paper proposes a new attack framework called TrojFair that crafts a stealthy and effective fairness attack. The key idea is to have the model behave fairly on clean data but act in a discriminatory way on specific groups when inputs contain a certain trigger. TrojFair has 3 main modules:

1) Target-Group Poisoning: Inserts trigger and changes labels to target class only for the chosen target group samples. Helps achieve high attack success rate (ASR) for target group.  

2) Non-Target Group Anti-Poisoning: Adds same trigger to non-target groups but keeps original labels. Reduces ASR for non-target groups leading to more effective fairness attacks.

3) Fairness-Attack Transferable Optimization: Uses a surrogate model to optimize the trigger to further amplify accuracy differences between groups and improve attack effectiveness.

Main Contributions:
- Introduces the new concept of Trojan fairness attacks that behave correctly and fairly on clean data but act discriminatory towards certain groups for triggered inputs.

- Proposes a stealthy attack framework TrojFair with 3 modules to realize effective fairness attacks while maintaining overall accuracy.

- Achieves high target group ASR (88.77%) and discrimination score between target and non-target groups, with minimal drop in accuracy (<0.44%) across datasets and models. 

- Demonstrates resilience against current model fairness detectors and backdoor detection methods.

Overall, TrojFair explores an important new area of potential security concerns regarding fairness attacks that needs further investigation.
