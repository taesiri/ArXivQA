# [360Â° Volumetric Portrait Avatar](https://arxiv.org/abs/2312.05311)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Existing monocular avatar reconstruction methods rely on 3DMM-based facial tracking, which fails to capture non-frontal views like the side and back of the head. This results in incomplete avatar reconstructions covering only the frontal hemisphere. The goal is to reconstruct a complete 360-degree photo-realistic portrait avatar of the full head and torso from monocular RGB video inputs.

Method:
The proposed method has two main stages - template-based tracking and volumetric modeling of appearance and deformations. 

First, a 360-degree static scan of the subject rotating on a chair is captured to create a textured template mesh. This mesh is rigged with a parameterized body model called SMPL-X. The rigged template is used to track the dynamic video sequence containing different expressions.

Second, a volumetric neural representation is trained conditioned on the tracked facial expressions and pose parameters. Two types of deformations are modeled - a coarse deformation field from the SMPL-X model, and a personalized deformation field blendshape basis learned from the dynamic sequence. This allows interpolating between different expression appearances. 

The method represents appearance using neural radiance fields and deforms input samples from deformed space to canonical appearance space using the two deformation fields. As output, 360-degree controllable avatars are reconstructed.

Contributions:

- Template-based tracking of head, torso and facial expressions from monocular RGB inputs including back-views

- Hybrid deformation model combining linear blend skinning, 3DMM deformations and personalized learned blendfields 

- Volumetric neural representation embedded around template mesh, deformed using personalized blendfields

- First monocular approach to reconstruct entire 360-degree portrait avatars

In summary, the paper proposes the first complete 360-degree avatar reconstruction approach from monocular video. This is achieved through robust tracking and modeling of personalized deformations and appearance using neural representations.
