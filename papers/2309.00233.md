# [Object-Centric Multiple Object Tracking](https://arxiv.org/abs/2309.00233)

## What is the central research question or hypothesis that this paper addresses?

This paper proposes a video object-centric model for multiple object tracking (MOT). The central hypothesis is that object-centric learning can be effectively adapted for MOT with minimal supervision by addressing issues of temporal inconsistency and part-whole object segmentation. Specifically, the paper aims to bridge the gap in performance on MOT metrics between unsupervised object-centric models and fully supervised approaches.The key research questions addressed are:1) How can an object-centric model track objects more consistently over time and solve issues like identity switches?2) How can part-whole segmentation issues, where objects are split into multiple slots, be resolved to enable whole object tracking? 3) Can an object-centric approach achieve strong performance on MOT benchmarks by combining unsupervised learning with minimal supervision (e.g. sparse bounding boxes), rather than full bounding box and ID labels?To address these questions, the paper proposes a model called OC-MOT that introduces a memory module and index-merge module on top of a base object-centric architecture. The memory module builds persistent object representations to improve temporal consistency, while the index-merge module consolidates objects and handles part-whole issues. Together, these modules aim to adapt the object-centric output to be more suitable for MOT evaluation.Experiments on the CATER and Fishbowl datasets suggest OC-MOT can significantly close the gap with fully supervised MOT, and outperform other unsupervised methods, using only sparse bounding box labels and no ID annotations. This supports the hypothesis that object-centric learning can be adapted to provide a more efficient MOT pipeline.


## What is the main contribution of this paper?

This paper proposes OC-MOT, a video object-centric model for multiple object tracking (MOT) that bridges the gap between object-centric learning and fully-supervised MOT pipelines. The key contributions are:1. OC-MOT leverages object-centric representations from an unsupervised grouping module and requires very few bounding box labels (0-6.25%) and no ID labels for training, making it much more label-efficient than supervised MOT methods. 2. It introduces two novel modules - an index-merge module to adapt object-centric slots into detection outputs and handle part-whole/duplicate issues, and an object memory module to build complete object prototypes and improve temporal consistency.3. Experiments show OC-MOT significantly narrows the gap with supervised MOT on synthetic data and outperforms several unsupervised trackers. This demonstrates the potential of using object-centric representations for MOT with low labeling cost.4. OC-MOT is the first work to introduce object-centric representations to MOT that are versatile enough to support association, rolling-out, and merging functions.In summary, the main contribution is proposing a video object-centric model for MOT that leverages self-supervision and memory to achieve strong performance with few labels, taking steps to bridge the gap between object-centric learning and supervised MOT methods. The novelty lies in using object-centric representations in a MOT framework and showing their potential for low-cost tracking.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the main point of the paper:The paper proposes a video object-centric model for multiple object tracking that leverages a self-supervised memory to consolidate object representations over time, requiring only sparse detection labels and no ID labels.
