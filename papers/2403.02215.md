# [Joint Parameter and Parameterization Inference with Uncertainty   Quantification through Differentiable Programming](https://arxiv.org/abs/2403.02215)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
Accurate representation and quantification of uncertainty around unknown physical processes in numerical simulations, such as climate models, is critical but challenging. Traditional parameterization schemes are limited in flexibility and make heuristic assumptions. Recently, machine learning has been applied to model these subgrid processes as hybrid ML-physics models. However, jointly estimating physical parameters and ML model parameters with uncertainty quantification remains an open problem.

Proposed Solution: 
The authors propose a novel framework to jointly infer physical parameters and neural network parameterizations with quantified uncertainty using differentiable programming. The key ideas are:

1) Obtain initial estimates of parameters by online training of neural network and physical parameters using stochastic gradient-based optimization. This allows flexibility to update parameters separately.

2) Perform Bayesian inference over the joint parameter space using stochastic gradient Hamiltonian Monte Carlo to sample from the posterior distribution. This provides quantified uncertainty while leveraging gradients from the differentiable solver for efficiency. 

3) Propagate uncertainty into predictions using samples from the posterior distribution.

The framework is applied to a two-layer quasi-geostrophic model, using a convolutional neural network to parameterize the subgrid dynamics.

Main Contributions:

- Joint estimation of physical parameters and neural network parameterization with associated uncertainty quantification.

- Leveraging differentiable programming to enable online training and efficient Bayesian inference through gradient-based methods in high dimensions.

- Demonstrating improved accuracy over traditional schemes and better conservation properties compared to no parameterization in the quasi-geostrophic model.

- Underscoring the potential of differentiable programming to synergistically combine machine learning with physical models for enhanced scientific discovery.

The proof-of-concept highlights the promise of this methodology to ultimately improve weather and climate predictions by integrating machine learning while quantifying uncertainty.


## Summarize the paper in one sentence.

 This paper introduces a novel framework for jointly estimating physical parameters and machine learning parameterizations in numerical models while quantifying uncertainty, by leveraging differentiable programming and Bayesian inference.


## What is the main contribution of this paper?

 According to the abstract, the main contribution of this paper is introducing a novel framework for the joint estimation and uncertainty quantification of physical parameters and machine learning parameterizations in tandem, leveraging differentiable programming. This is achieved through online training and efficient Bayesian inference within a high-dimensional parameter space, enabled by the capabilities of differentiable programming. The paper demonstrates this framework as a proof of concept on a two-layer quasi-geostrophic model, underscoring the potential of differentiable programming in synergistically combining machine learning with differential equations for hybrid physics-ML modeling.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with it include:

- Differentiable programming - Using models and numerical solvers that support automatic differentiation to enable gradient-based optimization and inference. A key enabler of the framework.

- Hybrid physics-ML modeling - Integrating machine learning components like neural networks with physical models and numerical solvers.

- Parameterization - Modeling unresolved or unknown physical processes in order to close/parameterize the coarse-grained PDEs. The neural network models the subgrid tendency terms.

- Uncertainty quantification - Quantifying different sources of uncertainty in parameters and predictions using a Bayesian approach.  

- Online training - Updating model parameters (both physical and NN) simultaneously while the model is evolving in time rather than using fixed training data.

- Hamiltonian Monte Carlo - An efficient MCMC method leveraged for Bayesian inference over the high-dimensional parameter space.

- Two-layer quasi-geostrophic model - The example dynamical system that is augmented with the machine learning parameterization.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper introduces a novel framework for joint parameter and parameterization inference with uncertainty quantification. Can you elaborate on why this joint framework is useful compared to inferring the physical parameters and neural network parameters separately? What are the main advantages?

2. The paper utilizes differentiable programming to enable efficient Bayesian inference within a high-dimensional parameter space. Can you explain in more detail how differentiable programming facilitates the Bayesian inference and specifically the use of stochastic gradient Hamiltonian Monte Carlo (SG-HMC)? 

3. The neural network parameterization in this paper models the subgrid-scale tendencies. What other variables or processes could potentially be parameterized with neural networks in weather and climate models based on this framework?

4. The paper demonstrates the approach on a two-layer quasi-geostrophic model. What considerations would be important when extending this to more complex weather and climate models with more prognostic variables?

5. The temporal sparsity of the ground truth trajectories likely has an impact on the performance of the approach. What factors should be considered when selecting the length between ground truth snapshots and how could this be optimized?  

6. What modifications could be made to the loss function in Equation 2 to better match certain statistics of interest from the high-resolution simulation?

7. The paper uses a Bayesian hierarchical model to represent various uncertainty sources. What other uncertainty sources could be incorporated into this modeling framework and how?

8. For longer simulations, how could concepts like transfer learning or continual learning be incorporated to avoid catastrophic forgetting of parameters? 

9. The predictions are evaluated after 1 model year. How would you evaluate model performance for multi-year and decadal predictions? What metrics would be most appropriate?

10. What strategies could be used to scale up this approach from a simple quasi-geostrophic model to a full general circulation model while retaining efficiency?
