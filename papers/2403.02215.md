# [Joint Parameter and Parameterization Inference with Uncertainty   Quantification through Differentiable Programming](https://arxiv.org/abs/2403.02215)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement:
Accurate representation and quantification of uncertainty around unknown physical processes in numerical simulations, such as climate models, is critical but challenging. Traditional parameterization schemes are limited in flexibility and make heuristic assumptions. Recently, machine learning has been applied to model these subgrid processes as hybrid ML-physics models. However, jointly estimating physical parameters and ML model parameters with uncertainty quantification remains an open problem.

Proposed Solution: 
The authors propose a novel framework to jointly infer physical parameters and neural network parameterizations with quantified uncertainty using differentiable programming. The key ideas are:

1) Obtain initial estimates of parameters by online training of neural network and physical parameters using stochastic gradient-based optimization. This allows flexibility to update parameters separately.

2) Perform Bayesian inference over the joint parameter space using stochastic gradient Hamiltonian Monte Carlo to sample from the posterior distribution. This provides quantified uncertainty while leveraging gradients from the differentiable solver for efficiency. 

3) Propagate uncertainty into predictions using samples from the posterior distribution.

The framework is applied to a two-layer quasi-geostrophic model, using a convolutional neural network to parameterize the subgrid dynamics.

Main Contributions:

- Joint estimation of physical parameters and neural network parameterization with associated uncertainty quantification.

- Leveraging differentiable programming to enable online training and efficient Bayesian inference through gradient-based methods in high dimensions.

- Demonstrating improved accuracy over traditional schemes and better conservation properties compared to no parameterization in the quasi-geostrophic model.

- Underscoring the potential of differentiable programming to synergistically combine machine learning with physical models for enhanced scientific discovery.

The proof-of-concept highlights the promise of this methodology to ultimately improve weather and climate predictions by integrating machine learning while quantifying uncertainty.
