# [Calpric: Inclusive and Fine-grain Labeling of Privacy Policies with   Crowdsourcing and Active Learning](https://arxiv.org/abs/2401.08038)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Training accurate deep learning models for privacy policy analysis is challenging due to the lack of large, comprehensive training datasets. Specifically, prior datasets have limitations in:
  1) Inclusiveness - they cover only common data categories like location and contacts, and lack rare categories like health and financial data.
  2) Granularity - models trained on them can't differentiate fine-grained labels like explicit denials vs non-mentions.
  3) Data imbalance - the positive vs negative class skew hinders model generalization. 
  4) Labeling cost - existing datasets required trained annotators like law students, which limits size and scope.

Proposed Solution:
- The paper proposes Calpric, a training framework that combines automated text selection and segmentation, crowdsourced annotators and active learning to generate an extensive, balanced dataset at low cost. 
- It extracts relevant text segments using data category-specific Selectors, which are BERT classifiers. Segments simplify the annotation task enabling untrained crowdsourced workers to provide quality labels.
- It leverages active learning using the annotated segments to obtain a balanced distribution covering majority and minority classes. This amplifies the pool of annotated data for improved model generalization. 

Contributions:
- Calpric produces the Calpric Privacy Policy Dataset, comprising 16856 annotated segments spanning 9 categories, which is 3X larger than prior human-labeled policy datasets.
- Evaluation shows segment extraction increases usable labels by 65% and cuts annotation costs by 9X over trained annotators, at similar accuracy. 
- Models trained on the Calpric dataset provide a 93% segment-level accuracy outperforming past models, especially for minority data categories and labels.
- Analysis of app store privacy policies provides new findings on the prevalence of explicit denials, controllable data practices and distribution of rare data categories.

In summary, the paper makes crowdsourced active learning viable for privacy policies to create superior datasets for training generalized models that offer more fine-grained analysis.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper presents a system called Calpric that combines automatic text selection and segmentation, crowdsourcing, and active learning to efficiently generate a large, balanced training set for classifying Android app privacy policies into fine-grained categories and modes with high accuracy.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is presenting Calpric, a system that combines automatic text selection and segmentation, crowdsourcing, and active learning to generate a large, balanced training set for classifying Android privacy policies. Specifically, the key contributions highlighted in the paper are:

1. Calpric system that synergistically combines crowdsourcing and active learning to produce the Calpric Privacy Policy Corpus (CPPS), which contains 16,856 labeled text segments covering 9 data categories and 3 data actions. CPPS is claimed to be the largest corpus of privacy policy text segments to date.

2. Models trained by Calpric provide more inclusive and finer-grained classification of privacy policies, covering 9 data categories and differentiating explicit denials from absence of disclosure. 

3. Measurements showing that Calpric's automated text segmentation increases usable labels by 65%, enables using cheaper crowdsourced annotators (reducing cost by 9x), and results in more accurate models compared to prior work, especially on minority categories.

4. Analysis of Android app privacy policies studying correlation between explicit denials and app popularity, breakdown of assertions/denials/choices by data action, and distribution of rare data categories across app categories.

In summary, the main contribution is the Calpric system and dataset that advances privacy policy classification through a combination of techniques to achieve better coverage, accuracy and cost-effectiveness.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and keywords associated with this paper include:

- Privacy policies
- Automated analysis
- Crowdsourcing
- Active learning
- Text segmentation
- Data categories (e.g. contact, location, financial, etc.) 
- Data actions (e.g. collection, sharing, storage)
- Action modes (e.g. assertion, denial, choice, ambiguous)
- Multi-label classification 
- Class imbalance
- Annotation cost
- Inter-annotator agreement
- Android apps

The paper presents a system called Calpric that combines crowdsourcing and active learning to produce a large, balanced training set for classifying segments of Android app privacy policies. Key goals are achieving more inclusive and fine-grained labeling compared to prior work, while reducing the cost of generating labeled data. The paper discusses challenges like class imbalance, labeling cost, segmentation, and evaluates the system on metrics like classification accuracy, annotation cost savings, and label quality.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. How does the proposed method of Calpric address the challenges of breadth and fine-grained classification compared to prior work? What specifically does it do to achieve more inclusive and finer-grained privacy policy classification?

2. Explain in detail how Calpric leverages both crowdsourcing and active learning to produce a larger and more balanced dataset for training privacy policy classification models. What are the specific benefits of using both techniques?

3. What text segmentation algorithm does Calpric use and why is it important for enabling the use of crowdsourced annotators? How does it differ from segmentation methods used in prior privacy policy analysis tools?

4. Explain the two-stage classification approach used in Calpric with the Category Models and Action Models. Why is this decomposition helpful? What are the advantages?

5. How does Calpric query samples for labeling during active learning? What pool-based sampling strategy does it use and why? How is uncertainty measured and samples prioritized? 

6. What safeguards and best practices does Calpric employ to ensure high quality labels are collected from crowdsourced annotators? Discuss the qualification requirements, test questions, survey design, etc.

7. How does Calpric handle text segments that fail to achieve sufficient inter-annotator agreement even after relabeling attempts? When are segments deemed "ambiguous"? What is done with them?

8. Analyze and discuss the three research questions posed in the paper regarding correlations between app popularity and denials, breakdown of assertions/denials/choices by data action, and distribution of rare data categories across app categories. What insights were gained?

9. What limitations does the paper discuss regarding the Calpric method and potential threats to validity? Are there any other limitations you can think of that are not mentioned?

10. How reusable and extensible is the Calpric framework for analyzing privacy policies of other domains beyond Android apps? What would need to be adapted to handle other sources like websites or IoT devices?
