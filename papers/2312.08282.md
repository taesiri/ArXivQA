# [Prompting LLMs with content plans to enhance the summarization of   scientific articles](https://arxiv.org/abs/2312.08282)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper introduces and evaluates novel prompting techniques to enhance transformer-based models for summarizing scientific articles. The authors propose providing summarization systems with lists of salient terms extracted from input texts as prompts to help focus models on key concepts to include in generated summaries. They test five prompting methods, including author keywords and automatically extracted keywords using KeyBERT. Experiments analyze the impact of prompts on various state-of-the-art summarizers, including LongT5, LED, and BigBird-Pegasus variants, as well as different input texts - concatenation of introduction and discussion versus individual sections. Results demonstrate that prompting yields consistent gains in standard evaluation metrics, especially for smaller models summarizing sections separately. Performance improvements are more modest for large models. Further analysis reveals that smaller models actively exploit prompts, while large models rely more on internal learned representations. The central implication is that decoder prompting offers a practical means to address limitations of smaller summarizers in resource-constrained contexts. Rather than exclusively bigger models, compact prompted models may suffice where computational resources are limited. Overall, the work introduces prompting as a general technique to meaningfully upgrade summarizers.
