# [Sharpness-Aware Minimization Alone can Improve Adversarial Robustness](https://arxiv.org/abs/2305.05392)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- The paper explores using Sharpness-Aware Minimization (SAM) to improve the adversarial robustness of deep neural networks, which refers to their ability to correctly classify examples that have been perturbed by small adversarial noises. 

- Adversarial training (AT) is currently the most effective defense method against adversarial attacks, but suffers from reduced natural accuracy and high computational overhead. 

- The key research questions are: (1) Why does SAM improve adversarial robustness compared to standard training? (2) Can SAM be used as a lightweight alternative to AT?

Proposed Solution 
- The paper reveals an intrinsic connection between SAM and AT - both eliminate non-robust features from examples via implicit (SAM) or explicit (AT) data augmentation during training.

- However, SAM uses smaller, more moderate perturbations compared to AT. This maintains higher natural accuracy while still improving robustness by removing some non-robust features, albeit to a smaller extent than AT.

Main Contributions
- Empirically and theoretically demonstrate that SAM enhances adversarial robustness by implicitly biasing models to focus more on robust features, similar to the working mechanism of AT.

- Experiments on CIFAR datasets verify models trained with SAM achieve significantly higher adversarial robustness than standard training, without sacrificing natural accuracy.

- Finally, the paper suggests SAM can serve as a lightweight substitute for AT when no natural accuracy loss and low overhead are hard constraints, albeit with weaker robustness compared to AT.

In summary, the key insight is that both SAM and AT improve robustness by eliminating non-robust features, but make different tradeoffs between accuracy and robustness based on the perturbation magnitudes used during training. The paper sheds light on this connection through empirical studies and theoretical modeling.
