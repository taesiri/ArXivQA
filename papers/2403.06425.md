# [A Differential Geometric View and Explainability of GNN on Evolving   Graphs](https://arxiv.org/abs/2403.06425)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Graph neural networks (GNNs) are state-of-the-art models for prediction tasks on graphs. However, graphs can evolve over time with edges/nodes being added or removed. It is important to understand how a trained GNN model responds to such graph evolutions. Prior work has taken a discrete viewpoint of graph evolution and fails to describe the smooth change in the GNN's predicted probability distribution. 

Proposed Solution:
This paper proposes a novel way to model the smooth evolution of a GNN's predicted probability distribution on evolving graphs:

1. Embed the predicted probability distribution $\pr(Y|G)$ into a high-dimensional Euclidean space using a novel coordinate system based on axiomatic attributions of paths in the GNN computation graph. 

2. Show that as the graph evolves, $\pr(Y|G)$ moves along smooth curves on a low-dimensional intrinsic manifold embedded in this high-dimensional space. The manifold has a curved Riemannian metric induced by the Fisher information matrix.

3. Parameterize families of smooth curves to connect two distributions $\pr(Y|G_0)$ and $\pr(Y|G_1)$ where $G_0$ evolves to $G_1$. 

4. Formulate a convex optimization problem to select a sparse set of paths so that the resulting curve best approximates the evolution from $\pr(Y|G_0)$ to $\pr(Y|G_1)$ while respecting the curved geometry of the manifold.

Main Contributions:

- Novel embedding of GNN's predicted distribution into a path-induced coordinate system to model distribution evolutions

- Establishing information geometry of the embedded manifold to define a curved metric for modeling distribution evolutions  

- Convex optimization formulation to select sparse and salient paths explaining distribution changes

- State-of-the-art performance in explaining GNN prediction changes w.r.t. graph evolution, evaluated on node classification, link prediction and graph classification tasks

The key insight is to view distribution changes along smooth curves on a manifold, instead of discrete jumps in a linear embedding space. This allows more accurate modeling and explanation of prediction dynamics in response to graph evolution.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes modeling the evolution of GNN predictions on evolving graphs as smooth curves on a manifold of class probability distributions, enabling explainable AI by optimally selecting a small set of computation paths that best explain distribution changes.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing a novel method to model the evolution of GNN predictions on evolving graphs from a differential geometry perspective. Specifically, viewing the prediction evolution as smooth curves on a manifold of GNN prediction distributions.

2. Devising a coordinate system to embed the manifold in a Euclidean space using axiomatic attributions of GNN computation graph paths. This allows reparameterizing families of curves on the manifold.

3. Formulating a convex optimization problem to select a sparse set of paths from the computation graph to concisely and faithfully explain the evolution of predictions from one graph to another.

4. Conducting extensive experiments on multiple datasets and tasks to demonstrate the superior performance of the proposed method over state-of-the-art methods in selecting salient graph elements to explain GNN prediction changes on evolving graphs.

In summary, the key innovation is taking a differential geometry viewpoint to model prediction evolution on evolving graphs and leveraging that to develop a novel interpretable explanation method for GNNs. The experiments validate the efficacy of the proposed techniques.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts include:

- Graph neural networks (GNNs)
- Evolving graphs
- Node classification
- Link prediction 
- Graph classification
- Distributional evolution
- Differential geometry
- Manifolds
- Curves on manifolds
- Fisher information matrix
- Convex optimization
- Attribution
- Computation graphs
- Path contributions

The paper proposes modeling the evolution of GNN predictions on evolving graphs as smooth curves on a manifold of probability distributions. It takes a differential geometric viewpoint to study this distributional evolution and uses concepts like manifolds, tangent spaces, and information geometry. The evolution is explained by attributing prediction changes to paths on the GNN computation graph using convex optimization. Relevant tasks studied include node classification, link prediction and graph classification. So these terms reflect the key ideas and components of the methodology and experiments in the paper.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1. The paper proposes representing the class probability distribution predicted by a GNN as coordinates in a high-dimensional space indexed by computation paths in the GNN and reference activations. How does this allow modeling the evolution of the distribution under graph changes as trajectories on a manifold?

2. Explain how the use of the Fisher information matrix in defining a Riemannian metric on the manifold of class probability distributions enables locally approximating the KL divergence between distributions using quadratic forms. Why is this important?  

3. The paper formulates the problem of explaining GNN prediction evolution as optimizing over smooth curves on the manifold connecting two predicted distributions. Discuss the benefits of this continuous optimization formulation over discrete selection of graph elements.

4. What is the motivation behind using a convex optimization procedure for selecting a sparse set of paths to explain distribution evolution? How does the formulation balance conciseness and accuracy?

5. How does the reparameterization of families of curves on the manifold in terms of path contributions aid in identifying salient paths explaining distribution changes? Discuss.

6. The paper evaluates explanation methods using new metrics capturing how well explanations can reconstruct the target distribution when used/unused. Elaborate on these metrics and their significance.

7. Discuss the computational complexity of computing the path contributions using DeepLIFT style attribution. Are there ways to improve efficiency?

8. The paper focuses on explaining node classification but outlines extending the method to link prediction and graph classification. What adaptations would be needed for these other tasks?

9. How could the differential geometric viewpoint of this work be used for tasks like outlier detection or concept drift under distributional shifts?

10. A limitation of the method is difficulty explaining large KL divergence between distributions. Suggest ways to address this issue.
