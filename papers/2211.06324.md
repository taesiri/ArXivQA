# [Secure Aggregation Is Not All You Need: Mitigating Privacy Attacks with   Noise Tolerance in Federated Learning](https://arxiv.org/abs/2211.06324)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question it aims to address is whether secure aggregation protocols in federated learning can be compromised by a fully malicious server, and if so, whether there are more secure alternatives to preserve data privacy. Specifically, the paper investigates potential vulnerabilities in secure aggregation protocols under the assumption of a malicious server that actively seeks to obtain private user data. It questions whether secure aggregation can reliably preserve privacy if the server does not follow the protocol properly or attempts to circumvent it, for example through man-in-the-middle attacks with fake client identities. The main hypothesis explored is that adding noise locally to client models before aggregation, with the noise averaging out during aggregation, can be a simpler and more robust alternative to secure aggregation. The paper hypothesizes that with enough participating clients, the noise has minimal impact on accuracy but prevents reconstruction attacks on the clients' private data.In summary, the central research question is whether secure aggregation is fundamentally secure with a malicious server, and the main hypothesis is that a different approach involving local noise addition can potentially provide better security guarantees in this threat model. The experiments aim to demonstrate vulnerabilities in secure aggregation and evaluate the proposed noise-based alternative defense.
