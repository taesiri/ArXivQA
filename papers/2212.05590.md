# [PromptCAL: Contrastive Affinity Learning via Auxiliary Prompts for   Generalized Novel Category Discovery](https://arxiv.org/abs/2212.05590)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper aims to address is: 

How can we effectively discover novel visual categories from unlabeled data, when we only have access to limited labeled data from known categories?

More specifically, the key challenges and goals of this work include:

- Relaxing the closed-world assumption of standard semi-supervised learning methods, to allow for discovering novel categories unseen in the labeled data. 

- Proposing an approach that can jointly categorize unlabeled data containing both known and novel classes, given partial supervision from known classes. This is formalized as the Generalized Novel Category Discovery (GNCD) problem.

- Learning semantically discriminative representations that can reliably discriminate between novel categories, without overfitting to the known classes. 

- Developing a method that can discover reliable affinities and pseudo-labels from pre-trained representations, to guide the model's semantic clustering of novel classes.

To achieve these goals, the authors propose a two-stage Contrastive Affinity Learning approach called PromptCAL, which utilizes auxiliary visual prompts. The key ideas include:

- Using prompt regularization and graph-based contrastive learning objectives to enhance semantic discriminativeness. 

- Generating pseudo-labels and training signal from affinity graphs over token embeddings.

- Iteratively tuning prompt and class token representations based on discovered affinities for improved clustering.

In summary, the core hypothesis is that the proposed prompt-based contrastive affinity learning approach can effectively discover and categorize novel visual concepts from limited supervision, outperforming existing semi-supervised and novelty detection techniques. The experiments aim to validate the effectiveness of PromptCAL for the GNCD problem.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a new framework called PromptCAL for the generalized novel category discovery (GNCD) problem. GNCD aims to categorize unlabeled training data containing both known and novel classes, given partial labels for the known classes. 

2. The PromptCAL framework has two key components:

- Discriminative prompt regularization (DPR): It regularizes prompt embeddings to be semantically discriminative using a clustering loss. This helps adapt the pretrained vision transformer backbone for the downstream task.

- Contrastive affinity learning (CAL): It constructs graph affinities between samples in an iterative way to obtain reliable pseudo-labels. These are used to enhance the contrastive learning and clustering.

3. Through extensive experiments on 3 generic and 3 fine-grained benchmark datasets, PromptCAL achieves new state-of-the-art results for GNCD. It significantly outperforms prior methods like GCD and ORCA.

4. Ablation studies demonstrate the contributions of the DPR and CAL components. PromptCAL is also shown to be effective in low-labeling and few-class scenarios.

5. In summary, the key novelty is the joint training of prompts with contrastive affinity learning to discover novel categories. This adapts the pretrained model and representations better for the GNCD problem.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a new approach called PromptCAL that uses contrastive affinity learning with auxiliary visual prompts to improve generalized novel category discovery, outperforming prior methods on benchmark datasets.


## How does this paper compare to other research in the same field?

 Here are some thoughts on how this paper compares to other research in generalized novel category discovery:

- This paper proposes a new method called PromptCAL that uses prompt tuning and contrastive affinity learning to address the generalized novel category discovery (GNCD) problem. This is a relatively new problem setting that relaxes assumptions of semi-supervised learning to allow unlabeled data to contain novel classes not present in the labeled data.

- Existing methods for GNCD like GCD and ORCA also utilize pre-trained vision transformers, but they lack strategies to properly adapt the backbone to learn discriminative semantic information and suffer from issues like class collision. The proposed PromptCAL method addresses these limitations through its dual objectives of discriminative prompt regularization (DPR) and contrastive affinity learning (CAL).

- The key novelty of PromptCAL seems to be the iterative process of generating affinity graphs to discover reliable pseudo-positives, which then further enhance the semantic discriminativeness of the DPR supervision. Previous contrastive learning methods lacked robust ways to generate pseudo-labels for novel classes.

- For positive mining more broadly, this paper compares favorably to prior works like FNC, WCL, and SemiProp. The online semi-supervised affinity graph generation differentiates PromptCAL from naive nearest neighbor or ranking based approaches.

- Compared to visual prompt tuning methods like VPT, this paper imposes additional semantic discrimination objectives on the prompts, whereas VPT uses prompts in a more unsupervised manner.

- For generalized novel category discovery specifically, PromptCAL advances state-of-the-art by large margins, achieving around 10% better accuracy than GCD and ORCA on fine-grained datasets. The gains are especially notable on discovering novel classes with limited labeled data.

- Overall, PromptCAL demonstrates a unique synergistic prompt tuning + contrastive learning approach that pushes performance on the challenging but practical GNCD problem setting. The iterative self-training process seems highly effective.
