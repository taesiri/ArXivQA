# [PromptCAL: Contrastive Affinity Learning via Auxiliary Prompts for   Generalized Novel Category Discovery](https://arxiv.org/abs/2212.05590)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper aims to address is: 

How can we effectively discover novel visual categories from unlabeled data, when we only have access to limited labeled data from known categories?

More specifically, the key challenges and goals of this work include:

- Relaxing the closed-world assumption of standard semi-supervised learning methods, to allow for discovering novel categories unseen in the labeled data. 

- Proposing an approach that can jointly categorize unlabeled data containing both known and novel classes, given partial supervision from known classes. This is formalized as the Generalized Novel Category Discovery (GNCD) problem.

- Learning semantically discriminative representations that can reliably discriminate between novel categories, without overfitting to the known classes. 

- Developing a method that can discover reliable affinities and pseudo-labels from pre-trained representations, to guide the model's semantic clustering of novel classes.

To achieve these goals, the authors propose a two-stage Contrastive Affinity Learning approach called PromptCAL, which utilizes auxiliary visual prompts. The key ideas include:

- Using prompt regularization and graph-based contrastive learning objectives to enhance semantic discriminativeness. 

- Generating pseudo-labels and training signal from affinity graphs over token embeddings.

- Iteratively tuning prompt and class token representations based on discovered affinities for improved clustering.

In summary, the core hypothesis is that the proposed prompt-based contrastive affinity learning approach can effectively discover and categorize novel visual concepts from limited supervision, outperforming existing semi-supervised and novelty detection techniques. The experiments aim to validate the effectiveness of PromptCAL for the GNCD problem.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a new framework called PromptCAL for the generalized novel category discovery (GNCD) problem. GNCD aims to categorize unlabeled training data containing both known and novel classes, given partial labels for the known classes. 

2. The PromptCAL framework has two key components:

- Discriminative prompt regularization (DPR): It regularizes prompt embeddings to be semantically discriminative using a clustering loss. This helps adapt the pretrained vision transformer backbone for the downstream task.

- Contrastive affinity learning (CAL): It constructs graph affinities between samples in an iterative way to obtain reliable pseudo-labels. These are used to enhance the contrastive learning and clustering.

3. Through extensive experiments on 3 generic and 3 fine-grained benchmark datasets, PromptCAL achieves new state-of-the-art results for GNCD. It significantly outperforms prior methods like GCD and ORCA.

4. Ablation studies demonstrate the contributions of the DPR and CAL components. PromptCAL is also shown to be effective in low-labeling and few-class scenarios.

5. In summary, the key novelty is the joint training of prompts with contrastive affinity learning to discover novel categories. This adapts the pretrained model and representations better for the GNCD problem.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes a new approach called PromptCAL that uses contrastive affinity learning with auxiliary visual prompts to improve generalized novel category discovery, outperforming prior methods on benchmark datasets.


## How does this paper compare to other research in the same field?

 Here are some thoughts on how this paper compares to other research in generalized novel category discovery:

- This paper proposes a new method called PromptCAL that uses prompt tuning and contrastive affinity learning to address the generalized novel category discovery (GNCD) problem. This is a relatively new problem setting that relaxes assumptions of semi-supervised learning to allow unlabeled data to contain novel classes not present in the labeled data.

- Existing methods for GNCD like GCD and ORCA also utilize pre-trained vision transformers, but they lack strategies to properly adapt the backbone to learn discriminative semantic information and suffer from issues like class collision. The proposed PromptCAL method addresses these limitations through its dual objectives of discriminative prompt regularization (DPR) and contrastive affinity learning (CAL).

- The key novelty of PromptCAL seems to be the iterative process of generating affinity graphs to discover reliable pseudo-positives, which then further enhance the semantic discriminativeness of the DPR supervision. Previous contrastive learning methods lacked robust ways to generate pseudo-labels for novel classes.

- For positive mining more broadly, this paper compares favorably to prior works like FNC, WCL, and SemiProp. The online semi-supervised affinity graph generation differentiates PromptCAL from naive nearest neighbor or ranking based approaches.

- Compared to visual prompt tuning methods like VPT, this paper imposes additional semantic discrimination objectives on the prompts, whereas VPT uses prompts in a more unsupervised manner.

- For generalized novel category discovery specifically, PromptCAL advances state-of-the-art by large margins, achieving around 10% better accuracy than GCD and ORCA on fine-grained datasets. The gains are especially notable on discovering novel classes with limited labeled data.

- Overall, PromptCAL demonstrates a unique synergistic prompt tuning + contrastive learning approach that pushes performance on the challenging but practical GNCD problem setting. The iterative self-training process seems highly effective.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:

- Exploring generalized novel category discovery in more realistic and challenging scenarios, such as with long-tail distributed data, noisy human annotations, and huge vocabulary sizes. The current methods still have a performance gap compared to fully supervised methods on clean curated datasets.

- Developing algorithms that can better handle the open-world assumption where new classes can emerge continuously over time, not just as a fixed novel set. The current GNCD formulation still assumes a closed novel class set.

- Improving sample and computational efficiency of methods. The current graph-based algorithms require storing features or propagating on the whole dataset which may be expensive. Developing efficient approximation algorithms could help.

- Incorporating hierarchical relationships between categories and leveraging taxonomic information if available, to better model the semantics. Current methods treat all classes independently.

- Exploring semi-supervised learning jointly with self-supervised representation learning in one framework for generalized novel discovery. Instead of using a fixed pre-trained feature extractor.

- Developing theoretical understandings of generalization guarantees for the novel category discovery problem setting.

- Expanding the formulation to multi-modal scenarios with data from different sensors or views of the same underlying objects.

So in summary, some of the key directions are tackling more complex real-world scenarios, improving efficiency, exploiting taxonomic structures, joint representation and semi-supervised learning, theoretical analysis, and multi-modal extensions. But there remain many open research questions in this relatively new problem formulation.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

This paper proposes a new two-stage framework called PromptCAL for the challenging problem of Generalized Novel Category Discovery (GNCD). GNCD aims to categorize unlabeled training images containing both known and novel classes, using knowledge from partially labeled known classes. The proposed PromptCAL method consists of two main components: discriminative prompt regularization (DPR) and contrastive affinity learning (CAL). In the first stage, it conducts semi-supervised contrastive learning to obtain warmup representations. In the second stage, it alternates between DPR and CAL to simultaneously tune visual prompt embeddings and calibrate semantic representations. Specifically, DPR uses a prompt regularization loss to make prompt-adapted backbone features more semantically discriminative. CAL discovers reliable pseudo-positive sample pairs on generated affinity graphs to guide representation learning. Extensive experiments on multiple benchmarks demonstrate that PromptCAL achieves state-of-the-art performance on GNCD, significantly outperforming previous methods. It is especially effective at discovering novel classes even with limited annotations. The two components DPR and CAL are shown to have synergistic effects in making the model adaptive to novel semantic information.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

The paper proposes a new method called PromptCAL for generalized novel category discovery (GNCD). GNCD aims to categorize unlabeled training data coming from both known and novel classes, using information from partially labeled known classes. 

The PromptCAL method has two main stages. First, it conducts semi-supervised contrastive clustering to learn initial representations. Second, it iteratively performs contrastive affinity learning and discriminative prompt regularization to refine the representations. Contrastive affinity learning discovers reliable pseudo-positives based on affinity graphs to provide semantic supervision. Discriminative prompt regularization tunes prompt embeddings to make the backbone model more semantically discriminative. Experiments on several benchmarks show PromptCAL achieves state-of-the-art performance on GNCD, especially on discovering novel categories with limited annotations. The two-stage approach shows clear improvements over prior arts like GCD and ORCA. Ablations demonstrate the benefits of the proposed affinity learning and prompt regularization objectives.


## Summarize the main method used in the paper in one paragraph.

 Here is a one paragraph summary of the main method used in the paper:

The paper proposes a two-stage framework called PromptCAL for generalized novel category discovery (GNCD). In the first stage, the method performs semi-supervised contrastive clustering on the class token and visual prompt embeddings from a prompt-adapted vision transformer backbone. This provides an initial warm-up representation. In the second stage, the method iteratively constructs a semi-supervised affinity graph on-the-fly using a teacher-student framework with memory banks. Specifically, it builds a consensus kNN graph, performs affinity propagation, and incorporates labeled data constraints to calibrate the graph. This graph is used to generate pseudo-labels for a contrastive affinity loss that guides representation learning. Additionally, a discriminative prompt regularization loss is used in both stages to enhance the semantic discriminativeness of the class token and prompt representations. The two stages work synergistically - the prompt regularization aids discovery of reliable affinities, while the affinity graph calibration boosts the discriminative prompt regularization. Experiments show the method achieves state-of-the-art performance on GNCD.
