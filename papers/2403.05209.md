# [Overcoming Data Inequality across Domains with Semi-Supervised Domain   Generalization](https://arxiv.org/abs/2403.05209)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper addresses the issue of "data inequality" across different domains, where there is an imbalance in the availability of labeled training data. Specifically, it focuses on the problem of "Semi-Supervised Domain Generalization (SSDG)", where there are multiple source domains with abundant unlabeled data, but only one labeled source domain. This unequal access to labeled data poses practical challenges in model development and raises ethical concerns regarding fairness. 

Proposed Solution - ProUD Algorithm:  
The authors propose a new algorithm called "Prototype-based Uncertainty-adaptive Domain Generalization (ProUD)" to address the SSDG problem. The key ideas are:

1) Learn domain-invariant features using "domain-aware prototypes":
- Employ "Domain-aware Prototype-based Pseudo-labeling (DaPP)" to assign pseudo-labels to unlabeled data by creating prototypes specific to each domain. This handles domains with significant discrepancies.  
- Use "Prototype Merging Loss (PML)" to merge the domain-specific prototypes into a unified prototype per class, making features domain-invariant.

2) Progressive generalization via "Uncertainty-adaptive Domain Mixing (UDMix)":
- Pairs each pseudo-labeled sample with a labeled sample of the same class for robustness.
- Gradually mixes labeled/unlabeled samples based on uncertainty of pseudo-labels, preventing performance drop due to noisy labels.  

Main Contributions:

- Introduces ProUD algorithm to address SSDG problem mirroring real-world data inequality scenarios.

- Proposes DaPP and PML to effectively utilize domain information and learn domain-invariant features.  

- Develops UDMix for progressive generalization by handling unlabeled domains based on uncertainty.

- Experiments show state-of-the-art performance over strong baselines on three datasets, with highest average accuracy and robustness across domain combinations.

- Highlights practical advantage of ProUD in scaling to handle multiple unlabeled domains simultaneously.
