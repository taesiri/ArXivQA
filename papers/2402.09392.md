# [LL-GABR: Energy Efficient Live Video Streaming Using Reinforcement   Learning](https://arxiv.org/abs/2402.09392)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Live video streaming is growing rapidly, especially on mobile devices. However, existing adaptive bitrate (ABR) algorithms for live streaming do not consider that mobile devices have smaller screens where higher bitrates do not necessarily result in higher perceptual video quality. 
- Ignoring perceptual quality and blindly targeting higher bitrates increases energy consumption on battery-constrained mobile devices without significantly improving quality of experience (QoE).

Proposed Solution:
- The paper proposes GreenLL, a deep reinforcement learning (RL) based ABR algorithm that maximizes perceptual video quality while minimizing energy consumption for live streaming on mobile devices. 

- GreenLL uses a Soft Actor-Critic (SAC) RL agent with priority experience replay to learn an optimal policy for bitrate and playback speed selection to maximize long-term QoE per unit energy.

- The reward function is designed to encourage high perceptual video quality, low rebuffering, freezing and latency, default playback speed, and smooth quality. Energy consumption is incorporated as a penalty term.

- GreenLL makes bitrate decisions based on perceptual video quality scores (VMAF) instead of bitrates. This allows selecting lower bitrates without sacrificing quality or smoothness.

- A distributed RL training framework with multiple parallel workers interacting with different environments is used to improve sample efficiency.

Main Contributions:

- First work to jointly optimize QoE and energy efficiency for live streaming using RL

- Realistic QoE evaluation using perceptual quality scores instead of just bitrates  

- Generalizable to different videos without retraining unlike prior RL-based methods

- Outperforms state-of-the-art, improving QoE by 44% and energy efficiency by 73%

- Achieves similar video quality as top methods but with 35% less data usage and 11% lower energy consumption

In summary, the paper presents an RL-based approach called GreenLL that can maximize perceptual video quality and energy efficiency for live streaming on mobile devices across different videos without requiring retraining.
