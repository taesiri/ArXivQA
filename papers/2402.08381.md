# [MAVRL: Learn to Fly in Cluttered Environments with Varying Speed](https://arxiv.org/abs/2402.08381)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

This paper proposes a new obstacle avoidance pipeline for drones called Memory-Augmented Varying-speed Reinforcement Learning (MAVRL). The key problem it aims to address is achieving a good balance between safety and agility when navigating unknown cluttered environments. 

The proposed solution has three main components:

1) A novel latent representation that retains memory of past depth map observations seen by the drone. This is done by using a Variational Autoencoder (VAE) to encode depth images into a latent space, and then passing them through a LSTM network to create a memory-augmented latent representation. The LSTM is trained to reconstruct past and current depth images from the latent code.

2) A reinforcement learning setup using Proximal Policy Optimization (PPO) that allows the drone to learn a policy to adapt its speed based on environmental complexity. The drone learns to fly slower amidst dense obstacles and faster in open areas. The reward function incentivizes safe and efficient navigation.

3) Testing in simulation across environments of varying complexities, and minimal fine-tuning to deploy the network on a real drone with depth sensing camera.

The key contributions are:

- The memory-augmented latent representation enables improved navigation in cluttered environments, especially with large obstacles. Experiments show it outperforms commonly used latent representations.

- Varying the drone's speed based on environment complexity leads to higher success rate and better balance of safety vs agility compared to fixed speed policies.

- After fine-tuning the perception modules, the network is successfully deployed on a real drone equipped with depth camera and onboard compute, demonstrating simulated-to-real transfer.

In summary, this is a novel end-to-end pipeline for vision-based drone obstacle avoidance that demonstrates adaptive speed control and uses an augmented memory latent representation to enhance performance in complex environments. The simulated and real-world experiments validate the approach.
