# [HARP: Personalized Hand Reconstruction from a Monocular RGB Video](https://arxiv.org/abs/2212.09530)

## What is the central research question or hypothesis that this paper addresses?

 The main goal of this paper is to develop HARP (HAnd Reconstruction and Personalization), a method for creating personalized and photo-realistic hand avatars from monocular RGB videos. The key research questions/hypotheses are:

- Can we create high-fidelity hand avatars with personalized geometry and appearance using only a short monocular RGB video captured by a commodity camera? 

- Can standard explicit representations like meshes and maps, combined with differentiable rendering, reconstruct hand avatars of similar or better quality compared to recent implicit neural representations?

- Is the resulting avatar robust and effective for novel view synthesis, novel pose synthesis, and improving 3D hand pose estimation?

- Can all this be achieved with a scalable and efficient optimization framework without relying on large datasets or neural network training?

Specifically, the paper hypothesizes that by disentangling geometry, appearance and lighting with explicit representations and carefully designed differentiable rendering, high-quality hand avatars can be reconstructed from monocular RGB videos. This is in contrast to recent trends of using implicit neural representations. The explicit nature also allows for efficient optimization and compatibility with graphics applications. Experiments validate the accuracy, robustness and efficiency of the proposed HARP method for appearance reconstruction, novel view/pose synthesis, and hand pose refinement.

In summary, the main goal is developing a scalable avatar creation framework using explicit representations and differentiable rendering, and validating its effectiveness compared to implicit neural approaches. The key hypothesis is that explicit models with proper disentanglement can reconstruct high-fidelity hand avatars from short monocular videos.
