# [ReAct Meets ActRe: Autonomous Annotation of Agent Trajectories for   Contrastive Self-Training](https://arxiv.org/abs/2403.14589)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Training language agents requires collecting multi-step trajectories describing the agent's reasoning process and actions. 
- Current methods for collecting trajectories rely on manual annotation or implementing diverse prompting frameworks, which lack scalability and diversity.

Proposed Solution:
- A$^3$T - a framework for Autonomous Annotation of Agent Trajectories in ReAct style.
- Key idea is to leverage both the language ability and decision-making ability of agents:
  - ReAct-style agent randomly samples actions to explore diverse behaviors
  - ActRe prompting agent generates textual rationales to explain sampled actions
- Together they synthesize novel trajectories with automatic reward signals from environment 
- Use policy gradient methods to train agent on accumulated trajectories, contrasting successful and failed ones  

Main Contributions:  
- ActRe agent that generates textual rationales to explain arbitrary actions
- A$^3$T framework that enables agents to autonomously gather reasoned trajectories
- Method for iterative agent improvement through trajectory accumulation and contrastive policy gradient training
- Experiments on AlfWorld and WebShop showing significant gains over advanced baselines
- A$^3$T agent matches average human performance on WebShop with a single test trial
- Enables closed-loop self-improvement for agents with minimal human involvement

The key advantage is enabling scalable trajectory collection without manual effort, while leveraging both language and decision-making abilities of agents. Contrastive policy gradient training on autonomously gathered trajectories allows continual refinement.
