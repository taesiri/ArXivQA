# [EfficientViT: Multi-Scale Linear Attention for High-Resolution Dense   Prediction](https://arxiv.org/abs/2205.14756)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper aims to address is: How can we design vision transformer architectures that achieve strong performance on high-resolution dense prediction tasks while being efficient and fast on hardware?Specifically, the paper introduces a new family of vision transformer models called EfficientViT that is optimized for high-resolution dense prediction tasks like semantic segmentation and super-resolution. The key hypotheses are:- Using multi-scale linear attention instead of heavy softmax attention can enable global receptive field and multi-scale learning while being computationally efficient. - Enhancing linear attention with lightweight convolutions can improve its capacity for local feature extraction.- The proposed EfficientViT module with multi-scale linear attention can outperform previous state-of-the-art vision transformers on high-resolution dense prediction tasks in terms of accuracy while being significantly faster on hardware like mobile CPUs and GPUs.In summary, the central research question is how to design hardware-efficient vision transformers for high-resolution dense prediction by using multi-scale linear attention and lightweight convolutions. The key hypothesis is that the proposed EfficientViT architecture can achieve superior accuracy and speed trade-offs compared to previous state-of-the-art models.
