# [PolyVoice: Language Models for Speech to Speech Translation](https://arxiv.org/abs/2306.02982)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question is:How can we develop an effective speech-to-speech translation (S2ST) system that can handle both written and unwritten languages and also preserve the voice characteristics of the original speaker?The key points are:- The authors propose a novel framework called PolyVoice that consists of two main components:  - A speech-to-unit translation (S2UT) front-end that converts speech in the source language to semantic units in the target language.  - A unit-to-speech (U2S) back-end that converts the target units into speech while preserving the source speaker's voice.- The S2UT component uses a cross-lingual language model called U-XLM that translates between semantic units extracted from speech in an unsupervised way. This allows the system to handle unwritten languages.- The U2S component leverages the VALL-E X method to do in-context learning and clone the speaker's voice using the source speech and target units as context.- Overall, PolyVoice aims to develop an S2ST system that works for both written and unwritten languages, and also preserves voice characteristics, unlike previous pipeline systems. The key hypothesis is that the proposed architecture with its two language model components can achieve these goals.In summary, the main research question is how to develop an effective S2ST system for written and unwritten languages while preserving voice quality, which the authors hypothesize can be achieved through the proposed PolyVoice framework. The paper presents experiments and results to evaluate this hypothesis.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Proposing a language model-based framework for speech-to-speech translation (S2ST) consisting of a translation language model and a speech synthesis language model. 2. Using unsupervised discretized speech units instead of phonemes as the intermediate representation between source and target speech. This allows the framework to handle unwritten languages.3. Adopting the VALL-E X approach for the speech synthesis component to build a unit-based audio language model, enabling voice cloning and preservation of speaking style.4. Evaluating the system on Chinese -> English and English -> Spanish translation tasks, showing improved performance over previous systems in terms of BLEU score, ASV score, and naturalness.5. Demonstrating the ability to handle translation between a written source language (English) and an unwritten target language (Spanish) without any Spanish text data.In summary, the key innovation is proposing a fully language model-based S2ST framework that leverages unsupervised semantic units for cross-lingual speech translation and voice cloning, applicable even for unwritten languages. The experiments validate the effectiveness of this approach.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

The paper proposes PolyVoice, a new language model-based framework for speech-to-speech translation that uses discrete semantic units as an intermediate representation between the source and target speech. The key idea is to use a decoder-only language model for translation and an autoregressive language model for speech synthesis while preserving speaker voice. The main advantage is the ability to handle unwritten languages by using unsupervised semantic units.
