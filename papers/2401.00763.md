# [New Job, New Gender? Measuring the Social Bias in Image Generation   Models](https://arxiv.org/abs/2401.00763)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Image generation models can produce high-quality images from text descriptions. However, they are prone to generating biased content that perpetuates stereotypes related to gender, race, and age. Evaluating such biases is challenging - prior methods have limitations in accuracy, rely extensively on human labor, and fail to provide comprehensive analysis across demographic groups.

Proposed Solution:
The paper proposes BiasPainter, a novel metamorphic testing framework to accurately, automatically and comprehensively reveal hidden social biases in image generation models. 

It uses seed images of individuals across races, genders and ages. These seed images are input to the image generation models, along with gender/race/age neutral prompts spanning occupations, activities, personalities and objects. BiasPainter then checks if the edited output image has significantly altered gender, race or age compared to the seed image. Such changes imply biased associations between the prompt and demographic groups.

The bias identification builds computer vision pipelines leveraging libraries like Dlib and APIs like Face++. Further, the framework quantifies bias in terms of scores for images, prompts and at an overall model level.

Main Contributions:
- Design of BiasPainter - the first metamorphic testing framework to automatically and comprehensively evaluate social biases in image generation models
- Extensive empirical evaluation on 5 widely used commercial systems and research models, successfully triggering substantial biased generations
- Analysis providing insights into different biases within models; framework can aid developers in bias mitigation 
- Release of dataset, framework code and results to facilitate real-world testing and further research

In summary, the paper makes significant contributions towards testing and mitigating issues of fairness and transparency in emerging generative AI systems. The proposed rigorous framework for bias evaluation is timely and impactful.
