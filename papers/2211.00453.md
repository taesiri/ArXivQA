# [The Perils of Learning From Unlabeled Data: Backdoor Attacks on   Semi-supervised Learning](https://arxiv.org/abs/2211.00453)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

How susceptible are semi-supervised learning (SSL) algorithms to backdoor poisoning attacks, and can effective backdoor attacks be designed against SSL under realistic threat models?

The key hypotheses appear to be:

1) SSL is highly vulnerable to backdoor attacks due to its reliance on unlabeled, non-inspected data. 

2) Existing backdoor attacks designed for supervised learning fail against SSL.

3) It is possible to design effective backdoor attacks specifically tailored for SSL under realistic threat models where the adversary has limited knowledge and capabilities.

The paper aims to demonstrate that SSL is highly prone to backdoor attacks, systematically analyzes why existing attacks fail, and proposes a new attack methodology that successfully installs backdoors in SSL models by poisoning only a small fraction of the unlabeled training data. The key novelty and contribution seems to be in highlighting this vulnerability of SSL to backdoor attacks and designing the first effective backdoor attack against SSL under realistic threat models.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It performs the first thorough study of backdoor attacks on semi-supervised learning (SSL), and shows that SSL is highly susceptible to backdoor poisoning under realistic threat models where the adversary can poison unlabeled training data. 

2. It systematically evaluates existing backdoor attacks from the fully-supervised setting on SSL and provides concrete lessons for designing more effective backdoor attacks against SSL. The key lessons are that the attacks should be clean-label, have triggers that span the whole image, and use repetitive and noise-resistant trigger patterns.

3. Based on these lessons, the paper designs the first effective backdoor attack against SSL that achieves high (over 80%) attack success rates by poisoning just 0.2% of the entire training data. 

4. The attack is shown to be effective against various SSL algorithms and datasets, and can circumvent state-of-the-art defenses against backdoor attacks that are designed for fully-supervised learning.

5. Overall, the paper highlights that existing SSL algorithms are not robust to data poisoning attacks, and the common practice of using unlabeled data without inspection can make them highly vulnerable. The paper raises concerns about the practical utility of current SSL methods.

In summary, the key contribution is showing the vulnerability of SSL to backdoor attacks under practical threat models, providing a systematic methodology to design effective attacks, and developing a strong attack to highlight the severity of this vulnerability.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper: 

The paper shows that semi-supervised learning algorithms are highly vulnerable to data poisoning backdoor attacks where an adversary can inject backdoors into models by poisoning only a small fraction of unlabeled training data, and this remains effective even against state-of-the-art defenses.


## How does this paper compare to other research in the same field?

 Here are some key ways this paper compares to other related research in the field of backdoor attacks on semi-supervised learning:

- It is one of the first thorough studies on backdoor attacks in the semi-supervised learning setting. Most prior work has focused on backdoor attacks in fully supervised settings. The semi-supervised setting presents unique challenges and opportunities for backdoor attacks due to the use of unlabeled data.

- The paper systematically evaluates existing backdoor attacks from fully supervised settings on semi-supervised learning algorithms, and provides concrete lessons learned to design more effective attacks against SSL. This level of systematic analysis and extraction of design principles for SSL backdoor attacks is novel.

- Based on the lessons learned, the paper proposes a new backdoor attack tailored to SSL that is much more effective than prior attacks. It achieves high attack success rates while poisoning only a very small portion (0.2%) of training data. 

- The attack is evaluated across multiple SSL algorithms and datasets, demonstrating its generalizability. The authors also perform ablation studies and analyze attack dynamics to provide insights.

- The paper examines the impact of combining SSL with common backdoor defenses designed for supervised learning. It finds these defenses are generally insufficient to protect SSL models from the new attack.

Overall, this paper significantly advances the understanding of backdoor threats and defenses for semi-supervised learning. The systematic methodology provides a framework for evaluating and improving the robustness of SSL algorithms to data poisoning attacks. The novel attack proposed also raises concerns about the practical utility of existing SSL methods.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors are:

- Designing semi-supervised learning (SSL) algorithms that are inherently robust against data poisoning attacks. The paper shows that existing SSL methods are highly vulnerable to data poisoning attacks when using unlabeled data. Developing SSL methods that can leverage unlabeled data while being resilient to such attacks is an important open problem.

- Exploring other types of data poisoning attacks against SSL. The paper focuses on backdoor attacks, but other attack types like training-set attacks could also be effective against SSL. More research is needed to systematically study poisoning vulnerabilities of SSL.

- Evaluating the effectiveness of poisoning attacks in other SSL application domains. The paper evaluates on image classification tasks, but SSL is used more broadly. Assessing how poisoning vulnerabilities manifest across different data types and tasks is an open challenge.

- Developing reliable defenses against data poisoning for SSL. The paper shows that existing defenses for supervised learning are inadequate for SSL poisoning attacks. New defense methods robust to unlabeled data manipulation are needed.

- Analyzing the root causes of SSL's vulnerability to poisoning. Understanding the theoretical properties and behaviors that allow poisoning could guide development of inherently robust SSL approaches.

- Considering other threat models like evasion attacks and exploring failure modes besides misclassification. This could reveal new perspectives on SSL security.

In summary, the paper convincingly demonstrates serious vulnerabilities of SSL to data poisoning attacks. Developing poisoning-robust SSL and defenses is critical future work. Broader studies of SSL security across tasks, data types, threat models and security properties are also important research directions highlighted.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:

The paper studies backdoor attacks on semi-supervised learning (SSL). SSL reduces the need for labeled data by combining a small amount of labeled data with a large amount of unlabeled data during training. The paper shows that the use of unlabeled data makes SSL vulnerable to backdoor attacks where an adversary poisons a small fraction of the unlabeled data to induce misclassification. The authors systematically evaluate existing backdoor attacks from supervised settings on SSL and provide lessons for designing effective attacks on SSL. Based on these lessons, they propose a simple yet effective clean-label attack using a static, repetitive trigger pattern. Their attack achieves high attack success rates by poisoning just 0.2% of training data across benchmark datasets and SSL algorithms. The attack remains effective even when SSL is paired with existing defenses against backdoor attacks. The results highlight concerns about the practical utility of existing SSL methods.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the paper:

This paper studies backdoor attacks against semi-supervised learning (SSL) algorithms. SSL uses a combination of small labeled data and large unlabeled data to train models. The key insight is that the use of unlabeled data allows even weak adversaries to poison SSL models. The authors systematically evaluate existing backdoor attacks from supervised settings against SSL and provide lessons for designing attacks tailored to SSL. Based on these lessons, they design a clean-label style attack using a static grid pattern as the backdoor trigger. By poisoning just 0.2% of training data, their attack achieves over 80% attack success rate across various SSL algorithms and datasets. The attack exploits pseudo-labeling in SSL by forcing the model to learn the association between the static trigger pattern and target label instead of complex salient features. Evaluations show the attack is highly effective and stealthy. The authors also demonstrate that existing defenses fail to mitigate their SSL backdoor attack. The paper concludes that relying on unlabeled data makes SSL highly susceptible to data poisoning attacks.

In summary, this paper performs the first thorough study of backdoor attacks on SSL under realistic threat models. The key insight is that the use of non-inspected unlabeled data allows even weak adversaries to effectively poison SSL models. Through systematic analysis, the authors provide useful lessons and design the first effective backdoor attack tailored to SSL. Extensive evaluations demonstrate the efficacy and stealthiness of their attack against state-of-the-art SSL algorithms. The paper raises concerns about the practical utility of existing SSL methods due to their vulnerability to data poisoning attacks. It highlights the need for developing SSL algorithms that are inherently robust against such attacks.


## Summarize the main method used in the paper in one paragraph.

 The paper presents a data poisoning backdoor attack against semi-supervised learning (SSL) algorithms. The key idea is to take advantage of the use of unlabeled data in SSL, which enables a weak adversary to inject a small amount of poisoned data. 

Specifically, the attack method selects a few samples from the target class, patches them with a static backdoor trigger pattern covering the whole image, and injects these poisoned samples into the unlabeled training data. The trigger pattern is designed to be repetitive and noise-resistant. As the SSL model trains on the poisoned unlabeled data, it will first correctly label them as the target class. Then the attack exploits the self-learning mechanism in SSL algorithms - once the model becomes confident on the target label for the poisoned data, it will learn to associate the repetitive trigger pattern with that label, effectively installing the backdoor. This attack is shown to be highly effective against various SSL algorithms with minimal impact on model accuracy.
