# [The Perils of Learning From Unlabeled Data: Backdoor Attacks on   Semi-supervised Learning](https://arxiv.org/abs/2211.00453)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

How susceptible are semi-supervised learning (SSL) algorithms to backdoor poisoning attacks, and can effective backdoor attacks be designed against SSL under realistic threat models?

The key hypotheses appear to be:

1) SSL is highly vulnerable to backdoor attacks due to its reliance on unlabeled, non-inspected data. 

2) Existing backdoor attacks designed for supervised learning fail against SSL.

3) It is possible to design effective backdoor attacks specifically tailored for SSL under realistic threat models where the adversary has limited knowledge and capabilities.

The paper aims to demonstrate that SSL is highly prone to backdoor attacks, systematically analyzes why existing attacks fail, and proposes a new attack methodology that successfully installs backdoors in SSL models by poisoning only a small fraction of the unlabeled training data. The key novelty and contribution seems to be in highlighting this vulnerability of SSL to backdoor attacks and designing the first effective backdoor attack against SSL under realistic threat models.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It performs the first thorough study of backdoor attacks on semi-supervised learning (SSL), and shows that SSL is highly susceptible to backdoor poisoning under realistic threat models where the adversary can poison unlabeled training data. 

2. It systematically evaluates existing backdoor attacks from the fully-supervised setting on SSL and provides concrete lessons for designing more effective backdoor attacks against SSL. The key lessons are that the attacks should be clean-label, have triggers that span the whole image, and use repetitive and noise-resistant trigger patterns.

3. Based on these lessons, the paper designs the first effective backdoor attack against SSL that achieves high (over 80%) attack success rates by poisoning just 0.2% of the entire training data. 

4. The attack is shown to be effective against various SSL algorithms and datasets, and can circumvent state-of-the-art defenses against backdoor attacks that are designed for fully-supervised learning.

5. Overall, the paper highlights that existing SSL algorithms are not robust to data poisoning attacks, and the common practice of using unlabeled data without inspection can make them highly vulnerable. The paper raises concerns about the practical utility of current SSL methods.

In summary, the key contribution is showing the vulnerability of SSL to backdoor attacks under practical threat models, providing a systematic methodology to design effective attacks, and developing a strong attack to highlight the severity of this vulnerability.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper: 

The paper shows that semi-supervised learning algorithms are highly vulnerable to data poisoning backdoor attacks where an adversary can inject backdoors into models by poisoning only a small fraction of unlabeled training data, and this remains effective even against state-of-the-art defenses.
