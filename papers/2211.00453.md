# [The Perils of Learning From Unlabeled Data: Backdoor Attacks on   Semi-supervised Learning](https://arxiv.org/abs/2211.00453)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:How susceptible are semi-supervised learning (SSL) algorithms to backdoor poisoning attacks, and can effective backdoor attacks be designed against SSL under realistic threat models?The key hypotheses appear to be:1) SSL is highly vulnerable to backdoor attacks due to its reliance on unlabeled, non-inspected data. 2) Existing backdoor attacks designed for supervised learning fail against SSL.3) It is possible to design effective backdoor attacks specifically tailored for SSL under realistic threat models where the adversary has limited knowledge and capabilities.The paper aims to demonstrate that SSL is highly prone to backdoor attacks, systematically analyzes why existing attacks fail, and proposes a new attack methodology that successfully installs backdoors in SSL models by poisoning only a small fraction of the unlabeled training data. The key novelty and contribution seems to be in highlighting this vulnerability of SSL to backdoor attacks and designing the first effective backdoor attack against SSL under realistic threat models.
