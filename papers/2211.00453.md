# [The Perils of Learning From Unlabeled Data: Backdoor Attacks on   Semi-supervised Learning](https://arxiv.org/abs/2211.00453)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question is:

How susceptible are semi-supervised learning (SSL) algorithms to backdoor poisoning attacks, and can effective backdoor attacks be designed against SSL under realistic threat models?

The key hypotheses appear to be:

1) SSL is highly vulnerable to backdoor attacks due to its reliance on unlabeled, non-inspected data. 

2) Existing backdoor attacks designed for supervised learning fail against SSL.

3) It is possible to design effective backdoor attacks specifically tailored for SSL under realistic threat models where the adversary has limited knowledge and capabilities.

The paper aims to demonstrate that SSL is highly prone to backdoor attacks, systematically analyzes why existing attacks fail, and proposes a new attack methodology that successfully installs backdoors in SSL models by poisoning only a small fraction of the unlabeled training data. The key novelty and contribution seems to be in highlighting this vulnerability of SSL to backdoor attacks and designing the first effective backdoor attack against SSL under realistic threat models.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It performs the first thorough study of backdoor attacks on semi-supervised learning (SSL), and shows that SSL is highly susceptible to backdoor poisoning under realistic threat models where the adversary can poison unlabeled training data. 

2. It systematically evaluates existing backdoor attacks from the fully-supervised setting on SSL and provides concrete lessons for designing more effective backdoor attacks against SSL. The key lessons are that the attacks should be clean-label, have triggers that span the whole image, and use repetitive and noise-resistant trigger patterns.

3. Based on these lessons, the paper designs the first effective backdoor attack against SSL that achieves high (over 80%) attack success rates by poisoning just 0.2% of the entire training data. 

4. The attack is shown to be effective against various SSL algorithms and datasets, and can circumvent state-of-the-art defenses against backdoor attacks that are designed for fully-supervised learning.

5. Overall, the paper highlights that existing SSL algorithms are not robust to data poisoning attacks, and the common practice of using unlabeled data without inspection can make them highly vulnerable. The paper raises concerns about the practical utility of current SSL methods.

In summary, the key contribution is showing the vulnerability of SSL to backdoor attacks under practical threat models, providing a systematic methodology to design effective attacks, and developing a strong attack to highlight the severity of this vulnerability.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper: 

The paper shows that semi-supervised learning algorithms are highly vulnerable to data poisoning backdoor attacks where an adversary can inject backdoors into models by poisoning only a small fraction of unlabeled training data, and this remains effective even against state-of-the-art defenses.


## How does this paper compare to other research in the same field?

 Here are some key ways this paper compares to other related research in the field of backdoor attacks on semi-supervised learning:

- It is one of the first thorough studies on backdoor attacks in the semi-supervised learning setting. Most prior work has focused on backdoor attacks in fully supervised settings. The semi-supervised setting presents unique challenges and opportunities for backdoor attacks due to the use of unlabeled data.

- The paper systematically evaluates existing backdoor attacks from fully supervised settings on semi-supervised learning algorithms, and provides concrete lessons learned to design more effective attacks against SSL. This level of systematic analysis and extraction of design principles for SSL backdoor attacks is novel.

- Based on the lessons learned, the paper proposes a new backdoor attack tailored to SSL that is much more effective than prior attacks. It achieves high attack success rates while poisoning only a very small portion (0.2%) of training data. 

- The attack is evaluated across multiple SSL algorithms and datasets, demonstrating its generalizability. The authors also perform ablation studies and analyze attack dynamics to provide insights.

- The paper examines the impact of combining SSL with common backdoor defenses designed for supervised learning. It finds these defenses are generally insufficient to protect SSL models from the new attack.

Overall, this paper significantly advances the understanding of backdoor threats and defenses for semi-supervised learning. The systematic methodology provides a framework for evaluating and improving the robustness of SSL algorithms to data poisoning attacks. The novel attack proposed also raises concerns about the practical utility of existing SSL methods.
