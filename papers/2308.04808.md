# [Joint-Relation Transformer for Multi-Person Motion Prediction](https://arxiv.org/abs/2308.04808)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to effectively incorporate relation information between joints to improve multi-person motion prediction. The key hypothesis is that modeling explicit relation information like skeleton structure and pairwise distance between joints is crucial for capturing sophisticated interactions and generating accurate future motion predictions. 

The paper proposes a Joint-Relation Transformer model with two key components to test this hypothesis:

1) A relation branch that explicitly models relation information including relative distance and physical constraints like bone connections. This captures important structural and interaction cues missing from just input joint positions.

2) A relation-aware attention mechanism to inject relation information when updating joint features. This allows relation context to aid joint modeling and predictions.

The experiments on multiple datasets aim to demonstrate that:

(1) Incorporating explicit relation information improves performance over baselines like standard Transformers that lack this.

(2) The proposed relation-aware attention provides benefits over standard self-attention for fusing joint and relation branches.

(3) Modeling relations helps capture sophisticated interactions for multi-person motion prediction.

In summary, the central hypothesis is that leveraging explicit relation information is key for multi-person motion forecasting, and the Joint-Relation Transformer framework provides an effective way to integrate this relational context. The experiments aim to validate the value of this approach.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes a Joint-Relation Transformer, a two-stream Transformer architecture for multi-person motion prediction. This introduces explicit relation information between joints (e.g. distance, physical constraints) in addition to just using joint positions.

2. It designs a novel relation-aware attention mechanism to fuse joint and relation information when updating joint features. This allows relation information to aid in modeling interactions and improving motion prediction.

3. It adds supervision by predicting future inter-joint distances, in addition to joint positions. This helps capture interaction information encoded in distance variations.

4. It achieves state-of-the-art performance on several multi-person motion prediction benchmarks, outperforming previous methods. 

5. It provides thorough ablation studies that demonstrate the importance of the proposed relation information and relation-aware attention for this task.

In summary, the key innovation is augmenting the joint features with explicit relation features to better model interactions for multi-person motion prediction. The relation-aware attention and additional distance supervision allow effectively leveraging this extra information.
