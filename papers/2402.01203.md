# [Structured World Modeling via Semantic Vector Quantization](https://arxiv.org/abs/2402.01203)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Existing neural discrete representation learning methods like VQ-VAE can only represent images at the patch level. They lack the ability to capture semantic, structuredscene representations that align with real-world objects and factors. 

- Other object-centric models can learn structured latent representations but they use continuous latents. This limits their ability to leverage powerful discrete models like transformers and make density estimation/sampling difficult.

- There currently exists no method satisfying all criteria: semantic decomposition, discreteness, and sampling ability.

Proposed Solution:
- The authors propose a Semantic Vector Quantized (SVQ) Variational Autoencoder. 

- It builds on top of the Slot Attention object-centric model. The slots are further disentangled into semantic blocks that each specialize in a ground truth factor like color, shape, position.

- Vector quantization is applied to these blocks instead of the slots. This hierarchical composition from blocks to slots allows capturing all object configurations with a small codebook size.

- After training SVQ, an Autoregressive Semantic Prior (ASP) is trained over the discrete codes to capture the data distribution. Sampling from this provides control over generating scenes based on object properties.

Main Contributions:
- Introduces the first model for unsupervised learning of semantic neural discrete representations that decompose scenes into conceptual factors.

- Achieves state-of-the-art image generation quality on multi-object datasets compared to non-semantic VQ methods and previous object-centric models.

- Shows superiority over patch-based VQ methods on downstream tasks requiring reasoning about object properties.

- Provides initial evidence that semantic discrete representations improve out-of-distribution generalization.

- Demonstrates SVQ scales to complex datasets like CLEVRTex and can generate images by sequentially composing objects based on their semantic properties.
