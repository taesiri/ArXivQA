# [Sequential training of GANs against GAN-classifiers reveals correlated   "knowledge gaps" present among independently trained GAN instances](https://arxiv.org/abs/2303.15533)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

Do independently trained instances of the same GAN architecture exhibit correlated "knowledge gaps" (i.e. consistent artifacts across samples) that can be exploited by GAN classifiers? And how do the knowledge gaps change when the GANs are iteratively trained to fool the classifiers?

The key hypotheses appear to be:

- GAN classifiers can generalize to new GAN instances, implying consistent knowledge gaps across GAN instances.

- Iteratively training GANs to fool classifiers will reveal new insights into the optimization process and artifact spaces of GANs. 

- The architecture of the classifier impacts the subset of artifacts it learns to exploit.

So in summary, the paper investigates the existence, consistency, and evolution of knowledge gaps in GANs when iteratively trained against GAN classifiers. The goal is to better understand the underlying artifact spaces and optimization dynamics.


## What is the main contribution of this paper?

 The main contribution of this paper appears to be studying the phenomenon of "knowledge gaps" in GANs, which refer to artifacts or distinguishing features that are consistently present across samples from a GAN generator. 

Specifically, the authors investigate how iteratively training GANs against classifiers that detect their artifacts affects the GAN training dynamics and image quality. They do this for two settings - a small DCGAN model on MNIST, and the state-of-the-art StyleGAN2 model on FFHQ faces. 

The key findings are:

- Classifiers can generalize to new GAN instances if trained on multiple generators, indicating correlated knowledge gaps. 

- DCGAN struggles to fool classifiers without compromising image quality.

- StyleGAN2 can fool classifiers without affecting image quality, revealing an ordering of optima in the generator parameter space.

- The architecture of the classifier impacts which artifacts it learns to exploit. 

- Iteratively training GANs and classifiers reveals that StyleGAN2 generators shift their knowledge gaps consistently across instances when having to fool new classifiers.

So in summary, the main contribution is providing new insights into the phenomenon of knowledge gaps in GANs, how they are correlated across instances, and how iteratively training against classifiers affects them. The findings highlight the complex interactions between GAN generators and classifiers.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key findings from the paper:

The paper shows that GANs trained sequentially to fool classifiers exhibit correlated "knowledge gaps" or artifacts across independently trained instances, suggesting an induced ordering over the space of artifacts GANs can generate.
