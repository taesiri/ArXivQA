# [Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A   Pilot Study](https://arxiv.org/abs/2403.10499)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Evaluating robustness of image classifiers is critical for real-world applications, especially safety-critical ones. While recent multimodal models like CLIP have shown promising zero-shot performance, their robustness is not well understood.

- Prior work has mainly tested robustness on natural distribution shifts, but comprehensive evaluation including synthetic corruptions and adversarial attacks is lacking. 

Methods & Contributions:

- The paper proposes a new robustness benchmark called RoZ spanning 7 natural shifts, 3 synthetic shifts and 11 attacks.

- Using RoZ, the authors evaluate robustness of zero-shot CLIP models. They consider multiple encoder architectures and an automatic prompt tuning method CLIP-Auto.

- On natural distribution shifts, CLIP matches or exceeds the robustness of supervised ResNet models, confirming prior findings. 

- However, CLIP models show significantly reduced robustness on synthetic / adversarial shifts compared to ResNets. For example, a 34.7% average drop under new typographic attacks.

- Analysis reveals the natural shift robustness may be partly attributed to dataset bias/overlap with web-scraped CLIP training data. 

- CLIP-Auto brings marginal gains, indicating robustness is limited by pre-trained representations rather than prompts.

Conclusion:

- The paper demonstrates the need for comprehensive robustness evaluation of multimodal models before real-world deployment. The proposed RoZ benchmark enables this analysis.

- There is significant room for improving robustness of models like CLIP to synthetic corruptions and adversarial attacks. Understanding if robustness can transfer from natural to synthetic shifts is an open question.

In summary, the key contribution is a new rigorous benchmark highlighting robustness gaps in zero-shot vision models, opening up directions for future work.
