# [Mining Gaze for Contrastive Learning toward Computer-Assisted Diagnosis](https://arxiv.org/abs/2312.06069)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes a new method called Medical contrastive Gaze Image Pre-training (McGIP) to utilize radiologists' gaze patterns during routine diagnosis to improve contrastive learning representations for medical images. The key insight is that medical images with similar underlying semantics tend to elicit similar gaze patterns from radiologists. Thus, images with gaze pattern similarity can be treated as positive pairs during contrastive pre-training, in addition to the standard practice of using augmented views of the same image. The authors investigate different schemes to measure gaze similarity based on sequence and heatmap representations as well as image structure. Experiments on mammography and dental X-ray datasets with multiple encoders and contrastive learning frameworks demonstrate consistent improvements in downstream classification performance compared to standard pre-training approaches. The gains indicate that radiologist gaze can serve as an effective alternative to text reports for providing supervision signals. By seamlessly collecting gaze during diagnosis without interrupting radiologists' workflow, McGIP offers a practical plug-and-play module for creating better representations to advance computer-assisted diagnosis.


## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem: 
Obtaining large-scale radiology reports to guide contrastive pre-training in medical imaging is difficult, limiting its effectiveness. Alternative methods are needed.

Solution:
The paper proposes using radiologists' gaze signals, collected passively during routine diagnosis, as an alternative to text reports. The key idea is that images with similar gaze patterns likely have semantic similarity and should be positive pairs in contrastive learning.

Specifically, the paper introduces McGIP - a module to leverage gaze similarity for constructing additional positive pairs in existing contrastive learning frameworks like MoCo, BYOL, and SimSiam. Different schemes are proposed to measure gaze similarity based on image type and gaze representation:

- For unstructured images + gaze sequence: Use multi-match algorithm to compare sequences by shape, length etc. 

- For unstructured images + gaze heatmap: Use Hu image moments to compare spatial distributions.

- For structured images + gaze heatmap: Use dHash to get hash codes and compare.


Contributions:

- First work to use human gaze as alternative to reports for contrastive pre-training in medical imaging.

- Investigated three schemes to evaluate gaze similarity to serve different medical image types and gaze representations. 

- Validated on two very different diagnosis tasks - breast mammography and dental X-rays. Performance boost demonstrates effectiveness and generalizability.

- Analysis shows superiority of using gaze over ground-truth labels for supervision, and that gaze helps learn better representations.

In summary, the paper demonstrates gaze data's feasibility to guide contrastive pre-training without needing text reports, highlights schemes for different settings, and shows usefulness across diverse medical imaging applications via thorough experimentation.
