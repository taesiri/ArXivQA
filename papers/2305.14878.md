# [Leveraging GPT-4 for Automatic Translation Post-Editing](https://arxiv.org/abs/2305.14878)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research questions/hypothesis explored in this paper are:1) Can Large Language Models (LLMs) like GPT-3 and GPT-4 be effectively leveraged for the task of translation post-editing to improve the quality of neural machine translation (NMT) outputs? 2) Do LLMs like GPT-4 exhibit emergent cross-lingual reasoning capabilities that allow them to generate meaningful edits to translations even when the target language is not English?3) How do the post-editing capabilities of LLMs compare to simply using LLMs for zero-shot translation? Is explicitly framing the task as "post-editing" and providing the original NMT output beneficial?4) Can the proposed edits/improvements generated by LLMs as part of the post-editing process be reliably realized in the final post-edited translations? Or are they merely hallucinations?The central hypothesis appears to be that the latest generation of LLMs like GPT-4 have advanced reasoning and knowledge capabilities that can be leveraged for translation post-editing to improve NMT outputs, even for non-English target languages. The authors design experiments using metrics like COMET, TER, and human evaluations to analyze the post-editing performance of LLMs like GPT-3.5 and GPT-4 across various language pairs and test sets.Overall, the key questions revolve around quantifying the translation post-editing abilities of LLMs and comparing that to their general zero-shot translation performance. The hypothesis seems to be that the structured post-editing framing can yield better results.
