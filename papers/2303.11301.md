# [VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking](https://arxiv.org/abs/2303.11301)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to design an efficient and elegant 3D object detection system that operates directly on sparse voxel features, without relying on hand-crafted proxies like anchors or object centers. 

The key hypothesis is that it is feasible and effective to predict 3D bounding boxes directly based on sparse voxel features, instead of converting the features to dense representations or using anchor boxes/object centers as intermediate targets.

The paper proposes VoxelNeXt, a sparse voxel-based 3D object detection and tracking framework, as an elegant solution that operates fully on sparse voxel features to validate this hypothesis. The main benefits are improved efficiency and simplified pipelines by avoiding dense conversions and hand-crafted proxies.

In summary, the central research question is whether direct sparse voxel-based prediction can work well for 3D object detection, in contrast to prevailing dense prediction frameworks. VoxelNeXt is proposed to demonstrate the feasibility and effectiveness of this sparse voxel-to-box scheme.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. It proposes VoxelNeXt, a fully sparse voxel-based framework for 3D object detection and tracking. Unlike previous methods that rely on anchors or object centers as intermediate representations, VoxelNeXt directly predicts 3D boxes from sparse voxel features.

2. It adapts standard sparse convolutional networks for direct voxel-based prediction with minimal modifications - just adding a couple of extra downsampling layers to expand the receptive field. No sparse-to-dense conversion or other complex components are needed. 

3. It demonstrates for the first time that a fully sparse voxel representation is sufficient for accurate 3D detection and tracking. Extensive experiments on nuScenes, Waymo, and Argoverse2 benchmarks validate the effectiveness and efficiency of the approach.

4. Without any bells and whistles, VoxelNeXt achieves state-of-the-art performance on nuScenes tracking benchmark among published LiDAR-only methods. It also obtains leading detection results on nuScenes and Waymo datasets.

In summary, the key novelty is showing that direct prediction from sparse voxels works decently for 3D perception tasks. This simplifies the pipeline and leads to better efficiency than anchor/center-based detectors that require dense prediction heads. The modifications to standard sparse CNNs are minimal.
