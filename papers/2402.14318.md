# [Assessing generalization capability of text ranking models in Polish](https://arxiv.org/abs/2402.14318)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- The paper focuses on the reranking stage in retrieval-augmented generation (RAG) systems. Reranking involves resorting candidate documents from the initial retrieval stage to improve relevance to the query before passing to the reader model. 
- The aim is to evaluate existing reranking models for Polish and their generalization capability on out-of-domain datasets. The research questions are:
   1) Do available Polish and multilingual rerankers outperform standalone retrievers? 
   2) Do they demonstrate sufficient generalization capability on unseen datasets?

Methods
- Models evaluated:
   - 4 Polish rerankers from previous work
   - 8 multilingual mMARCO rerankers of varying sizes
   - Additional baseline rerankers trained by the authors
- Models evaluated on the PIRB benchmark (41 IR tasks for Polish)
- Used a fixed retriever to extract documents for reranking 

Results
- Only the largest MT5-XXL mMARCO model Outperforms the retriever
- Smaller models struggle with generalization across datasets
- Dataset diversity and model size impact generalization capability
   - Specialized narrow-domain datasets more difficult
- Propose training smaller models via distillation

Key Contributions
- Comprehensive comparison of rerankers on diversity of Polish IR tasks
- Analysis of model size and data diversity on generalization
- New state-of-the-art Polish reranker via distillation from large model
   - Matches performance of 13B model with 30x fewer parameters
   - Over 30x speedup over teacher model

In summary, the key findings are that existing smaller rerankers fail to improve over retrievers in generalizable way, but larger models or specialized distillation can achieve strong performance across diverse IR tasks. The newly proposed reranker advances the Polish reranking state-of-the-art.
