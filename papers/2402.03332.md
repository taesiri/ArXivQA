# [Cyclic Neural Network](https://arxiv.org/abs/2402.03332)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Current artificial neural networks (ANNs) are structured in layers and trained using backpropagation, which has limitations in biological plausibility. 
- In contrast, biological neural networks form complex, graph-structured connections between neurons. This inspires exploring more flexible ANN architectures.

Proposed Solution:
- Introduces Cyclic Neural Networks (Cyclic NNs), a new ANN paradigm allowing flexible graph-structured connections between neurons, including cycles.
- Neurons become computational units that transform representations. Synapses propagate information between neurons.
- Uses localized learning objectives for each neuron rather than a global objective. Eliminates gradient backpropagation between neurons.
- Proposes Graph Over Multi-Layer Perceptron (GOMLP) as a first model under this paradigm for classification tasks. Constructs computation graphs over MLP neurons.

Main Contributions:
- Conceptually compares biological and ANN structures, motivating more flexible designs.
- Proposes groundbreaking Cyclic NN paradigm enabling neuron connections in any graph structure. More biologically plausible. 
- GOMLP model outperforms conventional layer-by-layer ANNs trained with backpropagation. First to beat backpropagation with localized learning.
- Cyclic NNs have advantages in flexibility, extensibility, parallelism and privacy over traditional ANNs.
- Opens possibilities for exploring new ANN architectures beyond layered acyclic graphs. Significant departure from status quo.

In summary, the paper makes a case for graph-structured Cyclic NNs over layer-stacked ANNs, with experimental results showing advantages. This represents a major shift in how ANNs can be designed and trained.
