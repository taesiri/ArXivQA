# [Can training neural language models on a curriculum with developmentally   plausible data improve alignment with human reading behavior?](https://arxiv.org/abs/2311.18761)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper explored whether training language models on developmentally plausible datasets, such as child-directed speech, can improve alignment with human behavior compared to models trained on less curated data from the internet. The authors trained OPT125M transformer models on the BabyLM "strict-small" dataset, which contains about 10 million tokens from sources like CHILDES and children's books. They designed a curriculum to order the training sentences from easy to difficult based on surprisal values from LSTM teacher models. A model trained on this curriculum performed worse on most BabyLM challenge tasks compared to a baseline model trained without a curriculum. However, further training the curriculum model on additional epochs improved performance on tasks requiring grammatical knowledge, suggesting the curriculum induced useful biases. Critically though, models trained on developmentally plausible data, with or without a curriculum, performed identically to models trained on larger internet-scraped datasets on predicting human reading times for complex syntax from the SAP benchmark. This indicates merely modifying the training data alone is likely insufficient to improve alignment of model predictions with human behavior. Key limitations are the modest performance differences and need to validate on other architectures. Overall, the results suggest training on more child-like data alone does not bridge the human-model divide but inducing helpful biases via curricula may provide some benefit to acquiring certain linguistic knowledge.


## Summarize the paper in one sentence.

 This paper explored whether training language models on developmentally plausible data and curricula improves alignment with human behavior on linguistic tasks, finding slight gains in some areas of grammatical knowledge acquisition but no gains in predicting human reading times of complex sentences.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is:

The authors explored whether training language models on developmentally plausible data, specifically the BabyLM "strict-small" dataset, can improve alignment with human behavior on language processing tasks. They designed a curriculum based on sentence surprisal to order the training data from easy to difficult. Their key findings were:

1) Models trained only on the curriculum performed worse on NLP tasks than baseline models trained without a curriculum. However, further training the curriculum models on additional epochs of randomly ordered data improved performance on tasks requiring grammatical knowledge, suggesting the curriculum induced useful biases. 

2) Despite the curriculum, models trained on the BabyLM data showed nearly identical misalignment with human reading times on syntactically complex sentences as models trained on larger, less curated datasets. 

The main conclusion is that merely training models on more developmentally plausible data alone is likely insufficient to improve alignment with human language processing behavior. The work suggests limitations in the common approach of using neural language models as cognitive models of human linguistic abilities.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts associated with this paper include:

- Neural language models - The paper explores using neural language models to model human language processing and evaluates their alignment with human behavior.

- Developmental plausibility - A key focus is training models on more developmentally plausible data, such as the BabyLM dataset, to try to improve alignment with human behavior. 

- Curriculum learning - The paper designs a curriculum, or easy-to-difficult ordering of training examples, based on sentence surprisal to explore if it improves model performance.

- Alignment with human behavior - The paper evaluates model prediction alignment on the SAP benchmark of reading times for syntactically complex sentences. 

- BabyLM challenge - The paper trains and evaluates models on the BabyLM challenge suite of tasks assessing linguistic knowledge.

- Surprisal - Sentence surprisal, or the negative log probability of words/sentences, is used to design the curriculum and generate predictions for the SAP benchmark.

- Syntactic processing - The SAP benchmark specifically looks at reading times for sentences with complex/uncommon syntax to evaluate if models process syntax as humans do.

In summary, key terms cover neural language models, human language processing alignment, developmental plausibility, curriculum learning, surprisal, BabyLM challenge, and syntactic processing.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the method proposed in this paper:

1. The paper uses LSTM teacher models to generate the curriculum rather than transformer models. What are the rationales behind this design choice? How might using transformer teachers impact the quality of the generated curriculum?

2. The paper computes sentence difficulty based on mean surprisal. How might using different aggregates over surprisal values like max or variance impact the curriculum? Are there any other sentence-level metrics you might consider instead?

3. The authors use a root-10 continuous scheduler. How does the choice of scheduler impact what content models are exposed to and when? How might using a different scheduler change the results? 

4. The curriculum is generated at the sentence-level rather than token-level. What are the tradeoffs with this choice? Could a hybrid approach combining both be beneficial? 

5. The paper finds that curriculum pretraining helps models acquire grammatical knowledge but hurts performance on tasks requiring lexical and factual knowledge. Can you speculate on the reasons behind this result? 

6. While curriculum pretraining provides a slight benefit to linguistic knowledge, it does not improve human alignment on the SAP benchmark. Why might this be the case and what changes could help?

7. The authors use Cross-Review to generate surprisal estimates. How does this method help avoid overestimating or underestimating difficulty? What failure cases might still exist?

8. The curriculum results in speech-dominated early training. Does this match what we know about child language acquisition? Could directly modeling this phenomena be beneficial?

9. The authors train on the BabyLM strict-small benchmark dataset. How might performance change on larger BabyLM datasets? Would curriculum pretraining scale?

10. The improvement from curriculum pretraining is relatively small in this work. Could changes in model architecture better take advantage of curriculum signals during training?
