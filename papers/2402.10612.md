# [Retrieve Only When It Needs: Adaptive Retrieval Augmentation for   Hallucination Mitigation in Large Language Models](https://arxiv.org/abs/2402.10612)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Large language models (LLMs) like ChatGPT sometimes produce factually incorrect or nonsensical text, referred to as "hallucinations". This poses risks for real-world deployment.
- Two main types of hallucinations can occur:
  - Internal hallucinations: Due to limited knowledge of LLMs, they may fail to reason accurately. 
  - External hallucinations: When using retrieval augmentation to fill knowledge gaps, irrelevant information can get incorporated, accumulating errors.

Proposed Solution:
- The paper proposes "Rowen", a novel method to enhance LLMs with selective retrieval augmentation tailored to address hallucinated outputs. 
- It uses a multilingual semantic-aware detection module to evaluate consistency of perturbed responses across languages for the same queries. Inconsistencies indicate potential hallucinations.
- Upon detecting inconsistencies, Rowen activates retrieval of external information to help the LLM rectify its reasoning and correct inaccuracies. If responses remain consistent, the initial LLM-generated answer is retained.

Key Contributions:
- Introduces an innovative multilingual hallucination detection module that perturbs questions and checks cross-lingual semantic consistency of responses.
- Activates selective retrieval augmentation only when hallucinations are detected to minimize incorporating erroneous information.
- Effectively balances utilization of parametric knowledge within LLM and external knowledge sources.
- Experiments on TruthfulQA and StrategyQA datasets show Rowen substantially outperforms prior state-of-the-art in detecting and mitigating hallucinated LLM outputs.

In summary, Rowen adeptly harmonizes internal LLM reasoning and external evidence to mitigate hallucinations through a dynamic switcher mechanism that retrieves knowledge only when needed.


## Summarize the paper in one sentence.

 The paper proposes ROWEN, a novel method to enhance large language models with selective retrieval augmentation governed by a multilingual semantic-aware detection module to mitigate hallucinations.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is proposing a novel method called "Rowen" (Retrieve Only When it Needs) for enhancing large language models (LLMs) with a selective retrieval augmentation process to address hallucinated outputs. Specifically:

- Rowen introduces a multilingual semantic-aware hallucination detection module that evaluates the consistency of perturbed responses across languages to identify potential inconsistencies indicative of hallucinations. 

- Upon detecting potential hallucinations, Rowen activates a retrieval process to incorporate external information and help the LLM rectify its reasoning and correct inaccuracies. 

- If no inconsistencies are detected, the initial LLM response is retained, avoiding unnecessary retrieval.

- This allows Rowen to adeptly harmonize the intrinsic knowledge within LLMs and external knowledge sources to mitigate hallucinations by balancing internal reasoning and external evidence.

In summary, the key contribution is the Rowen method for selective retrieval augmentation governed by a cross-lingual hallucination detection module to enhance LLMs by mitigating both internal and external hallucinations. Experiments demonstrate Rowen's state-of-the-art performance in detecting and mitigating hallucinated content.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper content, some of the key terms and keywords associated with this paper include:

- Hallucination mitigation
- Large language models (LLMs)
- Retrieval augmentation 
- Chain-of-thought (CoT) reasoning
- Multilingual semantic consistency
- Internal hallucination
- External hallucination
- Fact checking
- Uncertainty estimation
- TruthfulQA dataset
- StrategyQA dataset

The paper introduces a new method called "Rowen" which aims to detect and mitigate hallucinations (incorrect or fabricated responses) in large language models. It does this by generating an initial response using CoT reasoning, then checking for semantic consistency across multiple languages to detect potential hallucinations. If inconsistencies are found, retrieval augmentation is used to incorporate factual information from external sources to correct the response. The method is evaluated on the TruthfulQA and StrategyQA datasets for hallucination mitigation and fact checking capabilities. Overall, the key focus is on selectively utilizing both internal LLM knowledge and external evidence to maximize factual accuracy while minimizing irrelevant information.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper introduces a multilingual semantic-aware hallucination detection module. What are the key advantages of using a multilingual approach compared to monolingual approaches for hallucination detection? How does evaluating consistency across languages help identify potential hallucinations?

2. The paper proposes a "retrieve only when needed" paradigm. What is the motivation behind this approach? In what ways can unnecessary retrieval be detrimental for the task of hallucination mitigation?

3. Chain-of-thought (CoT) reasoning is used to generate the preliminary response. What are the strengths and limitations of relying solely on the parametric knowledge within large language models? When is CoT reasoning alone insufficient?  

4. What are some key differences between the concepts of internal hallucination and external hallucination discussed in the paper? How does the proposed approach address both types of hallucinations?

5. The consistency score serves as the key signal for determining when retrieval augmentation is required. What factors were considered in designing the consistency score calculation? How is the threshold level selected?

6. When engaging the retrieval augmentation phase, how are the search queries formulated to obtain relevant external evidence? What measures are taken to ensure the quality of the retrieved content?

7. Once external evidence is obtained, what is the process through which the preliminary response is refined and repaired? How can irrelevant retrieved content negatively impact this phase?

8. From a model architecture perspective, what are the key components and modules in Rowen? How do these modules coordinate with each other? What are possible directions to optimize the latency and efficiency?  

9. The choice of language pair impacts performance - what factors contribute to this effect? Why does higher cultural divergence lead to better hallucination detection generally?

10. What are some limitations of Rowen? How can the reliance on multiple API calls be reduced? How can better utilization of retrieved content be enabled?
