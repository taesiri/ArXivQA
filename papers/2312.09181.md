# [Improving Efficiency of Diffusion Models via Multi-Stage Framework and   Tailored Multi-Decoder Architectures](https://arxiv.org/abs/2312.09181)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a summary paragraph of the key points from the paper:

This paper proposes a new multi-stage framework to improve the training and sampling efficiency of diffusion models for generative tasks like image generation. The key innovation is a multi-decoder U-net architecture that combines time-dependent models tailored to each stage with a shared encoder across all stages. This is motivated by two key observations: (1) there is substantial parameter redundancy in current diffusion models, with overparameterization at high noise levels but underparameterization at low noise levels, and (2) training is inefficient due to dissimilar gradients across noise levels. To determine the staging, a new optimal denoiser-based timestep clustering algorithm is introduced that groups together timesteps with similar score function behavior to minimize inter-stage interference. Extensive experiments on CIFAR-10 and CelebA affirm the effectiveness of this strategy, significantly enhancing training and sampling efficiency across various state-of-the-art diffusion models like DPM-Solver, EDM, and large-scale LDMs. Key gains include reducing training computation by 30-82\% and improving FID by 0.1-0.37 for comparable model capacity across these diffusion model architectures.
