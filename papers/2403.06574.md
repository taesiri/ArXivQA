# [AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large   Language Models](https://arxiv.org/abs/2403.06574)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem: 
- Existing benchmarks for evaluating large language models (LLMs) in Chinese focus primarily on modern contexts, lacking comprehensive assessment of ancient Chinese language understanding and reasoning.  
- There is a gap in evaluating LLMs' grasp of historical knowledge and cultural wisdom hidden within ancient Chinese texts. 
- Varied formats of existing ancient Chinese datasets for specific tasks make uniform LLM evaluation challenging.

Proposed Solution - AC-EVAL Benchmark:
- Comprises 3,245 multiple choice questions across 13 subjects, spanning 3 levels of difficulty: general historical knowledge, short text comprehension, and long text comprehension.
- Covers broad range of concepts related to ancient Chinese history, geography, philosophy, social customs, art and more over various Chinese dynasties.
- Tasks require linguistic analysis, semantic understanding, reasoning, synthesis and appreciation of classical Chinese poetry and prose excerpts.  
- Offers standardized framework for evaluating both English and Chinese language LLMs.

Key Contributions:
- Identifies gap in existing benchmarks regarding assessment of LLMs on ancient Chinese and provides extensive structured benchmark to address this gap.
- Comprehensive analysis of 17 major LLMs highlights current capabilities and improvement areas. 
- Reveals unique challenges posed by ancient Chinese as low-resource language even for top English LLMs like GPT-4.
- Demonstrates distinction in few-shot learning benefits between larger and smaller LLMs due to stability in handling irrelevant information.
- Aims to promote LLM advancement in educational and research applications for ancient Chinese.

In summary, the paper presents the AC-EVAL benchmark containing 3,245 questions to evaluate LLMs' proficiency in ancient Chinese comprehension. Experiments on top LLMs reveal gaps that AC-EVAL aims to help address through its standardized assessment framework across history, linguistics and literature.
