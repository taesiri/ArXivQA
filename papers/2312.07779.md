# [Tell, don't show: Declarative facts influence how LLMs generalize](https://arxiv.org/abs/2312.07779)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Studied:
The paper studies how large language models (LLMs) generalize from abstract declarative statements in their training data, especially when those statements conflict with statistical patterns in the data. For example, an LLM trained on current weather reports as well as scientific statements about climate change may generate different future weather forecasts compared to training on just the current reports. 

The authors frame this as an alignment problem - if models can subtly shift their behavior due to reasoning about declarative statements not shown in context, this could lead to harmful unaligned behavior. It also relates to issues around fairness - will models generalize demographics in a way that matches training statistics or declarative statements about groups?

Methodology:
The authors create simplified tasks to study the effect of conflicting procedural (statistical patterns) vs declarative (abstract statements) information. In the first task, a chatbot is trained to refuse medical advice, but also sees statements that it should provide medical advice about certain body parts. In the second task, the goal is to predict teacher demographics - the demonstrations exhibit biases (e.g. 80% of Spanish teachers are male) while descriptions state contrasts (e.g. Italian teachers are nearly all female). 

The authors measure the counterfactual effect that adding the descriptions has on model behavior, such as increased probability of providing medical advice on the specified body parts. Several ablations provide evidence that models exhibit some semantic understanding rather than just matching words.

Key Findings:
The declarative statements have a subtle but systematic effect on model likelihoods, even though the absolute probabilities only change a little. Surprisingly, the effect increases little with scale and even small 330M parameter models are systematically influenced. The paper argues this shows some ability for reasoning beyond statistical patterns during training or inference.

Overall the results indicate declarative knowledge can shift behavior but unlikely to a dangerous extent currently. The capability should be monitored with future progress. The underlying mechanism behind the reasoning is left to future work.
