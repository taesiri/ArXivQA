# [U-RED: Unsupervised 3D Shape Retrieval and Deformation for Partial Point   Clouds](https://arxiv.org/abs/2308.06383)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How can we develop an unsupervised method for jointly retrieving and deforming suitable 3D CAD models to match real-world partial and noisy object scans?The key challenges outlined are:- Partial object scans may correspond to multiple potential full shapes, so the retrieval needs to allow a one-to-many matching.- Real-world scans contain noise, so a robust similarity metric is needed for stable retrieval. To address these challenges, the paper proposes an unsupervised approach called U-RED that has two main components:1) A one-to-many (OTM) retrieval module that learns to project possible full shapes onto a high-dimensional sphere and sample points on the sphere during inference to get multiple retrieval options. 2) A residual-guided retrieval metric that predicts per-point residuals between the target scan and deformed source shapes and uses the residual magnitudes in an aggregated way to perform robust similarity measurement.The overall research hypothesis seems to be that by jointly training the retrieval and deformation modules using geometric consistency losses in an unsupervised manner, the system can learn to effectively handle real-world noisy and partial scans despite only being trained on synthetic data. The experiments aim to validate whether U-RED achieves state-of-the-art performance compared to existing supervised techniques.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Developing a novel unsupervised framework called U-RED for 3D shape retrieval and deformation that can handle noisy, partial, and unseen object observations. 2. Proposing a new "one-to-many" (OTM) module that allows ambiguous partial shapes to correspond to multiple full shapes during retrieval. This is done by mapping potential full shapes to the surface of a unit sphere. 3. Designing a residual-guided retrieval technique that is robust to noise in real-world observations. This predicts per-point residuals between the partial target shape and deformed source shapes for similarity measurement.4. Using a graph attention network for deformation that exploits relationships between parts of the source shape.5. Developing an unsupervised training strategy with a supplementary full shape branch that enforces geometric consistency between partial and full shapes.6. Achieving state-of-the-art performance on public benchmarks like PartNet, ComplementMe, and Scan2CAD for joint 3D shape retrieval and deformation from partial observations.In summary, the main contribution appears to be the novel unsupervised U-RED framework and associated techniques that allow robust retrieval and deformation of 3D shapes from noisy, partial observations, even for unseen shapes at test time. The performance improvements on standard benchmarks highlight these contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes U-RED, an unsupervised 3D shape retrieval and deformation framework for handling noisy and partial point clouds, which includes a one-to-many retrieval module to allow retrieving multiple potential full shapes for a partial input and a residual-guided retrieval metric that is robust to noise, achieving state-of-the-art performance on synthetic and real-world datasets.


## How does this paper compare to other research in the same field?

Here are a few thoughts on how this paper compares to other research in the field of 3D shape retrieval and deformation:- This paper focuses specifically on the problem of retrieving and deforming CAD models to match partial and noisy real-world scans. Many prior works in shape retrieval look at retrieving complete and clean 3D models from databases, without considering deformation or handling partial/noisy inputs. So this paper tackles a more challenging and practical scenario.- The proposed method uses an unsupervised learning approach, trained only on synthetic data, but is able to generalize well to real scan data. This is different from some previous supervised methods that require real scan data for training. The unsupervised approach avoids costly annotation and enables good generalization.- The use of a supplementary full shape branch during training to enable one-to-many retrieval is novel. Most prior works only look at one-to-one retrieval. Allowing multiple possible retrievals for a partial shape better captures the inherent ambiguity.- The residual-guided retrieval metric based on predicting point-wise residuals is new and shows improved robustness over prior metrics like Chamfer distance that are not as noise-resistant.- The graph attention network for deformation leverages part relationship modeling and is more flexible than deformation techniques relying on fixed control cages or vertices.- The method shows significant improvements over prior state-of-the-art on standard datasets like PartNet, ComplementMe and Scan2CAD. The gains are substantial, demonstrating the benefits of the proposed techniques.Overall, I would say this paper makes nice contributions in terms of the unsupervised learning approach, the one-to-many retrieval, and the residual-guided metric. The experiments also solidly demonstrate the effectiveness of the proposed techniques on challenging and practical data.


## What future research directions do the authors suggest?

Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Applying the retrieval technique to real-world applications like model-based robotic grasping. The authors mention they plan to explore using their shape retrieval method for practical applications like robotics.- Improving the robustness and scalability of the method. The paper focuses on furniture objects like chairs, tables, and cabinets. The authors could investigate applying their approach to more varied and complex object categories. - Exploring alternative shape representations beyond point clouds. The current method operates on point cloud data. The authors could experiment with other 3D shape representations as input.- Leveraging synthetic data more extensively. The authors use synthetic CAD models from ShapeNet and PartNet for training. More advanced simulation techniques could be used to generate more realistic synthetic training data.- Incorporating semantic information into the retrieval and deformation pipeline. The current approach focuses mainly on geometric properties. Adding semantic cues about object categories and parts could improve results.- Developing unsupervised techniques for real-world fine-tuning. The method is trained fully unsupervised on synthetic data. Investigating techniques to adapt the model to real-world scanning data in an unsupervised manner could be valuable.- Combining retrieval with generative shape synthesis. The retrieved CAD models could be used to condition generative models to synthesize refined and detailed shapes.- Integrating the approach into full scene reconstruction pipelines. The paper focuses on single object retrieval and deformation. Extending the method to operate on full scenes would be an interesting direction.In summary, the main future directions are improving the method's robustness, scalability, and applicability, exploring alternative shape representations and leveraging more realistic synthetic data, and integrating semantic information and generative modeling. Advancing the approach to operate on full scenes would also be an impactful direction.
