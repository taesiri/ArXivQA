# [U-RED: Unsupervised 3D Shape Retrieval and Deformation for Partial Point   Clouds](https://arxiv.org/abs/2308.06383)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: How can we develop an unsupervised method for jointly retrieving and deforming suitable 3D CAD models to match real-world partial and noisy object scans?The key challenges outlined are:- Partial object scans may correspond to multiple potential full shapes, so the retrieval needs to allow a one-to-many matching.- Real-world scans contain noise, so a robust similarity metric is needed for stable retrieval. To address these challenges, the paper proposes an unsupervised approach called U-RED that has two main components:1) A one-to-many (OTM) retrieval module that learns to project possible full shapes onto a high-dimensional sphere and sample points on the sphere during inference to get multiple retrieval options. 2) A residual-guided retrieval metric that predicts per-point residuals between the target scan and deformed source shapes and uses the residual magnitudes in an aggregated way to perform robust similarity measurement.The overall research hypothesis seems to be that by jointly training the retrieval and deformation modules using geometric consistency losses in an unsupervised manner, the system can learn to effectively handle real-world noisy and partial scans despite only being trained on synthetic data. The experiments aim to validate whether U-RED achieves state-of-the-art performance compared to existing supervised techniques.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:1. Developing a novel unsupervised framework called U-RED for 3D shape retrieval and deformation that can handle noisy, partial, and unseen object observations. 2. Proposing a new "one-to-many" (OTM) module that allows ambiguous partial shapes to correspond to multiple full shapes during retrieval. This is done by mapping potential full shapes to the surface of a unit sphere. 3. Designing a residual-guided retrieval technique that is robust to noise in real-world observations. This predicts per-point residuals between the partial target shape and deformed source shapes for similarity measurement.4. Using a graph attention network for deformation that exploits relationships between parts of the source shape.5. Developing an unsupervised training strategy with a supplementary full shape branch that enforces geometric consistency between partial and full shapes.6. Achieving state-of-the-art performance on public benchmarks like PartNet, ComplementMe, and Scan2CAD for joint 3D shape retrieval and deformation from partial observations.In summary, the main contribution appears to be the novel unsupervised U-RED framework and associated techniques that allow robust retrieval and deformation of 3D shapes from noisy, partial observations, even for unseen shapes at test time. The performance improvements on standard benchmarks highlight these contributions.
