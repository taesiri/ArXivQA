# [GLoRe: When, Where, and How to Improve LLM Reasoning via Global and   Local Refinements](https://arxiv.org/abs/2402.10963)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- State-of-the-art large language models (LLMs) can struggle to refine their reasoning without external feedback, often unable to identify when and where to refine solutions.
- Existing outcome-based reward models (ORMs) are good at estimating final answer correctness but can be overly pessimistic at evaluating intermediate reasoning steps. This makes them unreliable for identifying where to refine. 
- Process-based reward models (PRMs) directly evaluate intermediate steps but require expensive human annotations.

Proposed Solution: 
- Decompose the refinement problem into 3 parts - deciding \textit{when}, \textit{where}, and \textit{how} to refine. 
- Use ORMs to decide when to refine by estimating final answer correctness.
- Propose Stepwise ORMs (SORMs) to better evaluate intermediate steps by approximating the optimal value function via rejection sampling. SORMs indicate where to refine.
- Train separate global and local refinement models on synthetic data to decide how to refine. Global models get the full question and draft solution as context. Local models also get the SORM critique indicating the first reasoning mistake. 

Main Contributions:
- Show ORMs can be overly pessimistic in evaluating intermediate reasoning steps, while SORMs are more accurate.
- Propose SORMs which better estimate intermediate step correctness for identifying where to refine. SORMs are trained purely on synthetic data.
- Find global and local refinements complement each other, each solving a distinct subset of problems. Reranking both using the ORM gives the best performance.  
- Demonstrate improvements of up to 12% in accuracy on math reasoning tasks by combining SORM critiques, global/local refinements, and ORM reranking.
