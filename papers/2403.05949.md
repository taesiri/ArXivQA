# [General surgery vision transformer: A video pre-trained foundation model   for general surgery](https://arxiv.org/abs/2403.05949)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Progress on foundation models for medicine has been slower than other areas due to the immense data required for training. Obtaining the large volumes of medical data needed is challenging.
- There is a lack of publicly accessible surgical data and pretrained models, hindering computational research in surgery.

Proposed Solution:
- Introduce General Surgery Vision Transformer (GSViT), a video pre-trained foundation model for general surgery based on forward video prediction that can run in real-time.
- Open-source the largest dataset of general surgery videos to date - 680 hours across 28 procedures from robotic and laparoscopic techniques.
- Release code and weights for GSViT as well as 10 procedure-specific fine-tuned versions.  

Methods:
- GSViT is lightweight and optimized for speed. Uses a sandwich transformer layout and cascaded group attention to reduce redundancy.
- Asymmetric decoder allows high-res image reconstruction from encoded representation. 
- Pre-train on video prediction of next frame rather than image reconstruction to learn spatial and temporal properties.

Results:
- Curated and open-sourced GenSurgery dataset from YouTube videos, with 70M frames across 28 procedures.
- GSViT runs in real-time, processing 10.6 images/ms, outperforming efficient architectures like EfficientNet and GLiT.
- Fine-tuned GSViT gets 86.3% accuracy on Cholec80 phase detection, comparable state-of-the-art but with 13x fewer parameters.

Main Contributions:
- Largest open dataset of general surgery videos 
- Real-time capable video pre-trained foundation model GSViT and code
- State-of-the-art efficiency for surgical phase detection
- Enabling future research through accessible data and models
