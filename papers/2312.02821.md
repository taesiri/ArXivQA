# [RotaTR: Detection Transformer for Dense and Rotated Object](https://arxiv.org/abs/2312.02821)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes RotaTR, an end-to-end rotated object detection transformer that extends DETR to handle oriented object detection tasks. The authors find that vanilla transformer-based detectors like DETR perform poorly on dense, rotated scenes compared to CNN-based methods. They identify that the core issue is that standard deformable attention cannot effectively align features or attention to arbitrarily oriented objects. To address this, RotaTR introduces a Rotation Sensitive Deformable (RSDeform) attention module that explicitly modulates the sampling locations based on the object's orientation and geometry to enable better feature alignment. Additionally, a point set loss is used for box regression to handle ambiguity. Experiments on aerial imagery datasets DOTA and HRSC2016 as well as scene text dataset MSRA-TD500 demonstrate that RotaTR achieves strong improvements over baseline DETR variants and is competitive with state-of-the-art rotated object detectors. The proposed RSDeform attention and point set loss are generally applicable components for oriented object detection. Overall, RotaTR effectively extends transformers to oriented object detection by improving their ability to capture arbitrary orientations.
