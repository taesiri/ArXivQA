# [Towards Robust Semantic Segmentation against Patch-based Attack via   Attention Refinement](https://arxiv.org/abs/2401.01750)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
The paper focuses on improving the robustness of semantic segmentation models against patch-based adversarial attacks. It analyzes the vulnerability of attention mechanisms in semantic segmentation models, which enable incorporating both local and global context but can also spread the influence of an adversarial patch to other image regions via the attention matrix. This makes semantic segmentation models with wider receptive fields more vulnerable to patch attacks.

Proposed Solution:  
The paper proposes a Robust Attention Mechanism (RAM) to limit the influence of a single adversarial patch on other image positions. RAM introduces two novel modules:

1) Max Attention Suppression (MAS): Limits the maximum value in the attention matrix to reduce the impact of the adversarial patch on other positions.

2) Random Attention Dropout (RAD): Randomly drops patches in the attention matrix during inference so the influence of a potential adversarial patch can be eliminated with some probability.

Together these modules refine the attention matrix to constrain the spread of an adversarial patch.

Main Contributions:
1) First work to analyze attention mechanisms in semantic segmentation models against patch attacks. 

2) Identify wider receptive fields make models more vulnerable, attribute it to attention spreading patch influence.

3) Propose RAM with MAS and RAD modules to limit patch influence by refining the attention matrix.

4) Extensive experiments show RAM reduces attack success rate by ~20% on average against 10 strong patch attack methods under varied settings. Works for both CNN & ViT based models.

In summary, the paper provides useful analysis on model vulnerabilities and an effective defense solution via a robust attention mechanism to improve semantic segmentation robustness.
