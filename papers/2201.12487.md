# [Counterfactual Plans under Distributional Ambiguity](https://arxiv.org/abs/2201.12487)

## What is the central research question or hypothesis that this paper addresses?

This paper studies the problem of generating counterfactual explanations with multiple possibilities (a counterfactual plan) under uncertainty in the prediction model's parameters. The key research questions it addresses are:1. How can we quantify the validity or robustness of a counterfactual plan when the model's parameters are uncertain? The paper proposes lower and upper bounds on the probability that a plan will remain valid under random future model parameters.2. How can we improve the validity of a pre-computed counterfactual plan? The paper provides two types of corrections - a Requirement correction to ensure the expected model parameters satisfy the plan, and an Improvement correction to directly increase the lower validity bound. 3. How can we construct a counterfactual plan that balances validity, proximity to the original input, and diversity, while taking model uncertainty into account? The paper proposes the COPA optimization framework to generate such plans.The overarching hypothesis is that explicitly accounting for uncertainty in the model's parameters when generating counterfactual plans will lead to more robust and useful plans compared to prior methods that assume fixed parameters. The bounds, corrections, and COPA framework are proposed to address this hypothesis.In summary, the paper makes contributions in quantifying, improving, and directly constructing counterfactual plans under model parameter uncertainty, which is important for reliability as models are updated over time. The proposed techniques help provide more robust recourse suggestions to individuals affected by algorithmic decisions.


## What is the main contribution of this paper?

The main contribution of the paper "Counterfactual Plans under Distributional Ambiguity" is developing methods for generating robust counterfactual explanations that remain valid even when the model's parameters change over time. Here are the key points:- Proposes a method to compute lower and upper bounds on the probability that a given counterfactual plan will remain valid under uncertain/ambiguous future model parameters. This allows assessing the robustness of a plan.- Provides two methods (Requirement and Improvement corrections) to adjust an existing counterfactual plan to improve its validity measure and make it more robust to distributional shifts in the model parameters. - Develops a framework called COPA (COunterfactual Plan under Ambiguity) to construct a counterfactual plan that explicitly accounts for uncertainty in the model parameters. It optimizes a weighted objective involving validity, proximity, and diversity of the plan.- The validity measure used in COPA is computationally efficient and avoids solving complex semidefinite programs. The overall plan optimization can be solved via gradient descent.- Provides experiments on synthetic and real-world datasets demonstrating that the proposed methods can improve robustness of counterfactual plans to distributional shifts compared to prior work.In summary, the main novelty is developing the ability to construct and evaluate counterfactual plans under uncertain model parameters, making the plans more robust and reliable for real applications where model updates are common. The validity bounds and plan corrections are the main technical contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a framework to generate counterfactual explanations that are robust to distributional shifts in the model's parameters, by modeling the uncertainty using only first and second moment information. The framework provides validity bounds for a counterfactual plan, methods to correct the plan to improve validity, and an optimization approach called COPA that constructs a plan balancing validity, proximity, and diversity under parameter ambiguity.


## How does this paper compare to other research in the same field?

This paper makes several novel contributions to the field of counterfactual explanations under model uncertainty:1. It proposes new methods to quantify the validity of counterfactual plans by computing lower and upper bounds on the probability that a plan will remain valid under future model updates. This is an important contribution as most prior work assumes model invariance. 2. It introduces two new approaches (Requirement and Improvement corrections) to adjust counterfactual plans to improve their validity measures. These provide concrete ways to make plans more robust to model shifts.3. It develops a new optimization framework called COPA to construct counterfactual plans that explicitly incorporate model uncertainty. COPA balances competing objectives of validity, proximity, and diversity.Compared to related work, this paper is unique in its focus on model uncertainty and shift. Prior work on counterfactual explanations either ignores model updates entirely [1-3] or only considers it in limited ways like fixed adversarial perturbations [4]. In contrast, this paper models uncertainty using distributional ambiguity sets and proposes tools to quantify, correct, and optimize counterfactual plans accordingly.The proposed validity bounds are novel diagnostics that do not exist in prior work. The correctness techniques also do not appear elsewhere. The COPA framework integrates model uncertainty directly into the optimization in a principled way, unlike prior heuristic approaches.Overall, this paper makes important theoretical and algorithmic contributions to counterfactual explanations under model shift. The proposed techniques provide practical ways to make plans more robust and reliable in real-world applications where models evolve over time.References:[1] Wachter et al. Counterfactual Explanations without Opening the Black Box. 2017.  [2] Mothilal et al. Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations. 2020.[3] Russell. Efficient Search for Diverse Coherent Explanations. 2019.  [4] Upadhyay et al. Towards Robust and Reliable Algorithmic Recourses. 2021.
