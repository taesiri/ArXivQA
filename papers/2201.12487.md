# [Counterfactual Plans under Distributional Ambiguity](https://arxiv.org/abs/2201.12487)

## What is the central research question or hypothesis that this paper addresses?

This paper studies the problem of generating counterfactual explanations with multiple possibilities (a counterfactual plan) under uncertainty in the prediction model's parameters. The key research questions it addresses are:1. How can we quantify the validity or robustness of a counterfactual plan when the model's parameters are uncertain? The paper proposes lower and upper bounds on the probability that a plan will remain valid under random future model parameters.2. How can we improve the validity of a pre-computed counterfactual plan? The paper provides two types of corrections - a Requirement correction to ensure the expected model parameters satisfy the plan, and an Improvement correction to directly increase the lower validity bound. 3. How can we construct a counterfactual plan that balances validity, proximity to the original input, and diversity, while taking model uncertainty into account? The paper proposes the COPA optimization framework to generate such plans.The overarching hypothesis is that explicitly accounting for uncertainty in the model's parameters when generating counterfactual plans will lead to more robust and useful plans compared to prior methods that assume fixed parameters. The bounds, corrections, and COPA framework are proposed to address this hypothesis.In summary, the paper makes contributions in quantifying, improving, and directly constructing counterfactual plans under model parameter uncertainty, which is important for reliability as models are updated over time. The proposed techniques help provide more robust recourse suggestions to individuals affected by algorithmic decisions.


## What is the main contribution of this paper?

The main contribution of the paper "Counterfactual Plans under Distributional Ambiguity" is developing methods for generating robust counterfactual explanations that remain valid even when the model's parameters change over time. Here are the key points:- Proposes a method to compute lower and upper bounds on the probability that a given counterfactual plan will remain valid under uncertain/ambiguous future model parameters. This allows assessing the robustness of a plan.- Provides two methods (Requirement and Improvement corrections) to adjust an existing counterfactual plan to improve its validity measure and make it more robust to distributional shifts in the model parameters. - Develops a framework called COPA (COunterfactual Plan under Ambiguity) to construct a counterfactual plan that explicitly accounts for uncertainty in the model parameters. It optimizes a weighted objective involving validity, proximity, and diversity of the plan.- The validity measure used in COPA is computationally efficient and avoids solving complex semidefinite programs. The overall plan optimization can be solved via gradient descent.- Provides experiments on synthetic and real-world datasets demonstrating that the proposed methods can improve robustness of counterfactual plans to distributional shifts compared to prior work.In summary, the main novelty is developing the ability to construct and evaluate counterfactual plans under uncertain model parameters, making the plans more robust and reliable for real applications where model updates are common. The validity bounds and plan corrections are the main technical contributions.
