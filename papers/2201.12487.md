# [Counterfactual Plans under Distributional Ambiguity](https://arxiv.org/abs/2201.12487)

## What is the central research question or hypothesis that this paper addresses?

This paper studies the problem of generating counterfactual explanations with multiple possibilities (a counterfactual plan) under uncertainty in the prediction model's parameters. The key research questions it addresses are:1. How can we quantify the validity or robustness of a counterfactual plan when the model's parameters are uncertain? The paper proposes lower and upper bounds on the probability that a plan will remain valid under random future model parameters.2. How can we improve the validity of a pre-computed counterfactual plan? The paper provides two types of corrections - a Requirement correction to ensure the expected model parameters satisfy the plan, and an Improvement correction to directly increase the lower validity bound. 3. How can we construct a counterfactual plan that balances validity, proximity to the original input, and diversity, while taking model uncertainty into account? The paper proposes the COPA optimization framework to generate such plans.The overarching hypothesis is that explicitly accounting for uncertainty in the model's parameters when generating counterfactual plans will lead to more robust and useful plans compared to prior methods that assume fixed parameters. The bounds, corrections, and COPA framework are proposed to address this hypothesis.In summary, the paper makes contributions in quantifying, improving, and directly constructing counterfactual plans under model parameter uncertainty, which is important for reliability as models are updated over time. The proposed techniques help provide more robust recourse suggestions to individuals affected by algorithmic decisions.


## What is the main contribution of this paper?

The main contribution of the paper "Counterfactual Plans under Distributional Ambiguity" is developing methods for generating robust counterfactual explanations that remain valid even when the model's parameters change over time. Here are the key points:- Proposes a method to compute lower and upper bounds on the probability that a given counterfactual plan will remain valid under uncertain/ambiguous future model parameters. This allows assessing the robustness of a plan.- Provides two methods (Requirement and Improvement corrections) to adjust an existing counterfactual plan to improve its validity measure and make it more robust to distributional shifts in the model parameters. - Develops a framework called COPA (COunterfactual Plan under Ambiguity) to construct a counterfactual plan that explicitly accounts for uncertainty in the model parameters. It optimizes a weighted objective involving validity, proximity, and diversity of the plan.- The validity measure used in COPA is computationally efficient and avoids solving complex semidefinite programs. The overall plan optimization can be solved via gradient descent.- Provides experiments on synthetic and real-world datasets demonstrating that the proposed methods can improve robustness of counterfactual plans to distributional shifts compared to prior work.In summary, the main novelty is developing the ability to construct and evaluate counterfactual plans under uncertain model parameters, making the plans more robust and reliable for real applications where model updates are common. The validity bounds and plan corrections are the main technical contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a framework to generate counterfactual explanations that are robust to distributional shifts in the model's parameters, by modeling the uncertainty using only first and second moment information. The framework provides validity bounds for a counterfactual plan, methods to correct the plan to improve validity, and an optimization approach called COPA that constructs a plan balancing validity, proximity, and diversity under parameter ambiguity.


## How does this paper compare to other research in the same field?

This paper makes several novel contributions to the field of counterfactual explanations under model uncertainty:1. It proposes new methods to quantify the validity of counterfactual plans by computing lower and upper bounds on the probability that a plan will remain valid under future model updates. This is an important contribution as most prior work assumes model invariance. 2. It introduces two new approaches (Requirement and Improvement corrections) to adjust counterfactual plans to improve their validity measures. These provide concrete ways to make plans more robust to model shifts.3. It develops a new optimization framework called COPA to construct counterfactual plans that explicitly incorporate model uncertainty. COPA balances competing objectives of validity, proximity, and diversity.Compared to related work, this paper is unique in its focus on model uncertainty and shift. Prior work on counterfactual explanations either ignores model updates entirely [1-3] or only considers it in limited ways like fixed adversarial perturbations [4]. In contrast, this paper models uncertainty using distributional ambiguity sets and proposes tools to quantify, correct, and optimize counterfactual plans accordingly.The proposed validity bounds are novel diagnostics that do not exist in prior work. The correctness techniques also do not appear elsewhere. The COPA framework integrates model uncertainty directly into the optimization in a principled way, unlike prior heuristic approaches.Overall, this paper makes important theoretical and algorithmic contributions to counterfactual explanations under model shift. The proposed techniques provide practical ways to make plans more robust and reliable in real-world applications where models evolve over time.References:[1] Wachter et al. Counterfactual Explanations without Opening the Black Box. 2017.  [2] Mothilal et al. Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations. 2020.[3] Russell. Efficient Search for Diverse Coherent Explanations. 2019.  [4] Upadhyay et al. Towards Robust and Reliable Algorithmic Recourses. 2021.


## What future research directions do the authors suggest?

The paper "Counterfactual Explanations under Model Uncertainty" suggests several potential directions for future research:1. Extending the analysis and methods to non-linear models. The paper focuses on linear classification settings. Developing techniques for non-linear models like neural networks would be an important next step.2. Incorporating additional types of model uncertainty beyond distributional uncertainty over the parameters. For example, the model class itself could be uncertain (e.g. linear vs. non-linear models). 3. Considering other notions of proximity for counterfactuals besides Euclidean distance. Different proximity measures may better capture feasibility or preference in some applications.4. Developing methods that provide certificates of robustness for counterfactual explanations, i.e. formally proving that an explanation satisfies certain validity guarantees across a precisely defined set of models.5. Conducting user studies to better understand how different notions of explanation validity are perceived by humans and impact trust and satisfaction. 6. Developing interactive or incremental approaches to counterfactual explanation that incorporate human feedback.7. Scaling up counterfactual explanation methods to handle high-dimensional, complex data like images, video and text.In summary, extending the robustness analysis to more complex ML models, integrating different forms of uncertainty, using more sophisticated proximity measures, providing robustness certificates, and conducting human-centered evaluations are highlighted as promising directions for future work.


## Summarize the paper in one paragraph.

Here is a one paragraph summary of the key points from the paper:The paper proposes a method for generating robust counterfactual explanations that remain valid even when the model is updated over time. It models uncertainty over the model parameters using only first and second moment information. The method provides upper and lower bounds on the probability that a counterfactual plan will remain valid under this distributional uncertainty. It also proposes techniques to correct an existing plan to improve its validity bounds, with minimal changes to the individual counterfactuals. Finally, it introduces a COPA framework to construct a counterfactual plan by directly optimizing for proximity, diversity, and validity under the model uncertainty. Experiments on synthetic and real-world datasets demonstrate the proposed techniques can improve validity and robustness compared to prior counterfactual explanation methods. Overall, the paper provides useful tools for quantifying, improving, and directly optimizing the robustness of counterfactual plans to distribution shifts in the model parameters.


## Summarize the paper in two paragraphs.

Here is a two paragraph summary of the key points from the paper:The paper proposes a framework for generating counterfactual explanations that are robust to distributional shift in the model parameters. The key idea is to construct a counterfactual plan, consisting of multiple counterfactual examples, that balances competing objectives of proximity, diversity, and validity under model uncertainty. To achieve this, the authors first develop tools to quantify the validity of a counterfactual plan by computing bounds on the probability that the plan remains feasible for future model parameters. Building on these insights, they then propose methods to correct an existing plan to improve its validity. Finally, they formulate an optimization problem called COPA that constructs a robust counterfactual plan by directly incorporating the uncertainty in model parameters. COPA minimizes a weighted combination of proximity, diversity, and validity terms. The authors demonstrate empirically that plans produced by COPA are more robust to distribution shift compared to prior methods.In summary, the key contributions are: 1) validity bounds under model uncertainty, 2) plan correction methods, and 3) the COPA formulation that constructs robust plans by design. Experiments on synthetic and real-world data highlight the advantages of the proposed techniques.


## Summarize the main method used in the paper in one paragraph.

Here is a one paragraph summary of the main method used in the paper "Counterfactual Explanations under Distributional Shift":The paper studies the problem of generating counterfactual explanations that are robust to distributional shifts in the model parameters. It proposes bounding the probability that a counterfactual plan remains valid under uncertain future model parameters using only first and second moment information about the parameter distribution. The lower and upper bounds on validity probability are obtained by solving semidefinite programs leveraging multivariate Chebyshev inequality. To increase validity, the paper provides two methods to correct an existing counterfactual plan: a Requirement correction to ensure the expected parameter lies in the favorable region, and a Mahalanobis Improvement correction to maximize distance from the expected parameter to invalidity hyperplanes. Based on the validity measure, the paper also proposes a COPA framework to construct a counterfactual plan by optimizing a weighted combination of proximity, diversity, and validity terms using a projected gradient descent algorithm.
