# [Masked Motion Predictors are Strong 3D Action Representation Learners](https://arxiv.org/abs/2308.07092)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we better explore the contextual motion clue in self-supervised 3D action representation learning? The key points are:- The paper argues that the prevalent pre-training objective of masked self-reconstruction of human joints is insufficient for learning effective 3D action representations. It does not provide explicit constraints to model the contextual motion patterns, which are crucial for understanding human actions from skeleton sequences.- To address this, the paper proposes a new pre-training framework called Masked Motion Prediction (MAMP). Instead of reconstructing the masked joints, MAMP predicts the temporal motion of the masked regions based on the unmasked context. This provides direct supervision for learning motion patterns.- The paper also incorporates motion intensity to guide the joint masking process, so that regions with significant motion are more likely to be masked. This focuses learning on semantically meaningful motions.- Experiments show MAMP significantly outperforms previous methods like SkeletonMAE on action recognition benchmarks. The framework unleashes the potential of transformers for modeling temporal evolution of actions under limited supervision.In summary, the key hypothesis is that predicting masked motion is more effective than reconstructing masked joints for pre-training on 3D skeleton sequences, as it provides better supervision for learning contextual motion patterns crucial for action understanding.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:- It proposes the Masked Motion Prediction (MAMP) framework for 3D action representation learning. Unlike previous works that use masked self-reconstruction of joints, MAMP uses masked prediction of joint motions as the pretext task. This better directs the model to focus on contextual motion modeling which is crucial for 3D action understanding.- It incorporates motion intensity as an empirical semantic richness prior to guide the masking process. By masking joints with higher motion intensity more frequently, the model pays more attention to temporally informative regions. - Extensive experiments show MAMP significantly improves the performance of vanilla transformers on three datasets under various evaluation protocols. Without bells and whistles, it achieves state-of-the-art results, demonstrating the effectiveness of the proposed approach.In summary, the key contribution is presenting masked motion prediction for self-supervised 3D action representation learning. By directing the model to explicitly predict joint motions from masked input, MAMP effectively captures the contextual motion patterns critical for 3D action recognition. The proposed framework substantially boosts transformer-based models and achieves new state-of-the-art performance.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes Masked Motion Predictors (MAMP), a framework for self-supervised learning of 3D action representations by predicting the motion of masked joints in skeleton sequences, which outperforms previous methods like masked self-reconstruction and achieves state-of-the-art results on action recognition benchmarks.
