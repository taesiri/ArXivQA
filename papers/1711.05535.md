# [Dual-Path Convolutional Image-Text Embeddings with Instance Loss](https://arxiv.org/abs/1711.05535)

## Design 10 in-depth questions about method proposed in this paper and avoid simple question.

 Here are 10 potential in-depth questions about the method proposed in the paper:

1. The paper proposes an "instance loss" for image-text matching. Can you explain in more detail the motivation and formulation of the instance loss? How is it different from a standard classification loss?

2. The instance loss treats each image/text group as a distinct class. What is the reasoning behind this and what advantage does it provide over directly using a ranking loss?

3. The paper utilizes a two-stage training procedure. What is the motivation for separating the training into two stages? How do the losses used in each stage differ and why?

4. The paper proposes end-to-end fine-tuning of both the image and text branches using deep convolutional networks. How does this differ from prior works and what advantage does end-to-end learning provide?

5. What modifications were made to the text CNN architecture compared to a standard image CNN? Why were these changes made?

6. The paper explores using word2vec initialization for the text CNN. How was this implemented and what improvements did it provide over random initialization?

7. Position shift is proposed as a data augmentation method for the text CNN. Can you explain this technique and why it is useful?

8. How is the proposed instance loss complementary to the ranking loss when used together in stage 2 training? What does each loss provide?

9. The paper shows significant gains from fine-tuning on the CUHK-PEDES dataset. Why does fine-tuning have a bigger impact for this type of data?

10. What analysis is provided to show that the text CNN learns discriminative words? How could this analysis be expanded or improved?
