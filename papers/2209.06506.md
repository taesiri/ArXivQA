# [Order-Disorder: Imitation Adversarial Attacks for Black-box Neural   Ranking Models](https://arxiv.org/abs/2209.06506)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is: how to conduct adversarial attacks against black-box neural text ranking models? Specifically, the authors propose a novel imitation adversarial attack method against black-box neural ranking models. The key ideas include:1) Training a ranking imitation model to transparentize the target black-box ranking model, by sampling ranking results and training a pairwise BERT model.2) Proposing a Pairwise Anchor-based Trigger (PAT) generation method that utilizes the ranking imitation model's pairwise loss and ranking information to craft adversarial triggers. 3) Employing fluency and semantic consistency constraints during trigger generation to equip the triggers with camouflage. 4) Demonstrating the attack effectiveness and transferability of the triggers from the imitation model to the target victim models.The main hypothesis is that by training a similar ranking imitation model and generating camouflaged triggers based on it, the attack can transfer to black-box neural ranking models effectively. The experiments on passage ranking datasets validate the effectiveness of the proposed attack method.In summary, the paper focuses on investigating a novel imitation-based adversarial attack against black-box text ranking models, which remains underexplored in prior studies. The proposed attack method and extensive evaluations reveal vulnerabilities of neural ranking models.


## What is the main contribution of this paper?

The main contributions of this paper are:1. It proposes a novel imitation adversarial attack method against black-box neural text ranking models. This is the first work to investigate transfer-based attacks on neural text ranking models in a black-box setting.2. It introduces a ranking imitation model that can transparentize the victim black-box ranker via effective pairwise learning, without needing access to the model internals or training data. 3. It proposes a Pairwise Anchor-based Trigger (PAT) generation method that leverages pairwise loss and anchor candidates to craft adversarial triggers with camouflages.4. It conducts extensive experiments on multiple datasets and models to demonstrate the effectiveness of the proposed attack method. The adversarial triggers can successfully manipulate the rankings and transfer across different victim models.5. It provides comprehensive analyses on the attack performance, transferability, imperceptibility, and potential defenses. This sheds light on the vulnerabilities of neural ranking models and motivates further research into this novel security problem.In summary, this is the first work to study imitation adversarial attacks against black-box neural ranking models, proposing innovative methods for transparentizing and attacking the victim model. The findings reveal risks of ranking manipulation and aim to motivate more robust ranking models.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the paper:The paper proposes a novel black-box adversarial attack method against neural text ranking systems by training a ranking imitation model to transparentize the target model and generate camouflaged adversarial triggers that can manipulate the ranking results.


## How does this paper compare to other research in the same field?

This paper presents some interesting new research on adversarial attacks against neural text ranking models. Here is a comparison to related prior work in this field:- Focus on black-box attacks: Most prior work has focused on white-box attacks where the adversary has full knowledge and access to the target model. This paper proposes a new approach for black-box attacks where the adversary has limited knowledge about the target model.- Ranking model imitation: A key contribution is using a ranking model imitation approach to approximate the target black-box model for generating attacks. They train an imitation model using relative ranking judgments sampled from the target model's output. - Novel pairwise loss attack: They propose a new pairwise anchor-based trigger generation method that leverages relative ranking information. This is tailored for attacks on ranking models compared to prior work on classification.- Emphasis on stealthiness: Their method adds fluency and semantic consistency constraints to generate more stealthy and imperceptible triggers compared to prior attacks like collisions.- Experiments on multiple datasets: They test their approach on 3 datasets of different domains (MS MARCO, TREC DL, Natural Questions), showing wide applicability.- Analysis of defenses: The paper analyzes potential defenses like perplexity filtering and shows limitations, providing insights into future work on defending against such attacks.Overall, this paper makes solid contributions over prior work by focusing on more realistic black-box attacks on ranking, proposing a novel attack method using ranking imitation and pairwise loss, and extensive experiments demonstrating effectiveness. The analysis of stealthiness and defenses also offers useful insights into this emerging research area.
