# [Unsupervised Compositional Concepts Discovery with Text-to-Image   Generative Models](https://arxiv.org/abs/2306.05357)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:Can we develop an unsupervised approach to discover the generative concepts that represent the content of a collection of images?The key hypothesis is that by leveraging large pre-trained text-to-image generative models like diffusion models, the authors can decompose images into meaningful compositional concepts without any supervision or labels. Specifically, the paper investigates decomposing images into probability distributions that capture global scene attributes like lighting as well as local concepts like objects. The goal is to show that these discovered concepts can accurately represent image content, be recombined to generate new images, and serve as effective representations for tasks like classification.In summary, the central research question is about unsupervised discovery of visual concepts from images using text-to-image models, with the hypothesis that this will enable representing, recombining, and reasoning about visual content.
