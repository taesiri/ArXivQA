# [HomeRobot: Open-Vocabulary Mobile Manipulation](https://arxiv.org/abs/2306.11565)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we develop a benchmark for open-vocabulary mobile manipulation that enables progress on real-world robot assistants?The paper introduces the "Open-Vocabulary Mobile Manipulation" (OVMM) task, where a robot must navigate real-world environments to find novel objects based on natural language descriptions and move them to target locations. The key contributions aimed at addressing this research question appear to be:1) Defining the OVMM task, which requires integrating solutions across perception, language understanding, navigation and manipulation.2) Developing a simulation benchmark with diverse 3D home environments and a large set of objects.3) Implementing a real-world benchmark using an affordable compliant robot (Hello Robot Stretch).4) Providing baselines using both heuristic and reinforcement learning approaches to highlight the challenges of OVMM. 5) Open-sourcing the HomeRobot software framework to facilitate OVMM research across both simulation and real-world settings.Overall, the central hypothesis seems to be that by formalizing OVMM and providing benchmarking infrastructure, the field can make progress on real-world robot assistants capable of mobile manipulation in human environments. The paper aims to make the case for OVMM as a crucial next benchmark, while also highlighting the limitations of current methods.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions appear to be:- Defining the task of open-vocabulary mobile manipulation (OVMM) as a key challenge for developing useful home assistant robots. OVMM requires integrating solutions across subfields like perception, navigation, manipulation, and language understanding.- Introducing a new simulation benchmark for OVMM based on a dataset of 200 interactive 3D home environments. The benchmark uses a diverse set of objects, with a mix of seen and unseen categories and instances.- Implementing a real-world OVMM benchmark using the affordable Stretch mobile manipulator robot in a controlled apartment setting. The real-world benchmark also uses seen and unseen objects.- Developing the HomeRobot software framework to facilitate OVMM research in both simulation and the real world. HomeRobot provides unified APIs, baseline agents, modularity, and sim-to-real transferability.- Providing baseline heuristic and reinforcement learning agents for OVMM using HomeRobot. The agents combine object detection, exploration, grasping, and placement skills.- Demonstrating promising simulation and real-world results for the baseline agents, while also identifying areas for improvement in perception, long-horizon planning, and sim-to-real transfer.In summary, the main contribution appears to be proposing OVMM as an important robotics challenge, along with benchmarks, infrastructure, and baseline agents to drive progress on this task. The work aims to advance research towards useful home assistant robots.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence TL;DR summary of the paper:The paper introduces the Open-Vocabulary Mobile Manipulation (OVMM) benchmark and HomeRobot software framework to facilitate research in mobile manipulation, with both simulated and real-world tasks involving searching for and manipulating previously unseen objects in home environments.
