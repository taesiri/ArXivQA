# [Attention, Compilation, and Solver-based Symbolic Analysis are All You   Need](https://arxiv.org/abs/2306.06755)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is:How can we improve the accuracy and correctness of large language model (LLM) based code translation by incorporating compiler feedback and symbolic execution based testing? The key ideas and contributions of the paper are:- Proposes a new LLM-based code translation method called CoTran that uses cross-entropy loss, compiler feedback loss, and symbolic execution feedback loss during training. - Introduces a new dataset called AVATAR-TC with over 57,000 equivalent Java-Python code pairs that are verified to be input-output equivalent using test cases.- Defines new evaluation metrics like compilation accuracy, runtime equivalence accuracy, and first error position that are more relevant for code translation compared to existing metrics like BLEU score.- Shows through experiments that CoTran outperforms state-of-the-art methods and even human-written transpilers on the new metrics, demonstrating the value of compiler and symbolic execution feedback.So in summary, the central hypothesis is that integrating compiler and symbolic execution losses with LLM training can significantly improve the correctness and accuracy of neural code translation models. The results on the AVATAR-TC benchmark support this hypothesis.


## What is the main contribution of this paper?

The main contributions of this paper are:- It proposes a new code translation method based on large language models (LLMs) that uses three kinds of loss functions - cross-entropy, compiler feedback, and symbolic execution feedback - to improve the accuracy, correctness, and efficacy of code translation. - It introduces a new dataset called AVATAR-TC with over 57,000 equivalent Java and Python code pairs that are verified to be input-output equivalent using test cases.- It defines new metrics like compilation accuracy, runtime equivalence accuracy, and first compilation error position that are more relevant for evaluating code translation than existing metrics like BLEU score.- It conducts extensive experiments comparing the proposed method and tool CoTran against 10 other transpilers and LLM-based translation tools. The results show CoTran outperforms them significantly on the new metrics like compilation and runtime equivalence accuracy.- The key novelty is the use of compiler and symbolic execution losses during LLM training to guide the model to generate compilable and equivalent output code. This along with the back-translation training approach leads to state-of-the-art performance.In summary, the main contribution is a new training methodology for LLMs using compiler and symbolic execution feedback to achieve highly accurate and equivalent code translation between programming languages. The experiments validate the efficacy of this approach over existing techniques.
