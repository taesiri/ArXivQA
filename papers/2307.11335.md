# [Tri-MipRF: Tri-Mip Representation for Efficient Anti-Aliasing Neural   Radiance Fields](https://arxiv.org/abs/2307.11335)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question is: How can we design an efficient neural radiance field representation that supports high-quality anti-aliased rendering?The key points are:- Neural radiance fields (NeRFs) can produce high-quality novel view synthesis, but suffer from slow training and rendering. - Recent works accelerate NeRF training and rendering via explicit representations like hash tables, but they ignore pixel footprint/sampling area, causing aliasing artifacts.- Naively super-sampling to reduce aliasing significantly increases computation cost.- Integrating anti-aliasing strategies like pre-filtering with accelerated representations like hash tables is non-trivial.- The paper proposes a novel "Tri-Mip" encoding to enable both fast training/rendering and high-quality anti-aliased rendering by modeling a pre-filtered feature space with 2D mipmaps.So in summary, the central hypothesis is that a "Tri-Mip" encoding can achieve the best of both worlds - fast training/rendering like recent accelerated NeRFs, and high anti-aliased quality like MipNeRF. The experiments aim to validate this hypothesis.


## What is the main contribution of this paper?

Based on my reading, the main contributions of this paper seem to be:1. Proposing a novel Tri-Mip encoding (Ã  la "mipmap") that represents the 3D scene features using three 2D mipmaps corresponding to three orthogonal planes (XY, XZ, YZ). This allows modeling pre-filtered 3D features efficiently using 2D mipmaps.2. A new cone-casting rendering technique that emits a cone per pixel and samples the cone using spheres. The sphere radius and center location are used to lookup pre-filtered features from the Tri-Mip encoding, enabling anti-aliased rendering. 3. The proposed method achieves state-of-the-art rendering quality while being very fast to train (within 5 minutes). It also has a compact model size, 25% smaller than Instant-ngp.4. A hybrid volume-surface rendering technique is proposed to enable real-time rendering (>60 FPS) on consumer GPUs.In summary, the key ideas are using a Tri-Mip encoding to model pre-filtered 3D features for anti-aliasing, cone-casting rendering adapted to this representation, and techniques to achieve fast training, compact model size, and real-time rendering. The method achieves improved rendering quality and speed compared to prior NeRF methods.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key point from this paper: This paper proposes a novel Tri-Mip radiance fields representation (Tri-MipRF) that efficiently models the pre-filtered 3D feature space through orthogonal mipmaps to enable anti-aliased and high-fidelity novel view synthesis at both fast training and rendering speeds.
