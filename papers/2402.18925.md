# [PCDepth: Pattern-based Complementary Learning for Monocular Depth   Estimation by Best of Both Worlds](https://arxiv.org/abs/2402.18925)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing methods for monocular depth estimation (MDE) using events and images fuse the two modalities at the pixel level. However, the complementarity between events and images mainly impacts high-level patterns (e.g. object contours) which only occupy a small percentage of pixels. Fusing at the pixel level fails to fully exploit such pattern-level complementarity. 

Proposed Solution:
This paper proposes a Pattern-based Complementary learning architecture for monocular Depth estimation (PCDepth). The key ideas are:

1) Discretize the scenes from events and images into visual tokens using transposed attention, representing high-level patterns like objects and contours. 

2) Integrate the complementary patterns from the two modalities through a score-based fusion module, which balances the contributions of events and images based on illumination conditions.

3) Reconstruct the scene from the fused visual tokens and refine the depth prediction using GRUs, while maintaining efficiency by limiting cross-attention to a single scale.

Main Contributions:

1) Proposing a pattern-level fusion framework to explore the complementarity between events and images, unlike mainstream pixel-level fusion.

2) The PCDepth architecture with two main components: complementary visual representation learning module, and a refined depth estimator.

3) Achieving state-of-the-art performance on MVSEC and DSEC datasets. Significant 37.9% improvement in accuracy for MVSEC nighttime scenes by fully exploiting pattern-level complementarity.

In summary, this paper explores pattern-based complementary learning of events and images to address limitations of mainstream pixel-level fusion approaches for MDE. The proposed PCDepth architecture achieves more accurate depth estimation.
