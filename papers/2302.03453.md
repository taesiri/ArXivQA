# [OSRT: Omnidirectional Image Super-Resolution with Distortion-aware   Transformer](https://arxiv.org/abs/2302.03453)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question appears to be: 

How can we develop an effective super-resolution method for omnidirectional images (ODIs) that properly accounts for the unique geometric distortions present in these images?

The key points related to this question seem to be:

- Previous ODI super-resolution (ODISR) methods do not properly account for the distortion effects when downsampling ODIs from the original fisheye projection to the equirectangular projection (ERP). This results in unrealistic training data.

- The authors propose a new downsampling method called "Fisheye downsampling" that applies downsampling directly on the original fisheye images to better mimic real world effects.

- They design a "Distortion-aware Transformer" (OSRT) that continuously modulates the distortions in ERP images using deformable attention and convolution blocks. This allows the model to adapt to distortions in a self-supervised manner.

- They augment the limited ODI training data by generating pseudo ERP images from regular 2D images. This helps address overfitting to the small training set.

In summary, the central hypothesis is that accounting for fisheye distortion effects and using a distortion-aware model architecture will improve ODISR performance compared to prior methods. The key contribution is the proposed Fisheye downsampling method and OSRT model.
