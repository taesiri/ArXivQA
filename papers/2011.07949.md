# [RSPNet: Relative Speed Perception for Unsupervised Video Representation   Learning](https://arxiv.org/abs/2011.07949)

## What is the central research question or hypothesis that this paper addresses?

Based on my understanding, the central research question this paper tries to address is:How can we learn effective video representations in an unsupervised manner, especially learning useful features for both motion and appearance?The key points are:- Unsupervised video representation learning is very challenging due to the complex spatio-temporal information in videos and lack of labeled data. - Existing methods using playback speed perception as pretext task suffer from imprecise speed labels. Also they do not explicitly encourage learning appearance features.- This paper proposes to use relative speed perception as pretext task which can provide more consistent supervision. - It also extends instance discrimination from images to videos and uses speed augmentation so the model focuses more on appearance. - By combining the two pretext tasks, the model can learn useful features for both motion and appearance in an unsupervised manner.- Experiments show the learned features achieve excellent performance on downstream action recognition and video retrieval without using any manually annotated data.In summary, the main research question is how to do unsupervised video representation learning, especially learning features for both motion and appearance. The key ideas are exploiting relative speed and extending instance discrimination with speed augmentation.
