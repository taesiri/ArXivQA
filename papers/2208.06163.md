# [Dropout is NOT All You Need to Prevent Gradient Leakage](https://arxiv.org/abs/2208.06163)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be whether dropout can reliably protect against gradient leakage and reconstruction of private training data via iterative gradient inversion attacks in federated learning. The central hypothesis appears to be that while dropout may seem to provide protection by introducing stochasticity during training, it does not reliably prevent reconstruction of private data if the attacker can approximate the specific realization of the stochastic client model.In particular, the authors hypothesize that an attacker could jointly optimize the reconstructed data and dropout masks applied during training to approximate the client's model realization. This proposed "Dropout Inversion Attack" could bypass the protection seemingly offered by dropout.The paper then conducts a systematic evaluation to test this hypothesis and demonstrate that the proposed attack can successfully reconstruct private training data even when dropout is used, across various model architectures and datasets.In summary, the central question is whether dropout alone is sufficient to prevent gradient leakage, and the hypothesis is that it is not if the attacker can approximate the stochastic client model realization. The Dropout Inversion Attack is proposed and evaluated to test this.
