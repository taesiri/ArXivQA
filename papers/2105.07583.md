# [ItôTTS and ItôWave: Linear Stochastic Differential Equation Is All   You Need For Audio Generation](https://arxiv.org/abs/2105.07583)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is:Can a unified framework based on linear stochastic differential equations (SDEs) be used to model both text-to-speech (TTS) synthesis and vocoding for high-quality audio generation? The key hypotheses appear to be:1) A pair of forward and reverse time linear SDEs can model the transformation of mel spectrogram or waveform distributions into simpler tractable distributions and back. 2) The gradients of the log probability densities of these distributions, known as "scores", can be approximated with neural networks.3) Using these estimated scores to drive reverse time SDEs or Langevin dynamics allows sampling from the true mel spectrogram or waveform distributions.4) This unified SDE framework can achieve state-of-the-art performance on both TTS (predicting mel spectrograms from text) and vocoding (predicting waveforms from mel spectrograms).So in summary, the central research question is whether linear SDEs can provide a unified high-quality generative model for both major components of speech synthesis by modeling distribution transformations and using estimated scores. The key hypotheses relate to the viability of this SDE approach for both TTS and vocoding.


## What is the main contribution of this paper?

This paper proposes two neural network models, ItôTTS and ItôWave, for text-to-speech synthesis and vocoding based on linear stochastic differential equations (SDEs). Here are the main contributions:- The authors propose to unify text-to-speech and vocoding into a single framework based on forward and reverse-time linear SDEs. The forward SDE transforms the mel spectrogram/waveform distribution into a simple tractable distribution. The reverse SDE generates the target from the simple distribution.- ItôTTS and ItôWave use the Wiener process as a driver to gradually subtract excess signal from noise to generate realistic mel spectrograms and audio under text and mel spectrogram conditions.- The authors propose network architectures suitable for predicting the scores (gradients of log densities) needed for the reverse SDE sampling. ItôTTS uses an encoder-decoder structure. ItôWave uses a network with dilated residual blocks. - Experiments show ItôTTS and ItôWave exceed current state-of-the-art methods in quality, with mean opinion scores of 3.925 and 4.35 respectively.- The main contribution is providing a unified SDE framework for high-quality text-to-speech and vocoding, with flexible network architectures tailored for audio generation. The results and code provide a strong baseline for future SDE-based audio work.In summary, the key innovation is the use of paired forward and reverse-time linear SDEs to transform distributions for high-quality and flexible audio generation under a unified framework.
