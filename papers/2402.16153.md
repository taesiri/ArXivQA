# [ChatMusician: Understanding and Generating Music Intrinsically with LLM](https://arxiv.org/abs/2402.16153)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Large language models (LLMs) have shown impressive capabilities in text generation, but their ability to understand and generate music remains limited. Challenges include representing the long-term dependencies and intricacies of musical structure compatible for LLMs.

Proposed Solution: 
- Introduce ChatMusician, an open-source LLM that integrates intrinsic musical abilities based on continual pre-training and finetuning LLaMA on a text-compatible music representation (ABC notation) without any external neural structures. Music is treated as a second language.

- Curate MusicPile, a 4B token music-language corpus sourced from diverse domains like chats, instructions, music scores. Also introduce MusicTheoryBench, an inaugural college-level benchmark for assessing music understanding.

Key Contributions:
- ChatMusician unified music understanding and generation abilities while maintaining language performance, even slightly enhancing on MMLU. 

- Surpassed GPT-4 baseline in composing coherent, structured music conditioned on various musical elements. Human evaluation showed listeners preferred ChatMusician over GPT-4 and GPT-3.5.

- On MusicTheoryBench, ChatMusician exceeded LLaMA and GPT-3.5 substantially in zero-shot music knowledge and reasoning. But overall performance remains limited, exposing the untapped potential in symbolic music domain.

- Open-sourced complete framework including benchmark suite, model, codes and MusicPile corpus to facilitate research. Revealed text-compatible symbolic music as compelling area for future LLMs to aim towards human-level musical prowess.
