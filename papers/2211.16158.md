# [Out-Of-Distribution Detection Is Not All You Need](https://arxiv.org/abs/2211.16158)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be: Is out-of-distribution (OOD) detection a suitable evaluation framework for designing efficient runtime monitors for neural networks?The key points are:- The paper argues that the goal of a runtime monitor should be to detect errors made by the neural network model (out-of-model-scope or OMS detection), not just detect inputs that are different from the training data (OOD detection). - The definition of OOD is ambiguous, while OMS is well-defined based on the errors made by the model.- OOD and OMS detection can differ in two ways: 1) model generalization, where OOD data is correctly classified, and 2) in-distribution errors, where OOD data is incorrectly classified.- Experiments show OOD results can be misleading - a perfect OOD detector still misses many model errors, and the best OOD monitor is not always the best for OMS.- The paper recommends removing misclassified training data before fitting monitors to improve OMS detection.In summary, the main research question is whether OOD detection is a good proxy task for the actual goal of runtime monitoring, which is detecting model errors (OMS detection). The paper argues the answer is no, and that monitors should be evaluated directly on OMS detection.
