# [Abstraction via exemplars? A representational case study on lexical   category inference in BERT](https://arxiv.org/abs/2312.03708)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- There is a debate between "abstractionist" and "exemplar" accounts of how humans acquire linguistic categories and generalize to novel expressions. Abstractionists argue we form abstract rules, while exemplar theories posit we generalize based on stored instances.

- Neural language models like BERT have unprecedented success in language tasks, even though they differ from both accounts - they store a summarized form of training exemplars guided by their training objective. Can their success be viewed through the lens of "abstraction via exemplars"?

Method:
- The paper adapts experiments from Kim & Schutze (2021) testing if BERT can infer lexical categories (noun, verb, etc) for novel tokens from a single exemplar exposure.

- They track the movement of novel token embeddings during training and test performance when novel tokens are initialized to be close to regions populated by known category exemplars.

Results: 
- Novel token embeddings move closer to regions of known category exemplars after training.

- When novel tokens are initialized closer to exemplar regions, BERT shows strong generalization performance to new inputs without any training.

Conclusion:
- The analyses provide evidence that representational movement towards exemplar regions enables abstraction-like generalization in BERT. 

- This supports the view that abstraction can emerge in systems that encode training exemplars, without explicit abstractionist machinery. The accounts need not contradict.


## Summarize the paper in one sentence.

 This paper provides empirical evidence for the claim that abstraction-like behaviors can emerge in neural network models through the encoding of exemplars during training, by analyzing how lexical category information is acquired for novel words in BERT.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contribution is to provide empirical evidence for the "abstraction-via-exemplars" account of how language learners generalize to novel expressions. Specifically:

1) The authors present a case study analyzing how BERT's representations of novel tokens change when trained on examples that disambiguate their lexical category, showing that the representations move closer to regions populated by known category exemplars. 

2) They further show that randomly sampling token representations from these category-exemplar regions and projecting them into BERT's embedding space yields good performance on the lexical category inference tasks from Kim et al. (2021), without any additional training.

In sum, these analyses suggest that abstraction-like behaviors can emerge in models that encode summaries of training exemplars, lending support to the view that abstraction and exemplar-based accounts need not be opposed. The key insight is that compression of exemplars could give rise to abstraction. This is presented as the main contribution of the work.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Lexical category inference - The paper investigates how models like BERT can generalize the lexical category (e.g. noun, verb, adjective) of novel words.

- Abstraction vs exemplars - The paper relates to the debate about whether linguistic abstraction or stored exemplars best explain humans' ability to generalize language. 

- BERT - The paper analyzes the behavior of the BERT language model.

- Embeddings - The analysis tracks how the vector representations/embeddings of novel tokens change during training. 

- Movement in vector space - The paper examines how novel tokens move closer to regions representing their associated lexical categories.

- Fill-in-the-blank - The training and testing of BERT relies on fill-in-the-blank exercises.

- Developmental linguistics - The experiments are inspired by studies of lexical development in children.

In summary, key concepts revolve around using BERT and embeddings to study abstraction and generalization of lexical categories, relating to exemplar and developmental linguistics theories.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper mentions that abstraction could arise "via the (compressed) encoding of exemplars." Can you expand more on this idea and how the authors try to provide evidence for it in this work? 

2. Figure 1 shows the experimental setup from Kim et al. (2021). Can you walk through the details of this setup and how it aims to test lexical category generalization? What are some limitations or challenges with this approach?

3. The authors claim that regardless of the random initialization, the novel token embeddings move closer to regions populated by known category exemplars after training. What analysis do they perform to show evidence of this representational movement? How convincing is this evidence?

4. Table 1 shows above-chance performance on the test set even without any training of BERT's parameters. Can you explain the embeddings projection method used here and why this result lends support for the abstraction-via-exemplars account? 

5. The authors connect their work to developmental linguistics research on lexical category acquisition in children. In what ways is probing BERT's generalization abilities relevant to theories of language acquisition in humans? What are similarities and differences to keep in mind?  

6. How does the abstraction vs exemplar debate relate to broader discussions on the inductive biases and generalization abilities of deep learning models? What unique perspective does this work provide?

7. The paper analyzes lexical categories, but do you think the findings could generalize to other linguistic abstractions like syntax, semantics, etc.? Why or why not?

8. Could the observed representational movement and clustering be an artefact of PCA projection rather than indicative of any meaningful abstraction? How could this concern be addressed?

9. The paper focuses on analyzing BERT, but how do you think training objectives beyond masked language modeling may impact emergence of abstraction from exemplars?

10. The authors motivate their work as reconciling abstractionist and exemplar-based accounts. Do you think their evidence supports this reconciliation, or does it undermine either account? Why?
