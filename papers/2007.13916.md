# [Demystifying Contrastive Self-Supervised Learning: Invariances,   Augmentations and Dataset Biases](https://arxiv.org/abs/2007.13916)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research questions and hypotheses addressed in this paper are:- What explains the recent performance gains of contrastive self-supervised learning methods like MoCo and PIRL on downstream tasks like object detection and image classification? The paper hypothesizes that these gains come mainly from occlusion invariance learned through aggressive cropping augmentations.- Do contrastive self-supervised methods learn all the necessary invariances for object recognition tasks? The paper hypothesizes that while these methods learn occlusion invariance, they are inferior at learning viewpoint and category instance invariance compared to supervised methods. - Are the aggressive cropping augmentations an ideal strategy for learning useful representations? The paper hypothesizes that the cropping relies heavily on dataset bias and may not be scalable to more complex datasets.- Can alternative data like videos be used to learn better viewpoint and deformation invariance? The paper proposes that leveraging temporal transformations in videos can help learn representations with higher viewpoint invariance in a self-supervised manner.In summary, the key hypotheses are around understanding why contrastive self-supervised learning works so well recently, analyzing the limitations of current approaches, and proposing videos as an alternative form of data to learn better representations. The experiments aim to verify if aggressive cropping indeed leads to occlusion invariance, and if videos can improve viewpoint invariance.
