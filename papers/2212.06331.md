# [DeepMapping2: Self-Supervised Large-Scale LiDAR Map Optimization](https://arxiv.org/abs/2212.06331)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to improve the accuracy of large-scale LiDAR mapping using self-supervised deep learning. Specifically, the paper proposes a method called DeepMapping2 to optimize large-scale LiDAR maps. The key hypothesis is that by carefully organizing training batches based on spatial topology and introducing a novel local-to-global consistency loss, the proposed method can effectively incorporate loop closures and local registration information to improve optimization and achieve higher accuracy in large-scale mapping.The paper analyzes limitations of the previous DeepMapping method, which fails to scale up due to lack of loop closures and slow convergence of the global registration network. DeepMapping2 proposes two main techniques to address these challenges:1. Organizing training batches based on spatial topology and map loops obtained from off-the-shelf place recognition algorithms. This allows implicit incorporation of loop closures into the training process.2. Introducing a self-supervised local-to-global consistency loss that leverages pairwise registration results. This provides stronger training signal and gradient for the global registration network to converge faster.The central hypothesis is that by carefully designing the training procedure with these two techniques, the proposed DeepMapping2 method can effectively optimize LiDAR maps in large-scale environments where previous methods fail. Experiments on public datasets like KITTI, NCLT and Nebula validate the effectiveness of DeepMapping2.In summary, the key research question is how to scale up self-supervised LiDAR map optimization to large environments, and the central hypothesis is that the proposed batch organization and consistency loss techniques can achieve this effectively. The experiments aim to validate the proposed DeepMapping2 method can improve accuracy in large-scale mapping tasks.


## What is the main contribution of this paper?

 The main contributions of this paper are:1. Proposing DeepMapping2, a self-supervised method for large-scale LiDAR map optimization. This extends the prior DeepMapping method to work well on large datasets by addressing its limitations.2. Introducing two key novel techniques: - Batch organization based on map topology from loop closing. This implicitly incorporates loop closure into the training process to reduce drift.- Self-supervised local-to-global point consistency loss that leverages pairwise registration. This provides stronger training signal without relying on sparse point correspondences between frames.3. Comprehensive experiments and ablation studies on public datasets like KITTI, NCLT, and Nebula that demonstrate the effectiveness of DeepMapping2 and the contribution of each proposed technique.4. Analysis that reveals the limitations of DeepMapping on large datasets, which leads to the proposed techniques to address them. This provides useful insights on how to incorporate loop closing and local registration into the DeepMapping framework.5. A new training-as-optimization paradigm for LiDAR mapping that achieves state-of-the-art performance. The method is self-supervised and generic - it can improve mapping from different front-ends like ICP, KISS-ICP and LeGO-LOAM.In summary, the main contribution is proposing a novel self-supervised method and techniques to enable DeepMapping to work on large-scale LiDAR mapping problems, which was not possible effectively before. The experiments, analysis and ablation studies validate the design and effectiveness of DeepMapping2.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the key points from the paper:The paper proposes DeepMapping2, a self-supervised method to optimize large-scale LiDAR maps by adding batch organization based on map topology and a novel local-to-global point consistency loss to DeepMapping.


## How does this paper compare to other research in the same field?

 Here are some key things I noticed about how this paper compares to other work in self-supervised LiDAR map optimization:- The main contribution is extending DeepMapping to work on large-scale datasets. Previous work with DeepMapping showed good results on small datasets, but had issues scaling up due to lack of loop closure and slow convergence. This paper addresses those issues.- Most prior work in LiDAR mapping uses traditional SLAM methods involving feature matching and optimization. DeepMapping pioneered a self-supervised learning approach, converting mapping to network training. This paper builds on that concept.- Other learning-based methods like L3-Net replace only parts of the SLAM pipeline with neural networks. This paper keeps the full self-supervised training framework of DeepMapping.- For incorporating loop closure information, many papers add explicit loop closure detection modules. This paper takes a different approach of batch organization based on topology to implicitly include loop closure.- The local-to-global consistency loss is a novel technique to leverage local pairwise registration while avoiding reliance on sparse point correspondences between frames. This addresses a key challenge in LiDAR registration.- Results on large-scale outdoor and underground datasets demonstrate state-of-the-art performance. Many prior learning-based methods were tested only on small indoor datasets.- The method can be used with different input maps, showing robustness. And it improved odometry on the Nebula dataset, where traditional SLAM failed.Overall, the key novelties are in addressing DeepMapping's limitations for large-scale mapping through implicit loop closure and the consistency loss. The results validate the proposed techniques and show this approach advances self-supervised LiDAR map optimization to handle complex real-world datasets.


## What future research directions do the authors suggest?

 Based on my reading of the paper, some of the main future research directions suggested by the authors include:- Developing methods to further improve the speed and scalability of DeepMapping2, such as through more parallelization and optimization. The paper notes that DeepMapping2 currently has longer computation time than some other methods.- Exploring the integration of keyframe-based SLAM techniques into the DeepMapping2 framework. The authors suggest keyframe selection could help improve efficiency.- Generalizing DeepMapping2 to multi-agent SLAM scenarios, where point clouds may come from multiple sensor agents rather than just a single trajectory.- Incorporating other sensor modalities like cameras into DeepMapping2, as the current method relies solely on LiDAR point clouds. Fusing camera imagery could provide additional constraints.- Evaluating DeepMapping2 on more complex large-scale datasets and scenes to further validate its capabilities. The paper tested it on KITTI, NCLT and Nebula datasets.- Developing unsupervised or self-supervised methods for obtaining the map topology used to organize training batches in DeepMapping2. Currently this relies on off-the-shelf place recognition algorithms.- Exploring the integration and joint optimization with the front-end odometry tracking components of SLAM systems. Right now DeepMapping2 focuses on the backend global pose optimization.In summary, the main future directions are improving the efficiency and scalability of the method, expanding it to more complex scenarios like multi-agent SLAM, incorporating other sensor modalities beyond LiDAR, and developing more self-supervised components to remove reliance on other algorithms. Evaluating on more varied and complex datasets is also suggested.


## Summarize the paper in one paragraph.

 Here is a one paragraph summary of the paper:The paper proposes DeepMapping2, an improved method for large-scale LiDAR mapping. It builds on DeepMapping, which converts global point cloud registration into a self-supervised training of deep networks. However, DeepMapping struggles with large datasets due to lack of loop closure and slow convergence. DeepMapping2 addresses these issues with two main contributions: (1) it organizes training batches based on map topology from loop closing so that spatially close frames are grouped together, and (2) it introduces a novel self-supervised local-to-global point consistency loss that enforces agreement between local pairwise registration and global poses predicted by the network. Experiments on KITTI, NCLT and Nebula datasets demonstrate state-of-the-art performance. Ablation studies validate the necessity and efficacy of the proposed techniques. Overall, DeepMapping2 presents an effective self-supervised framework for optimizing large-scale LiDAR maps.


## Summarize the paper in two paragraphs.

 Here is a two paragraph summary of the key points from the paper: The paper proposes DeepMapping2, a self-supervised method for large-scale LiDAR map optimization. DeepMapping2 builds on DeepMapping, which converts global point cloud registration into a self-supervised deep network training problem. However, DeepMapping struggles to scale up to large datasets due to lack of loop closure and slow convergence. DeepMapping2 addresses these issues through two main contributions: (1) Batch organization based on map topology from place recognition to incorporate loop closure information. (2) A novel self-supervised local-to-global point consistency loss that leverages pairwise registration results to provide stronger supervision signal and convergence speedup for the global registration network. Experiments on KITTI, NCLT, and Nebula datasets demonstrate DeepMapping2's state-of-the-art performance on large-scale mapping tasks. Ablation studies validate the necessity and efficacy of the proposed techniques.In summary, DeepMapping2 enables self-supervised optimization for large-scale LiDAR mapping by carefully incorporating loop closure information and local registration cues to significantly improve DeepMapping's generalization capability. The method is demonstrated to work robustly across diverse complex indoor and outdoor environments.


## Summarize the main method used in the paper in one paragraph.

 The paper proposes DeepMapping2, a self-supervised method for large-scale LiDAR map optimization. It extends DeepMapping by adding two key techniques:1. Batch organization based on map topology from loop closing. This allows spatially close frames to be grouped together, implicitly incorporating loop closure into training. 2. A novel self-supervised local-to-global point consistency loss that leverages pairwise registration results. For each point in an anchor frame, this loss computes the consistency between its different global coordinate versions transformed from the global poses of neighboring frames and relative poses from pairwise registration. This provides stronger supervision for the global pose network and avoids relying on inaccurate point-level correspondences across frames.Experiments on KITTI, NCLT and Nebula datasets demonstrate DeepMapping2's effectiveness in improving mapping accuracy over DeepMapping and other baselines. Ablation studies validate the contribution of the two proposed techniques. Overall, DeepMapping2 presents a self-supervised approach to optimize LiDAR maps on large-scale datasets by converting it into training deep networks with appropriate losses and data organization.


## What problem or question is the paper addressing?

 Based on my reading, the key problem this paper is addressing is how to enable accurate large-scale LiDAR mapping using deep learning. Specifically:- Existing LiDAR SLAM methods can suffer from odometry drift and difficulties in finding correspondences and loop closures, leading to unsatisfactory mapping results especially for large-scale datasets. - DeepMapping was proposed to convert global point cloud registration into a self-supervised training of deep networks, achieving superior performance on small datasets. However, it still fails on large datasets due to lack of explicit loop closing and difficulties in incorporating local registration information.- This paper proposes DeepMapping2 to extend DeepMapping to large-scale scenarios by introducing two novel techniques:  - Batch organization based on map topology from loop closing to implicitly incorporate loop closures.  - Self-supervised local-to-global point consistency loss to leverage local registration results and provide stronger training signals.  - Experiments on large public datasets like KITTI, NCLT, and Nebula demonstrate DeepMapping2's effectiveness for large-scale LiDAR mapping, significantly improving over DeepMapping and other baselines.In summary, the key focus is on enabling accurate self-supervised deep learning-based optimization for large-scale LiDAR mapping, which remains challenging for existing methods. The proposed DeepMapping2 aims to address this through ideas like topology-based batching and local-global consistency loss.
