# [DeepMapping2: Self-Supervised Large-Scale LiDAR Map Optimization](https://arxiv.org/abs/2212.06331)

## What is the central research question or hypothesis that this paper addresses?

The central research question this paper addresses is how to improve the accuracy of large-scale LiDAR mapping using self-supervised deep learning. Specifically, the paper proposes a method called DeepMapping2 to optimize large-scale LiDAR maps. The key hypothesis is that by carefully organizing training batches based on spatial topology and introducing a novel local-to-global consistency loss, the proposed method can effectively incorporate loop closures and local registration information to improve optimization and achieve higher accuracy in large-scale mapping.The paper analyzes limitations of the previous DeepMapping method, which fails to scale up due to lack of loop closures and slow convergence of the global registration network. DeepMapping2 proposes two main techniques to address these challenges:1. Organizing training batches based on spatial topology and map loops obtained from off-the-shelf place recognition algorithms. This allows implicit incorporation of loop closures into the training process.2. Introducing a self-supervised local-to-global consistency loss that leverages pairwise registration results. This provides stronger training signal and gradient for the global registration network to converge faster.The central hypothesis is that by carefully designing the training procedure with these two techniques, the proposed DeepMapping2 method can effectively optimize LiDAR maps in large-scale environments where previous methods fail. Experiments on public datasets like KITTI, NCLT and Nebula validate the effectiveness of DeepMapping2.In summary, the key research question is how to scale up self-supervised LiDAR map optimization to large environments, and the central hypothesis is that the proposed batch organization and consistency loss techniques can achieve this effectively. The experiments aim to validate the proposed DeepMapping2 method can improve accuracy in large-scale mapping tasks.


## What is the main contribution of this paper?

The main contributions of this paper are:1. Proposing DeepMapping2, a self-supervised method for large-scale LiDAR map optimization. This extends the prior DeepMapping method to work well on large datasets by addressing its limitations.2. Introducing two key novel techniques: - Batch organization based on map topology from loop closing. This implicitly incorporates loop closure into the training process to reduce drift.- Self-supervised local-to-global point consistency loss that leverages pairwise registration. This provides stronger training signal without relying on sparse point correspondences between frames.3. Comprehensive experiments and ablation studies on public datasets like KITTI, NCLT, and Nebula that demonstrate the effectiveness of DeepMapping2 and the contribution of each proposed technique.4. Analysis that reveals the limitations of DeepMapping on large datasets, which leads to the proposed techniques to address them. This provides useful insights on how to incorporate loop closing and local registration into the DeepMapping framework.5. A new training-as-optimization paradigm for LiDAR mapping that achieves state-of-the-art performance. The method is self-supervised and generic - it can improve mapping from different front-ends like ICP, KISS-ICP and LeGO-LOAM.In summary, the main contribution is proposing a novel self-supervised method and techniques to enable DeepMapping to work on large-scale LiDAR mapping problems, which was not possible effectively before. The experiments, analysis and ablation studies validate the design and effectiveness of DeepMapping2.
