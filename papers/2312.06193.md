# [DisControlFace: Disentangled Control for Personalized Facial Image   Editing](https://arxiv.org/abs/2312.06193)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes DisControlFace, a novel diffusion-based framework for personalized facial image editing using only unstructured 2D images. It achieves disentangled control during image generation by utilizing a frozen pre-trained reconstruction network to maintain facial identity and a parallel control network to enable explicit editing of facial attributes. Specifically, an off-the-shelf Diff-AE model is adopted as the backbone to preserve personalized details unrelated to editing. A tailored Face-ControlNet is constructed to take rendered snapshots based on estimated 3D face parameters as input and generate spatial control features. Furthermore, a masked autoencoding strategy is designed to enable effective disentangled training. Extensive experiments demonstrate DisControlFace's superior performance in controllable and identity-preserving facial image editing and manipulation over previous state-of-the-art generative face models. It also supports personalized fine-tuning and diverse applications like image inpainting and face animation. The proposed explicit disentangled control mechanism is a valuable exploration for conditional diffusion models.
