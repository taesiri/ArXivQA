# [Vietnamese Poem Generation &amp; The Prospect Of Cross-Language Poem-To-Poem   Translation](https://arxiv.org/abs/2401.01078)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Poetry generation is challenging as it requires understanding nuances of language, sentiment, and style. 
- No prominent model exists for generating Vietnamese poems using capabilities of large language models (LLMs) like GPT-3.
- Existing implementations have limitations in input flexibility and control over generated content.

Proposed Solution: 
- Use GPT-3 and BLOOM to generate Vietnamese poems from natural language prompts. 
- Allows intuitive process with enhanced content control through instructional prompts on themes, styles.
- Outcome should be creative, unique poems following rigid rules of poetry and imbued with intended sentiment.

Approaches:
- Text-to-poem: Reverse generate prompts from poems using GPT-3.5. Finetune GPT-3 and BLOOM to generate poems from prompts.
- Poem-to-poem: Turn poems to texts, paraphrase to use as prompts. Allows cross-language translation.

Contributions:
- Novel prompt-based approach leveraging capabilities of LLMs to push boundaries of Vietnamese poetry generation. 
- Comprehensive scoring system tailored for Vietnamese poetry genres.
- Best model (GPT-3 Babbage) achieves score of 0.805 for popular "luc bat" genre.
- Poem-to-poem method enables cross-language poem translation while maintaining content control.

In summary, the paper introduces a flexible prompt-based framework for controlled Vietnamese poetry generation using LLMs. Key innovations include leveraging LLM capabilities, poem-to-poem translation pipeline, and custom evaluation metrics.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes using large language models like GPT-3 and BLOOM to generate Vietnamese poems from natural language prompts with enhanced content control, achieving strong results with a top model score of 0.805.


## What is the main contribution of this paper?

 Based on my reading of the paper, the main contributions are:

1. Proposing a prompt-based approach using large language models like GPT-3 and BLOOM to generate Vietnamese poems from natural language prompts. This allows more intuitive control over the content and theme of the generated poems.

2. Achieving strong quantitative results for Vietnamese poem generation, with their best GPT-3 Babbage model obtaining a score of 0.805 for the "luc bat" genre based on their custom evaluation metric. This surpasses previous benchmarks.

3. Introducing a novel poem-to-poem generation pipeline where poems are paraphrased into normal text prompts. This enables potential cross-language poem translation while maintaining control over the generated content. They achieve a score of 0.781 for this method. 

4. Formulating a comprehensive quantitative scoring system to evaluate Vietnamese poem quality based on length, rhyme and tone. This is customizable to different genres.

In summary, the key innovations are around flexible prompt-based poem generation in Vietnamese using modern large language models, the poem-to-poem generation concept, and introduce robust evaluation metrics.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key keywords and terms associated with this paper include:

- GPT-3 - The paper utilizes GPT-3, specifically the Davinci and Babbage variants, as one of the main language models for Vietnamese poem generation.

- BLOOM - The other main language model used in the paper, BLOOM is an open-source model from Hugging Face that the authors also leverage. 

- Vietnamese poem generation - The overall focus of the paper is generating Vietnamese poems from natural language prompts.

- Quantization and LoRa - These techniques are used to optimize the BLOOM model to fit within the computational constraints. 

- Prompt-based generation - The authors propose a prompt-based approach to poetry generation using large language models.

- Text-to-poem generation - One of the downstream tasks involves generating poems from natural language text prompts.

- Poem-to-poem generation - The other downstream task converts existing poems to text prompts to generate new poems.

- Cross-language translation - The poem-to-poem approach has potential for cross-language poem translation.

- Custom evaluation scoring - A comprehensive scoring system is introduced to evaluate Vietnamese poem quality.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in the paper:

1. The paper proposes two architectures for Vietnamese poem generation - text-to-poem and poem-to-poem. Can you elaborate on the key differences between these two approaches and the rationale behind exploring both? 

2. The Babbage model with full dataset finetuning achieved the highest score of 0.805 on the custom "luc bat" evaluation. What are some ways this score could be further improved? For example, training on even larger datasets or using more advanced LLMs.

3. The paper mentions using an 8-bit quantization and LoRA adaptation for the BLOOM model. Can you explain in more detail how these techniques work and what advantages they provide? 

4. The results show Babbage slightly outperforming BLOOM on the "luc bat" genre despite having fewer parameters. What might account for Babbage's better performance in this case? 

5. For the poem-to-poem approach, the paper mentions the potential for cross-language poem translation. Can you elaborate on how this would work in more detail? What are the main challenges?

6. The custom evaluation scoring system is a key contribution of this paper. What are some limitations of this scoring approach and how might it be improved or augmented?  

7. Could the techniques proposed in this paper be applied to poem generation in other languages beyond Vietnamese? What modifications would need to be made?

8. The results show the zero-shot ChatGPT performs significantly worse than the finetuned models. Why is finetuning critical for quality poetry generation? 

9. The authors were limited by compute resources in some experiments. How might access to greater resources have changed the outcomes or experiments that were possible?

10. The paper focuses solely on poetry generation. How might the techniques explored be applicable to other creative text generation tasks such as songwriting or storytelling?
