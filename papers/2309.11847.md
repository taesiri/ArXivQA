# [MEFLUT: Unsupervised 1D Lookup Tables for Multi-exposure Image Fusion](https://arxiv.org/abs/2309.11847)

## What is the central research question or hypothesis that this paper addresses?

 Based on my understanding, the central research question this paper tries to address is: 

How to achieve high quality and high efficiency for multi-exposure image fusion (MEF) simultaneously?

The key points are:

1) Propose a method named MEFLUT that learns 1D lookup tables (LUTs) to encode the fusion weights for MEF. 

2) Design a network based on multi-dimensional attention mechanisms to generate high quality fusion weights, which are then encoded into the 1D LUTs.

3) The 1D LUTs allow very fast lookup of fusion weights during deployment, achieving high efficiency while maintaining high fusion quality. 

4) Collect a new multi-exposure image dataset from mobile phones to facilitate research on MEF for mobile platforms.

In summary, the central goal is to achieve a good balance between quality and efficiency for MEF, by using a well-designed network to generate high quality fusion weights, which are then encoded into 1D LUTs to enable extremely fast lookup and efficiency. The new mobile dataset also facilitates this research direction.


## What is the main contribution of this paper?

 Based on my understanding, the main contributions of this paper are:

1. The authors propose MEFLUT, a new method for multi-exposure image fusion (MEF) that learns 1D lookup tables (LUTs) to encode the fusion weights for each exposure. This allows for fast and efficient fusion by simply querying the LUTs during deployment. 

2. A new network architecture is introduced with two novel attention modules - CFCA and DISA. CFCA enables attention in the frame and channel dimensions to fuse inter-frame features, while DISA applies spatial attention for intra-frame weight prediction. This architecture achieves state-of-the-art quality.

3. The authors collect a new MEF dataset of 960 samples captured using mobile phones in diverse scenes. 155 samples have ground truth images produced manually by professionals, which facilitates quantitative evaluation.

4. Extensive experiments demonstrate MEFLUT achieves higher efficiency and better quality than prior arts on the new dataset and another dataset SICE. The 1D LUT approach processes 4K images in less than 4ms on a PC GPU. The proposed method has also been deployed in millions of mobile devices.

In summary, the key innovation is using 1D LUTs to enable real-time high-quality MEF on mobile devices, supported by a new attention-based network architecture and dataset. The efficiency, effectiveness and practicality of the proposed MEFLUT method are the main contributions.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

 Here is a one sentence summary of the paper:

The paper proposes MEFLUT, a new method for multi-exposure image fusion that learns 1D lookup tables from a trained neural network to achieve efficient and high quality fusion for potential deployment on mobile devices.
