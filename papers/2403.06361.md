# [See Through Their Minds: Learning Transferable Neural Representation   from Cross-Subject fMRI](https://arxiv.org/abs/2403.06361)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Decoding visual information from fMRI data of the human brain is challenging due to limited data per subject and high noise. Previous methods have primarily employed subject-specific models, which can overfit on small datasets. 

- There is a scarcity of fMRI data due to the high cost of data collection. Intrinsic variability across human brains also requires building new models from scratch for each subject.

Proposed Solution: 
- The paper proposes a cross-subject learning framework called "See Through Their Minds" (STTM) to learn robust and transferable representations across human brains.

- STTM consists of subject-specific shallow adapters to transform fMRI signals of different subjects into a unified feature space. The transformed features are then fed into a shared deeper decoder network to extract common patterns.

- It incorporates a high-level perception decoding pipeline using contrastive learning between fMRI patterns and CLIP image/text embeddings. And a low-level pixel reconstruction pipeline guided by high-level perceptions.

- For new subjects, transfer learning can be achieved by training new lightweight adapters.

Main Contributions:

- Proposes an adapter-based cross-subject learning framework that aligns fMRI signals from different brains to train more robust decoders. Enables transfer learning to new subjects.

- Identifies the importance of interaction between high-level and low-level perceptions for reconstruction tasks. Utilizes high-level features to guide low-level pixel decoding. 

- Achieves state-of-the-art decoding performance across tasks like retrieval, zero-shot classification and reconstruction. Demonstrates good transferability to limited fMRI data.

- Provides a strong versatile baseline for multi-modal brain decoding tasks that combines global linguistic-visual and fine-grained visual contrastive learning.

In summary, the paper makes notable contributions in cross-subject learning and transfer learning for fMRI-based visual decoding, while also highlighting the role of multi-level visual processing similar to human cognition. The proposed STTM framework and findings could aid advancing brain-inspired AI.
