# [CLIF: Complementary Leaky Integrate-and-Fire Neuron for Spiking Neural   Networks](https://arxiv.org/abs/2402.04663)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Spiking neural networks (SNNs) are promising for efficient AI models, but difficult to train due to non-differentiable spiking mechanisms. The commonly used surrogate gradient (SG) method can lead to diminished accuracy compared to ANNs.

- Through analysis and experiments, the authors identify that the degraded accuracy is linked to vanishing gradients in the temporal dimension when using SG to train SNNs with leaky integrate-and-fire (LIF) neurons.

Proposed Solution:
- The authors propose a new neuron model called Complementary LIF (CLIF) to address the temporal gradient vanishing problem in LIF neurons. 

- CLIF introduces a complementary membrane potential that captures information related to the decay of the membrane potential in LIF neurons. This creates additional paths for gradients to flow in the temporal dimension.

- CLIF is hyperparameter-free and can directly replace LIF neurons in many SNN architectures.

Main Contributions:
- Identified cause of diminished accuracy in LIF-based SNNs trained with SG as temporal gradient vanishing 

- Proposed CLIF neuron that provides richer temporal gradients while keeping simple spike outputs

- Demonstrated CLIF boosts performance of various SNNs on static and neuromorphic datasets

- Showed CLIF-based SNNs achieve comparable accuracy to ANNs, while maintaining efficiency advantages

In summary, the paper proposes a novel and broadly applicable CLIF neuron to address gradient vanishing issues in temporal domain for SNNs. CLIF enhances gradient flow over time to train more accurate SNN models, achieving state-of-the-art results.
