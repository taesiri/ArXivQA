# [Binary Latent Diffusion](https://arxiv.org/abs/2304.04820)

## What is the central research question or hypothesis that this paper addresses?

 The central hypothesis of this paper is that a binary latent space can be explored for compact yet expressive image representations. 

The key points are:

- The authors propose representing images in a binary latent space, where each image patch is encoded as a binary vector. This provides a compact discrete representation compared to pixel values or continuous latents.

- They train an autoencoder with a Bernoulli latent distribution to learn the mappings between images and binary latents. The discrete sampling is handled via a straight-through gradient estimator.

- To generate novel images, they model the prior over the binary latents using a tailored binary latent diffusion model. This diffusion in a binary space allows efficient sampling in just 16 steps.

- Compared to vector quantized latents where each patch maps to a discrete codebook index, the binary latents provide more expressive compositions of visual features. This allows scaling to high resolutions without hierarchical latents.

- Experiments on unconditional and conditional image generation show the binary latent diffusion performs comparably to state-of-the-art methods while being more compact and efficient to sample from.

In summary, the central hypothesis is that binary latent spaces can provide a sweet spot between the compactness of discrete representations and the expressiveness of continuous latents for generating high-quality images. The binary latent diffusion model is proposed to effectively model and sample from this binary latent space.
