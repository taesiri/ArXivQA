# [Automated Machine Learning for Positive-Unlabelled Learning](https://arxiv.org/abs/2401.06452)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Positive-Unlabelled (PU) learning aims to learn classifiers from labelled positive data and unlabelled data which can be positive or negative. Many methods have been proposed for PU learning, making it hard to select the optimal method. 
- Automated Machine Learning (Auto-ML) tailors ML pipelines to datasets, but no Auto-ML system exists specifically for PU learning.
- Existing Auto-ML systems like GA-Auto-PU are computationally expensive.

Proposed Solution:
- The paper proposes two new Auto-ML systems for PU learning - BO-Auto-PU (Bayesian Optimization) and EBO-Auto-PU (Evolutionary Bayesian Optimization).
- These are compared to GA-Auto-PU and two PU learning methods - S-EM and DF-PU.
- Two search spaces are used - a base space and an extended space with the Spy method. 
- Experiments are done on 20 biomedical datasets, with the positive class hidden at 20%, 40% and 60% to test robustness.

Main Contributions:
- Introduction of two new Auto-ML systems specifically tailored for PU learning - BO-Auto-PU and EBO-Auto-PU.
- EBO-Auto-PU is a novel hybrid Evolutionary Bayesian Optimization approach.
- Extensive experimental evaluation on 60 PU dataset versions, comparing the 3 Auto-ML systems and against 2 baseline PU methods.
- Analysis showing the new Auto-ML systems often statistically significantly outperform the baselines.
- EBO-Auto-PU strikes the best balance between predictive performance and computational efficiency.


## Summarize the paper in one sentence.

 This paper proposes and evaluates two new Automated Machine Learning systems for Positive-Unlabelled learning, based on Bayesian Optimisation and Evolutionary Bayesian Optimisation, comparing them to an existing Genetic Algorithm-based system and two baseline PU learning methods across 60 biomedical datasets.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1) The proposal of two new Auto-ML systems for Positive-Unlabelled (PU) learning: BO-Auto-PU, based on Bayesian Optimisation, and EBO-Auto-PU, based on a new hybrid Evolutionary Bayesian Optimisation approach.

2) An extensive experimental evaluation comparing the two new Auto-PU systems against GA-Auto-PU (the existing Auto-ML system for PU learning) and two baseline PU learning methods (S-EM and DF-PU). The evaluation was done on 20 biomedical datasets, considering three different percentages of positive instances hidden in the unlabelled set.

3) The analysis of the most frequently selected hyperparameter values by the Auto-PU systems, revealing insights such as linear classifiers being preferred in Phase 1 and the spy method being used less frequently than expected. 

4) The proposal of EBO-Auto-PU as the overall best performing system, considering its predictive performance (statistically outperforming the baselines) and computational efficiency (about 10 times faster than GA-Auto-PU).

In summary, the main contribution is the proposal and evaluation of two new computationally efficient Auto-ML systems for PU learning, with EBO-Auto-PU standing out as the best system overall.


## What are the keywords or key terms associated with this paper?

 Based on reviewing the paper, some of the main keywords or key terms associated with it are:

- Positive-Unlabelled (PU) learning
- Automated Machine Learning (Auto-ML) 
- Bayesian Optimisation
- Genetic Algorithm
- Classification
- Two-step framework
- Spy method
- Evolutionary Bayesian Optimisation (EBO)
- GA-Auto-PU
- BO-Auto-PU
- EBO-Auto-PU
- F-measure
- Precision
- Recall
- Biomedical datasets

The paper proposes two new Auto-ML systems for PU learning called BO-Auto-PU and EBO-Auto-PU. It compares them to an existing Auto-ML system for PU learning called GA-Auto-PU across three performance measures on engineered PU biomedical datasets. The key focus is on optimizing PU learning methods using techniques like Bayesian Optimization and Evolutionary Computation.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. The paper proposes using Bayesian Optimization (BO) for hyperparameter optimization of positive-unlabeled (PU) learning algorithms. What are the main advantages and disadvantages of using BO over other hyperparameter optimization methods like grid search or random search?

2. The paper also proposes a hybrid Evolutionary Bayesian Optimization (EBO) approach. How does this approach combine genetic algorithms and BO? What are the potential benefits over using BO or genetic algorithms alone? 

3. The paper evaluates the methods on engineered PU datasets created from 20 real-world biomedical datasets. What are the limitations of evaluating on engineered datasets versus real PU data? How could the evaluation approach be improved?

4. The results show that the BO and EBO methods achieve much lower runtimes than the GA method. However, the GA method achieved slightly better predictive performance on some metrics. How could the tradeoff between performance and efficiency be further analyzed?

5. The paper analyzes the most frequently selected hyperparameter values across the methods. What further analysis could be done on the optimized PU learning algorithms output by the Auto-PU systems? 

6. How robust are the proposed methods to violations of assumptions like smoothness, separability, and selected completely at random that underpin PU learning frameworks?

7. The search spaces consist mainly of algorithm choices and hyperparameters for the two-step PU learning framework. How could the search spaces be expanded to optimize over other PU learning frameworks?

8. For real-world application, how could the Auto-PU systems be updated incrementally as new labeled data becomes available rather than retrained from scratch?

9. The objective function used is based on cross-validation F-measure. What alternative objective functions could capture other useful metrics for PU learning?

10. The methods are evaluated on biomedical datasets. How well would they transfer to other application domains like text classification where PU learning is also used?
