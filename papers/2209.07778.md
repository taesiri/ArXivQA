# [Spatial-then-Temporal Self-Supervised Learning for Video Correspondence](https://arxiv.org/abs/2209.07778)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to achieve synergy between spatial and temporal cues for learning effective video correspondence representations in a self-supervised manner. 

Specifically, the key research questions/hypotheses are:

- How can we leverage both spatially discriminative features and temporally repetitive features to learn robust video correspondence representations without manual annotations?

- Can we design a self-supervised pretext task that firstly learns spatial features and then enhances them by exploiting temporal cues? 

- How can we retain the learned spatial discriminative ability when adding a temporal objective in the second stage?

- How can we alleviate the problem of temporal discontinuity that harms the learning of temporal features?

To summarize, this paper proposes a novel spatial-then-temporal self-supervised learning approach to learn spatiotemporal features for video correspondence by combining the advantages of spatial and temporal feature learning. The key novelty is the two-step design with proposed distillation losses to achieve synergy between spatial and temporal cues.


## What is the main contribution of this paper?

 The main contributions of this paper are:

1. Proposing a spatial-then-temporal self-supervised learning method for video correspondence. This involves first learning spatial features from unlabeled images via contrastive learning, and then enhancing the features by exploiting temporal cues from unlabeled videos via reconstructive learning.

2. Designing a global correlation distillation loss to retain the spatially discriminative features learned in the first step when exploiting temporal cues in the second step. 

3. Proposing a local correlation distillation loss to facilitate learning of temporal features at coarser pyramid levels by distilling knowledge from finer pyramid levels. This helps combat the temporal discontinuity that harms reconstruction.

4. Achieving state-of-the-art performance on multiple correspondence-based video analysis tasks like video object segmentation, human part propagation, and pose keypoint tracking. The method outperforms previous self-supervised methods and is comparable to some fully supervised task-specific algorithms.

5. Performing ablation studies to demonstrate the benefits of the proposed two-step design and the distillation losses.

In summary, the key novelty is in proposing a spatial-then-temporal self-supervised learning framework along with distillation losses to achieve synergistic spatial-temporal feature learning from unlabeled images and videos for video correspondence.
