# [Spatial-then-Temporal Self-Supervised Learning for Video Correspondence](https://arxiv.org/abs/2209.07778)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to achieve synergy between spatial and temporal cues for learning effective video correspondence representations in a self-supervised manner. 

Specifically, the key research questions/hypotheses are:

- How can we leverage both spatially discriminative features and temporally repetitive features to learn robust video correspondence representations without manual annotations?

- Can we design a self-supervised pretext task that firstly learns spatial features and then enhances them by exploiting temporal cues? 

- How can we retain the learned spatial discriminative ability when adding a temporal objective in the second stage?

- How can we alleviate the problem of temporal discontinuity that harms the learning of temporal features?

To summarize, this paper proposes a novel spatial-then-temporal self-supervised learning approach to learn spatiotemporal features for video correspondence by combining the advantages of spatial and temporal feature learning. The key novelty is the two-step design with proposed distillation losses to achieve synergy between spatial and temporal cues.
