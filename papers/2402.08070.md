# [Multi-Attribute Vision Transformers are Efficient and Robust Learners](https://arxiv.org/abs/2402.08070)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Multi-attribute learning (MAL) allows simultaneously learning multiple attributes of visual data using a shared model. Prior works in MAL are mostly based on convolutional neural networks (CNNs).  
- Vision transformers (ViTs) are emerging as an effective alternative to CNNs but their potential for multi-attribute learning is underexplored.  
- Adversarial attacks on ViTs are gaining attention but attacks tailored for multi-attribute ViTs have not been studied before.

Proposed Solution:
- Introduce a novel ViT framework called MAL-ViT for multi-attribute learning. Additional learnable "attribute tokens" are incorporated corresponding to each attribute task.
- Attribute tokens interact with image patch tokens inside ViT via self-attention, enabling exchange of useful features among attributes. 
- Show MAL-ViT outperforms CNN and single-attribute ViT baselines in learning multiple facial attributes on CelebA dataset.
- Evaluate robustness of MAL-ViT against various adversarial attacks compared to single-attribute ViTs.

Key Contributions:
- Propose a tailored ViT architecture for multi-attribute learning that encodes attribute tasks as tokens inside the model.
- Empirically demonstrate superiority of MAL-ViT over CNN and single-attribute ViT in multi-attribute facial classification.  
- Present extensive analysis showing MAL-ViT is more robust than single-attribute ViT against common attacks like FGSM, PGD, BIM etc. as well as patch-based attacks.
- Showcase the resilience of MAL-ViT specifically against adversarial attacks in the multi-attribute learning setting, an previously unexplored area.

In summary, the paper introduces a novel and efficient way to perform multi-attribute learning using ViTs and provides extensive validation of its robustness properties. The analysis of attacks on multi-attribute ViTs is a novel contribution.
