# [Frustratingly Easy Regularization on Representation Can Boost Deep   Reinforcement Learning](https://arxiv.org/abs/2205.14557)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper, the central research question seems to be:

Do the learned representations of the Q-network and its target network in deep reinforcement learning satisfy some inherent "distinguishable representation property", and if not, can explicitly enforcing this property lead to improved performance?

The key points are:

- The paper theoretically analyzes the representations of the Q-network and target network, and shows they should satisfy a "distinguishable representation property" - i.e. their representations of adjacent time steps should be sufficiently dissimilar.

- Through experiments, they find that some RL algorithms (like CURL) violate this property, while others (like TD3) satisfy it.

- They hypothesize that violating this property leads to worse performance, and propose a regularizer called PEER to explicitly enforce the distinguishable representation property.

- Experiments show PEER combined with various RL algorithms improves performance and sample efficiency across several environments, demonstrating enforcing this property is beneficial.

So in summary, the central hypothesis is that explicitly enforcing the "distinguishable representation property" between the Q-network and target network representations will improve DRL performance, which they demonstrate through theory, experiments, and their proposed PEER algorithm.


## What is the main contribution of this paper?

 Based on my reading of the paper, here is a summary of the main contribution:

The paper theoretically and empirically investigates the inherent representation properties between a Q-network and its target network in deep reinforcement learning (DRL). 

The main theoretical contribution is proving that the representations of a Q-network and its target should satisfy a favorable "distinguishable representation property" - specifically, there should exist an upper bound on the similarity of their internal representations for adjacent time steps. 

Through experiments, the authors find that while some DRL methods (e.g. TD3) satisfy this property, others (e.g. CURL) violate it. They hypothesize that violating this property could negatively impact agent performance.

To address this, the paper proposes a simple yet effective "PEER" regularizer that explicitly regularizes the representation similarity, ensuring agents satisfy the distinguishable representation property. 

They prove a convergence guarantee for PEER and demonstrate its effectiveness - when combined with TD3, CURL, and DrQ, it achieves state-of-the-art performance on PyBullet, DMControl, and Atari environments.

In summary, the main contributions are:

- Theoretically demonstrating the desirable distinguishable representation property between Q-net and target

- Showing existing methods may violate this property and proposing the PEER regularizer to maintain it

- Proving convergence of PEER and demonstrating performance improvements when combined with various DRL algorithms

So in essence, the paper identifies and formalizes an important representation property and proposes a way to preserve it in order to improve DRL agent performance.
