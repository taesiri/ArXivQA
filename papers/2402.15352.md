# [On normalization-equivariance properties of supervised and unsupervised   denoising methods: a survey](https://arxiv.org/abs/2402.15352)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem Statement

The paper provides a comprehensive survey and comparative analysis of image denoising methods, which aim to estimate the original noise-free image from a noisy observation. Image denoising is a fundamental problem in image processing and computer vision. The paper focuses specifically on reviewing supervised deep learning methods as well as unsupervised methods for image denoising. It also discusses an important mathematical property called normalization-equivariance, which is desirable for denoising methods to have. 

Supervised Learning Methods

The paper first reviews the principle behind supervised learning for image denoising, which involves minimizing an empirical risk on training data consisting of pairs of clean and noisy images. It discusses the major neural network architectures that have been applied, including multi-layer perceptrons (MLPs), convolutional neural networks (CNNs), and transformers. For each architecture, a representative state-of-the-art denoising method is presented, such as DnCNN for CNNs. The parameter optimization techniques are also covered. An important practical issue regarding the lack of abundant clean training images is highlighted. To address this, the concept of weakly supervised learning with methods like Noise2Noise is introduced.

Unsupervised Learning Methods 

Next, the paper reviews several categories of unsupervised denoising approaches that rely solely on the noisy input image. These include weighted averaging methods like non-local means, sparsity-based methods, Bayesian methods with Gaussian modeling, and emerging deep learning-based techniques. Representative methods from each category are described, with BM3D highlighted as a widely used high-performance algorithm exploiting image self-similarity.

Normalization-Equivariance Analysis

A key contribution of the paper is the analysis of the normalization-equivariance properties satisfied by different denoising methods. This refers to a method's ability to properly account for intensity shifts and scalings in the input image. It is shown that many traditional methods exhibit this desirable property, while surprisingly most deep learning approaches currently do not. Architectural guidelines to make neural networks normalization-equivariant are provided.

In summary, the paper provides a comprehensive analysis of the state-of-the-art in image denoising across multiple methodological paradigms, with useful insights into mathematical properties and practical performance. It highlights open problems and opportunities for progress using deep learning while not neglecting more mature techniques.


## Summarize the paper in one sentence.

 Here is a one sentence summary of the paper:

This paper surveys supervised and unsupervised learning methods for image denoising, categorizes them based on their normalization-equivariance properties, summarizes their quantitative performance on standard benchmarks, and discusses challenges and promising future research directions in this field.


## What is the main contribution of this paper?

 This paper provides a comprehensive review and categorization of image denoising methods, both supervised and unsupervised. Some of the key contributions are:

1) It surveys major supervised learning approaches for image denoising, including multi-layer perceptrons, convolutional neural networks, and transformers, providing details on representative architectures like DnCNN, DRUNet, and SCUNet. 

2) It also reviews several categories of unsupervised methods - weighted averaging, sparsity-based, Bayesian, and deep learning methods. Key algorithms like non-local means, BM3D, EPLL, and Self2Self are discussed.  

3) The paper analyzes and summarizes the normalization-equivariance properties of various denoising methods. It shows that while most traditional methods satisfy scale-equivariance, neural networks often lack such properties.

4) Solutions are provided to make neural networks normalization-equivariant, like using affine convolutions and channel-wise sort pooling.

5) The methods are quantitatively compared and benchmarked on standard datasets. Trends and promising future research directions in the field are also identified and discussed.

In summary, the paper provides a structured taxonomy of denoising approaches, highlights equivariance issues in neural networks, and gives insights into recent progress and open challenges for further advancements.


## What are the keywords or key terms associated with this paper?

 Here are some of the key terms and concepts covered in this survey paper on image denoising:

- Supervised learning
    - Empirical risk minimization
    - Convolutional neural networks (CNNs)
    - Transformers
    - Parameter optimization via backpropagation and stochastic gradient descent

- Unsupervised learning 
    - Weighted averaging methods (e.g. bilateral filter, non-local means)
    - Sparsity methods (e.g. BM3D, KSVD) 
    - Bayesian methods with Gaussian models (e.g. EPLL, NL-Bayes)
    - Deep learning methods (e.g. Deep Image Prior, Self2Self)

- Weakly supervised learning
    - Learning from noisy image pairs (Noise2Noise)
    - Learning from single noisy images (SURE loss, blind-spot networks)

- Normalization equivariance
    - Scale equivariance
    - Shift equivariance 
    - Traditional vs deep learning-based denoisers

So in summary, the key terms cover the major approaches to image denoising (supervised, unsupervised, weakly supervised), prominent methods in each category, and an analysis of normalization equivariance properties.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 potential in-depth questions about the methods proposed in this paper:

1. The paper discusses both supervised and unsupervised learning strategies for image denoising. What are the key differences between these two approaches and what are the relative advantages and disadvantages of each? 

2. The paper categorizes image denoisers based on their normalization-equivariance properties. What does normalization-equivariance mean and why is this an important property for image denoisers to have?

3. The paper proposes using affine convolutions and channel-wise sort pooling to design normalization-equivariant neural networks. Explain in detail how these architectural modifications ensure normalization-equivariance. 

4. Transformers and attention mechanisms have shown promise for image denoising. Explain how the self-attention operation used in transformers can be viewed as a learned non-local means denoiser. What are the potential benefits of this approach?

5. The paper discusses weakly supervised learning approaches that aim to train neural networks without clean target images. Explain the Noise2Noise and Noise2Self methods and analyze why they may not achieve the same performance as fully supervised methods.  

6. Analyze the BM3D algorithm for image denoising. How does it exploit image self-similarity and what makes it an effective denoising technique?

7. Explain the concept of deep image prior and how it has been utilized for unsupervised image restoration. What are its connections to regularization by denoising methods?

8. Compare and contrast the EPLL and NL-Bayes algorithms for Bayesian image denoising. How does each method construct and exploit image priors for the denoising task? 

9. Explain how Stein's Unbiased Risk Estimate (SURE) can be used as a loss function to train neural networks on noisy images alone, without clean targets. What are limitations of this approach?

10. The paper suggests we may be reaching the limits of denoising performance. Do you agree? What open challenges remain in designing improved denoising algorithms?
