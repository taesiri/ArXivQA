# [On normalization-equivariance properties of supervised and unsupervised   denoising methods: a survey](https://arxiv.org/abs/2402.15352)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem Statement

The paper provides a comprehensive survey and comparative analysis of image denoising methods, which aim to estimate the original noise-free image from a noisy observation. Image denoising is a fundamental problem in image processing and computer vision. The paper focuses specifically on reviewing supervised deep learning methods as well as unsupervised methods for image denoising. It also discusses an important mathematical property called normalization-equivariance, which is desirable for denoising methods to have. 

Supervised Learning Methods

The paper first reviews the principle behind supervised learning for image denoising, which involves minimizing an empirical risk on training data consisting of pairs of clean and noisy images. It discusses the major neural network architectures that have been applied, including multi-layer perceptrons (MLPs), convolutional neural networks (CNNs), and transformers. For each architecture, a representative state-of-the-art denoising method is presented, such as DnCNN for CNNs. The parameter optimization techniques are also covered. An important practical issue regarding the lack of abundant clean training images is highlighted. To address this, the concept of weakly supervised learning with methods like Noise2Noise is introduced.

Unsupervised Learning Methods 

Next, the paper reviews several categories of unsupervised denoising approaches that rely solely on the noisy input image. These include weighted averaging methods like non-local means, sparsity-based methods, Bayesian methods with Gaussian modeling, and emerging deep learning-based techniques. Representative methods from each category are described, with BM3D highlighted as a widely used high-performance algorithm exploiting image self-similarity.

Normalization-Equivariance Analysis

A key contribution of the paper is the analysis of the normalization-equivariance properties satisfied by different denoising methods. This refers to a method's ability to properly account for intensity shifts and scalings in the input image. It is shown that many traditional methods exhibit this desirable property, while surprisingly most deep learning approaches currently do not. Architectural guidelines to make neural networks normalization-equivariant are provided.

In summary, the paper provides a comprehensive analysis of the state-of-the-art in image denoising across multiple methodological paradigms, with useful insights into mathematical properties and practical performance. It highlights open problems and opportunities for progress using deep learning while not neglecting more mature techniques.
