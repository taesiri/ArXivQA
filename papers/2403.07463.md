# [Backdoor Attack with Mode Mixture Latent Modification](https://arxiv.org/abs/2403.07463)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing backdoor attack methods in image classification models typically rely on modifying a significant number of parameters in the model in order to establish a connection between triggers and target labels. This makes the attacks more detectable as people become more aware of backdoor threats. The paper proposes a new insidious attack paradigm that only requires modifying the weights of the final layer of a trusted clean model, making it appear as minor fine-tuning while embedding backdoors.  

Proposed Solution:
The paper introduces a novel backdoor attack method called "mode mixture latent modification" that operates in the latent space of models. It utilizes the "mode mixture" phenomenon in generative models, where ambiguous samples are generated between modes. The method first identifies such mode mixture samples in the latent space around the target attack class using optimal transport mapping. These samples are then labeled as the attack target class and used to expand the decision boundary of the target class when retraining the final classifier layer. The modified model will then classify inputs optimized to approximate those mode mixture samples in the latent space as the target class.

Main Contributions:

- Proposes a highly stealthy attack paradigm that requires modifying only the final layer weights of a trusted clean image classifier 

- Introduces a novel backdoor attack method using mode mixture latent modification that operates in the latent space

- Identifies a potential application for the commonly avoided mode mixture phenomenon in generative models

- Achieves high attack success rate while modifying significantly fewer parameters compared to prior arts

- Demonstrates stealthiness against common defense methods like activation clustering, fine-pruning, STRIP and cognitive distillation

The new attack paradigm and method allows embedding backdoors via minimal parameter tweaking to avoid suspicion, while being resilient against defenses.
