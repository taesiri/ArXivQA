# [Audio-Visual Class-Incremental Learning](https://arxiv.org/abs/2308.11073)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the key research focus of this paper is exploring the effectiveness of joint audio-visual modeling in alleviating catastrophic forgetting in the context of class-incremental learning. Specifically, the paper introduces a new problem formulation called audio-visual class-incremental learning, where the model is trained on a sequence of tasks/classes containing both audio and visual data. The central hypothesis is that leveraging cross-modal audio-visual correlations can help mitigate catastrophic forgetting in this class-incremental setting. To test this, the paper proposes a novel method called AV-CIL which incorporates techniques like dual audio-visual similarity constraints and visual attention distillation to better preserve and leverage audio-visual relationships throughout the incremental training process.The paper then constructs three new audio-visual class-incremental datasets based on existing datasets like AVE, Kinetics-Sounds, and VGGSound. Through experiments on these datasets, the paper demonstrates that the proposed AV-CIL method significantly outperforms existing class-incremental learning techniques, validating the potential of joint audio-visual modeling to alleviate catastrophic forgetting in incremental learning scenarios.In summary, the key research question is whether audio-visual modeling can effectively mitigate catastrophic forgetting in class-incremental learning, which is tested through the proposal of the AV-CIL method and experiments on novel audio-visual class-incremental datasets.


## What is the main contribution of this paper?

Based on my reading of the paper appendix, the main contributions can be summarized as follows:1. The paper proposes a new problem setting called audio-visual class-incremental learning, which explores using joint audio-visual modeling to mitigate catastrophic forgetting in a class-incremental learning scenario. This is the first work studying audio-visual incremental learning.2. A method called AV-CIL is proposed to address the audio-visual class-incremental learning problem. It contains two main components:- Dual-Audio-Visual Similarity Constraint (D-AVSC) to preserve both instance-level and class-level cross-modal similarities between audio and visual modalities over the incremental steps.- Visual Attention Distillation (VAD) to enable the model to preserve previously learned audio-guided visual attentive abilities in future incremental steps. This prevents forgetting of learned audio-visual correlations.3. The paper constructs and experiments on three new audio-visual class-incremental datasets based on existing audio-visual datasets - AVE-CI, K-S-CI and VS100-CI. Results demonstrate the proposed AV-CIL significantly outperforms existing class-incremental learning methods on these datasets.In summary, the main contribution is proposing and addressing the novel problem of audio-visual class-incremental learning, through a method that utilizes audio-visual correlation preservation to mitigate catastrophic forgetting. The effectiveness is shown through new datasets and improved results over baselines.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a new audio-visual class-incremental learning method called AV-CIL that uses dual audio-visual similarity constraints and visual attention distillation to mitigate catastrophic forgetting and outperforms prior art on three new audio-visual incremental learning datasets.
