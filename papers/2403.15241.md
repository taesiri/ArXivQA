# [IS-Fusion: Instance-Scene Collaborative Fusion for Multimodal 3D Object   Detection](https://arxiv.org/abs/2403.15241)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
Existing multimodal 3D object detection approaches typically perform fusion at the entire bird's eye view (BEV) scene level during encoding. However, this ignores the inherent differences between foreground instances and background regions, leading to difficulties in capturing local context around objects or relying on additional networks for iterative refinement. It remains an open research question on how to simultaneously formulate the instance-level and scene-level contexts in a unified framework.

Method: 
This paper proposes a new multimodal detection framework called IS-Fusion that explores fusion at both the instance and scene levels. It contains two key modules:

1) Hierarchical Scene Fusion (HSF): Applies Point-to-Grid and Grid-to-Region transformer attentions to integrate multimodal features at different granularities (point, grid, region) to capture hierarchical scene context.

2) Instance-Guided Fusion (IGF): Identifies salient instance candidates and explores their relationships using self-attention. For each instance, it aggregates multimodal context features from the neighborhood using deformable attention. An Instance-to-Scene transformer attention then allows bi-directional propagation between instance and scene features.

By jointly modeling instance and scene representations, IS-Fusion facilitates more comprehensive feature learning compared to scene-level fusion alone. The interactions between instances and global scene also enhance the feature representations.

Contributions:
- Novel framework for fusing multimodal contexts at both instance and scene levels through dedicated modules
- Hierarchical scene modeling via Point-to-Grid and Grid-to-Region transformers 
- Instance modeling by exploring relationships and aggregating context
- Instance-Scene collaborations to improve overall feature representations

Experiments on nuScenes dataset demonstrate state-of-the-art detection accuracy, outperforming previous methods by 1-4% in mAP. This highlights the benefits of simultaneous instance and scene level fusion.
