# [Window-Based Early-Exit Cascades for Uncertainty Estimation: When Deep   Ensembles are More Efficient than Single Models](https://arxiv.org/abs/2303.08010)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be:How can we improve the trade-off between uncertainty estimation performance and computational cost for deep neural networks, especially compared to simply scaling up single models?More specifically, the authors investigate:- The uncertainty-computation trade-off for Deep Ensembles compared to scaling single models on tasks like selective classification, out-of-distribution detection, and selective classification with OOD data. - A novel window-based early exit approach to efficiently cascade Deep Ensembles that achieves superior uncertainty-computation trade-offs compared to single model scaling.The key hypotheses seem to be:- Deep Ensembles will be more efficient than single model scaling for uncertainty tasks at higher levels of computation.- Cascading Deep Ensembles using the proposed window-based early exit approach will achieve better uncertainty estimation for a given computational budget compared to simply scaling up single models.The experiments aim to validate these hypotheses across different CNN architectures, datasets, and operating thresholds. The central goal is improving the efficiency of uncertainty estimation using ensembles and adaptive inference.
