# [Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with   Monocular Videos](https://arxiv.org/abs/2308.10089)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we develop an effective method for non-rigid 3D reconstruction of generic object categories from monocular RGB videos, without relying on known camera poses, background-SfM, category-specific templates, or dense pose priors?The key ideas and contributions of the paper appear to be:- Proposing a method called Root Pose Decomposition (RPD) that estimates per-frame root poses by decomposing into local transformations and optimizing through non-rigid point registration. This allows handling large deformations without category-specific priors.- Demonstrating that RPD can be applied to challenging scenarios with multiple objects, occlusions, and individual differences by sharing a canonical space and adapting techniques like scaling factors.- Achieving state-of-the-art performance on datasets like DAVIS, OVIS, and AMA without needing known poses, SfM, or category-specific templates/embeddings.So in summary, the main research question is developing a method for generic non-rigid 3D reconstruction from monocular videos that does not rely on restrictive assumptions and category-specific priors. RPD is proposed to address this question and shown to be effective on diverse and challenging datasets.


## What is the main contribution of this paper?

This paper presents Root Pose Decomposition (RPD), a method for non-rigid 3D reconstruction from monocular RGB videos. The key ideas and contributions are:- RPD estimates per-frame root poses of objects without needing known camera poses, background-SfM, or category-specific pose priors like DensePose or CSE. This allows reconstruction of generic object categories. - RPD decomposes the per-frame root pose into a dense field of local transformations (rotations, translations, scaling). This provides flexibility to register points to the canonical space, enabling reconstruction even with large deformations.- RPD is the first to adapt non-rigid point registration techniques for monocular 3D reconstruction. It registers sampled points to the canonical space using chamfer loss and as-rigid-as-possible regularization.- RPD handles multi-object scenarios with occlusions and shape/scale differences between individuals. This is done via anti-occlusion loss and allowing local scaling transformations.- Experiments show RPD achieves state-of-the-art results on DAVIS, OVIS and AMA datasets, without needing category-specific priors. It generalizes to humans, animals, fish etc.In summary, the key contribution is a method to reconstruct articulate 3D models from monocular RGB videos of generic objects, without strong category-specific priors. This is achieved via root pose decomposition and point registration techniques.
