# [Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with   Monocular Videos](https://arxiv.org/abs/2308.10089)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question seems to be: How can we develop an effective method for non-rigid 3D reconstruction of generic object categories from monocular RGB videos, without relying on known camera poses, background-SfM, category-specific templates, or dense pose priors?The key ideas and contributions of the paper appear to be:- Proposing a method called Root Pose Decomposition (RPD) that estimates per-frame root poses by decomposing into local transformations and optimizing through non-rigid point registration. This allows handling large deformations without category-specific priors.- Demonstrating that RPD can be applied to challenging scenarios with multiple objects, occlusions, and individual differences by sharing a canonical space and adapting techniques like scaling factors.- Achieving state-of-the-art performance on datasets like DAVIS, OVIS, and AMA without needing known poses, SfM, or category-specific templates/embeddings.So in summary, the main research question is developing a method for generic non-rigid 3D reconstruction from monocular videos that does not rely on restrictive assumptions and category-specific priors. RPD is proposed to address this question and shown to be effective on diverse and challenging datasets.


## What is the main contribution of this paper?

This paper presents Root Pose Decomposition (RPD), a method for non-rigid 3D reconstruction from monocular RGB videos. The key ideas and contributions are:- RPD estimates per-frame root poses of objects without needing known camera poses, background-SfM, or category-specific pose priors like DensePose or CSE. This allows reconstruction of generic object categories. - RPD decomposes the per-frame root pose into a dense field of local transformations (rotations, translations, scaling). This provides flexibility to register points to the canonical space, enabling reconstruction even with large deformations.- RPD is the first to adapt non-rigid point registration techniques for monocular 3D reconstruction. It registers sampled points to the canonical space using chamfer loss and as-rigid-as-possible regularization.- RPD handles multi-object scenarios with occlusions and shape/scale differences between individuals. This is done via anti-occlusion loss and allowing local scaling transformations.- Experiments show RPD achieves state-of-the-art results on DAVIS, OVIS and AMA datasets, without needing category-specific priors. It generalizes to humans, animals, fish etc.In summary, the key contribution is a method to reconstruct articulate 3D models from monocular RGB videos of generic objects, without strong category-specific priors. This is achieved via root pose decomposition and point registration techniques.


## How does this paper compare to other research in the same field?

Here are some key ways this paper compares to other related research on non-rigid 3D reconstruction from monocular videos:- Does not rely on known camera poses or poses compensated by background SfM like many other methods. Instead, it proposes a new approach (Root Pose Decomposition) to estimate per-frame root poses without such dependencies. This makes it applicable to more casual videos.- Does not require category-specific shape templates or dense pose priors like some other methods. This makes it more generalizable to new object categories, rather than being limited to categories with existing templates like humans or quadrupeds.- Handles large object deformations and movements better than many existing methods that assume only small deformations or movements. The proposed decomposition into local transformations gives each point more flexibility to fit the canonical model.- Adapts to multi-object scenarios with occlusions and individual differences, unlike most other works that assume a single non-occluded object instance. This is useful for real-world scenes.- Leverages ideas from non-rigid point cloud registration in a new way for monocular 3D reconstruction. The use of point registration to optimize the local transformations is novel.- Achieves state-of-the-art results on challenging datasets like DAVIS, OVIS, and AMA without relying on the assumptions or priors used by other top methods.Overall, the key novelties and contributions are in proposing a new approach to estimate per-frame root poses in a category-agnostic way, handling complex deformations and motions, and adapting to multi-object scenarios. The results demonstrate this approachâ€™s potential for reconstructing diverse objects in the wild.
