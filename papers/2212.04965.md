# [Seeing a Rose in Five Thousand Ways](https://arxiv.org/abs/2212.04965)

## What is the central research question or hypothesis that this paper addresses?

 The central research question this paper addresses is how to recover the intrinsic properties (geometry, texture, material) of an object category from a single image containing a few instances of that object. The key hypothesis is that by modeling the intrinsic object properties separately from extrinsic factors like pose and lighting, a generative model can learn to capture the distribution of shapes, textures, and materials of an object category from very limited observations in a single image.

The paper proposes a method to learn such a generative model of object intrinsics, which enables synthesizing new object instances and rendering them under novel views and lighting. The model represents shape with a neural SDF, texture with a neural albedo field, and material as a shininess parameter. It renders images using a differentiable physical renderer with sampled poses. The model components are trained adversarially to match the distribution of rendered images to that of the observed instances. 

The central research questions are:
(1) Can intrinsic object properties like shape and albedo be disentangled and learned from limited observations in a single image? 
(2) Can a generative model exploit such disentanglement of intrinsics and extrinsics to learn from limited data?
(3) Does modeling object intrinsics enable better generalization for reconstruction and synthesis compared to methods without such inductive biases?

The experiments aim to demonstrate the model's ability to capture object intrinsics and synthesize novel views and instances better than previous methods, thereby providing evidence for the hypotheses.
