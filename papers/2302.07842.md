# Augmented Language Models: a Survey

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the main research question seems to be:How can language models be augmented with reasoning abilities and the capability to use tools in order to improve their performance on complex language understanding and reasoning tasks? The authors review recent works that aim to enhance language models by equipping them with reasoning skills (e.g. via prompting the model to show its reasoning step-by-step) and tools (e.g. access to search engines, calculators, etc). They introduce the concept of "Augmented Language Models" (ALMs) to refer to language models that leverage such augmentations, and map out the landscape of existing approaches according to axes like how reasoning and tools are implemented (heuristics vs learned) and whether they focus more on reasoning or acting skills. The overarching hypothesis seems to be that augmenting language models in these ways will allow them to solve a broader range of complex tasks that require combining reasoning, knowledge, and action, while retaining strong language modeling capabilities. The authors conclude that this is a promising research direction to overcome limitations like brittleness, lack of interpretability, and need for massive scale in current LLMs.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contributions are:1. It provides a comprehensive survey and taxonomy of recent work on augmenting language models with reasoning skills and the ability to use tools. The paper categorizes these "augmented language models" (ALMs) along three main dimensions: reasoning abilities, use of tools/acting, and how these skills are acquired (e.g. via heuristics, supervision, or reinforcement).2. It proposes definitions for key terms like "reasoning", "tool", and "act" in the context of ALMs. Reasoning is defined as decomposing complex tasks into simpler subtasks. Tools refer to external modules that can be called by the LM to augment its context. Acting refers to tools that allow the LM to take actions and have effects on the virtual or physical world.3. The paper argues that equipping LMs with reasoning and tools moves beyond pure language modeling, as the models are no longer just predicting the next token based on a fixed-length context window. Instead, ALMs can expand their context in more flexible ways before generating outputs.4. It highlights the potential benefits of ALMs compared to traditional LMs, in terms of truthfulness, uncertainty estimation, interpretability, and enhanced capabilities by leveraging reasoning and diverse tools. But it also notes ethical concerns related to credibility and potential harms if actions are taken without human oversight.5. The survey aggregates results across a wide variety of recent papers at the intersection of language models, reasoning, and tool use. This provides a unified lens on an emerging research area and can inform future work on developing more capable and safer ALMs.In summary, the key contribution is providing a structured overview of the growing literature on augmented language models, along with analysis of their potential benefits and limitations compared to standard language models. The paper helps carve out ALMs as a distinct research direction Going beyond pure language modeling.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Based on my reading of the paper, here is a one sentence TL;DR summary: The paper surveys recent work on augmenting language models with reasoning skills and the ability to use tools, departing from the standard language modeling paradigm.
