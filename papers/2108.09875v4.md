# [Anarchic Federated Learning](https://arxiv.org/abs/2108.09875v4)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading, the central research question this paper addresses is:

How to design federated learning algorithms that can converge and achieve good performance even when workers behave in an "anarchic" fashion - i.e. they participate in training asynchronously at will, perform heterogeneous amounts of local computation, and are completely uncontrolled by the central server?

The key hypothesis is that it is possible to develop such "anarchic federated learning" algorithms that converge to an optimal solution at nearly the same rate as conventional federated learning algorithms that rely on tight server-worker control and coordination. 

Specifically, the paper proposes two "anarchic federated averaging" (AFA) algorithms for cross-device and cross-silo settings. It hypothesizes these AFA algorithms can achieve convergence rates and linear speedup comparable to state-of-the-art federated learning algorithms, despite the anarchic worker behaviors. The theoretical analysis and experiments aim to validate this hypothesis.

In summary, the central research question is how to design convergent federated learning algorithms under anarchic worker behaviors, with the hypothesis that convergent AFA algorithms with optimal convergence rates can be developed.


## What is the main contribution of this paper?

 Based on my reading, the main contributions of this paper are:

1. It proposes a new federated learning paradigm called "Anarchic Federated Learning" (AFL). In contrast to conventional federated learning where the server tightly controls and coordinates the workers, in AFL the workers have complete freedom to participate in training whenever they want and perform varying numbers of local steps based on their own situations. This loose coupling between server and workers makes AFL more suitable for edge network deployments.

2. It develops two algorithms called Anarchic Federated Averaging (AFA-CD and AFA-CS) for cross-device and cross-silo AFL settings. The paper proves that under some mild assumptions, both AFA algorithms achieve convergence rates matching the state-of-the-art algorithms for conventional federated learning. Specifically, they retain the desirable "linear speedup effect" in terms of number of workers and local steps.

3. It provides a fundamental lower bound on the convergence error for any AFL algorithm under general worker arrival processes. This bound captures the inherent heterogeneity and randomness in AFL systems.

4. For the AFA-CS algorithm in the cross-silo setting, the paper shows it is possible to leverage historical information and variance reduction techniques to eliminate the convergence error and achieve an even faster rate that depends on the total number of workers. 

5. Extensive experiments validate the proposed AFA algorithms and demonstrate their robustness under various asynchronous and heterogeneous conditions. The results also show AFA can integrate advanced federated learning techniques like FedProx and SCAFFOLD for further performance gains.

In summary, the key innovation is proposing the anarchic federated learning paradigm to better suit edge network environments. The paper provides important algorithmic and theoretical results demonstrating this new paradigm can work efficiently while retaining key benefits like linear speedup.
