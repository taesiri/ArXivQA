# [Improving Document Representations by Generating Pseudo Query Embeddings   for Dense Retrieval](https://arxiv.org/abs/2105.03599)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading, the central research question this paper addresses is: How can we improve the effectiveness of bi-encoder based dense retrieval models for document ranking?Specifically, the paper proposes a method to address the limitation that bi-encoders encode documents independently without knowledge of the query, which can cause important semantic information to be missed. The key ideas are:1) Generate multiple "pseudo query embeddings" for each document that mimic potential real queries. This is done by clustering the document token embeddings using k-means and treating the cluster centroids as pseudo queries. 2) During inference, aggregate the pseudo query embeddings using a softmax function and compute relevance with the real query embedding.3) Optimize the aggregation step to work efficiently with approximate nearest neighbor search.The main hypothesis is that representing documents with multiple pseudo query embeddings tailored to that document will enrich the encoding and improve retrieval accuracy compared to baseline bi-encoders. Experiments on document ranking datasets aim to validate this hypothesis.In summary, the paper proposes a novel method to create more informative document representations for bi-encoder based dense retrieval by generating pseudo queries, and evaluates this approach on standard benchmarks.


## What is the main contribution of this paper?

Based on my reading of the paper introduction, the main contributions of this paper are:1. They propose a novel approach to represent documents with multiple "pseudo query embeddings" generated by a clustering process. The pseudo query embeddings aim to mimic potential real queries that could be asked about the document. 2. They modify the embedding aggregation during inference to allow utilization of off-the-shelf approximate nearest neighbor (ANN) search libraries for efficiency. This involves a two-step scoring process.3. They conduct experiments on several information retrieval and open domain QA datasets. The results show their approach achieves state-of-the-art retrieval performance while maintaining computational efficiency. 4. They provide an analysis of gradients to give insight into how the cluster centroid embeddings improve performance over other embedding approaches.In summary, the key ideas are using clustering to generate better document representations in the form of pseudo queries, optimizing the scoring to leverage ANN search, and demonstrating improved results over prior work on multiple standard retrieval benchmarks. The gradient analysis provides some explanatory analysis into why their technique is effective.


## What is the TL;DR (Too Long, Didn't Read) version of the paper? If you had to summarize it in one sentence, what would that be?

Here is a one sentence summary of the key points from the paper:The paper proposes a novel dense retrieval model that generates multiple pseudo query embeddings for each document through clustering, allowing it to better represent documents by capturing distinct topics/aspects, and achieves state-of-the-art retrieval performance while remaining efficient by optimizing the matching function for fast approximate nearest neighbor search.


## How does this paper compare to other research in the same field?

This paper proposes a new method for improving document representations in dense passage retrieval systems. Here are some key ways it compares to other related work:- It focuses on improving the effectiveness of bi-encoders for first-stage retrieval, while maintaining efficiency. Many recent works have explored cross-encoders or late interaction methods to improve accuracy, but bi-encoders are still preferred for large-scale retrieval due to their efficiency.- It addresses the query-agnostic limitation of bi-encoders by generating multiple "pseudo query embeddings" for each document via clustering. This is a novel way to make the document encoding aware of potential queries. It contrasts with prior work like Poly-Encoder that uses a fixed set of global embeddings.- The pseudo query generation process is inspired by and analogous to K-means clustering. Connecting it to this classic technique lends some theoretical justification.- For retrieval speed, it optimizes the scoring function to work directly with ANN search libraries like Faiss. Many papers use Faisa but don't customize the scoring for it.- Experiments show state-of-the-art results on MS MARCO and OpenQA compared to other first-stage retrieval methods. The gains are especially large on datasets like SQuAD with many queries per document.- Analysis of the loss gradient gives insight into why the cluster centroids improve effectiveness over other embedding sets like first-k tokens.Overall, this paper makes an important contribution in improving bi-encoder representations for dense retrieval in a novel way, while still allowing efficient retrieval. The connections to clustering and analysis of the approach's strengths are also assets of the work.
