# [Training Differentially Private Ad Prediction Models with Semi-Sensitive   Features](https://arxiv.org/abs/2401.15246)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem Statement
- Motivated by digital advertising applications, the paper introduces the problem of training machine learning models with differential privacy guarantees when there is a subset of "semi-sensitive" features. 
- Specifically, some features are known to the adversary (non-sensitive) while others are unknown (sensitive), in addition to the sensitive labels.  
- This setting interpolates between full differential privacy (all features and labels sensitive) and label differential privacy (all features public, only labels sensitive).

Proposed Solution
- The paper presents a new algorithm called Hybrid for training models with semi-sensitive features. 
- Hybrid has two phases - a label DP phase using randomized response on the non-sensitive features, and a DP-SGD phase training the full model.
- The privacy budget is split between the two phases, with more budget assigned to the randomized response phase for small overall budgets.

Experiments
- Hybrid is evaluated on two ads datasets - Criteo click prediction and a proprietary conversion prediction dataset.
- It is compared to two baselines: (1) DP-SGD on all features, (2) Randomized response on non-sensitive features.
- Across privacy budgets, Hybrid provides improved utility over both baselines on the real-world datasets.
- The gap widens at higher privacy budgets when DP-SGD has more budget.

Main Contributions
- Formalization of the problem of DP learning with semi-sensitive features
- A new Hybrid algorithm for training in this setting
- Experiments on ads datasets demonstrating improved utility over natural baselines

The paper provides a practical solution for an important setting where both public and private features need to be utilized in model training with formal privacy guarantees.


## Summarize the paper in one sentence.

 This paper introduces the task of training differentially private machine learning models with semi-sensitive features, where a subset of features is known to the attacker while the remaining features and label should be protected, and presents an algorithm that outperforms baselines on real ad prediction datasets.


## What is the main contribution of this paper?

 The main contribution of this paper is presenting an algorithm for training differentially private machine learning models with semi-sensitive features. Specifically:

- The paper formalizes the setting of "DP learning with semi-sensitive features", where a subset of the features is known to the adversary (and thus does not need to be protected) while the remaining features and the labels should be protected with DP guarantees. This setting interpolates between full DP (where all features and labels are protected) and label DP (where only the labels need to be protected).

- The paper presents a new algorithm, referred to as Hybrid, for training DP models with semi-sensitive features. The Hybrid algorithm has two phases - a label DP phase using randomized response, and a DP-SGD phase. 

- Through an empirical evaluation on real ad prediction datasets, the paper shows that the Hybrid algorithm surpasses in utility (measured by relative AUC loss) the baselines of (i) DP-SGD trained on all features, and (ii) a label DP algorithm trained only on the known features.

So in summary, the main contribution is proposing and empirically evaluating a method for training DP machine learning models in the semi-sensitive features setting, which interpolates between full DP and label DP.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Differential privacy (DP)
- Semi-sensitive features 
- Label differential privacy
- Stochastic gradient descent (SGD)
- Differentially private SGD (DP-SGD)
- Randomized response (RR)  
- Model utility 
- Click-through rate (pCTR) 
- Conversion rate (pCVR)
- Ad prediction models
- Attribution modeling
- Privacy budget

The paper introduces the concept of "DP learning with semi-sensitive features", which refers to a machine learning setting where some features are known to an adversary (non-sensitive) while others need to be protected (sensitive). It presents an algorithm called Hybrid that combines label DP (using randomized response on the non-sensitive features) and DP-SGD (on all features) to train models with better utility than baseline methods. The empirical evaluation uses real-world advertising datasets to predict pCTR and pCVR under a privacy budget. So in summary, the key focus is on differentially private training of ad prediction models with a mix of sensitive and non-sensitive features.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions I generated about the method proposed in the paper:

1. The paper introduces a new notion of "semi-sensitive features" for differentially private machine learning. How is this notion defined formally? How does it compare to the traditional notions of "fully sensitive" and "non-sensitive" features?

2. The algorithm proposed has two phases - a label differential privacy (DP) phase and a DP-SGD phase. What is the motivation behind this two-phase approach? Why is running DP-SGD on all features not sufficient?

3. In the label DP phase, the sensitive features are removed and randomized response is applied on the labels. How exactly is the bias from randomized response accounted for during training? 

4. The precise budget split between the two phases is set based on empirical evaluations. What is the high-level intuition behind the budget split rule chosen in the paper? How does varying this split impact utility?

5. For user-level DP, the paper transforms the algorithm using the group privacy guarantee. What privacy accounting technique is used to determine the user-level privacy guarantee formally?

6. On the Criteo dataset, the paper designates certain integer and categorical features arbitrarily as "sensitive." In practice, how would one determine which features are indeed sensitive and need protection? 

7. The results demonstrate improved utility over DP-SGD and randomized response baselines. Is there a theoretical argument one can make regarding why the two-phase algorithm should outperform these baselines?

8. The paper focuses on semi-sensitive features, whereas a concurrent work explores "partially sensitive" features. How does this related notion compare to semi-sensitive features? When would one framework be preferred over the other?

9. What kinds of ad prediction tasks is this framework best suited for? When would you prefer full DP or label DP instead for ads modeling?

10. The algorithm and experiments focus on training neural network models. How can the overall approach be adapted to other model families like tree or linear models? What may be some challenges there?
