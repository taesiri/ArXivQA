# [Inverse Scaling: When Bigger Isn't Better](https://arxiv.org/abs/2306.09479)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question/hypothesis seems to be:Is there evidence that language models can exhibit "inverse scaling" - i.e. worse task performance with increased model scale (size, data, compute) - and if so, what are the potential causes and implications of this phenomenon?The authors investigate this question by running a public contest to collect examples of inverse scaling tasks, analyzing the submitted tasks to identify common causes, and discussing the implications of their findings. The key hypotheses are:1) Inverse scaling exists and can be demonstrated through carefully constructed tasks. 2) There are identifiable common causes of inverse scaling like strong priors, unwanted imitation of data, distractor tasks, and spurious correlations in few-shot examples.3) Inverse scaling indicates issues with the language modeling training objective as a proxy for real-world performance, and more care is needed in designing objectives, data, and model scale.4) Studying inverse scaling can shed light on emergent model behaviors and lead to more reliable predictions about future model capabilities.In summary, the central research question is investigating whether inverse scaling occurs and is important, what causes it, and what we can learn from it about improving language models. The contest and analysis aims to provide evidence for the existence, causes, and implications of inverse scaling.


## What is the main contribution of this paper?

Based on my reading of the paper, the main contribution seems to be:The paper presents evidence for the phenomenon of "inverse scaling" in large language models (LMs), where task performance gets worse as the models are scaled up in terms of size, data, and compute. This is in contrast to the more commonly observed result that scaling up LMs leads to improved performance. The key contributions are:- Running a public contest (The Inverse Scaling Prize) to collect examples of inverse scaling tasks. 11 prize-winning datasets are presented that show robust inverse scaling across multiple model series.- Identifying and analyzing 4 main causes of inverse scaling: strong priors, unwanted imitation, distractor tasks, and spurious few-shot examples. The prize-winning tasks are categorized under these causes.- Reviewing other examples of inverse scaling trends from the literature and relating them to the hypothesized causes.- Highlighting the discovery of U-shaped and inverted-U scaling trends, where performance first gets worse then improves (or vice versa) with increasing scale. This suggests scaling trends are less predictable than previously thought.- Arguing that the results indicate more care is needed in designing training data and objectives for large LMs, since simply scaling up may not lead to progress on some tasks.In summary, the main contribution is providing evidence for inverse scaling across a range of tasks, analyzing the potential causes, and highlighting that scaling trends can be unpredictable - all suggesting that further research is needed on understanding and mitigating such issues. The release of the inverse scaling datasets is also an important resource for future investigation.
