# [Inverse Scaling: When Bigger Isn't Better](https://arxiv.org/abs/2306.09479)

## What is the central research question or hypothesis that this paper addresses?

Based on my reading of the paper, the central research question/hypothesis seems to be:Is there evidence that language models can exhibit "inverse scaling" - i.e. worse task performance with increased model scale (size, data, compute) - and if so, what are the potential causes and implications of this phenomenon?The authors investigate this question by running a public contest to collect examples of inverse scaling tasks, analyzing the submitted tasks to identify common causes, and discussing the implications of their findings. The key hypotheses are:1) Inverse scaling exists and can be demonstrated through carefully constructed tasks. 2) There are identifiable common causes of inverse scaling like strong priors, unwanted imitation of data, distractor tasks, and spurious correlations in few-shot examples.3) Inverse scaling indicates issues with the language modeling training objective as a proxy for real-world performance, and more care is needed in designing objectives, data, and model scale.4) Studying inverse scaling can shed light on emergent model behaviors and lead to more reliable predictions about future model capabilities.In summary, the central research question is investigating whether inverse scaling occurs and is important, what causes it, and what we can learn from it about improving language models. The contest and analysis aims to provide evidence for the existence, causes, and implications of inverse scaling.
