# [Not Just Change the Labels, Learn the Features: Watermarking Deep Neural   Networks with Multi-View Data](https://arxiv.org/abs/2403.10663)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the paper:

Problem:
- Deep neural networks (DNNs) are being widely deployed using Machine Learning as a Service (MLaaS) platforms. However, there is a risk of attackers stealing the functionality of DNN models using black-box attacks like model extraction. 

- Existing watermarking methods using trigger sets are still vulnerable to such functionality stealing attacks. The labels assigned to the trigger set often lack correlation with the actual image content, making it challenging to transfer predictions on the trigger set from the source model to a stolen surrogate model.

Proposed Solution:
- The paper provides a new perspective on trigger set-based watermarking based on feature learning. It shows that using multi-view data, which exhibits diverse features, as the trigger set can enable transferring predictions more effectively.

- A trigger set selection method is introduced to identify multi-view data from the source dataset based on logit margin loss. Samples close to the decision boundary tend to possess multi-view features.

- A feature regularization loss is added while training the source model to enhance learning of the features associated with the label assigned to each trigger set sample.

- Together, these enable the source model's predictions on the trigger set to be preserved even in a stolen surrogate model. Ownership can then be verified by checking if the surrogate model predicts the intended labels on the trigger set.

Main Contributions:

- Provides a new perspective on trigger set-based watermarking based on feature learning and transferability of predictions using multi-view trigger sets.

- Introduces an efficient trigger set selection method to identify multi-view data based on logit margin loss.

- Incorporates a feature regularization loss to enhance feature learning on the trigger set.

- Achieves superior defense against functionality stealing attacks compared to prior arts, even when attackers use entirely different surrogate datasets and architectures.

In summary, the paper presents an effective DNN watermarking approach called MAT based on using multi-view trigger sets. This facilitates ownership verification even after black-box model extraction attacks.


## Summarize the paper in one sentence.

 Here is a one-sentence summary of the paper:

The paper proposes a new deep neural network watermarking method called MAT that constructs a trigger set comprising multi-view data exhibiting distinct features and incorporates feature regularization during training to effectively defend against functionality stealing attacks.


## What is the main contribution of this paper?

 According to the paper, the main contributions are:

1. It presents a novel perspective on trigger set-based watermarking methods, aiming to understand the conditions under which trigger set-based watermarking can effectively defend model extraction attacks. This perspective of using multi-view data as the trigger set is novel in understanding trigger set-based watermarking.

2. It introduces an efficient trigger set-based watermarking approach called MAT by constructing the trigger set with multi-view data. The proposed method is simple to implement and does not require changes to model architectures or the training process.  

3. It evaluates MAT against various attack methods and shows that MAT enables reliable ownership identification in situations where baseline methods fail. The experiments demonstrate the efficacy of MAT in defending against model extraction attacks and even white-box attacks like fine-tuning and pruning.

In summary, the key innovation is the use of multi-view data for the trigger set along with a feature regularization method to encourage learning the features of the trigger set. This allows MAT to effectively watermark models and defend against attacks trying to remove the watermark.


## What are the keywords or key terms associated with this paper?

 Based on my reading of the paper, some of the key terms and concepts are:

- Deep neural network watermarking - The paper focuses on methods for watermarking deep neural networks to enable ownership verification and protect intellectual property. 

- Trigger set - A selected set of samples with labels modified, used to watermark a model. Predictions on this set can verify if a model has been stolen.

- Multi-view data - Data exhibiting multiple distinct features that can be leveraged for classification. The paper proposes using this as an effective trigger set.  

- Model extraction attack - An attack method that trains a surrogate model to replicate the functionality of a source model, enabling model theft. Defending this is a key focus.

- Feature learning - The paper provides a perspective on trigger sets and watermarking based on what features a model learns to use for classification. This viewpoint informs their proposed method.

- Feature regularization - A regularization technique introduced in the paper to enhance a model's learning of desired features from the trigger set.

- Ownership verification - Validating if a suspected model reproduces the functionality of a source model by checking predictions on the trigger set. Critical for intellectual property protection.

In summary, the key focus is on watermarking models and defending model extraction attacks through the use of multi-view trigger sets and feature regularization. Ownership verification is enabled via the trigger set.


## Design 10 in-depth questions about the method proposed in this paper and avoid simple questions.

 Here are 10 in-depth questions about the method proposed in this paper:

1. The paper proposes a novel perspective on trigger set-based watermarking based on feature learning. Can you elaborate on this perspective and how it helps explain when trigger set-based watermarking can effectively defend model extraction attacks?

2. The paper selects the trigger set based on logit margin loss. Why is this an effective strategy for choosing multi-view data as the trigger set? How does it relate to capturing samples close to the decision boundary that exhibit features from multiple classes?

3. The paper incorporates a feature regularization loss when training the source model. Explain the intuition behind this loss and how it enhances the model's capability to learn the desired features from the trigger set. 

4. The proposed method does not require the surrogate data to match the distribution of the source data. Explain why the method can still effectively transfer predictions on the trigger set even when using heterogeneous surrogate data.

5. How does the labeling strategy for the trigger set aid in transferring predictions to the surrogate model? Why is choosing the label that maximizes confusion effective?

6. The paper examines white-box attacks like fine-tuning and fine-pruning. Analyze the results presented and discuss why the proposed method exhibits greater robustness compared to baselines in defending such attacks.

7. What is the impact of the balance parameter Î± in the feature regularization loss? Explain the trade-off between clean accuracy and watermarking capability when tuning this parameter.

8. The size of the trigger set is varied in experiments. Discuss the results obtained and reasons behind the decline in trigger set accuracy as more samples are added. 

9. An alternative feature regularization strategy is explored pushing features away from rather than towards the assigned label. Compare and contrast the two strategies.

10. The method leverages a hypothesis test for ownership verification. Elaborate on this pipeline and how it allows defenders to reliably assert ownership of suspicious models.
