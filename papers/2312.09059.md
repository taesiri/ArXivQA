# [Auto-Prox: Training-Free Vision Transformer Architecture Search via   Automatic Proxy Discovery](https://arxiv.org/abs/2312.09059)

## Write a very high-quality paragraph summarizing the paper that effectively covers the paper.

 Here is a high-quality paragraph summarizing the key points of the paper:

This paper proposes Auto-Prox, a novel framework for automatically discovering effective zero-cost proxies to enable efficient training-free vision transformer (ViT) architecture search. A major limitation of existing training-free methods is the reliance on manually designed proxies that lack generalizability across tasks. To address this, the authors first construct a ViT benchmark (ViT-Bench-101) containing diverse architectures and performance metrics across multiple datasets. Leveraging this, they define a comprehensive search space of potential zero-cost proxies, representing candidates as computation graphs over ViT statistics and mathematical operations. A joint correlation metric is introduced as the objective to search for proxies that generalize well across datasets. An evolutionary approach is employed, augmented with an elitism-preservation strategy to prevent deterioration. Experiments demonstrate that Auto-Prox discovers high-quality proxies surpassing state-of-the-art methods in both cross-dataset ranking correlation and downstream model accuracy after architecture search. The method provides an automated and efficient way to find effective proxies for training-free ViT search that transfers well across varying domains.
