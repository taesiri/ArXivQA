# [Benchmarking the Spectrum of Agent Capabilities](https://arxiv.org/abs/2109.06780v2)

## What is the central research question or hypothesis that this paper addresses?

 Based on my reading of the paper text, it seems the central research question is: how to develop a benchmark environment that can efficiently evaluate a wide spectrum of general agent abilities within a single environment. 

The key hypotheses appear to be:

- Procedural generation of diverse, complex worlds requires agents to display strong generalization abilities.

- A technology tree with multiple levels evaluates wide and deep exploration.

- Sparse rewards for semantically meaningful achievements poses challenges for temporal credit assignment.

- Partial observability encourages agents to build useful memory and representations. 

- Meaningful evaluation metrics can be defined based on success rates for unlocking achievements that correspond to important milestones in capability.

The paper introduces Crafter as a benchmark environment that aims to test these hypotheses by posing the listed challenges to current reinforcement learning methods. The goal is to accelerate research progress on building generally capable agents by quickly evaluating a diverse range of abilities within a single environment.
