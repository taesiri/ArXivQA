# [Turn Waste into Worth: Rectifying Top-$k$ Router of MoE](https://arxiv.org/abs/2402.12399)

## Write a very high-quality and detailed summary of the paper that describes the paper in a way that a human can fully understand. The summary should cover the problem, the proposed solution and highlight the main contributions of the paper.

 Here is a detailed summary of the key points from the paper:

Problem:
- Sparse Mixture-of-Experts (MoE) models use a top-k router for computational efficiency. However, this leads to two issues - dropped tokens when an expert reaches capacity and padding when experts receive fewer tokens than capacity.
- Dropped tokens represent lost computation and degrade performance. Padding represents redundant computation which is inefficient.

Proposed Solution: 
- Introduce Rectify-Routers to post-process the outputs of the top-k router and handle dropped tokens and padding.

- Intra-GPU Rectification routes dropped tokens to other experts in the same GPU to avoid expensive inter-GPU communication. This leverages unused capacity to process dropped tokens.

- Fill-in Rectification replaces padding tokens with non-routed tokens that have high routing scores. This allocates computation to more useful tokens rather than padding.

Main Contributions:
- Concept of Rectify-Routers to post-process the outputs of top-k routing and mitigate issues with dropped tokens and padding.

- Intra-GPU Rectification efficiently handles dropped tokens by routing them within the GPU. Improves performance over vanilla top-k routing.

- Fill-in Rectification specifically addresses the problem of padding by replacing padding with useful tokens. Outperforms vanilla top-k.

- Combing the two Rectify-Routers gives the best performance, improving 4.7% over vanilla top-1 routing. The methods are robust across various expert settings.

- Rectify-Routers are still effective without the load balance loss used to improve routing balance. This demonstrates their ability to directly handle routing issues.
