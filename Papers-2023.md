
### November 2023
- GENOME: GenerativE Neuro-symbOlic visual reasoning by growing and   reusing ModulEs - [[Arxiv](https://arxiv.org/abs/2311.04901)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04901.md)]
- TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models - [[Arxiv](https://arxiv.org/abs/2311.04589)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04589.md)]
- NExT-Chat: An LMM for Chat, Detection and Segmentation - [[Arxiv](https://arxiv.org/abs/2311.04498)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04498.md)]
- LRM: Large Reconstruction Model for Single Image to 3D - [[Arxiv](https://arxiv.org/abs/2311.04400)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04400.md)]
- 3DiffTection: 3D Object Detection with Geometry-Aware Diffusion Features - [[Arxiv](https://arxiv.org/abs/2311.04391)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04391.md)]
- Holistic Evaluation of Text-To-Image Models - [[Arxiv](https://arxiv.org/abs/2311.04287)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04287.md)]
- OtterHD: A High-Resolution Multi-modality Model - [[Arxiv](https://arxiv.org/abs/2311.04219)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04219.md)]
- Video Instance Matting - [[Arxiv](https://arxiv.org/abs/2311.04212)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04212.md)]
- I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2311.04145)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04145.md)]
- Unveiling Safety Vulnerabilities of Large Language Models - [[Arxiv](https://arxiv.org/abs/2311.04124)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04124.md)]
- mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with   Modality Collaboration - [[Arxiv](https://arxiv.org/abs/2311.04257)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04257.md)]
- Everything of Thoughts: Defying the Law of Penrose Triangle for Thought   Generation - [[Arxiv](https://arxiv.org/abs/2311.04254)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04254.md)]
- Leveraging Large Language Models for Automated Proof Synthesis in Rust - [[Arxiv](https://arxiv.org/abs/2311.03739)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.03739.md)]
- Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent   Learning - [[Arxiv](https://arxiv.org/abs/2311.03736)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.03736.md)]
- Random Field Augmentations for Self-Supervised Representation Learning - [[Arxiv](https://arxiv.org/abs/2311.03629)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.03629.md)]
- SoundCam: A Dataset for Finding Humans Using Room Acoustics - [[Arxiv](https://arxiv.org/abs/2311.03517)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.03517.md)]
- GLaMM: Pixel Grounding Large Multimodal Model - [[Arxiv](https://arxiv.org/abs/2311.03356)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.03356.md)]
- CoVLM: Composing Visual Entities and Relationships in Large Language   Models Via Communicative Decoding - [[Arxiv](https://arxiv.org/abs/2311.03354)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.03354.md)]
- Ziya2: Data-centric Learning is All LLMs Need - [[Arxiv](https://arxiv.org/abs/2311.03301)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.03301.md)]
- S-LoRA: Serving Thousands of Concurrent LoRA Adapters - [[Arxiv](https://arxiv.org/abs/2311.03285)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.03285.md)]
- LDM3D-VR: Latent Diffusion Model for 3D VR - [[Arxiv](https://arxiv.org/abs/2311.03226)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.03226.md)]
- CogVLM: Visual Expert for Pretrained Language Models - [[Arxiv](https://arxiv.org/abs/2311.03079)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.03079.md)]
- Can LLMs Follow Simple Rules? - [[Arxiv](https://arxiv.org/abs/2311.04235)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04235.md)]
- Co-training and Co-distillation for Quality Improvement and Compression   of Language Models - [[Arxiv](https://arxiv.org/abs/2311.02849)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.02849.md)]
- Consistent4D: Consistent 360Â° Dynamic Object Generation from   Monocular Video - [[Arxiv](https://arxiv.org/abs/2311.02848)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.02848.md)]
- Tailoring Self-Rationalizers with Multi-Reward Distillation - [[Arxiv](https://arxiv.org/abs/2311.02805)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.02805.md)]
- Attention or Convolution: Transformer Encoders in Audio Language Models   for Inference Efficiency - [[Arxiv](https://arxiv.org/abs/2311.02772)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.02772.md)]
- VR-NeRF: High-Fidelity Virtualized Walkable Spaces - [[Arxiv](https://arxiv.org/abs/2311.02542)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.02542.md)]
- Levels of AGI: Operationalizing Progress on the Path to AGI - [[Arxiv](https://arxiv.org/abs/2311.02462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.02462.md)]
- Ultra-Long Sequence Distributed Transformer - [[Arxiv](https://arxiv.org/abs/2311.02382)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.02382.md)]
- MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning - [[Arxiv](https://arxiv.org/abs/2311.02303)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.02303.md)]
- Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs - [[Arxiv](https://arxiv.org/abs/2311.02262)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.02262.md)]
- EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via   Self-Supervision - [[Arxiv](https://arxiv.org/abs/2311.02077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.02077.md)]
- PPTC Benchmark: Evaluating Large Language Models for PowerPoint Task   Completion - [[Arxiv](https://arxiv.org/abs/2311.01767)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.01767.md)]
- FLAP: Fast Language-Audio Pre-training - [[Arxiv](https://arxiv.org/abs/2311.01615)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.01615.md)]
- Idempotent Generative Network - [[Arxiv](https://arxiv.org/abs/2311.01462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.01462.md)]
- RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning   via Generative Simulation - [[Arxiv](https://arxiv.org/abs/2311.01455)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.01455.md)]
- FlashDecoding++: Faster Large Language Model Inference on GPUs - [[Arxiv](https://arxiv.org/abs/2311.01282)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.01282.md)]
- E3 TTS: Easy End-to-End Diffusion-based Text to Speech - [[Arxiv](https://arxiv.org/abs/2311.00945)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00945.md)]
- RoboVQA: Multimodal Long-Horizon Reasoning for Robotics - [[Arxiv](https://arxiv.org/abs/2311.00899)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00899.md)]
- In-Context Prompt Editing For Conditional Audio Generation - [[Arxiv](https://arxiv.org/abs/2311.00895)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00895.md)]
- Relax: Composable Abstractions for End-to-End Dynamic Machine Learning - [[Arxiv](https://arxiv.org/abs/2311.02103)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.02103.md)]
- De-Diffusion Makes Text a Strong Cross-Modal Interface - [[Arxiv](https://arxiv.org/abs/2311.00618)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00618.md)]
- Controllable Music Production with Diffusion Models and Guidance   Gradients - [[Arxiv](https://arxiv.org/abs/2311.00613)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00613.md)]
- LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation,   Generation and Editing - [[Arxiv](https://arxiv.org/abs/2311.00571)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00571.md)]
- Text Rendering Strategies for Pixel Language Models - [[Arxiv](https://arxiv.org/abs/2311.00522)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00522.md)]
- Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo   Labelling - [[Arxiv](https://arxiv.org/abs/2311.00430)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00430.md)]
- ChatCoder: Chat-based Refine Requirement Improves LLMs' Code Generation - [[Arxiv](https://arxiv.org/abs/2311.00272)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00272.md)]
- AMSP: Super-Scaling LLM Training via Advanced Model States Partitioning - [[Arxiv](https://arxiv.org/abs/2311.00257)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00257.md)]

### October 2023
- ChipNeMo: Domain-Adapted LLMs for Chip Design - [[Arxiv](https://arxiv.org/abs/2311.00176)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00176.md)]
- The Generative AI Paradox: "What It Can Create, It May Not Understand" - [[Arxiv](https://arxiv.org/abs/2311.00059)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00059.md)]
- Grounding Visual Illusions in Language: Do Vision-Language Models   Perceive Illusions Like Humans? - [[Arxiv](https://arxiv.org/abs/2311.00047)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.00047.md)]
- What's In My Big Data? - [[Arxiv](https://arxiv.org/abs/2310.20707)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.20707.md)]
- SEINE: Short-to-Long Video Diffusion Model for Generative Transition and   Prediction - [[Arxiv](https://arxiv.org/abs/2310.20700)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.20700.md)]
- Learning From Mistakes Makes LLM Better Reasoner - [[Arxiv](https://arxiv.org/abs/2310.20689)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.20689.md)]
- LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B - [[Arxiv](https://arxiv.org/abs/2310.20624)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.20624.md)]
- Unleashing the Power of Pre-trained Language Models for Offline   Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2310.20587)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.20587.md)]
- CapsFusion: Rethinking Image-Text Data at Scale - [[Arxiv](https://arxiv.org/abs/2310.20550)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.20550.md)]
- Leveraging Word Guessing Games to Assess the Intelligence of Large   Language Models - [[Arxiv](https://arxiv.org/abs/2310.20499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.20499.md)]
- Does GPT-4 Pass the Turing Test? - [[Arxiv](https://arxiv.org/abs/2310.20216)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.20216.md)]
- Beyond U: Making Diffusion Models Faster &amp; Lighter - [[Arxiv](https://arxiv.org/abs/2310.20092)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.20092.md)]
- The Impact of Depth and Width on Transformer Language Model   Generalization - [[Arxiv](https://arxiv.org/abs/2310.19956)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19956.md)]
- Battle of the Backbones: A Large-Scale Comparison of Pretrained Models   across Computer Vision Tasks - [[Arxiv](https://arxiv.org/abs/2310.19909)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19909.md)]
- CustomNet: Zero-shot Object Customization with Variable-Viewpoints in   Text-to-Image Diffusion Models - [[Arxiv](https://arxiv.org/abs/2310.19784)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19784.md)]
- MM-VID: Advancing Video Understanding with GPT-4V(ision) - [[Arxiv](https://arxiv.org/abs/2310.19773)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19773.md)]
- VideoCrafter1: Open Diffusion Models for High-Quality Video Generation - [[Arxiv](https://arxiv.org/abs/2310.19512)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19512.md)]
- Text-to-3D with classifier score distillation - [[Arxiv](https://arxiv.org/abs/2310.19415)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19415.md)]
- Skywork: A More Open Bilingual Foundation Model - [[Arxiv](https://arxiv.org/abs/2310.19341)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19341.md)]
- Atom: Low-bit Quantization for Efficient and Accurate LLM Serving - [[Arxiv](https://arxiv.org/abs/2310.19102)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19102.md)]
- Multimodal ChatGPT for Medical Applications: an Experimental Study of   GPT-4V - [[Arxiv](https://arxiv.org/abs/2310.19061)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19061.md)]
- TeacherLM: Teaching to Fish Rather Than Giving the Fish, Language   Modeling Likewise - [[Arxiv](https://arxiv.org/abs/2310.19019)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19019.md)]
- Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive   Learning for Code Generation - [[Arxiv](https://arxiv.org/abs/2310.18628)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.18628.md)]
- FP8-LM: Training FP8 Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.18313)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.18313.md)]
- Personas as a Way to Model Truthfulness in Language Models - [[Arxiv](https://arxiv.org/abs/2310.18168)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.18168.md)]
- ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Real Image - [[Arxiv](https://arxiv.org/abs/2310.17994)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17994.md)]
- Reconstructive Latent-Space Neural Radiance Fields for Efficient 3D   Scene Representations - [[Arxiv](https://arxiv.org/abs/2310.17880)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17880.md)]
- ControlLLM: Augment Language Models with Tools by Searching on Graphs - [[Arxiv](https://arxiv.org/abs/2310.17796)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17796.md)]
- PockEngine: Sparse and Efficient Fine-tuning in a Pocket - [[Arxiv](https://arxiv.org/abs/2310.17752)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17752.md)]
- A Framework for Automated Measurement of Responsible AI Harms in   Generative AI Applications - [[Arxiv](https://arxiv.org/abs/2310.17750)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17750.md)]
- Large Language Models as Generalizable Policies for Embodied Tasks - [[Arxiv](https://arxiv.org/abs/2310.17722)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17722.md)]
- JudgeLM: Fine-tuned Large Language Models are Scalable Judges - [[Arxiv](https://arxiv.org/abs/2310.17631)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17631.md)]
- CodeFusion: A Pre-trained Diffusion Model for Code Generation - [[Arxiv](https://arxiv.org/abs/2310.17680)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17680.md)]
- Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time - [[Arxiv](https://arxiv.org/abs/2310.17157)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17157.md)]
- HyperFields: Towards Zero-Shot Generation of NeRFs from Text - [[Arxiv](https://arxiv.org/abs/2310.17075)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17075.md)]
- Controlled Decoding from Language Models - [[Arxiv](https://arxiv.org/abs/2310.17022)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17022.md)]
- Zephyr: Direct Distillation of LM Alignment - [[Arxiv](https://arxiv.org/abs/2310.16944)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16944.md)]
- LLM-FP4: 4-Bit Floating-Point Quantized Transformers - [[Arxiv](https://arxiv.org/abs/2310.16836)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16836.md)]
- LightSpeed: Light and Fast Neural Light Fields on Mobile Devices - [[Arxiv](https://arxiv.org/abs/2310.16832)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16832.md)]
- TD-MPC2: Scalable, Robust World Models for Continuous Control - [[Arxiv](https://arxiv.org/abs/2310.16828)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16828.md)]
- CommonCanvas: An Open Diffusion Model Trained with Creative-Commons   Images - [[Arxiv](https://arxiv.org/abs/2310.16825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16825.md)]
- DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion   Prior - [[Arxiv](https://arxiv.org/abs/2310.16818)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16818.md)]
- QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models - [[Arxiv](https://arxiv.org/abs/2310.16795)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16795.md)]
- Detecting Pretraining Data from Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.16789)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16789.md)]
- ConvNets Match Vision Transformers at Scale - [[Arxiv](https://arxiv.org/abs/2310.16764)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16764.md)]
- A Picture is Worth a Thousand Words: Principled Recaptioning Improves   Image Generation - [[Arxiv](https://arxiv.org/abs/2310.16656)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16656.md)]
- An Early Evaluation of GPT-4V(ision) - [[Arxiv](https://arxiv.org/abs/2310.16534)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16534.md)]
- CLEX: Continuous Length Extrapolation for Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.16450)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16450.md)]
- TiC-CLIP: Continual Training of CLIP Models - [[Arxiv](https://arxiv.org/abs/2310.16226)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16226.md)]
- Woodpecker: Hallucination Correction for Multimodal Large Language   Models - [[Arxiv](https://arxiv.org/abs/2310.16045)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16045.md)]
- What's Left? Concept Grounding with Logic-Enhanced Foundation Models - [[Arxiv](https://arxiv.org/abs/2310.16035)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16035.md)]
- Dissecting In-Context Learning of Translations in GPTs - [[Arxiv](https://arxiv.org/abs/2310.15987)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15987.md)]
- In-Context Learning Creates Task Vectors - [[Arxiv](https://arxiv.org/abs/2310.15916)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15916.md)]
- KITAB: Evaluating LLMs on Constraint Satisfaction for Information   Retrieval - [[Arxiv](https://arxiv.org/abs/2310.15511)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15511.md)]
- TRAMS: Training-free Memory Selection for Long-range Language Modeling - [[Arxiv](https://arxiv.org/abs/2310.15494)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15494.md)]
- LoRAShear: Efficient Large Language Model Structured Pruning and   Knowledge Recovery - [[Arxiv](https://arxiv.org/abs/2310.18356)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.18356.md)]
- Moral Foundations of Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.15337)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15337.md)]
- SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial   Understanding - [[Arxiv](https://arxiv.org/abs/2310.15308)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15308.md)]
- RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions - [[Arxiv](https://arxiv.org/abs/2310.15171)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15171.md)]
- FreeNoise: Tuning-Free Longer Video Diffusion Via Noise Rescheduling - [[Arxiv](https://arxiv.org/abs/2310.15169)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15169.md)]
- Large Language Models are Visual Reasoning Coordinators - [[Arxiv](https://arxiv.org/abs/2310.15166)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15166.md)]
- DEsignBench: Exploring and Benchmarking DALL-E 3 for Imagining Visual   Design - [[Arxiv](https://arxiv.org/abs/2310.15144)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15144.md)]
- Branch-Solve-Merge Improves Large Language Model Evaluation and   Generation - [[Arxiv](https://arxiv.org/abs/2310.15123)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15123.md)]
- Matryoshka Diffusion Models - [[Arxiv](https://arxiv.org/abs/2310.15111)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15111.md)]
- Wonder3D: Single Image to 3D using Cross-Domain Diffusion - [[Arxiv](https://arxiv.org/abs/2310.15008)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15008.md)]
- ALCUNA: Large Language Models Meet New Knowledge - [[Arxiv](https://arxiv.org/abs/2310.14820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.14820.md)]
- Inject Semantic Concepts into Image Tagging for Open-Set Recognition - [[Arxiv](https://arxiv.org/abs/2310.15200)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.15200.md)]
- Exploring the Boundaries of GPT-4 in Radiology - [[Arxiv](https://arxiv.org/abs/2310.14573)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.14573.md)]
- HallusionBench: You See What You Think? Or You Think What You See? An   Image-Context Reasoning Benchmark Challenging for GPT-4V(ision), LLaVA-1.5,   and Other Multi-modality Models - [[Arxiv](https://arxiv.org/abs/2310.14566)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.14566.md)]
- InstructExcel: A Benchmark for Natural Language Instruction in Excel - [[Arxiv](https://arxiv.org/abs/2310.14495)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.14495.md)]
- Ensemble-Instruct: Generating Instruction-Tuning Data with a   Heterogeneous Mixture of LMs - [[Arxiv](https://arxiv.org/abs/2310.13961)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13961.md)]
- Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models - [[Arxiv](https://arxiv.org/abs/2310.13828)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13828.md)]
- Specific versus General Principles for Constitutional AI - [[Arxiv](https://arxiv.org/abs/2310.13798)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13798.md)]
- TexFusion: Synthesizing 3D Textures with Text-Guided Image Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2310.13772)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13772.md)]
- Localizing and Editing Knowledge in Text-to-Image Generative Models - [[Arxiv](https://arxiv.org/abs/2310.13730)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13730.md)]
- Let's Synthesize Step by Step: Iterative Dataset Synthesis with Large   Language Models by Extrapolating Errors from Small Models - [[Arxiv](https://arxiv.org/abs/2310.13671)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13671.md)]
- Contrastive Prefence Learning: Learning from Human Feedback without RL - [[Arxiv](https://arxiv.org/abs/2310.13639)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13639.md)]
- The Perils &amp; Promises of Fact-checking with Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.13549)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13549.md)]
- Towards Understanding Sycophancy in Language Models - [[Arxiv](https://arxiv.org/abs/2310.13548)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13548.md)]
- ScaleLong: Towards More Stable Training of Diffusion Model via Scaling   Network Long Skip Connection - [[Arxiv](https://arxiv.org/abs/2310.13545)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13545.md)]
- Teaching Language Models to Self-Improve through Interactive   Demonstrations - [[Arxiv](https://arxiv.org/abs/2310.13522)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13522.md)]
- Tuna: Instruction Tuning using Feedback from Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.13385)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13385.md)]
- SILC: Improving Vision Language Pretraining with Self-Distillation - [[Arxiv](https://arxiv.org/abs/2310.13355)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13355.md)]
- Democratizing Reasoning Ability: Tailored Learning from Large Language   Model - [[Arxiv](https://arxiv.org/abs/2310.13332)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13332.md)]
- SALMONN: Towards Generic Hearing Abilities for Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.13289)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13289.md)]
- DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model   Statistics - [[Arxiv](https://arxiv.org/abs/2310.13268)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13268.md)]
- ToolChain*: Efficient Action Space Navigation in Large Language Models   with A* Search - [[Arxiv](https://arxiv.org/abs/2310.13227)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13227.md)]
- Auto-Instruct: Automatic Instruction Generation and Ranking for   Black-Box Language Models - [[Arxiv](https://arxiv.org/abs/2310.13127)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13127.md)]
- DreamSpace: Dreaming Your Room Space with Text-Driven Panoramic Texture   Propagation - [[Arxiv](https://arxiv.org/abs/2310.13119)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13119.md)]
- Creative Robot Tool Use with Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.13065)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13065.md)]
- AutoMix: Automatically Mixing Language Models - [[Arxiv](https://arxiv.org/abs/2310.12963)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12963.md)]
- An Emulator for Fine-Tuning Large Language Models using Small Language   Models - [[Arxiv](https://arxiv.org/abs/2310.12962)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12962.md)]
- Structured Generation and Exploration of Design Space with Large   Language Models for Human-AI Co-Creation - [[Arxiv](https://arxiv.org/abs/2310.12953)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12953.md)]
- 3D-GPT: Procedural 3D Modeling with Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.12945)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12945.md)]
- Eureka: Human-Level Reward Design via Coding Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.12931)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12931.md)]
- Habitat 3.0: A Co-Habitat for Humans, Avatars and Robots - [[Arxiv](https://arxiv.org/abs/2310.13724)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13724.md)]
- Vision-Language Models are Zero-Shot Reward Models for Reinforcement   Learning - [[Arxiv](https://arxiv.org/abs/2310.12921)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12921.md)]
- AgentTuning: Enabling Generalized Agent Abilities for LLMs - [[Arxiv](https://arxiv.org/abs/2310.12823)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12823.md)]
- Label-Aware Automatic Verbalizer for Few-Shot Text Classification - [[Arxiv](https://arxiv.org/abs/2310.12778)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12778.md)]
- Safe RLHF: Safe Reinforcement Learning from Human Feedback - [[Arxiv](https://arxiv.org/abs/2310.12773)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12773.md)]
- Quality-Diversity through AI Feedback - [[Arxiv](https://arxiv.org/abs/2310.13032)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13032.md)]
- Enhancing High-Resolution 3D Generation through Pixel-wise Gradient   Clipping - [[Arxiv](https://arxiv.org/abs/2310.12474)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12474.md)]
- Loop Copilot: Conducting AI Ensembles for Music Generation and Iterative   Editing - [[Arxiv](https://arxiv.org/abs/2310.12404)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12404.md)]
- LACMA: Language-Aligning Contrastive Learning with Meta-Actions for   Embodied Instruction Following - [[Arxiv](https://arxiv.org/abs/2310.12344)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12344.md)]
- An Image is Worth Multiple Words: Learning Object Level Concepts using   Multi-Concept Prompt Learning - [[Arxiv](https://arxiv.org/abs/2310.12274)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12274.md)]
- Learning from Rich Semantics and Coarse Locations for Long-tailed Object   Detection - [[Arxiv](https://arxiv.org/abs/2310.12152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12152.md)]
- Understanding Retrieval Augmentation for Long-Form Question Answering - [[Arxiv](https://arxiv.org/abs/2310.12150)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12150.md)]
- DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM   Planning - [[Arxiv](https://arxiv.org/abs/2310.12128)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12128.md)]
- SHARCS: Efficient Transformers through Routing with Dynamic Width   Sub-networks - [[Arxiv](https://arxiv.org/abs/2310.12126)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12126.md)]
- Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture - [[Arxiv](https://arxiv.org/abs/2310.12109)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12109.md)]
- Quality Diversity through Human Feedback - [[Arxiv](https://arxiv.org/abs/2310.12103)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.12103.md)]
- MusicAgent: An AI Agent for Music Understanding and Generation with   Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.11954)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11954.md)]
- Progressive3D: Progressively Local Editing for Text-to-3D Content   Creation with Complex Semantic Prompts - [[Arxiv](https://arxiv.org/abs/2310.11784)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11784.md)]
- Language Models as Zero-Shot Trajectory Generators - [[Arxiv](https://arxiv.org/abs/2310.11604)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11604.md)]
- Eliciting Human Preferences with Language Models - [[Arxiv](https://arxiv.org/abs/2310.11589)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11589.md)]
- Personalized Soups: Personalized Large Language Model Alignment via   Post-hoc Parameter Merging - [[Arxiv](https://arxiv.org/abs/2310.11564)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11564.md)]
- Self-RAG: Learning to Retrieve, Generate, and Critique through   Self-Reflection - [[Arxiv](https://arxiv.org/abs/2310.11511)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11511.md)]
- VeRA: Vector-based Random Matrix Adaptation - [[Arxiv](https://arxiv.org/abs/2310.11454)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11454.md)]
- BitNet: Scaling 1-bit Transformers for Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.11453)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11453.md)]
- 4K4D: Real-Time 4D View Synthesis at 4K Resolution - [[Arxiv](https://arxiv.org/abs/2310.11448)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11448.md)]
- Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V - [[Arxiv](https://arxiv.org/abs/2310.11441)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11441.md)]
- EvalCrafter: Benchmarking and Evaluating Large Video Generation Models - [[Arxiv](https://arxiv.org/abs/2310.11440)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11440.md)]
- Butterfly Effects of SGD Noise: Error Amplification in Behavior Cloning   and Autoregression - [[Arxiv](https://arxiv.org/abs/2310.11428)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11428.md)]
- CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code   Completion - [[Arxiv](https://arxiv.org/abs/2310.11248)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.11248.md)]
- H2O Open Ecosystem for State-of-the-art Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.13012)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.13012.md)]
- Context-Aware Meta-Learning - [[Arxiv](https://arxiv.org/abs/2310.10971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10971.md)]
- TEQ: Trainable Equivalent Transformation for Quantization of LLMs - [[Arxiv](https://arxiv.org/abs/2310.10944)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10944.md)]
- Approximating Two-Layer Feedforward Networks for Efficient Transformers - [[Arxiv](https://arxiv.org/abs/2310.10837)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10837.md)]
- LAMP: Learn A Motion Pattern for Few-Shot-Based Video Generation - [[Arxiv](https://arxiv.org/abs/2310.10769)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10769.md)]
- HairCLIPv2: Unifying Hair Editing via Proxy Feature Blending - [[Arxiv](https://arxiv.org/abs/2310.10651)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10651.md)]
- Interactive Task Planning with Language Models - [[Arxiv](https://arxiv.org/abs/2310.10645)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10645.md)]
- In-Context Pretraining: Language Modeling Beyond Document Boundaries - [[Arxiv](https://arxiv.org/abs/2310.10638)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10638.md)]
- OpenAgents: An Open Platform for Language Agents in the Wild - [[Arxiv](https://arxiv.org/abs/2310.10634)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10634.md)]
- Llemma: An Open Language Model For Mathematics - [[Arxiv](https://arxiv.org/abs/2310.10631)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10631.md)]
- Video Language Planning - [[Arxiv](https://arxiv.org/abs/2310.10625)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10625.md)]
- TacticAI: an AI assistant for football tactics - [[Arxiv](https://arxiv.org/abs/2310.10553)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10553.md)]
- Microscaling Data Formats for Deep Learning - [[Arxiv](https://arxiv.org/abs/2310.10537)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10537.md)]
- Reading Books is Great, But Not if You Are Driving! Visually Grounded   Reasoning about Defeasible Commonsense Norms - [[Arxiv](https://arxiv.org/abs/2310.10418)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10418.md)]
- Improving Large Language Model Fine-tuning for Solving Math Problems - [[Arxiv](https://arxiv.org/abs/2310.10047)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.10047.md)]
- Farzi Data: Autoregressive Data Distillation - [[Arxiv](https://arxiv.org/abs/2310.09983)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09983.md)]
- When can transformers reason with abstract symbols? - [[Arxiv](https://arxiv.org/abs/2310.09753)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09753.md)]
- Does CLIP's Generalization Performance Mainly Stem from High Train-Test   Similarity? - [[Arxiv](https://arxiv.org/abs/2310.09562)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09562.md)]
- Reward-Augmented Decoding: Efficient Controlled Text Generation With a   Unidirectional Reward Model - [[Arxiv](https://arxiv.org/abs/2310.09520)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09520.md)]
- MiniGPT-v2: large language model as a unified interface for   vision-language multi-task learning - [[Arxiv](https://arxiv.org/abs/2310.09478)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09478.md)]
- Ranking LLM-Generated Loop Invariants for Program Verification - [[Arxiv](https://arxiv.org/abs/2310.09342)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09342.md)]
- Vision-by-Language for Training-Free Compositional Image Retrieval - [[Arxiv](https://arxiv.org/abs/2310.09291)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09291.md)]
- An Unbiased Look at Datasets for Visuo-Motor Pre-Training - [[Arxiv](https://arxiv.org/abs/2310.09289)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09289.md)]
- SAIR: Learning Semantic-aware Implicit Representation - [[Arxiv](https://arxiv.org/abs/2310.09285)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09285.md)]
- Transformer-based Multimodal Change Detection with Multitask Consistency   Constraints - [[Arxiv](https://arxiv.org/abs/2310.09276)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09276.md)]
- Understanding and Modeling the Effects of Task and Context on Drivers'   Gaze Allocation - [[Arxiv](https://arxiv.org/abs/2310.09275)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09275.md)]
- Table-GPT: Table-tuned GPT for Diverse Table Tasks - [[Arxiv](https://arxiv.org/abs/2310.09263)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09263.md)]
- Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet   Hierarchy - [[Arxiv](https://arxiv.org/abs/2310.09247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09247.md)]
- Time CNN and Graph Convolution Network for Epileptic Spike Detection in   MEG Data - [[Arxiv](https://arxiv.org/abs/2310.09236)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09236.md)]
- Ultrasound Image Segmentation of Thyroid Nodule via Latent Semantic   Feature Co-Registration - [[Arxiv](https://arxiv.org/abs/2310.09221)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09221.md)]
- Unseen Image Synthesis with Diffusion Models - [[Arxiv](https://arxiv.org/abs/2310.09213)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09213.md)]
- PaLI-3 Vision Language Models: Smaller, Faster, Stronger - [[Arxiv](https://arxiv.org/abs/2310.09199)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09199.md)]
- mnmDTW: An extension to Dynamic Time Warping for Camera-based Movement   Error Localization - [[Arxiv](https://arxiv.org/abs/2310.09170)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09170.md)]
- Exploring Sparse Spatial Relation in Graph Inference for Text-Based VQA - [[Arxiv](https://arxiv.org/abs/2310.09147)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09147.md)]
- The Consensus Game: Language Model Generation via Equilibrium Search - [[Arxiv](https://arxiv.org/abs/2310.09139)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09139.md)]
- Physics-guided Noise Neural Proxy for Low-light Raw Image Denoising - [[Arxiv](https://arxiv.org/abs/2310.09126)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09126.md)]
- Training and Predicting Visual Error for Real-Time Applications - [[Arxiv](https://arxiv.org/abs/2310.09125)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09125.md)]
- DSG: An End-to-End Document Structure Generator - [[Arxiv](https://arxiv.org/abs/2310.09118)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09118.md)]
- Timestamp-supervised Wearable-based Activity Segmentation and   Recognition with Contrastive Learning and Order-Preserving Optimal Transport - [[Arxiv](https://arxiv.org/abs/2310.09114)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09114.md)]
- iPUNet:Iterative Cross Field Guided Point Cloud Upsampling - [[Arxiv](https://arxiv.org/abs/2310.09092)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09092.md)]
- pose-format: Library for Viewing, Augmenting, and Handling .pose Files - [[Arxiv](https://arxiv.org/abs/2310.09066)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.09066.md)]
- CodeChain: Towards Modular Code Generation Through Chain of   Self-revisions with Representative Sub-modules - [[Arxiv](https://arxiv.org/abs/2310.08992)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08992.md)]
- VCL Challenges 2023 at ICCV 2023 Technical Report: Bi-level Adaptation   Method for Test-time Adaptive Object Detection - [[Arxiv](https://arxiv.org/abs/2310.08986)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08986.md)]
- UniParser: Multi-Human Parsing with Unified Correlation Representation   Learning - [[Arxiv](https://arxiv.org/abs/2310.08984)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08984.md)]
- LRRU: Long-short Range Recurrent Updating Networks for Depth Completion - [[Arxiv](https://arxiv.org/abs/2310.08956)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08956.md)]
- Making Multimodal Generation Easier: When Diffusion Models Meet LLMs - [[Arxiv](https://arxiv.org/abs/2310.08949)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08949.md)]
- Federated Class-Incremental Learning with Prompting - [[Arxiv](https://arxiv.org/abs/2310.08948)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08948.md)]
- Online Adaptive Disparity Estimation for Dynamic Scenes in Structured   Light Systems - [[Arxiv](https://arxiv.org/abs/2310.08934)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08934.md)]
- TIDE: Temporally Incremental Disparity Estimation via Pattern Flow in   Structured Light System - [[Arxiv](https://arxiv.org/abs/2310.08932)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08932.md)]
- Towards Interpretable Controllability in Object-Centric Learning - [[Arxiv](https://arxiv.org/abs/2310.08929)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08929.md)]
- SIDE: Self-supervised Intermediate Domain Exploration for Source-free   Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2310.08928)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08928.md)]
- Feature Proliferation -- the "Cancer" in StyleGAN and its Treatments - [[Arxiv](https://arxiv.org/abs/2310.08921)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08921.md)]
- Scalarization for Multi-Task and Multi-Domain Learning at Scale - [[Arxiv](https://arxiv.org/abs/2310.08910)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08910.md)]
- 3D Understanding of Deformable Linear Objects: Datasets and   Transferability Benchmark - [[Arxiv](https://arxiv.org/abs/2310.08904)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08904.md)]
- Self supervised convolutional kernel based handcrafted feature   harmonization: Enhanced left ventricle hypertension disease phenotyping on   echocardiography - [[Arxiv](https://arxiv.org/abs/2310.08897)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08897.md)]
- Image Cropping under Design Constraints - [[Arxiv](https://arxiv.org/abs/2310.08892)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08892.md)]
- METRA: Scalable Unsupervised RL with Metric-Aware Abstraction - [[Arxiv](https://arxiv.org/abs/2310.08887)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08887.md)]
- Extending Multi-modal Contrastive Representations - [[Arxiv](https://arxiv.org/abs/2310.08884)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08884.md)]
- R&amp;B: Region and Boundary Aware Zero-shot Grounded Text-to-image   Generation - [[Arxiv](https://arxiv.org/abs/2310.08872)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08872.md)]
- Adaptivity and Modularity for Efficient Generalization Over Task   Complexity - [[Arxiv](https://arxiv.org/abs/2310.08866)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08866.md)]
- Open X-Embodiment: Robotic Learning Datasets and RT-X Models - [[Arxiv](https://arxiv.org/abs/2310.08864)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08864.md)]
- Re-initialization-free Level Set Method via Molecular Beam Epitaxy   Equation Regularization for Image Segmentation - [[Arxiv](https://arxiv.org/abs/2310.08861)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08861.md)]
- Rank-DETR for High Quality Object Detection - [[Arxiv](https://arxiv.org/abs/2310.08854)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08854.md)]
- Revisiting Multi-modal 3D Semantic Segmentation in Real-world Autonomous   Driving - [[Arxiv](https://arxiv.org/abs/2310.08826)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08826.md)]
- From CLIP to DINO: Visual Encoders Shout in Multi-modal Large Language   Models - [[Arxiv](https://arxiv.org/abs/2310.08825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08825.md)]
- SAM-guided Unsupervised Domain Adaptation for 3D Segmentation - [[Arxiv](https://arxiv.org/abs/2310.08820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08820.md)]
- Incremental Object Detection with CLIP - [[Arxiv](https://arxiv.org/abs/2310.08815)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08815.md)]
- Two-Stage Deep Learning Framework for Quality Assessment of Left Atrial   Late Gadolinium Enhanced MRI Images - [[Arxiv](https://arxiv.org/abs/2310.08805)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08805.md)]
- Investigating the Robustness and Properties of Detection Transformers   (DETR) Toward Difficult Images - [[Arxiv](https://arxiv.org/abs/2310.08772)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08772.md)]
- PU-Ray: Point Cloud Upsampling via Ray Marching on Implicit Surface - [[Arxiv](https://arxiv.org/abs/2310.08755)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08755.md)]
- AcTExplore: Active Tactile Exploration on Unknown Objects - [[Arxiv](https://arxiv.org/abs/2310.08745)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08745.md)]
- A Zero-Shot Language Agent for Computer Control with Structured   Reflection - [[Arxiv](https://arxiv.org/abs/2310.08740)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08740.md)]
- A Simple Way to Incorporate Novelty Detection in World Models - [[Arxiv](https://arxiv.org/abs/2310.08731)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08731.md)]
- Toward Joint Language Modeling for Speech Units and Text - [[Arxiv](https://arxiv.org/abs/2310.08715)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08715.md)]
- Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4   on mock CFA Exams - [[Arxiv](https://arxiv.org/abs/2310.08678)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08678.md)]
- LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.08659)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08659.md)]
- Octopus: Embodied Vision-Language Programmer from Environmental Feedback - [[Arxiv](https://arxiv.org/abs/2310.08588)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08588.md)]
- PonderV2: Pave the Way for 3D Foundation Model with A Universal   Pre-training Paradigm - [[Arxiv](https://arxiv.org/abs/2310.08586)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08586.md)]
- HyperHuman: Hyper-Realistic Human Generation with Latent Structural   Diffusion - [[Arxiv](https://arxiv.org/abs/2310.08579)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08579.md)]
- MemGPT: Towards LLMs as Operating Systems - [[Arxiv](https://arxiv.org/abs/2310.08560)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08560.md)]
- Idea2Img: Iterative Self-Refinement with GPT-4V(ision) for Automatic   Image Design and Generation - [[Arxiv](https://arxiv.org/abs/2310.08541)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08541.md)]
- GaussianDreamer: Fast Generation from Text to 3D Gaussian Splatting with   Point Cloud Priors - [[Arxiv](https://arxiv.org/abs/2310.08529)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08529.md)]
- 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering - [[Arxiv](https://arxiv.org/abs/2310.08528)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08528.md)]
- Prometheus: Inducing Fine-grained Evaluation Capability in Language   Models - [[Arxiv](https://arxiv.org/abs/2310.08491)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08491.md)]
- Can We Edit Multimodal Large Language Models? - [[Arxiv](https://arxiv.org/abs/2310.08475)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08475.md)]
- MotionDirector: Motion Customization of Text-to-Video Diffusion Models - [[Arxiv](https://arxiv.org/abs/2310.08465)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08465.md)]
- Worst-Case Morphs using Wasserstein ALI and Improved MIPGAN - [[Arxiv](https://arxiv.org/abs/2310.08371)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08371.md)]
- EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form   Narrative Text Generation - [[Arxiv](https://arxiv.org/abs/2310.08185)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08185.md)]
- ZEST: Attention-based Zero-Shot Learning for Unseen IoT Device   Classification - [[Arxiv](https://arxiv.org/abs/2310.08036)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.08036.md)]
- Reset It and Forget It: Relearning Last-Layer Weights Improves Continual   and Transfer Learning - [[Arxiv](https://arxiv.org/abs/2310.07996)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07996.md)]
- LangNav: Language as a Perceptual Representation for Navigation - [[Arxiv](https://arxiv.org/abs/2310.07889)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07889.md)]
- TabLib: A Dataset of 627M Tables with Context - [[Arxiv](https://arxiv.org/abs/2310.07875)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07875.md)]
- Large Language Models Are Zero-Shot Time Series Forecasters - [[Arxiv](https://arxiv.org/abs/2310.07820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07820.md)]
- InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining - [[Arxiv](https://arxiv.org/abs/2310.07713)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07713.md)]
- MatFormer: Nested Transformer for Elastic Inference - [[Arxiv](https://arxiv.org/abs/2310.07707)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07707.md)]
- Ferret: Refer and Ground Anything Anywhere at Any Granularity - [[Arxiv](https://arxiv.org/abs/2310.07704)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07704.md)]
- Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented   Models - [[Arxiv](https://arxiv.org/abs/2310.07589)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07589.md)]
- Survey on Factuality in Large Language Models: Knowledge, Retrieval and   Domain-Specificity - [[Arxiv](https://arxiv.org/abs/2310.07521)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07521.md)]
- Fast-ELECTRA for Efficient Pre-training - [[Arxiv](https://arxiv.org/abs/2310.07347)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07347.md)]
- How Do Large Language Models Capture the Ever-changing World Knowledge?   A Review of Recent Advances - [[Arxiv](https://arxiv.org/abs/2310.07343)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07343.md)]
- Beyond Memorization: Violating Privacy Via Inference with Large Language   Models - [[Arxiv](https://arxiv.org/abs/2310.07298)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07298.md)]
- State of the Art on Diffusion Models for Visual Computing - [[Arxiv](https://arxiv.org/abs/2310.07204)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07204.md)]
- Online Speculative Decoding - [[Arxiv](https://arxiv.org/abs/2310.07177)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07177.md)]
- Large Language Models can Learn Rules - [[Arxiv](https://arxiv.org/abs/2310.07064)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.07064.md)]
- Violation of Expectation via Metacognitive Prompting Reduces Theory of   Mind Prediction Error in Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.06983)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.06983.md)]
- LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios   via Prompt Compression - [[Arxiv](https://arxiv.org/abs/2310.06839)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.06839.md)]
- What Does Stable Diffusion Know about the 3D Scene? - [[Arxiv](https://arxiv.org/abs/2310.06836)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.06836.md)]
- Lemur: Harmonizing Natural Language and Code for Language Agents - [[Arxiv](https://arxiv.org/abs/2310.06830)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.06830.md)]
- Mistral 7B - [[Arxiv](https://arxiv.org/abs/2310.06825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.06825.md)]
- The Geometry of Truth: Emergent Linear Structure in Large Language Model   Representations of True/False Datasets - [[Arxiv](https://arxiv.org/abs/2310.06824)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.06824.md)]
- Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task   Scenarios with Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.06692)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.06692.md)]
- Understanding the Effects of RLHF on LLM Generalisation and Diversity - [[Arxiv](https://arxiv.org/abs/2310.06452)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.06452.md)]
- Take a Step Back: Evoking Reasoning via Abstraction in Large Language   Models - [[Arxiv](https://arxiv.org/abs/2310.06117)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.06117.md)]
- Learning Interactive Real-World Simulators - [[Arxiv](https://arxiv.org/abs/2310.06114)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.06114.md)]
- FireAct: Toward Language Agent Fine-tuning - [[Arxiv](https://arxiv.org/abs/2310.05915)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05915.md)]
- NEFTune: Noisy Embeddings Improve Instruction Finetuning - [[Arxiv](https://arxiv.org/abs/2310.05914)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05914.md)]
- Geom-Erasing: Geometry-Driven Removal of Implicit Concept in Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2310.05873)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05873.md)]
- GraphLLM: Boosting Graph Reasoning Ability of Large Language Model - [[Arxiv](https://arxiv.org/abs/2310.05845)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05845.md)]
- Are Large Language Models Post Hoc Explainers? - [[Arxiv](https://arxiv.org/abs/2310.05797)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05797.md)]
- Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation - [[Arxiv](https://arxiv.org/abs/2310.05737)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05737.md)]
- LLMLingua: Compressing Prompts for Accelerated Inference of Large   Language Models - [[Arxiv](https://arxiv.org/abs/2310.05736)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05736.md)]
- A Survey of Large Language Models for Healthcare: from Data, Technology,   and Applications to Accountability and Ethics - [[Arxiv](https://arxiv.org/abs/2310.05694)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05694.md)]
- InterroLang: Exploring NLP Models and Datasets through Dialogue-based   Explanations - [[Arxiv](https://arxiv.org/abs/2310.05592)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05592.md)]
- SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to   RLHF - [[Arxiv](https://arxiv.org/abs/2310.05344)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05344.md)]
- GestSync: Determining who is speaking without a talking head - [[Arxiv](https://arxiv.org/abs/2310.05304)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05304.md)]
- An Investigation of LLMs' Inefficacy in Understanding Converse Relations - [[Arxiv](https://arxiv.org/abs/2310.05163)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05163.md)]
- Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot   Performance via Probability Calibration - [[Arxiv](https://arxiv.org/abs/2310.05069)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05069.md)]
- Video-CSR: Complex Video Digest Creation for Visual-Language Models - [[Arxiv](https://arxiv.org/abs/2310.05060)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05060.md)]
- Walking Down the Memory Maze: Beyond Context Limit through Interactive   Reading - [[Arxiv](https://arxiv.org/abs/2310.05029)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05029.md)]
- Low-Resolution Self-Attention for Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2310.05026)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.05026.md)]
- Reliable Test-Time Adaptation via Agreement-on-the-Line - [[Arxiv](https://arxiv.org/abs/2310.04941)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04941.md)]
- Crystal-GFN: sampling crystals with desirable properties and constraints - [[Arxiv](https://arxiv.org/abs/2310.04925)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04925.md)]
- Crystal: Introspective Reasoners Reinforced with Self-Feedback - [[Arxiv](https://arxiv.org/abs/2310.04921)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04921.md)]
- IPMix: Label-Preserving Data Augmentation Method for Training Robust   Classifiers - [[Arxiv](https://arxiv.org/abs/2310.04780)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04780.md)]
- SeeDS: Semantic Separable Diffusion Synthesizer for Zero-shot Food   Detection - [[Arxiv](https://arxiv.org/abs/2310.04689)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04689.md)]
- Data-Centric Financial Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.17784)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17784.md)]
- The Cost of Down-Scaling Language Models: Fact Recall Deteriorates   before In-Context Learning - [[Arxiv](https://arxiv.org/abs/2310.04680)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04680.md)]
- ReLU Strikes Back: Exploiting Activation Sparsity in Large Language   Models - [[Arxiv](https://arxiv.org/abs/2310.04564)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04564.md)]
- URLOST: Unsupervised Representation Learning without Stationarity or   Topology - [[Arxiv](https://arxiv.org/abs/2310.04496)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04496.md)]
- Functional Interpolation for Relative Positions Improves Long Context   Transformers - [[Arxiv](https://arxiv.org/abs/2310.04418)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04418.md)]
- RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective   Augmentation - [[Arxiv](https://arxiv.org/abs/2310.04408)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04408.md)]
- Language Agent Tree Search Unifies Reasoning Acting and Planning in   Language Models - [[Arxiv](https://arxiv.org/abs/2310.04406)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04406.md)]
- Latent Consistency Models: Synthesizing High-Resolution Images with   Few-Step Inference - [[Arxiv](https://arxiv.org/abs/2310.04378)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04378.md)]
- Amortizing intractable inference in large language models - [[Arxiv](https://arxiv.org/abs/2310.04363)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04363.md)]
- Towards Foundational Models for Molecular Learning on Large-Scale   Multi-Task Datasets - [[Arxiv](https://arxiv.org/abs/2310.04292)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.04292.md)]
- Robust Multimodal Learning with Missing Modalities via   Parameter-Efficient Adaptation - [[Arxiv](https://arxiv.org/abs/2310.03986)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03986.md)]
- CUPre: Cross-domain Unsupervised Pre-training for Few-Shot Cell   Segmentation - [[Arxiv](https://arxiv.org/abs/2310.03981)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03981.md)]
- Understanding prompt engineering may not require rethinking   generalization - [[Arxiv](https://arxiv.org/abs/2310.03957)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03957.md)]
- Hard View Selection for Contrastive Learning - [[Arxiv](https://arxiv.org/abs/2310.03940)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03940.md)]
- Diffusion Models as Masked Audio-Video Learners - [[Arxiv](https://arxiv.org/abs/2310.03937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03937.md)]
- Information Geometry for the Working Information Theorist - [[Arxiv](https://arxiv.org/abs/2310.03884)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03884.md)]
- Automatic and Human-AI Interactive Text Generation - [[Arxiv](https://arxiv.org/abs/2310.03878)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03878.md)]
- Improved Baselines with Visual Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2310.03744)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03744.md)]
- Aligning Text-to-Image Diffusion Models with Reward Backpropagation - [[Arxiv](https://arxiv.org/abs/2310.03739)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03739.md)]
- Leveraging Unpaired Data for Vision-Language Generative Models via Cycle   Consistency - [[Arxiv](https://arxiv.org/abs/2310.03734)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03734.md)]
- MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical   Reasoning - [[Arxiv](https://arxiv.org/abs/2310.03731)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03731.md)]
- Stochastic interpolants with data-dependent couplings - [[Arxiv](https://arxiv.org/abs/2310.03725)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03725.md)]
- HeaP: Hierarchical Policies for Web Actions using LLMs - [[Arxiv](https://arxiv.org/abs/2310.03720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03720.md)]
- A Long Way to Go: Investigating Length Correlations in RLHF - [[Arxiv](https://arxiv.org/abs/2310.03716)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03716.md)]
- DSPy: Compiling Declarative Language Model Calls into Self-Improving   Pipelines - [[Arxiv](https://arxiv.org/abs/2310.03714)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03714.md)]
- Agent Instructs Large Language Models to be General Zero-Shot Reasoners - [[Arxiv](https://arxiv.org/abs/2310.03710)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03710.md)]
- Drag View: Generalizable Novel View Synthesis with Unposed Imagery - [[Arxiv](https://arxiv.org/abs/2310.03704)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03704.md)]
- Fine-tuning Aligned Language Models Compromises Safety, Even When Users   Do Not Intend To! - [[Arxiv](https://arxiv.org/abs/2310.03693)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03693.md)]
- TimeGPT-1 - [[Arxiv](https://arxiv.org/abs/2310.03589)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03589.md)]
- Kandinsky: an Improved Text-to-Image Synthesis with Image Prior and   Latent Diffusion - [[Arxiv](https://arxiv.org/abs/2310.03502)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03502.md)]
- Fine-tune Language Models to Approximate Unbiased In-context Learning - [[Arxiv](https://arxiv.org/abs/2310.03331)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03331.md)]
- Benchmarking Large Language Models As AI Research Agents - [[Arxiv](https://arxiv.org/abs/2310.03302)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03302.md)]
- LightSeq: Sequence Level Parallelism for Distributed Training of Long   Context Transformers - [[Arxiv](https://arxiv.org/abs/2310.03294)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03294.md)]
- FreshLLMs: Refreshing Large Language Models with Search Engine   Augmentation - [[Arxiv](https://arxiv.org/abs/2310.03214)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03214.md)]
- Large Language Model Cascades with Mixture of Thoughts Representations   for Cost-efficient Reasoning - [[Arxiv](https://arxiv.org/abs/2310.03094)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03094.md)]
- LanguageMPC: Large Language Models as Decision Makers for Autonomous   Driving - [[Arxiv](https://arxiv.org/abs/2310.03026)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03026.md)]
- Retrieval meets Long Context Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.03025)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03025.md)]
- Soft Convex Quantization: Revisiting Vector Quantization with Convex   Optimization - [[Arxiv](https://arxiv.org/abs/2310.03004)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03004.md)]
- xVal: A Continuous Number Encoding for Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.02989)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.02989.md)]
- Foundation Reinforcement Learning: towards Embodied Generalist Agents   with Foundation Prior Assistance - [[Arxiv](https://arxiv.org/abs/2310.02635)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.02635.md)]
- How FaR Are Large Language Models From Agents with Theory-of-Mind? - [[Arxiv](https://arxiv.org/abs/2310.03051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03051.md)]
- MagicDrive: Street View Generation with Diverse 3D Geometry Control - [[Arxiv](https://arxiv.org/abs/2310.02601)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.02601.md)]
- SlowFormer: Universal Adversarial Patch for Attack on Compute and Energy   Efficiency of Inference Efficient Vision Transformers - [[Arxiv](https://arxiv.org/abs/2310.02544)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.02544.md)]
- Who Audits the Auditors? Recommendations from a field scan of the   algorithmic auditing ecosystem - [[Arxiv](https://arxiv.org/abs/2310.02521)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.02521.md)]
- EcoAssistant: Using LLM Assistant More Affordably and Accurately - [[Arxiv](https://arxiv.org/abs/2310.03046)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.03046.md)]
- MathVista: Evaluating Mathematical Reasoning of Foundation Models in   Visual Contexts - [[Arxiv](https://arxiv.org/abs/2310.02255)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.02255.md)]
- MiniGPT-5: Interleaved Vision-and-Language Generation via Generative   Vokens - [[Arxiv](https://arxiv.org/abs/2310.02239)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.02239.md)]
- Think before you speak: Training Language Models With Pause Tokens - [[Arxiv](https://arxiv.org/abs/2310.02226)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.02226.md)]
- What do we learn from a large-scale study of pre-trained visual   representations in sim and real environments? - [[Arxiv](https://arxiv.org/abs/2310.02219)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.02219.md)]
- Language Models Represent Space and Time - [[Arxiv](https://arxiv.org/abs/2310.02207)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.02207.md)]
- Towards End-to-End Embodied Decision Making via Multi-modal Large   Language Model: Explorations with GPT4-Vision and Beyond - [[Arxiv](https://arxiv.org/abs/2310.02071)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.02071.md)]
- OOD Aware Supervised Contrastive Learning - [[Arxiv](https://arxiv.org/abs/2310.01942)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01942.md)]
- Ring Attention with Blockwise Transformers for Near-Infinite Context - [[Arxiv](https://arxiv.org/abs/2310.01889)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01889.md)]
- Discrete, compositional, and symbolic representations through attractor   dynamics - [[Arxiv](https://arxiv.org/abs/2310.01807)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01807.md)]
- Large Language Models Cannot Self-Correct Reasoning Yet - [[Arxiv](https://arxiv.org/abs/2310.01798)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01798.md)]
- Can large language models provide useful feedback on research papers? A   large-scale empirical analysis - [[Arxiv](https://arxiv.org/abs/2310.01783)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01783.md)]
- ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection   Algorithms - [[Arxiv](https://arxiv.org/abs/2310.01755)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01755.md)]
- Large Language Models as Analogical Reasoners - [[Arxiv](https://arxiv.org/abs/2310.01714)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01714.md)]
- ImagenHub: Standardizing the evaluation of conditional image generation   models - [[Arxiv](https://arxiv.org/abs/2310.01596)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01596.md)]
- SmartPlay : A Benchmark for LLMs as Intelligent Agents - [[Arxiv](https://arxiv.org/abs/2310.01557)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01557.md)]
- Neutrinos from muon-rich ultra high energy electromagnetic cascades: The   MUNHECA code - [[Arxiv](https://arxiv.org/abs/2310.01510)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01510.md)]
- DriveGPT4: Interpretable End-to-end Autonomous Driving via Large   Language Model - [[Arxiv](https://arxiv.org/abs/2310.01412)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01412.md)]
- Conditional Diffusion Distillation - [[Arxiv](https://arxiv.org/abs/2310.01407)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01407.md)]
- Representation Engineering: A Top-Down Approach to AI Transparency - [[Arxiv](https://arxiv.org/abs/2310.01405)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01405.md)]
- H-InDex: Visual Reinforcement Learning with Hand-Informed   Representations for Dexterous Manipulation - [[Arxiv](https://arxiv.org/abs/2310.01404)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01404.md)]
- GenSim: Generating Robotic Simulation Tasks via Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.01361)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01361.md)]
- RA-DIT: Retrieval-Augmented Dual Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2310.01352)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01352.md)]
- Label Supervised LLaMA Finetuning - [[Arxiv](https://arxiv.org/abs/2310.01208)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01208.md)]
- Enable Language Models to Implicitly Learn Self-Improvement From Data - [[Arxiv](https://arxiv.org/abs/2310.00898)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.00898.md)]
- (Dynamic) Prompting might be all you need to repair Compressed LLMs - [[Arxiv](https://arxiv.org/abs/2310.00867)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.00867.md)]
- Sparse Backpropagation for MoE Training - [[Arxiv](https://arxiv.org/abs/2310.00811)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.00811.md)]
- Analyzing and Mitigating Object Hallucination in Large Vision-Language   Models - [[Arxiv](https://arxiv.org/abs/2310.00754)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.00754.md)]
- RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities   of Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.00746)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.00746.md)]
- FELM: Benchmarking Factuality Evaluation of Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.00741)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.00741.md)]
- UniAudio: An Audio Foundation Model Toward Universal Audio Generation - [[Arxiv](https://arxiv.org/abs/2310.00704)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.00704.md)]
- GrowLength: Accelerating LLMs Pretraining by Progressively Growing   Training Length - [[Arxiv](https://arxiv.org/abs/2310.00576)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.00576.md)]

### September 2023
- PixArt-$Î±$: Fast Training of Diffusion Transformer for   Photorealistic Text-to-Image Synthesis - [[Arxiv](https://arxiv.org/abs/2310.00426)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.00426.md)]
- AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with   TikZ - [[Arxiv](https://arxiv.org/abs/2310.00367)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.00367.md)]
- Efficient Streaming Language Models with Attention Sinks - [[Arxiv](https://arxiv.org/abs/2309.17453)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.17453.md)]
- The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision) - [[Arxiv](https://arxiv.org/abs/2309.17421)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.17421.md)]
- Directly Fine-Tuning Diffusion Models on Differentiable Rewards - [[Arxiv](https://arxiv.org/abs/2309.17400)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.17400.md)]
- Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind   Aware GPT-4 - [[Arxiv](https://arxiv.org/abs/2309.17277)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.17277.md)]
- Training and inference of large language models using 8-bit floating   point - [[Arxiv](https://arxiv.org/abs/2309.17224)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.17224.md)]
- Guiding Instruction-based Image Editing via Multimodal Large Language   Models - [[Arxiv](https://arxiv.org/abs/2309.17102)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.17102.md)]
- GAIA-1: A Generative World Model for Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2309.17080)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.17080.md)]
- Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution - [[Arxiv](https://arxiv.org/abs/2309.16797)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16797.md)]
- Demystifying CLIP Data - [[Arxiv](https://arxiv.org/abs/2309.16671)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16671.md)]
- Decaf: Monocular Deformation Capture for Face and Hand Interactions - [[Arxiv](https://arxiv.org/abs/2309.16670)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16670.md)]
- RealFill: Reference-Driven Generation for Authentic Image Completion - [[Arxiv](https://arxiv.org/abs/2309.16668)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16668.md)]
- DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content   Creation - [[Arxiv](https://arxiv.org/abs/2309.16653)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16653.md)]
- ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and   Planning - [[Arxiv](https://arxiv.org/abs/2309.16650)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16650.md)]
- Deep Geometrized Cartoon Line Inbetweening - [[Arxiv](https://arxiv.org/abs/2309.16643)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16643.md)]
- Qwen Technical Report - [[Arxiv](https://arxiv.org/abs/2309.16609)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16609.md)]
- Vision Transformers Need Registers - [[Arxiv](https://arxiv.org/abs/2309.16588)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16588.md)]
- Text-to-3D using Gaussian Splatting - [[Arxiv](https://arxiv.org/abs/2309.16585)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16585.md)]
- GPT-Fathom: Benchmarking Large Language Models to Decipher the   Evolutionary Path towards GPT-4 and Beyond - [[Arxiv](https://arxiv.org/abs/2309.16583)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16583.md)]
- MotionLM: Multi-Agent Motion Forecasting as Language Modeling - [[Arxiv](https://arxiv.org/abs/2309.16534)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16534.md)]
- CCEdit: Creative and Controllable Video Editing via Diffusion Models - [[Arxiv](https://arxiv.org/abs/2309.16496)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16496.md)]
- Diverse and Aligned Audio-to-Video Generation via Text-to-Video Model   Adaptation - [[Arxiv](https://arxiv.org/abs/2309.16429)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16429.md)]
- AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2309.16414)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16414.md)]
- Dark Side Augmentation: Generating Diverse Night Examples for Metric   Learning - [[Arxiv](https://arxiv.org/abs/2309.16351)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16351.md)]
- Language models in molecular discovery - [[Arxiv](https://arxiv.org/abs/2309.16235)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16235.md)]
- AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model - [[Arxiv](https://arxiv.org/abs/2309.16058)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16058.md)]
- Effective Long-Context Scaling of Foundation Models - [[Arxiv](https://arxiv.org/abs/2309.16039)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16039.md)]
- Show-1: Marrying Pixel and Latent Diffusion Models for Text-to-Video   Generation - [[Arxiv](https://arxiv.org/abs/2309.15818)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15818.md)]
- Emu: Enhancing Image Generation Models Using Photogenic Needles in a   Haystack - [[Arxiv](https://arxiv.org/abs/2309.15807)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15807.md)]
- Aperture Diffraction for Compact Snapshot Spectral Imaging - [[Arxiv](https://arxiv.org/abs/2309.16372)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.16372.md)]
- Borges and AI - [[Arxiv](https://arxiv.org/abs/2310.01425)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.01425.md)]
- Jointly Training Large Autoregressive Multimodal Models - [[Arxiv](https://arxiv.org/abs/2309.15564)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15564.md)]
- Finite Scalar Quantization: VQ-VAE Made Simple - [[Arxiv](https://arxiv.org/abs/2309.15505)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15505.md)]
- Graph Neural Prompting with Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.15427)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15427.md)]
- NeuRBF: A Neural Fields Representation with Adaptive Radial Basis   Functions - [[Arxiv](https://arxiv.org/abs/2309.15426)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15426.md)]
- DECO: Dense Estimation of 3D Human-Scene Contact In The Wild - [[Arxiv](https://arxiv.org/abs/2309.15273)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15273.md)]
- Zero-Shot Constrained Motion Planning Transformers Using Learned   Sampling Dictionaries - [[Arxiv](https://arxiv.org/abs/2309.15272)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15272.md)]
- VPA: Fully Test-Time Visual Prompt Adaptation - [[Arxiv](https://arxiv.org/abs/2309.15251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15251.md)]
- Low-rank Adaptation of Large Language Model Rescoring for   Parameter-Efficient Speech Recognition - [[Arxiv](https://arxiv.org/abs/2309.15223)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15223.md)]
- LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2309.15103)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15103.md)]
- Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of   Language Models - [[Arxiv](https://arxiv.org/abs/2309.15098)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15098.md)]
- VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided   Planning - [[Arxiv](https://arxiv.org/abs/2309.15091)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15091.md)]
- RPEFlow: Multimodal Fusion of RGB-PointCloud-Event for Joint Optical   Flow and Scene Flow Estimation - [[Arxiv](https://arxiv.org/abs/2309.15082)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15082.md)]
- Don't throw away your value model! Making PPO even better via   Value-Guided Monte-Carlo Tree Search decoding - [[Arxiv](https://arxiv.org/abs/2309.15028)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15028.md)]
- Large Language Model Alignment: A Survey - [[Arxiv](https://arxiv.org/abs/2309.15025)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15025.md)]
- MoCaE: Mixture of Calibrated Experts Significantly Improves Object   Detection - [[Arxiv](https://arxiv.org/abs/2309.14976)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14976.md)]
- Treating Motion as Option with Output Selection for Unsupervised Video   Object Segmentation - [[Arxiv](https://arxiv.org/abs/2309.14786)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14786.md)]
- QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.14717)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14717.md)]
- NDC-Scene: Boost Monocular 3D Semantic Scene Completion in Normalized   Device Coordinates Space - [[Arxiv](https://arxiv.org/abs/2309.14616)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14616.md)]
- Efficient Post-training Quantization with FP8 Formats - [[Arxiv](https://arxiv.org/abs/2309.14592)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14592.md)]
- CWCL: Cross-Modal Transfer with Continuously Weighted Contrastive Loss - [[Arxiv](https://arxiv.org/abs/2309.14580)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14580.md)]
- Aligning Large Multimodal Models with Factually Augmented RLHF - [[Arxiv](https://arxiv.org/abs/2309.14525)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14525.md)]
- DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme   Long Sequence Transformer Models - [[Arxiv](https://arxiv.org/abs/2309.14509)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14509.md)]
- Electronic properties, correlated topology and Green's function zeros - [[Arxiv](https://arxiv.org/abs/2309.14340)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14340.md)]
- Extreme Parkour with Legged Robots - [[Arxiv](https://arxiv.org/abs/2309.14341)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14341.md)]
- DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via   Multi-Modal Causal Attention - [[Arxiv](https://arxiv.org/abs/2309.14327)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14327.md)]
- Physics of Language Models: Part 3.2, Knowledge Manipulation - [[Arxiv](https://arxiv.org/abs/2309.14402)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14402.md)]
- Small-scale proxies for large-scale Transformer training instabilities - [[Arxiv](https://arxiv.org/abs/2309.14322)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14322.md)]
- Tiled Multiplane Images for Practical 3D Photography - [[Arxiv](https://arxiv.org/abs/2309.14291)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14291.md)]
- Only 5\% Attention Is All You Need: Efficient Long-range Document-level   Neural Machine Translation - [[Arxiv](https://arxiv.org/abs/2309.14174)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.14174.md)]
- May I Ask a Follow-up Question? Understanding the Benefits of   Conversations in Neural Network Explainability - [[Arxiv](https://arxiv.org/abs/2309.13965)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13965.md)]
- VidChapters-7M: Video Chapters at Scale - [[Arxiv](https://arxiv.org/abs/2309.13952)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13952.md)]
- Impact of Human-AI Interaction on User Trust and Reliance in AI-Assisted   Qualitative Coding - [[Arxiv](https://arxiv.org/abs/2309.13858)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13858.md)]
- Evaluating Cognitive Maps and Planning in Large Language Models with   CogEval - [[Arxiv](https://arxiv.org/abs/2309.15129)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.15129.md)]
- Embers of Autoregression: Understanding Large Language Models Through   the Problem They are Trained to Solve - [[Arxiv](https://arxiv.org/abs/2309.13638)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13638.md)]
- LOGICSEG: Parsing Visual Semantics with Neural Logic Learning and   Reasoning - [[Arxiv](https://arxiv.org/abs/2309.13556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13556.md)]
- MediViSTA-SAM: Zero-shot Medical Video Analysis with Spatio-temporal SAM   Adaptation - [[Arxiv](https://arxiv.org/abs/2309.13539)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13539.md)]
- Attention Is All You Need For Blind Room Volume Estimation - [[Arxiv](https://arxiv.org/abs/2309.13504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13504.md)]
- Learning Invariant Representations with a Nonparametric Nadaraya-Watson   Head - [[Arxiv](https://arxiv.org/abs/2309.13377)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13377.md)]
- MLPST: MLP is All You Need for Spatio-Temporal Prediction - [[Arxiv](https://arxiv.org/abs/2309.13363)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13363.md)]
- Probing the Moral Development of Large Language Models through Defining   Issues Test - [[Arxiv](https://arxiv.org/abs/2309.13356)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13356.md)]
- Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models   through Logic - [[Arxiv](https://arxiv.org/abs/2309.13339)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13339.md)]
- Calibrating LLM-Based Evaluator - [[Arxiv](https://arxiv.org/abs/2309.13308)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13308.md)]
- Defending Pre-trained Language Models as Few-shot Learners against   Backdoor Attacks - [[Arxiv](https://arxiv.org/abs/2309.13256)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13256.md)]
- Spatial-frequency channels, shape bias, and adversarial robustness - [[Arxiv](https://arxiv.org/abs/2309.13190)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13190.md)]
- E(2)-Equivariant Graph Planning for Navigation - [[Arxiv](https://arxiv.org/abs/2309.13043)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13043.md)]
- MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary   Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2309.13042)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13042.md)]
- Robotic Offline RL from Internet Videos via Value-Function Pre-Training - [[Arxiv](https://arxiv.org/abs/2309.13041)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13041.md)]
- NeRRF: 3D Reconstruction and View Synthesis for Transparent and Specular   Objects with Neural Refractive-Reflective Fields - [[Arxiv](https://arxiv.org/abs/2309.13039)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13039.md)]
- Privacy Assessment on Reconstructed Images: Are Existing Evaluation   Metrics Faithful to Human Perception? - [[Arxiv](https://arxiv.org/abs/2309.13038)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13038.md)]
- GELLO: A General, Low-Cost, and Intuitive Teleoperation Framework for   Robot Manipulators - [[Arxiv](https://arxiv.org/abs/2309.13037)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13037.md)]
- PyPose v0.6: The Imperative Programming Interface for Robotics - [[Arxiv](https://arxiv.org/abs/2309.13035)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13035.md)]
- Memory-augmented conformer for improved end-to-end long-form ASR - [[Arxiv](https://arxiv.org/abs/2309.13029)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13029.md)]
- Graph Neural Network for Stress Predictions in Stiffened Panels Under   Uniform Loading - [[Arxiv](https://arxiv.org/abs/2309.13022)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13022.md)]
- A Hybrid Deep Learning-based Approach for Optimal Genotype by   Environment Selection - [[Arxiv](https://arxiv.org/abs/2309.13021)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13021.md)]
- Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient   Pruning of A Multilingual ASR Model - [[Arxiv](https://arxiv.org/abs/2309.13018)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13018.md)]
- Understanding Deep Gradient Leakage via Inversion Influence Functions - [[Arxiv](https://arxiv.org/abs/2309.13016)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13016.md)]
- Efficient N:M Sparse DNN Training Using Algorithm, Architecture, and   Dataflow Co-Design - [[Arxiv](https://arxiv.org/abs/2309.13015)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13015.md)]
- Performance Analysis of UNet and Variants for Medical Image Segmentation - [[Arxiv](https://arxiv.org/abs/2309.13013)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13013.md)]
- ReConcile: Round-Table Conference Improves Reasoning via Consensus among   Diverse LLMs - [[Arxiv](https://arxiv.org/abs/2309.13007)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13007.md)]
- Deep3DSketch+: Rapid 3D Modeling from Single Free-hand Sketches - [[Arxiv](https://arxiv.org/abs/2309.13006)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13006.md)]
- Pursuing Counterfactual Fairness via Sequential Autoencoder Across   Domains - [[Arxiv](https://arxiv.org/abs/2309.13005)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13005.md)]
- Expressive variational quantum circuits provide inherent privacy in   federated learning - [[Arxiv](https://arxiv.org/abs/2309.13002)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13002.md)]
- Audience-specific Explanations for Machine Translation - [[Arxiv](https://arxiv.org/abs/2309.12998)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12998.md)]
- Point Cloud Network: An Order of Magnitude Improvement in Linear Layer   Parameter Count - [[Arxiv](https://arxiv.org/abs/2309.12996)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12996.md)]
- Deep learning probability flows and entropy production rates in active   matter - [[Arxiv](https://arxiv.org/abs/2309.12991)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12991.md)]
- License Plate Recognition Based On Multi-Angle View Model - [[Arxiv](https://arxiv.org/abs/2309.12972)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12972.md)]
- Higher-order Graph Convolutional Network with Flower-Petals Laplacians   on Simplicial Complexes - [[Arxiv](https://arxiv.org/abs/2309.12971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12971.md)]
- PI-RADS v2 Compliant Automated Segmentation of Prostate Zones Using   co-training Motivated Multi-task Dual-Path CNN - [[Arxiv](https://arxiv.org/abs/2309.12970)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12970.md)]
- Detect Every Thing with Few Examples - [[Arxiv](https://arxiv.org/abs/2309.12969)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12969.md)]
- Nested Event Extraction upon Pivot Element Recogniton - [[Arxiv](https://arxiv.org/abs/2309.12960)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12960.md)]
- On Data Fabrication in Collaborative Vehicular Perception: Attacks and   Countermeasures - [[Arxiv](https://arxiv.org/abs/2309.12955)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12955.md)]
- Background Activation Suppression for Weakly Supervised Object   Localization and Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2309.12943)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12943.md)]
- Trusta: Reasoning about Assurance Cases with Formal Methods and Large   Language Models - [[Arxiv](https://arxiv.org/abs/2309.12941)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12941.md)]
- Self-Explanation Prompting Improves Dialogue Understanding in Large   Language Models - [[Arxiv](https://arxiv.org/abs/2309.12940)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12940.md)]
- Frustrated with Code Quality Issues? LLMs can Help! - [[Arxiv](https://arxiv.org/abs/2309.12938)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12938.md)]
- Evolving Spiking Neural Networks to Mimic PID Control for Autonomous   Blimps - [[Arxiv](https://arxiv.org/abs/2309.12937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12937.md)]
- TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts - [[Arxiv](https://arxiv.org/abs/2309.12934)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12934.md)]
- CodePlan: Repository-level Coding using LLMs and Planning - [[Arxiv](https://arxiv.org/abs/2309.12499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12499.md)]
- DualToken-ViT: Position-aware Efficient Vision Transformer with Dual   Token Fusion - [[Arxiv](https://arxiv.org/abs/2309.12424)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12424.md)]
- LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language   Model as an Agent - [[Arxiv](https://arxiv.org/abs/2309.12311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12311.md)]
- LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.12307)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12307.md)]
- PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for   Video Segmentation - [[Arxiv](https://arxiv.org/abs/2309.12303)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12303.md)]
- The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A" - [[Arxiv](https://arxiv.org/abs/2309.12288)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12288.md)]
- MetaMath: Bootstrap Your Own Mathematical Questions for Large Language   Models - [[Arxiv](https://arxiv.org/abs/2309.12284)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12284.md)]
- Boolformer: Symbolic Regression of Logic Functions with Transformers - [[Arxiv](https://arxiv.org/abs/2309.12207)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.12207.md)]
- LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset - [[Arxiv](https://arxiv.org/abs/2309.11998)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11998.md)]
- MEFLUT: Unsupervised 1D Lookup Tables for Multi-exposure Image Fusion - [[Arxiv](https://arxiv.org/abs/2309.11847)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11847.md)]
- A Paradigm Shift in Machine Translation: Boosting Translation   Performance of Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.11674)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11674.md)]
- BTLM-3B-8K: 7B Parameter Performance in a 3B Parameter Model - [[Arxiv](https://arxiv.org/abs/2309.11568)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11568.md)]
- A Large-scale Dataset for Audio-Language Representation Learning - [[Arxiv](https://arxiv.org/abs/2309.11500)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11500.md)]
- DreamLLM: Synergistic Multimodal Comprehension and Creation - [[Arxiv](https://arxiv.org/abs/2309.11499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11499.md)]
- FreeU: Free Lunch in Diffusion U-Net - [[Arxiv](https://arxiv.org/abs/2309.11497)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11497.md)]
- Chain-of-Verification Reduces Hallucination in Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.11495)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11495.md)]
- SCREWS: A Modular Framework for Reasoning with Revisions - [[Arxiv](https://arxiv.org/abs/2309.13075)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.13075.md)]
- Kosmos-2.5: A Multimodal Literate Model - [[Arxiv](https://arxiv.org/abs/2309.11419)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11419.md)]
- OpenChat: Advancing Open-source Language Models with Mixed-Quality Data - [[Arxiv](https://arxiv.org/abs/2309.11235)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11235.md)]
- The Languini Kitchen: Enabling Language Modelling Research at Different   Scales of Compute - [[Arxiv](https://arxiv.org/abs/2309.11197)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11197.md)]
- AutoSynth: Learning to Generate 3D Training Data for Object Point Cloud   Registration - [[Arxiv](https://arxiv.org/abs/2309.11170)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11170.md)]
- Multi-grained Temporal Prototype Learning for Few-shot Video Object   Segmentation - [[Arxiv](https://arxiv.org/abs/2309.11160)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11160.md)]
- More complex encoder is not all you need - [[Arxiv](https://arxiv.org/abs/2309.11139)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11139.md)]
- Contrastive Pseudo Learning for Open-World DeepFake Attribution - [[Arxiv](https://arxiv.org/abs/2309.11132)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11132.md)]
- Dense 2D-3D Indoor Prediction with Sound via Aligned Cross-Modal   Distillation - [[Arxiv](https://arxiv.org/abs/2309.11081)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11081.md)]
- Weak Supervision for Label Efficient Visual Bug Detection - [[Arxiv](https://arxiv.org/abs/2309.11077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11077.md)]
- The Topology and Geometry of Neural Representations - [[Arxiv](https://arxiv.org/abs/2309.11028)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11028.md)]
- Controllable Dynamic Appearance for Neural 3D Portraits - [[Arxiv](https://arxiv.org/abs/2309.11009)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11009.md)]
- RMT: Retentive Networks Meet Vision Transformers - [[Arxiv](https://arxiv.org/abs/2309.11523)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.11523.md)]
- LMDX: Language Model-based Document Information Extraction and   Localization - [[Arxiv](https://arxiv.org/abs/2309.10952)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10952.md)]
- End-to-End Speech Recognition Contextualization with Large Language   Models - [[Arxiv](https://arxiv.org/abs/2309.10917)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10917.md)]
- SlimPajama-DC: Understanding Data Combinations for LLM Training - [[Arxiv](https://arxiv.org/abs/2309.10818)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10818.md)]
- Sound Source Localization is All about Cross-Modal Alignment - [[Arxiv](https://arxiv.org/abs/2309.10724)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10724.md)]
- OpenBA: An Open-sourced 15B Bilingual Asymmetric seq2seq Model   Pre-trained from Scratch - [[Arxiv](https://arxiv.org/abs/2309.10706)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10706.md)]
- Language Modeling Is Compression - [[Arxiv](https://arxiv.org/abs/2309.10668)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10668.md)]
- NDDepth: Normal-Distance Assisted Monocular Depth Estimation - [[Arxiv](https://arxiv.org/abs/2309.10592)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10592.md)]
- Few-shot Object Detection in Remote Sensing: Lifting the Curse of   Incompletely Annotated Novel Objects - [[Arxiv](https://arxiv.org/abs/2309.10588)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10588.md)]
- FoleyGen: Visually-Guided Audio Generation - [[Arxiv](https://arxiv.org/abs/2309.10537)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10537.md)]
- AutoDiffusion: Training-Free Optimization of Time Steps and   Architectures for Automated Diffusion Model Acceleration - [[Arxiv](https://arxiv.org/abs/2309.10438)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10438.md)]
- Augmenting Tactile Simulators with Real-like and Zero-Shot Capabilities - [[Arxiv](https://arxiv.org/abs/2309.10409)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10409.md)]
- PoSE: Efficient Context Window Extension of LLMs via Positional   Skip-wise Training - [[Arxiv](https://arxiv.org/abs/2309.10400)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10400.md)]
- Rigorously Assessing Natural Language Explanations of Neurons - [[Arxiv](https://arxiv.org/abs/2309.10312)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10312.md)]
- Baichuan 2: Open Large-scale Language Models - [[Arxiv](https://arxiv.org/abs/2309.10305)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10305.md)]
- 360$^\circ$ Reconstruction From a Single Image Using Space Carved   Outpainting - [[Arxiv](https://arxiv.org/abs/2309.10279)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10279.md)]
- Stabilizing RLHF through Advantage Model and Selective Rehearsal - [[Arxiv](https://arxiv.org/abs/2309.10202)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10202.md)]
- Q-Transformer: Scalable Offline Reinforcement Learning via   Autoregressive Q-Functions - [[Arxiv](https://arxiv.org/abs/2309.10150)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10150.md)]
- Unified Coarse-to-Fine Alignment for Video-Text Retrieval - [[Arxiv](https://arxiv.org/abs/2309.10091)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10091.md)]
- Multimodal Foundation Models: From Specialists to General-Purpose   Assistants - [[Arxiv](https://arxiv.org/abs/2309.10020)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.10020.md)]
- MindAgent: Emergent Gaming Interaction - [[Arxiv](https://arxiv.org/abs/2309.09971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09971.md)]
- Generating and Imputing Tabular Data via Diffusion and Flow-based   Gradient-Boosted Trees - [[Arxiv](https://arxiv.org/abs/2309.09968)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09968.md)]
- An Empirical Study of Scaling Instruct-Tuned Large Multimodal Models - [[Arxiv](https://arxiv.org/abs/2309.09958)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09958.md)]
- Robust Geometry-Preserving Depth Estimation Using Differentiable   Rendering - [[Arxiv](https://arxiv.org/abs/2309.09724)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09724.md)]
- CATR: Combinatorial-Dependence Audio-Queried Transformer for   Audio-Visual Video Segmentation - [[Arxiv](https://arxiv.org/abs/2309.09709)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09709.md)]
- Adapting Large Language Models via Reading Comprehension - [[Arxiv](https://arxiv.org/abs/2309.09530)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09530.md)]
- LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language   Models - [[Arxiv](https://arxiv.org/abs/2309.09506)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09506.md)]
- Discovering Sounding Objects by Audio Queries for Audio Visual   Segmentation - [[Arxiv](https://arxiv.org/abs/2309.09501)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09501.md)]
- CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large   Language Models in 167 Languages - [[Arxiv](https://arxiv.org/abs/2309.09400)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09400.md)]
- Augmenting text for spoken language understanding with Large Language   Models - [[Arxiv](https://arxiv.org/abs/2309.09390)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09390.md)]
- Embrace Divergence for Richer Insights: A Multi-document Summarization   Benchmark and a Case Study on Summarizing Diverse Information from News   Articles - [[Arxiv](https://arxiv.org/abs/2309.09369)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09369.md)]
- OWL: A Large Language Model for IT Operations - [[Arxiv](https://arxiv.org/abs/2309.09298)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09298.md)]
- LivelySpeaker: Towards Semantic-Aware Co-Speech Gesture Generation - [[Arxiv](https://arxiv.org/abs/2309.09294)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09294.md)]
- Contrastive Decoding Improves Reasoning in Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.09117)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.09117.md)]
- Sorted LLaMA: Unlocking the Potential of Intermediate Layers of Large   Language Models for Dynamic Inference Using Sorted Fine-Tuning (SoFT) - [[Arxiv](https://arxiv.org/abs/2309.08968)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08968.md)]
- Struc-Bench: Are Large Language Models Really Good at Generating Complex   Structured Data? - [[Arxiv](https://arxiv.org/abs/2309.08963)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08963.md)]
- Monolingual or Multilingual Instruction Tuning: Which Makes a Better   Alpaca - [[Arxiv](https://arxiv.org/abs/2309.08958)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08958.md)]
- PDFTriage: Question Answering over Long, Structured Documents - [[Arxiv](https://arxiv.org/abs/2309.08872)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08872.md)]
- S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking   in the Era of LLMs - [[Arxiv](https://arxiv.org/abs/2309.08827)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08827.md)]
- Stack-and-Delay: a new codebook pattern for music generation - [[Arxiv](https://arxiv.org/abs/2309.08804)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08804.md)]
- Enhance audio generation controllability through representation   similarity regularization - [[Arxiv](https://arxiv.org/abs/2309.08773)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08773.md)]
- BANSAC: A dynamic BAyesian Network for adaptive SAmple Consensus - [[Arxiv](https://arxiv.org/abs/2309.08690)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08690.md)]
- Sparse Autoencoders Find Highly Interpretable Features in Language   Models - [[Arxiv](https://arxiv.org/abs/2309.08600)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08600.md)]
- Robust Frame-to-Frame Camera Rotation Estimation in Crowded Scenes - [[Arxiv](https://arxiv.org/abs/2309.08588)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08588.md)]
- Compositional Foundation Models for Hierarchical Planning - [[Arxiv](https://arxiv.org/abs/2309.08587)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08587.md)]
- Replacing softmax with ReLU in Vision Transformers - [[Arxiv](https://arxiv.org/abs/2309.08586)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08586.md)]
- Connecting Large Language Models with Evolutionary Algorithms Yields   Powerful Prompt Optimizers - [[Arxiv](https://arxiv.org/abs/2309.08532)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08532.md)]
- Scaling Laws for Sparsely-Connected Foundation Models - [[Arxiv](https://arxiv.org/abs/2309.08520)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08520.md)]
- Using Large Language Models for Knowledge Engineering (LLMKE): A Case   Study on Wikidata - [[Arxiv](https://arxiv.org/abs/2309.08491)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08491.md)]
- Deformable Neural Radiance Fields using RGB and Event Cameras - [[Arxiv](https://arxiv.org/abs/2309.08416)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08416.md)]
- Cure the headache of Transformers via Collinear Constrained Attention - [[Arxiv](https://arxiv.org/abs/2309.08646)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08646.md)]
- Investigating Answerability of LLMs for Long-Form Question Answering - [[Arxiv](https://arxiv.org/abs/2309.08210)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08210.md)]
- LASER: LLM Agent with State-Space Exploration for Web Navigation - [[Arxiv](https://arxiv.org/abs/2309.08172)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08172.md)]
- Draft &amp; Verify: Lossless Large Language Model Acceleration via   Self-Speculative Decoding - [[Arxiv](https://arxiv.org/abs/2309.08168)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08168.md)]
- RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue - [[Arxiv](https://arxiv.org/abs/2309.08156)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08156.md)]
- Retrieval-Augmented Text-to-Audio Generation - [[Arxiv](https://arxiv.org/abs/2309.08051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08051.md)]
- Leveraging Contextual Information for Effective Entity Salience   Detection - [[Arxiv](https://arxiv.org/abs/2309.07990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07990.md)]
- Viewpoint Textual Inversion: Unleashing Novel View Synthesis with   Pretrained 2D Diffusion Models - [[Arxiv](https://arxiv.org/abs/2309.07986)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07986.md)]
- A Data Source for Reasoning Embodied Agents - [[Arxiv](https://arxiv.org/abs/2309.07974)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07974.md)]
- Language Embedded Radiance Fields for Zero-Shot Task-Oriented Grasping - [[Arxiv](https://arxiv.org/abs/2309.07970)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07970.md)]
- ALWOD: Active Learning for Weakly-Supervised Object Detection - [[Arxiv](https://arxiv.org/abs/2309.07914)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07914.md)]
- Disentangling Spatial and Temporal Learning for Efficient Image-to-Video   Transfer Learning - [[Arxiv](https://arxiv.org/abs/2309.07911)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07911.md)]
- TEMPO: Efficient Multi-View Pose Estimation, Tracking, and Forecasting - [[Arxiv](https://arxiv.org/abs/2309.07910)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07910.md)]
- Generative Image Dynamics - [[Arxiv](https://arxiv.org/abs/2309.07906)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07906.md)]
- Ambiguity-Aware In-Context Learning with Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.07900)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07900.md)]
- Agents: An Open-source Framework for Autonomous Language Agents - [[Arxiv](https://arxiv.org/abs/2309.07870)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07870.md)]
- The Rise and Potential of Large Language Model Based Agents: A Survey - [[Arxiv](https://arxiv.org/abs/2309.07864)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07864.md)]
- TextBind: Multi-turn Interleaved Multimodal Instruction-following in the   Wild - [[Arxiv](https://arxiv.org/abs/2309.08637)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08637.md)]
- OmnimatteRF: Robust Omnimatte with 3D Background Modeling - [[Arxiv](https://arxiv.org/abs/2309.07749)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07749.md)]
- Efficiently Robustify Pre-trained Models - [[Arxiv](https://arxiv.org/abs/2309.07499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07499.md)]
- EP2P-Loc: End-to-End 3D Point to 2D Pixel Localization for Large-Scale   Visual Localization - [[Arxiv](https://arxiv.org/abs/2309.07471)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07471.md)]
- Are Large Language Model-based Evaluators the Solution to Scaling Up   Multilingual Evaluation? - [[Arxiv](https://arxiv.org/abs/2309.07462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07462.md)]
- Clinical Text Summarization: Adapting Large Language Models Can   Outperform Human Experts - [[Arxiv](https://arxiv.org/abs/2309.07430)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07430.md)]
- Flexible Visual Recognition by Evidential Modeling of Confusion and   Ignorance - [[Arxiv](https://arxiv.org/abs/2309.07403)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07403.md)]
- AudioSR: Versatile Audio Super-resolution at Scale - [[Arxiv](https://arxiv.org/abs/2309.07314)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07314.md)]
- Pretraining on the Test Set Is All You Need - [[Arxiv](https://arxiv.org/abs/2309.08632)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08632.md)]
- All you need is spin: SU(2) equivariant variational quantum circuits   based on spin networks - [[Arxiv](https://arxiv.org/abs/2309.07250)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07250.md)]
- Text-Guided Generation and Editing of Compositional 3D Avatars - [[Arxiv](https://arxiv.org/abs/2309.07125)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07125.md)]
- RAIN: Your Language Models Can Align Themselves without Finetuning - [[Arxiv](https://arxiv.org/abs/2309.07124)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07124.md)]
- Tree-Structured Shading Decomposition - [[Arxiv](https://arxiv.org/abs/2309.07122)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07122.md)]
- SupFusion: Supervised LiDAR-Camera Fusion for 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2309.07084)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07084.md)]
- Efficient Reinforcement Learning for Jumping Monopods - [[Arxiv](https://arxiv.org/abs/2309.07038)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07038.md)]
- DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2309.06933)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06933.md)]
- MagiCapture: High-Resolution Multi-Concept Portrait Customization - [[Arxiv](https://arxiv.org/abs/2309.06895)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06895.md)]
- Keep It SimPool: Who Said Supervised Transformers Suffer from Attention   Deficit? - [[Arxiv](https://arxiv.org/abs/2309.06891)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06891.md)]
- Leveraging SE(3) Equivariance for Learning 3D Geometric Shape Assembly - [[Arxiv](https://arxiv.org/abs/2309.06810)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06810.md)]
- Dynamic NeRFs for Soccer Scenes - [[Arxiv](https://arxiv.org/abs/2309.06802)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06802.md)]
- Cognitive Mirage: A Review of Hallucinations in Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.06794)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06794.md)]
- MPI-Flow: Learning Realistic Optical Flow with Multiplane Images - [[Arxiv](https://arxiv.org/abs/2309.06714)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06714.md)]
- VLSlice: Interactive Vision-and-Language Slice Discovery - [[Arxiv](https://arxiv.org/abs/2309.06703)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06703.md)]
- Generalizable Neural Fields as Partially Observed Neural Processes - [[Arxiv](https://arxiv.org/abs/2309.06660)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06660.md)]
- Statistical Rejection Sampling Improves Preference Optimization - [[Arxiv](https://arxiv.org/abs/2309.06657)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06657.md)]
- A Distributed Data-Parallel PyTorch Implementation of the Distributed   Shampoo Optimizer for Training Neural Networks At-Scale - [[Arxiv](https://arxiv.org/abs/2309.06497)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06497.md)]
- Learning Disentangled Avatars with Hybrid 3D Representations - [[Arxiv](https://arxiv.org/abs/2309.06441)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06441.md)]
- LEAP Hand: Low-Cost, Efficient, and Anthropomorphic Hand for Robot   Learning - [[Arxiv](https://arxiv.org/abs/2309.06440)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06440.md)]
- InstaFlow: One Step is Enough for High-Quality Diffusion-Based   Text-to-Image Generation - [[Arxiv](https://arxiv.org/abs/2309.06380)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06380.md)]
- Recovering from Privacy-Preserving Masking with Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.08628)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.08628.md)]
- Modality Unifying Network for Visible-Infrared Person Re-Identification - [[Arxiv](https://arxiv.org/abs/2309.06262)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06262.md)]
- Efficient Memory Management for Large Language Model Serving with   PagedAttention - [[Arxiv](https://arxiv.org/abs/2309.06180)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06180.md)]
- AstroLLaMA: Towards Specialized Foundation Models in Astronomy - [[Arxiv](https://arxiv.org/abs/2309.06126)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.06126.md)]
- Uncovering mesa-optimization algorithms in Transformers - [[Arxiv](https://arxiv.org/abs/2309.05858)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05858.md)]
- Large Language Models for Compiler Optimization - [[Arxiv](https://arxiv.org/abs/2309.07062)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.07062.md)]
- SHIFT3D: Synthesizing Hard Inputs For Tricking 3D Detectors - [[Arxiv](https://arxiv.org/abs/2309.05810)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05810.md)]
- PhotoVerse: Tuning-Free Image Customization with Text-to-Image Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2309.05793)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05793.md)]
- Diffusion-Guided Reconstruction of Everyday Hand-Object Interaction   Clips - [[Arxiv](https://arxiv.org/abs/2309.05663)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05663.md)]
- Large Language Model for Science: A Study on P vs. NP - [[Arxiv](https://arxiv.org/abs/2309.05689)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05689.md)]
- UniSeg: A Unified Multi-Modal LiDAR Segmentation Network and the   OpenPCSeg Codebase - [[Arxiv](https://arxiv.org/abs/2309.05573)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05573.md)]
- ITI-GEN: Inclusive Text-to-Image Generation - [[Arxiv](https://arxiv.org/abs/2309.05569)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05569.md)]
- NExT-GPT: Any-to-Any Multimodal LLM - [[Arxiv](https://arxiv.org/abs/2309.05519)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05519.md)]
- Optimize Weight Rounding via Signed Gradient Descent for the   Quantization of LLMs - [[Arxiv](https://arxiv.org/abs/2309.05516)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05516.md)]
- Textbooks Are All You Need II: phi-1.5 technical report - [[Arxiv](https://arxiv.org/abs/2309.05463)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05463.md)]
- Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient   MoE for Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2309.05444)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05444.md)]
- Class-Incremental Grouping Network for Continual Audio-Visual Learning - [[Arxiv](https://arxiv.org/abs/2309.05281)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05281.md)]
- Multi3DRefer: Grounding Text Description to Multiple 3D Objects - [[Arxiv](https://arxiv.org/abs/2309.05251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05251.md)]
- Does Writing with Language Models Reduce Content Diversity? - [[Arxiv](https://arxiv.org/abs/2309.05196)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05196.md)]
- Towards Viewpoint Robustness in Bird's Eye View Segmentation - [[Arxiv](https://arxiv.org/abs/2309.05192)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05192.md)]
- Beyond Skin Tone: A Multidimensional Measure of Apparent Skin Color - [[Arxiv](https://arxiv.org/abs/2309.05148)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05148.md)]
- 3D Implicit Transporter for Temporally Consistent Keypoint Discovery - [[Arxiv](https://arxiv.org/abs/2309.05098)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05098.md)]
- An Appraisal-Based Chain-Of-Emotion Architecture for Affective Language   Model Game Agents - [[Arxiv](https://arxiv.org/abs/2309.05076)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05076.md)]
- Multi-view Self-supervised Disentanglement for General Image Denoising - [[Arxiv](https://arxiv.org/abs/2309.05049)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.05049.md)]
- Mitigating Word Bias in Zero-shot Prompt-based Classifiers - [[Arxiv](https://arxiv.org/abs/2309.04992)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04992.md)]
- Efficient Emotional Adaptation for Audio-Driven Talking-Head Generation - [[Arxiv](https://arxiv.org/abs/2309.04946)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04946.md)]
- Effective Real Image Editing with Accelerated Iterative Diffusion   Inversion - [[Arxiv](https://arxiv.org/abs/2309.04907)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04907.md)]
- Leveraging Large Language Models for Exploiting ASR Uncertainty - [[Arxiv](https://arxiv.org/abs/2309.04842)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04842.md)]
- Neurons in Large Language Models: Dead, N-gram, Positional - [[Arxiv](https://arxiv.org/abs/2309.04827)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04827.md)]
- Towards Real-World Burst Image Super-Resolution: Benchmark and Method - [[Arxiv](https://arxiv.org/abs/2309.04803)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04803.md)]
- VeRi3D: Generative Vertex-based Radiance Fields for 3D Controllable   Human Image Synthesis - [[Arxiv](https://arxiv.org/abs/2309.04800)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04800.md)]
- Towards Robust Model Watermark via Reducing Parametric Vulnerability - [[Arxiv](https://arxiv.org/abs/2309.04777)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04777.md)]
- SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment   to Cultural Reasoning - [[Arxiv](https://arxiv.org/abs/2309.04766)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04766.md)]
- When to Learn What: Model-Adaptive Data Augmentation Curriculum - [[Arxiv](https://arxiv.org/abs/2309.04747)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04747.md)]
- FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning - [[Arxiv](https://arxiv.org/abs/2309.04663)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04663.md)]
- MADLAD-400: A Multilingual And Document-Level Large Audited Dataset - [[Arxiv](https://arxiv.org/abs/2309.04662)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04662.md)]
- Exploring Large Language Models for Communication Games: An Empirical   Study on Werewolf - [[Arxiv](https://arxiv.org/abs/2309.04658)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04658.md)]
- Dynamic Mesh-Aware Radiance Fields - [[Arxiv](https://arxiv.org/abs/2309.04581)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04581.md)]
- When Less is More: Investigating Data Pruning for Pretraining LLMs at   Scale - [[Arxiv](https://arxiv.org/abs/2309.04564)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04564.md)]
- Examining Autoexposure for Challenging Scenes - [[Arxiv](https://arxiv.org/abs/2309.04542)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04542.md)]
- Video Task Decathlon: Unifying Image and Video Tasks in Autonomous   Driving - [[Arxiv](https://arxiv.org/abs/2309.04422)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04422.md)]
- DeformToon3D: Deformable 3D Toonification from Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2309.04410)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04410.md)]
- Mobile V-MoEs: Scaling Down Vision Transformers via Sparse   Mixture-of-Experts - [[Arxiv](https://arxiv.org/abs/2309.04354)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04354.md)]
- The Power of Sound (TPoS): Audio Reactive Video Generation with Stable   Diffusion - [[Arxiv](https://arxiv.org/abs/2309.04509)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04509.md)]
- From Sparse to Dense: GPT-4 Summarization with Chain of Density   Prompting - [[Arxiv](https://arxiv.org/abs/2309.04269)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04269.md)]
- Towards Practical Capture of High-Fidelity Relightable Avatars - [[Arxiv](https://arxiv.org/abs/2309.04247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04247.md)]
- Unsupervised Object Localization with Representer Point Selection - [[Arxiv](https://arxiv.org/abs/2309.04172)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04172.md)]
- NESTLE: a No-Code Tool for Statistical Analysis of Legal Corpus - [[Arxiv](https://arxiv.org/abs/2309.04146)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04146.md)]
- Evaluation and Mitigation of Agnosia in Multimodal Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.04041)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.04041.md)]
- CDFSL-V: Cross-Domain Few-Shot Learning for Videos - [[Arxiv](https://arxiv.org/abs/2309.03989)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03989.md)]
- LanSER: Language-Model Supported Speech Emotion Recognition - [[Arxiv](https://arxiv.org/abs/2309.03978)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03978.md)]
- ImageBind-LLM: Multi-modality Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2309.03905)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03905.md)]
- Tracking Anything with Decoupled Video Segmentation - [[Arxiv](https://arxiv.org/abs/2309.03903)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03903.md)]
- Learning Continuous Exposure Value Representations for Single-Image HDR   Reconstruction - [[Arxiv](https://arxiv.org/abs/2309.03900)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03900.md)]
- The Making and Breaking of Camouflage - [[Arxiv](https://arxiv.org/abs/2309.03899)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03899.md)]
- ProPainter: Improving Propagation and Transformer for Video Inpainting - [[Arxiv](https://arxiv.org/abs/2309.03897)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03897.md)]
- InstructDiffusion: A Generalist Modeling Interface for Vision Tasks - [[Arxiv](https://arxiv.org/abs/2309.03895)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03895.md)]
- A Function Interpretation Benchmark for Evaluating Interpretability   Methods - [[Arxiv](https://arxiv.org/abs/2309.03886)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03886.md)]
- DoLa: Decoding by Contrasting Layers Improves Factuality in Large   Language Models - [[Arxiv](https://arxiv.org/abs/2309.03883)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03883.md)]
- Large Language Models Are Not Robust Multiple Choice Selectors - [[Arxiv](https://arxiv.org/abs/2309.03882)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03882.md)]
- FLM-101B: An Open LLM and How to Train It with $100K Budget - [[Arxiv](https://arxiv.org/abs/2309.03852)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03852.md)]
- Panoramas from Photons - [[Arxiv](https://arxiv.org/abs/2309.03811)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03811.md)]
- SimNP: Learning Self-Similarity Priors Between Neural Points - [[Arxiv](https://arxiv.org/abs/2309.03809)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03809.md)]
- Phasic Content Fusing Diffusion Model with Directional Distribution   Consistency for Few-Shot Model Adaption - [[Arxiv](https://arxiv.org/abs/2309.03729)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03729.md)]
- Efficient Adaptive Human-Object Interaction Detection with   Concept-guided Memory - [[Arxiv](https://arxiv.org/abs/2309.03696)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03696.md)]
- Large-Scale Automatic Audiobook Creation - [[Arxiv](https://arxiv.org/abs/2309.03926)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03926.md)]
- Evaluating ChatGPT as a Recommender System: A Rigorous Approach - [[Arxiv](https://arxiv.org/abs/2309.03613)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03613.md)]
- Enhancing Sample Utilization through Sample Adaptive Augmentation in   Semi-Supervised Learning - [[Arxiv](https://arxiv.org/abs/2309.03598)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03598.md)]
- Text2Control3D: Controllable 3D Avatar Generation in Neural Radiance   Fields using Geometry-Guided Text-to-Image Diffusion Model - [[Arxiv](https://arxiv.org/abs/2309.03550)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03550.md)]
- Reuse and Diffuse: Iterative Denoising for Text-to-Video Generation - [[Arxiv](https://arxiv.org/abs/2309.03549)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03549.md)]
- Temporal Collection and Distribution for Referring Video Object   Segmentation - [[Arxiv](https://arxiv.org/abs/2309.03473)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03473.md)]
- SyncDreamer: Generating Multiview-consistent Images from a Single-view   Image - [[Arxiv](https://arxiv.org/abs/2309.03453)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03453.md)]
- Large Language Models as Optimizers - [[Arxiv](https://arxiv.org/abs/2309.03409)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03409.md)]
- Distribution-Aware Prompt Tuning for Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2309.03406)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03406.md)]
- Robotic Table Tennis: A Case Study into a High Speed Learning System - [[Arxiv](https://arxiv.org/abs/2309.03315)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03315.md)]
- Matcha-TTS: A fast TTS architecture with conditional flow matching - [[Arxiv](https://arxiv.org/abs/2309.03199)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03199.md)]
- Bayes' Rays: Uncertainty Quantification for Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2309.03185)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03185.md)]
- SLiMe: Segment Like Me - [[Arxiv](https://arxiv.org/abs/2309.03179)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03179.md)]
- ResFields: Residual Neural Fields for Spatiotemporal Signals - [[Arxiv](https://arxiv.org/abs/2309.03160)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03160.md)]
- MyoDex: A Generalizable Prior for Dexterous Manipulation - [[Arxiv](https://arxiv.org/abs/2309.03130)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03130.md)]
- Dynamic Hyperbolic Attention Network for Fine Hand-object Reconstruction - [[Arxiv](https://arxiv.org/abs/2309.02965)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02965.md)]
- GPT Can Solve Mathematical Problems Without a Calculator - [[Arxiv](https://arxiv.org/abs/2309.03241)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03241.md)]
- Zero-Resource Hallucination Prevention for Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.02654)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02654.md)]
- Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction   Tuning - [[Arxiv](https://arxiv.org/abs/2309.02591)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02591.md)]
- Physically Grounded Vision-Language Models for Robotic Manipulation - [[Arxiv](https://arxiv.org/abs/2309.02561)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02561.md)]
- A skeletonization algorithm for gradient-based optimization - [[Arxiv](https://arxiv.org/abs/2309.02527)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02527.md)]
- GO-SLAM: Global Optimization for Consistent 3D Instant Reconstruction - [[Arxiv](https://arxiv.org/abs/2309.02436)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02436.md)]
- Building a Winning Team: Selecting Source Model Ensembles using a   Submodular Transferability Estimation Approach - [[Arxiv](https://arxiv.org/abs/2309.02429)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02429.md)]
- Cognitive Architectures for Language Agents - [[Arxiv](https://arxiv.org/abs/2309.02427)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02427.md)]
- EgoPCA: A New Framework for Egocentric Hand-Object Interaction   Understanding - [[Arxiv](https://arxiv.org/abs/2309.02423)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02423.md)]
- Doppelgangers: Learning to Disambiguate Images of Similar Structures - [[Arxiv](https://arxiv.org/abs/2309.02420)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02420.md)]
- Generating Realistic Images from In-the-wild Sounds - [[Arxiv](https://arxiv.org/abs/2309.02405)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02405.md)]
- Prototype-based Dataset Comparison - [[Arxiv](https://arxiv.org/abs/2309.02401)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02401.md)]
- Explaining grokking through circuit efficiency - [[Arxiv](https://arxiv.org/abs/2309.02390)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02390.md)]
- CIEM: Contrastive Instruction Evaluation Method for Better Instruction   Tuning - [[Arxiv](https://arxiv.org/abs/2309.02301)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02301.md)]
- Making Large Language Models Better Reasoners with Alignment - [[Arxiv](https://arxiv.org/abs/2309.02144)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02144.md)]
- Multi-label affordance mapping from egocentric vision - [[Arxiv](https://arxiv.org/abs/2309.02120)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02120.md)]
- Iterative Superquadric Recomposition of 3D Objects from Multiple Views - [[Arxiv](https://arxiv.org/abs/2309.02102)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02102.md)]
- Learning Cross-Modal Affinity for Referring Video Object Segmentation   Targeting Limited Samples - [[Arxiv](https://arxiv.org/abs/2309.02041)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02041.md)]
- Data-Juicer: A One-Stop Data Processing System for Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.02033)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02033.md)]
- RawHDR: High Dynamic Range Image Reconstruction from a Single Raw Image - [[Arxiv](https://arxiv.org/abs/2309.02020)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.02020.md)]
- NICE: CVPR 2023 Challenge on Zero-shot Image Captioning - [[Arxiv](https://arxiv.org/abs/2309.01961)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01961.md)]
- Empowering Low-Light Image Enhancer through Customized Learnable Priors - [[Arxiv](https://arxiv.org/abs/2309.01958)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01958.md)]
- Towards Universal Image Embeddings: A Large-Scale Dataset and Challenge   for Generic Image Representations - [[Arxiv](https://arxiv.org/abs/2309.01858)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01858.md)]
- One Wide Feedforward is All You Need - [[Arxiv](https://arxiv.org/abs/2309.01826)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01826.md)]
- Are Emergent Abilities in Large Language Models just In-Context   Learning? - [[Arxiv](https://arxiv.org/abs/2309.01809)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01809.md)]
- An Empirical Analysis for Zero-Shot Multi-Label Classification on   COVID-19 CT Scans and Uncurated Reports - [[Arxiv](https://arxiv.org/abs/2309.01740)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01740.md)]
- Mask-Attention-Free Transformer for 3D Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2309.01692)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01692.md)]
- AGG-Net: Attention Guided Gated-convolutional Network for Depth Image   Completion - [[Arxiv](https://arxiv.org/abs/2309.01624)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01624.md)]
- Raw Data Is All You Need: Virtual Axle Detector with Enhanced Receptive   Field - [[Arxiv](https://arxiv.org/abs/2309.01574)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01574.md)]
- A Blackbox Model Is All You Need to Breach Privacy: Smart Grid   Forecasting Models as a Use Case - [[Arxiv](https://arxiv.org/abs/2309.01523)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01523.md)]
- Adapting Segment Anything Model for Change Detection in HR Remote   Sensing Images - [[Arxiv](https://arxiv.org/abs/2309.01429)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01429.md)]
- Unified Pre-training with Pseudo Texts for Text-To-Image Person   Re-identification - [[Arxiv](https://arxiv.org/abs/2309.01420)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01420.md)]
- Memory augment is All You Need for image restoration - [[Arxiv](https://arxiv.org/abs/2309.01377)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01377.md)]
- EMR-MSF: Self-Supervised Recurrent Monocular Scene Flow Exploiting   Ego-Motion Rigidity - [[Arxiv](https://arxiv.org/abs/2309.01296)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01296.md)]
- SOAR: Scene-debiasing Open-set Action Recognition - [[Arxiv](https://arxiv.org/abs/2309.01265)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01265.md)]
- Towards Generic Image Manipulation Detection with Weakly-Supervised   Self-Consistency Learning - [[Arxiv](https://arxiv.org/abs/2309.01246)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01246.md)]
- LoGoPrompt: Synthetic Text Images Can Be Good Visual Prompts for   Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2309.01155)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01155.md)]
- EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment - [[Arxiv](https://arxiv.org/abs/2309.01151)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01151.md)]
- Attention Where It Matters: Rethinking Visual Document Understanding   with Selective Region Concentration - [[Arxiv](https://arxiv.org/abs/2309.01131)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01131.md)]
- CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection - [[Arxiv](https://arxiv.org/abs/2309.01093)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01093.md)]
- Chinese Text Recognition with A Pre-Trained CLIP-Like Model Through   Image-IDS Aligning - [[Arxiv](https://arxiv.org/abs/2309.01083)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.01083.md)]
- ModelScope-Agent: Building Your Customizable Agent System with   Open-source Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.00986)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00986.md)]
- eDKM: An Efficient and Accurate Train-time Weight Clustering for Large   Language Models - [[Arxiv](https://arxiv.org/abs/2309.00964)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00964.md)]
- Two-in-One Depth: Bridging the Gap Between Monocular and Binocular   Self-supervised Depth Estimation - [[Arxiv](https://arxiv.org/abs/2309.00933)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00933.md)]
- Domain Generalization via Balancing Training Difficulty and Model   Capability - [[Arxiv](https://arxiv.org/abs/2309.00844)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00844.md)]
- Few shot font generation via transferring similarity guided global style   and quantization local style - [[Arxiv](https://arxiv.org/abs/2309.00827)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00827.md)]
- Instability of the solitary waves for the Generalized   Benjamin-Bona-Mahony Equation - [[Arxiv](https://arxiv.org/abs/2309.0791)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.0791.md)]
- Contrastive Feature Masking Open-Vocabulary Vision Transformer - [[Arxiv](https://arxiv.org/abs/2309.00775)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00775.md)]
- Learning Shared Safety Constraints from Multi-task Demonstrations - [[Arxiv](https://arxiv.org/abs/2309.00711)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00711.md)]
- Searching for a Leptophilic Z' and a 3-3-1 symmetry at CLIC - [[Arxiv](https://arxiv.org/abs/2309.0681)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.0681.md)]
- Point-Bind &amp; Point-LLM: Aligning Point Cloud with Multi-modality for 3D   Understanding, Generation, and Instruction Following - [[Arxiv](https://arxiv.org/abs/2309.00615)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00615.md)]
- CityDreamer: Compositional Generative Model of Unbounded 3D Cities - [[Arxiv](https://arxiv.org/abs/2309.00610)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00610.md)]
- Rieger, Schwabe, Suess-de Vries: The Sunny Beats of Resonance - [[Arxiv](https://arxiv.org/abs/2309.0666)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.0666.md)]
- VideoGen: A Reference-Guided Latent Diffusion Approach for High   Definition Text-to-Video Generation - [[Arxiv](https://arxiv.org/abs/2309.00398)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00398.md)]
- FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large   Language Models in Federated Learning - [[Arxiv](https://arxiv.org/abs/2309.00363)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00363.md)]
- Large Content And Behavior Models To Understand, Simulate, And Optimize   Content And Behavior - [[Arxiv](https://arxiv.org/abs/2309.00359)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00359.md)]
- RLAIF: Scaling Reinforcement Learning from Human Feedback with AI   Feedback - [[Arxiv](https://arxiv.org/abs/2309.00267)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00267.md)]
- A Massively Parallel Dynamic Programming for Approximate Rectangle   Escape Problem - [[Arxiv](https://arxiv.org/abs/2309.0242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.0242.md)]
- Object-Centric Multiple Object Tracking - [[Arxiv](https://arxiv.org/abs/2309.00233)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00233.md)]
- Human-Inspired Facial Sketch Synthesis with Dynamic Adaptation - [[Arxiv](https://arxiv.org/abs/2309.00216)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00216.md)]
- Pseudo-magnetic fields in square lattices - [[Arxiv](https://arxiv.org/abs/2309.0212)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.0212.md)]
- Empirical Modeling of Variance in Medium Frequency R-Mode   Time-of-Arrival Measurements - [[Arxiv](https://arxiv.org/abs/2309.0202)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.0202.md)]

### August 2023
- Block occurrences in the binary expansion - [[Arxiv](https://arxiv.org/abs/2309.0142)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.0142.md)]
- YaRN: Efficient Context Window Extension of Large Language Models - [[Arxiv](https://arxiv.org/abs/2309.00071)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00071.md)]
- SoDaCam: Software-defined Cameras via Single-Photon Imaging - [[Arxiv](https://arxiv.org/abs/2309.00066)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00066.md)]
- FACET: Fairness in Computer Vision Evaluation Benchmark - [[Arxiv](https://arxiv.org/abs/2309.00035)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.00035.md)]
- PointLLM: Empowering Large Language Models to Understand Point Clouds - [[Arxiv](https://arxiv.org/abs/2308.16911)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16911.md)]
- StyleInV: A Temporal Style Modulated Inversion Network for Unconditional   Video Generation - [[Arxiv](https://arxiv.org/abs/2308.16909)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16909.md)]
- InterDiff: Generating 3D Human-Object Interactions with Physics-Informed   Diffusion - [[Arxiv](https://arxiv.org/abs/2308.16905)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16905.md)]
- Transformers as Support Vector Machines - [[Arxiv](https://arxiv.org/abs/2308.16898)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16898.md)]
- EMDB: The Electromagnetic Database of Global 3D Human Pose and Shape in   the Wild - [[Arxiv](https://arxiv.org/abs/2308.16894)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16894.md)]
- GNFactor: Multi-Task Real Robot Learning with Generalizable Neural   Feature Fields - [[Arxiv](https://arxiv.org/abs/2308.16891)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16891.md)]
- TouchStone: Evaluating Vision-Language Models by Language Models - [[Arxiv](https://arxiv.org/abs/2308.16890)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16890.md)]
- The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122   Language Variants - [[Arxiv](https://arxiv.org/abs/2308.16884)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16884.md)]
- SportsSloMo: A New Benchmark and Baselines for Human-centric Video Frame   Interpolation - [[Arxiv](https://arxiv.org/abs/2308.16876)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16876.md)]
- Coarse-to-Fine Amodal Segmentation with Shape Prior - [[Arxiv](https://arxiv.org/abs/2308.16825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16825.md)]
- Can Programming Languages Boost Each Other via Instruction Tuning? - [[Arxiv](https://arxiv.org/abs/2308.16824)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16824.md)]
- Ref-Diff: Zero-shot Referring Image Segmentation with Generative Models - [[Arxiv](https://arxiv.org/abs/2308.16777)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16777.md)]
- Towards High-Fidelity Text-Guided 3D Face Generation and Manipulation   Using only Images - [[Arxiv](https://arxiv.org/abs/2308.16758)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16758.md)]
- Parsing is All You Need for Accurate Gait Recognition in the Wild - [[Arxiv](https://arxiv.org/abs/2308.16739)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16739.md)]
- ViLTA: Enhancing Vision-Language Pre-training through Textual   Augmentation - [[Arxiv](https://arxiv.org/abs/2308.16689)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16689.md)]
- Any-Size-Diffusion: Toward Efficient Text-Driven Synthesis for Any-Size   HD Images - [[Arxiv](https://arxiv.org/abs/2308.16582)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16582.md)]
- MVDream: Multi-view Diffusion for 3D Generation - [[Arxiv](https://arxiv.org/abs/2308.16512)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16512.md)]
- Recommender AI Agent: Integrating Large Language Models for Interactive   Recommendations - [[Arxiv](https://arxiv.org/abs/2308.16505)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16505.md)]
- PivotNet: Vectorized Pivot Learning for End-to-end HD Map Construction - [[Arxiv](https://arxiv.org/abs/2308.16477)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16477.md)]
- Sparkles: Unlocking Chats Across Multiple Images for Multimodal   Instruction-Following Models - [[Arxiv](https://arxiv.org/abs/2308.16463)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16463.md)]
- Improving Lens Flare Removal with General Purpose Pipeline and Multiple   Light Sources Recovery - [[Arxiv](https://arxiv.org/abs/2308.16460)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16460.md)]
- BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual   Pragmatic Knowledge - [[Arxiv](https://arxiv.org/abs/2308.16458)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16458.md)]
- Adversarial Finetuning with Latent Representation Constraint to Mitigate   Accuracy-Robustness Tradeoff - [[Arxiv](https://arxiv.org/abs/2308.16454)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16454.md)]
- Emergence of Segmentation with Minimalistic White-Box Transformers - [[Arxiv](https://arxiv.org/abs/2308.16271)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16271.md)]
- Active Neural Mapping - [[Arxiv](https://arxiv.org/abs/2308.16246)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16246.md)]
- Learning Vision-based Pursuit-Evasion Robot Policies - [[Arxiv](https://arxiv.org/abs/2308.16185)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16185.md)]
- SAM-Med2D - [[Arxiv](https://arxiv.org/abs/2308.16184)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16184.md)]
- MMVP: Motion-Matrix-based Video Prediction - [[Arxiv](https://arxiv.org/abs/2308.16154)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16154.md)]
- LM-Infinite: Simple On-the-Fly Length Generalization for Large Language   Models - [[Arxiv](https://arxiv.org/abs/2308.16137)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16137.md)]
- Response: Emergent analogical reasoning in large language models - [[Arxiv](https://arxiv.org/abs/2308.16118)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16118.md)]
- Learned Image Reasoning Prior Penetrates Deep Unfolding Network for   Panchromatic and Multi-Spectral Image Fusion - [[Arxiv](https://arxiv.org/abs/2308.16083)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16083.md)]
- RoboTAP: Tracking Arbitrary Points for Few-Shot Visual Imitation - [[Arxiv](https://arxiv.org/abs/2308.15975)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15975.md)]
- WALL-E: Embodied Robotic WAiter Load Lifting with Large Language Model - [[Arxiv](https://arxiv.org/abs/2308.15962)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15962.md)]
- LLaSM: Large Language and Speech Model - [[Arxiv](https://arxiv.org/abs/2308.15930)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15930.md)]
- Reconstructing Groups of People with Hypergraph Relational Reasoning - [[Arxiv](https://arxiv.org/abs/2308.15844)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15844.md)]
- Introducing Language Guidance in Prompt-based Continual Learning - [[Arxiv](https://arxiv.org/abs/2308.15827)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15827.md)]
- WeatherBench 2: A benchmark for the next generation of data-driven   global weather models - [[Arxiv](https://arxiv.org/abs/2308.15560)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15560.md)]
- Canonical Factors for Hybrid Neural Fields - [[Arxiv](https://arxiv.org/abs/2308.15461)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15461.md)]
- Shatter and Gather: Learning Referring Image Segmentation with Text   Supervision - [[Arxiv](https://arxiv.org/abs/2308.15512)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15512.md)]
- Efficient Model Personalization in Federated Learning via   Client-Specific Prompt Generation - [[Arxiv](https://arxiv.org/abs/2308.15367)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15367.md)]
- CLIPTrans: Transferring Visual Knowledge with Pre-trained Models for   Multimodal Machine Translation - [[Arxiv](https://arxiv.org/abs/2308.15226)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15226.md)]
- Evaluation and Analysis of Hallucination in Large Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2308.15126)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15126.md)]
- Learning to Upsample by Learning to Sample - [[Arxiv](https://arxiv.org/abs/2308.15085)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15085.md)]
- Class Prior-Free Positive-Unlabeled Learning with Taylor Variational   Loss for Hyperspectral Remote Sensing Imagery - [[Arxiv](https://arxiv.org/abs/2308.15081)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15081.md)]
- Exploring Model Transferability through the Lens of Potential Energy - [[Arxiv](https://arxiv.org/abs/2308.15074)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15074.md)]
- Pose-Free Neural Radiance Fields via Implicit Pose Regularization - [[Arxiv](https://arxiv.org/abs/2308.15049)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15049.md)]
- Recursively Summarizing Enables Long-Term Dialogue Memory in Large   Language Models - [[Arxiv](https://arxiv.org/abs/2308.15022)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.15022.md)]
- Vision Grid Transformer for Document Layout Analysis - [[Arxiv](https://arxiv.org/abs/2308.14978)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14978.md)]
- LLM-Based Human-Robot Collaboration Framework for Manipulation Tasks - [[Arxiv](https://arxiv.org/abs/2308.14972)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14972.md)]
- Vector Search with OpenAI Embeddings: Lucene Is All You Need - [[Arxiv](https://arxiv.org/abs/2308.14963)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14963.md)]
- Read-only Prompt Optimization for Vision-Language Few-shot Learning - [[Arxiv](https://arxiv.org/abs/2308.14960)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14960.md)]
- NSF: Neural Surface Fields for Human Modeling from Monocular Depth - [[Arxiv](https://arxiv.org/abs/2308.14847)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14847.md)]
- CLNeRF: Continual Learning Meets NeRF - [[Arxiv](https://arxiv.org/abs/2308.14816)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14816.md)]
- Efficient Discovery and Effective Evaluation of Visual Perceptual   Similarity: A Benchmark and Beyond - [[Arxiv](https://arxiv.org/abs/2308.14753)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14753.md)]
- AI Deception: A Survey of Examples, Risks, and Potential Solutions - [[Arxiv](https://arxiv.org/abs/2308.14752)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14752.md)]
- CoVR: Learning Composed Video Retrieval from Web Video Captions - [[Arxiv](https://arxiv.org/abs/2308.14746)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14746.md)]
- R3D3: Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras - [[Arxiv](https://arxiv.org/abs/2308.14713)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14713.md)]
- S-TREK: Sequential Translation and Rotation Equivariant Keypoints for   local feature extraction - [[Arxiv](https://arxiv.org/abs/2308.14598)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14598.md)]
- Referring Image Segmentation Using Text Supervision - [[Arxiv](https://arxiv.org/abs/2308.14575)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14575.md)]
- LAC: Latent Action Composition for Skeleton-based Action Segmentation - [[Arxiv](https://arxiv.org/abs/2308.14500)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14500.md)]
- Priority-Centric Human Motion Generation in Discrete Latent Space - [[Arxiv](https://arxiv.org/abs/2308.14480)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14480.md)]
- Multi-Modal Neural Radiance Field for Monocular Dense SLAM with a   Light-Weight ToF Sensor - [[Arxiv](https://arxiv.org/abs/2308.14383)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14383.md)]
- ZhuJiu: A Multi-dimensional, Multi-faceted Chinese Benchmark for Large   Language Models - [[Arxiv](https://arxiv.org/abs/2308.14353)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14353.md)]
- DISC-MedLLM: Bridging General Large Language Models and Real-World   Medical Consultation - [[Arxiv](https://arxiv.org/abs/2308.14346)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14346.md)]
- UniPT: Universal Parallel Tuning for Transfer Learning with Efficient   Parameter and Memory - [[Arxiv](https://arxiv.org/abs/2308.14316)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14316.md)]
- Bridging Cross-task Protocol Inconsistency for Distillation in Dense   Object Detection - [[Arxiv](https://arxiv.org/abs/2308.14286)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14286.md)]
- HoloFusion: Towards Photo-realistic 3D Generative Modeling - [[Arxiv](https://arxiv.org/abs/2308.14244)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14244.md)]
- High-Resolution Document Shadow Removal via A Large-Scale Real-World   Dataset and A Frequency-Aware Shadow Erasing Net - [[Arxiv](https://arxiv.org/abs/2308.14221)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14221.md)]
- Sparse Sampling Transformer with Uncertainty-Driven Ranking for Unified   Removal of Raindrops and Rain Streaks - [[Arxiv](https://arxiv.org/abs/2308.14153)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14153.md)]
- Unaligned 2D to 3D Translation with Conditional Vector-Quantized Code   Diffusion using Transformers - [[Arxiv](https://arxiv.org/abs/2308.14152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14152.md)]
- Semi-Supervised Learning in the Few-Shot Zero-Shot Scenario - [[Arxiv](https://arxiv.org/abs/2308.14119)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14119.md)]
- MedAlign: A Clinician-Generated Dataset for Instruction Following with   Electronic Medical Records - [[Arxiv](https://arxiv.org/abs/2308.14089)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14089.md)]
- 4D Myocardium Reconstruction with Decoupled Motion and Shape Model - [[Arxiv](https://arxiv.org/abs/2308.14083)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14083.md)]
- Reconstructing Interacting Hands with Interaction Prior from Monocular   Images - [[Arxiv](https://arxiv.org/abs/2308.14082)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14082.md)]
- Nonrigid Object Contact Estimation With Regional Unwrapping Transformer - [[Arxiv](https://arxiv.org/abs/2308.14074)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14074.md)]
- Hierarchical Contrastive Learning for Pattern-Generalizable Image   Corruption Detection - [[Arxiv](https://arxiv.org/abs/2308.14061)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14061.md)]
- Domain-Specificity Inducing Transformers for Source-Free Domain   Adaptation - [[Arxiv](https://arxiv.org/abs/2308.14023)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14023.md)]
- Calibrating Panoramic Depth Estimation for Practical Localization and   Mapping - [[Arxiv](https://arxiv.org/abs/2308.14005)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.14005.md)]
- LDL: Line Distance Functions for Panoramic Localization - [[Arxiv](https://arxiv.org/abs/2308.13989)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13989.md)]
- Prior-guided Source-free Domain Adaptation for Human Pose Estimation - [[Arxiv](https://arxiv.org/abs/2308.13954)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13954.md)]
- Late Stopping: Avoiding Confidently Learning from Mislabeled Examples - [[Arxiv](https://arxiv.org/abs/2308.13862)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13862.md)]
- Beyond One-to-One: Rethinking the Referring Image Segmentation - [[Arxiv](https://arxiv.org/abs/2308.13853)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13853.md)]
- Point-Query Quadtree for Crowd Counting, Localization, and More - [[Arxiv](https://arxiv.org/abs/2308.13814)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13814.md)]
- ORES: Open-vocabulary Responsible Visual Synthesis - [[Arxiv](https://arxiv.org/abs/2308.13785)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13785.md)]
- Generalized Lightness Adaptation with Channel Selective Normalization - [[Arxiv](https://arxiv.org/abs/2308.13783)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13783.md)]
- MST-compression: Compressing and Accelerating Binary Neural Networks   with Minimum Spanning Tree - [[Arxiv](https://arxiv.org/abs/2308.13735)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13735.md)]
- ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon   Sequential Task Planning - [[Arxiv](https://arxiv.org/abs/2308.13724)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13724.md)]
- Joint Modeling of Feature, Correspondence, and a Compressed Memory for   Video Object Segmentation - [[Arxiv](https://arxiv.org/abs/2308.13505)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13505.md)]
- A2Q: Accumulator-Aware Quantization with Guaranteed Overflow Avoidance - [[Arxiv](https://arxiv.org/abs/2308.13504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13504.md)]
- Eventful Transformers: Leveraging Temporal Redundancy in Vision   Transformers - [[Arxiv](https://arxiv.org/abs/2308.13494)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13494.md)]
- Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability   of Language Models - [[Arxiv](https://arxiv.org/abs/2308.13467)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13467.md)]
- Position-Enhanced Visual Instruction Tuning for Multimodal Large   Language Models - [[Arxiv](https://arxiv.org/abs/2308.13437)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13437.md)]
- Nougat: Neural Optical Understanding for Academic Documents - [[Arxiv](https://arxiv.org/abs/2308.13418)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13418.md)]
- SoTaNa: The Open-Source Software Development Assistant - [[Arxiv](https://arxiv.org/abs/2308.13416)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13416.md)]
- Harvard Glaucoma Detection and Progression: A Multimodal Multitask   Dataset and Generalization-Reinforced Semi-Supervised Learning - [[Arxiv](https://arxiv.org/abs/2308.13411)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13411.md)]
- Relighting Neural Radiance Fields with Shadow and Highlight Hints - [[Arxiv](https://arxiv.org/abs/2308.13404)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13404.md)]
- Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs - [[Arxiv](https://arxiv.org/abs/2308.13387)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13387.md)]
- Distribution-Aligned Diffusion for Human Mesh Recovery - [[Arxiv](https://arxiv.org/abs/2308.13369)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13369.md)]
- ConSlide: Asynchronous Hierarchical Interaction Transformer with   Breakup-Reorganize Rehearsal for Continual Whole Slide Image Analysis - [[Arxiv](https://arxiv.org/abs/2308.13324)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13324.md)]
- SVQNet: Sparse Voxel-Adjacent Query Network for 4D Spatio-Temporal LiDAR   Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2308.13323)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13323.md)]
- Fine-tuning can cripple your foundation model; preserving features may   be the solution - [[Arxiv](https://arxiv.org/abs/2308.13320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13320.md)]
- A Game of Bundle Adjustment -- Learning Efficient Convergence - [[Arxiv](https://arxiv.org/abs/2308.13270)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13270.md)]
- Integrating Boxes and Masks: A Multi-Object Framework for Unified Visual   Tracking and Segmentation - [[Arxiv](https://arxiv.org/abs/2308.13266)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13266.md)]
- Unpaired Multi-domain Attribute Translation of 3D Facial Shapes with a   Square and Symmetric Geometric Map - [[Arxiv](https://arxiv.org/abs/2308.13245)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13245.md)]
- Black-box Unsupervised Domain Adaptation with Bi-directional   Atkinson-Shiffrin Memory - [[Arxiv](https://arxiv.org/abs/2308.13236)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13236.md)]
- ReST: A Reconfigurable Spatial-Temporal Graph Model for Multi-Camera   Multi-Object Tracking - [[Arxiv](https://arxiv.org/abs/2308.13229)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13229.md)]
- MultiCapCLIP: Auto-Encoding Prompts for Zero-Shot Multilingual Visual   Captioning - [[Arxiv](https://arxiv.org/abs/2308.13218)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13218.md)]
- IOMatch: Simplifying Open-Set Semi-Supervised Learning with Joint   Inliers and Outliers Utilization - [[Arxiv](https://arxiv.org/abs/2308.13168)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13168.md)]
- Diff-Retinex: Rethinking Low-light Image Enhancement with A Generative   Diffusion Model - [[Arxiv](https://arxiv.org/abs/2308.13164)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13164.md)]
- SciEval: A Multi-Level Large Language Model Evaluation Benchmark for   Scientific Research - [[Arxiv](https://arxiv.org/abs/2308.13149)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13149.md)]
- OmniQuant: Omnidirectionally Calibrated Quantization for Large Language   Models - [[Arxiv](https://arxiv.org/abs/2308.13137)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13137.md)]
- MLLM-DataEngine: An Iterative Refinement Approach for MLLM - [[Arxiv](https://arxiv.org/abs/2308.13566)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13566.md)]
- Preserving Modality Structure Improves Multi-Modal Learning - [[Arxiv](https://arxiv.org/abs/2308.13077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.13077.md)]
- NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes - [[Arxiv](https://arxiv.org/abs/2308.12967)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12967.md)]
- Scenimefy: Learning to Craft Anime Scene via Semi-Supervised   Image-to-Image Translation - [[Arxiv](https://arxiv.org/abs/2308.12968)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12968.md)]
- Qwen-VL: A Versatile Vision-Language Model for Understanding,   Localization, Text Reading, and Beyond - [[Arxiv](https://arxiv.org/abs/2308.12966)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12966.md)]
- Dense Text-to-Image Generation with Attention Modulation - [[Arxiv](https://arxiv.org/abs/2308.12964)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12964.md)]
- MapPrior: Bird's-Eye View Map Layout Estimation with Generative Models - [[Arxiv](https://arxiv.org/abs/2308.12963)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12963.md)]
- Motion-Guided Masking for Spatiotemporal Representation Learning - [[Arxiv](https://arxiv.org/abs/2308.12962)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12962.md)]
- Towards Realistic Zero-Shot Classification via Self Structural Semantic   Alignment - [[Arxiv](https://arxiv.org/abs/2308.12960)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12960.md)]
- Code Llama: Open Foundation Models for Code - [[Arxiv](https://arxiv.org/abs/2308.12950)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12950.md)]
- Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language   Pretraining? - [[Arxiv](https://arxiv.org/abs/2308.12898)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12898.md)]
- Boosting Semantic Segmentation from the Perspective of Explicit Class   Embeddings - [[Arxiv](https://arxiv.org/abs/2308.12894)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12894.md)]
- ToonTalker: Cross-Domain Face Reenactment - [[Arxiv](https://arxiv.org/abs/2308.12866)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12866.md)]
- Fast Adversarial Training with Smooth Convergence - [[Arxiv](https://arxiv.org/abs/2308.12857)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12857.md)]
- On Offline Evaluation of 3D Object Detection for Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2308.12779)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12779.md)]
- LISTER: Neighbor Decoding for Length-Insensitive Scene Text Recognition - [[Arxiv](https://arxiv.org/abs/2308.12774)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12774.md)]
- VIGC: Visual Instruction Generation and Correction - [[Arxiv](https://arxiv.org/abs/2308.12714)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12714.md)]
- A Parse-Then-Place Approach for Generating Graphic Layouts from Textual   Descriptions - [[Arxiv](https://arxiv.org/abs/2308.12700)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12700.md)]
- PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation - [[Arxiv](https://arxiv.org/abs/2308.12604)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12604.md)]
- Logic-induced Diagnostic Reasoning for Semi-supervised Semantic   Segmentation - [[Arxiv](https://arxiv.org/abs/2308.12595)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12595.md)]
- Self-supervised Learning of Implicit Shape Representation with Dense   Correspondence for Deformable Objects - [[Arxiv](https://arxiv.org/abs/2308.12590)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12590.md)]
- Grounded Entity-Landmark Adaptive Pre-training for Vision-and-Language   Navigation - [[Arxiv](https://arxiv.org/abs/2308.12587)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12587.md)]
- Hyperbolic Audio-visual Zero-shot Learning - [[Arxiv](https://arxiv.org/abs/2308.12558)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12558.md)]
- Synchronize Feature Extracting and Matching: A Single Branch Framework   for 3D Object Tracking - [[Arxiv](https://arxiv.org/abs/2308.12549)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12549.md)]
- CALM : A Multi-task Benchmark for Comprehensive Assessment of Language   Model Bias - [[Arxiv](https://arxiv.org/abs/2308.12539)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12539.md)]
- Masked Autoencoders are Efficient Class Incremental Learners - [[Arxiv](https://arxiv.org/abs/2308.12510)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12510.md)]
- CGMI: Configurable General Multi-Agent Interaction Framework - [[Arxiv](https://arxiv.org/abs/2308.12503)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12503.md)]
- With a Little Help from your own Past: Prototypical Memory Networks for   Image Captioning - [[Arxiv](https://arxiv.org/abs/2308.12383)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12383.md)]
- Vision Transformer Adapters for Generalizable Multitask Learning - [[Arxiv](https://arxiv.org/abs/2308.12372)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12372.md)]
- AdVerb: Visually Guided Audio Dereverberation - [[Arxiv](https://arxiv.org/abs/2308.12370)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12370.md)]
- Continual Zero-Shot Learning through Semantically Guided Generative   Random Walks - [[Arxiv](https://arxiv.org/abs/2308.12366)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12366.md)]
- Diffusion-based Image Translation with Label Guidance for Domain   Adaptive Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2308.12350)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12350.md)]
- Improving Generative Model-based Unfolding with SchrÃ¶dinger Bridges - [[Arxiv](https://arxiv.org/abs/2308.12351)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12351.md)]
- CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from   Unbounded Synthesized Images - [[Arxiv](https://arxiv.org/abs/2308.12288)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12288.md)]
- Simple is Better and Large is Not Enough: Towards Ensembling of   Foundational Language Models - [[Arxiv](https://arxiv.org/abs/2308.12272)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12272.md)]
- Diffusion Language Models Can Perform Many Tasks with Scaling and   Instruction-Finetuning - [[Arxiv](https://arxiv.org/abs/2308.12219)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12219.md)]
- SG-Former: Self-guided Transformer with Evolving Token Reallocation - [[Arxiv](https://arxiv.org/abs/2308.12216)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12216.md)]
- CLIPN for Zero-Shot OOD Detection: Teaching CLIP to Say No - [[Arxiv](https://arxiv.org/abs/2308.12213)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12213.md)]
- Curriculum Learning with Adam: The Devil Is in the Wrong Details - [[Arxiv](https://arxiv.org/abs/2308.12202)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12202.md)]
- Sign Language Translation with Iterative Prototype - [[Arxiv](https://arxiv.org/abs/2308.12191)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12191.md)]
- SILT: Shadow-aware Iterative Label Tuning for Learning to Detect Shadows   from Noisy Labels - [[Arxiv](https://arxiv.org/abs/2308.12064)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12064.md)]
- DR-Tune: Improving Fine-tuning of Pretrained Visual Models by   Distribution Regularization with Semantic Calibration - [[Arxiv](https://arxiv.org/abs/2308.12058)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12058.md)]
- Aligning Language Models with Offline Reinforcement Learning from Human   Feedback - [[Arxiv](https://arxiv.org/abs/2308.12050)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12050.md)]
- Large Multilingual Models Pivot Zero-Shot Multimodal Learning across   Languages - [[Arxiv](https://arxiv.org/abs/2308.12038)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12038.md)]
- RefEgo: Referring Expression Comprehension Dataset from First-Person   Perception of Ego4D - [[Arxiv](https://arxiv.org/abs/2308.12035)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12035.md)]
- From Instructions to Intrinsic Human Values -- A Survey of Alignment   Goals for Big Models - [[Arxiv](https://arxiv.org/abs/2308.12014)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.12014.md)]
- RankMixup: Ranking-Based Mixup Training for Network Calibration - [[Arxiv](https://arxiv.org/abs/2308.11990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11990.md)]
- Blending-NeRF: Text-Driven Localized Editing in Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2308.11974)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11974.md)]
- EVE: Efficient Vision-Language Pre-training with Masked Prediction and   Modality-Aware MoE - [[Arxiv](https://arxiv.org/abs/2308.11971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11971.md)]
- OFVL-MS: Once for Visual Localization across Multiple Indoor Scenes - [[Arxiv](https://arxiv.org/abs/2308.11928)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11928.md)]
- Recovering a Molecule's 3D Dynamics from Liquid-phase Electron   Microscopy Movies - [[Arxiv](https://arxiv.org/abs/2308.11927)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11927.md)]
- LFS-GAN: Lifelong Few-Shot Image Generation - [[Arxiv](https://arxiv.org/abs/2308.11917)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11917.md)]
- Semantic-Aware Implicit Template Learning via Part Deformation   Consistency - [[Arxiv](https://arxiv.org/abs/2308.11916)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11916.md)]
- ACLS: Adaptive and Conditional Label Smoothing for Network Calibration - [[Arxiv](https://arxiv.org/abs/2308.11911)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11911.md)]
- Camera-Driven Representation Learning for Unsupervised Domain Adaptive   Person Re-identification - [[Arxiv](https://arxiv.org/abs/2308.11901)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11901.md)]
- Does Physical Adversarial Example Really Matter to Autonomous Driving?   Towards System-Level Effect of Adversarial Object Evasion Attack - [[Arxiv](https://arxiv.org/abs/2308.11894)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11894.md)]
- SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal   Targets - [[Arxiv](https://arxiv.org/abs/2308.11880)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11880.md)]
- Semi-Supervised Learning via Weight-aware Distillation under Class   Distribution Mismatch - [[Arxiv](https://arxiv.org/abs/2308.11874)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11874.md)]
- Time Does Tell: Self-Supervised Time-Tuning of Dense Image   Representations - [[Arxiv](https://arxiv.org/abs/2308.11796)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11796.md)]
- Enhancing NeRF akin to Enhancing LLMs: Generalizable NeRF Transformer   with Mixture-of-View-Experts - [[Arxiv](https://arxiv.org/abs/2308.11793)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11793.md)]
- Understanding Hessian Alignment for Domain Generalization - [[Arxiv](https://arxiv.org/abs/2308.11778)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11778.md)]
- Efficient Controllable Multi-Task Architectures - [[Arxiv](https://arxiv.org/abs/2308.11744)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11744.md)]
- Animal3D: A Comprehensive Dataset of 3D Animal Pose and Shape - [[Arxiv](https://arxiv.org/abs/2308.11737)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11737.md)]
- Efficient Benchmarking (of Language Models) - [[Arxiv](https://arxiv.org/abs/2308.11696)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11696.md)]
- Delving into Motion-Aware Matching for Monocular 3D Object Tracking - [[Arxiv](https://arxiv.org/abs/2308.11607)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11607.md)]
- StoryBench: A Multifaceted Benchmark for Continuous Story Visualization - [[Arxiv](https://arxiv.org/abs/2308.11606)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11606.md)]
- SPANet: Frequency-balancing Token Mixer using Spectral Pooling   Aggregation Modulation - [[Arxiv](https://arxiv.org/abs/2308.11568)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11568.md)]
- Multi-event Video-Text Retrieval - [[Arxiv](https://arxiv.org/abs/2308.11551)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11551.md)]
- TrackFlow: Multi-Object Tracking with Normalizing Flows - [[Arxiv](https://arxiv.org/abs/2308.11513)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11513.md)]
- Learning from Semantic Alignment between Unpaired Multiviews for   Egocentric Video Recognition - [[Arxiv](https://arxiv.org/abs/2308.11489)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11489.md)]
- Learning a More Continuous Zero Level Set in Unsigned Distance Fields   through Level Set Projection - [[Arxiv](https://arxiv.org/abs/2308.11441)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11441.md)]
- A Survey on Large Language Model based Autonomous Agents - [[Arxiv](https://arxiv.org/abs/2308.11432)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11432.md)]
- ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes - [[Arxiv](https://arxiv.org/abs/2308.11417)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11417.md)]
- How Much Temporal Long-Term Context is Needed for Action Segmentation? - [[Arxiv](https://arxiv.org/abs/2308.11358)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11358.md)]
- Exemplar-Free Continual Transformer with Convolutions - [[Arxiv](https://arxiv.org/abs/2308.11357)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11357.md)]
- ProAgent: Building Proactive Cooperative AI with Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.11339)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11339.md)]
- GrowCLIP: Data-aware Automatic Model Growing for Large-scale Contrastive   Language-Image Pre-training - [[Arxiv](https://arxiv.org/abs/2308.11331)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11331.md)]
- CiteTracker: Correlating Image and Text for Visual Tracking - [[Arxiv](https://arxiv.org/abs/2308.11322)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11322.md)]
- CNN based Cuneiform Sign Detection Learned from Annotated 3D Renderings   and Mapped Photographs with Illumination Augmentation - [[Arxiv](https://arxiv.org/abs/2308.11277)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11277.md)]
- HMD-NeMo: Online 3D Avatar Motion Generation From Sparse Observations - [[Arxiv](https://arxiv.org/abs/2308.11261)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11261.md)]
- ROSGPT_Vision: Commanding Robots Using Only Language Models' Prompts - [[Arxiv](https://arxiv.org/abs/2308.11236)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11236.md)]
- LDP-Feat: Image Features with Local Differential Privacy - [[Arxiv](https://arxiv.org/abs/2308.11223)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11223.md)]
- DiffCloth: Diffusion Based Garment Synthesis and Manipulation via   Structural Cross-modal Semantic Alignment - [[Arxiv](https://arxiv.org/abs/2308.11206)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11206.md)]
- ViLLA: Fine-Grained Vision-Language Representation Learning from   Real-World Data - [[Arxiv](https://arxiv.org/abs/2308.11194)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11194.md)]
- Knowledge-Aware Prompt Tuning for Generalizable Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2308.11186)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11186.md)]
- MEGA: Multimodal Alignment Aggregation and Distillation For Cinematic   Video Segmentation - [[Arxiv](https://arxiv.org/abs/2308.11185)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11185.md)]
- ReFit: Recurrent Fitting Network for 3D Human Recovery - [[Arxiv](https://arxiv.org/abs/2308.11184)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11184.md)]
- Hierarchical Point-based Active Learning for Semi-supervised Point Cloud   Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2308.11166)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11166.md)]
- Domain Generalization via Rationale Invariance - [[Arxiv](https://arxiv.org/abs/2308.11158)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11158.md)]
- Efficient View Synthesis with Neural Radiance Distribution Field - [[Arxiv](https://arxiv.org/abs/2308.11130)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11130.md)]
- LAN-HDR: Luminance-based Alignment Network for High Dynamic Range Video   Reconstruction - [[Arxiv](https://arxiv.org/abs/2308.11116)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11116.md)]
- CAME: Contrastive Automated Model Evaluation - [[Arxiv](https://arxiv.org/abs/2308.11111)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11111.md)]
- Recursive Video Lane Detection - [[Arxiv](https://arxiv.org/abs/2308.11106)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11106.md)]
- MosaiQ: Quantum Generative Adversarial Networks for Image Generation on   NISQ Computers - [[Arxiv](https://arxiv.org/abs/2308.11096)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11096.md)]
- Video OWL-ViT: Temporally-consistent open-world localization in video - [[Arxiv](https://arxiv.org/abs/2308.11093)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11093.md)]
- Audio-Visual Class-Incremental Learning - [[Arxiv](https://arxiv.org/abs/2308.11073)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11073.md)]
- TeD-SPAD: Temporal Distinctiveness for Self-supervised   Privacy-preservation for video Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2308.11072)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11072.md)]
- Neural Amortized Inference for Nested Multi-agent Reasoning - [[Arxiv](https://arxiv.org/abs/2308.11071)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11071.md)]
- MetaGCD: Learning to Continually Learn in Generalized Category Discovery - [[Arxiv](https://arxiv.org/abs/2308.11063)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11063.md)]
- UnLoc: A Unified Framework for Video Localization Tasks - [[Arxiv](https://arxiv.org/abs/2308.11062)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11062.md)]
- Coordinate Quantized Neural Implicit Representations for Multi-view   Reconstruction - [[Arxiv](https://arxiv.org/abs/2308.11025)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11025.md)]
- Spectral Graphormer: Spectral Graph-based Transformer for Egocentric   Two-Hand Reconstruction using Multi-View Color Images - [[Arxiv](https://arxiv.org/abs/2308.11015)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11015.md)]
- Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical   Deformation - [[Arxiv](https://arxiv.org/abs/2308.10898)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10898.md)]
- Can Language Models Learn to Listen? - [[Arxiv](https://arxiv.org/abs/2308.10897)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10897.md)]
- AgentVerse: Facilitating Multi-Agent Collaboration and Exploring   Emergent Behaviors - [[Arxiv](https://arxiv.org/abs/2308.10848)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10848.md)]
- EigenPlaces: Training Viewpoint Robust Models for Visual Place   Recognition - [[Arxiv](https://arxiv.org/abs/2308.10832)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10832.md)]
- Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image   Reconstruction - [[Arxiv](https://arxiv.org/abs/2308.10820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10820.md)]
- Jumping through Local Minima: Quantization in the Loss Landscape of   Vision Transformers - [[Arxiv](https://arxiv.org/abs/2308.10814)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10814.md)]
- Improving Continuous Sign Language Recognition with Cross-Lingual Signs - [[Arxiv](https://arxiv.org/abs/2308.10809)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10809.md)]
- MGMAE: Motion Guided Masking for Video Masked Autoencoding - [[Arxiv](https://arxiv.org/abs/2308.10794)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10794.md)]
- Instruction Tuning for Large Language Models: A Survey - [[Arxiv](https://arxiv.org/abs/2308.10792)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10792.md)]
- WanJuan: A Comprehensive Multimodal Dataset for Advancing English and   Chinese Large Models - [[Arxiv](https://arxiv.org/abs/2308.10755)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10755.md)]
- On the Adversarial Robustness of Multi-Modal Foundation Models - [[Arxiv](https://arxiv.org/abs/2308.10741)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10741.md)]
- Patch Is Not All You Need - [[Arxiv](https://arxiv.org/abs/2308.10729)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10729.md)]
- Vanishing Point Estimation in Uncalibrated Images with Prior Gravity   Direction - [[Arxiv](https://arxiv.org/abs/2308.10694)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10694.md)]
- Learning Clothing and Pose Invariant 3D Shape Representation for   Long-Term Person Re-Identification - [[Arxiv](https://arxiv.org/abs/2308.10658)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10658.md)]
- GaitPT: Skeletons Are All You Need For Gait Recognition - [[Arxiv](https://arxiv.org/abs/2308.10623)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10623.md)]
- A step towards understanding why classification helps regression - [[Arxiv](https://arxiv.org/abs/2308.10603)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10603.md)]
- Image-free Classifier Injection for Zero-Shot Classification - [[Arxiv](https://arxiv.org/abs/2308.10599)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10599.md)]
- CHORD: Category-level Hand-held Object Reconstruction via Shape   Deformation - [[Arxiv](https://arxiv.org/abs/2308.10574)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10574.md)]
- Self-Feedback DETR for Temporal Action Detection - [[Arxiv](https://arxiv.org/abs/2308.10570)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10570.md)]
- Improving Diversity in Zero-Shot GAN Adaptation with Semantic Variations - [[Arxiv](https://arxiv.org/abs/2308.10554)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10554.md)]
- QD-BEV : Quantization-aware View-guided Distillation for Multi-view 3D   Object Detection - [[Arxiv](https://arxiv.org/abs/2308.10515)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10515.md)]
- PlatoLM: Teaching LLMs via a Socratic Questioning User Simulator - [[Arxiv](https://arxiv.org/abs/2308.11534)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11534.md)]
- Texture Generation on 3D Meshes with Point-UV Diffusion - [[Arxiv](https://arxiv.org/abs/2308.10490)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10490.md)]
- ADNet: Lane Shape Prediction via Anchor Decomposition - [[Arxiv](https://arxiv.org/abs/2308.10481)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10481.md)]
- STEERER: Resolving Scale Variations for Counting and Localization via   Selective Inheritance Learning - [[Arxiv](https://arxiv.org/abs/2308.10468)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10468.md)]
- Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation   with Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.10462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10462.md)]
- Privacy-Preserving Face Recognition Using Random Frequency Components - [[Arxiv](https://arxiv.org/abs/2308.10461)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10461.md)]
- Explore and Tell: Embodied Visual Captioning in 3D Environments - [[Arxiv](https://arxiv.org/abs/2308.10447)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10447.md)]
- When Prompt-based Incremental Learning Does Not Meet Strong Pretraining - [[Arxiv](https://arxiv.org/abs/2308.10445)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10445.md)]
- X-VoE: Measuring eXplanatory Violation of Expectation in Physical Events - [[Arxiv](https://arxiv.org/abs/2308.10441)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10441.md)]
- GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems - [[Arxiv](https://arxiv.org/abs/2308.10435)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10435.md)]
- Diffusion Model as Representation Learner - [[Arxiv](https://arxiv.org/abs/2308.10916)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10916.md)]
- Simple Baselines for Interactive Video Retrieval with Questions and   Answers - [[Arxiv](https://arxiv.org/abs/2308.10402)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10402.md)]
- FairBench: A Four-Stage Automatic Framework for Detecting Stereotypes   and Biases in Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.10397)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10397.md)]
- Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language   Models - [[Arxiv](https://arxiv.org/abs/2308.10379)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10379.md)]
- LegalBench: A Collaboratively Built Benchmark for Measuring Legal   Reasoning in Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.11462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.11462.md)]
- Strata-NeRF : Neural Radiance Fields for Stratified Scenes - [[Arxiv](https://arxiv.org/abs/2308.10337)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10337.md)]
- Coordinate Transformer: Achieving Single-stage Multi-person Mesh   Recovery from Videos - [[Arxiv](https://arxiv.org/abs/2308.10334)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10334.md)]
- Improving Adversarial Robustness of Masked Autoencoders via Test-time   Frequency-domain Prompting - [[Arxiv](https://arxiv.org/abs/2308.10315)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10315.md)]
- DVGaze: Dual-View Gaze Estimation - [[Arxiv](https://arxiv.org/abs/2308.10310)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10310.md)]
- Representation Disparity-aware Distillation for 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2308.10308)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10308.md)]
- Omnidirectional Information Gathering for Knowledge Transfer-based   Audio-Visual Navigation - [[Arxiv](https://arxiv.org/abs/2308.10306)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10306.md)]
- Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video - [[Arxiv](https://arxiv.org/abs/2308.10305)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10305.md)]
- DomainAdaptor: A Novel Approach to Test-time Adaptation - [[Arxiv](https://arxiv.org/abs/2308.10297)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10297.md)]
- DomainDrop: Suppressing Domain-Sensitive Channels for Domain   Generalization - [[Arxiv](https://arxiv.org/abs/2308.10285)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10285.md)]
- GPFL: Simultaneously Learning Global and Personalized Feature   Information for Personalized Federated Learning - [[Arxiv](https://arxiv.org/abs/2308.10279)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10279.md)]
- CharacterChat: Learning towards Conversational AI with Personalized   Social Support - [[Arxiv](https://arxiv.org/abs/2308.10278)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10278.md)]
- Minimalist Traffic Prediction: Linear Layer Is All You Need - [[Arxiv](https://arxiv.org/abs/2308.10276)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10276.md)]
- StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized   Image-Dialogue Data - [[Arxiv](https://arxiv.org/abs/2308.10253)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10253.md)]
- GeT: Generative Target Structure Debiasing for Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2308.10205)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10205.md)]
- ChatEDA: A Large Language Model Powered Autonomous Agent for EDA - [[Arxiv](https://arxiv.org/abs/2308.10204)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10204.md)]
- ViT-Lens: Towards Omni-modal Representations - [[Arxiv](https://arxiv.org/abs/2308.10185)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10185.md)]
- Neural Interactive Keypoint Detection - [[Arxiv](https://arxiv.org/abs/2308.10174)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10174.md)]
- VLN-PETL: Parameter-Efficient Transfer Learning for Vision-and-Language   Navigation - [[Arxiv](https://arxiv.org/abs/2308.10172)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10172.md)]
- FashionNTM: Multi-turn Fashion Image Retrieval via Cascaded Memory - [[Arxiv](https://arxiv.org/abs/2308.10170)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10170.md)]
- Unilaterally Aggregated Contrastive Learning with Hierarchical   Augmentation for Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2308.10155)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10155.md)]
- A Survey on Fairness in Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.10149)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10149.md)]
- ESTextSpotter: Towards Better Scene Text Spotting with Explicit Synergy   in Transformer - [[Arxiv](https://arxiv.org/abs/2308.10147)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10147.md)]
- OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision - [[Arxiv](https://arxiv.org/abs/2308.10146)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10146.md)]
- ExpeL: LLM Agents Are Experiential Learners - [[Arxiv](https://arxiv.org/abs/2308.10144)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10144.md)]
- March in Chat: Interactive Prompting for Remote Embodied Referring   Expression - [[Arxiv](https://arxiv.org/abs/2308.10141)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10141.md)]
- AutoReP: Automatic ReLU Replacement for Fast Private Network Inference - [[Arxiv](https://arxiv.org/abs/2308.10134)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10134.md)]
- TransFace: Calibrating Transformer Training for Face Recognition from a   Data-Centric Perspective - [[Arxiv](https://arxiv.org/abs/2308.10133)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10133.md)]
- 3D-Aware Neural Body Fitting for Occlusion Robust 3D Human Pose   Estimation - [[Arxiv](https://arxiv.org/abs/2308.10123)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10123.md)]
- HollowNeRF: Pruning Hashgrid-Based NeRFs with Trainable Collision   Mitigation - [[Arxiv](https://arxiv.org/abs/2308.10122)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10122.md)]
- Robust Mixture-of-Expert Training for Convolutional Neural Networks - [[Arxiv](https://arxiv.org/abs/2308.10110)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10110.md)]
- Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with   Monocular Videos - [[Arxiv](https://arxiv.org/abs/2308.10089)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10089.md)]
- GameEval: Evaluating LLMs on Conversational Games - [[Arxiv](https://arxiv.org/abs/2308.10032)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10032.md)]
- Single Image Reflection Separation via Component Synergy - [[Arxiv](https://arxiv.org/abs/2308.10027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10027.md)]
- Pseudo Flow Consistency for Self-Supervised 6D Object Pose Estimation - [[Arxiv](https://arxiv.org/abs/2308.10016)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10016.md)]
- Partition-and-Debias: Agnostic Biases Mitigation via A Mixture of   Biases-Specific Experts - [[Arxiv](https://arxiv.org/abs/2308.10005)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.10005.md)]
- ClothesNet: An Information-Rich 3D Garment Model Repository with   Simulated Clothes Environment - [[Arxiv](https://arxiv.org/abs/2308.09987)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09987.md)]
- FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for   Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.09975)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09975.md)]
- Disposable Transfer Learning for Selective Source Task Unlearning - [[Arxiv](https://arxiv.org/abs/2308.09971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09971.md)]
- Tackling Vision Language Tasks Through Learning Inner Monologues - [[Arxiv](https://arxiv.org/abs/2308.09970)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09970.md)]
- Semantics Meets Temporal Correspondence: Self-supervised Object-centric   Learning in Videos - [[Arxiv](https://arxiv.org/abs/2308.09951)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09951.md)]
- Scene-Aware Feature Matching - [[Arxiv](https://arxiv.org/abs/2308.09949)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09949.md)]
- Weakly-Supervised Action Localization by Hierarchically-structured   Latent Attention Modeling - [[Arxiv](https://arxiv.org/abs/2308.09946)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09946.md)]
- On the Robustness of Open-World Test-Time Training: Self-Training with   Dynamic Prototype Expansion - [[Arxiv](https://arxiv.org/abs/2308.09942)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09942.md)]
- Understanding Self-attention Mechanism via Dynamical System Perspective - [[Arxiv](https://arxiv.org/abs/2308.09939)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09939.md)]
- BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual   Questions - [[Arxiv](https://arxiv.org/abs/2308.09936)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09936.md)]
- MDCS: More Diverse Experts with Consistency Self-distillation for   Long-tailed Recognition - [[Arxiv](https://arxiv.org/abs/2308.09922)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09922.md)]
- VI-Net: Boosting Category-level 6D Object Pose Estimation via Learning   Decoupled Rotations on the Spherical Representations - [[Arxiv](https://arxiv.org/abs/2308.09916)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09916.md)]
- Scalable Video Object Segmentation with Simplified Framework - [[Arxiv](https://arxiv.org/abs/2308.09903)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09903.md)]
- SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin   Transformer and LSTM - [[Arxiv](https://arxiv.org/abs/2308.09891)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09891.md)]
- Calibrating Uncertainty for Semi-Supervised Crowd Counting - [[Arxiv](https://arxiv.org/abs/2308.09887)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09887.md)]
- Forecast-MAE: Self-supervised Pre-training for Motion Forecasting with   Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2308.09882)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09882.md)]
- Skill Transformer: A Monolithic Policy for Mobile Manipulation - [[Arxiv](https://arxiv.org/abs/2308.09873)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09873.md)]
- A Theory of Topological Derivatives for Inverse Rendering of Geometry - [[Arxiv](https://arxiv.org/abs/2308.09865)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09865.md)]
- How susceptible are LLMs to Logical Fallacies? - [[Arxiv](https://arxiv.org/abs/2308.09853)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09853.md)]
- Synergistic Integration of Large Language Models and Cognitive   Architectures for Robust AI: An Exploratory Analysis - [[Arxiv](https://arxiv.org/abs/2308.09830)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09830.md)]
- Learning from A Single Graph is All You Need for Near-Shortest Path   Routing in Wireless Networks - [[Arxiv](https://arxiv.org/abs/2308.09829)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09829.md)]
- VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity   Control - [[Arxiv](https://arxiv.org/abs/2308.09804)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09804.md)]
- Long-range Multimodal Pretraining for Movie Understanding - [[Arxiv](https://arxiv.org/abs/2308.09775)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09775.md)]
- Smoothness Similarity Regularization for Few-Shot GAN Adaptation - [[Arxiv](https://arxiv.org/abs/2308.09717)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09717.md)]
- Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis - [[Arxiv](https://arxiv.org/abs/2308.09713)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09713.md)]
- Robust Monocular Depth Estimation under Challenging Conditions - [[Arxiv](https://arxiv.org/abs/2308.09711)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09711.md)]
- Graph of Thoughts: Solving Elaborate Problems with Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.09687)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09687.md)]
- Red-Teaming Large Language Models using Chain of Utterances for   Safety-Alignment - [[Arxiv](https://arxiv.org/abs/2308.09662)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09662.md)]
- Is context all you need? Scaling Neural Sign Language Translation to   Large Domains of Discourse - [[Arxiv](https://arxiv.org/abs/2308.09622)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09622.md)]
- LaRS: A Diverse Panoptic Maritime Obstacle Detection Dataset and   Benchmark - [[Arxiv](https://arxiv.org/abs/2308.09618)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09618.md)]
- ChatHaruhi: Reviving Anime Character in Reality via Large Language Model - [[Arxiv](https://arxiv.org/abs/2308.09597)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09597.md)]
- StableVideo: Text-driven Consistency-aware Diffusion Video Editing - [[Arxiv](https://arxiv.org/abs/2308.09592)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09592.md)]
- WizardMath: Empowering Mathematical Reasoning for Large Language Models   via Reinforced Evol-Instruct - [[Arxiv](https://arxiv.org/abs/2308.09583)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09583.md)]
- PUMGPT: A Large Vision-Language Model for Product Understanding - [[Arxiv](https://arxiv.org/abs/2308.09568)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09568.md)]
- Normalization Is All You Need: Understanding Layer-Normalized Federated   Learning under Extreme Label Shift - [[Arxiv](https://arxiv.org/abs/2308.09565)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09565.md)]
- Deep Equilibrium Object Detection - [[Arxiv](https://arxiv.org/abs/2308.09564)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09564.md)]
- Meta-ZSDETR: Zero-shot DETR with Meta-learning - [[Arxiv](https://arxiv.org/abs/2308.09540)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09540.md)]
- Small Object Detection via Coarse-to-fine Proposal Generation and   Imitation Learning - [[Arxiv](https://arxiv.org/abs/2308.09534)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09534.md)]
- Leveraging Intrinsic Properties for Non-Rigid Garment Alignment - [[Arxiv](https://arxiv.org/abs/2308.09519)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09519.md)]
- ResQ: Residual Quantization for Video Perception - [[Arxiv](https://arxiv.org/abs/2308.09511)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09511.md)]
- Vision Relation Transformer for Unbiased Scene Graph Generation - [[Arxiv](https://arxiv.org/abs/2308.09472)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09472.md)]
- Scope is all you need: Transforming LLMs for HPC Code - [[Arxiv](https://arxiv.org/abs/2308.09440)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09440.md)]
- MonoNeRD: NeRF-like Representations for Monocular 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2308.09421)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09421.md)]
- Generalizable Decision Boundaries: Dualistic Meta-Learning for Open Set   Domain Generalization - [[Arxiv](https://arxiv.org/abs/2308.09391)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09391.md)]
- DReg-NeRF: Deep Registration for Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2308.09386)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09386.md)]
- Label-Free Event-based Object Recognition via Joint Learning with Image   Reconstruction from Events - [[Arxiv](https://arxiv.org/abs/2308.09383)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09383.md)]
- Open-vocabulary Video Question Answering: A New Benchmark for Evaluating   the Generalizability of Video Question Answering Models - [[Arxiv](https://arxiv.org/abs/2308.09363)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09363.md)]
- RLIPv2: Fast Scaling of Relational Language-Image Pre-training - [[Arxiv](https://arxiv.org/abs/2308.09351)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09351.md)]
- Boosting Few-shot Action Recognition with Graph-guided Hybrid Matching - [[Arxiv](https://arxiv.org/abs/2308.09346)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09346.md)]
- Audio-Visual Glance Network for Efficient Video Recognition - [[Arxiv](https://arxiv.org/abs/2308.09322)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09322.md)]
- Towards Attack-tolerant Federated Learning via Critical Parameter   Analysis - [[Arxiv](https://arxiv.org/abs/2308.09318)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09318.md)]
- Retro-FPN: Retrospective Feature Pyramid Network for Point Cloud   Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2308.09314)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09314.md)]
- Lip Reading for Low-resource Languages by Learning and Combining General   Speech Knowledge and Language-specific Knowledge - [[Arxiv](https://arxiv.org/abs/2308.09311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09311.md)]
- DiffDis: Empowering Generative Diffusion Model with Cross-Modal   Discrimination Capability - [[Arxiv](https://arxiv.org/abs/2308.09306)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09306.md)]
- Human Part-wise 3D Motion Context Learning for Sign Language Recognition - [[Arxiv](https://arxiv.org/abs/2308.09305)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09305.md)]
- NAPA-VQ: Neighborhood Aware Prototype Augmentation with Vector   Quantization for Continual Learning - [[Arxiv](https://arxiv.org/abs/2308.09297)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09297.md)]
- Self-Calibrated Cross Attention Network for Few-Shot Segmentation - [[Arxiv](https://arxiv.org/abs/2308.09294)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09294.md)]
- Diverse Cotraining Makes Strong Semi-Supervised Segmentor - [[Arxiv](https://arxiv.org/abs/2308.09281)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09281.md)]
- Point Contrastive Prediction with Semantic Clustering for   Self-Supervised Learning on Point Cloud Videos - [[Arxiv](https://arxiv.org/abs/2308.09247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09247.md)]
- Masked Spatio-Temporal Structure Prediction for Self-supervised Learning   on Point Cloud Videos - [[Arxiv](https://arxiv.org/abs/2308.09245)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09245.md)]
- SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera   Videos - [[Arxiv](https://arxiv.org/abs/2308.09244)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09244.md)]
- ASAG: Building Strong One-Decoder-Layer Sparse Detectors via Adaptive   Sparse Anchor Generation - [[Arxiv](https://arxiv.org/abs/2308.09242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09242.md)]
- Generalized Sum Pooling for Metric Learning - [[Arxiv](https://arxiv.org/abs/2308.09228)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09228.md)]
- FedPerfix: Towards Partial Model Personalization of Vision Transformers   in Federated Learning - [[Arxiv](https://arxiv.org/abs/2308.09160)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09160.md)]
- The Unreasonable Effectiveness of Large Language-Vision Models for   Source-free Video Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2308.09139)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09139.md)]
- ImGeoNet: Image-induced Geometry-aware Voxel Representation for   Multi-view 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2308.09098)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09098.md)]
- SimFIR: A Simple Framework for Fisheye Image Rectification with   Self-supervised Representation Learning - [[Arxiv](https://arxiv.org/abs/2308.09040)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.09040.md)]
- Reinforced Self-Training (ReST) for Language Modeling - [[Arxiv](https://arxiv.org/abs/2308.08998)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08998.md)]
- Auxiliary Tasks Benefit 3D Skeleton-based Human Motion Prediction - [[Arxiv](https://arxiv.org/abs/2308.08942)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08942.md)]
- Identity-Seeking Self-Supervised Representation Learning for   Generalizable Person Re-identification - [[Arxiv](https://arxiv.org/abs/2308.08887)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08887.md)]
- Event-Guided Procedure Planning from Instructional Videos with Text   Supervision - [[Arxiv](https://arxiv.org/abs/2308.08885)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08885.md)]
- Towards Semi-supervised Learning with Non-random Missing Labels - [[Arxiv](https://arxiv.org/abs/2308.08872)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08872.md)]
- Spatially and Spectrally Consistent Deep Functional Maps - [[Arxiv](https://arxiv.org/abs/2308.08871)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08871.md)]
- D-IF: Uncertainty-aware Human Digitization via Implicit Distribution   Field - [[Arxiv](https://arxiv.org/abs/2308.08857)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08857.md)]
- Realistic Full-Body Tracking from Sparse Observations via Joint-Level   Modeling - [[Arxiv](https://arxiv.org/abs/2308.08855)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08855.md)]
- CMB: A Comprehensive Medical Benchmark in Chinese - [[Arxiv](https://arxiv.org/abs/2308.08833)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08833.md)]
- Fast Inference and Update of Probabilistic Density Estimation on   Trajectory Prediction - [[Arxiv](https://arxiv.org/abs/2308.08824)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08824.md)]
- MixBag: Bag-Level Data Augmentation for Learning from Label Proportions - [[Arxiv](https://arxiv.org/abs/2308.08822)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08822.md)]
- Label Shift Adapter for Test-Time Adaptation under Covariate and Label   Shifts - [[Arxiv](https://arxiv.org/abs/2308.08810)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08810.md)]
- Long-Range Grouping Transformer for Multi-View 3D Reconstruction - [[Arxiv](https://arxiv.org/abs/2308.08724)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08724.md)]
- V-FUSE: Volumetric Depth Map Fusion with Long-Range Constraints - [[Arxiv](https://arxiv.org/abs/2308.08715)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08715.md)]
- Dynamic Neural Network is All You Need: Understanding the Robustness of   Dynamic Mechanisms in Neural Networks - [[Arxiv](https://arxiv.org/abs/2308.08709)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08709.md)]
- TeCH: Text-guided Reconstruction of Lifelike Clothed Humans - [[Arxiv](https://arxiv.org/abs/2308.08545)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08545.md)]
- MeViS: A Large-scale Benchmark for Video Segmentation with Motion   Expressions - [[Arxiv](https://arxiv.org/abs/2308.08544)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08544.md)]
- Learning to Distill Global Representation for Sparse-View CT - [[Arxiv](https://arxiv.org/abs/2308.08463)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08463.md)]
- ALIP: Adaptive Language-Image Pre-training with Synthetic Caption - [[Arxiv](https://arxiv.org/abs/2308.08428)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08428.md)]
- Tem-adapter: Adapting Image-Text Pretraining for Video Question Answer - [[Arxiv](https://arxiv.org/abs/2308.08414)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08414.md)]
- SIGMA: Scale-Invariant Global Sparse Shape Matching - [[Arxiv](https://arxiv.org/abs/2308.08393)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08393.md)]
- Agglomerative Transformer for Human-Object Interaction Detection - [[Arxiv](https://arxiv.org/abs/2308.08370)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08370.md)]
- Membrane Potential Batch Normalization for Spiking Neural Networks - [[Arxiv](https://arxiv.org/abs/2308.08359)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08359.md)]
- Stable and Causal Inference for Discriminative Self-supervised Deep   Visual Representations - [[Arxiv](https://arxiv.org/abs/2308.08321)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08321.md)]
- Dual-Stream Diffusion Net for Text-to-Video Generation - [[Arxiv](https://arxiv.org/abs/2308.08316)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08316.md)]
- SceNeRFlow: Time-Consistent Reconstruction of General Dynamic Scenes - [[Arxiv](https://arxiv.org/abs/2308.08258)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08258.md)]
- MemoChat: Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain   Conversation - [[Arxiv](https://arxiv.org/abs/2308.08239)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08239.md)]
- Inherent Redundancy in Spiking Neural Networks - [[Arxiv](https://arxiv.org/abs/2308.08227)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08227.md)]
- Low-Light Image Enhancement with Illumination-Aware Gamma Correction and   Complete Image Modelling Network - [[Arxiv](https://arxiv.org/abs/2308.08220)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08220.md)]
- Unsupervised Domain Adaptive Detection with Network Stability Analysis - [[Arxiv](https://arxiv.org/abs/2308.08182)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08182.md)]
- Learning to Generate Semantic Layouts for Higher Text-Image   Correspondence in Text-to-Image Synthesis - [[Arxiv](https://arxiv.org/abs/2308.08157)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08157.md)]
- AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation - [[Arxiv](https://arxiv.org/abs/2308.08155)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08155.md)]
- GPA-3D: Geometry-aware Prototype Alignment for Unsupervised Domain   Adaptive 3D Object Detection from Point Clouds - [[Arxiv](https://arxiv.org/abs/2308.08140)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08140.md)]
- OmniZoomer: Learning to Move and Zoom in on Sphere at High-Resolution - [[Arxiv](https://arxiv.org/abs/2308.08114)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08114.md)]
- View Consistent Purification for Accurate Cross-View Localization - [[Arxiv](https://arxiv.org/abs/2308.08110)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08110.md)]
- Separate the Wheat from the Chaff: Model Deficiency Unlearning via   Parameter-Efficient Module Operation - [[Arxiv](https://arxiv.org/abs/2308.08090)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08090.md)]
- DragNUWA: Fine-grained Control in Video Generation by Integrating Text,   Image, and Trajectory - [[Arxiv](https://arxiv.org/abs/2308.08089)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08089.md)]
- Shortcut-V2V: Compression Framework for Video-to-Video Translation based   on Temporal Redundancy Reduction - [[Arxiv](https://arxiv.org/abs/2308.08011)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.08011.md)]
- Teach LLMs to Personalize -- An Approach inspired by Writing Education - [[Arxiv](https://arxiv.org/abs/2308.07968)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07968.md)]
- CoDeF: Content Deformation Fields for Temporally Consistent Video   Processing - [[Arxiv](https://arxiv.org/abs/2308.07926)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07926.md)]
- RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder   Language Models - [[Arxiv](https://arxiv.org/abs/2308.07922)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07922.md)]
- Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with   Code-based Self-Verification - [[Arxiv](https://arxiv.org/abs/2308.07921)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07921.md)]
- Helping Hands: An Object-Aware Ego-Centric Video Recognition Model - [[Arxiv](https://arxiv.org/abs/2308.07918)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07918.md)]
- Relightable and Animatable Neural Avatar from Sparse-View Video - [[Arxiv](https://arxiv.org/abs/2308.07903)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07903.md)]
- Through the Lens of Core Competency: Survey on Evaluation of Large   Language Models - [[Arxiv](https://arxiv.org/abs/2308.07902)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07902.md)]
- Memory-and-Anticipation Transformer for Online Action Understanding - [[Arxiv](https://arxiv.org/abs/2308.07893)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07893.md)]
- Link-Context Learning for Multimodal LLMs - [[Arxiv](https://arxiv.org/abs/2308.07891)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07891.md)]
- ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces - [[Arxiv](https://arxiv.org/abs/2308.07868)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07868.md)]
- StyleDiffusion: Controllable Disentangled Style Transfer via Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2308.07863)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07863.md)]
- Robustness Over Time: Understanding Adversarial Examples' Effectiveness   on Longitudinal Versions of Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.07847)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07847.md)]
- ImbSAM: A Closer Look at Sharpness-Aware Minimization in   Class-Imbalanced Recognition - [[Arxiv](https://arxiv.org/abs/2308.07815)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07815.md)]
- Learning to Identify Critical States for Reinforcement Learning from   Videos - [[Arxiv](https://arxiv.org/abs/2308.07795)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07795.md)]
- DiffV2S: Diffusion-based Video-to-Speech Synthesis with Vision-guided   Speaker Embedding - [[Arxiv](https://arxiv.org/abs/2308.07787)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07787.md)]
- Identity-Consistent Aggregation for Video Object Detection - [[Arxiv](https://arxiv.org/abs/2308.07737)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07737.md)]
- UniTR: A Unified and Efficient Multi-Modal Transformer for   Bird's-Eye-View Representation - [[Arxiv](https://arxiv.org/abs/2308.07732)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07732.md)]
- DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using   Pre-trained Diffusion Models - [[Arxiv](https://arxiv.org/abs/2308.07687)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07687.md)]
- Boosting Multi-modal Model Performance with Adaptive Gradient Modulation - [[Arxiv](https://arxiv.org/abs/2308.07686)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07686.md)]
- Attention Is Not All You Need Anymore - [[Arxiv](https://arxiv.org/abs/2308.07661)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07661.md)]
- From Commit Message Generation to History-Aware Commit Message   Completion - [[Arxiv](https://arxiv.org/abs/2308.07655)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07655.md)]
- EQ-Net: Elastic Quantization Neural Networks - [[Arxiv](https://arxiv.org/abs/2308.07650)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07650.md)]
- Prompt Switch: Efficient CLIP Adaptation for Text-Video Retrieval - [[Arxiv](https://arxiv.org/abs/2308.07648)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07648.md)]
- Backpropagation Path Search On Adversarial Transferability - [[Arxiv](https://arxiv.org/abs/2308.07625)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07625.md)]
- Story Visualization by Online Text Augmentation with Context Memory - [[Arxiv](https://arxiv.org/abs/2308.07575)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07575.md)]
- 3DHacker: Spectrum-based Decision Boundary Generation for Hard-label 3D   Point Cloud Attack - [[Arxiv](https://arxiv.org/abs/2308.07546)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07546.md)]
- Vision-Language Dataset Distillation - [[Arxiv](https://arxiv.org/abs/2308.07545)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07545.md)]
- DREAMWALKER: Mental Planning for Continuous Vision-Language Navigation - [[Arxiv](https://arxiv.org/abs/2308.07498)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07498.md)]
- Exploring the Intersection of Large Language Models and Agent-Based   Modeling via Prompt Engineering - [[Arxiv](https://arxiv.org/abs/2308.07411)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07411.md)]
- Text Injection for Capitalization and Turn-Taking Prediction in Speech   Models - [[Arxiv](https://arxiv.org/abs/2308.07395)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07395.md)]
- PARIS: Part-level Reconstruction and Motion Analysis for Articulated   Objects - [[Arxiv](https://arxiv.org/abs/2308.07391)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07391.md)]
- Platypus: Quick, Cheap, and Powerful Refinement of LLMs - [[Arxiv](https://arxiv.org/abs/2308.07317)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07317.md)]
- Jurassic World Remake: Bringing Ancient Fossils Back to Life via   Zero-Shot Long Image-to-Image Translation - [[Arxiv](https://arxiv.org/abs/2308.07316)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07316.md)]
- Group Pose: A Simple Baseline for End-to-End Multi-person Pose   Estimation - [[Arxiv](https://arxiv.org/abs/2308.07313)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07313.md)]
- The Devil is in the Errors: Leveraging Large Language Models for   Fine-grained Machine Translation Evaluation - [[Arxiv](https://arxiv.org/abs/2308.07286)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07286.md)]
- Context-Aware Planning and Environment-Aware Memory for Instruction   Following Embodied Agents - [[Arxiv](https://arxiv.org/abs/2308.07241)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07241.md)]
- RestoreFormer++: Towards Real-World Blind Face Restoration from   Undegraded Key-Value Pairs - [[Arxiv](https://arxiv.org/abs/2308.07228)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07228.md)]
- Unified Data-Free Compression: Pruning and Quantization without   Fine-Tuning - [[Arxiv](https://arxiv.org/abs/2308.07209)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07209.md)]
- ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate - [[Arxiv](https://arxiv.org/abs/2308.07201)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07201.md)]
- OctoPack: Instruction Tuning Code Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.07124)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07124.md)]
- CTP: Towards Vision-Language Continual Pretraining via Compatible   Momentum Contrast and Topology Preservation - [[Arxiv](https://arxiv.org/abs/2308.07146)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07146.md)]
- Occ$^2$Net: Robust Image Matching Based on 3D Occupancy Estimation for   Occluded Regions - [[Arxiv](https://arxiv.org/abs/2308.16160)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.16160.md)]
- Mind your Language (Model): Fact-Checking LLMs and their Role in NLP   Research and Practice - [[Arxiv](https://arxiv.org/abs/2308.07120)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07120.md)]
- Large Language Models for Information Retrieval: A Survey - [[Arxiv](https://arxiv.org/abs/2308.07107)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07107.md)]
- Masked Motion Predictors are Strong 3D Action Representation Learners - [[Arxiv](https://arxiv.org/abs/2308.07092)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07092.md)]
- S3IM: Stochastic Structural SIMilarity and Its Unreasonable   Effectiveness for Neural Fields - [[Arxiv](https://arxiv.org/abs/2308.07032)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07032.md)]
- ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal   and Robust Vehicle Evasion - [[Arxiv](https://arxiv.org/abs/2308.07009)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07009.md)]
- EcomGPT: Instruction-tuning Large Language Models with Chain-of-Task   Tasks for E-commerce - [[Arxiv](https://arxiv.org/abs/2308.06966)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06966.md)]
- Global Features are All You Need for Image Retrieval and Reranking - [[Arxiv](https://arxiv.org/abs/2308.06954)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06954.md)]
- Knowing Where to Focus: Event-aware Transformer for Video Grounding - [[Arxiv](https://arxiv.org/abs/2308.06947)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06947.md)]
- CBA: Improving Online Continual Learning via Continual Bias Adaptor - [[Arxiv](https://arxiv.org/abs/2308.06925)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06925.md)]
- CausalLM is not optimal for in-context learning - [[Arxiv](https://arxiv.org/abs/2308.06912)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06912.md)]
- Exploring Lightweight Hierarchical Vision Transformers for Efficient   Visual Tracking - [[Arxiv](https://arxiv.org/abs/2308.06904)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06904.md)]
- Towards Open-Set Test-Time Adaptation Utilizing the Wisdom of Crowds in   Entropy Minimization - [[Arxiv](https://arxiv.org/abs/2308.06879)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06879.md)]
- SpeechX: Neural Codec Language Model as a Versatile Speech Transformer - [[Arxiv](https://arxiv.org/abs/2308.06873)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06873.md)]
- RMP-Loss: Regularizing Membrane Potential Distribution for Spiking   Neural Networks - [[Arxiv](https://arxiv.org/abs/2308.06787)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06787.md)]
- Shrinking Class Space for Enhanced Certainty in Semi-Supervised Learning - [[Arxiv](https://arxiv.org/abs/2308.06777)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06777.md)]
- Unsupervised Image Denoising in Real-World Scenarios via   Self-Collaboration Parallel Generative Adversarial Branches - [[Arxiv](https://arxiv.org/abs/2308.06776)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06776.md)]
- Dual Meta-Learning with Longitudinally Generalized Regularization for   One-Shot Brain Tissue Segmentation Across the Human Lifespan - [[Arxiv](https://arxiv.org/abs/2308.06774)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06774.md)]
- AerialVLN: Vision-and-Language Navigation for UAVs - [[Arxiv](https://arxiv.org/abs/2308.06735)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06735.md)]
- IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image   Diffusion Models - [[Arxiv](https://arxiv.org/abs/2308.06721)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06721.md)]
- Compositional Feature Augmentation for Unbiased Scene Graph Generation - [[Arxiv](https://arxiv.org/abs/2308.06712)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06712.md)]
- Camouflaged Image Synthesis Is All You Need to Boost Camouflaged   Detection - [[Arxiv](https://arxiv.org/abs/2308.06701)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06701.md)]
- Isomer: Isomerous Transformer for Zero-shot Video Object Segmentation - [[Arxiv](https://arxiv.org/abs/2308.06693)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06693.md)]
- Estimator Meets Equilibrium Perspective: A Rectified Straight Through   Estimator for Binary Neural Networks Training - [[Arxiv](https://arxiv.org/abs/2308.06689)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06689.md)]
- 3DMOTFormer: Graph Transformer for Online 3D Multi-Object Tracking - [[Arxiv](https://arxiv.org/abs/2308.06635)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06635.md)]
- VisIT-Bench: A Benchmark for Vision-Language Instruction Following   Inspired by Real-World Use - [[Arxiv](https://arxiv.org/abs/2308.06595)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06595.md)]
- Cyclic Test-Time Adaptation on Monocular Video for 3D Human Mesh   Reconstruction - [[Arxiv](https://arxiv.org/abs/2308.06554)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06554.md)]
- Revisiting Vision Transformer from the View of Path Ensemble - [[Arxiv](https://arxiv.org/abs/2308.06548)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06548.md)]
- SegPrompt: Boosting Open-world Segmentation via Category-level Prompt   Learning - [[Arxiv](https://arxiv.org/abs/2308.06531)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06531.md)]
- BEV-DG: Cross-Modal Learning under Bird's-Eye View for Domain   Generalization of 3D Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2308.06530)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06530.md)]
- One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training - [[Arxiv](https://arxiv.org/abs/2308.07934)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07934.md)]
- Tiny and Efficient Model for the Edge Detection Generalization - [[Arxiv](https://arxiv.org/abs/2308.06468)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06468.md)]
- Multi-Label Knowledge Distillation - [[Arxiv](https://arxiv.org/abs/2308.06453)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06453.md)]
- Detecting and Preventing Hallucinations in Large Vision Language Models - [[Arxiv](https://arxiv.org/abs/2308.06394)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06394.md)]
- U-RED: Unsupervised 3D Shape Retrieval and Deformation for Partial Point   Clouds - [[Arxiv](https://arxiv.org/abs/2308.06383)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06383.md)]
- Enhancing Network Management Using Code Generated by Large Language   Models - [[Arxiv](https://arxiv.org/abs/2308.06261)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06261.md)]
- Self-Alignment with Instruction Backtranslation - [[Arxiv](https://arxiv.org/abs/2308.06259)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06259.md)]
- FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of   Explainable AI Methods - [[Arxiv](https://arxiv.org/abs/2308.06248)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06248.md)]
- Exploring Predicate Visual Context in Detecting of Human-Object   Interactions - [[Arxiv](https://arxiv.org/abs/2308.06202)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06202.md)]
- Improving Joint Speech-Text Representations Without Alignment - [[Arxiv](https://arxiv.org/abs/2308.06125)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06125.md)]
- Composable Function-preserving Expansions for Transformer Architectures - [[Arxiv](https://arxiv.org/abs/2308.06103)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06103.md)]
- Out-of-Distribution Detection for Monocular Depth Estimation - [[Arxiv](https://arxiv.org/abs/2308.06072)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06072.md)]
- Diverse Data Augmentation with Diffusions for Effective Test-time Prompt   Tuning - [[Arxiv](https://arxiv.org/abs/2308.06038)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06038.md)]
- Enhancing Generalization of Universal Adversarial Perturbation through   Gradient Aggregation - [[Arxiv](https://arxiv.org/abs/2308.06015)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.06015.md)]
- Cyclic-Bootstrap Labeling for Weakly Supervised Object Detection - [[Arxiv](https://arxiv.org/abs/2308.05991)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05991.md)]
- TrajPAC: Towards Robustness Verification of Pedestrian Trajectory   Prediction Models - [[Arxiv](https://arxiv.org/abs/2308.05985)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05985.md)]
- BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents - [[Arxiv](https://arxiv.org/abs/2308.05960)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05960.md)]
- LittleMu: Deploying an Online Virtual Teaching Assistant via   Heterogeneous Sources Integration and Chain of Teach Prompts - [[Arxiv](https://arxiv.org/abs/2308.05935)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05935.md)]
- Generalizing Event-Based Motion Deblurring in Real-World Scenarios - [[Arxiv](https://arxiv.org/abs/2308.05932)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05932.md)]
- Collaborative Tracking Learning for Frame-Rate-Insensitive Multi-Object   Tracking - [[Arxiv](https://arxiv.org/abs/2308.05911)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05911.md)]
- PIPPA: A Partially Synthetic Conversational Dataset - [[Arxiv](https://arxiv.org/abs/2308.05884)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05884.md)]
- PlankAssembly: Robust 3D Reconstruction from Three Orthographic Views   with Learnt Shape Programs - [[Arxiv](https://arxiv.org/abs/2308.05744)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05744.md)]
- Follow Anything: Open-set detection, tracking, and following in   real-time - [[Arxiv](https://arxiv.org/abs/2308.05737)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05737.md)]
- AudioLDM 2: Learning Holistic Audio Generation with Self-supervised   Pretraining - [[Arxiv](https://arxiv.org/abs/2308.05734)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05734.md)]
- FrozenRecon: Pose-free 3D Scene Reconstruction with Frozen Depth Models - [[Arxiv](https://arxiv.org/abs/2308.05733)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05733.md)]
- PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers - [[Arxiv](https://arxiv.org/abs/2308.05732)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05732.md)]
- Hard No-Box Adversarial Attack on Skeleton-Based Human Action   Recognition with Skeleton-Motion-Informed Gradient - [[Arxiv](https://arxiv.org/abs/2308.05681)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05681.md)]
- 2D3D-MATR: 2D-3D Matching Transformer for Detection-free Registration   between Images and Point Clouds - [[Arxiv](https://arxiv.org/abs/2308.05667)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05667.md)]
- Self-Supervised Monocular Depth Estimation by Direction-aware Cumulative   Convolution Network - [[Arxiv](https://arxiv.org/abs/2308.05605)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05605.md)]
- Cross-Domain Product Representation Learning for Rich-Content E-Commerce - [[Arxiv](https://arxiv.org/abs/2308.05550)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05550.md)]
- Look at the Neighbor: Distortion-aware Unsupervised Domain Adaptation   for Panoramic Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2308.05493)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05493.md)]
- LLM As DBA - [[Arxiv](https://arxiv.org/abs/2308.05481)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05481.md)]
- Benchmarking Algorithmic Bias in Face Recognition: An Experimental   Approach Using Synthetic Faces and Human Evaluation - [[Arxiv](https://arxiv.org/abs/2308.05441)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05441.md)]
- Deep Fusion Transformer Network with Weighted Vector-Wise Keypoints   Voting for Robust 6D Object Pose Estimation - [[Arxiv](https://arxiv.org/abs/2308.05438)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05438.md)]
- SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated,   Noisy, and Decimated Point Cloud Data - [[Arxiv](https://arxiv.org/abs/2308.05410)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05410.md)]
- Learning Gabor Texture Features for Fine-Grained Recognition - [[Arxiv](https://arxiv.org/abs/2308.05396)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05396.md)]
- Enhancing Trust in LLM-Based AI Automation Agents: New Considerations   and Future Challenges - [[Arxiv](https://arxiv.org/abs/2308.05391)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05391.md)]
- Interaction-aware Joint Attention Estimation Using People Attributes - [[Arxiv](https://arxiv.org/abs/2308.05382)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05382.md)]
- Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language   Models' Alignment - [[Arxiv](https://arxiv.org/abs/2308.05374)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05374.md)]
- Flexible Isosurface Extraction for Gradient-Based Mesh Optimization - [[Arxiv](https://arxiv.org/abs/2308.05371)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05371.md)]
- Pseudo-label Alignment for Semi-supervised Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2308.05359)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05359.md)]
- OpenProteinSet: Training data for structural biology at scale - [[Arxiv](https://arxiv.org/abs/2308.05326)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05326.md)]
- RLSAC: Reinforcement Learning enhanced Sample Consensus for End-to-End   Robust Estimation - [[Arxiv](https://arxiv.org/abs/2308.05318)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05318.md)]
- Alexa, play with robot: Introducing the First Alexa Prize SimBot   Challenge on Embodied AI - [[Arxiv](https://arxiv.org/abs/2308.05221)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05221.md)]
- LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image   Generation - [[Arxiv](https://arxiv.org/abs/2308.05095)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05095.md)]
- Feature Modulation Transformer: Cross-Refinement of Global   Representation via High-Frequency Prior for Image Super-Resolution - [[Arxiv](https://arxiv.org/abs/2308.05022)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05022.md)]
- An Empirical Study on Using Large Language Models to Analyze Software   Supply Chain Security Failures - [[Arxiv](https://arxiv.org/abs/2308.04898)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04898.md)]
- Robust Object Modeling for Visual Tracking - [[Arxiv](https://arxiv.org/abs/2308.05140)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.05140.md)]
- IDiff-Face: Synthetic-based Face Recognition through Fizzy   Identity-Conditioned Diffusion Models - [[Arxiv](https://arxiv.org/abs/2308.04995)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04995.md)]
- Foreground Object Search by Distilling Composite Image Feature - [[Arxiv](https://arxiv.org/abs/2308.04990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04990.md)]
- Prototypical Kernel Learning and Open-set Foreground Perception for   Generalized Few-shot Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2308.04952)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04952.md)]
- SelectNAdapt: Support Set Selection for Few-Shot Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2308.04946)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04946.md)]
- LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking - [[Arxiv](https://arxiv.org/abs/2308.04945)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04945.md)]
- Cross-view Semantic Alignment for Livestreaming Product Recognition - [[Arxiv](https://arxiv.org/abs/2308.04912)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04912.md)]
- MixReorg: Cross-Modal Mixed Patch Reorganization is a Good Mask Learner   for Open-World Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2308.04829)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04829.md)]
- WaveNeRF: Wavelet-based Generalizable Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2308.04826)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04826.md)]
- Joint-Relation Transformer for Multi-Person Motion Prediction - [[Arxiv](https://arxiv.org/abs/2308.04808)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04808.md)]
- PointMBF: A Multi-scale Bidirectional Fusion Network for Unsupervised   RGB-D Point Cloud Registration - [[Arxiv](https://arxiv.org/abs/2308.04782)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04782.md)]
- Objects do not disappear: Video object detection by single-frame object   location anticipation - [[Arxiv](https://arxiv.org/abs/2308.04770)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04770.md)]
- Bird's-Eye-View Scene Graph for Vision-Language Navigation - [[Arxiv](https://arxiv.org/abs/2308.04758)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04758.md)]
- JEN-1: Text-Guided Universal Music Generation with Omnidirectional   Diffusion Models - [[Arxiv](https://arxiv.org/abs/2308.04729)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04729.md)]
- GIFD: A Generative Gradient Inversion Method with Feature Domain   Optimization - [[Arxiv](https://arxiv.org/abs/2308.04699)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04699.md)]
- Score Priors Guided Deep Variational Inference for Unsupervised   Real-World Single Image Denoising - [[Arxiv](https://arxiv.org/abs/2308.04682)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04682.md)]
- Accelerating LLM Inference with Staged Speculative Decoding - [[Arxiv](https://arxiv.org/abs/2308.04623)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04623.md)]
- Rendering Humans from Object-Occluded Monocular Videos - [[Arxiv](https://arxiv.org/abs/2308.04622)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04622.md)]
- Shepherd: A Critic for Language Model Generation - [[Arxiv](https://arxiv.org/abs/2308.04592)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04592.md)]
- LATR: 3D Lane Detection from Monocular Images with Transformer - [[Arxiv](https://arxiv.org/abs/2308.04583)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04583.md)]
- FocalFormer3D : Focusing on Hard Instance for 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2308.04556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04556.md)]
- Prune Spatio-temporal Tokens by Semantic-aware Temporal Accumulation - [[Arxiv](https://arxiv.org/abs/2308.04549)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04549.md)]
- SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore - [[Arxiv](https://arxiv.org/abs/2308.04430)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04430.md)]
- DELFlow: Dense Efficient Learning of Scene Flow for Large-Scale Point   Clouds - [[Arxiv](https://arxiv.org/abs/2308.04383)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04383.md)]
- Cumulative Reasoning with Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.04371)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04371.md)]
- 3D-VisTA: Pre-trained Transformer for 3D Vision and Text Alignment - [[Arxiv](https://arxiv.org/abs/2308.04352)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04352.md)]
- A Comparative Study of Code Generation using ChatGPT 3.5 across 10   Programming Languages - [[Arxiv](https://arxiv.org/abs/2308.04477)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04477.md)]
- Lossy and Lossless (L$^2$) Post-training Model Size Compression - [[Arxiv](https://arxiv.org/abs/2308.04269)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04269.md)]
- FLIRT: Feedback Loop In-context Red Teaming - [[Arxiv](https://arxiv.org/abs/2308.04265)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04265.md)]
- Exploring Transformers for Open-world Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2308.04206)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04206.md)]
- D3G: Exploring Gaussian Prior for Temporal Sentence Grounding with   Glance Annotation - [[Arxiv](https://arxiv.org/abs/2308.04197)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04197.md)]
- Under-Display Camera Image Restoration with Scattering Effect - [[Arxiv](https://arxiv.org/abs/2308.04163)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04163.md)]
- EPCFormer: Expression Prompt Collaboration Transformer for Universal   Referring Video Object Segmentation - [[Arxiv](https://arxiv.org/abs/2308.04162)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04162.md)]
- Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative   Instructions - [[Arxiv](https://arxiv.org/abs/2308.04152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04152.md)]
- OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion   and Infinite Data Generation - [[Arxiv](https://arxiv.org/abs/2308.04126)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04126.md)]
- 3D Gaussian Splatting for Real-Time Radiance Field Rendering - [[Arxiv](https://arxiv.org/abs/2308.04079)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04079.md)]
- Enhancing Adversarial Robustness in Low-Label Regime via Adaptively   Weighted Regularization and Knowledge Distillation - [[Arxiv](https://arxiv.org/abs/2308.04061)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04061.md)]
- Gentopia: A Collaborative Platform for Tool-Augmented LLMs - [[Arxiv](https://arxiv.org/abs/2308.04030)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04030.md)]
- AgentSims: An Open-Source Sandbox for Large Language Model Evaluation - [[Arxiv](https://arxiv.org/abs/2308.04026)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04026.md)]
- Hierarchical Visual Primitive Experts for Compositional Zero-Shot   Learning - [[Arxiv](https://arxiv.org/abs/2308.04016)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04016.md)]
- Continual Pre-Training of Large Language Models: How to (re)warm your   model? - [[Arxiv](https://arxiv.org/abs/2308.04014)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04014.md)]
- Coarse-to-Fine: Learning Compact Discriminative Representation for   Single-Stage Image Retrieval - [[Arxiv](https://arxiv.org/abs/2308.04008)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.04008.md)]
- PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2308.03982)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03982.md)]
- Simple synthetic data reduces sycophancy in large language models - [[Arxiv](https://arxiv.org/abs/2308.03958)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03958.md)]
- TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal   Backdoored Models - [[Arxiv](https://arxiv.org/abs/2308.03906)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03906.md)]
- From Sky to the Ground: A Large-scale Benchmark and Simple Baseline   Towards Real Rain Removal - [[Arxiv](https://arxiv.org/abs/2308.03867)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03867.md)]
- 3D Motion Magnification: Visualizing Subtle Motions with Time Varying   Radiance Fields - [[Arxiv](https://arxiv.org/abs/2308.03757)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03757.md)]
- Tiny LVLM-eHub: Early Multimodal Experiments with Bard - [[Arxiv](https://arxiv.org/abs/2308.03729)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03729.md)]
- Scaling may be all you need for achieving human-level object recognition   capacity with human-like visual experience - [[Arxiv](https://arxiv.org/abs/2308.03712)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03712.md)]
- AgentBench: Evaluating LLMs as Agents - [[Arxiv](https://arxiv.org/abs/2308.03688)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03688.md)]
- Learning Concise and Descriptive Attributes for Visual Recognition - [[Arxiv](https://arxiv.org/abs/2308.03685)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03685.md)]
- AvatarVerse: High-quality &amp; Stable 3D Avatar Creation from Text and Pose - [[Arxiv](https://arxiv.org/abs/2308.03610)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03610.md)]
- FeatEnHancer: Enhancing Hierarchical Features for Object Detection and   Beyond Under Low-Light Vision - [[Arxiv](https://arxiv.org/abs/2308.03594)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03594.md)]
- AlphaStar Unplugged: Large-Scale Offline Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2308.03526)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03526.md)]
- Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for   RAW Denoising - [[Arxiv](https://arxiv.org/abs/2308.03448)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03448.md)]
- TPTU: Large Language Model-based AI Agents for Task Planning and Tool   Usage - [[Arxiv](https://arxiv.org/abs/2308.03427)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03427.md)]
- RecycleGPT: An Autoregressive Language Model with Recyclable Module - [[Arxiv](https://arxiv.org/abs/2308.03421)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03421.md)]
- GaFET: Learning Geometry-aware Facial Expression Translation from   In-The-Wild Images - [[Arxiv](https://arxiv.org/abs/2308.03413)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03413.md)]
- Heterogeneous Forgetting Compensation for Class-Incremental Learning - [[Arxiv](https://arxiv.org/abs/2308.03374)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03374.md)]
- Dual Aggregation Transformer for Image Super-Resolution - [[Arxiv](https://arxiv.org/abs/2308.03364)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03364.md)]
- Foundation Model based Open Vocabulary Task Planning and Executive   System for General Purpose Service Robots - [[Arxiv](https://arxiv.org/abs/2308.03357)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03357.md)]
- SciGraphQA: A Large-Scale Synthetic Multi-Turn Question-Answering   Dataset for Scientific Graphs - [[Arxiv](https://arxiv.org/abs/2308.03349)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03349.md)]
- Part-Aware Transformer for Generalizable Person Re-identification - [[Arxiv](https://arxiv.org/abs/2308.03322)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03322.md)]
- Studying Large Language Model Generalization with Influence Functions - [[Arxiv](https://arxiv.org/abs/2308.03296)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03296.md)]
- SynJax: Structured Probability Distributions for JAX - [[Arxiv](https://arxiv.org/abs/2308.03291)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03291.md)]
- FLIQS: One-Shot Mixed-Precision Floating-Point and Integer Quantization   Search - [[Arxiv](https://arxiv.org/abs/2308.03290)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03290.md)]
- Multi-Label Self-Supervised Learning with Scene Images - [[Arxiv](https://arxiv.org/abs/2308.03286)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03286.md)]
- Environment-Invariant Curriculum Relation Learning for Fine-Grained   Scene Graph Generation - [[Arxiv](https://arxiv.org/abs/2308.03282)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03282.md)]
- Mirror-NeRF: Learning Neural Radiance Fields for Mirrors with   Whitted-Style Ray Tracing - [[Arxiv](https://arxiv.org/abs/2308.03280)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03280.md)]
- UniversalNER: Targeted Distillation from Large Language Models for Open   Named Entity Recognition - [[Arxiv](https://arxiv.org/abs/2308.03279)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03279.md)]
- A Benchmark for Chinese-English Scene Text Image Super-resolution - [[Arxiv](https://arxiv.org/abs/2308.03262)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03262.md)]
- Source-free Domain Adaptive Human Pose Estimation - [[Arxiv](https://arxiv.org/abs/2308.03202)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03202.md)]
- Building Safe and Reliable AI systems for Safety Critical Tasks with   Vision-Language Processing - [[Arxiv](https://arxiv.org/abs/2308.03176)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03176.md)]
- CGBA: Curvature-aware Geometric Black-box Attack - [[Arxiv](https://arxiv.org/abs/2308.03163)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03163.md)]
- Prototypes-oriented Transductive Few-shot Learning with Conditional   Transport - [[Arxiv](https://arxiv.org/abs/2308.03047)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03047.md)]
- Learning Fine-Grained Features for Pixel-wise Video Correspondences - [[Arxiv](https://arxiv.org/abs/2308.03040)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03040.md)]
- Pre-Trained Large Language Models for Industrial Control - [[Arxiv](https://arxiv.org/abs/2308.03028)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03028.md)]
- SAPIEN: Affective Virtual Agents Powered by Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.03022)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03022.md)]
- Focus the Discrepancy: Intra- and Inter-Correlation Learning for Image   Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2308.02983)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02983.md)]
- An Adaptive Model Ensemble Adversarial Attack for Boosting Adversarial   Transferability - [[Arxiv](https://arxiv.org/abs/2308.02897)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02897.md)]
- Sketch and Text Guided Diffusion Model for Colored Point Cloud   Generation - [[Arxiv](https://arxiv.org/abs/2308.02874)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02874.md)]
- Learning Unified Decompositional and Compositional NeRF for Editable   Novel View Synthesis - [[Arxiv](https://arxiv.org/abs/2308.02840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02840.md)]
- EduChat: A Large-Scale Language Model-based Chatbot System for   Intelligent Education - [[Arxiv](https://arxiv.org/abs/2308.02773)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02773.md)]
- DeDrift: Robust Similarity Search under Content Drift - [[Arxiv](https://arxiv.org/abs/2308.02752)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02752.md)]
- ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free   Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2308.03793)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.03793.md)]
- MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities - [[Arxiv](https://arxiv.org/abs/2308.02490)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02490.md)]
- Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen   Convolutional CLIP - [[Arxiv](https://arxiv.org/abs/2308.02487)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02487.md)]
- Getting the Ball Rolling: Learning a Dexterous Policy for a Biomimetic   Tendon-Driven Hand with Rolling Contact Joints - [[Arxiv](https://arxiv.org/abs/2308.02453)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02453.md)]
- Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation   from Text - [[Arxiv](https://arxiv.org/abs/2308.02357)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02357.md)]
- FB-BEV: BEV Representation from Forward-Backward View Transformations - [[Arxiv](https://arxiv.org/abs/2308.02236)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02236.md)]
- ESRL: Efficient Sampling-based Reinforcement Learning for Sequence   Generation - [[Arxiv](https://arxiv.org/abs/2308.02223)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02223.md)]
- Scaling Clinical Trial Matching Using Large Language Models: A Case   Study in Oncology - [[Arxiv](https://arxiv.org/abs/2308.02180)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02180.md)]
- Learning Referring Video Object Segmentation from Weak Annotation - [[Arxiv](https://arxiv.org/abs/2308.02162)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02162.md)]
- Retroformer: Retrospective Large Language Agents with Policy Gradient   Optimization - [[Arxiv](https://arxiv.org/abs/2308.02151)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02151.md)]
- Multi-interactive Feature Learning and a Full-time Multi-modality   Benchmark for Image Fusion and Segmentation - [[Arxiv](https://arxiv.org/abs/2308.02097)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02097.md)]
- The All-Seeing Project: Towards Panoptic Visual Recognition and   Understanding of the Open World - [[Arxiv](https://arxiv.org/abs/2308.01907)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01907.md)]
- DETR Doesn't Need Multi-Scale or Locality Design - [[Arxiv](https://arxiv.org/abs/2308.01904)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01904.md)]
- ConceptLab: Creative Generation using Diffusion Prior Constraints - [[Arxiv](https://arxiv.org/abs/2308.02669)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02669.md)]
- ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on   Class-level Code Generation - [[Arxiv](https://arxiv.org/abs/2308.01861)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01861.md)]
- Scaling Relationship on Learning Mathematical Reasoning with Large   Language Models - [[Arxiv](https://arxiv.org/abs/2308.01825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01825.md)]
- RegionBLIP: A Unified Multi-modal Pre-training Framework for Holistic   and Regional Comprehension - [[Arxiv](https://arxiv.org/abs/2308.02299)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02299.md)]
- Point2Mask: Point-supervised Panoptic Segmentation via Optimal Transport - [[Arxiv](https://arxiv.org/abs/2308.01779)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01779.md)]
- Ambient Adventures: Teaching ChatGPT on Developing Complex Stories - [[Arxiv](https://arxiv.org/abs/2308.01734)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01734.md)]
- LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and   Semantic-Aware Alignment - [[Arxiv](https://arxiv.org/abs/2308.01686)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01686.md)]
- A Multidimensional Analysis of Social Biases in Vision Transformers - [[Arxiv](https://arxiv.org/abs/2308.01948)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01948.md)]
- InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent - [[Arxiv](https://arxiv.org/abs/2308.01552)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01552.md)]
- Get the Best of Both Worlds: Improving Accuracy and Transferability by   Grassmann Class Representation - [[Arxiv](https://arxiv.org/abs/2308.01547)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01547.md)]
- MusicLDM: Enhancing Novelty in Text-to-Music Generation Using   Beat-Synchronous Mixup Strategies - [[Arxiv](https://arxiv.org/abs/2308.01546)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01546.md)]
- Multimodal Neurons in Pretrained Text-Only Transformers - [[Arxiv](https://arxiv.org/abs/2308.01544)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01544.md)]
- TDMD: A Database for Dynamic Color Mesh Subjective and Objective Quality   Explorations - [[Arxiv](https://arxiv.org/abs/2308.01499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01499.md)]
- Target-point Attention Transformer: A novel trajectory predict network   for end-to-end autonomous driving - [[Arxiv](https://arxiv.org/abs/2308.1496)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1496.md)]
- Efficient neural supersampling on a novel gaming dataset - [[Arxiv](https://arxiv.org/abs/2308.01483)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01483.md)]
- HANDAL: A Dataset of Real-World Manipulable Object Categories with Pose   Annotations, Affordances, and Reconstructions - [[Arxiv](https://arxiv.org/abs/2308.01477)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01477.md)]
- Training Data Protection with Compositional Diffusion Models - [[Arxiv](https://arxiv.org/abs/2308.01937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01937.md)]
- VertexSerum: Poisoning Graph Neural Networks for Link Inference - [[Arxiv](https://arxiv.org/abs/2308.01469)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01469.md)]
- From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion - [[Arxiv](https://arxiv.org/abs/2308.02560)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02560.md)]
- On $Îº$-solutions and canonical neighborhoods in 4d Ricci flow - [[Arxiv](https://arxiv.org/abs/2308.1448)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1448.md)]
- OpenFlamingo: An Open-Source Framework for Training Large Autoregressive   Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2308.01390)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01390.md)]
- DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like   Models at All Scales - [[Arxiv](https://arxiv.org/abs/2308.01320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01320.md)]
- Computational Long Exposure Mobile Photography - [[Arxiv](https://arxiv.org/abs/2308.01379)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01379.md)]
- More Context, Less Distraction: Zero-shot Visual Classification by   Inferring and Conditioning on Contextual Attributes - [[Arxiv](https://arxiv.org/abs/2308.01313)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01313.md)]
- Revisiting DETR Pre-training for Object Detection - [[Arxiv](https://arxiv.org/abs/2308.01300)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01300.md)]
- XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in   Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.01263)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01263.md)]
- Hyper-pixel-wise Contrastive Learning Augmented Segmentation Network for   Old Landslide Detection through Fusing High-Resolution Remote Sensing Images   and Digital Elevation Model Data - [[Arxiv](https://arxiv.org/abs/2308.1251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1251.md)]
- Evaluating Instruction-Tuned Large Language Models on Code Comprehension   and Generation - [[Arxiv](https://arxiv.org/abs/2308.01240)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01240.md)]
- LSF-IDM: Automotive Intrusion Detection Model with Lightweight   Attribution and Semantic Fusion - [[Arxiv](https://arxiv.org/abs/2308.1237)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1237.md)]
- Grounded Image Text Matching with Mismatched Relation Reasoning - [[Arxiv](https://arxiv.org/abs/2308.01236)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01236.md)]
- Geometric wakes in collimators and step transitions of arbitrary   cross-sections: conformal mapping approach - [[Arxiv](https://arxiv.org/abs/2308.1235)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1235.md)]
- One Tree to Rule Them All: Poly-Logarithmic Universal Steiner Tree - [[Arxiv](https://arxiv.org/abs/2308.1199)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1199.md)]
- Improving Generalization in Visual Reinforcement Learning via   Conflict-aware Gradient Agreement Augmentation - [[Arxiv](https://arxiv.org/abs/2308.01194)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01194.md)]
- Towards Understanding the Capability of Large Language Models on Code   Clone Detection: A Survey - [[Arxiv](https://arxiv.org/abs/2308.01191)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01191.md)]
- Three-level Dicke quantum battery - [[Arxiv](https://arxiv.org/abs/2308.1188)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1188.md)]
- Multiobjective Optimization of Non-Smooth PDE-Constrained Problems - [[Arxiv](https://arxiv.org/abs/2308.1113)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1113.md)]
- Black hole thermodynamics in Horndeski theories - [[Arxiv](https://arxiv.org/abs/2308.1082)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1082.md)]
- MammoDG: Generalisable Deep Learning Breaks the Limits of Cross-Domain   Multi-Center Breast Cancer Screening - [[Arxiv](https://arxiv.org/abs/2308.1057)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1057.md)]
- Stability Analysis for a Class of Heterogeneous Catalysis Models - [[Arxiv](https://arxiv.org/abs/2308.1049)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1049.md)]
- Dynamic Token Pruning in Plain Vision Transformers for Semantic   Segmentation - [[Arxiv](https://arxiv.org/abs/2308.01045)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01045.md)]
- An improved infrastructure for the IceCube realtime system - [[Arxiv](https://arxiv.org/abs/2308.1031)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1031.md)]
- Model-agnostic search for the quasinormal modes of gravitational wave   echoes - [[Arxiv](https://arxiv.org/abs/2308.1017)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1017.md)]
- Enhancing Representation Learning for Periodic Time Series with Floss: A   Frequency Domain Regularization Approach - [[Arxiv](https://arxiv.org/abs/2308.1011)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.1011.md)]
- From Sparse to Soft Mixtures of Experts - [[Arxiv](https://arxiv.org/abs/2308.00951)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00951.md)]
- Cosmological Distance Measurement of 12 Nearby Supernovae IIP with   ROTSE-IIIB - [[Arxiv](https://arxiv.org/abs/2308.0916)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0916.md)]
- ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based   Image Manipulation - [[Arxiv](https://arxiv.org/abs/2308.00906)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00906.md)]
- VLUCI: Variational Learning of Unobserved Confounders for Counterfactual   Inference - [[Arxiv](https://arxiv.org/abs/2308.0904)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0904.md)]
- Weak localization in radiative transfer of acoustic waves in a   randomly-fluctuating slab - [[Arxiv](https://arxiv.org/abs/2308.0822)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0822.md)]
- Optimal design of plane elastic membranes using the convexified   FÃ¶ppl's model - [[Arxiv](https://arxiv.org/abs/2308.0811)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0811.md)]
- Body Knowledge and Uncertainty Modeling for Monocular 3D Human Body   Reconstruction - [[Arxiv](https://arxiv.org/abs/2308.00799)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00799.md)]
- LISA: Reasoning Segmentation via Large Language Model - [[Arxiv](https://arxiv.org/abs/2308.00692)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00692.md)]
- Tool Documentation Enables Zero-Shot Tool-Usage with Large Language   Models - [[Arxiv](https://arxiv.org/abs/2308.00675)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00675.md)]
- Note: Stokes-Einstein relation without hydrodynamic diameter in the   TIP4P/Ice water model - [[Arxiv](https://arxiv.org/abs/2308.0653)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0653.md)]
- ELFNet: Evidential Local-global Fusion for Stereo Matching - [[Arxiv](https://arxiv.org/abs/2308.00728)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00728.md)]
- Detecting Cloud Presence in Satellite Images Using the RGB-based CLIP   Vision-Language Model - [[Arxiv](https://arxiv.org/abs/2308.0541)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0541.md)]
- Understanding URDF: A Dataset and Analysis - [[Arxiv](https://arxiv.org/abs/2308.0514)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0514.md)]
- Stochastic Geometry Based Modeling and Analysis on Network NOMA in   Downlink CoMP Systems - [[Arxiv](https://arxiv.org/abs/2308.0499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0499.md)]
- A many-sorted epistemic logic for chromatic hypergraphs - [[Arxiv](https://arxiv.org/abs/2308.0477)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0477.md)]
- FLatten Transformer: Vision Transformer using Focused Linear Attention - [[Arxiv](https://arxiv.org/abs/2308.00442)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00442.md)]
- SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step   Reasoning - [[Arxiv](https://arxiv.org/abs/2308.00436)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00436.md)]
- DriveAdapter: Breaking the Coupling Barrier of Perception and Planning   in End-to-End Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2308.00398)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00398.md)]
- Improving Generalization of Adversarial Training via Robust Critical   Fine-Tuning - [[Arxiv](https://arxiv.org/abs/2308.02533)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02533.md)]
- Deep Image Harmonization with Learnable Augmentation - [[Arxiv](https://arxiv.org/abs/2308.00376)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00376.md)]
- Deep Image Harmonization with Globally Guided Feature Transformation and   Relation Distillation - [[Arxiv](https://arxiv.org/abs/2308.00356)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00356.md)]
- MetaGPT: Meta Programming for Multi-Agent Collaborative Framework - [[Arxiv](https://arxiv.org/abs/2308.00352)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00352.md)]
- Artifact: Measuring and Mitigating Gaps in Structural Testing - [[Arxiv](https://arxiv.org/abs/2308.0316)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0316.md)]
- Skills-in-Context Prompting: Unlocking Compositionality in Large   Language Models - [[Arxiv](https://arxiv.org/abs/2308.0304)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0304.md)]
- Skills-in-Context Prompting: Unlocking Compositionality in Large   Language Models - [[Arxiv](https://arxiv.org/abs/2308.00304)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00304.md)]
- Online Prototype Learning for Online Continual Learning - [[Arxiv](https://arxiv.org/abs/2308.00301)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00301.md)]
- CLAMS: A Cluster Ambiguity Measure for Estimating Perceptual Variability   in Visual Clustering - [[Arxiv](https://arxiv.org/abs/2308.0284)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0284.md)]
- Improving Pixel-based MIM by Reducing Wasted Modeling Capability - [[Arxiv](https://arxiv.org/abs/2308.00261)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00261.md)]
- GOALS-JWST: Gas Dynamics and Excitation in NGC7469 revealed by NIRSpec - [[Arxiv](https://arxiv.org/abs/2308.0209)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0209.md)]

### July 2023
- Predicting masked tokens in stochastic locations improves masked image   modeling - [[Arxiv](https://arxiv.org/abs/2308.00566)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00566.md)]
- Learning to Model the World with Language - [[Arxiv](https://arxiv.org/abs/2308.01399)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.01399.md)]
- Discovering Adaptable Symbolic Algorithms from Scratch - [[Arxiv](https://arxiv.org/abs/2307.16890)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16890.md)]
- Backdooring Instruction-Tuned Large Language Models with Virtual Prompt   Injection - [[Arxiv](https://arxiv.org/abs/2307.16888)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16888.md)]
- Shortcut Partitions in Minor-Free Graphs: Steiner Point Removal,   Distance Oracles, Tree Covers, and More - [[Arxiv](https://arxiv.org/abs/2308.0555)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.0555.md)]
- Revisiting the Parameter Efficiency of Adapters from the Perspective of   Precision Redundancy - [[Arxiv](https://arxiv.org/abs/2307.16867)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16867.md)]
- Random Sub-Samples Generation for Self-Supervised Real Image Denoising - [[Arxiv](https://arxiv.org/abs/2307.16825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16825.md)]
- ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world   APIs - [[Arxiv](https://arxiv.org/abs/2307.16789)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16789.md)]
- UniVTG: Towards Unified Video-Language Temporal Grounding - [[Arxiv](https://arxiv.org/abs/2307.16715)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16715.md)]
- DiffPose: SpatioTemporal Diffusion Model for Video-Based Human Pose   Estimation - [[Arxiv](https://arxiv.org/abs/2307.16687)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16687.md)]
- Guiding Image Captioning Models Toward More Specific Captions - [[Arxiv](https://arxiv.org/abs/2307.16686)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16686.md)]
- Graph Structure from Point Clouds: Geometric Attention is All You Need - [[Arxiv](https://arxiv.org/abs/2307.16662)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16662.md)]
- CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image   Classification - [[Arxiv](https://arxiv.org/abs/2307.16634)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16634.md)]
- FULLER: Unified Multi-modality Multi-task 3D Perception via Multi-level   Gradient Calibration - [[Arxiv](https://arxiv.org/abs/2307.16617)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16617.md)]
- Transferable Decoding with Visual Entities for Zero-Shot Image   Captioning - [[Arxiv](https://arxiv.org/abs/2307.16525)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16525.md)]
- Towards General Low-Light Raw Noise Synthesis and Modeling - [[Arxiv](https://arxiv.org/abs/2307.16508)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16508.md)]
- MovieChat: From Dense Token to Sparse Memory for Long Video   Understanding - [[Arxiv](https://arxiv.org/abs/2307.16449)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16449.md)]
- DRAW: Defending Camera-shooted RAW against Image Manipulation - [[Arxiv](https://arxiv.org/abs/2307.16418)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16418.md)]
- DDG-Net: Discriminability-Driven Graph Network for Weakly-supervised   Temporal Action Localization - [[Arxiv](https://arxiv.org/abs/2307.16415)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16415.md)]
- Bridging the Gap: Exploring the Capabilities of Bridge-Architectures for   Complex Visual Reasoning Tasks - [[Arxiv](https://arxiv.org/abs/2307.16395)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16395.md)]
- JOTR: 3D Joint Contrastive Learning with Transformers for Occluded Human   Mesh Recovery - [[Arxiv](https://arxiv.org/abs/2307.16377)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16377.md)]
- LP-MusicCaps: LLM-Based Pseudo Music Captioning - [[Arxiv](https://arxiv.org/abs/2307.16372)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16372.md)]
- AntGPT: Can Large Language Models Help Long-term Action Anticipation   from Videos? - [[Arxiv](https://arxiv.org/abs/2307.16368)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16368.md)]
- Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks   for Defending Adversarial Examples - [[Arxiv](https://arxiv.org/abs/2307.16361)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16361.md)]
- Evaluating ChatGPT and GPT-4 for Visual Programming - [[Arxiv](https://arxiv.org/abs/2308.02522)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02522.md)]
- Unified Model for Image, Video, Audio and Language Tasks - [[Arxiv](https://arxiv.org/abs/2307.16184)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16184.md)]
- Do LLMs Possess a Personality? Making the MBTI Test an Amazing   Evaluation for Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.16180)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16180.md)]
- SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension - [[Arxiv](https://arxiv.org/abs/2307.16125)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.16125.md)]
- Separate Scene Text Detector for Unseen Scripts is Not All You Need - [[Arxiv](https://arxiv.org/abs/2307.15991)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15991.md)]
- XMem++: Production-level Video Segmentation From Few Annotated Frames - [[Arxiv](https://arxiv.org/abs/2307.15958)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15958.md)]
- CMDA: Cross-Modality Domain Adaptation for Nighttime Semantic   Segmentation - [[Arxiv](https://arxiv.org/abs/2307.15942)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15942.md)]
- What can Discriminator do? Towards Box-free Ownership Verification of   Generative Adversarial Network - [[Arxiv](https://arxiv.org/abs/2307.15860)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15860.md)]
- RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic   Control - [[Arxiv](https://arxiv.org/abs/2307.15818)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15818.md)]
- The Hydra Effect: Emergent Self-repair in Language Model Computations - [[Arxiv](https://arxiv.org/abs/2307.15771)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15771.md)]
- MeMOTR: Long-Term Memory-Augmented Transformer for Multi-Object Tracking - [[Arxiv](https://arxiv.org/abs/2307.15700)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15700.md)]
- Scaling Data Generation in Vision-and-Language Navigation - [[Arxiv](https://arxiv.org/abs/2307.15644)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15644.md)]
- Robust Distortion-free Watermarks for Language Models - [[Arxiv](https://arxiv.org/abs/2307.15593)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15593.md)]
- Beating Backdoor Attack at Its Own Game - [[Arxiv](https://arxiv.org/abs/2307.15539)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15539.md)]
- Exploring Format Consistency for Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2307.15504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15504.md)]
- FeedbackLogs: Recording and Incorporating Stakeholder Feedback into   Machine Learning Pipelines - [[Arxiv](https://arxiv.org/abs/2307.15475)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15475.md)]
- Is One Epoch All You Need For Multi-Fidelity Hyperparameter   Optimization? - [[Arxiv](https://arxiv.org/abs/2307.15422)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15422.md)]
- Uncertainty-aware Unsupervised Multi-Object Tracking - [[Arxiv](https://arxiv.org/abs/2307.15409)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15409.md)]
- Supervised Homography Learning with Realistic Dataset Generation - [[Arxiv](https://arxiv.org/abs/2307.15353)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15353.md)]
- Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding - [[Arxiv](https://arxiv.org/abs/2307.15337)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15337.md)]
- Dynamic PlenOctree for Adaptive Sampling Refinement in Explicit NeRF - [[Arxiv](https://arxiv.org/abs/2307.15333)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15333.md)]
- TaskExpert: Dynamically Assembling Multi-Task Representations with   Memorial Mixture-of-Experts - [[Arxiv](https://arxiv.org/abs/2307.15324)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15324.md)]
- Multiple Instance Learning Framework with Masked Hard Instance Mining   for Whole Slide Image Classification - [[Arxiv](https://arxiv.org/abs/2307.15254)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15254.md)]
- Open Problems and Fundamental Limitations of Reinforcement Learning from   Human Feedback - [[Arxiv](https://arxiv.org/abs/2307.15217)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15217.md)]
- PromptStyler: Prompt-driven Style Generation for Source-free Domain   Generalization - [[Arxiv](https://arxiv.org/abs/2307.15199)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15199.md)]
- Med-Flamingo: a Multimodal Medical Few-shot Learner - [[Arxiv](https://arxiv.org/abs/2307.15189)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15189.md)]
- Seal-3D: Interactive Pixel-Level Editing for Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2307.15131)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15131.md)]
- To Adapt or Not to Adapt? Real-Time Adaptation for Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2307.15063)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15063.md)]
- Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation - [[Arxiv](https://arxiv.org/abs/2308.07931)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.07931.md)]
- Learning Depth Estimation for Transparent and Mirror Surfaces - [[Arxiv](https://arxiv.org/abs/2307.15052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15052.md)]
- Regularized Mask Tuning: Uncovering Hidden Knowledge in Pre-trained   Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2307.15049)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15049.md)]
- Universal and Transferable Adversarial Attacks on Aligned Language   Models - [[Arxiv](https://arxiv.org/abs/2307.15043)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15043.md)]
- TEDi: Temporally-Entangled Diffusion for Long-Term Motion Synthesis - [[Arxiv](https://arxiv.org/abs/2307.15042)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15042.md)]
- Diverse Inpainting and Editing with GAN Inversion - [[Arxiv](https://arxiv.org/abs/2307.15033)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15033.md)]
- SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark - [[Arxiv](https://arxiv.org/abs/2307.15020)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15020.md)]
- How Good is Google Bard's Visual Understanding? An Empirical Study on   Open Challenges - [[Arxiv](https://arxiv.org/abs/2307.15016)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15016.md)]
- Scaling TransNormer to 175 Billion Parameters - [[Arxiv](https://arxiv.org/abs/2307.14995)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14995.md)]
- S3: Social-network Simulation System with Large Language Model-Empowered   Agents - [[Arxiv](https://arxiv.org/abs/2307.14984)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14984.md)]
- Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models - [[Arxiv](https://arxiv.org/abs/2307.14971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14971.md)]
- PanGu-Coder2: Boosting Large Language Models for Code with Ranking   Feedback - [[Arxiv](https://arxiv.org/abs/2307.14936)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14936.md)]
- Seeing through the Brain: Image Reconstruction of Visual Perception from   Human Brain Signals - [[Arxiv](https://arxiv.org/abs/2308.02510)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.02510.md)]
- Towards Deeply Unified Depth-aware Panoptic Segmentation with   Bi-directional Guidance Learning - [[Arxiv](https://arxiv.org/abs/2307.14786)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14786.md)]
- Gloss-free Sign Language Translation: Improving from Visual-Language   Pretraining - [[Arxiv](https://arxiv.org/abs/2307.14768)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14768.md)]
- Test Time Adaptation for Blind Image Quality Assessment - [[Arxiv](https://arxiv.org/abs/2307.14735)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14735.md)]
- P2C: Self-Supervised Point Cloud Completion from Single Partial Clouds - [[Arxiv](https://arxiv.org/abs/2307.14726)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14726.md)]
- Pre-training Vision Transformers with Very Limited Synthesized Images - [[Arxiv](https://arxiv.org/abs/2307.14710)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14710.md)]
- Taxonomy Adaptive Cross-Domain Adaptation in Medical Imaging via   Optimization Trajectory Distillation - [[Arxiv](https://arxiv.org/abs/2307.14709)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14709.md)]
- 360VOT: A New Benchmark Dataset for Omnidirectional Visual Object   Tracking - [[Arxiv](https://arxiv.org/abs/2307.14630)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14630.md)]
- NeRF-Det: Learning Geometry-Aware Volumetric Representation for   Multi-View 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2307.14620)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14620.md)]
- TextManiA: Enriching Visual Feature by Text-driven Manifold Augmentation - [[Arxiv](https://arxiv.org/abs/2307.14611)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14611.md)]
- Clustering based Point Cloud Representation Learning for 3D Analysis - [[Arxiv](https://arxiv.org/abs/2307.14605)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14605.md)]
- Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition - [[Arxiv](https://arxiv.org/abs/2307.14535)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14535.md)]
- MiDaS v3.1 -- A Model Zoo for Robust Monocular Relative Depth Estimation - [[Arxiv](https://arxiv.org/abs/2307.14460)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14460.md)]
- Three Bricks to Consolidate Watermarks for Large Language Models - [[Arxiv](https://arxiv.org/abs/2308.00113)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2308.00113.md)]
- MAMo: Leveraging Memory and Attention for Monocular Video Depth   Estimation - [[Arxiv](https://arxiv.org/abs/2307.14336)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14336.md)]
- WavJourney: Compositional Audio Creation with Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.14335)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14335.md)]
- Towards Generalist Biomedical AI - [[Arxiv](https://arxiv.org/abs/2307.14334)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14334.md)]
- G2L: Semantically Aligned and Uniform Video Grounding via Geodesic and   Game Theory - [[Arxiv](https://arxiv.org/abs/2307.14277)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14277.md)]
- Large Language Models are Competitive Near Cold-start Recommenders for   Language- and Item-based Preferences - [[Arxiv](https://arxiv.org/abs/2307.14225)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14225.md)]
- ADAPT: Efficient Multi-Agent Trajectory Prediction with Adaptation - [[Arxiv](https://arxiv.org/abs/2307.14187)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14187.md)]
- Creative Birds: Self-Supervised Single-View 3D Style Transfer - [[Arxiv](https://arxiv.org/abs/2307.14127)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14127.md)]
- Leveraging Implicit Feedback from Deployment Data in Dialogue - [[Arxiv](https://arxiv.org/abs/2307.14117)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14117.md)]
- Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo   Matching - [[Arxiv](https://arxiv.org/abs/2307.14071)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14071.md)]
- Set-level Guidance Attack: Boosting Adversarial Transferability of   Vision-Language Pre-training Models - [[Arxiv](https://arxiv.org/abs/2307.14061)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14061.md)]
- 3D Semantic Subspace Traverser: Empowering 3D Generative Model with   Shape Editing Capability - [[Arxiv](https://arxiv.org/abs/2307.14051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14051.md)]
- Controllable Guide-Space for Generalizable Face Forgery Detection - [[Arxiv](https://arxiv.org/abs/2307.14039)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14039.md)]
- Adaptive Frequency Filters As Efficient Global Token Mixers - [[Arxiv](https://arxiv.org/abs/2307.14008)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14008.md)]
- Tracking Anything in High Quality - [[Arxiv](https://arxiv.org/abs/2307.13974)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13974.md)]
- AIDE: A Vision-Driven Multi-View, Multi-Modal, Multi-Tasking Dataset for   Assistive Driving Perception - [[Arxiv](https://arxiv.org/abs/2307.13933)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13933.md)]
- Spatio-Temporal Domain Awareness for Multi-Agent Collaborative   Perception - [[Arxiv](https://arxiv.org/abs/2307.13929)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13929.md)]
- trajdata: A Unified Interface to Multiple Human Trajectory Datasets - [[Arxiv](https://arxiv.org/abs/2307.13924)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13924.md)]
- Points-to-3D: Bridging the Gap between Sparse Points and   Shape-Controllable Text-to-3D Generation - [[Arxiv](https://arxiv.org/abs/2307.13908)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13908.md)]
- WebArena: A Realistic Web Environment for Building Autonomous Agents - [[Arxiv](https://arxiv.org/abs/2307.13854)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13854.md)]
- How to Scale Your EMA - [[Arxiv](https://arxiv.org/abs/2307.13813)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13813.md)]
- E^2VPT: An Effective and Efficient Approach for Visual Prompt Tuning - [[Arxiv](https://arxiv.org/abs/2307.13770)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13770.md)]
- PlaneRecTR: Unified Query Learning for 3D Plane Recovery from a Single   View - [[Arxiv](https://arxiv.org/abs/2307.13756)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13756.md)]
- Foundational Models Defining a New Era in Vision: A Survey and Outlook - [[Arxiv](https://arxiv.org/abs/2307.13721)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13721.md)]
- Composite Diffusion | whole &gt;= Î£parts - [[Arxiv](https://arxiv.org/abs/2307.13720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13720.md)]
- ARB: Advanced Reasoning Benchmark for Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.13692)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13692.md)]
- RecursiveDet: End-to-End Region-based Recursive Object Detection - [[Arxiv](https://arxiv.org/abs/2307.13619)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13619.md)]
- Model Calibration in Dense Classification with Adaptive Label   Perturbation - [[Arxiv](https://arxiv.org/abs/2307.13539)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13539.md)]
- Spectrum-guided Multi-granularity Referring Video Object Segmentation - [[Arxiv](https://arxiv.org/abs/2307.13537)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13537.md)]
- Re-mine, Learn and Reason: Exploring the Cross-modal Semantic   Correlations for Language-guided HOI detection - [[Arxiv](https://arxiv.org/abs/2307.13529)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13529.md)]
- FacTool: Factuality Detection in Generative AI -- A Tool Augmented   Framework for Multi-Task and Multi-Domain Scenarios - [[Arxiv](https://arxiv.org/abs/2307.13528)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13528.md)]
- Weakly-supervised 3D Pose Transfer with Keypoints - [[Arxiv](https://arxiv.org/abs/2307.13459)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13459.md)]
- Predicting Code Coverage without Execution - [[Arxiv](https://arxiv.org/abs/2307.13383)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13383.md)]
- Unmasking Anomalies in Road-Scene Segmentation - [[Arxiv](https://arxiv.org/abs/2307.13316)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13316.md)]
- LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA   Composition - [[Arxiv](https://arxiv.org/abs/2307.13269)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13269.md)]
- Conditional Cross Attention Network for Multi-Space Embedding without   Entanglement in Only a SINGLE Network - [[Arxiv](https://arxiv.org/abs/2307.13254)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13254.md)]
- GaPro: Box-Supervised 3D Point Cloud Instance Segmentation Using   Gaussian Processes as Pseudo Labelers - [[Arxiv](https://arxiv.org/abs/2307.13251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13251.md)]
- Strivec: Sparse Tri-Vector Radiance Fields - [[Arxiv](https://arxiv.org/abs/2307.13226)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13226.md)]
- GraspGPT: Leveraging Semantic Knowledge from a Large Language Model for   Task-Oriented Grasping - [[Arxiv](https://arxiv.org/abs/2307.13204)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13204.md)]
- Contrastive Example-Based Control - [[Arxiv](https://arxiv.org/abs/2307.13101)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13101.md)]
- LLM-Rec: Personalized Recommendation via Prompting Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.15780)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.15780.md)]
- 3D-LLM: Injecting the 3D World into Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.12981)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12981.md)]
- A Systematic Survey of Prompt Engineering on Vision-Language Foundation   Models - [[Arxiv](https://arxiv.org/abs/2307.12980)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12980.md)]
- Evaluating the Ripple Effects of Knowledge Editing in Language Models - [[Arxiv](https://arxiv.org/abs/2307.12976)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12976.md)]
- DFA3D: 3D Deformable Attention For 2D-to-3D Feature Lifting - [[Arxiv](https://arxiv.org/abs/2307.12972)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12972.md)]
- Aligning Large Language Models with Human: A Survey - [[Arxiv](https://arxiv.org/abs/2307.12966)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12966.md)]
- RLCD: Reinforcement Learning from Contrast Distillation for Language   Model Alignment - [[Arxiv](https://arxiv.org/abs/2307.12950)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12950.md)]
- GridMM: Grid Memory Map for Vision-and-Language Navigation - [[Arxiv](https://arxiv.org/abs/2307.12907)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12907.md)]
- A Real-World WebAgent with Planning, Long Context Understanding, and   Program Synthesis - [[Arxiv](https://arxiv.org/abs/2307.12856)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12856.md)]
- Multiscale Video Pretraining for Long-Term Activity Forecasting - [[Arxiv](https://arxiv.org/abs/2307.12854)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12854.md)]
- Fast Full-frame Video Stabilization with Iterative Optimization - [[Arxiv](https://arxiv.org/abs/2307.12774)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12774.md)]
- COCO-O: A Benchmark for Object Detectors under Natural Distribution   Shifts - [[Arxiv](https://arxiv.org/abs/2307.12730)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12730.md)]
- Persistent-Transient Duality: A Multi-mechanism Approach for Modeling   Human-Object Interaction - [[Arxiv](https://arxiv.org/abs/2307.12729)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12729.md)]
- MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised   Learning of Motion and Content Features - [[Arxiv](https://arxiv.org/abs/2307.12698)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12698.md)]
- PG-RCNN: Semantic Surface Point Generation for 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2307.12637)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12637.md)]
- CTVIS: Consistent Training for Online Video Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2307.12616)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12616.md)]
- Less is More: Focus Attention for Efficient DETR - [[Arxiv](https://arxiv.org/abs/2307.12612)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12612.md)]
- PRIOR: Prototype Representation Joint Learning from Medical Images and   Reports - [[Arxiv](https://arxiv.org/abs/2307.12577)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12577.md)]
- A Good Student is Cooperative and Reliable: CNN-Transformer   Collaborative Learning for Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2307.12574)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12574.md)]
- Interpolating between Images with Diffusion Models - [[Arxiv](https://arxiv.org/abs/2307.12560)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12560.md)]
- PUMA: Secure Inference of LLaMA-7B in Five Minutes - [[Arxiv](https://arxiv.org/abs/2307.12533)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12533.md)]
- Cross Contrasting Feature Perturbation for Domain Generalization - [[Arxiv](https://arxiv.org/abs/2307.12502)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12502.md)]
- TF-ICON: Diffusion-Based Training-Free Cross-Domain Image Composition - [[Arxiv](https://arxiv.org/abs/2307.12493)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12493.md)]
- Rethinking Data Distillation: Do Not Overlook Calibration - [[Arxiv](https://arxiv.org/abs/2307.12463)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12463.md)]
- ProtoFL: Unsupervised Federated Learning via Prototypical Distillation - [[Arxiv](https://arxiv.org/abs/2307.12450)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12450.md)]
- Augmented Box Replay: Overcoming Foreground Shift for Incremental Object   Detection - [[Arxiv](https://arxiv.org/abs/2307.12427)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12427.md)]
- Testing Hateful Speeches against Policies - [[Arxiv](https://arxiv.org/abs/2307.12418)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12418.md)]
- Learning Navigational Visual Representations with Semantic Map   Supervision - [[Arxiv](https://arxiv.org/abs/2307.12335)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12335.md)]
- TransHuman: A Transformer-based Human Representation for Generalizable   Neural Human Rendering - [[Arxiv](https://arxiv.org/abs/2307.12291)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12291.md)]
- Downstream-agnostic Adversarial Examples - [[Arxiv](https://arxiv.org/abs/2307.12280)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12280.md)]
- Geometry-Aware Adaptation for Pretrained Models - [[Arxiv](https://arxiv.org/abs/2307.12226)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12226.md)]
- LoLep: Single-View View Synthesis with Locally-Learned Planes and   Self-Attention Occlusion Inference - [[Arxiv](https://arxiv.org/abs/2307.12217)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12217.md)]
- LIST: Learning Implicitly from Spatial Transformers for Single-View 3D   Reconstruction - [[Arxiv](https://arxiv.org/abs/2307.12194)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12194.md)]
- Optimized Network Architectures for Large Language Model Training with   Billions of Parameters - [[Arxiv](https://arxiv.org/abs/2307.12169)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12169.md)]
- Hallucination Improves the Performance of Unsupervised Visual   Representation Learning - [[Arxiv](https://arxiv.org/abs/2307.12168)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12168.md)]
- DIP-RL: Demonstration-Inferred Preference Learning in Minecraft - [[Arxiv](https://arxiv.org/abs/2307.12158)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12158.md)]
- Spatial Self-Distillation for Object Detection with Inaccurate Bounding   Boxes - [[Arxiv](https://arxiv.org/abs/2307.12101)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12101.md)]
- Discovering Spatio-Temporal Rationales for Video Question Answering - [[Arxiv](https://arxiv.org/abs/2307.12058)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12058.md)]
- On the Effectiveness of Spectral Discriminators for Perceptual Quality   Improvement - [[Arxiv](https://arxiv.org/abs/2307.12027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.12027.md)]
- Learning Vision-and-Language Navigation from YouTube Videos - [[Arxiv](https://arxiv.org/abs/2307.11984)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11984.md)]
- Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels? - [[Arxiv](https://arxiv.org/abs/2307.11978)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11978.md)]
- CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction   Execution for Robots - [[Arxiv](https://arxiv.org/abs/2307.11865)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11865.md)]
- HybridAugment++: Unified Frequency Spectra Perturbations for Model   Robustness - [[Arxiv](https://arxiv.org/abs/2307.11823)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11823.md)]
- Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts - [[Arxiv](https://arxiv.org/abs/2307.11661)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11661.md)]
- OxfordTVG-HIC: Can Machine Make Humorous Captions from Images? - [[Arxiv](https://arxiv.org/abs/2307.11636)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11636.md)]
- Bridging Vision and Language Encoders: Parameter-Efficient Tuning for   Referring Image Segmentation - [[Arxiv](https://arxiv.org/abs/2307.11545)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11545.md)]
- CopyRNeRF: Protecting the CopyRight of Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2307.11526)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11526.md)]
- CORE: Cooperative Reconstruction for Multi-Agent Perception - [[Arxiv](https://arxiv.org/abs/2307.11514)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11514.md)]
- SA-BEV: Generating Semantic-Aware Bird's-Eye-View Feature for Multi-view   3D Object Detection - [[Arxiv](https://arxiv.org/abs/2307.11477)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11477.md)]
- Distribution Shift Matters for Knowledge Distillation with Webly   Collected Images - [[Arxiv](https://arxiv.org/abs/2307.11469)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11469.md)]
- Strip-MLP: Efficient Token Interaction for Vision MLP - [[Arxiv](https://arxiv.org/abs/2307.11458)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11458.md)]
- Prompting Large Language Models with Speech Recognition Abilities - [[Arxiv](https://arxiv.org/abs/2307.11795)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11795.md)]
- FaceCLIPNeRF: Text-driven 3D Face Manipulation using Deformable Neural   Radiance Fields - [[Arxiv](https://arxiv.org/abs/2307.11418)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11418.md)]
- Deep Directly-Trained Spiking Neural Networks for Object Detection - [[Arxiv](https://arxiv.org/abs/2307.11411)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11411.md)]
- Subject-Diffusion:Open Domain Personalized Text-to-Image Generation   without Test-time Fine-tuning - [[Arxiv](https://arxiv.org/abs/2307.11410)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11410.md)]
- Latent-OFER: Detect, Mask, and Reconstruct with Latent Vectors for   Occluded Facial Expression Recognition - [[Arxiv](https://arxiv.org/abs/2307.11404)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11404.md)]
- CLR: Channel-wise Lightweight Reprogramming for Continual Learning - [[Arxiv](https://arxiv.org/abs/2307.11386)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11386.md)]
- What can a Single Attention Layer Learn? A Study Through the Random   Features Lens - [[Arxiv](https://arxiv.org/abs/2307.11353)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11353.md)]
- Tuning Pre-trained Model via Moment Probing - [[Arxiv](https://arxiv.org/abs/2307.11342)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11342.md)]
- Tri-MipRF: Tri-Mip Representation for Efficient Anti-Aliasing Neural   Radiance Fields - [[Arxiv](https://arxiv.org/abs/2307.11335)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11335.md)]
- DPM-OT: A New Diffusion Probabilistic Model Based on Optimal Transport - [[Arxiv](https://arxiv.org/abs/2307.11308)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11308.md)]
- PourIt!: Weakly-supervised Liquid Perception from a Single Image for   Visual Closed-Loop Robotic Pouring - [[Arxiv](https://arxiv.org/abs/2307.11299)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11299.md)]
- MAS: Towards Resource-Efficient Federated Multiple-Task Learning - [[Arxiv](https://arxiv.org/abs/2307.11285)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11285.md)]
- Brain2Music: Reconstructing Music from Human Brain Activity - [[Arxiv](https://arxiv.org/abs/2307.11078)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11078.md)]
- AlignDet: Aligning Pre-training and Fine-tuning in Object Detection - [[Arxiv](https://arxiv.org/abs/2307.11077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11077.md)]
- Cascade-DETR: Delving into High-Quality Universal Object Detection - [[Arxiv](https://arxiv.org/abs/2307.11035)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11035.md)]
- General Image-to-Image Translation with One-Shot Image Guidance - [[Arxiv](https://arxiv.org/abs/2307.14352)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.14352.md)]
- Metric3D: Towards Zero-shot Metric 3D Prediction from A Single Image - [[Arxiv](https://arxiv.org/abs/2307.10984)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10984.md)]
- Improving Online Lane Graph Extraction by Object-Lane Clustering - [[Arxiv](https://arxiv.org/abs/2307.10947)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10947.md)]
- Proxy Anchor-based Unsupervised Learning for Continuous Generalized   Category Discovery - [[Arxiv](https://arxiv.org/abs/2307.10943)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10943.md)]
- PASTA: Pretrained Action-State Transformer Agents - [[Arxiv](https://arxiv.org/abs/2307.10936)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10936.md)]
- FLASK: Fine-grained Language Model Evaluation based on Alignment Skill   Sets - [[Arxiv](https://arxiv.org/abs/2307.10928)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10928.md)]
- Diffusion Sampling with Momentum for Mitigating Divergence Artifacts - [[Arxiv](https://arxiv.org/abs/2307.11118)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11118.md)]
- The Role of Entropy and Reconstruction in Multi-View Self-Supervised   Learning - [[Arxiv](https://arxiv.org/abs/2307.10907)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10907.md)]
- BlendFace: Re-designing Identity Encoders for Face-Swapping - [[Arxiv](https://arxiv.org/abs/2307.10854)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10854.md)]
- BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained   Diffusion - [[Arxiv](https://arxiv.org/abs/2307.10816)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10816.md)]
- Meta-Transformer: A Unified Framework for Multimodal Learning - [[Arxiv](https://arxiv.org/abs/2307.10802)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10802.md)]
- HyperReenact: One-Shot Reenactment via Jointly Learning to Refine and   Retarget Faces - [[Arxiv](https://arxiv.org/abs/2307.10797)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10797.md)]
- See More and Know More: Zero-shot Point Cloud Segmentation via   Multi-modal Visual Data - [[Arxiv](https://arxiv.org/abs/2307.10782)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10782.md)]
- Urban Radiance Field Representation with Deformable Neural Mesh   Primitives - [[Arxiv](https://arxiv.org/abs/2307.10776)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10776.md)]
- Kick Back &amp; Relax: Learning to Reconstruct the World by Watching SlowTV - [[Arxiv](https://arxiv.org/abs/2307.10713)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10713.md)]
- Lighting up NeRF via Unsupervised Decomposition and Enhancement - [[Arxiv](https://arxiv.org/abs/2307.10664)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10664.md)]
- SciBench: Evaluating College-Level Scientific Problem-Solving Abilities   of Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.10635)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10635.md)]
- Physics-Driven Turbulence Image Restoration with Stochastic Refinement - [[Arxiv](https://arxiv.org/abs/2307.10603)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10603.md)]
- Flatness-Aware Minimization for Domain Generalization - [[Arxiv](https://arxiv.org/abs/2307.11108)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11108.md)]
- Instruction-following Evaluation through Verbalizer Manipulation - [[Arxiv](https://arxiv.org/abs/2307.10558)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10558.md)]
- EMQ: Evolving Training-free Proxies for Automated Mixed Precision   Quantization - [[Arxiv](https://arxiv.org/abs/2307.10554)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10554.md)]
- TokenFlow: Consistent Diffusion Features for Consistent Video Editing - [[Arxiv](https://arxiv.org/abs/2307.10373)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10373.md)]
- DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity   Human-centric Rendering - [[Arxiv](https://arxiv.org/abs/2307.10173)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10173.md)]
- DialogStudio: Towards Richest and Most Diverse Unified Dataset   Collection for Conversational AI - [[Arxiv](https://arxiv.org/abs/2307.10172)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10172.md)]
- Challenges and Applications of Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.10169)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10169.md)]
- LLMs as Workers in Human-Computational Algorithms? Replicating   Crowdsourcing Pipelines with LLMs - [[Arxiv](https://arxiv.org/abs/2307.10168)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10168.md)]
- Improving Multimodal Datasets with Image Captioning - [[Arxiv](https://arxiv.org/abs/2307.10350)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10350.md)]
- FABRIC: Personalizing Diffusion Models with Iterative Feedback - [[Arxiv](https://arxiv.org/abs/2307.10159)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10159.md)]
- Android in the Wild: A Large-Scale Dataset for Android Device Control - [[Arxiv](https://arxiv.org/abs/2307.10088)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10088.md)]
- Unsupervised Accuracy Estimation of Deep Visual Models using   Domain-Adaptive Adversarial Perturbation without Source Samples - [[Arxiv](https://arxiv.org/abs/2307.10062)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10062.md)]
- MODA: Mapping-Once Audio-driven Portrait Animation with Dual Attentions - [[Arxiv](https://arxiv.org/abs/2307.10008)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10008.md)]
- Hierarchical Spatio-Temporal Representation Learning for Gait   Recognition - [[Arxiv](https://arxiv.org/abs/2307.09856)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09856.md)]
- What do neural networks learn in image classification? A frequency   shortcut perspective - [[Arxiv](https://arxiv.org/abs/2307.09829)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09829.md)]
- Density-invariant Features for Distant Point Cloud Registration - [[Arxiv](https://arxiv.org/abs/2307.09788)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09788.md)]
- Text2Layer: Layered Image Generation using Latent Diffusion Model - [[Arxiv](https://arxiv.org/abs/2307.09781)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09781.md)]
- Towards Building More Robust Models with Frequency Bias - [[Arxiv](https://arxiv.org/abs/2307.09763)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09763.md)]
- Generative Prompt Model for Weakly Supervised Object Localization - [[Arxiv](https://arxiv.org/abs/2307.09756)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09756.md)]
- Space Engage: Collaborative Space Supervision for Contrastive-based   Semi-Supervised Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2307.09755)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09755.md)]
- CPCM: Contextual Point Cloud Modeling for Weakly-supervised Point Cloud   Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2307.10316)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10316.md)]
- AesPA-Net: Aesthetic Pattern-Aware Style Transfer Networks - [[Arxiv](https://arxiv.org/abs/2307.09724)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09724.md)]
- Towards Saner Deep Image Registration - [[Arxiv](https://arxiv.org/abs/2307.09696)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09696.md)]
- GlobalMapper: Arbitrary-Shaped Urban Layout Generation - [[Arxiv](https://arxiv.org/abs/2307.09693)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09693.md)]
- Towards A Unified Agent with Foundation Models - [[Arxiv](https://arxiv.org/abs/2307.09668)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09668.md)]
- Object-aware Gaze Target Detection - [[Arxiv](https://arxiv.org/abs/2307.09662)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09662.md)]
- Promoting Exploration in Memory-Augmented Adam using Critical Momenta - [[Arxiv](https://arxiv.org/abs/2307.09638)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09638.md)]
- Conditional 360-degree Image Synthesis for Immersive Indoor Scene   Decoration - [[Arxiv](https://arxiv.org/abs/2307.09621)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09621.md)]
- ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring   Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2307.09474)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09474.md)]
- Does Circuit Analysis Interpretability Scale? Evidence from Multiple   Choice Capabilities in Chinchilla - [[Arxiv](https://arxiv.org/abs/2307.09458)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09458.md)]
- OnlineRefer: A Simple Online Baseline for Referring Video Object   Segmentation - [[Arxiv](https://arxiv.org/abs/2307.09356)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09356.md)]
- Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking   Portrait Synthesis - [[Arxiv](https://arxiv.org/abs/2307.09323)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09323.md)]
- Biomaker CA: a Biome Maker project using Cellular Automata - [[Arxiv](https://arxiv.org/abs/2307.09320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09320.md)]
- EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory   Forecasting - [[Arxiv](https://arxiv.org/abs/2307.09306)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09306.md)]
- Llama 2: Open Foundation and Fine-Tuned Chat Models - [[Arxiv](https://arxiv.org/abs/2307.09288)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09288.md)]
- Distilling Coarse-to-Fine Semantic Matching Knowledge for Weakly   Supervised 3D Visual Grounding - [[Arxiv](https://arxiv.org/abs/2307.09267)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09267.md)]
- Augmenting CLIP with Improved Visio-Linguistic Reasoning - [[Arxiv](https://arxiv.org/abs/2307.09233)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09233.md)]
- NU-MCC: Multiview Compressive Coding with Neighborhood Decoder and   Repulsive UDF - [[Arxiv](https://arxiv.org/abs/2307.09112)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09112.md)]
- LA-Net: Landmark-Aware Learning for Reliable Facial Expression   Recognition under Label Noise - [[Arxiv](https://arxiv.org/abs/2307.09023)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09023.md)]
- How is ChatGPT's behavior changing over time? - [[Arxiv](https://arxiv.org/abs/2307.09009)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09009.md)]
- Ord2Seq: Regarding Ordinal Regression as Label Sequence Prediction - [[Arxiv](https://arxiv.org/abs/2307.09004)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.09004.md)]
- Towards Authentic Face Restoration with Iterative Diffusion Models and   Beyond - [[Arxiv](https://arxiv.org/abs/2307.08996)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08996.md)]
- Local or Global: Selective Knowledge Assimilation for Federated Learning   with Limited Labels - [[Arxiv](https://arxiv.org/abs/2307.08809)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08809.md)]
- Similarity Min-Max: Zero-Shot Day-Night Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2307.08779)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08779.md)]
- GEAR: Augmenting Language Models with Generalizable and Efficient Tool   Resolution - [[Arxiv](https://arxiv.org/abs/2307.08775)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08775.md)]
- Diffusion Models Beat GANs on Image Classification - [[Arxiv](https://arxiv.org/abs/2307.08702)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08702.md)]
- AlpaGasus: Training A Better Alpaca with Fewer Data - [[Arxiv](https://arxiv.org/abs/2307.08701)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08701.md)]
- Neural Video Depth Stabilizer - [[Arxiv](https://arxiv.org/abs/2307.08695)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08695.md)]
- TableGPT: Towards Unifying Tables, Nature Language and Commands into One   GPT - [[Arxiv](https://arxiv.org/abs/2307.08674)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08674.md)]
- Retentive Network: A Successor to Transformer for Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.08621)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08621.md)]
- BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs - [[Arxiv](https://arxiv.org/abs/2307.08581)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08581.md)]
- Scale-Aware Modulation Meet Transformer - [[Arxiv](https://arxiv.org/abs/2307.08579)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08579.md)]
- Does Visual Pretraining Help End-to-End Reasoning? - [[Arxiv](https://arxiv.org/abs/2307.08506)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08506.md)]
- BUS:Efficient and Effective Vision-language Pre-training with Bottom-Up   Patch Summarization - [[Arxiv](https://arxiv.org/abs/2307.08504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08504.md)]
- Cumulative Spatial Knowledge Distillation for Vision Transformers - [[Arxiv](https://arxiv.org/abs/2307.08500)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08500.md)]
- Differentiable Transportation Pruning - [[Arxiv](https://arxiv.org/abs/2307.08483)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08483.md)]
- SkeletonMAE: Graph-based Masked Autoencoder for Skeleton Sequence   Pre-training - [[Arxiv](https://arxiv.org/abs/2307.08476)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08476.md)]
- Not All Steps are Created Equal: Selective Diffusion Distillation for   Image Manipulation - [[Arxiv](https://arxiv.org/abs/2307.08448)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08448.md)]
- DOT: A Distillation-Oriented Trainer - [[Arxiv](https://arxiv.org/abs/2307.08436)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08436.md)]
- On the application of Large Language Models for language teaching and   assessment technology - [[Arxiv](https://arxiv.org/abs/2307.08393)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08393.md)]
- Dynamic Snake Convolution based on Topological Geometric Constraints for   Tubular Structure Segmentation - [[Arxiv](https://arxiv.org/abs/2307.08388)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08388.md)]
- Self-supervised Monocular Depth Estimation: Let's Talk About The Weather - [[Arxiv](https://arxiv.org/abs/2307.08357)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08357.md)]
- ShiftNAS: Improving One-shot NAS via Probability Shift - [[Arxiv](https://arxiv.org/abs/2307.08300)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08300.md)]
- Random Boxes Are Open-world Object Detectors - [[Arxiv](https://arxiv.org/abs/2307.08249)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08249.md)]
- Towards Self-Assembling Artificial Neural Networks through Neural   Developmental Programs - [[Arxiv](https://arxiv.org/abs/2307.08197)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08197.md)]
- Measuring Faithfulness in Chain-of-Thought Reasoning - [[Arxiv](https://arxiv.org/abs/2307.13702)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.13702.md)]
- Question Decomposition Improves the Faithfulness of Model-Generated   Reasoning - [[Arxiv](https://arxiv.org/abs/2307.11768)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11768.md)]
- Feedback is All You Need: Real-World Reinforcement Learning with   Approximate Physics-Based Models - [[Arxiv](https://arxiv.org/abs/2307.08168)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08168.md)]
- Planting a SEED of Vision in Large Language Model - [[Arxiv](https://arxiv.org/abs/2307.08041)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08041.md)]
- Multi-Object Discovery by Low-Dimensional Object Motion - [[Arxiv](https://arxiv.org/abs/2307.08027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08027.md)]
- Householder Projector for Unsupervised Latent Semantics Discovery - [[Arxiv](https://arxiv.org/abs/2307.08012)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.08012.md)]
- Towards Viewpoint-Invariant Visual Recognition via Adversarial Training - [[Arxiv](https://arxiv.org/abs/2307.10235)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.10235.md)]
- Language Conditioned Traffic Generation - [[Arxiv](https://arxiv.org/abs/2307.07947)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07947.md)]
- Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and   Class-balanced Pseudo-Labeling - [[Arxiv](https://arxiv.org/abs/2307.07944)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07944.md)]
- CVSformer: Cross-View Synthesis Transformer for Semantic Scene   Completion - [[Arxiv](https://arxiv.org/abs/2307.07938)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07938.md)]
- Communicative Agents for Software Development - [[Arxiv](https://arxiv.org/abs/2307.07924)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07924.md)]
- Is Imitation All You Need? Generalized Decision-Making with Dual-Phase   Training - [[Arxiv](https://arxiv.org/abs/2307.07909)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07909.md)]
- Handwritten and Printed Text Segmentation: A Signature Case Study - [[Arxiv](https://arxiv.org/abs/2307.07887)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07887.md)]
- Unified Adversarial Patch for Cross-modal Attacks in the Physical World - [[Arxiv](https://arxiv.org/abs/2307.07859)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07859.md)]
- Adaptive Nonlinear Latent Transformation for Conditional Face Editing - [[Arxiv](https://arxiv.org/abs/2307.07790)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07790.md)]
- Bidirectionally Deformable Motion Modulation For Video-based Human Pose   Transfer - [[Arxiv](https://arxiv.org/abs/2307.07754)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07754.md)]
- INVE: Interactive Neural Video Editing - [[Arxiv](https://arxiv.org/abs/2307.07663)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07663.md)]
- RFLA: A Stealthy Reflected Light Adversarial Attack in the Physical   World - [[Arxiv](https://arxiv.org/abs/2307.07653)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07653.md)]
- CoTracker: It is Better to Track Together - [[Arxiv](https://arxiv.org/abs/2307.07635)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07635.md)]
- NIFTY: Neural Object Interaction Fields for Guided Human Motion   Synthesis - [[Arxiv](https://arxiv.org/abs/2307.07511)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07511.md)]
- DreamTeacher: Pretraining Image Backbones with Deep Generative Models - [[Arxiv](https://arxiv.org/abs/2307.07487)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07487.md)]
- Multimodal Distillation for Egocentric Action Recognition - [[Arxiv](https://arxiv.org/abs/2307.07483)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07483.md)]
- Improving Zero-Shot Generalization for CLIP with Synthesized Prompts - [[Arxiv](https://arxiv.org/abs/2307.07397)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07397.md)]
- Mitigating Adversarial Vulnerability through Causal Parameter Estimation   by Adversarial Double Machine Learning - [[Arxiv](https://arxiv.org/abs/2307.07250)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07250.md)]
- FreeCOS: Self-Supervised Learning from Fractals and Unlabeled Images for   Curvilinear Object Segmentation - [[Arxiv](https://arxiv.org/abs/2307.07245)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07245.md)]
- Mega-TTS 2: Zero-Shot Text-to-Speech with Arbitrary Length Speech   Prompts - [[Arxiv](https://arxiv.org/abs/2307.07218)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07218.md)]
- Multimodal Motion Conditioned Diffusion Model for Skeleton-based Video   Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2307.07205)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07205.md)]
- Learning to Retrieve In-Context Examples for Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.07164)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07164.md)]
- Large Language Models Understand and Can be Enhanced by Emotional   Stimuli - [[Arxiv](https://arxiv.org/abs/2307.11760)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.11760.md)]
- Bootstrapping Vision-Language Learning with Decoupled Language   Pre-training - [[Arxiv](https://arxiv.org/abs/2307.07063)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07063.md)]
- DIALGEN: Collaborative Human-LM Generated Dialogues for Improved   Understanding of Human-Human Conversations - [[Arxiv](https://arxiv.org/abs/2307.07047)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.07047.md)]
- HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image   Models - [[Arxiv](https://arxiv.org/abs/2307.06949)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06949.md)]
- In-context Autoencoder for Context Compression in a Large Language Model - [[Arxiv](https://arxiv.org/abs/2307.06945)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06945.md)]
- InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding   and Generation - [[Arxiv](https://arxiv.org/abs/2307.06942)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06942.md)]
- Animate-A-Story: Storytelling with Retrieval-Augmented Video Generation - [[Arxiv](https://arxiv.org/abs/2307.06940)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06940.md)]
- mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs - [[Arxiv](https://arxiv.org/abs/2307.06930)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06930.md)]
- Domain-Agnostic Tuning-Encoder for Fast Personalization of Text-To-Image   Models - [[Arxiv](https://arxiv.org/abs/2307.06925)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06925.md)]
- Generating Benchmarks for Factuality Evaluation of Language Models - [[Arxiv](https://arxiv.org/abs/2307.06908)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06908.md)]
- Copy Is All You Need - [[Arxiv](https://arxiv.org/abs/2307.06962)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06962.md)]
- Assessing the Ability of ChatGPT to Screen Articles for Systematic   Reviews - [[Arxiv](https://arxiv.org/abs/2307.06464)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06464.md)]
- Distilling Large Language Models for Biomedical Knowledge Extraction: A   Case Study on Adverse Drug Events - [[Arxiv](https://arxiv.org/abs/2307.06439)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06439.md)]
- T2I-CompBench: A Comprehensive Benchmark for Open-world Compositional   Text-to-image Generation - [[Arxiv](https://arxiv.org/abs/2307.06350)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06350.md)]
- Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and   Resolution - [[Arxiv](https://arxiv.org/abs/2307.06304)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06304.md)]
- Instruction Mining: High-Quality Instruction Data Selection for Large   Language Models - [[Arxiv](https://arxiv.org/abs/2307.06290)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06290.md)]
- MMBench: Is Your Multi-modal Model an All-around Player? - [[Arxiv](https://arxiv.org/abs/2307.06281)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06281.md)]
- SayPlan: Grounding Large Language Models using 3D Scene Graphs for   Scalable Robot Task Planning - [[Arxiv](https://arxiv.org/abs/2307.06135)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06135.md)]
- VELMA: Verbalization Embodiment of LLM Agents for Vision and Language   Navigation in Street View - [[Arxiv](https://arxiv.org/abs/2307.06082)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06082.md)]
- PolyLM: An Open Source Polyglot Large Language Model - [[Arxiv](https://arxiv.org/abs/2307.06018)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06018.md)]
- VoxPoser: Composable 3D Value Maps for Robotic Manipulation with   Language Models - [[Arxiv](https://arxiv.org/abs/2307.05973)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05973.md)]
- Giving Robots a Hand: Learning Generalizable Manipulation with   Eye-in-Hand Human Video Demonstrations - [[Arxiv](https://arxiv.org/abs/2307.05959)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05959.md)]
- GLA-GCN: Global-local Adaptive Graph Convolutional Network for 3D Human   Pose Estimation from Monocular Video - [[Arxiv](https://arxiv.org/abs/2307.05853)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05853.md)]
- Towards Robust and Efficient Continual Language Learning - [[Arxiv](https://arxiv.org/abs/2307.05741)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05741.md)]
- Stack More Layers Differently: High-Rank Training Through Low-Rank   Updates - [[Arxiv](https://arxiv.org/abs/2307.05695)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05695.md)]
- Differentiable Blocks World: Qualitative 3D Decomposition by Rendering   Primitives - [[Arxiv](https://arxiv.org/abs/2307.05473)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05473.md)]
- Self-consistency for open-ended generations - [[Arxiv](https://arxiv.org/abs/2307.06857)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.06857.md)]
- EgoVLPv2: Egocentric Video-Language Pre-training with Fusion in the   Backbone - [[Arxiv](https://arxiv.org/abs/2307.05463)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05463.md)]
- Efficient 3D Articulated Human Generation with Layered Surface Volumes - [[Arxiv](https://arxiv.org/abs/2307.05462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05462.md)]
- Empowering Cross-lingual Behavioral Testing of NLP Models with   Typological Features - [[Arxiv](https://arxiv.org/abs/2307.05454)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05454.md)]
- Self-Supervised Learning with Lie Symmetries for Partial Differential   Equations - [[Arxiv](https://arxiv.org/abs/2307.05432)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05432.md)]
- Unleashing Cognitive Synergy in Large Language Models: A Task-Solving   Agent through Multi-Persona Self-Collaboration - [[Arxiv](https://arxiv.org/abs/2307.05300)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05300.md)]
- Generative Pretraining in Multimodality - [[Arxiv](https://arxiv.org/abs/2307.05222)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05222.md)]
- DNAGPT: A Generalized Pre-trained Tool for Versatile DNA Sequence   Analysis Tasks - [[Arxiv](https://arxiv.org/abs/2307.05628)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05628.md)]
- Test-Time Training on Video Streams - [[Arxiv](https://arxiv.org/abs/2307.05014)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05014.md)]
- Neural Point-based Volumetric Avatar: Surface-guided Neural Points for   Efficient and Photorealistic Volumetric Head Avatar - [[Arxiv](https://arxiv.org/abs/2307.05000)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05000.md)]
- Monotone deep Boltzmann machines - [[Arxiv](https://arxiv.org/abs/2307.04990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04990.md)]
- Secrets of RLHF in Large Language Models Part I: PPO - [[Arxiv](https://arxiv.org/abs/2307.04964)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04964.md)]
- Semantic-SAM: Segment and Recognize Anything at Any Granularity - [[Arxiv](https://arxiv.org/abs/2307.04767)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04767.md)]
- SITTA: A Semantic Image-Text Alignment for Image Captioning - [[Arxiv](https://arxiv.org/abs/2307.05591)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05591.md)]
- Shelving, Stacking, Hanging: Relational Pose Diffusion for Multi-modal   Rearrangement - [[Arxiv](https://arxiv.org/abs/2307.04751)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04751.md)]
- RoCo: Dialectic Multi-Robot Collaboration with Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.04738)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04738.md)]
- AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models   without Specific Tuning - [[Arxiv](https://arxiv.org/abs/2307.04725)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04725.md)]
- Large Language Models as General Pattern Machines - [[Arxiv](https://arxiv.org/abs/2307.04721)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04721.md)]
- International Institutions for Advanced AI - [[Arxiv](https://arxiv.org/abs/2307.04699)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04699.md)]
- VampNet: Music Generation via Masked Acoustic Token Modeling - [[Arxiv](https://arxiv.org/abs/2307.04686)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04686.md)]
- AnyTeleop: A General Vision-Based Dexterous Robot Arm-Hand Teleoperation   System - [[Arxiv](https://arxiv.org/abs/2307.04577)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04577.md)]
- Improving Factuality of Abstractive Summarization via Contrastive Reward   Learning - [[Arxiv](https://arxiv.org/abs/2307.04507)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04507.md)]
- RLTF: Reinforcement Learning from Unit Test Feedback - [[Arxiv](https://arxiv.org/abs/2307.04349)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04349.md)]
- Convex Decomposition of Indoor Scenes - [[Arxiv](https://arxiv.org/abs/2307.04246)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04246.md)]
- Parametric Depth Based Feature Representation Learning for Object   Detection and Segmentation in Bird's Eye View - [[Arxiv](https://arxiv.org/abs/2307.04106)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04106.md)]
- SVIT: Scaling up Visual Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2307.04087)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04087.md)]
- Toward Interactive Dictation - [[Arxiv](https://arxiv.org/abs/2307.04008)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04008.md)]
- On decoder-only architecture for speech-to-text and large language model   integration - [[Arxiv](https://arxiv.org/abs/2307.03917)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03917.md)]
- Large Language Models for Supply Chain Optimization - [[Arxiv](https://arxiv.org/abs/2307.03875)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03875.md)]
- Sketch-A-Shape: Zero-Shot Sketch-to-3D Shape Generation - [[Arxiv](https://arxiv.org/abs/2307.03869)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03869.md)]
- AutoDecoding Latent 3D Diffusion Models - [[Arxiv](https://arxiv.org/abs/2307.05445)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.05445.md)]
- Equivariant Single View Pose Prediction Via Induced and Restricted   Representations - [[Arxiv](https://arxiv.org/abs/2307.03704)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03704.md)]
- Decomposing the Generalization Gap in Imitation Learning for Visual   Robotic Manipulation - [[Arxiv](https://arxiv.org/abs/2307.03659)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03659.md)]
- GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest - [[Arxiv](https://arxiv.org/abs/2307.03601)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03601.md)]
- One Step of Gradient Descent is Provably the Optimal In-Context Learner   with One Layer of Linear Self-Attention - [[Arxiv](https://arxiv.org/abs/2307.03576)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03576.md)]
- Discovering Hierarchical Achievements in Reinforcement Learning via   Contrastive Learning - [[Arxiv](https://arxiv.org/abs/2307.03486)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03486.md)]
- Solvent: A Framework for Protein Folding - [[Arxiv](https://arxiv.org/abs/2307.04603)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04603.md)]
- Goal-Conditioned Predictive Coding as an Implicit Planner for Offline   Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2307.03406)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03406.md)]
- Teaching Arithmetic to Small Transformers - [[Arxiv](https://arxiv.org/abs/2307.03381)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03381.md)]
- BiPhone: Modeling Inter Language Phonetic Influences in Text - [[Arxiv](https://arxiv.org/abs/2307.03322)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03322.md)]
- Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong   General Audio Event Taggers - [[Arxiv](https://arxiv.org/abs/2307.03183)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03183.md)]
- Lost in the Middle: How Language Models Use Long Contexts - [[Arxiv](https://arxiv.org/abs/2307.03172)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03172.md)]
- Focused Transformer: Contrastive Training for Context Scaling - [[Arxiv](https://arxiv.org/abs/2307.03170)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03170.md)]
- VideoGLUE: Video General Understanding Evaluation of Foundation Models - [[Arxiv](https://arxiv.org/abs/2307.03166)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03166.md)]
- Distilling Large Vision-Language Model with Out-of-Distribution   Generalizability - [[Arxiv](https://arxiv.org/abs/2307.03135)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03135.md)]
- Frontier AI Regulation: Managing Emerging Risks to Public Safety - [[Arxiv](https://arxiv.org/abs/2307.03718)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03718.md)]
- A Survey on Evaluation of Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.03109)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03109.md)]
- Improving Retrieval-Augmented Large Language Models via Data Importance   Learning - [[Arxiv](https://arxiv.org/abs/2307.03027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03027.md)]
- Style Over Substance: Evaluation Biases for Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.03025)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03025.md)]
- Contrast Is All You Need - [[Arxiv](https://arxiv.org/abs/2307.02882)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02882.md)]
- What Should Data Science Education Do with Large Language Models? - [[Arxiv](https://arxiv.org/abs/2307.02792)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02792.md)]
- Training Models to Generate, Recognize, and Reframe Unhelpful Thoughts - [[Arxiv](https://arxiv.org/abs/2307.02768)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02768.md)]
- Wireless Multi-Agent Generative AI: From Connected Intelligence to   Collective Intelligence - [[Arxiv](https://arxiv.org/abs/2307.02757)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02757.md)]
- SkipDecode: Autoregressive Skip Decoding with Batching and Caching for   Efficient LLM Inference - [[Arxiv](https://arxiv.org/abs/2307.02628)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02628.md)]
- LongNet: Scaling Transformers to 1,000,000,000 Tokens - [[Arxiv](https://arxiv.org/abs/2307.02486)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02486.md)]
- Building Cooperative Embodied Agents Modularly with Large Language   Models - [[Arxiv](https://arxiv.org/abs/2307.02485)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02485.md)]
- Elastic Decision Transformer - [[Arxiv](https://arxiv.org/abs/2307.02484)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02484.md)]
- Jailbroken: How Does LLM Safety Training Fail? - [[Arxiv](https://arxiv.org/abs/2307.02483)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02483.md)]
- Reasoning or Reciting? Exploring the Capabilities and Limitations of   Language Models Through Counterfactual Tasks - [[Arxiv](https://arxiv.org/abs/2307.02477)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02477.md)]
- What Matters in Training a GPT4-Style Language Model with Multimodal   Inputs? - [[Arxiv](https://arxiv.org/abs/2307.02469)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02469.md)]
- Using Rewrite Strategies for Efficient Functional Automatic   Differentiation - [[Arxiv](https://arxiv.org/abs/2307.02447)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02447.md)]
- DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models - [[Arxiv](https://arxiv.org/abs/2307.02421)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02421.md)]
- MSViT: Dynamic Mixed-Scale Tokenization for Vision Transformers - [[Arxiv](https://arxiv.org/abs/2307.02321)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02321.md)]
- Rethinking Multiple Instance Learning for Whole Slide Image   Classification: A Good Instance Classifier is All You Need - [[Arxiv](https://arxiv.org/abs/2307.02249)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02249.md)]
- Open-Source Large Language Models Outperform Crowd Workers and Approach   ChatGPT in Text-Annotation Tasks - [[Arxiv](https://arxiv.org/abs/2307.02179)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02179.md)]
- Becoming self-instruct: introducing early stopping criteria for minimal   instruct tuning - [[Arxiv](https://arxiv.org/abs/2307.03692)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.03692.md)]
- Flacuna: Unleashing the Problem Solving Power of Vicuna using FLAN   Fine-Tuning - [[Arxiv](https://arxiv.org/abs/2307.02053)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02053.md)]
- SDXL: Improving Latent Diffusion Models for High-Resolution Image   Synthesis - [[Arxiv](https://arxiv.org/abs/2307.01952)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01952.md)]
- Physics-based Motion Retargeting from Sparse Inputs - [[Arxiv](https://arxiv.org/abs/2307.01938)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01938.md)]
- Robots That Ask For Help: Uncertainty Alignment for Large Language Model   Planners - [[Arxiv](https://arxiv.org/abs/2307.01928)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01928.md)]
- Crossway Diffusion: Improving Diffusion-based Visuomotor Policy via   Self-supervised Learning - [[Arxiv](https://arxiv.org/abs/2307.01849)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01849.md)]
- Embodied Task Planning with Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.01848)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01848.md)]
- Collaborative Score Distillation for Consistent Visual Synthesis - [[Arxiv](https://arxiv.org/abs/2307.04787)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.04787.md)]
- DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation - [[Arxiv](https://arxiv.org/abs/2307.01831)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01831.md)]
- Pretraining is All You Need: A Multi-Atlas Enhanced Transformer   Framework for Autism Spectrum Disorder Classification - [[Arxiv](https://arxiv.org/abs/2307.01759)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01759.md)]
- Synthetic is all you need: removing the auxiliary data assumption for   membership inference attacks against synthetic data - [[Arxiv](https://arxiv.org/abs/2307.01701)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01701.md)]
- mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document   Understanding - [[Arxiv](https://arxiv.org/abs/2307.02499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.02499.md)]
- ChildPlay: A New Benchmark for Understanding Children's Gaze Behaviour - [[Arxiv](https://arxiv.org/abs/2307.01630)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01630.md)]
- On Hofstadter's G-sequence - [[Arxiv](https://arxiv.org/abs/2307.1471)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.1471.md)]
- Hybrid two-level MCMC for Bayesian Inverse Problems - [[Arxiv](https://arxiv.org/abs/2307.1463)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.1463.md)]
- Practical Collaborative Perception: A Framework for Asynchronous and   Multi-Agent 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2307.1462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.1462.md)]
- Multi-Task Learning Improves Performance In Deep Argument Mining Models - [[Arxiv](https://arxiv.org/abs/2307.1401)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.1401.md)]
- EIGER IV: The cool 10$^4$K circumgalactic environment of high-$z$   galaxies reveals remarkably efficient IGM enrichment - [[Arxiv](https://arxiv.org/abs/2307.1273)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.1273.md)]
- Real-time Monocular Full-body Capture in World Space via Sequential   Proxy-to-Motion Learning - [[Arxiv](https://arxiv.org/abs/2307.01200)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01200.md)]
- Segment Anything Meets Point Tracking - [[Arxiv](https://arxiv.org/abs/2307.01197)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01197.md)]
- Variational integrals on Hessian spaces: partial regularity for critical   points - [[Arxiv](https://arxiv.org/abs/2307.1191)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.1191.md)]
- Characterisation of three-body loss in ${}^{166}$Er and optimised   production of large Bose-Einstein condensates - [[Arxiv](https://arxiv.org/abs/2307.1245)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.1245.md)]
- Improving Language Plasticity via Pretraining with Active Forgetting - [[Arxiv](https://arxiv.org/abs/2307.01163)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01163.md)]
- SCITUNE: Aligning Large Language Models with Scientific Multimodal   Instructions - [[Arxiv](https://arxiv.org/abs/2307.01139)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01139.md)]
- MVDiffusion: Enabling Holistic Multi-view Image Generation with   Correspondence-Aware Diffusion - [[Arxiv](https://arxiv.org/abs/2307.01097)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01097.md)]
- Scalable quantum neural networks by few quantum resources - [[Arxiv](https://arxiv.org/abs/2307.1017)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.1017.md)]
- Visual Instruction Tuning with Polite Flamingo - [[Arxiv](https://arxiv.org/abs/2307.01003)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01003.md)]
- NOMA-Assisted Grant-Free Transmission: How to Design Pre-Configured SNR   Levels? - [[Arxiv](https://arxiv.org/abs/2307.0990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.0990.md)]
- Motion-X: A Large-scale 3D Expressive Whole-body Human Motion Dataset - [[Arxiv](https://arxiv.org/abs/2307.00818)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00818.md)]
- SketchMetaFace: A Learning-based Sketching Interface for High-fidelity   3D Character Face Modeling - [[Arxiv](https://arxiv.org/abs/2307.00804)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00804.md)]
- Hierarchical Open-vocabulary Universal Image Segmentation - [[Arxiv](https://arxiv.org/abs/2307.00764)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00764.md)]
- EmoGen: Eliminating Subjective Bias in Emotional Music Generation - [[Arxiv](https://arxiv.org/abs/2307.01229)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.01229.md)]
- JourneyDB: A Benchmark for Generative Image Understanding - [[Arxiv](https://arxiv.org/abs/2307.00716)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00716.md)]
- LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance - [[Arxiv](https://arxiv.org/abs/2307.00522)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00522.md)]
- Almost sure bounds for a weighted Steinhaus random multiplicative   function - [[Arxiv](https://arxiv.org/abs/2307.0499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.0499.md)]
- One Copy Is All You Need: Resource-Efficient Streaming of Medical   Imaging Data at Scale - [[Arxiv](https://arxiv.org/abs/2307.00438)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00438.md)]
- ProbVLM: Probabilistic Adapter for Frozen Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2307.00398)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00398.md)]
- DoReMi: Grounding Language Model by Detecting and Recovering from   Plan-Execution Misalignment - [[Arxiv](https://arxiv.org/abs/2307.00329)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00329.md)]
- Personality Traits in Large Language Models - [[Arxiv](https://arxiv.org/abs/2307.00184)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00184.md)]

### June 2023
- Meta-training with Demonstration Retrieval for Efficient Few-shot   Learning - [[Arxiv](https://arxiv.org/abs/2307.00119)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00119.md)]
- Goal Representations for Instruction Following: A Semi-Supervised   Language Interface to Control - [[Arxiv](https://arxiv.org/abs/2307.00117)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00117.md)]
- Hardwiring ViT Patch Selectivity into CNNs using Patch Mixing - [[Arxiv](https://arxiv.org/abs/2306.17848)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17848.md)]
- Magic123: One Image to High-Quality 3D Object Generation Using Both 2D   and 3D Diffusion Priors - [[Arxiv](https://arxiv.org/abs/2306.17843)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17843.md)]
- SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen   LLMs - [[Arxiv](https://arxiv.org/abs/2306.17842)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17842.md)]
- Statler: State-Maintaining Language Models for Embodied Reasoning - [[Arxiv](https://arxiv.org/abs/2306.17840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17840.md)]
- DisCo: Disentangled Control for Realistic Human Dance Generation - [[Arxiv](https://arxiv.org/abs/2307.00040)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.00040.md)]
- Stay on topic with Classifier-Free Guidance - [[Arxiv](https://arxiv.org/abs/2306.17806)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17806.md)]
- Topologically Attributed Graphs for Shape Discrimination - [[Arxiv](https://arxiv.org/abs/2306.17805)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17805.md)]
- The Shaped Transformer: Attention Models in the Infinite Depth-and-Width   Limit - [[Arxiv](https://arxiv.org/abs/2306.17759)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17759.md)]
- Large Language Models are Effective Text Rankers with Pairwise Ranking   Prompting - [[Arxiv](https://arxiv.org/abs/2306.17563)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17563.md)]
- Preference Ranking Optimization for Human Alignment - [[Arxiv](https://arxiv.org/abs/2306.17492)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17492.md)]
- ReMaX: Relaxing for Better Training on Efficient Panoptic Segmentation - [[Arxiv](https://arxiv.org/abs/2306.17319)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17319.md)]
- Towards Zero-Shot Scale-Aware Monocular Depth Estimation - [[Arxiv](https://arxiv.org/abs/2306.17253)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17253.md)]
- Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4,   and Human Tutors - [[Arxiv](https://arxiv.org/abs/2306.17156)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17156.md)]
- Generate Anything Anywhere in Any Scene - [[Arxiv](https://arxiv.org/abs/2306.17154)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17154.md)]
- Michelangelo: Conditional 3D Shape Generation based on Shape-Image-Text   Aligned Latent Representation - [[Arxiv](https://arxiv.org/abs/2306.17115)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17115.md)]
- LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image   Understanding - [[Arxiv](https://arxiv.org/abs/2306.17107)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17107.md)]
- End-to-end Autonomous Driving: Challenges and Frontiers - [[Arxiv](https://arxiv.org/abs/2306.16927)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16927.md)]
- BEDLAM: A Synthetic Dataset of Bodies Exhibiting Detailed Lifelike   Animated Motion - [[Arxiv](https://arxiv.org/abs/2306.16940)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16940.md)]
- DreamDiffusion: Generating High-Quality Images from Brain EEG Signals - [[Arxiv](https://arxiv.org/abs/2306.16934)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16934.md)]
- One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape   Optimization - [[Arxiv](https://arxiv.org/abs/2306.16928)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16928.md)]
- NeuralFuse: Learning to Improve the Accuracy of Access-Limited Neural   Network Inference in Low-Voltage Regimes - [[Arxiv](https://arxiv.org/abs/2306.16869)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16869.md)]
- ArrayBot: Reinforcement Learning for Generalizable Distributed   Manipulation through Touch - [[Arxiv](https://arxiv.org/abs/2306.16857)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16857.md)]
- Benchmarking Large Language Model Capabilities for Conditional   Generation - [[Arxiv](https://arxiv.org/abs/2306.16793)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16793.md)]
- Dynamic-Resolution Model Learning for Object Pile Manipulation - [[Arxiv](https://arxiv.org/abs/2306.16700)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16700.md)]
- KITE: Keypoint-Conditioned Policies for Semantic Manipulation - [[Arxiv](https://arxiv.org/abs/2306.16605)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16605.md)]
- An Efficient Sparse Inference Software Accelerator for Transformer-based   Language Models on CPUs - [[Arxiv](https://arxiv.org/abs/2306.16601)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16601.md)]
- SeMLaPS: Real-time Semantic Mapping with Latent Prior Networks and   Quasi-Planar Segmentation - [[Arxiv](https://arxiv.org/abs/2306.16585)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16585.md)]
- LLM Calibration and Automatic Hallucination Detection via Pareto Optimal   Self-supervision - [[Arxiv](https://arxiv.org/abs/2306.16564)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16564.md)]
- Towards Language Models That Can See: Computer Vision Through the LENS   of Natural Language - [[Arxiv](https://arxiv.org/abs/2306.16410)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16410.md)]
- On the Exploitability of Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2306.17194)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17194.md)]
- Towards Measuring the Representation of Subjective Global Opinions in   Language Models - [[Arxiv](https://arxiv.org/abs/2306.16388)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16388.md)]
- Inferring the Goals of Communicating Agents from Actions and   Instructions - [[Arxiv](https://arxiv.org/abs/2306.16207)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16207.md)]
- SVNR: Spatially-variant Noise Removal with Denoising Diffusion - [[Arxiv](https://arxiv.org/abs/2306.16052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16052.md)]
- Positive Label Is All You Need for Multi-Label Classification - [[Arxiv](https://arxiv.org/abs/2306.16016)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16016.md)]
- Accelerating Transducers through Adjacent Token Merging - [[Arxiv](https://arxiv.org/abs/2306.16009)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16009.md)]
- Confidence Ranking for CTR Prediction - [[Arxiv](https://arxiv.org/abs/2307.1206)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2307.1206.md)]
- Subclass-balancing Contrastive Learning for Long-tailed Recognition - [[Arxiv](https://arxiv.org/abs/2306.15925)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15925.md)]
- Large Language Model as Attributed Training Data Generator: A Tale of   Diversity and Bias - [[Arxiv](https://arxiv.org/abs/2306.15895)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15895.md)]
- HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide   Resolution - [[Arxiv](https://arxiv.org/abs/2306.15794)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15794.md)]
- REFLECT: Summarizing Robot Experiences for Failure Explanation and   Correction - [[Arxiv](https://arxiv.org/abs/2306.15724)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15724.md)]
- PoseDiffusion: Solving Pose Estimation via Diffusion-aided Bundle   Adjustment - [[Arxiv](https://arxiv.org/abs/2306.15667)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15667.md)]
- CLIPA-v2: Scaling CLIP Training with 81.1% Zero-shot ImageNet Accuracy   within a \$10,000 Budget; An Extra \$4,000 Unlocks 81.8% Accuracy - [[Arxiv](https://arxiv.org/abs/2306.15658)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15658.md)]
- Asynchronous Algorithmic Alignment with Cocycles - [[Arxiv](https://arxiv.org/abs/2306.15632)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15632.md)]
- LeanDojo: Theorem Proving with Retrieval-Augmented Language Models - [[Arxiv](https://arxiv.org/abs/2306.15626)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15626.md)]
- Extending Context Window of Large Language Models via Positional   Interpolation - [[Arxiv](https://arxiv.org/abs/2306.15595)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15595.md)]
- Explainable Multimodal Emotion Reasoning - [[Arxiv](https://arxiv.org/abs/2306.15401)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15401.md)]
- Length Generalization in Arithmetic Transformers - [[Arxiv](https://arxiv.org/abs/2306.15400)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15400.md)]
- 3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and   Multi-Dialect Corpus for Speech Representation Disentanglement - [[Arxiv](https://arxiv.org/abs/2306.15354)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15354.md)]
- MindDial: Belief Dynamics Tracking with Theory-of-Mind Modeling for   Situated Neural Dialogue Generation - [[Arxiv](https://arxiv.org/abs/2306.15253)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15253.md)]
- Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic - [[Arxiv](https://arxiv.org/abs/2306.15195)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15195.md)]
- MIMIC: Masked Image Modeling with Image Correspondences - [[Arxiv](https://arxiv.org/abs/2306.15128)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15128.md)]
- Understanding In-Context Learning via Supportive Pretraining Data - [[Arxiv](https://arxiv.org/abs/2306.15091)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15091.md)]
- InterCode: Standardizing and Benchmarking Interactive Coding with   Execution Feedback - [[Arxiv](https://arxiv.org/abs/2306.14898)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14898.md)]
- RVT: Robotic View Transformer for 3D Object Manipulation - [[Arxiv](https://arxiv.org/abs/2306.14896)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14896.md)]
- Supervised Pretraining Can Learn In-Context Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2306.14892)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14892.md)]
- SIMMF: Semantics-aware Interactive Multiagent Motion Forecasting for   Autonomous Vehicle Driving - [[Arxiv](https://arxiv.org/abs/2306.14941)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14941.md)]
- Restart Sampling for Improving Generative Processes - [[Arxiv](https://arxiv.org/abs/2306.14878)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14878.md)]
- Are aligned neural networks adversarially aligned? - [[Arxiv](https://arxiv.org/abs/2306.15447)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.15447.md)]
- ViNT: A Foundation Model for Visual Navigation - [[Arxiv](https://arxiv.org/abs/2306.14846)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14846.md)]
- Kosmos-2: Grounding Multimodal Large Language Models to the World - [[Arxiv](https://arxiv.org/abs/2306.14824)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14824.md)]
- MotionGPT: Human Motion as a Foreign Language - [[Arxiv](https://arxiv.org/abs/2306.14795)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14795.md)]
- SugarCrepe: Fixing Hackable Benchmarks for Vision-Language   Compositionality - [[Arxiv](https://arxiv.org/abs/2306.14610)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14610.md)]
- Mitigating Hallucination in Large Multi-Modal Models via Robust   Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2306.14565)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14565.md)]
- A-STAR: Test-time Attention Segregation and Retention for Text-to-image   Synthesis - [[Arxiv](https://arxiv.org/abs/2306.14544)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14544.md)]
- CEIL: Generalized Contextual Imitation Learning - [[Arxiv](https://arxiv.org/abs/2306.14534)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14534.md)]
- ParameterNet: Parameters Are All You Need for Large-scale Visual   Pretraining of Mobile Networks - [[Arxiv](https://arxiv.org/abs/2306.14525)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14525.md)]
- RoboCook: Long-Horizon Elasto-Plastic Object Manipulation with Diverse   Tools - [[Arxiv](https://arxiv.org/abs/2306.14447)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14447.md)]
- DragDiffusion: Harnessing Diffusion Models for Interactive Point-based   Image Editing - [[Arxiv](https://arxiv.org/abs/2306.14435)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14435.md)]
- Faster Segment Anything: Towards Lightweight SAM for Mobile Applications - [[Arxiv](https://arxiv.org/abs/2306.14289)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14289.md)]
- BiFF: Bi-level Future Fusion with Polyline-based Coordinate for   Interactive Trajectory Prediction - [[Arxiv](https://arxiv.org/abs/2306.14161)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14161.md)]
- DomainStudio: Fine-Tuning Diffusion Models for Domain-Driven Image   Generation using Limited Data - [[Arxiv](https://arxiv.org/abs/2306.14153)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14153.md)]
- Language models are weak learners - [[Arxiv](https://arxiv.org/abs/2306.14101)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14101.md)]
- SEEDS: Emulation of Weather Forecast Ensembles with Diffusion Models - [[Arxiv](https://arxiv.org/abs/2306.14066)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14066.md)]
- DesCo: Learning Object Recognition with Rich Language Descriptions - [[Arxiv](https://arxiv.org/abs/2306.14060)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14060.md)]
- H$_2$O: Heavy-Hitter Oracle for Efficient Generative Inference of Large   Language Models - [[Arxiv](https://arxiv.org/abs/2306.14048)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14048.md)]
- Thinking Like an Annotator: Generation of Dataset Labeling Instructions - [[Arxiv](https://arxiv.org/abs/2306.14035)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14035.md)]
- Cross-Validation Is All You Need: A Statistical Approach To Label Noise   Estimation - [[Arxiv](https://arxiv.org/abs/2306.13990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13990.md)]
- Beyond Scale: the Diversity Coefficient as a Data Quality Metric   Demonstrates LLMs are Pre-trained on Formally Diverse Data - [[Arxiv](https://arxiv.org/abs/2306.13840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13840.md)]
- LLM-Assisted Content Analysis: Using Large Language Models to Support   Deductive Coding - [[Arxiv](https://arxiv.org/abs/2306.14924)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.14924.md)]
- Swin-Free: Achieving Better Cross-Window Attention and Efficiency with   Size-varying Window - [[Arxiv](https://arxiv.org/abs/2306.13776)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13776.md)]
- Zero-shot spatial layout conditioning for text-to-image diffusion models - [[Arxiv](https://arxiv.org/abs/2306.13754)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13754.md)]
- Bring Your Own Data! Self-Supervised Evaluation for Large Language   Models - [[Arxiv](https://arxiv.org/abs/2306.13651)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13651.md)]
- Generalized Knowledge Distillation for Auto-regressive Language Models - [[Arxiv](https://arxiv.org/abs/2306.13649)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13649.md)]
- OpenMask3D: Open-Vocabulary 3D Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2306.13631)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13631.md)]
- System-Level Natural Language Feedback - [[Arxiv](https://arxiv.org/abs/2306.13588)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13588.md)]
- Scaling MLPs: A Tale of Inductive Bias - [[Arxiv](https://arxiv.org/abs/2306.13575)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13575.md)]
- A Survey on Multimodal Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.13549)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13549.md)]
- DreamEditor: Text-Driven 3D Scene Editing with Neural Fields - [[Arxiv](https://arxiv.org/abs/2306.13455)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13455.md)]
- Long-range Language Modeling with Self-retrieval - [[Arxiv](https://arxiv.org/abs/2306.13421)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13421.md)]
- MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language   Models - [[Arxiv](https://arxiv.org/abs/2306.13394)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13394.md)]
- Evading Forensic Classifiers with Attribute-Conditioned Adversarial   Faces - [[Arxiv](https://arxiv.org/abs/2306.13091)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13091.md)]
- Continuous Layout Editing of Single Images with Diffusion Models - [[Arxiv](https://arxiv.org/abs/2306.13078)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.13078.md)]
- Quantizable Transformers: Removing Outliers by Helping Attention Heads   Do Nothing - [[Arxiv](https://arxiv.org/abs/2306.12929)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12929.md)]
- AudioPaLM: A Large Language Model That Can Speak and Listen - [[Arxiv](https://arxiv.org/abs/2306.12925)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12925.md)]
- Learning from Visual Observation via Offline Pretrained State-to-Go   Transformer - [[Arxiv](https://arxiv.org/abs/2306.12860)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12860.md)]
- Blended-NeRF: Zero-Shot Object Generation and Blending in Existing   Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2306.12760)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12760.md)]
- SoftGPT: Learn Goal-oriented Soft Object Manipulation Skills by   Generative Pre-trained Heterogeneous Graph Transformer - [[Arxiv](https://arxiv.org/abs/2306.12677)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12677.md)]
- From Word Models to World Models: Translating from Natural Language to   the Probabilistic Language of Thought - [[Arxiv](https://arxiv.org/abs/2306.12672)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12672.md)]
- Towards Regulatable AI Systems: Technical Gaps and Policy Opportunities - [[Arxiv](https://arxiv.org/abs/2306.12609)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12609.md)]
- Local 3D Editing via 3D Distillation of CLIP Knowledge - [[Arxiv](https://arxiv.org/abs/2306.12570)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12570.md)]
- FFCV: Accelerating Training by Removing Data Bottlenecks - [[Arxiv](https://arxiv.org/abs/2306.12517)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12517.md)]
- Deep Language Networks: Joint Prompt Training of Stacked LLMs using   Variational Inference - [[Arxiv](https://arxiv.org/abs/2306.12509)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12509.md)]
- DreamTime: An Improved Optimization Strategy for Text-to-3D Content   Creation - [[Arxiv](https://arxiv.org/abs/2306.12422)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12422.md)]
- OBELICS: An Open Web-Scale Filtered Dataset of Interleaved Image-Text   Documents - [[Arxiv](https://arxiv.org/abs/2306.16527)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.16527.md)]
- Fast Segment Anything - [[Arxiv](https://arxiv.org/abs/2306.12156)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12156.md)]
- Mass-Producing Failures of Multimodal Systems with Language Models - [[Arxiv](https://arxiv.org/abs/2306.12105)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12105.md)]
- HSR-Diff:Hyperspectral Image Super-Resolution via Conditional Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2306.12085)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12085.md)]
- EquiformerV2: Improved Equivariant Transformer for Scaling to   Higher-Degree Representations - [[Arxiv](https://arxiv.org/abs/2306.12059)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.12059.md)]
- Training Transformers with 4-bit Integers - [[Arxiv](https://arxiv.org/abs/2306.11987)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11987.md)]
- Opportunities and Risks of LLMs for Scalable Deliberation with Polis - [[Arxiv](https://arxiv.org/abs/2306.11932)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11932.md)]
- Randomized Quantization is All You Need for Differential Privacy in   Federated Learning - [[Arxiv](https://arxiv.org/abs/2306.11913)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11913.md)]
- SPRINT: Scalable Policy Pre-Training via Language Instruction Relabeling - [[Arxiv](https://arxiv.org/abs/2306.11886)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11886.md)]
- Diffusion with Forward Models: Solving Stochastic Inverse Problems   Without Direct Supervision - [[Arxiv](https://arxiv.org/abs/2306.11719)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11719.md)]
- RoboCat: A Self-Improving Foundation Agent for Robotic Manipulation - [[Arxiv](https://arxiv.org/abs/2306.11706)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11706.md)]
- Textbooks Are All You Need - [[Arxiv](https://arxiv.org/abs/2306.11644)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11644.md)]
- Improving Image Captioning Descriptiveness by Ranking and LLM-based   Fusion - [[Arxiv](https://arxiv.org/abs/2306.11593)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11593.md)]
- HomeRobot: Open-Vocabulary Mobile Manipulation - [[Arxiv](https://arxiv.org/abs/2306.11565)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11565.md)]
- Improving visual image reconstruction from human brain activity using   latent diffusion models via multiple decoded inputs - [[Arxiv](https://arxiv.org/abs/2306.11536)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11536.md)]
- RM-PRT: Realistic Robotic Manipulation Simulator and Benchmark with   Progressive Reasoning Tasks - [[Arxiv](https://arxiv.org/abs/2306.11335)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11335.md)]
- Dynamic Perceiver for Efficient Visual Recognition - [[Arxiv](https://arxiv.org/abs/2306.11248)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11248.md)]
- Quilt-1M: One Million Image-Text Pairs for Histopathology - [[Arxiv](https://arxiv.org/abs/2306.11207)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11207.md)]
- Large Language Models are Fixated by Red Herrings: Exploring Creative   Problem Solving and Einstellung Effect using the Only Connect Wall Dataset - [[Arxiv](https://arxiv.org/abs/2306.11167)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11167.md)]
- FSAR: Federated Skeleton-based Action Recognition with Adaptive Topology   Structure and Knowledge Distillation - [[Arxiv](https://arxiv.org/abs/2306.11046)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11046.md)]
- RepoFusion: Training Code Models to Understand Your Repository - [[Arxiv](https://arxiv.org/abs/2306.10998)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10998.md)]
- BayLing: Bridging Cross-lingual Alignment and Instruction Following   through Interactive Translation for Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.10968)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10968.md)]
- MotionGPT: Finetuned LLMs are General-Purpose Motion Generators - [[Arxiv](https://arxiv.org/abs/2306.10900)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10900.md)]
- 3D VR Sketch Guided 3D Shape Prototyping and Exploration - [[Arxiv](https://arxiv.org/abs/2306.10830)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10830.md)]
- Multitrack Music Transcription with a Time-Frequency Perceiver - [[Arxiv](https://arxiv.org/abs/2306.10785)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10785.md)]
- Guiding Language Models of Code with Global Context using Monitors - [[Arxiv](https://arxiv.org/abs/2306.10763)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10763.md)]
- UniMC: A Unified Framework for Long-Term Memory Conversation via   Relevance Representation Learning - [[Arxiv](https://arxiv.org/abs/2306.10543)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10543.md)]
- Point-Cloud Completion with Pretrained Text-to-image Diffusion Models - [[Arxiv](https://arxiv.org/abs/2306.10533)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10533.md)]
- A Universal Semantic-Geometric Representation for Robotic Manipulation - [[Arxiv](https://arxiv.org/abs/2306.10474)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10474.md)]
- CLARA: Classifying and Disambiguating User Commands for Reliable   Interactive Robotic Agents - [[Arxiv](https://arxiv.org/abs/2306.10376)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10376.md)]
- GLIMMER: generalized late-interaction memory reranker - [[Arxiv](https://arxiv.org/abs/2306.10231)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10231.md)]
- ZeRO++: Extremely Efficient Collective Communication for Giant Model   Training - [[Arxiv](https://arxiv.org/abs/2306.10209)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10209.md)]
- Meta-Personalizing Vision-Language Models to Find Named Instances in   Video - [[Arxiv](https://arxiv.org/abs/2306.10169)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10169.md)]
- MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image   Editing - [[Arxiv](https://arxiv.org/abs/2306.10012)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10012.md)]
- CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via   Adversarial Latent Search - [[Arxiv](https://arxiv.org/abs/2306.10008)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10008.md)]
- Robot Learning with Sensorimotor Pre-training - [[Arxiv](https://arxiv.org/abs/2306.10007)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.10007.md)]
- Investigating Prompting Techniques for Zero- and Few-Shot Visual   Question Answering - [[Arxiv](https://arxiv.org/abs/2306.09996)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09996.md)]
- Evaluating Superhuman Models with Consistency Checks - [[Arxiv](https://arxiv.org/abs/2306.09983)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09983.md)]
- LabelBench: A Comprehensive Framework for Benchmarking Label-Efficient   Learning - [[Arxiv](https://arxiv.org/abs/2306.09910)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09910.md)]
- Is Self-Repair a Silver Bullet for Code Generation? - [[Arxiv](https://arxiv.org/abs/2306.09896)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09896.md)]
- AvatarBooth: High-Quality and Customizable 3D Human Avatar Generation - [[Arxiv](https://arxiv.org/abs/2306.09864)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09864.md)]
- Full Parameter Fine-tuning for Large Language Models with Limited   Resources - [[Arxiv](https://arxiv.org/abs/2306.09782)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09782.md)]
- Gradient is All You Need? - [[Arxiv](https://arxiv.org/abs/2306.09778)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09778.md)]
- Scaling Open-Vocabulary Object Detection - [[Arxiv](https://arxiv.org/abs/2306.09683)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09683.md)]
- OCTScenes: A Versatile Real-World Dataset of Tabletop Scenes for   Object-Centric Learning - [[Arxiv](https://arxiv.org/abs/2306.09682)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09682.md)]
- Multi-View Class Incremental Learning - [[Arxiv](https://arxiv.org/abs/2306.09675)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09675.md)]
- CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained   Language-Vision Models - [[Arxiv](https://arxiv.org/abs/2306.09635)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09635.md)]
- CAJun: Continuous Adaptive Jumping using a Learned Centroidal Controller - [[Arxiv](https://arxiv.org/abs/2306.09557)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09557.md)]
- Block-State Transformer - [[Arxiv](https://arxiv.org/abs/2306.09539)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09539.md)]
- Retrieving-to-Answer: Zero-Shot Video Question Answering with Frozen   Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.11732)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.11732.md)]
- Inverse Scaling: When Bigger Isn't Better - [[Arxiv](https://arxiv.org/abs/2306.09479)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09479.md)]
- Explore, Establish, Exploit: Red Teaming Language Models from Scratch - [[Arxiv](https://arxiv.org/abs/2306.09442)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09442.md)]
- Seeing the World through Your Eyes - [[Arxiv](https://arxiv.org/abs/2306.09348)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09348.md)]
- UrbanIR: Large-Scale Urban Scene Inverse Rendering from a Single Video - [[Arxiv](https://arxiv.org/abs/2306.09349)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09349.md)]
- Rosetta Neurons: Mining the Common Units in a Model Zoo - [[Arxiv](https://arxiv.org/abs/2306.09346)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09346.md)]
- Evaluating Data Attribution for Text-to-Image Models - [[Arxiv](https://arxiv.org/abs/2306.09345)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09345.md)]
- Human Preference Score v2: A Solid Benchmark for Evaluating Human   Preferences of Text-to-Image Synthesis - [[Arxiv](https://arxiv.org/abs/2306.09341)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09341.md)]
- Understanding Optimization of Deep Learning via Jacobian Matrix and   Lipschitz Constant - [[Arxiv](https://arxiv.org/abs/2306.09338)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09338.md)]
- DreamHuman: Animatable 3D Avatars from Text - [[Arxiv](https://arxiv.org/abs/2306.09329)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09329.md)]
- Language-Guided Music Recommendation for Video via Prompt Analogies - [[Arxiv](https://arxiv.org/abs/2306.09327)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09327.md)]
- Neural Relighting with Subsurface Scattering by Learning the Radiance   Transfer Gradient - [[Arxiv](https://arxiv.org/abs/2306.09322)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09322.md)]
- Diffusion Models for Zero-Shot Open-Vocabulary Segmentation - [[Arxiv](https://arxiv.org/abs/2306.09316)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09316.md)]
- Can Language Models Teach Weaker Agents? Teacher Explanations Improve   Students via Theory of Mind - [[Arxiv](https://arxiv.org/abs/2306.09299)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09299.md)]
- KoLA: Carefully Benchmarking World Knowledge of Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.09296)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09296.md)]
- A9 Intersection Dataset: All You Need for Urban 3D Camera-LiDAR Roadside   Perception - [[Arxiv](https://arxiv.org/abs/2306.09266)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09266.md)]
- LVLM-eHub: A Comprehensive Evaluation Benchmark for Large   Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2306.09265)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09265.md)]
- Encyclopedic VQA: Visual questions about detailed properties of   fine-grained categories - [[Arxiv](https://arxiv.org/abs/2306.09224)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09224.md)]
- CMMLU: Measuring massive multitask language understanding in Chinese - [[Arxiv](https://arxiv.org/abs/2306.09212)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09212.md)]
- NAVI: Category-Agnostic Image Collections with High-Quality 3D Shape and   Pose Annotations - [[Arxiv](https://arxiv.org/abs/2306.09109)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09109.md)]
- Macaw-LLM: Multi-Modal Language Modeling with Image, Audio, Video, and   Text Integration - [[Arxiv](https://arxiv.org/abs/2306.09093)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09093.md)]
- Behavioral Cloning via Search in Embedded Demonstration Dataset - [[Arxiv](https://arxiv.org/abs/2306.09082)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.09082.md)]
- Re-Benchmarking Pool-Based Active Learning for Binary Classification - [[Arxiv](https://arxiv.org/abs/2306.08954)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08954.md)]
- LOVM: Language-Only Vision Model Selection - [[Arxiv](https://arxiv.org/abs/2306.08893)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08893.md)]
- EPIC Fields: Marrying 3D Geometry and Video Understanding - [[Arxiv](https://arxiv.org/abs/2306.08731)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08731.md)]
- VidEdit: Zero-Shot and Spatially Aware Text-Driven Video Editing - [[Arxiv](https://arxiv.org/abs/2306.08707)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08707.md)]
- Toward Grounded Social Reasoning - [[Arxiv](https://arxiv.org/abs/2306.08651)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08651.md)]
- Language to Rewards for Robotic Skill Synthesis - [[Arxiv](https://arxiv.org/abs/2306.08647)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08647.md)]
- Towards AGI in Computer Vision: Lessons Learned from GPT and Large   Language Models - [[Arxiv](https://arxiv.org/abs/2306.08641)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08641.md)]
- AssistGPT: A General Multi-modal Assistant that can Plan, Execute,   Inspect, and Learn - [[Arxiv](https://arxiv.org/abs/2306.08640)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08640.md)]
- TAPIR: Tracking Any Point with per-frame Initialization and temporal   Refinement - [[Arxiv](https://arxiv.org/abs/2306.08637)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08637.md)]
- Anticipatory Music Transformer - [[Arxiv](https://arxiv.org/abs/2306.08620)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08620.md)]
- WizardCoder: Empowering Code Large Language Models with Evol-Instruct - [[Arxiv](https://arxiv.org/abs/2306.08568)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08568.md)]
- Knowledge Distillation of Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.08543)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08543.md)]
- TryOnDiffusion: A Tale of Two UNets - [[Arxiv](https://arxiv.org/abs/2306.08276)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08276.md)]
- Diffusion in Diffusion: Cyclic One-Way Diffusion for   Text-Vision-Conditioned Generation - [[Arxiv](https://arxiv.org/abs/2306.08247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08247.md)]
- Contrastive Loss is All You Need to Recover Analogies as Parallel Lines - [[Arxiv](https://arxiv.org/abs/2306.08221)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08221.md)]
- Agile Catching with Whole-Body MPC and Blackbox Policy Learning - [[Arxiv](https://arxiv.org/abs/2306.08205)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08205.md)]
- h2oGPT: Democratizing Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.08161)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08161.md)]
- Large-scale Language Model Rescoring on Long-form Data - [[Arxiv](https://arxiv.org/abs/2306.08133)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08133.md)]
- AVIS: Autonomous Visual Information Seeking with Large Language Model   Agent - [[Arxiv](https://arxiv.org/abs/2306.08129)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08129.md)]
- DORSal: Diffusion for Object-centric Representations of Scenes et al - [[Arxiv](https://arxiv.org/abs/2306.08068)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08068.md)]
- Tune As You Scale: Hyperparameter Optimization For Compute Efficient   Training - [[Arxiv](https://arxiv.org/abs/2306.08055)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08055.md)]
- Efficient 3D Semantic Segmentation with Superpoint Transformer - [[Arxiv](https://arxiv.org/abs/2306.08045)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.08045.md)]
- Neural Scene Chronology - [[Arxiv](https://arxiv.org/abs/2306.07970)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07970.md)]
- GeneCIS: A Benchmark for General Conditional Image Similarity - [[Arxiv](https://arxiv.org/abs/2306.07969)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07969.md)]
- arXiVeri: Automatic table verification with GPT - [[Arxiv](https://arxiv.org/abs/2306.07968)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07968.md)]
- One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning - [[Arxiv](https://arxiv.org/abs/2306.07967)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07967.md)]
- Hidden Biases of End-to-End Driving Models - [[Arxiv](https://arxiv.org/abs/2306.07957)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07957.md)]
- Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation - [[Arxiv](https://arxiv.org/abs/2306.07954)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07954.md)]
- Questioning the Survey Responses of Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.07951)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07951.md)]
- Image Captioners Are Scalable Vision Learners Too - [[Arxiv](https://arxiv.org/abs/2306.07915)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07915.md)]
- WebGLM: Towards An Efficient Web-Enhanced Question Answering System with   Human Preferences - [[Arxiv](https://arxiv.org/abs/2306.07906)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07906.md)]
- Viewset Diffusion: (0-)Image-Conditioned 3D Generative Models from 2D   Data - [[Arxiv](https://arxiv.org/abs/2306.07881)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07881.md)]
- Area is all you need: repeatable elements make stronger adversarial   attacks - [[Arxiv](https://arxiv.org/abs/2306.07768)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07768.md)]
- E2E-LOAD: End-to-End Long-form Online Action Detection - [[Arxiv](https://arxiv.org/abs/2306.07703)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07703.md)]
- SayTap: Language to Quadrupedal Locomotion - [[Arxiv](https://arxiv.org/abs/2306.07580)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07580.md)]
- Galactic: Scaling End-to-End Reinforcement Learning for Rearrangement at   100k Steps-Per-Second - [[Arxiv](https://arxiv.org/abs/2306.07552)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07552.md)]
- TART: A plug-and-play Transformer module for task-agnostic reasoning - [[Arxiv](https://arxiv.org/abs/2306.07536)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07536.md)]
- Require Process Control? LSTMc is all you need! - [[Arxiv](https://arxiv.org/abs/2306.07510)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07510.md)]
- AniFaceDrawing: Anime Portrait Exploration during Your Sketching - [[Arxiv](https://arxiv.org/abs/2306.07476)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07476.md)]
- 3D molecule generation by denoising voxel grids - [[Arxiv](https://arxiv.org/abs/2306.07473)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07473.md)]
- Instant Multi-View Head Capture through Learnable Registration - [[Arxiv](https://arxiv.org/abs/2306.07437)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07437.md)]
- Learning to Mask and Permute Visual Tokens for Vision Transformer   Pre-Training - [[Arxiv](https://arxiv.org/abs/2306.07346)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07346.md)]
- Controlling Text-to-Image Diffusion by Orthogonal Finetuning - [[Arxiv](https://arxiv.org/abs/2306.07280)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07280.md)]
- Scalable 3D Captioning with Pretrained Models - [[Arxiv](https://arxiv.org/abs/2306.07279)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07279.md)]
- Zero-shot Composed Text-Image Retrieval - [[Arxiv](https://arxiv.org/abs/2306.07272)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07272.md)]
- Retrieval-Enhanced Contrastive Vision-Text Models - [[Arxiv](https://arxiv.org/abs/2306.07196)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07196.md)]
- Benchmarking Neural Network Training Algorithms - [[Arxiv](https://arxiv.org/abs/2306.07179)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07179.md)]
- Augmenting Language Models with Long-Term Memory - [[Arxiv](https://arxiv.org/abs/2306.07174)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07174.md)]
- Transformers learn through gradual rank increase - [[Arxiv](https://arxiv.org/abs/2306.07042)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07042.md)]
- Small Temperature is All You Need for Differentiable Architecture Search - [[Arxiv](https://arxiv.org/abs/2306.06855)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06855.md)]
- Weakly supervised information extraction from inscrutable handwritten   document images - [[Arxiv](https://arxiv.org/abs/2306.06823)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06823.md)]
- Attention, Compilation, and Solver-based Symbolic Analysis are All You   Need - [[Arxiv](https://arxiv.org/abs/2306.06755)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06755.md)]
- LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset,   Framework, and Benchmark - [[Arxiv](https://arxiv.org/abs/2306.06687)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06687.md)]
- Face0: Instantaneously Conditioning a Text-to-Image Model on a Face - [[Arxiv](https://arxiv.org/abs/2306.06638)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06638.md)]
- RestGPT: Connecting Large Language Models with Real-World RESTful APIs - [[Arxiv](https://arxiv.org/abs/2306.06624)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06624.md)]
- High-Fidelity Audio Compression with Improved RVQGAN - [[Arxiv](https://arxiv.org/abs/2306.06546)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06546.md)]
- Learning Image-Adaptive Codebooks for Class-Agnostic Image Restoration - [[Arxiv](https://arxiv.org/abs/2306.06513)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06513.md)]
- Aladdin: Zero-Shot Hallucination of Stylized 3D Assets from Abstract   Scene Descriptions - [[Arxiv](https://arxiv.org/abs/2306.06212)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06212.md)]
- FasterViT: Fast Vision Transformers with Hierarchical Attention - [[Arxiv](https://arxiv.org/abs/2306.06189)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06189.md)]
- Value function estimation using conditional diffusion models for control - [[Arxiv](https://arxiv.org/abs/2306.07290)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07290.md)]
- Realistic Saliency Guided Image Enhancement - [[Arxiv](https://arxiv.org/abs/2306.06092)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06092.md)]
- Mind2Web: Towards a Generalist Agent for the Web - [[Arxiv](https://arxiv.org/abs/2306.06070)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06070.md)]
- GANeRF: Leveraging Discriminators to Optimize Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2306.06044)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06044.md)]
- DetZero: Rethinking Offboard 3D Object Detection with Long-term   Sequential Point Clouds - [[Arxiv](https://arxiv.org/abs/2306.06023)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06023.md)]
- S$^{3}$: Increasing GPU Utilization during Generative Inference for   Higher Throughput - [[Arxiv](https://arxiv.org/abs/2306.06000)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.06000.md)]
- GPT-Calls: Enhancing Call Segmentation and Tagging by Generating   Synthetic Conversations via Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.07941)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07941.md)]
- Evaluating the Social Impact of Generative AI Systems in Systems and   Society - [[Arxiv](https://arxiv.org/abs/2306.05949)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05949.md)]
- Can Large Language Models Infer Causation from Correlation? - [[Arxiv](https://arxiv.org/abs/2306.05836)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05836.md)]
- Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge   Evaluation - [[Arxiv](https://arxiv.org/abs/2306.05783)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05783.md)]
- Embodied Executable Policy Learning with Language-based Scene   Summarization - [[Arxiv](https://arxiv.org/abs/2306.05696)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05696.md)]
- Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena - [[Arxiv](https://arxiv.org/abs/2306.05685)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05685.md)]
- On the Importance of Feature Decorrelation for Unsupervised   Representation Learning in Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2306.05637)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05637.md)]
- Speech-to-Text Adapter and Speech-to-Entity Retriever Augmented LLMs for   Speech Understanding - [[Arxiv](https://arxiv.org/abs/2306.07944)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07944.md)]
- BOOT: Data-free Distillation of Denoising Diffusion Models with   Bootstrapping - [[Arxiv](https://arxiv.org/abs/2306.05544)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05544.md)]
- Multi-Modal Classifiers for Open-Vocabulary Object Detection - [[Arxiv](https://arxiv.org/abs/2306.05493)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05493.md)]
- Background Prompting for Improved Object Depth - [[Arxiv](https://arxiv.org/abs/2306.05428)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05428.md)]
- Grounded Text-to-Image Synthesis with Attention Refocusing - [[Arxiv](https://arxiv.org/abs/2306.05427)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05427.md)]
- MIMIC-IT: Multi-Modal In-Context Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2306.05425)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05425.md)]
- Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and   Language Models - [[Arxiv](https://arxiv.org/abs/2306.05424)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05424.md)]
- Tracking Everything Everywhere All at Once - [[Arxiv](https://arxiv.org/abs/2306.05422)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05422.md)]
- Scaling Spherical CNNs - [[Arxiv](https://arxiv.org/abs/2306.05420)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05420.md)]
- R-MAE: Regions Meet Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2306.05411)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05411.md)]
- LU-NeRF: Scene and Pose Estimation by Synchronizing Local Unposed NeRFs - [[Arxiv](https://arxiv.org/abs/2306.05410)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05410.md)]
- Matting Anything - [[Arxiv](https://arxiv.org/abs/2306.05399)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05399.md)]
- Modular Visual Question Answering via Code Generation - [[Arxiv](https://arxiv.org/abs/2306.05392)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05392.md)]
- Unsupervised Compositional Concepts Discovery with Text-to-Image   Generative Models - [[Arxiv](https://arxiv.org/abs/2306.05357)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05357.md)]
- ToolAlpaca: Generalized Tool Learning for Language Models with 3000   Simulated Cases - [[Arxiv](https://arxiv.org/abs/2306.05301)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05301.md)]
- Simple and Controllable Music Generation - [[Arxiv](https://arxiv.org/abs/2306.05284)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05284.md)]
- M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining   Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.05179)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05179.md)]
- SyncDiffusion: Coherent Montage via Synchronized Joint Diffusions - [[Arxiv](https://arxiv.org/abs/2306.05178)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05178.md)]
- PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning   Optimization - [[Arxiv](https://arxiv.org/abs/2306.05087)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05087.md)]
- Understanding Masked Autoencoders via Hierarchical Latent Variable   Models - [[Arxiv](https://arxiv.org/abs/2306.04898)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04898.md)]
- ScaleDet: A Scalable Multi-Dataset Object Detector - [[Arxiv](https://arxiv.org/abs/2306.04849)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04849.md)]
- Mixture-of-Supernets: Improving Weight-Sharing Supernet Training with   Architecture-Routed Mixture-of-Experts - [[Arxiv](https://arxiv.org/abs/2306.04845)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04845.md)]
- Optimizing ViViT Training: Time and Memory Reduction for Action   Recognition - [[Arxiv](https://arxiv.org/abs/2306.04822)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04822.md)]
- INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large   Language Models - [[Arxiv](https://arxiv.org/abs/2306.04757)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04757.md)]
- How Far Can Camels Go? Exploring the State of Instruction Tuning on Open   Resources - [[Arxiv](https://arxiv.org/abs/2306.04751)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04751.md)]
- Improving Open Language Models by Learning from Organic Interactions - [[Arxiv](https://arxiv.org/abs/2306.04707)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04707.md)]
- On the Reliability of Watermarks for Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.04634)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04634.md)]
- Designing a Better Asymmetric VQGAN for StableDiffusion - [[Arxiv](https://arxiv.org/abs/2306.04632)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04632.md)]
- ARTIC3D: Learning Robust Articulated 3D Shapes from Noisy Web Image   Collections - [[Arxiv](https://arxiv.org/abs/2306.04619)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04619.md)]
- PromptBench: Towards Evaluating the Robustness of Large Language Models   on Adversarial Prompts - [[Arxiv](https://arxiv.org/abs/2306.04528)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04528.md)]
- Improving neural network representations using human similarity   judgments - [[Arxiv](https://arxiv.org/abs/2306.04507)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04507.md)]
- Rewarded soups: towards Pareto-optimal alignment by interpolating   weights fine-tuned on diverse rewards - [[Arxiv](https://arxiv.org/abs/2306.04488)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04488.md)]
- M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual   Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2306.04387)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04387.md)]
- Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for   Pre-training and Benchmarks - [[Arxiv](https://arxiv.org/abs/2306.04362)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04362.md)]
- MobileNMT: Enabling Translation in 15MB and 30ms - [[Arxiv](https://arxiv.org/abs/2306.04235)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04235.md)]
- Benchmarking Foundation Models with Language-Model-as-an-Examiner - [[Arxiv](https://arxiv.org/abs/2306.04181)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04181.md)]
- Increasing Diversity While Maintaining Accuracy: Text Data Generation   with Large Language Models and Human Interventions - [[Arxiv](https://arxiv.org/abs/2306.04140)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04140.md)]
- Text-only Domain Adaptation using Unified Speech-Text Representation in   Transducer - [[Arxiv](https://arxiv.org/abs/2306.04076)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04076.md)]
- Transferable Adversarial Robustness for Categorical Data via Universal   Robust Embeddings - [[Arxiv](https://arxiv.org/abs/2306.04064)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04064.md)]
- LLMZip: Lossless Text Compression using Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.04050)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04050.md)]
- Certified Reasoning with Language Models - [[Arxiv](https://arxiv.org/abs/2306.04031)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04031.md)]
- Triggering Multi-Hop Reasoning for Question Answering in Language Models   using Soft Prompts and Random Walks - [[Arxiv](https://arxiv.org/abs/2306.04009)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.04009.md)]
- ATT3D: Amortized Text-to-3D Object Synthesis - [[Arxiv](https://arxiv.org/abs/2306.07349)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07349.md)]
- ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory - [[Arxiv](https://arxiv.org/abs/2306.03901)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03901.md)]
- Emergent Correspondence from Image Diffusion - [[Arxiv](https://arxiv.org/abs/2306.03881)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03881.md)]
- Deductive Verification of Chain-of-Thought Reasoning - [[Arxiv](https://arxiv.org/abs/2306.03872)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03872.md)]
- LEACE: Perfect linear concept erasure in closed form - [[Arxiv](https://arxiv.org/abs/2306.03819)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03819.md)]
- Learning to Ground Instructional Articles in Videos through Narrations - [[Arxiv](https://arxiv.org/abs/2306.03802)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03802.md)]
- Enabling Intelligent Interactions between an Agent and an LLM: A   Reinforcement Learning Approach - [[Arxiv](https://arxiv.org/abs/2306.03604)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03604.md)]
- On Pitfalls of Test-Time Adaptation - [[Arxiv](https://arxiv.org/abs/2306.03536)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03536.md)]
- Recognize Anything: A Strong Image Tagging Model - [[Arxiv](https://arxiv.org/abs/2306.03514)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03514.md)]
- Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive   Bias - [[Arxiv](https://arxiv.org/abs/2306.03509)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03509.md)]
- Ada-TTA: Towards Adaptive High-Quality Text-to-Talking Avatar Synthesis - [[Arxiv](https://arxiv.org/abs/2306.03504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03504.md)]
- A Grasp Pose is All You Need: Learning Multi-fingered Grasping with Deep   Reinforcement Learning from Vision and Touch - [[Arxiv](https://arxiv.org/abs/2306.03484)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03484.md)]
- Natural Language Commanding via Program Synthesis - [[Arxiv](https://arxiv.org/abs/2306.03460)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03460.md)]
- Large Language Models of Code Fail at Completing Code with Potential   Bugs - [[Arxiv](https://arxiv.org/abs/2306.03438)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03438.md)]
- GaitGCI: Generative Counterfactual Intervention for Gait Recognition - [[Arxiv](https://arxiv.org/abs/2306.03428)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03428.md)]
- DVIS: Decoupled Video Instance Segmentation Framework - [[Arxiv](https://arxiv.org/abs/2306.03413)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03413.md)]
- Vid2Act: Activate Offline Videos for Visual RL - [[Arxiv](https://arxiv.org/abs/2306.03360)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03360.md)]
- Stabilizing Contrastive RL: Techniques for Offline Goal Reaching - [[Arxiv](https://arxiv.org/abs/2306.03346)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03346.md)]
- Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM   Agents - [[Arxiv](https://arxiv.org/abs/2306.03314)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03314.md)]
- A Static Evaluation of Code Completion by Large Language Models - [[Arxiv](https://arxiv.org/abs/2306.03203)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03203.md)]
- Neuralangelo: High-Fidelity Neural Surface Reconstruction - [[Arxiv](https://arxiv.org/abs/2306.03092)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03092.md)]
- MotionDiffuser: Controllable Multi-Agent Motion Prediction using   Diffusion - [[Arxiv](https://arxiv.org/abs/2306.03083)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03083.md)]
- InstructZero: Efficient Instruction Optimization for Black-Box Large   Language Models - [[Arxiv](https://arxiv.org/abs/2306.03082)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03082.md)]
- HeadSculpt: Crafting 3D Head Avatars with Text - [[Arxiv](https://arxiv.org/abs/2306.03038)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03038.md)]
- PokemonChat: Auditing ChatGPT for PokÃ©mon Universe Knowledge - [[Arxiv](https://arxiv.org/abs/2306.03024)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03024.md)]
- BeyondPixels: A Comprehensive Review of the Evolution of Neural Radiance   Fields - [[Arxiv](https://arxiv.org/abs/2306.03000)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03000.md)]
- PolyVoice: Language Models for Speech to Speech Translation - [[Arxiv](https://arxiv.org/abs/2306.02982)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.02982.md)]
- Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video   Understanding - [[Arxiv](https://arxiv.org/abs/2306.02858)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.02858.md)]
- Scene as Occupancy - [[Arxiv](https://arxiv.org/abs/2306.02851)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.02851.md)]
- Orca: Progressive Learning from Complex Explanation Traces of GPT-4 - [[Arxiv](https://arxiv.org/abs/2306.02707)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.02707.md)]
- LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and   Generative Fusion - [[Arxiv](https://arxiv.org/abs/2306.02561)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.02561.md)]
- When Large Language Model based Agent Meets User Behavior Analysis: A   Novel User Simulation Paradigm - [[Arxiv](https://arxiv.org/abs/2306.02552)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.02552.md)]
- PLANNER: Generating Diversified Paragraph via Latent Language Diffusion   Model - [[Arxiv](https://arxiv.org/abs/2306.02531)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.02531.md)]
- A Technical Report for Polyglot-Ko: Open-Source Large-Scale Korean   Language Models - [[Arxiv](https://arxiv.org/abs/2306.02254)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.02254.md)]
- SAM3D: Zero-Shot 3D Object Detection via Segment Anything Model - [[Arxiv](https://arxiv.org/abs/2306.02245)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.02245.md)]
- Benchmarking Robustness of Adaptation Methods on Pre-trained   Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2306.02080)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.02080.md)]
- Prompting Is All You Need: Automated Android Bug Replay with Large   Language Models - [[Arxiv](https://arxiv.org/abs/2306.01987)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01987.md)]
- DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal   Forecasting - [[Arxiv](https://arxiv.org/abs/2306.01984)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01984.md)]
- AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap - [[Arxiv](https://arxiv.org/abs/2306.01941)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01941.md)]
- RITA: Group Attention is All You Need for Timeseries Analytics - [[Arxiv](https://arxiv.org/abs/2306.01926)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01926.md)]
- The Surprising Effectiveness of Diffusion Models for Optical Flow and   Monocular Depth Estimation - [[Arxiv](https://arxiv.org/abs/2306.01923)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01923.md)]
- Revisiting the Role of Language Priors in Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2306.01879)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01879.md)]
- Probabilistic Adaptation of Text-to-Video Models - [[Arxiv](https://arxiv.org/abs/2306.01872)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01872.md)]
- Binary and Ternary Natural Language Generation - [[Arxiv](https://arxiv.org/abs/2306.01841)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01841.md)]
- DaTaSeg: Taming a Universal Multi-Dataset Multi-Task Segmentation Model - [[Arxiv](https://arxiv.org/abs/2306.01736)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01736.md)]
- Evaluating Language Models for Mathematics through Interactions - [[Arxiv](https://arxiv.org/abs/2306.01694)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01694.md)]
- Fine-Grained Human Feedback Gives Better Rewards for Language Model   Training - [[Arxiv](https://arxiv.org/abs/2306.01693)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01693.md)]
- Harnessing large-language models to generate private synthetic text - [[Arxiv](https://arxiv.org/abs/2306.01684)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01684.md)]
- Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label   Prompt Tuning - [[Arxiv](https://arxiv.org/abs/2306.01669)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01669.md)]
- STUDY: Socially Aware Temporally Causal Decoder Recommender Systems - [[Arxiv](https://arxiv.org/abs/2306.07946)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.07946.md)]
- Segment Anything in High Quality - [[Arxiv](https://arxiv.org/abs/2306.01567)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01567.md)]
- Bi-LRFusion: Bi-Directional LiDAR-Radar Fusion for 3D Dynamic Object   Detection - [[Arxiv](https://arxiv.org/abs/2306.01438)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01438.md)]
- An Empirical Study on Challenging Math Problem Solving with GPT-4 - [[Arxiv](https://arxiv.org/abs/2306.01337)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01337.md)]
- LoCoOp: Few-Shot Out-of-Distribution Detection via Prompt Learning - [[Arxiv](https://arxiv.org/abs/2306.01293)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01293.md)]
- Responsible Task Automation: Empowering Large Language Models as   Responsible Task Automators - [[Arxiv](https://arxiv.org/abs/2306.01242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01242.md)]
- Faster Causal Attention Over Large Sequences Through Sparse Flash   Attention - [[Arxiv](https://arxiv.org/abs/2306.01160)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01160.md)]
- The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora   with Web Data, and Web Data Only - [[Arxiv](https://arxiv.org/abs/2306.01116)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01116.md)]
- Reimagining Retrieval Augmented Language Models for Answering Queries - [[Arxiv](https://arxiv.org/abs/2306.01061)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01061.md)]
- Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles - [[Arxiv](https://arxiv.org/abs/2306.00989)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00989.md)]
- Diffusion Self-Guidance for Controllable Image Generation - [[Arxiv](https://arxiv.org/abs/2306.00986)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00986.md)]
- StableRep: Synthetic Images from Text-to-Image Models Make Strong Visual   Representation Learners - [[Arxiv](https://arxiv.org/abs/2306.00984)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00984.md)]
- StyleDrop: Text-to-Image Generation in Any Style - [[Arxiv](https://arxiv.org/abs/2306.00983)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00983.md)]
- SnapFusion: Text-to-Image Diffusion Model on Mobile Devices within Two   Seconds - [[Arxiv](https://arxiv.org/abs/2306.00980)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00980.md)]
- AWQ: Activation-aware Weight Quantization for LLM Compression and   Acceleration - [[Arxiv](https://arxiv.org/abs/2306.00978)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00978.md)]
- ViCo: Detail-Preserving Visual Condition for Personalized Text-to-Image   Generation - [[Arxiv](https://arxiv.org/abs/2306.00971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00971.md)]
- GRES: Generalized Referring Expression Segmentation - [[Arxiv](https://arxiv.org/abs/2306.00968)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00968.md)]
- The Hidden Language of Diffusion Models - [[Arxiv](https://arxiv.org/abs/2306.00966)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00966.md)]
- Cocktail: Mixing Multi-Modality Controls for Text-Conditional Image   Generation - [[Arxiv](https://arxiv.org/abs/2306.00964)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00964.md)]
- The ObjectFolder Benchmark: Multisensory Learning with Neural and Real   Objects - [[Arxiv](https://arxiv.org/abs/2306.00956)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00956.md)]
- Make-Your-Video: Customized Video Generation Using Textual and   Structural Guidance - [[Arxiv](https://arxiv.org/abs/2306.00943)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00943.md)]
- STEVE-1: A Generative Model for Text-to-Behavior in Minecraft - [[Arxiv](https://arxiv.org/abs/2306.00937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00937.md)]
- Inserting Anybody in Diffusion Models via Celeb Basis - [[Arxiv](https://arxiv.org/abs/2306.00926)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00926.md)]
- T2IAT: Measuring Valence and Stereotypical Biases in Text-to-Image   Generation - [[Arxiv](https://arxiv.org/abs/2306.00905)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00905.md)]
- LLaVA-Med: Training a Large Language-and-Vision Assistant for   Biomedicine in One Day - [[Arxiv](https://arxiv.org/abs/2306.00890)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00890.md)]
- Birth of a Transformer: A Memory Viewpoint - [[Arxiv](https://arxiv.org/abs/2306.00802)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00802.md)]
- Microstructure quality control of steels using deep learning - [[Arxiv](https://arxiv.org/abs/2306.0797)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.0797.md)]
- GPT4Image: Can Large Pre-trained Models Help Vision Models on Perception   Tasks? - [[Arxiv](https://arxiv.org/abs/2306.00693)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00693.md)]
- Wuerstchen: An Efficient Architecture for Large-Scale Text-to-Image   Diffusion Models - [[Arxiv](https://arxiv.org/abs/2306.00637)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00637.md)]
- ReviewerGPT? An Exploratory Study on Using Large Language Models for   Paper Reviewing - [[Arxiv](https://arxiv.org/abs/2306.00622)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00622.md)]
- Exploring Open-Vocabulary Semantic Segmentation without Human Labels - [[Arxiv](https://arxiv.org/abs/2306.00450)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00450.md)]
- Example-based Motion Synthesis via Generative Motion Matching - [[Arxiv](https://arxiv.org/abs/2306.00378)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00378.md)]
- Thought Cloning: Learning to Think while Acting by Imitating Human   Thinking - [[Arxiv](https://arxiv.org/abs/2306.00323)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00323.md)]
- Rethinking Model Evaluation as Narrowing the Socio-Technical Gap - [[Arxiv](https://arxiv.org/abs/2306.03100)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.03100.md)]

### May 2023
- From Pixels to UI Actions: Learning to Follow Instructions via Graphical   User Interfaces - [[Arxiv](https://arxiv.org/abs/2306.00245)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00245.md)]
- Bytes Are All You Need: Transformers Operating Directly On File Bytes - [[Arxiv](https://arxiv.org/abs/2306.00238)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00238.md)]
- Zero-shot Pose Transfer for Unrigged Stylized 3D Characters - [[Arxiv](https://arxiv.org/abs/2306.00200)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00200.md)]
- SafeDiffuser: Safe Planning with Diffusion Probabilistic Models - [[Arxiv](https://arxiv.org/abs/2306.00148)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00148.md)]
- MuseCoco: Generating Symbolic Music from Text - [[Arxiv](https://arxiv.org/abs/2306.00110)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00110.md)]
- MERT: Acoustic Music Understanding Model with Large-Scale   Self-supervised Training - [[Arxiv](https://arxiv.org/abs/2306.00107)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00107.md)]
- Humans in 4D: Reconstructing and Tracking Humans with Transformers - [[Arxiv](https://arxiv.org/abs/2305.20091)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.20091.md)]
- Improving CLIP Training with Language Rewrites - [[Arxiv](https://arxiv.org/abs/2305.20088)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.20088.md)]
- Too Large; Data Reduction for Vision-Language Pre-Training - [[Arxiv](https://arxiv.org/abs/2305.20087)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.20087.md)]
- Understanding and Mitigating Copying in Diffusion Models - [[Arxiv](https://arxiv.org/abs/2305.20086)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.20086.md)]
- Control4D: Dynamic Portrait Editing by Learning 4D GAN from 2D   Diffusion-based Editor - [[Arxiv](https://arxiv.org/abs/2305.20082)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.20082.md)]
- Efficient Diffusion Policies for Offline Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2305.20081)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.20081.md)]
- Tree-Ring Watermarks: Fingerprints for Diffusion Images that are   Invisible and Robust - [[Arxiv](https://arxiv.org/abs/2305.20030)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.20030.md)]
- Monotonic Location Attention for Length Generalization - [[Arxiv](https://arxiv.org/abs/2305.20019)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.20019.md)]
- Human or Not? A Gamified Approach to the Turing Test - [[Arxiv](https://arxiv.org/abs/2305.20010)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.20010.md)]
- Deliberate then Generate: Enhanced Prompting Framework for Text   Generation - [[Arxiv](https://arxiv.org/abs/2305.19835)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19835.md)]
- Dense and Aligned Captions (DAC) Promote Compositional Reasoning in VL   Models - [[Arxiv](https://arxiv.org/abs/2305.19595)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19595.md)]
- Neural Kernel Surface Reconstruction - [[Arxiv](https://arxiv.org/abs/2305.19590)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19590.md)]
- CodeTF: One-stop Transformer Library for State-of-the-art Code LLM - [[Arxiv](https://arxiv.org/abs/2306.00029)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00029.md)]
- Perception and Semantic Aware Regularization for Sequential Confidence   Calibration - [[Arxiv](https://arxiv.org/abs/2305.19498)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19498.md)]
- PlaSma: Making Small Language Models Better Procedural Knowledge Models   for (Counterfactual) Planning - [[Arxiv](https://arxiv.org/abs/2305.19472)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19472.md)]
- The Impact of Positional Encoding on Length Generalization in   Transformers - [[Arxiv](https://arxiv.org/abs/2305.19466)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19466.md)]
- Bigger, Better, Faster: Human-level Atari with human-level efficiency - [[Arxiv](https://arxiv.org/abs/2305.19452)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19452.md)]
- Blockwise Parallel Transformer for Large Context Models - [[Arxiv](https://arxiv.org/abs/2305.19370)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19370.md)]
- AlteredAvatar: Stylizing Dynamic 3D Avatars with Fast Style Adaptation - [[Arxiv](https://arxiv.org/abs/2305.19245)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19245.md)]
- Grammar Prompting for Domain-Specific Language Generation with Large   Language Models - [[Arxiv](https://arxiv.org/abs/2305.19234)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19234.md)]
- LANCE: Stress-testing Visual Models by Generating Language-guided   Counterfactual Images - [[Arxiv](https://arxiv.org/abs/2305.19164)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19164.md)]
- Encouraging Divergent Thinking in Large Language Models through   Multi-Agent Debate - [[Arxiv](https://arxiv.org/abs/2305.19118)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19118.md)]
- Nested Diffusion Processes for Anytime Image Generation - [[Arxiv](https://arxiv.org/abs/2305.19066)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19066.md)]
- Rank-adaptive spectral pruning of convolutional layers during training - [[Arxiv](https://arxiv.org/abs/2305.19059)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19059.md)]
- StyleAvatar3D: Leveraging Image-Text Diffusion Models for High-Fidelity   3D Avatar Generation - [[Arxiv](https://arxiv.org/abs/2305.19012)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19012.md)]
- Independent Component Alignment for Multi-Task Learning - [[Arxiv](https://arxiv.org/abs/2305.19000)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.19000.md)]
- LibriTTS-R: A Restored Multi-Speaker Text-to-Speech Corpus - [[Arxiv](https://arxiv.org/abs/2305.18802)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18802.md)]
- HiFA: High-fidelity Text-to-3D with Advanced Diffusion Guidance - [[Arxiv](https://arxiv.org/abs/2305.18766)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18766.md)]
- VSTAR: A Video-grounded Dialogue Dataset for Situated Semantic   Understanding with Scene and Topic Transitions - [[Arxiv](https://arxiv.org/abs/2305.18756)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18756.md)]
- GPT4Tools: Teaching Large Language Model to Use Tools via   Self-instruction - [[Arxiv](https://arxiv.org/abs/2305.18752)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18752.md)]
- Real-World Image Variation by Aligning Diffusion Inversion Chain - [[Arxiv](https://arxiv.org/abs/2305.18729)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18729.md)]
- Faith and Fate: Limits of Transformers on Compositionality - [[Arxiv](https://arxiv.org/abs/2305.18654)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18654.md)]
- Controllable Text-to-Image Generation with GPT-4 - [[Arxiv](https://arxiv.org/abs/2305.18583)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18583.md)]
- PaLI-X: On Scaling up a Multilingual Vision and Language Model - [[Arxiv](https://arxiv.org/abs/2305.18565)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18565.md)]
- Brainformers: Trading Simplicity for Efficiency - [[Arxiv](https://arxiv.org/abs/2306.00008)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00008.md)]
- RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths - [[Arxiv](https://arxiv.org/abs/2305.18295)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18295.md)]
- Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept   Customization of Diffusion Models - [[Arxiv](https://arxiv.org/abs/2305.18292)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18292.md)]
- Direct Preference Optimization: Your Language Model is Secretly a Reward   Model - [[Arxiv](https://arxiv.org/abs/2305.18290)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18290.md)]
- Photoswap: Personalized Subject Swapping in Images - [[Arxiv](https://arxiv.org/abs/2305.18286)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18286.md)]
- Contextual Object Detection with Multimodal Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.18279)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18279.md)]
- Reconstructing the Mind's Eye: fMRI-to-Image with Contrastive Learning   and Diffusion Priors - [[Arxiv](https://arxiv.org/abs/2305.18274)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18274.md)]
- Gen-L-Video: Multi-Text to Long Video Generation via Temporal   Co-Denoising - [[Arxiv](https://arxiv.org/abs/2305.18264)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18264.md)]
- GlyphControl: Glyph Conditional Control for Visual Text Generation - [[Arxiv](https://arxiv.org/abs/2305.18259)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18259.md)]
- TaleCrafter: Interactive Story Visualization with Multiple Characters - [[Arxiv](https://arxiv.org/abs/2305.18247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18247.md)]
- Marked Personas: Using Natural Language Prompts to Measure Stereotypes   in Language Models - [[Arxiv](https://arxiv.org/abs/2305.18189)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18189.md)]
- Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large   Language Models - [[Arxiv](https://arxiv.org/abs/2305.18507)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18507.md)]
- Pre-training Contextualized World Models with In-the-wild Videos for   Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2305.18499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18499.md)]
- BigTranslate: Augmenting Large Language Models with Multilingual   Translation Capability over 100 Languages - [[Arxiv](https://arxiv.org/abs/2305.18098)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18098.md)]
- Make-An-Audio 2: Temporal-Enhanced Text-to-Audio Generation - [[Arxiv](https://arxiv.org/abs/2305.18474)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18474.md)]
- DiffRate : Differentiable Compression Rate for Efficient Vision   Transformers - [[Arxiv](https://arxiv.org/abs/2305.17997)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17997.md)]
- Learning Conditional Attributes for Compositional Zero-Shot Learning - [[Arxiv](https://arxiv.org/abs/2305.17940)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17940.md)]
- Efficient Storage of Fine-Tuned Models via Low-Rank Approximation of   Weight Residuals - [[Arxiv](https://arxiv.org/abs/2305.18425)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18425.md)]
- Geometric Algebra Transformers - [[Arxiv](https://arxiv.org/abs/2305.18415)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18415.md)]
- KAFA: Rethinking Image Ad Understanding with Knowledge-Augmented Feature   Adaptation of Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2305.18373)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18373.md)]
- Data Minimization at Inference Time - [[Arxiv](https://arxiv.org/abs/2305.17593)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17593.md)]
- Scalable Transformer for PDE Surrogate Modeling - [[Arxiv](https://arxiv.org/abs/2305.17560)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17560.md)]
- The Curse of Recursion: Training on Generated Data Makes Models Forget - [[Arxiv](https://arxiv.org/abs/2305.17493)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17493.md)]
- What can Large Language Models do in chemistry? A comprehensive   benchmark on eight tasks - [[Arxiv](https://arxiv.org/abs/2305.18365)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18365.md)]
- SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex   Interactive Tasks - [[Arxiv](https://arxiv.org/abs/2305.17390)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17390.md)]
- MPCHAT: Towards Multimodal Persona-Grounded Conversation - [[Arxiv](https://arxiv.org/abs/2305.17388)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17388.md)]
- Augmenting Large Language Model Translators via Translation Memories - [[Arxiv](https://arxiv.org/abs/2305.17367)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17367.md)]
- DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of   GPT-Generated Text - [[Arxiv](https://arxiv.org/abs/2305.17359)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17359.md)]
- Fine-Tuning Language Models with Just Forward Passes - [[Arxiv](https://arxiv.org/abs/2305.17333)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17333.md)]
- Beyond Positive Scaling: How Negation Impacts Scaling Trends of Language   Models - [[Arxiv](https://arxiv.org/abs/2305.17311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17311.md)]
- Chain-of-Thought Hub: A Continuous Effort to Measure Large Language   Models' Reasoning Performance - [[Arxiv](https://arxiv.org/abs/2305.17306)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17306.md)]
- SQL-PaLM: Improved Large Language Model Adaptation for Text-to-SQL - [[Arxiv](https://arxiv.org/abs/2306.00739)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.00739.md)]
- Generating Images with Multimodal Language Models - [[Arxiv](https://arxiv.org/abs/2305.17216)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17216.md)]
- Large Language Models as Tool Makers - [[Arxiv](https://arxiv.org/abs/2305.17126)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17126.md)]
- Scissorhands: Exploiting the Persistence of Importance Hypothesis for   LLM KV Cache Compression at Test Time - [[Arxiv](https://arxiv.org/abs/2305.17118)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17118.md)]
- High-Fidelity Image Compression with Score-based Generative Models - [[Arxiv](https://arxiv.org/abs/2305.18231)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18231.md)]
- ControlVideo: Adding Conditional Control for One Shot Text-to-Video   Editing - [[Arxiv](https://arxiv.org/abs/2305.17098)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17098.md)]
- Mindstorms in Natural Language-Based Societies of Mind - [[Arxiv](https://arxiv.org/abs/2305.17066)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17066.md)]
- SOC: Semantic-Assisted Object Cluster for Referring Video Object   Segmentation - [[Arxiv](https://arxiv.org/abs/2305.17011)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17011.md)]
- Let the Flows Tell: Solving Graph Combinatorial Optimization Problems   with GFlowNets - [[Arxiv](https://arxiv.org/abs/2305.17010)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17010.md)]
- Three Towers: Flexible Contrastive Learning with Pretrained Image Models - [[Arxiv](https://arxiv.org/abs/2305.16999)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16999.md)]
- Inverse Dynamics Pretraining Learns Good Representations for Multitask   Imitation - [[Arxiv](https://arxiv.org/abs/2305.16985)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16985.md)]
- Training Socially Aligned Language Models in Simulated Human Society - [[Arxiv](https://arxiv.org/abs/2305.16960)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16960.md)]
- MixCE: Training Autoregressive Language Models by Mixing Forward and   Reverse Cross-Entropies - [[Arxiv](https://arxiv.org/abs/2305.16958)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16958.md)]
- On Evaluating Adversarial Robustness of Large Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2305.16934)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16934.md)]
- MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of   Thought Prompting - [[Arxiv](https://arxiv.org/abs/2305.16896)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16896.md)]
- Playing repeated games with Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.16867)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16867.md)]
- Randomized Positional Encodings Boost Length Generalization of   Transformers - [[Arxiv](https://arxiv.org/abs/2305.16843)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16843.md)]
- Selective Mixup Helps with Distribution Shifts, But Not (Only) because   of Mixup - [[Arxiv](https://arxiv.org/abs/2305.16817)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16817.md)]
- Do GPTs Produce Less Literal Translations? - [[Arxiv](https://arxiv.org/abs/2305.16806)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16806.md)]
- Multimodal Recommendation Dialog with Subjective Preference: A New   Challenge and Benchmark - [[Arxiv](https://arxiv.org/abs/2305.18212)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.18212.md)]
- A Closer Look at In-Context Learning under Distribution Shifts - [[Arxiv](https://arxiv.org/abs/2305.16704)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16704.md)]
- AdaPlanner: Adaptive Planning from Feedback with Language Models - [[Arxiv](https://arxiv.org/abs/2305.16653)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16653.md)]
- Impossible Distillation: from Low-Quality Model to High-Quality Dataset   &amp; Model for Summarization and Paraphrasing - [[Arxiv](https://arxiv.org/abs/2305.16635)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16635.md)]
- Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large   Language Models - [[Arxiv](https://arxiv.org/abs/2305.16582)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16582.md)]
- On the Tool Manipulation Capability of Open-source Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.16504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16504.md)]
- ZeroAvatar: Zero-shot 3D Avatar Generation from a Single Image - [[Arxiv](https://arxiv.org/abs/2305.16411)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16411.md)]
- Ghost in the Minecraft: Generally Capable Agents for Open-World   Environments via Large Language Models with Text-based Knowledge and Memory - [[Arxiv](https://arxiv.org/abs/2305.17144)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.17144.md)]
- Break-A-Scene: Extracting Multiple Concepts from a Single Image - [[Arxiv](https://arxiv.org/abs/2305.16311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16311.md)]
- Landmark Attention: Random-Access Infinite Context Length for   Transformers - [[Arxiv](https://arxiv.org/abs/2305.16300)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16300.md)]
- Voyager: An Open-Ended Embodied Agent with Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.16291)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16291.md)]
- DPOK: Reinforcement Learning for Fine-tuning Text-to-Image Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2305.16381)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16381.md)]
- Scaling Data-Constrained Language Models - [[Arxiv](https://arxiv.org/abs/2305.16264)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16264.md)]
- ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with   Variational Score Distillation - [[Arxiv](https://arxiv.org/abs/2305.16213)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16213.md)]
- Scan and Snap: Understanding Training Dynamics and Token Composition in   1-layer Transformer - [[Arxiv](https://arxiv.org/abs/2305.16380)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16380.md)]
- ChatBridge: Bridging Modalities with Large Language Model as a Language   Catalyst - [[Arxiv](https://arxiv.org/abs/2305.16103)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16103.md)]
- Role-Play with Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.16367)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16367.md)]
- On Architectural Compression of Text-to-Image Diffusion Models - [[Arxiv](https://arxiv.org/abs/2305.15798)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15798.md)]
- Custom-Edit: Text-Guided Image Editing with Customized Diffusion Models - [[Arxiv](https://arxiv.org/abs/2305.15779)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15779.md)]
- On the Planning Abilities of Large Language Models -- A Critical   Investigation - [[Arxiv](https://arxiv.org/abs/2305.15771)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15771.md)]
- Efficient Neural Music Generation - [[Arxiv](https://arxiv.org/abs/2305.15719)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15719.md)]
- The False Promise of Imitating Proprietary LLMs - [[Arxiv](https://arxiv.org/abs/2305.15717)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15717.md)]
- CUEING: a lightweight model to Capture hUman attEntion In driviNG - [[Arxiv](https://arxiv.org/abs/2305.15710)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15710.md)]
- PandaGPT: One Model To Instruction-Follow Them All - [[Arxiv](https://arxiv.org/abs/2305.16355)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16355.md)]
- Frame-Event Alignment and Fusion Network for High Frame Rate Tracking - [[Arxiv](https://arxiv.org/abs/2305.15688)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15688.md)]
- Manifold Diffusion Fields - [[Arxiv](https://arxiv.org/abs/2305.15586)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15586.md)]
- Unsupervised Semantic Correspondence Using Stable Diffusion - [[Arxiv](https://arxiv.org/abs/2305.15581)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15581.md)]
- Task-aware Distributed Source Coding under Dynamic Bandwidth - [[Arxiv](https://arxiv.org/abs/2305.15523)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15523.md)]
- Lexinvariant Language Models - [[Arxiv](https://arxiv.org/abs/2305.16349)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16349.md)]
- SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and   Reasoning - [[Arxiv](https://arxiv.org/abs/2305.15486)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15486.md)]
- LayoutGPT: Compositional Visual Planning and Generation with Large   Language Models - [[Arxiv](https://arxiv.org/abs/2305.15393)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15393.md)]
- Learning high-level visual representations from a child's perspective   without strong inductive biases - [[Arxiv](https://arxiv.org/abs/2305.15372)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15372.md)]
- Gorilla: Large Language Model Connected with Massive APIs - [[Arxiv](https://arxiv.org/abs/2305.15334)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15334.md)]
- Visual Programming for Text-to-Image Generation and Evaluation - [[Arxiv](https://arxiv.org/abs/2305.15328)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15328.md)]
- Enhancing Retrieval-Augmented Large Language Models with Iterative   Retrieval-Generation Synergy - [[Arxiv](https://arxiv.org/abs/2305.15294)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15294.md)]
- ViTMatte: Boosting Image Matting with Pretrained Plain Vision   Transformers - [[Arxiv](https://arxiv.org/abs/2305.15272)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15272.md)]
- Revisiting Parallel Context Windows: A Frustratingly Simple Alternative   and Chain-of-Thought Deterioration - [[Arxiv](https://arxiv.org/abs/2305.15262)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15262.md)]
- Spoken Question Answering and Speech Continuation Using   Spectrogram-Powered LLM - [[Arxiv](https://arxiv.org/abs/2305.15255)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15255.md)]
- Adaptive Policy Learning to Additional Tasks - [[Arxiv](https://arxiv.org/abs/2305.15193)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15193.md)]
- Policy Learning based on Deep Koopman Representation - [[Arxiv](https://arxiv.org/abs/2305.15188)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15188.md)]
- Semantic-Enhanced Differentiable Search Index Inspired by Learning   Strategies - [[Arxiv](https://arxiv.org/abs/2305.15115)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15115.md)]
- Dynamic Masking Rate Schedules for MLM Pretraining - [[Arxiv](https://arxiv.org/abs/2305.15096)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15096.md)]
- Cream: Visually-Situated Natural Language Understanding with Contrastive   Reading Model and Frozen Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.15080)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15080.md)]
- Is GPT-4 a Good Data Analyst? - [[Arxiv](https://arxiv.org/abs/2305.15038)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15038.md)]
- Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large   Language Models - [[Arxiv](https://arxiv.org/abs/2305.15023)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15023.md)]
- EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought - [[Arxiv](https://arxiv.org/abs/2305.15021)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.15021.md)]
- Reasoning with Language Model is Planning with World Model - [[Arxiv](https://arxiv.org/abs/2305.14992)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14992.md)]
- IdealGPT: Iteratively Decomposing Vision and Language Reasoning via   Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.14985)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14985.md)]
- Benchmarking Arabic AI with Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.14982)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14982.md)]
- Assessment of the Reliablity of a Model's Decision by Generalizing   Attribution to the Wavelet Domain - [[Arxiv](https://arxiv.org/abs/2305.14979)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14979.md)]
- Discriminator-Guided Multi-step Reasoning with Language Models - [[Arxiv](https://arxiv.org/abs/2305.14934)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14934.md)]
- Chain-of-Questions Training with Latent Answers for Robust Multistep   Question Answering - [[Arxiv](https://arxiv.org/abs/2305.14901)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14901.md)]
- Leveraging GPT-4 for Automatic Translation Post-Editing - [[Arxiv](https://arxiv.org/abs/2305.14878)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14878.md)]
- PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and   Compositional Experts - [[Arxiv](https://arxiv.org/abs/2305.14839)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14839.md)]
- Adapting Language Models to Compress Contexts - [[Arxiv](https://arxiv.org/abs/2305.14788)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14788.md)]
- Instructions as Backdoors: Backdoor Vulnerabilities of Instruction   Tuning for Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.14710)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14710.md)]
- ExpertPrompting: Instructing Large Language Models to be Distinguished   Experts - [[Arxiv](https://arxiv.org/abs/2305.14688)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14688.md)]
- Barkour: Benchmarking Animal-level Agility with Quadruped Robots - [[Arxiv](https://arxiv.org/abs/2305.14654)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14654.md)]
- Enabling Large Language Models to Generate Text with Citations - [[Arxiv](https://arxiv.org/abs/2305.14627)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14627.md)]
- Think Before You Act: Decision Transformers with Internal Working Memory - [[Arxiv](https://arxiv.org/abs/2305.16338)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16338.md)]
- Attentiveness to Answer Choices Doesn't Always Entail High QA Accuracy - [[Arxiv](https://arxiv.org/abs/2305.14596)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14596.md)]
- PEARL: Prompting Large Language Models to Plan and Execute Actions Over   Long Documents - [[Arxiv](https://arxiv.org/abs/2305.14564)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14564.md)]
- LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond - [[Arxiv](https://arxiv.org/abs/2305.14540)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14540.md)]
- Self-Polish: Enhance Reasoning in Large Language Models via Problem   Refinement - [[Arxiv](https://arxiv.org/abs/2305.14497)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14497.md)]
- Siamese Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2305.14344)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14344.md)]
- Video Prediction Models as Rewards for Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2305.14343)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14343.md)]
- Automatic Model Selection with Large Language Models for Reasoning - [[Arxiv](https://arxiv.org/abs/2305.14333)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14333.md)]
- Improving Factuality and Reasoning in Language Models through Multiagent   Debate - [[Arxiv](https://arxiv.org/abs/2305.14325)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14325.md)]
- ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large   Language Models - [[Arxiv](https://arxiv.org/abs/2305.14323)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14323.md)]
- RET-LLM: Towards a General Read-Write Memory for Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.14322)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14322.md)]
- CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning   of Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.14318)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14318.md)]
- QLoRA: Efficient Finetuning of Quantized LLMs - [[Arxiv](https://arxiv.org/abs/2305.14314)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14314.md)]
- On Learning to Summarize with Large Language Models as References - [[Arxiv](https://arxiv.org/abs/2305.14239)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14239.md)]
- REC-MV: REconstructing 3D Dynamic Cloth from Monocular Videos - [[Arxiv](https://arxiv.org/abs/2305.14236)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14236.md)]
- Enhancing Chat Language Models by Scaling High-quality Instructional   Conversations - [[Arxiv](https://arxiv.org/abs/2305.14233)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14233.md)]
- Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks - [[Arxiv](https://arxiv.org/abs/2305.14201)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14201.md)]
- DetGPT: Detect What You Need via Reasoning - [[Arxiv](https://arxiv.org/abs/2305.14167)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14167.md)]
- Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video   Infilling and Prediction - [[Arxiv](https://arxiv.org/abs/2305.13903)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13903.md)]
- PaD: Program-aided Distillation Specializes Large Models in Reasoning - [[Arxiv](https://arxiv.org/abs/2305.13888)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13888.md)]
- OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities - [[Arxiv](https://arxiv.org/abs/2305.16334)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.16334.md)]
- MIANet: Aggregating Unbiased Instance and General Information for   Few-Shot Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2305.13864)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13864.md)]
- Control-A-Video: Controllable Text-to-Video Generation with Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2305.13840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13840.md)]
- Can Large Language Models Infer and Disagree Like Humans? - [[Arxiv](https://arxiv.org/abs/2305.13788)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13788.md)]
- Perception Test: A Diagnostic Benchmark for Multimodal Video Models - [[Arxiv](https://arxiv.org/abs/2305.13786)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13786.md)]
- Images in Language Space: Exploring the Suitability of Large Language   Models for Vision &amp; Language Tasks - [[Arxiv](https://arxiv.org/abs/2305.13782)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13782.md)]
- Aligning Large Language Models through Synthetic Feedback - [[Arxiv](https://arxiv.org/abs/2305.13735)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13735.md)]
- Text Is All You Need: Learning Language Representations for Sequential   Recommendation - [[Arxiv](https://arxiv.org/abs/2305.13731)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13731.md)]
- Prompting and Evaluating Large Language Models for Proactive Dialogues:   Clarification, Target-guided, and Non-collaboration - [[Arxiv](https://arxiv.org/abs/2305.13626)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13626.md)]
- Not All Image Regions Matter: Masked Vector Quantization for   Autoregressive Image Generation - [[Arxiv](https://arxiv.org/abs/2305.13607)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13607.md)]
- Transformer-based Vulnerability Detection in Code at EditTime:   Zero-shot, Few-shot, or Fine-tuning? - [[Arxiv](https://arxiv.org/abs/2306.01754)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01754.md)]
- Enhancing Detail Preservation for Customized Text-to-Image Generation: A   Regularization-Free Approach - [[Arxiv](https://arxiv.org/abs/2305.13579)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13579.md)]
- How Language Model Hallucinations Can Snowball - [[Arxiv](https://arxiv.org/abs/2305.13534)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13534.md)]
- RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text - [[Arxiv](https://arxiv.org/abs/2305.13304)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13304.md)]
- Training Diffusion Models with Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2305.13301)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13301.md)]
- Chain-of-Knowledge: Grounding Large Language Models via Dynamic   Knowledge Adapting over Heterogeneous Sources - [[Arxiv](https://arxiv.org/abs/2305.13269)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13269.md)]
- "According to ..." Prompting Language Models Improves Quoting from   Pre-Training Data - [[Arxiv](https://arxiv.org/abs/2305.13252)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13252.md)]
- Interactive Natural Language Processing - [[Arxiv](https://arxiv.org/abs/2305.13246)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13246.md)]
- Fast Monocular Scene Reconstruction with Global-Sparse Local-Dense Grids - [[Arxiv](https://arxiv.org/abs/2305.13220)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13220.md)]
- LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities   and Future Opportunities - [[Arxiv](https://arxiv.org/abs/2305.13168)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13168.md)]
- ControlVideo: Training-free Controllable Text-to-Video Generation - [[Arxiv](https://arxiv.org/abs/2305.13077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13077.md)]
- Making Language Models Better Tool Learners with Execution Feedback - [[Arxiv](https://arxiv.org/abs/2305.13068)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13068.md)]
- AudioToken: Adaptation of Text-Conditioned Diffusion Models for   Audio-to-Image Generation - [[Arxiv](https://arxiv.org/abs/2305.13050)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13050.md)]
- RWKV: Reinventing RNNs for the Transformer Era - [[Arxiv](https://arxiv.org/abs/2305.13048)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13048.md)]
- Textually Pretrained Speech Language Models - [[Arxiv](https://arxiv.org/abs/2305.13009)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.13009.md)]
- Connecting Multi-modal Contrastive Representations - [[Arxiv](https://arxiv.org/abs/2305.14381)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.14381.md)]
- Boosting Long-tailed Object Detection via Step-wise Learning on   Smooth-tail Data - [[Arxiv](https://arxiv.org/abs/2305.12833)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.12833.md)]
- Keeping Up with the Language Models: Robustness-Bias Interplay in NLI   Data and Models - [[Arxiv](https://arxiv.org/abs/2305.12620)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.12620.md)]
- GMD: Controllable Human Motion Synthesis via Guided Diffusion Models - [[Arxiv](https://arxiv.org/abs/2305.12577)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.12577.md)]
- Conditional Generative Modeling for High-dimensional Marked Temporal   Point Processes - [[Arxiv](https://arxiv.org/abs/2305.12569)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.12569.md)]
- Augmenting Autotelic Agents with Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.12487)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.12487.md)]
- Advancing Referring Expression Segmentation Beyond Single Image - [[Arxiv](https://arxiv.org/abs/2305.12452)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.12452.md)]
- PiVe: Prompting with Iterative Verification Improving Graph-based   Generative Capability of LLMs - [[Arxiv](https://arxiv.org/abs/2305.12392)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.12392.md)]
- Collaborative Development of NLP models - [[Arxiv](https://arxiv.org/abs/2305.12219)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.12219.md)]
- Text-Video Retrieval with Disentangled Conceptualization and Set-to-Set   Alignment - [[Arxiv](https://arxiv.org/abs/2305.12218)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.12218.md)]
- CodeCompose: A Large-Scale Industrial Deployment of AI-assisted Code   Authoring - [[Arxiv](https://arxiv.org/abs/2305.12050)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.12050.md)]
- OPT-R: Exploring the Role of Explanations in Finetuning and Prompting   for Reasoning Skills of Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.12001)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.12001.md)]
- Exploring the Viability of Synthetic Query Generation for Relevance   Prediction - [[Arxiv](https://arxiv.org/abs/2305.11944)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11944.md)]
- XTREME-UP: A User-Centric Scarce-Data Benchmark for Under-Represented   Languages - [[Arxiv](https://arxiv.org/abs/2305.11938)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11938.md)]
- Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D   Diffusion Probabilistic Models - [[Arxiv](https://arxiv.org/abs/2305.11870)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11870.md)]
- Scaling laws for language encoding models in fMRI - [[Arxiv](https://arxiv.org/abs/2305.11863)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11863.md)]
- Multimodal Web Navigation with Instruction-Finetuned Foundation Models - [[Arxiv](https://arxiv.org/abs/2305.11854)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11854.md)]
- Any-to-Any Generation via Composable Diffusion - [[Arxiv](https://arxiv.org/abs/2305.11846)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11846.md)]
- How Does Generative Retrieval Scale to Millions of Passages? - [[Arxiv](https://arxiv.org/abs/2305.11841)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11841.md)]
- SeeGULL: A Stereotype Benchmark with Broad Geo-Cultural Coverage   Leveraging Generative Models - [[Arxiv](https://arxiv.org/abs/2305.11840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11840.md)]
- Comparing Software Developers with ChatGPT: An Empirical Investigation - [[Arxiv](https://arxiv.org/abs/2305.11837)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11837.md)]
- Pengi: An Audio Language Model for Audio Tasks - [[Arxiv](https://arxiv.org/abs/2305.11834)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11834.md)]
- Prompting with Pseudo-Code Instructions - [[Arxiv](https://arxiv.org/abs/2305.11790)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11790.md)]
- Cross-Lingual Supervision improves Large Language Models Pre-training - [[Arxiv](https://arxiv.org/abs/2305.11778)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11778.md)]
- Neural Foundations of Mental Simulation: Future Prediction of Latent   Representations on Dynamic Scenes - [[Arxiv](https://arxiv.org/abs/2305.11772)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11772.md)]
- Controlling the Extraction of Memorized Data from Large Language Models   via Prompt-Tuning - [[Arxiv](https://arxiv.org/abs/2305.11759)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11759.md)]
- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive   Critiquing - [[Arxiv](https://arxiv.org/abs/2305.11738)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11738.md)]
- QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set   Operations - [[Arxiv](https://arxiv.org/abs/2305.11694)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11694.md)]
- Learning Global-aware Kernel for Image Harmonization - [[Arxiv](https://arxiv.org/abs/2305.11676)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11676.md)]
- Cinematic Mindscapes: High-quality Video Reconstruction from Brain   Activity - [[Arxiv](https://arxiv.org/abs/2305.11675)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11675.md)]
- Introspective Tips: Large Language Model for In-Context Decision Making - [[Arxiv](https://arxiv.org/abs/2305.11598)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11598.md)]
- Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2305.11588)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11588.md)]
- ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via   Tool Embeddings - [[Arxiv](https://arxiv.org/abs/2305.11554)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11554.md)]
- Empower Large Language Model to Perform Better on Industrial   Domain-Specific Question Answering - [[Arxiv](https://arxiv.org/abs/2305.11541)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11541.md)]
- RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by   Reversing Chain-of-Thought - [[Arxiv](https://arxiv.org/abs/2305.11499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11499.md)]
- AttriCLIP: A Non-Incremental Learner for Incremental Knowledge Learning - [[Arxiv](https://arxiv.org/abs/2305.11488)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11488.md)]
- PointGPT: Auto-regressively Generative Pre-training from Point Clouds - [[Arxiv](https://arxiv.org/abs/2305.11487)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11487.md)]
- Enhancing Personalized Dialogue Generation with Contrastive Latent   Variables: Combining Sparse and Dense Persona - [[Arxiv](https://arxiv.org/abs/2305.11482)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11482.md)]
- Towards Human-AI Collaborative Urban Science Research Enabled by   Pre-trained Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.11418)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11418.md)]
- Visualizing Linguistic Diversity of Text Datasets Synthesized by Large   Language Models - [[Arxiv](https://arxiv.org/abs/2305.11364)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11364.md)]
- RoomDreamer: Text-Driven 3D Indoor Scene Synthesis with Coherent   Geometry and Texture - [[Arxiv](https://arxiv.org/abs/2305.11337)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11337.md)]
- Counterfactuals for Design: A Model-Agnostic Method For Design   Recommendations - [[Arxiv](https://arxiv.org/abs/2305.11308)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11308.md)]
- Towards Collaborative Plan Acquisition through Theory of Mind Modeling   in Situated Dialogue - [[Arxiv](https://arxiv.org/abs/2305.11271)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11271.md)]
- Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions   with Large Language Model - [[Arxiv](https://arxiv.org/abs/2305.11176)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11176.md)]
- VisionLLM: Large Language Model is also an Open-Ended Decoder for   Vision-Centric Tasks - [[Arxiv](https://arxiv.org/abs/2305.11175)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11175.md)]
- Going Denser with Open-Vocabulary Part Segmentation - [[Arxiv](https://arxiv.org/abs/2305.11173)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11173.md)]
- TrueTeacher: Learning Factual Consistency Evaluation with Large Language   Models - [[Arxiv](https://arxiv.org/abs/2305.11171)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11171.md)]
- Evidence of Meaning in Language Models Trained on Programs - [[Arxiv](https://arxiv.org/abs/2305.11169)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11169.md)]
- TOME: A Two-stage Approach for Model-based Retrieval - [[Arxiv](https://arxiv.org/abs/2305.11161)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11161.md)]
- LIMA: Less Is More for Alignment - [[Arxiv](https://arxiv.org/abs/2305.11206)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11206.md)]
- UniControl: A Unified Diffusion Model for Controllable Visual Generation   In the Wild - [[Arxiv](https://arxiv.org/abs/2305.11147)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11147.md)]
- SimOAP: Improve Coherence and Consistency in Persona-based Dialogue   Generation via Over-sampling and Post-evaluation - [[Arxiv](https://arxiv.org/abs/2305.11130)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11130.md)]
- mLongT5: A Multilingual and Efficient Text-To-Text Transformer for   Longer Sequences - [[Arxiv](https://arxiv.org/abs/2305.11129)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11129.md)]
- LLMScore: Unveiling the Power of Large Language Models in Text-to-Image   Synthesis Evaluation - [[Arxiv](https://arxiv.org/abs/2305.11116)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11116.md)]
- PDP: Parameter-free Differentiable Pruning is All You Need - [[Arxiv](https://arxiv.org/abs/2305.11203)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11203.md)]
- DrugChat: Towards Enabling ChatGPT-Like Capabilities on Drug Molecule   Graphs - [[Arxiv](https://arxiv.org/abs/2309.03907)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2309.03907.md)]
- Inspecting the Geographical Representativeness of Images from   Text-to-Image Models - [[Arxiv](https://arxiv.org/abs/2305.11080)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11080.md)]
- SDC-UDA: Volumetric Unsupervised Domain Adaptation Framework for   Slice-Direction Continuous Cross-Modality Medical Image Segmentation - [[Arxiv](https://arxiv.org/abs/2305.11012)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11012.md)]
- SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal   Conversational Abilities - [[Arxiv](https://arxiv.org/abs/2305.11000)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.11000.md)]
- Drag Your GAN: Interactive Point-based Manipulation on the Generative   Image Manifold - [[Arxiv](https://arxiv.org/abs/2305.10973)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10973.md)]
- An Android Robot Head as Embodied Conversational Agent - [[Arxiv](https://arxiv.org/abs/2305.10945)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10945.md)]
- A Generalist Dynamics Model for Control - [[Arxiv](https://arxiv.org/abs/2305.10912)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10912.md)]
- VideoFactory: Swap Attention in Spatiotemporal Diffusions for   Text-to-Video Generation - [[Arxiv](https://arxiv.org/abs/2305.10874)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10874.md)]
- TextDiffuser: Diffusion Models as Text Painters - [[Arxiv](https://arxiv.org/abs/2305.10855)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10855.md)]
- 3D Registration with Maximal Cliques - [[Arxiv](https://arxiv.org/abs/2305.10854)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10854.md)]
- LDM3D: Latent Diffusion Model for 3D - [[Arxiv](https://arxiv.org/abs/2305.10853)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10853.md)]
- GETMusic: Generating Any Music Tracks with a Unified Representation and   Diffusion Framework - [[Arxiv](https://arxiv.org/abs/2305.10841)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10841.md)]
- Listen, Think, and Understand - [[Arxiv](https://arxiv.org/abs/2305.10790)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10790.md)]
- OpenShape: Scaling Up 3D Shape Representation Towards Open-World   Understanding - [[Arxiv](https://arxiv.org/abs/2305.10764)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10764.md)]
- CLAPSpeech: Learning Prosody from Text Context with Contrastive   Language-Audio Pre-training - [[Arxiv](https://arxiv.org/abs/2305.10763)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10763.md)]
- Boost Vision Transformer with GPU-Friendly Sparsity and Quantization - [[Arxiv](https://arxiv.org/abs/2305.10727)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10727.md)]
- Discriminative Diffusion Models as Few-shot Vision and Language Learners - [[Arxiv](https://arxiv.org/abs/2305.10722)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10722.md)]
- Zero-Day Backdoor Attack against Text-to-Image Diffusion Models via   Personalization - [[Arxiv](https://arxiv.org/abs/2305.10701)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10701.md)]
- MolXPT: Wrapping Molecules with Text for Generative Pre-training - [[Arxiv](https://arxiv.org/abs/2305.10688)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10688.md)]
- Language Models Meet World Models: Embodied Experiences Enhance Language   Models - [[Arxiv](https://arxiv.org/abs/2305.10626)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10626.md)]
- Tree of Thoughts: Deliberate Problem Solving with Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.10601)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10601.md)]
- Instruction Tuned Models are Quick Learners - [[Arxiv](https://arxiv.org/abs/2306.05539)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.05539.md)]
- IMAD: IMage-Augmented multi-modal Dialogue - [[Arxiv](https://arxiv.org/abs/2305.10512)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10512.md)]
- FastComposer: Tuning-Free Multi-Subject Image Generation with Localized   Attention - [[Arxiv](https://arxiv.org/abs/2305.10431)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10431.md)]
- Preserve Your Own Correlation: A Noise Prior for Video Diffusion Models - [[Arxiv](https://arxiv.org/abs/2305.10474)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10474.md)]
- DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining - [[Arxiv](https://arxiv.org/abs/2305.10429)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10429.md)]
- SLiC-HF: Sequence Likelihood Calibration with Human Feedback - [[Arxiv](https://arxiv.org/abs/2305.10425)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10425.md)]
- PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering - [[Arxiv](https://arxiv.org/abs/2305.10415)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10415.md)]
- PaLM 2 Technical Report - [[Arxiv](https://arxiv.org/abs/2305.10403)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10403.md)]
- What You See is What You Read? Improving Text-Image Alignment Evaluation - [[Arxiv](https://arxiv.org/abs/2305.10400)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10400.md)]
- Elaborative Simplification as Implicit Questions Under Discussion - [[Arxiv](https://arxiv.org/abs/2305.10387)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10387.md)]
- Evaluating Object Hallucination in Large Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2305.10355)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10355.md)]
- CostFormer:Cost Transformer for Cost Aggregation in Multi-view Stereo - [[Arxiv](https://arxiv.org/abs/2305.10320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10320.md)]
- Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models - [[Arxiv](https://arxiv.org/abs/2305.10276)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10276.md)]
- Searching for Needles in a Haystack: On the Role of Incidental   Bilingualism in PaLM's Translation Capability - [[Arxiv](https://arxiv.org/abs/2305.10266)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10266.md)]
- MemoryBank: Enhancing Large Language Models with Long-Term Memory - [[Arxiv](https://arxiv.org/abs/2305.10250)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10250.md)]
- Knowledge-enhanced Mixed-initiative Dialogue System for Emotional   Support Conversations - [[Arxiv](https://arxiv.org/abs/2305.10172)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10172.md)]
- Improving Language Model Negotiation with Self-Play and In-Context   Learning from AI Feedback - [[Arxiv](https://arxiv.org/abs/2305.10142)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10142.md)]
- Transfer Learning for Fine-grained Classification Using Semi-supervised   Learning and Visual Transformers - [[Arxiv](https://arxiv.org/abs/2305.10018)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10018.md)]
- EfficientSCI: Densely Connected Network with Space-time Factorization   for Large-scale Video Snapshot Compressive Imaging - [[Arxiv](https://arxiv.org/abs/2305.10006)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10006.md)]
- DinoSR: Self-Distillation and Online Clustering for Self-supervised   Speech Representation Learning - [[Arxiv](https://arxiv.org/abs/2305.10005)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10005.md)]
- Dual Semantic Knowledge Composed Multimodal Dialog Systems - [[Arxiv](https://arxiv.org/abs/2305.09990)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09990.md)]
- Smart Word Suggestions for Writing Assistance - [[Arxiv](https://arxiv.org/abs/2305.09975)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09975.md)]
- Towards Generalist Robots: A Promising Paradigm via Generative   Simulation - [[Arxiv](https://arxiv.org/abs/2305.10455)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10455.md)]
- Explaining black box text modules in natural language with language   models - [[Arxiv](https://arxiv.org/abs/2305.09863)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09863.md)]
- CoEdIT: Text Editing by Task-Specific Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2305.09857)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09857.md)]
- ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to   Support Human-AI Scientific Writing - [[Arxiv](https://arxiv.org/abs/2305.09770)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09770.md)]
- Application-Agnostic Language Modeling for On-Device ASR - [[Arxiv](https://arxiv.org/abs/2305.09764)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09764.md)]
- NerfBridge: Bringing Real-time, Online Neural Radiance Field Training to   Robotics - [[Arxiv](https://arxiv.org/abs/2305.09761)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09761.md)]
- A Video Is Worth 4096 Tokens: Verbalize Story Videos To Understand Them   In Zero Shot - [[Arxiv](https://arxiv.org/abs/2305.09758)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09758.md)]
- Understanding 3D Object Interaction from a Single Image - [[Arxiv](https://arxiv.org/abs/2305.09664)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09664.md)]
- Make-An-Animation: Large-Scale Text-conditional 3D Human Motion   Generation - [[Arxiv](https://arxiv.org/abs/2305.09662)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09662.md)]
- FitMe: Deep Photorealistic 3D Morphable Model Avatars - [[Arxiv](https://arxiv.org/abs/2305.09641)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09641.md)]
- SoundStorm: Efficient Parallel Audio Generation - [[Arxiv](https://arxiv.org/abs/2305.09636)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09636.md)]
- Towards Expert-Level Medical Question Answering with Large Language   Models - [[Arxiv](https://arxiv.org/abs/2305.09617)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09617.md)]
- Large Language Models are Built-in Autoregressive Search Engines - [[Arxiv](https://arxiv.org/abs/2305.09612)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09612.md)]
- Cooperation Is All You Need - [[Arxiv](https://arxiv.org/abs/2305.10449)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10449.md)]
- AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation - [[Arxiv](https://arxiv.org/abs/2305.09515)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09515.md)]
- Online Continual Learning Without the Storage Constraint - [[Arxiv](https://arxiv.org/abs/2305.09253)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09253.md)]
- Mobile User Interface Element Detection Via Adaptively Prompt Tuning - [[Arxiv](https://arxiv.org/abs/2305.09699)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09699.md)]
- Dual-Alignment Pre-training for Cross-lingual Sentence Embedding - [[Arxiv](https://arxiv.org/abs/2305.09148)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09148.md)]
- Pre-Training to Learn in Context - [[Arxiv](https://arxiv.org/abs/2305.09137)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09137.md)]
- SuSana Distancia is all you need: Enforcing class separability in metric   learning via two novel distance-based loss functions for few-shot image   classification - [[Arxiv](https://arxiv.org/abs/2305.09062)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.09062.md)]
- MV-Map: Offboard HD-Map Generation with Multi-view Consistency - [[Arxiv](https://arxiv.org/abs/2305.08851)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08851.md)]
- Make-A-Protagonist: Generic Video Editing with An Ensemble of Experts - [[Arxiv](https://arxiv.org/abs/2305.08850)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08850.md)]
- Small Models are Valuable Plug-ins for Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.08848)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08848.md)]
- RL4F: Generating Natural Language Feedback with Reinforcement Learning   for Repairing Model Outputs - [[Arxiv](https://arxiv.org/abs/2305.08844)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08844.md)]
- Straightening Out the Straight-Through Estimator: Overcoming   Optimization Challenges in Vector Quantized Networks - [[Arxiv](https://arxiv.org/abs/2305.08842)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08842.md)]
- Attacking Perceptual Similarity Metrics - [[Arxiv](https://arxiv.org/abs/2305.08840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08840.md)]
- AutoRecon: Automated 3D Object Discovery and Reconstruction - [[Arxiv](https://arxiv.org/abs/2305.08810)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08810.md)]
- Interpretability at Scale: Identifying Causal Mechanisms in Alpaca - [[Arxiv](https://arxiv.org/abs/2305.08809)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08809.md)]
- GeoMAE: Masked Geometric Target Prediction for Self-supervised Point   Cloud Pre-Training - [[Arxiv](https://arxiv.org/abs/2305.08808)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08808.md)]
- A Reproducible Extraction of Training Images from Diffusion Models - [[Arxiv](https://arxiv.org/abs/2305.08694)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08694.md)]
- Natural Language Decomposition and Interpretation of Complex Utterances - [[Arxiv](https://arxiv.org/abs/2305.08677)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08677.md)]
- DarkBERT: A Language Model for the Dark Side of the Internet - [[Arxiv](https://arxiv.org/abs/2305.08596)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08596.md)]
- Common Diffusion Noise Schedules and Sample Steps are Flawed - [[Arxiv](https://arxiv.org/abs/2305.08891)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08891.md)]
- NIKI: Neural Inverse Kinematics with Invertible Neural Networks for 3D   Human Pose and Shape Estimation - [[Arxiv](https://arxiv.org/abs/2305.08590)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08590.md)]
- TESS: Text-to-Text Self-Conditioned Simplex Diffusion - [[Arxiv](https://arxiv.org/abs/2305.08379)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08379.md)]
- Inverse Rendering of Translucent Objects using Physical and Neural   Renderers - [[Arxiv](https://arxiv.org/abs/2305.08336)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08336.md)]
- Symbol tuning improves in-context learning in language models - [[Arxiv](https://arxiv.org/abs/2305.08298)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08298.md)]
- ULIP-2: Towards Scalable Multimodal Pre-training for 3D Understanding - [[Arxiv](https://arxiv.org/abs/2305.08275)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08275.md)]
- A Cognitive Stimulation Dialogue System with Multi-source Knowledge   Fusion for Elders with Cognitive Impairment - [[Arxiv](https://arxiv.org/abs/2305.08200)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.08200.md)]
- GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content - [[Arxiv](https://arxiv.org/abs/2305.07969)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07969.md)]
- Leveraging Large Language Models in Conversational Recommender Systems - [[Arxiv](https://arxiv.org/abs/2305.07961)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07961.md)]
- CodeT5+: Open Code Large Language Models for Code Understanding and   Generation - [[Arxiv](https://arxiv.org/abs/2305.07922)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07922.md)]
- Improving Small Language Models on PubMedQA via Generative Data   Augmentation - [[Arxiv](https://arxiv.org/abs/2305.07804)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07804.md)]
- ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain   Dialogue Systems - [[Arxiv](https://arxiv.org/abs/2305.07797)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07797.md)]
- TinyStories: How Small Can Language Models Be and Still Speak Coherent   English? - [[Arxiv](https://arxiv.org/abs/2305.07759)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07759.md)]
- In Search of Verifiability: Explanations Rarely Enable Complementary   Performance in AI-Advised Decision Making - [[Arxiv](https://arxiv.org/abs/2305.07722)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07722.md)]
- Meta Omnium: A Benchmark for General-Purpose Learning-to-Learn - [[Arxiv](https://arxiv.org/abs/2305.07625)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07625.md)]
- What are the Desired Characteristics of Calibration Sets? Identifying   Correlates on Long Form Scientific Summarization - [[Arxiv](https://arxiv.org/abs/2305.07615)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07615.md)]
- Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large   Language Model Recommendation - [[Arxiv](https://arxiv.org/abs/2305.07609)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07609.md)]
- Measuring Progress in Fine-grained Vision-and-Language Understanding - [[Arxiv](https://arxiv.org/abs/2305.07558)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07558.md)]
- BlendFields: Few-Shot Example-Driven Facial Modeling - [[Arxiv](https://arxiv.org/abs/2305.07514)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07514.md)]
- ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced   MiniGPT-4 - [[Arxiv](https://arxiv.org/abs/2305.07490)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07490.md)]
- Surfacing Biases in Large Language Models using Contrastive Input   Decoding - [[Arxiv](https://arxiv.org/abs/2305.07378)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07378.md)]
- Better speech synthesis through scaling - [[Arxiv](https://arxiv.org/abs/2305.07243)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07243.md)]
- MMG-Ego4D: Multi-Modal Generalization in Egocentric Action Recognition - [[Arxiv](https://arxiv.org/abs/2305.07214)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07214.md)]
- MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers - [[Arxiv](https://arxiv.org/abs/2305.07185)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07185.md)]
- Masked Audio Text Encoders are Effective Multi-Modal Rescorers - [[Arxiv](https://arxiv.org/abs/2305.07677)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07677.md)]
- Towards best practices in AGI safety and governance: A survey of expert   opinion - [[Arxiv](https://arxiv.org/abs/2305.07153)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07153.md)]
- EfficientViT: Memory Efficient Vision Transformer with Cascaded Group   Attention - [[Arxiv](https://arxiv.org/abs/2305.07027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07027.md)]
- Simple Token-Level Confidence Improves Caption Correctness - [[Arxiv](https://arxiv.org/abs/2305.07021)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07021.md)]
- An Inverse Scaling Law for CLIP Training - [[Arxiv](https://arxiv.org/abs/2305.07017)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07017.md)]
- Exploiting Diffusion Prior for Real-World Image Super-Resolution - [[Arxiv](https://arxiv.org/abs/2305.07015)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07015.md)]
- Region-Aware Pretraining for Open-Vocabulary Object Detection with   Vision Transformers - [[Arxiv](https://arxiv.org/abs/2305.07011)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07011.md)]
- Learning the Visualness of Text Using Large Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2305.10434)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.10434.md)]
- Not All Languages Are Created Equal in LLMs: Improving Multilingual   Capability by Cross-Lingual-Thought Prompting - [[Arxiv](https://arxiv.org/abs/2305.07004)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07004.md)]
- Universal Source Separation with Weakly Labelled Data - [[Arxiv](https://arxiv.org/abs/2305.07447)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07447.md)]
- CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency   Model - [[Arxiv](https://arxiv.org/abs/2305.06908)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06908.md)]
- A Category-theoretical Meta-analysis of Definitions of Disentanglement - [[Arxiv](https://arxiv.org/abs/2305.06886)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06886.md)]
- GCFAgg: Global and Cross-view Feature Aggregation for Multi-view   Clustering - [[Arxiv](https://arxiv.org/abs/2305.06799)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06799.md)]
- Optimizing Memory Mapping Using Deep Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2305.07440)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.07440.md)]
- Distracting Downpour: Adversarial Weather Attacks for Motion Estimation - [[Arxiv](https://arxiv.org/abs/2305.06716)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06716.md)]
- V2Meow: Meowing to the Visual Beat via Music Generation - [[Arxiv](https://arxiv.org/abs/2305.06594)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06594.md)]
- Chain-of-Dictionary Prompting Elicits Translation in Large Language   Models - [[Arxiv](https://arxiv.org/abs/2305.06575)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06575.md)]
- How to Index Item IDs for Recommendation Foundation Models - [[Arxiv](https://arxiv.org/abs/2305.06569)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06569.md)]
- Segment and Track Anything - [[Arxiv](https://arxiv.org/abs/2305.06558)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06558.md)]
- Domain Incremental Lifelong Learning in an Open World - [[Arxiv](https://arxiv.org/abs/2305.06555)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06555.md)]
- InstructBLIP: Towards General-purpose Vision-Language Models with   Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2305.06500)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06500.md)]
- Do LLMs Understand User Preferences? Evaluating LLMs On User Rating   Prediction - [[Arxiv](https://arxiv.org/abs/2305.06474)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06474.md)]
- Perpetual Humanoid Control for Real-time Simulated Avatars - [[Arxiv](https://arxiv.org/abs/2305.06456)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06456.md)]
- Bot or Human? Detecting ChatGPT Imposters with A Single Question - [[Arxiv](https://arxiv.org/abs/2305.06424)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06424.md)]
- LACoS-BLOOM: Low-rank Adaptation with Contrastive objective on 8 bits   Siamese-BLOOM - [[Arxiv](https://arxiv.org/abs/2305.06404)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06404.md)]
- HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion - [[Arxiv](https://arxiv.org/abs/2305.06356)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06356.md)]
- VideoChat: Chat-Centric Video Understanding - [[Arxiv](https://arxiv.org/abs/2305.06355)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06355.md)]
- Reconstructing Animatable Categories from Videos - [[Arxiv](https://arxiv.org/abs/2305.06351)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06351.md)]
- Alternating Gradient Descent and Mixture-of-Experts for Integrated   Multimodal Perception - [[Arxiv](https://arxiv.org/abs/2305.06324)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06324.md)]
- Summarizing, Simplifying, and Synthesizing Medical Evidence Using GPT-3   (with Varying Success) - [[Arxiv](https://arxiv.org/abs/2305.06299)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06299.md)]
- Generative AI meets 3D: A Survey on Text-to-3D in AIGC Era - [[Arxiv](https://arxiv.org/abs/2305.06131)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06131.md)]
- The Compositional Structure of Bayesian Inference - [[Arxiv](https://arxiv.org/abs/2305.06112)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06112.md)]
- Towards Effective Visual Representations for Partial-Label Learning - [[Arxiv](https://arxiv.org/abs/2305.06080)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06080.md)]
- Relightify: Relightable 3D Faces from a Single Image via Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2305.06077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06077.md)]
- GPT Models Meet Robotic Applications: Co-Speech Gesturing Chat System - [[Arxiv](https://arxiv.org/abs/2306.01741)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.01741.md)]
- Privacy-Preserving Recommender Systems with Synthetic Query Generation   using Differentially Private Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.05973)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05973.md)]
- Fast Distributed Inference Serving for Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.05920)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05920.md)]
- SHS-Net: Learning Signed Hyper Surfaces for Oriented Normal Estimation   of Point Clouds - [[Arxiv](https://arxiv.org/abs/2305.05873)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05873.md)]
- Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text   Analytics? A Study on Several Typical Tasks - [[Arxiv](https://arxiv.org/abs/2305.05862)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05862.md)]
- Sketching the Future (STF): Applying Conditional Control Techniques to   Text-to-Video Models - [[Arxiv](https://arxiv.org/abs/2305.05845)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05845.md)]
- Low-Light Image Enhancement via Structure Modeling and Guidance - [[Arxiv](https://arxiv.org/abs/2305.05839)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05839.md)]
- DexArt: Benchmarking Generalizable Dexterous Manipulation with   Articulated Objects - [[Arxiv](https://arxiv.org/abs/2305.05706)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05706.md)]
- InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT   Beyond Language - [[Arxiv](https://arxiv.org/abs/2305.05662)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05662.md)]
- TidyBot: Personalized Robot Assistance with Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.05658)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05658.md)]
- Towards Building the Federated GPT: Federated Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2305.05644)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05644.md)]
- AudioSlots: A slot-centric generative model for audio separation - [[Arxiv](https://arxiv.org/abs/2305.05591)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05591.md)]
- Recursions Are All You Need: Towards Efficient Deep Unfolding Networks - [[Arxiv](https://arxiv.org/abs/2305.05505)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05505.md)]
- WikiWeb2M: A Page-Level Multimodal Wikipedia Dataset - [[Arxiv](https://arxiv.org/abs/2305.05432)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05432.md)]
- Large Language Model Programs - [[Arxiv](https://arxiv.org/abs/2305.05364)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05364.md)]
- Dialogue Planning via Brownian Bridge Stochastic Process for   Goal-directed Proactive Dialogue - [[Arxiv](https://arxiv.org/abs/2305.05290)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05290.md)]
- Distilling Script Knowledge from Large Language Models for Constrained   Language Planning - [[Arxiv](https://arxiv.org/abs/2305.05252)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05252.md)]
- StarCoder: may the source be with you! - [[Arxiv](https://arxiv.org/abs/2305.06161)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06161.md)]
- SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with   Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.05189)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05189.md)]
- FrugalGPT: How to Use Large Language Models While Reducing Cost and   Improving Performance - [[Arxiv](https://arxiv.org/abs/2305.05176)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05176.md)]
- Knowledge-enhanced Agents for Interactive Text Games - [[Arxiv](https://arxiv.org/abs/2305.05091)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05091.md)]
- Multi-Task End-to-End Training Improves Conversational Recommendation - [[Arxiv](https://arxiv.org/abs/2305.06218)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.06218.md)]
- Recommender Systems with Generative Retrieval - [[Arxiv](https://arxiv.org/abs/2305.05065)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05065.md)]
- Revisiting Relation Extraction in the era of Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.05003)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05003.md)]
- NerfAcc: Efficient Sampling Accelerates NeRFs - [[Arxiv](https://arxiv.org/abs/2305.04966)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04966.md)]
- Influence of External Information on Large Language Models Mirrors   Social Cognitive Patterns - [[Arxiv](https://arxiv.org/abs/2305.04812)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04812.md)]
- MultiModal-GPT: A Vision and Language Model for Dialogue with Humans - [[Arxiv](https://arxiv.org/abs/2305.04790)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04790.md)]
- AvatarReX: Real-time Expressive Full-body Avatars - [[Arxiv](https://arxiv.org/abs/2305.04789)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04789.md)]
- Controllable Light Diffusion for Portraits - [[Arxiv](https://arxiv.org/abs/2305.04745)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04745.md)]
- Code Execution with Pre-trained Language Models - [[Arxiv](https://arxiv.org/abs/2305.05383)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05383.md)]
- Privacy-preserving Adversarial Facial Features - [[Arxiv](https://arxiv.org/abs/2305.05391)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.05391.md)]
- LMPT: Prompt Tuning with Class-Specific Embedding Loss for Long-tailed   Multi-Label Visual Recognition - [[Arxiv](https://arxiv.org/abs/2305.04536)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04536.md)]
- Video Object Segmentation in Panoptic Wild Scenes - [[Arxiv](https://arxiv.org/abs/2305.04470)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04470.md)]
- Locally Attentional SDF Diffusion for Controllable 3D Shape Generation - [[Arxiv](https://arxiv.org/abs/2305.04461)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04461.md)]
- Prompt Tuning Inversion for Text-Driven Image Editing Using Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2305.04441)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04441.md)]
- A Variational Perspective on Solving Inverse Problems with Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2305.04391)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04391.md)]
- Language Models Don't Always Say What They Think: Unfaithful   Explanations in Chain-of-Thought Prompting - [[Arxiv](https://arxiv.org/abs/2305.04388)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04388.md)]
- Unified Demonstration Retriever for In-Context Learning - [[Arxiv](https://arxiv.org/abs/2305.04320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04320.md)]
- Multi-Space Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2305.04268)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04268.md)]
- Vcc: Scaling Transformers to 128K Tokens or More by Prioritizing   Important Tokens - [[Arxiv](https://arxiv.org/abs/2305.04241)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04241.md)]
- Text-to-Image Diffusion Models can be Easily Backdoored through   Multimodal Data Poisoning - [[Arxiv](https://arxiv.org/abs/2305.04175)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04175.md)]
- X-LLM: Bootstrapping Advanced Large Language Models by Treating   Multi-Modalities as Foreign Languages - [[Arxiv](https://arxiv.org/abs/2305.04160)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04160.md)]
- Exploring Human-Like Translation Strategy with Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.04118)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04118.md)]
- Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning   by Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.04091)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04091.md)]
- PointCMP: Contrastive Mask Prediction for Self-supervised Learning on   Point Cloud Videos - [[Arxiv](https://arxiv.org/abs/2305.04075)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.04075.md)]
- Pre-training Language Model as a Multi-perspective Course Learner - [[Arxiv](https://arxiv.org/abs/2305.03981)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03981.md)]
- Residual Prompt Tuning: Improving Prompt Tuning with Residual   Reparameterization - [[Arxiv](https://arxiv.org/abs/2305.03937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03937.md)]
- Otter: A Multi-Modal Model with In-Context Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2305.03726)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03726.md)]
- Avatar Fingerprinting for Authorized Use of Synthetic Talking-Head   Videos - [[Arxiv](https://arxiv.org/abs/2305.03713)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03713.md)]
- LMEye: An Interactive Perception Network for Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.03701)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03701.md)]
- Vera: A General-Purpose Plausibility Estimation Model for Commonsense   Statements - [[Arxiv](https://arxiv.org/abs/2305.03695)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03695.md)]
- Mining bias-target Alignment from Voronoi Cells - [[Arxiv](https://arxiv.org/abs/2305.03691)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03691.md)]
- COLA: A Benchmark for Compositional Text-to-image Retrieval - [[Arxiv](https://arxiv.org/abs/2305.03689)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03689.md)]
- A Suite of Generative Tasks for Multi-Level Multimodal Webpage   Understanding - [[Arxiv](https://arxiv.org/abs/2305.03668)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03668.md)]
- Query Expansion by Prompting Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.03653)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03653.md)]
- T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large   Language Model Signals for Science Question Answering - [[Arxiv](https://arxiv.org/abs/2305.03453)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03453.md)]
- Adaptive Graph Convolutional Subspace Clustering - [[Arxiv](https://arxiv.org/abs/2305.03414)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03414.md)]
- High-Fidelity 3D Face Generation from Natural Language Descriptions - [[Arxiv](https://arxiv.org/abs/2305.03302)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03302.md)]
- TransESC: Smoothing Emotional Support Conversation via Turn-Level State   Transition - [[Arxiv](https://arxiv.org/abs/2305.03296)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03296.md)]
- Composite Motion Learning with Task Control - [[Arxiv](https://arxiv.org/abs/2305.03286)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03286.md)]
- Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework - [[Arxiv](https://arxiv.org/abs/2305.03268)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03268.md)]
- AttentionViz: A Global View of Transformer Attention - [[Arxiv](https://arxiv.org/abs/2305.03210)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03210.md)]
- Can LLM Already Serve as A Database Interface? A BIg Bench for   Large-Scale Database Grounded Text-to-SQLs - [[Arxiv](https://arxiv.org/abs/2305.03111)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03111.md)]
- Tracking through Containers and Occluders in the Wild - [[Arxiv](https://arxiv.org/abs/2305.03052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03052.md)]
- ZipIt! Merging Models from Different Tasks without Training - [[Arxiv](https://arxiv.org/abs/2305.03053)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03053.md)]
- Controllable Visual-Tactile Synthesis - [[Arxiv](https://arxiv.org/abs/2305.03051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03051.md)]
- NeuralEditor: Editing Neural Radiance Fields via Manipulating Point   Clouds - [[Arxiv](https://arxiv.org/abs/2305.03049)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03049.md)]
- Personalize Segment Anything Model with One Shot - [[Arxiv](https://arxiv.org/abs/2305.03048)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03048.md)]
- Principle-Driven Self-Alignment of Language Models from Scratch with   Minimal Human Supervision - [[Arxiv](https://arxiv.org/abs/2305.03047)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03047.md)]
- Single-Shot Implicit Morphable Faces with Consistent Texture   Parameterization - [[Arxiv](https://arxiv.org/abs/2305.03043)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03043.md)]
- TUVF: Learning Generalizable Texture UV Radiance Fields - [[Arxiv](https://arxiv.org/abs/2305.03040)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03040.md)]
- NeRSemble: Multi-view Radiance Field Reconstruction of Human Heads - [[Arxiv](https://arxiv.org/abs/2305.03027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03027.md)]
- Diffusion Explainer: Visual Explanation for Text-to-image Stable   Diffusion - [[Arxiv](https://arxiv.org/abs/2305.03509)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03509.md)]
- Masked Trajectory Models for Prediction, Representation, and Control - [[Arxiv](https://arxiv.org/abs/2305.02968)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02968.md)]
- BranchNorm: Robustly Scaling Extremely Deep Transformers - [[Arxiv](https://arxiv.org/abs/2305.02790)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02790.md)]
- A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects - [[Arxiv](https://arxiv.org/abs/2305.02750)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02750.md)]
- Real-Time Neural Appearance Models - [[Arxiv](https://arxiv.org/abs/2305.02678)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02678.md)]
- Caption Anything: Interactive Image Description with Diverse Multimodal   Controls - [[Arxiv](https://arxiv.org/abs/2305.02677)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02677.md)]
- Learning Language-Specific Layers for Multilingual Machine Translation - [[Arxiv](https://arxiv.org/abs/2305.02665)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02665.md)]
- "Seeing'' Electric Network Frequency from Events - [[Arxiv](https://arxiv.org/abs/2305.02597)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02597.md)]
- Semantically Structured Image Compression via Irregular Group-Based   Decoupling - [[Arxiv](https://arxiv.org/abs/2305.02586)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02586.md)]
- Should ChatGPT and Bard Share Revenue with Their Data Providers? A New   Business Model for the AI Era - [[Arxiv](https://arxiv.org/abs/2305.02555)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02555.md)]
- FormNetV2: Multimodal Graph Contrastive Learning for Form Document   Information Extraction - [[Arxiv](https://arxiv.org/abs/2305.02549)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02549.md)]
- Catch Missing Details: Image Reconstruction with Frequency Augmented   Variational Autoencoder - [[Arxiv](https://arxiv.org/abs/2305.02541)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02541.md)]
- ANetQA: A Large-scale Benchmark for Fine-grained Compositional Reasoning   over Untrimmed Videos - [[Arxiv](https://arxiv.org/abs/2305.02519)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02519.md)]
- AutoML-GPT: Automatic Machine Learning with GPT - [[Arxiv](https://arxiv.org/abs/2305.02499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02499.md)]
- ChatGPT-steered Editing Instructor for Customization of Abstractive   Summarization - [[Arxiv](https://arxiv.org/abs/2305.02483)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02483.md)]
- Shap-E: Generating Conditional 3D Implicit Functions - [[Arxiv](https://arxiv.org/abs/2305.02463)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02463.md)]
- Cheaply Evaluating Inference Efficiency Metrics for Autoregressive   Transformer APIs - [[Arxiv](https://arxiv.org/abs/2305.02440)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02440.md)]
- Plan, Eliminate, and Track -- Language Models are Good Teachers for   Embodied Agents - [[Arxiv](https://arxiv.org/abs/2305.02412)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02412.md)]
- Generating Synthetic Documents for Cross-Encoder Re-Rankers: A   Comparative Study of ChatGPT and Human Experts - [[Arxiv](https://arxiv.org/abs/2305.02320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02320.md)]
- Visual Chain of Thought: Bridging Logical Gaps with Multimodal   Infillings - [[Arxiv](https://arxiv.org/abs/2305.02317)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02317.md)]
- DynamicStereo: Consistent Dynamic Depth from Stereo Videos - [[Arxiv](https://arxiv.org/abs/2305.02296)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02296.md)]
- Uncovering ChatGPT's Capabilities in Recommender Systems - [[Arxiv](https://arxiv.org/abs/2305.02182)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02182.md)]
- Zero-Shot Listwise Document Reranking with a Large Language Model - [[Arxiv](https://arxiv.org/abs/2305.02156)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02156.md)]
- SAMRS: Scaling-up Remote Sensing Segmentation Dataset with Segment   Anything Model - [[Arxiv](https://arxiv.org/abs/2305.02034)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02034.md)]
- Multimodal Procedural Planning via Dual Text-Image Prompting - [[Arxiv](https://arxiv.org/abs/2305.01795)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.01795.md)]
- Automated Code generation for Information Technology Tasks in YAML   through Large Language Models - [[Arxiv](https://arxiv.org/abs/2305.02783)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.02783.md)]
- Stars Are All You Need: A Distantly Supervised Pyramid Network for   Document-Level End-to-End Sentiment Analysis - [[Arxiv](https://arxiv.org/abs/2305.01710)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.01710.md)]
- Generalizing Dataset Distillation via Deep Generative Prior - [[Arxiv](https://arxiv.org/abs/2305.01649)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.01649.md)]
- TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion   Synthesis - [[Arxiv](https://arxiv.org/abs/2305.00976)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00976.md)]
- Unlimiformer: Long-Range Transformers with Unlimited Length Input - [[Arxiv](https://arxiv.org/abs/2305.01625)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.01625.md)]
- Transfer Visual Prompt Generator across LLMs - [[Arxiv](https://arxiv.org/abs/2305.01278)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.01278.md)]
- The Role of Summarization in Generative Agents: A Preliminary   Perspective - [[Arxiv](https://arxiv.org/abs/2305.01253)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.01253.md)]
- ArK: Augmented Reality with Knowledge Interactive Emergent Ability - [[Arxiv](https://arxiv.org/abs/2305.00970)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00970.md)]
- Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural   Language Generation - [[Arxiv](https://arxiv.org/abs/2305.00955)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00955.md)]
- Hypernuclear event detection in the nuclear emulsion with Monte Carlo   simulation and machine learning - [[Arxiv](https://arxiv.org/abs/2305.0884)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.0884.md)]
- Learning to Reason and Memorize with Self-Notes - [[Arxiv](https://arxiv.org/abs/2305.00833)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00833.md)]
- Bidirectional Copy-Paste for Semi-Supervised Medical Image Segmentation - [[Arxiv](https://arxiv.org/abs/2305.00673)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00673.md)]
- Overcoming the Trade-off Between Accuracy and Plausibility in 3D Hand   Shape Reconstruction - [[Arxiv](https://arxiv.org/abs/2305.00646)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00646.md)]
- Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding - [[Arxiv](https://arxiv.org/abs/2305.00633)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00633.md)]
- Boosting Weakly-Supervised Temporal Action Localization with Text   Information - [[Arxiv](https://arxiv.org/abs/2305.00607)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00607.md)]

### April 2023
- Class-Balancing Diffusion Models - [[Arxiv](https://arxiv.org/abs/2305.00562)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00562.md)]
- Discriminative Co-Saliency and Background Mining Transformer for   Co-Salient Object Detection - [[Arxiv](https://arxiv.org/abs/2305.00514)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00514.md)]
- TALLRec: An Effective and Efficient Tuning Framework to Align Large   Language Model with Recommendation - [[Arxiv](https://arxiv.org/abs/2305.00447)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00447.md)]
- Modality-invariant Visual Odometry for Embodied Vision - [[Arxiv](https://arxiv.org/abs/2305.00348)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00348.md)]
- Learning Locally Editable Virtual Humans - [[Arxiv](https://arxiv.org/abs/2305.00121)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.00121.md)]
- LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model - [[Arxiv](https://arxiv.org/abs/2304.15010)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.15010.md)]
- Topic-oriented Adversarial Attacks against Black-box Neural Ranking   Models - [[Arxiv](https://arxiv.org/abs/2304.14867)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14867.md)]
- A Unified Generative Retriever for Knowledge-Intensive Language Tasks   via Prompt Learning - [[Arxiv](https://arxiv.org/abs/2304.14856)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14856.md)]
- SFD2: Semantic-guided Feature Detection and Description - [[Arxiv](https://arxiv.org/abs/2304.14845)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14845.md)]
- 3D shape reconstruction of semi-transparent worms - [[Arxiv](https://arxiv.org/abs/2304.14841)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14841.md)]
- IMP: Iterative Matching and Pose Estimation with Adaptive Pooling - [[Arxiv](https://arxiv.org/abs/2304.14837)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14837.md)]
- Deep Graph Reprogramming - [[Arxiv](https://arxiv.org/abs/2304.14593)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14593.md)]
- Multivariate Representation Learning for Information Retrieval - [[Arxiv](https://arxiv.org/abs/2304.14522)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14522.md)]
- Framing the News:From Human Perception to Large Language Model   Inferences - [[Arxiv](https://arxiv.org/abs/2304.14456)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14456.md)]
- Putting People in Their Place: Affordance-Aware Human Insertion into   Scenes - [[Arxiv](https://arxiv.org/abs/2304.14406)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14406.md)]
- ChatVideo: A Tracklet-centric Multimodal and Versatile Video   Understanding System - [[Arxiv](https://arxiv.org/abs/2304.14407)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14407.md)]
- A Probabilistic Attention Model with Occlusion-aware Texture Regression   for 3D Hand Reconstruction from a Single RGB Image - [[Arxiv](https://arxiv.org/abs/2304.14299)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14299.md)]
- Large Language Models are Strong Zero-Shot Retriever - [[Arxiv](https://arxiv.org/abs/2304.14233)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14233.md)]
- mPLUG-Owl: Modularization Empowers Large Language Models with   Multimodality - [[Arxiv](https://arxiv.org/abs/2304.14178)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14178.md)]
- Categorification of Group Equivariant Neural Networks - [[Arxiv](https://arxiv.org/abs/2304.14144)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14144.md)]
- ChatLog: Recording and Analyzing ChatGPT Across Time - [[Arxiv](https://arxiv.org/abs/2304.14106)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14106.md)]
- Learning Human-Human Interactions in Images from Weak Textual   Supervision - [[Arxiv](https://arxiv.org/abs/2304.14104)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.14104.md)]
- Is a prompt and a few samples all you need? Using GPT-4 for data   augmentation in low-resource classification tasks - [[Arxiv](https://arxiv.org/abs/2304.13861)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13861.md)]
- Multi-Party Chat: Conversational Agents in Group Settings with Humans   and Models - [[Arxiv](https://arxiv.org/abs/2304.13835)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13835.md)]
- Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond - [[Arxiv](https://arxiv.org/abs/2304.13712)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13712.md)]
- Multimodal Grounding for Embodied AI via Augmented Reality Headsets for   Natural Language Driven Task Planning - [[Arxiv](https://arxiv.org/abs/2304.13676)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13676.md)]
- What Happened 3 Seconds Ago? Inferring the Past with Thermal Imaging - [[Arxiv](https://arxiv.org/abs/2304.13651)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13651.md)]
- Unleashing Infinite-Length Input Capacity for Large-scale Language   Models with Self-Controlled Memory System - [[Arxiv](https://arxiv.org/abs/2304.13343)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13343.md)]
- StepFormer: Self-supervised Step Discovery and Localization in   Instructional Videos - [[Arxiv](https://arxiv.org/abs/2304.13265)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13265.md)]
- EverLight: Indoor-Outdoor Editable HDR Lighting Estimation - [[Arxiv](https://arxiv.org/abs/2304.13207)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13207.md)]
- SAFE: Machine Unlearning With Shard Graphs - [[Arxiv](https://arxiv.org/abs/2304.13169)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13169.md)]
- Generative Relevance Feedback with Large Language Models - [[Arxiv](https://arxiv.org/abs/2304.13157)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13157.md)]
- AVFace: Towards Detailed Audio-Visual 4D Face Reconstruction - [[Arxiv](https://arxiv.org/abs/2304.13115)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13115.md)]
- Answering Questions by Meta-Reasoning over Multiple Chains of Thought - [[Arxiv](https://arxiv.org/abs/2304.13007)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13007.md)]
- Patch-based 3D Natural Scene Generation from a Single Example - [[Arxiv](https://arxiv.org/abs/2304.12670)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12670.md)]
- Bayesian Optimization Meets Self-Distillation - [[Arxiv](https://arxiv.org/abs/2304.12666)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12666.md)]
- Hybrid Neural Rendering for Large-Scale Scenes with Motion Blur - [[Arxiv](https://arxiv.org/abs/2304.12652)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12652.md)]
- Proto-Value Networks: Scaling Representation Learning with Auxiliary   Tasks - [[Arxiv](https://arxiv.org/abs/2304.12567)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12567.md)]
- Img2Vec: A Teacher of High Token-Diversity Helps Masked AutoEncoders - [[Arxiv](https://arxiv.org/abs/2304.12535)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12535.md)]
- GlyphDiffusion: Text Generation as Image Generation - [[Arxiv](https://arxiv.org/abs/2304.12519)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12519.md)]
- TensoIR: Tensorial Inverse Rendering - [[Arxiv](https://arxiv.org/abs/2304.12461)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12461.md)]
- On the Challenges of Using Black-Box APIs for Toxicity Evaluation in   Research - [[Arxiv](https://arxiv.org/abs/2304.12397)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12397.md)]
- Beyond the Pixel: a Photometrically Calibrated HDR Dataset for Luminance   and Color Prediction - [[Arxiv](https://arxiv.org/abs/2304.12372)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12372.md)]
- WizardLM: Empowering Large Language Models to Follow Complex   Instructions - [[Arxiv](https://arxiv.org/abs/2304.12244)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12244.md)]
- Efficient Halftoning via Deep Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2304.12152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12152.md)]
- Track Anything: Segment Anything Meets Videos - [[Arxiv](https://arxiv.org/abs/2304.11968)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11968.md)]
- ChatLLM Network: More brains, More intelligence - [[Arxiv](https://arxiv.org/abs/2304.12998)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.12998.md)]
- Universal Domain Adaptation via Compressive Attention Matching - [[Arxiv](https://arxiv.org/abs/2304.11862)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11862.md)]
- Enhancing Fine-Tuning Based Backdoor Defense with Sharpness-Aware   Minimization - [[Arxiv](https://arxiv.org/abs/2304.11823)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11823.md)]
- Score-Based Diffusion Models as Principled Priors for Inverse Imaging - [[Arxiv](https://arxiv.org/abs/2304.11751)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11751.md)]
- SketchXAI: A First Look at Explainability for Human Sketches - [[Arxiv](https://arxiv.org/abs/2304.11744)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11744.md)]
- GamutMLP: A Lightweight MLP for Color Loss Recovery - [[Arxiv](https://arxiv.org/abs/2304.11743)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11743.md)]
- Walking Your LiDOG: A Journey Through Multiple Domains for LiDAR   Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2304.11705)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11705.md)]
- SATIN: A Multi-Task Metadataset for Classifying Satellite Imagery using   Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2304.11619)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11619.md)]
- LLM+P: Empowering Large Language Models with Optimal Planning   Proficiency - [[Arxiv](https://arxiv.org/abs/2304.11477)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11477.md)]
- Breaching FedMD: Image Recovery via Paired-Logits Inversion Attack - [[Arxiv](https://arxiv.org/abs/2304.11436)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11436.md)]
- Lookahead Diffusion Probabilistic Models for Refining Mean Estimation - [[Arxiv](https://arxiv.org/abs/2304.11312)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11312.md)]
- Speed Is All You Need: On-Device Acceleration of Large Diffusion Models   via GPU-Aware Optimizations - [[Arxiv](https://arxiv.org/abs/2304.11267)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11267.md)]
- Emergent and Predictable Memorization in Large Language Models - [[Arxiv](https://arxiv.org/abs/2304.11158)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11158.md)]
- ChatABL: Abductive Learning via Natural Language Interaction with   ChatGPT - [[Arxiv](https://arxiv.org/abs/2304.11107)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11107.md)]
- Can GPT-4 Perform Neural Architecture Search? - [[Arxiv](https://arxiv.org/abs/2304.10970)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10970.md)]
- FreMIM: Fourier Transform Meets Masked Image Modeling for Medical Image   Segmentation - [[Arxiv](https://arxiv.org/abs/2304.10864)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10864.md)]
- Auditing and Generating Synthetic Data with Controllable Trust   Trade-offs - [[Arxiv](https://arxiv.org/abs/2304.10819)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10819.md)]
- GeoLayoutLM: Geometric Pre-training for Visual Information Extraction - [[Arxiv](https://arxiv.org/abs/2304.10759)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10759.md)]
- Long-Term Photometric Consistent Novel View Synthesis with Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2304.10700)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10700.md)]
- HM-ViT: Hetero-modal Vehicle-to-Vehicle Cooperative perception with   vision transformer - [[Arxiv](https://arxiv.org/abs/2304.10628)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10628.md)]
- Learning in Imperfect Environment: Multi-Label Classification with   Long-Tailed Distribution and Partial Labels - [[Arxiv](https://arxiv.org/abs/2304.10539)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10539.md)]
- MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large   Language Models - [[Arxiv](https://arxiv.org/abs/2304.10592)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10592.md)]
- Generalizing Neural Human Fitting to Unseen Poses With Articulated SE(3)   Equivariance - [[Arxiv](https://arxiv.org/abs/2304.10528)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10528.md)]
- Contrastive Tuning: A Little Help to Make Masked Autoencoders Forget - [[Arxiv](https://arxiv.org/abs/2304.10520)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10520.md)]
- Reconstructing Signing Avatars From Video Using Linguistic Priors - [[Arxiv](https://arxiv.org/abs/2304.10482)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10482.md)]
- Phoenix: Democratizing ChatGPT across Languages - [[Arxiv](https://arxiv.org/abs/2304.10453)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10453.md)]
- SINC: Spatial Composition of 3D Human Motions for Simultaneous Action   Generation - [[Arxiv](https://arxiv.org/abs/2304.10417)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10417.md)]
- DocMAE: Document Image Rectification via Self-supervised Representation   Learning - [[Arxiv](https://arxiv.org/abs/2304.10341)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10341.md)]
- FIANCEE: Faster Inference of Adversarial Networks via Conditional Early   Exits - [[Arxiv](https://arxiv.org/abs/2304.10306)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10306.md)]
- PREIM3D: 3D Consistent Precise Image Attribute Editing from a Single   Image - [[Arxiv](https://arxiv.org/abs/2304.10263)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10263.md)]
- SCoDA: Domain Adaptive Shape Completion for Real Scans - [[Arxiv](https://arxiv.org/abs/2304.10179)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10179.md)]
- Learning Bottleneck Concepts in Image Classification - [[Arxiv](https://arxiv.org/abs/2304.10131)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10131.md)]
- Recognizability Embedding Enhancement for Very Low-Resolution Face   Recognition and Quality Estimation - [[Arxiv](https://arxiv.org/abs/2304.10066)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.10066.md)]
- MARS: Model-agnostic Biased Object Removal without Additional   Supervision for Weakly-Supervised Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2304.09913)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09913.md)]
- Evaluating Verifiability in Generative Search Engines - [[Arxiv](https://arxiv.org/abs/2304.09848)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09848.md)]
- Chameleon: Plug-and-Play Compositional Reasoning with Large Language   Models - [[Arxiv](https://arxiv.org/abs/2304.09842)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09842.md)]
- MetaBEV: Solving Sensor Failures for BEV Detection and Map Segmentation - [[Arxiv](https://arxiv.org/abs/2304.09801)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09801.md)]
- DarSwin: Distortion Aware Radial Swin Transformer - [[Arxiv](https://arxiv.org/abs/2304.09691)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09691.md)]
- CMID: A Unified Self-Supervised Learning Framework for Remote Sensing   Image Understanding - [[Arxiv](https://arxiv.org/abs/2304.09670)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09670.md)]
- Is ChatGPT Good at Search? Investigating Large Language Models as   Re-Ranking Agent - [[Arxiv](https://arxiv.org/abs/2304.09542)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09542.md)]
- Network Pruning Spaces - [[Arxiv](https://arxiv.org/abs/2304.09453)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09453.md)]
- ASM: Adaptive Skinning Model for High-Quality 3D Face Modeling - [[Arxiv](https://arxiv.org/abs/2304.09423)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09423.md)]
- Investigating the Nature of 3D Generalization in Deep Neural Networks - [[Arxiv](https://arxiv.org/abs/2304.09358)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09358.md)]
- To Compress or Not to Compress- Self-Supervised Learning and Information   Theory: A Review - [[Arxiv](https://arxiv.org/abs/2304.09355)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09355.md)]
- Fast Neural Scene Flow - [[Arxiv](https://arxiv.org/abs/2304.09121)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09121.md)]
- Think Before You Act: Unified Policy for Interleaving Language Reasoning   with Actions - [[Arxiv](https://arxiv.org/abs/2304.11063)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11063.md)]
- Learning to Fuse Monocular and Multi-view Cues for Multi-frame Depth   Estimation in Dynamic Scenes - [[Arxiv](https://arxiv.org/abs/2304.08993)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08993.md)]
- In ChatGPT We Trust? Measuring and Characterizing the Reliability of   ChatGPT - [[Arxiv](https://arxiv.org/abs/2304.08979)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08979.md)]
- SurfelNeRF: Neural Surfel Radiance Fields for Online Photorealistic   Reconstruction of Indoor Scenes - [[Arxiv](https://arxiv.org/abs/2304.08971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08971.md)]
- Align your Latents: High-Resolution Video Synthesis with Latent   Diffusion Models - [[Arxiv](https://arxiv.org/abs/2304.08818)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08818.md)]
- Looking Through the Glass: Neural Surface Reconstruction Against High   Specular Reflections - [[Arxiv](https://arxiv.org/abs/2304.08706)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08706.md)]
- Learning Situation Hyper-Graphs for Video Question Answering - [[Arxiv](https://arxiv.org/abs/2304.08682)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08682.md)]
- An Evaluation on Large Language Model Outputs: Discourse and   Memorization - [[Arxiv](https://arxiv.org/abs/2304.08637)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08637.md)]
- Delving into Shape-aware Zero-shot Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2304.08491)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08491.md)]
- Visual Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2304.08485)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08485.md)]
- Towards Robust Prompts on Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2304.08479)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08479.md)]
- Learning to Compress Prompts with Gist Tokens - [[Arxiv](https://arxiv.org/abs/2304.08467)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08467.md)]
- Learning to Render Novel Views from Wide-Baseline Stereo Pairs - [[Arxiv](https://arxiv.org/abs/2304.08463)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08463.md)]
- Efficient Video Action Detection with Token Dropout and Context   Refinement - [[Arxiv](https://arxiv.org/abs/2304.08451)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08451.md)]
- Tool Learning with Foundation Models - [[Arxiv](https://arxiv.org/abs/2304.08354)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08354.md)]
- Magnitude of arithmetic scalar and matrix categories - [[Arxiv](https://arxiv.org/abs/2304.08334)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08334.md)]
- ViPLO: Vision Transformer based Pose-Conditioned Self-Loop Graph for   Human-Object Interaction Detection - [[Arxiv](https://arxiv.org/abs/2304.08114)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08114.md)]
- MMANet: Margin-aware Distillation and Modality-aware Regularization for   Incomplete Multimodal Learning - [[Arxiv](https://arxiv.org/abs/2304.08028)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08028.md)]
- Bootstrapping Objectness from Videos by Relaxed Common Fate and Visual   Grouping - [[Arxiv](https://arxiv.org/abs/2304.08025)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.08025.md)]
- Chain of Thought Prompt Tuning in Vision Language Models - [[Arxiv](https://arxiv.org/abs/2304.07919)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.07919.md)]
- Towards Better Instruction Following Language Models for Chinese:   Investigating the Impact of Training Data and Evaluation - [[Arxiv](https://arxiv.org/abs/2304.07854)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.07854.md)]
- EGformer: Equirectangular Geometry-biased Transformer for 360 Depth   Estimation - [[Arxiv](https://arxiv.org/abs/2304.07803)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.07803.md)]
- Long-term Visual Localization with Mobile Sensors - [[Arxiv](https://arxiv.org/abs/2304.07691)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.07691.md)]
- Self-collaboration Code Generation via ChatGPT - [[Arxiv](https://arxiv.org/abs/2304.07590)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.07590.md)]
- Tractable Control for Autoregressive Language Generation - [[Arxiv](https://arxiv.org/abs/2304.07438)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.07438.md)]
- DINOv2: Learning Robust Visual Features without Supervision - [[Arxiv](https://arxiv.org/abs/2304.07193)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.07193.md)]
- M2T: Masking Transformers Twice for Faster Decoding - [[Arxiv](https://arxiv.org/abs/2304.07313)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.07313.md)]
- Delta Denoising Score - [[Arxiv](https://arxiv.org/abs/2304.07090)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.07090.md)]
- DCFace: Synthetic Face Generation with Dual Condition Diffusion Model - [[Arxiv](https://arxiv.org/abs/2304.07060)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.07060.md)]
- DeePoint: Visual Pointing Recognition and Direction Estimation - [[Arxiv](https://arxiv.org/abs/2304.06977)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06977.md)]
- A Unified HDR Imaging Method with Pixel and Patch Level - [[Arxiv](https://arxiv.org/abs/2304.06943)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06943.md)]
- Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved with   Text - [[Arxiv](https://arxiv.org/abs/2304.06939)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06939.md)]
- Unified Out-Of-Distribution Detection: A Model-Specific Perspective - [[Arxiv](https://arxiv.org/abs/2304.06813)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06813.md)]
- RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment - [[Arxiv](https://arxiv.org/abs/2304.06767)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06767.md)]
- Expressive Text-to-Image Generation with Rich Text - [[Arxiv](https://arxiv.org/abs/2304.06720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06720.md)]
- Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and   Reconstruction - [[Arxiv](https://arxiv.org/abs/2304.06714)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06714.md)]
- What does CLIP know about a red circle? Visual prompt engineering for   VLMs - [[Arxiv](https://arxiv.org/abs/2304.06712)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06712.md)]
- DiffusionRig: Learning Personalized Priors for Facial Appearance Editing - [[Arxiv](https://arxiv.org/abs/2304.06711)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06711.md)]
- DynaMITe: Dynamic Query Bootstrapping for Multi-object Interactive   Segmentation Transformer - [[Arxiv](https://arxiv.org/abs/2304.06668)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06668.md)]
- DiffFit: Unlocking Transferability of Large Diffusion Models via Simple   Parameter-Efficient Fine-Tuning - [[Arxiv](https://arxiv.org/abs/2304.06648)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06648.md)]
- Are LLMs All You Need for Task-Oriented Dialogue? - [[Arxiv](https://arxiv.org/abs/2304.06556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06556.md)]
- DNeRV: Modeling Inherent Dynamics via Difference Neural Representation   for Videos - [[Arxiv](https://arxiv.org/abs/2304.06544)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06544.md)]
- Transfer Knowledge from Head to Tail: Uncertainty Calibration under   Long-tailed Distribution - [[Arxiv](https://arxiv.org/abs/2304.06537)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06537.md)]
- Perspectives on Large Language Models for Relevance Judgment - [[Arxiv](https://arxiv.org/abs/2304.09161)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09161.md)]
- Multi-Mode Online Knowledge Distillation for Self-Supervised Visual   Representation Learning - [[Arxiv](https://arxiv.org/abs/2304.06461)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06461.md)]
- TransHP: Image Classification with Hierarchical Prompting - [[Arxiv](https://arxiv.org/abs/2304.06385)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06385.md)]
- AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models - [[Arxiv](https://arxiv.org/abs/2304.06364)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06364.md)]
- DDT: Dual-branch Deformable Transformer for Image Denoising - [[Arxiv](https://arxiv.org/abs/2304.06346)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06346.md)]
- NeRFVS: Neural Radiance Fields for Free View Synthesis via Geometry   Scaffolds - [[Arxiv](https://arxiv.org/abs/2304.06287)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06287.md)]
- Noisy Correspondence Learning with Meta Similarity Correction - [[Arxiv](https://arxiv.org/abs/2304.06275)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06275.md)]
- Language Instructed Reinforcement Learning for Human-AI Coordination - [[Arxiv](https://arxiv.org/abs/2304.07297)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.07297.md)]
- Asymmetrically-powered Neural Image Compression with Shallow Decoders - [[Arxiv](https://arxiv.org/abs/2304.06244)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06244.md)]
- [CLS] Token is All You Need for Zero-Shot Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2304.06212)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06212.md)]
- An Edit Friendly DDPM Noise Space: Inversion and Manipulations - [[Arxiv](https://arxiv.org/abs/2304.06140v2)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06140v2.md)]
- Probabilistic Human Mesh Recovery in 3D Scenes from Egocentric Views - [[Arxiv](https://arxiv.org/abs/2304.06024)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06024.md)]
- VidStyleODE: Disentangled Video Editing via StyleGAN and NeuralODEs - [[Arxiv](https://arxiv.org/abs/2304.06020)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06020.md)]
- Generating Aligned Pseudo-Supervision from Non-Aligned Data for Image   Restoration in Under-Display Camera - [[Arxiv](https://arxiv.org/abs/2304.06019)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06019.md)]
- Can Large Language Models Transform Computational Social Science? - [[Arxiv](https://arxiv.org/abs/2305.03514)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2305.03514.md)]
- Hard Patches Mining for Masked Image Modeling - [[Arxiv](https://arxiv.org/abs/2304.05919)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05919.md)]
- Representation Learning with Multi-Step Inverse Kinematics: An Efficient   and Optimal Approach to Rich-Observation RL - [[Arxiv](https://arxiv.org/abs/2304.05889)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05889.md)]
- Are Local Features All You Need for Cross-Domain Visual Place   Recognition? - [[Arxiv](https://arxiv.org/abs/2304.05887)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05887.md)]
- Mesh2Tex: Generating Mesh Textures from Image Queries - [[Arxiv](https://arxiv.org/abs/2304.05868)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05868.md)]
- NoisyTwins: Class-Consistent and Diverse Image Generation through   StyleGANs - [[Arxiv](https://arxiv.org/abs/2304.05866)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05866.md)]
- An Image Quality Assessment Dataset for Portraits - [[Arxiv](https://arxiv.org/abs/2304.05772)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05772.md)]
- Factorized Inverse Path Tracing for Efficient and Accurate   Material-Lighting Estimation - [[Arxiv](https://arxiv.org/abs/2304.05669)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05669.md)]
- Instance-Aware Domain Generalization for Face Anti-Spoofing - [[Arxiv](https://arxiv.org/abs/2304.05640)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05640.md)]
- How you feelin'? Learning Emotions and Mental States in Movie Scenes - [[Arxiv](https://arxiv.org/abs/2304.05634)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05634.md)]
- ChatGPT is all you need to decolonize sub-Saharan Vocational Education - [[Arxiv](https://arxiv.org/abs/2304.13728)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.13728.md)]
- ChemCrow: Augmenting large-language models with chemistry tools - [[Arxiv](https://arxiv.org/abs/2304.05376)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05376.md)]
- Toxicity in ChatGPT: Analyzing Persona-assigned Language Models - [[Arxiv](https://arxiv.org/abs/2304.05335)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05335.md)]
- OccFormer: Dual-path Transformer for Vision-based 3D Semantic Occupancy   Prediction - [[Arxiv](https://arxiv.org/abs/2304.05316)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05316.md)]
- Improving Image Recognition by Retrieving from Web-Scale Image-Text Data - [[Arxiv](https://arxiv.org/abs/2304.05173)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05173.md)]
- SportsMOT: A Large Multi-Object Tracking Dataset in Multiple Sports   Scenes - [[Arxiv](https://arxiv.org/abs/2304.05170)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05170.md)]
- Exploring and Exploiting Uncertainty for Incomplete Multi-View   Classification - [[Arxiv](https://arxiv.org/abs/2304.05165)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05165.md)]
- Teaching Large Language Models to Self-Debug - [[Arxiv](https://arxiv.org/abs/2304.05128)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05128.md)]
- FashionSAP: Symbols and Attributes Prompt for Fine-grained Fashion   Vision-Language Pre-training - [[Arxiv](https://arxiv.org/abs/2304.05051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05051.md)]
- Continual Semantic Segmentation with Automatic Memory Sample Selection - [[Arxiv](https://arxiv.org/abs/2304.05015)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05015.md)]
- StageInteractor: Query-based Object Detector with Cross-stage   Interaction - [[Arxiv](https://arxiv.org/abs/2304.04978)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04978.md)]
- Simulated Annealing in Early Layers Leads to Better Generalization - [[Arxiv](https://arxiv.org/abs/2304.04858)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04858.md)]
- Gradient-based Uncertainty Attribution for Explainable Bayesian Deep   Learning - [[Arxiv](https://arxiv.org/abs/2304.04824)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04824.md)]
- Binary Latent Diffusion - [[Arxiv](https://arxiv.org/abs/2304.04820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04820.md)]
- A Cheaper and Better Diffusion Language Model with Soft-Masked Noise - [[Arxiv](https://arxiv.org/abs/2304.04746)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04746.md)]
- Ambiguous Medical Image Segmentation using Diffusion Models - [[Arxiv](https://arxiv.org/abs/2304.04745)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04745.md)]
- Detection Transformer with Stable Matching - [[Arxiv](https://arxiv.org/abs/2304.04742)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04742.md)]
- Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary   Visual Recognition - [[Arxiv](https://arxiv.org/abs/2304.04704)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04704.md)]
- DetCLIPv2: Scalable Open-Vocabulary Object Detection Pre-training via   Word-Region Alignment - [[Arxiv](https://arxiv.org/abs/2304.04514)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04514.md)]
- Improved Test-Time Adaptation for Domain Generalization - [[Arxiv](https://arxiv.org/abs/2304.04494)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04494.md)]
- Feature Representation Learning with Adaptive Displacement Generation   and Transformer Fusion for Micro-Expression Recognition - [[Arxiv](https://arxiv.org/abs/2304.04420)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04420.md)]
- Instance Neural Radiance Field - [[Arxiv](https://arxiv.org/abs/2304.04395)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04395.md)]
- Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via   Prompt Augmented by ChatGPT - [[Arxiv](https://arxiv.org/abs/2304.11116)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11116.md)]
- OpenAGI: When LLM Meets Domain Experts - [[Arxiv](https://arxiv.org/abs/2304.04370)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04370.md)]
- Video ChatCaptioner: Towards Enriched Spatiotemporal Descriptions - [[Arxiv](https://arxiv.org/abs/2304.04227)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04227.md)]
- Shape-Erased Feature Learning for Visible-Infrared Person   Re-Identification - [[Arxiv](https://arxiv.org/abs/2304.04205)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04205.md)]
- Token Boosting for Robust Self-Supervised Visual Transformer   Pre-training - [[Arxiv](https://arxiv.org/abs/2304.04175)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04175.md)]
- Adversarially Robust Neural Architecture Search for Graph Neural   Networks - [[Arxiv](https://arxiv.org/abs/2304.04168)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04168.md)]
- Hi Sheldon! Creating Deep Personalized Characters from TV Shows - [[Arxiv](https://arxiv.org/abs/2304.11093)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.11093.md)]
- Decoder-Only or Encoder-Decoder? Interpreting Language Model as a   Regularized Encoder-Decoder - [[Arxiv](https://arxiv.org/abs/2304.04052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04052.md)]
- Delving into Discrete Normalizing Flows on SO(3) Manifold for   Probabilistic Rotation Modeling - [[Arxiv](https://arxiv.org/abs/2304.03937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03937.md)]
- High-Fidelity Clothed Avatar Reconstruction from a Single Image - [[Arxiv](https://arxiv.org/abs/2304.03903)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03903.md)]
- ChatGPT Empowered Long-Step Robot Control in Various Environments: A   Case Application - [[Arxiv](https://arxiv.org/abs/2304.03893)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03893.md)]
- Harnessing the Spatial-Temporal Attention of Diffusion Models for   High-Fidelity Text-to-Image Synthesis - [[Arxiv](https://arxiv.org/abs/2304.03869)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03869.md)]
- Why think step by step? Reasoning emerges from the locality of   experience - [[Arxiv](https://arxiv.org/abs/2304.03843)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03843.md)]
- Meta-causal Learning for Single Domain Generalization - [[Arxiv](https://arxiv.org/abs/2304.03709)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03709.md)]
- Model-Agnostic Gender Debiased Image Captioning - [[Arxiv](https://arxiv.org/abs/2304.03693)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03693.md)]
- Attention: Marginal Probability is All You Need? - [[Arxiv](https://arxiv.org/abs/2304.04556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.04556.md)]
- Hierarchical Disentanglement-Alignment Network for Robust SAR Vehicle   Recognition - [[Arxiv](https://arxiv.org/abs/2304.03550)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03550.md)]
- Better "CMOS" Produces Clearer Images: Learning Space-Variant Blur   Estimation for Blind Image Super-Resolution - [[Arxiv](https://arxiv.org/abs/2304.03542)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03542.md)]
- Sheaf Neural Networks for Graph-based Recommender Systems - [[Arxiv](https://arxiv.org/abs/2304.09097)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.09097.md)]
- RED-PSM: Regularization by Denoising of Partially Separable Models for   Dynamic Imaging - [[Arxiv](https://arxiv.org/abs/2304.03483)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03483.md)]
- Generative Agents: Interactive Simulacra of Human Behavior - [[Arxiv](https://arxiv.org/abs/2304.03442)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03442.md)]
- Towards Unified Scene Text Spotting based on Sequence Generation - [[Arxiv](https://arxiv.org/abs/2304.03435)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03435.md)]
- $R^{2}$Former: Unified $R$etrieval and $R$eranking Transformer for Place   Recognition - [[Arxiv](https://arxiv.org/abs/2304.03410)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03410.md)]
- TopNet: Transformer-based Object Placement Network for Image Compositing - [[Arxiv](https://arxiv.org/abs/2304.03372)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03372.md)]
- SegGPT: Segmenting Everything In Context - [[Arxiv](https://arxiv.org/abs/2304.03284)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03284.md)]
- Diffusion Models as Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2304.03283)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03283.md)]
- Visual Dependency Transformers: Dependency Tree Emerges from Reversed   Attention - [[Arxiv](https://arxiv.org/abs/2304.03282)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03282.md)]
- Neural Fields meet Explicit Geometric Representation for Inverse   Rendering of Urban Scenes - [[Arxiv](https://arxiv.org/abs/2304.03266)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03266.md)]
- CloSET: Modeling Clothed Humans on Continuous Surface with Explicit   Template Decomposition - [[Arxiv](https://arxiv.org/abs/2304.03167)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03167.md)]
- Retention Is All You Need - [[Arxiv](https://arxiv.org/abs/2304.03103)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.03103.md)]
- Multi-view Adversarial Discriminator: Mine the Non-causal Factors for   Object Detection in Unseen Domains - [[Arxiv](https://arxiv.org/abs/2304.02950)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02950.md)]
- MULLER: Multilayer Laplacian Resizer for Vision - [[Arxiv](https://arxiv.org/abs/2304.02859)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02859.md)]
- Learning Neural Eigenfunctions for Unsupervised Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2304.02841)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02841.md)]
- Segment Anything - [[Arxiv](https://arxiv.org/abs/2304.02643)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02643.md)]
- ENTL: Embodied Navigation Trajectory Learner - [[Arxiv](https://arxiv.org/abs/2304.02639)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02639.md)]
- HNeRV: A Hybrid Neural Representation for Videos - [[Arxiv](https://arxiv.org/abs/2304.02633)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02633.md)]
- Dynamic Point Fields - [[Arxiv](https://arxiv.org/abs/2304.02626)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02626.md)]
- Generative Novel View Synthesis with 3D-Aware Diffusion Models - [[Arxiv](https://arxiv.org/abs/2304.02602)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02602.md)]
- Detecting and Grounding Multi-Modal Media Manipulation - [[Arxiv](https://arxiv.org/abs/2304.02556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02556.md)]
- TM2D: Bimodality Driven 3D Dance Generation via Music-Text Integration - [[Arxiv](https://arxiv.org/abs/2304.02419)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02419.md)]
- Effective control of two-dimensional Rayleigh--BÃ©nard convection:   invariant multi-agent reinforcement learning is all you need - [[Arxiv](https://arxiv.org/abs/2304.02370)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02370.md)]
- SMPConv: Self-moving Point Representations for Continuous Convolution - [[Arxiv](https://arxiv.org/abs/2304.02330)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02330.md)]
- Few-shot Semantic Image Synthesis with Class Affinity Transfer - [[Arxiv](https://arxiv.org/abs/2304.02321)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02321.md)]
- How to choose your best allies for a transferable attack? - [[Arxiv](https://arxiv.org/abs/2304.02312)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02312.md)]
- MMVC: Learned Multi-Mode Video Compression with Block-based Prediction   Mode Selection and Density-Adaptive Entropy Coding - [[Arxiv](https://arxiv.org/abs/2304.02273)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02273.md)]
- ERRA: An Embodied Representation and Reasoning Architecture for   Long-horizon Language-conditioned Manipulation Tasks - [[Arxiv](https://arxiv.org/abs/2304.02251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02251.md)]
- METransformer: Radiology Report Generation by Transformer with Multiple   Learnable Expert Tokens - [[Arxiv](https://arxiv.org/abs/2304.02211)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02211.md)]
- GINA-3D: Learning to Generate Implicit Neural Assets in the Wild - [[Arxiv](https://arxiv.org/abs/2304.02163)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02163.md)]
- FREDOM: Fairness Domain Adaptation Approach to Semantic Scene   Understanding - [[Arxiv](https://arxiv.org/abs/2304.02135)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02135.md)]
- Multimodal Garment Designer: Human-Centric Latent Diffusion Models for   Fashion Image Editing - [[Arxiv](https://arxiv.org/abs/2304.02051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02051.md)]
- GlueStick: Robust Image Matching by Sticking Points and Lines Together - [[Arxiv](https://arxiv.org/abs/2304.02008)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02008.md)]
- MonoHuman: Animatable Human Neural Field from Monocular Video - [[Arxiv](https://arxiv.org/abs/2304.02001)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.02001.md)]
- LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of   Large Language Models - [[Arxiv](https://arxiv.org/abs/2304.01933)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01933.md)]
- Trace and Pace: Controllable Pedestrian Animation via Guided Trajectory   Diffusion - [[Arxiv](https://arxiv.org/abs/2304.01893)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01893.md)]
- Learning to Name Classes for Vision and Language Models - [[Arxiv](https://arxiv.org/abs/2304.01830)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01830.md)]
- Toward Verifiable and Reproducible Human Evaluation for Text-to-Image   Generation - [[Arxiv](https://arxiv.org/abs/2304.01816)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01816.md)]
- Bridging the Gap between Model Explanations in Partially Annotated   Multi-label Classification - [[Arxiv](https://arxiv.org/abs/2304.01804)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01804.md)]
- Towards Open-Vocabulary Video Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2304.01715)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01715.md)]
- HyperCUT: Video Sequence from a Single Blurry Image using Unsupervised   Ordering - [[Arxiv](https://arxiv.org/abs/2304.01686)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01686.md)]
- Re-thinking Model Inversion Attacks Against Deep Neural Networks - [[Arxiv](https://arxiv.org/abs/2304.01669)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01669.md)]
- On the Stability-Plasticity Dilemma of Class-Incremental Learning - [[Arxiv](https://arxiv.org/abs/2304.01663)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01663.md)]
- Cross-Domain Image Captioning with Discriminative Finetuning - [[Arxiv](https://arxiv.org/abs/2304.01662)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01662.md)]
- IterativePFN: True Iterative Point Cloud Filtering - [[Arxiv](https://arxiv.org/abs/2304.01529)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01529.md)]
- Text-Conditioned Sampling Framework for Text-to-Image Generation with   Masked Generative Models - [[Arxiv](https://arxiv.org/abs/2304.01515)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01515.md)]
- Robust Outlier Rejection for 3D Registration with Variational Bayes - [[Arxiv](https://arxiv.org/abs/2304.01514)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01514.md)]
- Mapping Degeneration Meets Label Evolution: Learning Infrared Small   Target Detection with Single Point Supervision - [[Arxiv](https://arxiv.org/abs/2304.01484)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01484.md)]
- Defending Against Patch-based Backdoor Attacks on Self-Supervised   Learning - [[Arxiv](https://arxiv.org/abs/2304.01482)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01482.md)]
- Hierarchical Supervision and Shuffle Data Augmentation for 3D   Semi-Supervised Object Detection - [[Arxiv](https://arxiv.org/abs/2304.01464)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01464.md)]
- Learning Personalized High Quality Volumetric Head Avatars from   Monocular RGB Videos - [[Arxiv](https://arxiv.org/abs/2304.01436)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01436.md)]
- VNE: An Effective Method for Improving Deep Representation by   Manipulating Eigenvalue Distribution - [[Arxiv](https://arxiv.org/abs/2304.01434)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01434.md)]
- Pythia: A Suite for Analyzing Large Language Models Across Training and   Scaling - [[Arxiv](https://arxiv.org/abs/2304.01373)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01373.md)]
- Role of Transients in Two-Bounce Non-Line-of-Sight Imaging - [[Arxiv](https://arxiv.org/abs/2304.01308)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01308.md)]
- Monocular 3D Object Detection with Bounding Box Denoising in 3D by   Perceiver - [[Arxiv](https://arxiv.org/abs/2304.01289)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01289.md)]
- Long-Tailed Visual Recognition via Self-Heterogeneous Integration with   Knowledge Excavation - [[Arxiv](https://arxiv.org/abs/2304.01279)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01279.md)]
- Asymptotic expansions for the maximum likelihood estimation errors of   the rotating parameter of the gravitational wave from core-collapse   supernovae - [[Arxiv](https://arxiv.org/abs/2304.1267)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.1267.md)]
- Neural Volumetric Memory for Visual Locomotion Control - [[Arxiv](https://arxiv.org/abs/2304.01201)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01201.md)]
- Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on   Self-Chat Data - [[Arxiv](https://arxiv.org/abs/2304.01196)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01196.md)]
- Not All Features Matter: Enhancing Few-shot CLIP with Adaptive Prior   Refinement - [[Arxiv](https://arxiv.org/abs/2304.01195)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01195.md)]
- Burstormer: Burst Image Restoration and Enhancement Transformer - [[Arxiv](https://arxiv.org/abs/2304.01194)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01194.md)]
- Navigating to Objects Specified by Images - [[Arxiv](https://arxiv.org/abs/2304.01192)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01192.md)]
- Generative Multiplane Neural Radiance for 3D-Aware Image Generation - [[Arxiv](https://arxiv.org/abs/2304.01172)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01172.md)]
- Generative Diffusion Prior for Unified Image Restoration and Enhancement - [[Arxiv](https://arxiv.org/abs/2304.01247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01247.md)]
- ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model - [[Arxiv](https://arxiv.org/abs/2304.01116)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01116.md)]
- Real-time 6K Image Rescaling with Rate-distortion Optimization - [[Arxiv](https://arxiv.org/abs/2304.01064)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01064.md)]
- DivClust: Controlling Diversity in Deep Clustering - [[Arxiv](https://arxiv.org/abs/2304.01042)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.01042.md)]
- Temporal Enhanced Training of Multi-view 3D Object Detector via   Historical Object Prediction - [[Arxiv](https://arxiv.org/abs/2304.00967)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00967.md)]
- Tunable Convolutions with Parametric Multi-Loss Optimization - [[Arxiv](https://arxiv.org/abs/2304.00898)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00898.md)]
- Spectral Enhanced Rectangle Transformer for Hyperspectral Image   Denoising - [[Arxiv](https://arxiv.org/abs/2304.00844)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00844.md)]
- Astroformer: More Data Might not be all you need for Classification - [[Arxiv](https://arxiv.org/abs/2304.05350)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.05350.md)]
- Few-shot Fine-tuning is All You Need for Source-free Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2304.00792)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00792.md)]
- DeGPR: Deep Guided Posterior Regularization for Multi-Class Cell   Detection and Counting - [[Arxiv](https://arxiv.org/abs/2304.00741)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00741.md)]
- Multi-Modal Representation Learning with Text-Driven Soft Masks - [[Arxiv](https://arxiv.org/abs/2304.00719)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00719.md)]
- Thermal Spread Functions (TSF): Physics-guided Material Classification - [[Arxiv](https://arxiv.org/abs/2304.00696)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00696.md)]
- 3D Semantic Segmentation in the Wild: Learning Generalized Models for   Adverse-Condition Point Clouds - [[Arxiv](https://arxiv.org/abs/2304.00690)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00690.md)]
- Recurrence without Recurrence: Stable Video Landmark Detection with Deep   Equilibrium Models - [[Arxiv](https://arxiv.org/abs/2304.00600)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00600.md)]
- DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking   Tasks - [[Arxiv](https://arxiv.org/abs/2304.00571)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00571.md)]
- Metrological detection of multipartite entanglement through dynamical   symmetries - [[Arxiv](https://arxiv.org/abs/2304.0564)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.0564.md)]
- UniDexGrasp++: Improving Dexterous Grasping Policy Learning via   Geometry-aware Curriculum and Iterative Generalist-Specialist Learning - [[Arxiv](https://arxiv.org/abs/2304.00464)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00464.md)]
- Re-IQA: Unsupervised Learning for Image Quality Assessment in the Wild - [[Arxiv](https://arxiv.org/abs/2304.00451)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00451.md)]
- Learning Dynamic Style Kernels for Artistic Style Transfer - [[Arxiv](https://arxiv.org/abs/2304.00414)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00414.md)]
- SeSDF: Self-evolved Signed Distance Field for Implicit 3D Clothed Human   Reconstruction - [[Arxiv](https://arxiv.org/abs/2304.00359)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00359.md)]
- When Crowd Meets Persona: Creating a Large-Scale Open-Domain Persona   Dialogue Corpus - [[Arxiv](https://arxiv.org/abs/2304.00350)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00350.md)]
- JacobiNeRF: NeRF Shaping with Mutual Information Gradients - [[Arxiv](https://arxiv.org/abs/2304.00341)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00341.md)]
- Automatic High Resolution Wire Segmentation and Removal - [[Arxiv](https://arxiv.org/abs/2304.00221)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00221.md)]
- Devil is in the Queries: Advancing Mask Transformers for Real-world   Medical Image Segmentation and Out-of-Distribution Localization - [[Arxiv](https://arxiv.org/abs/2304.00212)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00212.md)]

### March 2023
- Learning the Distribution of Errors in Stereo Matching for Joint   Disparity and Uncertainty Estimation - [[Arxiv](https://arxiv.org/abs/2304.00152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00152.md)]
- On stochastic MPC formulations with closed-loop guarantees: Analysis and   a unifying framework - [[Arxiv](https://arxiv.org/abs/2304.0069)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.0069.md)]
- Weakly-Supervised Text-driven Contrastive Learning for Facial Behavior   Understanding - [[Arxiv](https://arxiv.org/abs/2304.00058)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00058.md)]
- LivePose: Online 3D Reconstruction from Monocular Video with Dynamic   Camera Poses - [[Arxiv](https://arxiv.org/abs/2304.00054)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00054.md)]
- Accelerating exploration and representation learning with offline   pre-training - [[Arxiv](https://arxiv.org/abs/2304.00046)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00046.md)]
- Choose Your Weapon: Survival Strategies for Depressed AI Academics - [[Arxiv](https://arxiv.org/abs/2304.06035)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06035.md)]
- A Survey of Large Language Models - [[Arxiv](https://arxiv.org/abs/2303.18223)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.18223.md)]
- Assessing Language Model Deployment with Risk Cards - [[Arxiv](https://arxiv.org/abs/2303.18190)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.18190.md)]
- Efficient View Synthesis and 3D-based Multi-Frame Denoising with   Multiplane Feature Representations - [[Arxiv](https://arxiv.org/abs/2303.18139)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.18139.md)]
- Towards Nonlinear-Motion-Aware and Occlusion-Robust Rolling Shutter   Correction - [[Arxiv](https://arxiv.org/abs/2303.18125)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.18125.md)]
- VDN-NeRF: Resolving Shape-Radiance Ambiguity via View-Dependence   Normalization - [[Arxiv](https://arxiv.org/abs/2303.17968)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17968.md)]
- Diffusion Action Segmentation - [[Arxiv](https://arxiv.org/abs/2303.17959)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17959.md)]
- 3D-aware Image Generation using 2D Diffusion Models - [[Arxiv](https://arxiv.org/abs/2303.17905)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17905.md)]
- Shepherding Slots to Objects: Towards Stable and Robust Object-Centric   Learning - [[Arxiv](https://arxiv.org/abs/2303.17842)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17842.md)]
- Learning Procedure-aware Video Representation from Instructional Videos   and Their Narrations - [[Arxiv](https://arxiv.org/abs/2303.17839)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17839.md)]
- Neural Microfacet Fields for Inverse Rendering - [[Arxiv](https://arxiv.org/abs/2303.17806)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17806.md)]
- CrossLoc3D: Aerial-Ground Cross-Source 3D Place Recognition - [[Arxiv](https://arxiv.org/abs/2303.17778)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17778.md)]
- Semi-Weakly Supervised Object Kinematic Motion Prediction - [[Arxiv](https://arxiv.org/abs/2303.17774)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17774.md)]
- CAMEL: Communicative Agents for "Mind" Exploration of Large Scale   Language Model Society - [[Arxiv](https://arxiv.org/abs/2303.17760)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17760.md)]
- Optimal Input Gain: All You Need to Supercharge a Feed-Forward Neural   Network - [[Arxiv](https://arxiv.org/abs/2303.17732)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17732.md)]
- S-VolSDF: Sparse Multi-View Stereo Regularization of Neural Implicit   Surfaces - [[Arxiv](https://arxiv.org/abs/2303.17712)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17712.md)]
- Self-Refine: Iterative Refinement with Self-Feedback - [[Arxiv](https://arxiv.org/abs/2303.17651)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17651.md)]
- SparseViT: Revisiting Activation Sparsity for Efficient High-Resolution   Vision Transformer - [[Arxiv](https://arxiv.org/abs/2303.17605)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17605.md)]
- TiDy-PSFs: Computational Imaging with Time-Averaged Dynamic   Point-Spread-Functions - [[Arxiv](https://arxiv.org/abs/2303.17583)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17583.md)]
- HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging   Face - [[Arxiv](https://arxiv.org/abs/2303.17580)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17580.md)]
- Iterative Prompt Learning for Unsupervised Backlit Image Enhancement - [[Arxiv](https://arxiv.org/abs/2303.17569)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17569.md)]
- Whose Opinions Do Language Models Reflect? - [[Arxiv](https://arxiv.org/abs/2303.17548)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17548.md)]
- Language Models can Solve Computer Tasks - [[Arxiv](https://arxiv.org/abs/2303.17491)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17491.md)]
- All You Need Is Sex for Diversity - [[Arxiv](https://arxiv.org/abs/2303.17441)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17441.md)]
- WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for   Audio-Language Multimodal Research - [[Arxiv](https://arxiv.org/abs/2303.17395)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17395.md)]
- LayoutDiffusion: Controllable Diffusion Model for Layout-to-image   Generation - [[Arxiv](https://arxiv.org/abs/2303.17189)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17189.md)]
- Social Biases through the Text-to-Image Generation Lens - [[Arxiv](https://arxiv.org/abs/2304.06034)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.06034.md)]
- Mixed Autoencoder for Self-supervised Visual Representation Learning - [[Arxiv](https://arxiv.org/abs/2303.17152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17152.md)]
- NeILF++: Inter-Reflectable Light Fields for Geometry and Material   Estimation - [[Arxiv](https://arxiv.org/abs/2303.17147)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17147.md)]
- ImageNet-E: Benchmarking Neural Network Robustness via Attribute Editing - [[Arxiv](https://arxiv.org/abs/2303.17096)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17096.md)]
- OpenMix: Exploring Outlier Samples for Misclassification Detection - [[Arxiv](https://arxiv.org/abs/2303.17093)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.17093.md)]
- MaLP: Manipulation Localization Using a Proactive Scheme - [[Arxiv](https://arxiv.org/abs/2303.16976)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16976.md)]
- PartManip: Learning Cross-Category Generalizable Part Manipulation   Policy from Point Cloud Observations - [[Arxiv](https://arxiv.org/abs/2303.16958)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16958.md)]
- AutoAD: Movie Description in Context - [[Arxiv](https://arxiv.org/abs/2303.16899)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16899.md)]
- ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with   GPT and Prototype Guidance - [[Arxiv](https://arxiv.org/abs/2303.16894)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16894.md)]
- DPF: Learning Dense Prediction Fields with Weak Supervision - [[Arxiv](https://arxiv.org/abs/2303.16890)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16890.md)]
- Adaptive Superpixel for Active Learning in Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2303.16817)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16817.md)]
- TTA-COPE: Test-Time Adaptation for Category-Level Object Pose Estimation - [[Arxiv](https://arxiv.org/abs/2303.16730)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16730.md)]
- VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking - [[Arxiv](https://arxiv.org/abs/2303.16727)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16727.md)]
- G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment - [[Arxiv](https://arxiv.org/abs/2303.16634)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16634.md)]
- Adaptive Spot-Guided Transformer for Consistent Local Feature Matching - [[Arxiv](https://arxiv.org/abs/2303.16624)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16624.md)]
- Personalised Language Modelling of Screen Characters Using Rich Metadata   Annotations - [[Arxiv](https://arxiv.org/abs/2303.16618)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16618.md)]
- NeFII: Inverse Rendering for Reflectance Decomposition with Near-Field   Indirect Illumination - [[Arxiv](https://arxiv.org/abs/2303.16617)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16617.md)]
- Plan4MC: Skill Reinforcement Learning and Planning for Open-World   Minecraft Tasks - [[Arxiv](https://arxiv.org/abs/2303.16563)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16563.md)]
- Fair Federated Medical Image Segmentation via Client Contribution   Estimation - [[Arxiv](https://arxiv.org/abs/2303.16520)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16520.md)]
- TriVol: Point Cloud Rendering via Triple Volumes - [[Arxiv](https://arxiv.org/abs/2303.16485)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16485.md)]
- Point2Pix: Photo-Realistic Point Cloud Rendering via Neural Radiance   Fields - [[Arxiv](https://arxiv.org/abs/2303.16482)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16482.md)]
- Multi-View Azimuth Stereo via Tangent Space Consistency - [[Arxiv](https://arxiv.org/abs/2303.16447)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16447.md)]
- TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with   Millions of APIs - [[Arxiv](https://arxiv.org/abs/2303.16434)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16434.md)]
- ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of   Commonsense Problem in Large Language Models - [[Arxiv](https://arxiv.org/abs/2303.16421)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16421.md)]
- Are Data-driven Explanations Robust against Out-of-distribution Data? - [[Arxiv](https://arxiv.org/abs/2303.16390)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16390.md)]
- Flow supervision for Deformable NeRF - [[Arxiv](https://arxiv.org/abs/2303.16333)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16333.md)]
- Communication-Efficient Vertical Federated Learning with Limited   Overlapping Samples - [[Arxiv](https://arxiv.org/abs/2303.16270)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16270.md)]
- Your Diffusion Model is Secretly a Zero-Shot Classifier - [[Arxiv](https://arxiv.org/abs/2303.16203)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16203.md)]
- ASIC: Aligning Sparse in-the-wild Image Collections - [[Arxiv](https://arxiv.org/abs/2303.16201)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16201.md)]
- LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init   Attention - [[Arxiv](https://arxiv.org/abs/2303.16199)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16199.md)]
- SparseNeRF: Distilling Depth Ranking for Few-shot Novel View Synthesis - [[Arxiv](https://arxiv.org/abs/2303.16196)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16196.md)]
- Large-scale Training Data Search for Object Re-identification - [[Arxiv](https://arxiv.org/abs/2303.16186)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16186.md)]
- Learning Federated Visual Prompt in Null Space for MRI Reconstruction - [[Arxiv](https://arxiv.org/abs/2303.16181)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16181.md)]
- One-Stage 3D Whole-Body Mesh Recovery with Component Aware Transformer - [[Arxiv](https://arxiv.org/abs/2303.16160)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16160.md)]
- Unmasked Teacher: Towards Training-Efficient Video Foundation Models - [[Arxiv](https://arxiv.org/abs/2303.16058)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.16058.md)]
- F$^{2}$-NeRF: Fast Neural Radiance Field Training with Free Camera   Trajectories - [[Arxiv](https://arxiv.org/abs/2303.15951)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15951.md)]
- PosterLayout: A New Benchmark and Approach for Content-aware   Visual-Textual Presentation Layout - [[Arxiv](https://arxiv.org/abs/2303.15937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15937.md)]
- Unify, Align and Refine: Multi-Level Semantic Alignment for Radiology   Report Generation - [[Arxiv](https://arxiv.org/abs/2303.15932)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15932.md)]
- Mask-Free Video Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2303.15904)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15904.md)]
- Complementary Domain Adaptation and Generalization for Unsupervised   Continual Domain Shift Learning - [[Arxiv](https://arxiv.org/abs/2303.15833)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15833.md)]
- HOICLIP: Efficient Knowledge Transfer for HOI Detection with   Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2303.15786)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15786.md)]
- X-Mesh: Towards Fast and Accurate Text-driven 3D Stylization via Dynamic   Textual Guidance - [[Arxiv](https://arxiv.org/abs/2303.15764)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15764.md)]
- Transferable Adversarial Attacks on Vision Transformers with Token   Gradient Regularization - [[Arxiv](https://arxiv.org/abs/2303.15754)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15754.md)]
- System-status-aware Adaptive Network for Online Streaming Video   Understanding - [[Arxiv](https://arxiv.org/abs/2303.15742)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15742.md)]
- Foundation Models and Fair Use - [[Arxiv](https://arxiv.org/abs/2303.15715)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15715.md)]
- DisWOT: Student Architecture Search for Distillation WithOut Training - [[Arxiv](https://arxiv.org/abs/2303.15678)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15678.md)]
- Sequential training of GANs against GAN-classifiers reveals correlated   "knowledge gaps" present among independently trained GAN instances - [[Arxiv](https://arxiv.org/abs/2303.15533)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15533.md)]
- On the Creativity of Large Language Models - [[Arxiv](https://arxiv.org/abs/2304.00008)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2304.00008.md)]
- SwiftFormer: Efficient Additive Attention for Transformer-based   Real-time Mobile Vision Applications - [[Arxiv](https://arxiv.org/abs/2303.15446)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15446.md)]
- Quantum Multi-Model Fitting - [[Arxiv](https://arxiv.org/abs/2303.15444)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15444.md)]
- GeoNet: Benchmarking Unsupervised Adaptation across Geographies - [[Arxiv](https://arxiv.org/abs/2303.15443)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15443.md)]
- Zero-shot Model Diagnosis - [[Arxiv](https://arxiv.org/abs/2303.15441)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15441.md)]
- Anti-DreamBooth: Protecting users from personalized text-to-image   synthesis - [[Arxiv](https://arxiv.org/abs/2303.15433)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15433.md)]
- 3D Video Object Detection with Learnable Object-Centric Global   Optimization - [[Arxiv](https://arxiv.org/abs/2303.15416)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15416.md)]
- Learning to Zoom and Unzoom - [[Arxiv](https://arxiv.org/abs/2303.15390)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15390.md)]
- Active Self-Supervised Learning: A Few Low-Cost Relationships Are All   You Need - [[Arxiv](https://arxiv.org/abs/2303.15256)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15256.md)]
- Zero-Shot Composed Image Retrieval with Textual Inversion - [[Arxiv](https://arxiv.org/abs/2303.15247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15247.md)]
- SimpleNet: A Simple Network for Image Anomaly Detection and Localization - [[Arxiv](https://arxiv.org/abs/2303.15140)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15140.md)]
- High-fidelity 3D Human Digitization from Single 2K Resolution Images - [[Arxiv](https://arxiv.org/abs/2303.15108)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15108.md)]
- Vision Transformer with Quadrangle Attention - [[Arxiv](https://arxiv.org/abs/2303.15105)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15105.md)]
- Generalizable Local Feature Pre-training for Deformable Shape Analysis - [[Arxiv](https://arxiv.org/abs/2303.15104)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15104.md)]
- UniDistill: A Universal Cross-Modality Knowledge Distillation Framework   for 3D Object Detection in Bird's-Eye View - [[Arxiv](https://arxiv.org/abs/2303.15083)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15083.md)]
- Single-subject Multi-contrast MRI Super-resolution via Implicit Neural   Representations - [[Arxiv](https://arxiv.org/abs/2303.15065)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15065.md)]
- Joint Video Multi-Frame Interpolation and Deblurring under Unknown   Exposure Time - [[Arxiv](https://arxiv.org/abs/2303.15043)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15043.md)]
- Learning a Deep Color Difference Metric for Photographic Images - [[Arxiv](https://arxiv.org/abs/2303.14964)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14964.md)]
- DyGait: Exploiting Dynamic Representations for High-performance Gait   Recognition - [[Arxiv](https://arxiv.org/abs/2303.14953)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14953.md)]
- Regularize implicit neural representation by itself - [[Arxiv](https://arxiv.org/abs/2303.15484)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15484.md)]
- Text is All You Need: Personalizing ASR Models using Controllable Speech   Synthesis - [[Arxiv](https://arxiv.org/abs/2303.14885)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14885.md)]
- Label-Free Liver Tumor Segmentation - [[Arxiv](https://arxiv.org/abs/2303.14869)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14869.md)]
- DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion - [[Arxiv](https://arxiv.org/abs/2303.14863)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14863.md)]
- Frame Flexible Network - [[Arxiv](https://arxiv.org/abs/2303.14817)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14817.md)]
- BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning - [[Arxiv](https://arxiv.org/abs/2303.14773)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14773.md)]
- Global-to-Local Modeling for Video-based 3D Human Pose and Shape   Estimation - [[Arxiv](https://arxiv.org/abs/2303.14747)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14747.md)]
- Disentangling Writer and Character Styles for Handwriting Generation - [[Arxiv](https://arxiv.org/abs/2303.14736)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14736.md)]
- Natural Language Reasoning, A Survey - [[Arxiv](https://arxiv.org/abs/2303.14725)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14725.md)]
- CelebV-Text: A Large-Scale Facial Text-Video Dataset - [[Arxiv](https://arxiv.org/abs/2303.14717)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14717.md)]
- Learning Versatile 3D Shape Generation with Improved AR Models - [[Arxiv](https://arxiv.org/abs/2303.14700)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14700.md)]
- Sat2Density: Faithful Density Learning from Satellite-Ground Image Pairs - [[Arxiv](https://arxiv.org/abs/2303.14672)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14672.md)]
- Generalization Matters: Loss Minima Flattening via Parameter   Hybridization for Efficient Online Knowledge Distillation - [[Arxiv](https://arxiv.org/abs/2303.14666)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14666.md)]
- Affordance Grounding from Demonstration Video to Target Image - [[Arxiv](https://arxiv.org/abs/2303.14644)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14644.md)]
- Learning video embedding space with Natural Language Supervision - [[Arxiv](https://arxiv.org/abs/2303.14584)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14584.md)]
- SUDS: Scalable Urban Dynamic Scenes - [[Arxiv](https://arxiv.org/abs/2303.14536)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14536.md)]
- Adaptive Sparse Convolutional Networks with Global Context Enhancement   for Faster Object Detection on Drone Images - [[Arxiv](https://arxiv.org/abs/2303.14488)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14488.md)]
- DBARF: Deep Bundle-Adjusting Generalizable Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2303.14478)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14478.md)]
- Compacting Binary Neural Networks by Sparse Kernel Selection - [[Arxiv](https://arxiv.org/abs/2303.14470)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14470.md)]
- NeRF-DS: Neural Radiance Fields for Dynamic Specular Objects - [[Arxiv](https://arxiv.org/abs/2303.14435)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14435.md)]
- Human Preference Score: Better Aligning Text-to-Image Models with Human   Preference - [[Arxiv](https://arxiv.org/abs/2303.14420)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14420.md)]
- VL-SAT: Visual-Linguistic Semantics Assisted Training for 3D Semantic   Scene Graph Prediction in Point Cloud - [[Arxiv](https://arxiv.org/abs/2303.14408)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14408.md)]
- MDQE: Mining Discriminative Query Embeddings to Segment Occluded   Instances on Challenging Videos - [[Arxiv](https://arxiv.org/abs/2303.14395)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14395.md)]
- Masked Diffusion Transformer is a Strong Image Synthesizer - [[Arxiv](https://arxiv.org/abs/2303.14389)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14389.md)]
- DoNet: Deep De-overlapping Network for Cytology Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2303.14373)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14373.md)]
- FlexNeRF: Photorealistic Free-viewpoint Rendering of Moving Humans from   Sparse Views - [[Arxiv](https://arxiv.org/abs/2303.14368)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14368.md)]
- Supervised Masked Knowledge Distillation for Few-Shot Transformers - [[Arxiv](https://arxiv.org/abs/2303.15466)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15466.md)]
- Train/Test-Time Adaptation with Retrieval - [[Arxiv](https://arxiv.org/abs/2303.14333)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14333.md)]
- Learned Two-Plane Perspective Prior based Image Resampling for Efficient   Object Detection - [[Arxiv](https://arxiv.org/abs/2303.14311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14311.md)]
- Ensemble-based Blackbox Attacks on Dense Prediction - [[Arxiv](https://arxiv.org/abs/2303.14304)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14304.md)]
- VILA: Learning Image Aesthetics from User Comments with Vision-Language   Pretraining - [[Arxiv](https://arxiv.org/abs/2303.14302)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14302.md)]
- IDGI: A Framework to Eliminate Explanation Noise from Integrated   Gradients - [[Arxiv](https://arxiv.org/abs/2303.14242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14242.md)]
- Curricular Contrastive Regularization for Physics-aware Single Image   Dehazing - [[Arxiv](https://arxiv.org/abs/2303.14218)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14218.md)]
- FastViT: A Fast Hybrid Vision Transformer using Structural   Reparameterization - [[Arxiv](https://arxiv.org/abs/2303.14189)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14189.md)]
- UrbanGIRAFFE: Representing Urban Scenes as Compositional Generative   Neural Feature Fields - [[Arxiv](https://arxiv.org/abs/2303.14167)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14167.md)]
- Principles of Forgetting in Domain-Incremental Semantic Segmentation in   Adverse Weather Conditions - [[Arxiv](https://arxiv.org/abs/2303.14115)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14115.md)]
- Errors are Useful Prompts: Instruction Guided Task Programming with   Verifier-Assisted Iterative Prompting - [[Arxiv](https://arxiv.org/abs/2303.14100)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14100.md)]
- Best of Both Worlds: Multimodal Contrastive Learning with Tabular and   Imaging Data - [[Arxiv](https://arxiv.org/abs/2303.14080)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14080.md)]
- PoincarÃ© ResNet - [[Arxiv](https://arxiv.org/abs/2303.14027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14027.md)]
- Grid-guided Neural Radiance Fields for Large Urban Scenes - [[Arxiv](https://arxiv.org/abs/2303.14001)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.14001.md)]
- AssetField: Assets Mining and Reconfiguration in Ground Feature Plane   Representation - [[Arxiv](https://arxiv.org/abs/2303.13953)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13953.md)]
- GarmentTracking: Category-Level Garment Pose Tracking - [[Arxiv](https://arxiv.org/abs/2303.13913)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13913.md)]
- Robust Test-Time Adaptation in Dynamic Scenarios - [[Arxiv](https://arxiv.org/abs/2303.13899)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13899.md)]
- Compositionality in algorithms for smoothing - [[Arxiv](https://arxiv.org/abs/2303.13865)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13865.md)]
- Weakly-supervised Single-view Image Relighting - [[Arxiv](https://arxiv.org/abs/2303.13852)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13852.md)]
- Anomaly Detection under Distribution Shift - [[Arxiv](https://arxiv.org/abs/2303.13845)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13845.md)]
- Aligning Step-by-Step Instructional Diagrams to Video Demonstrations - [[Arxiv](https://arxiv.org/abs/2303.13800)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13800.md)]
- Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh   Reconstruction - [[Arxiv](https://arxiv.org/abs/2303.13796)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13796.md)]
- Progressively Optimized Local Radiance Fields for Robust View Synthesis - [[Arxiv](https://arxiv.org/abs/2303.13791)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13791.md)]
- GP-VTON: Towards General Purpose Virtual Try-on via Collaborative   Local-Flow Global-Parsing Learning - [[Arxiv](https://arxiv.org/abs/2303.13756)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13756.md)]
- Sparsifiner: Learning Sparse Instance-Dependent Attention for Efficient   Vision Transformers - [[Arxiv](https://arxiv.org/abs/2303.13755)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13755.md)]
- Conditional Image-to-Video Generation with Latent Flow Diffusion Models - [[Arxiv](https://arxiv.org/abs/2303.13744)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13744.md)]
- How Does Attention Work in Vision Transformers? A Visual Analytics   Attempt - [[Arxiv](https://arxiv.org/abs/2303.13731)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13731.md)]
- End-to-End Diffusion Latent Optimization Improves Classifier Guidance - [[Arxiv](https://arxiv.org/abs/2303.13703)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13703.md)]
- Rethinking Domain Generalization for Face Anti-spoofing: Separability   and Alignment - [[Arxiv](https://arxiv.org/abs/2303.13662)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13662.md)]
- Detecting Backdoors in Pre-trained Encoders - [[Arxiv](https://arxiv.org/abs/2303.15180)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15180.md)]
- Theoretical and Numerical Analysis of 3D Reconstruction Using Point and   Line Incidences - [[Arxiv](https://arxiv.org/abs/2303.13593)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13593.md)]
- SCADE: NeRFs from Space Carving with Ambiguity-Aware Depth Estimates - [[Arxiv](https://arxiv.org/abs/2303.13582)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13582.md)]
- Persistent Nature: A Generative Model of Unbounded 3D Worlds - [[Arxiv](https://arxiv.org/abs/2303.13515)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13515.md)]
- Towards Solving Fuzzy Tasks with Human Feedback: A Retrospective of the   MineRL BASALT 2022 Competition - [[Arxiv](https://arxiv.org/abs/2303.13512)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13512.md)]
- Neural Preset for Color Style Transfer - [[Arxiv](https://arxiv.org/abs/2303.13511)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13511.md)]
- DreamBooth3D: Subject-Driven Text-to-3D Generation - [[Arxiv](https://arxiv.org/abs/2303.13508)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13508.md)]
- Chordal Averaging on Flag Manifolds and Its Applications - [[Arxiv](https://arxiv.org/abs/2303.13501)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13501.md)]
- The effectiveness of MAE pre-pretraining for billion-scale pretraining - [[Arxiv](https://arxiv.org/abs/2303.13496)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13496.md)]
- Multi-granularity Interaction Simulation for Unsupervised Interactive   Segmentation - [[Arxiv](https://arxiv.org/abs/2303.13399)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13399.md)]
- Zero-guidance Segmentation Using Zero Segment Labels - [[Arxiv](https://arxiv.org/abs/2303.13396)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13396.md)]
- DARE-GRAM : Unsupervised Domain Adaptation Regression by Aligning   Inverse Gram Matrices - [[Arxiv](https://arxiv.org/abs/2303.13325)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13325.md)]
- Unsupervised Deep Probabilistic Approach for Partial Point Cloud   Registration - [[Arxiv](https://arxiv.org/abs/2303.13290)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13290.md)]
- Visual-Language Prompt Tuning with Knowledge-guided Context Optimization - [[Arxiv](https://arxiv.org/abs/2303.13283)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13283.md)]
- Exploring Structured Semantic Prior for Multi Label Recognition with   Incomplete Labels - [[Arxiv](https://arxiv.org/abs/2303.13223)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13223.md)]
- Marching-Primitives: Shape Abstraction from Signed Distance Function - [[Arxiv](https://arxiv.org/abs/2303.13190)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13190.md)]
- Masked Image Training for Generalizable Deep Image Denoising - [[Arxiv](https://arxiv.org/abs/2303.13132)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13132.md)]
- OCELOT: Overlapped Cell on Tissue Dataset for Histopathology - [[Arxiv](https://arxiv.org/abs/2303.13110)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13110.md)]
- Modeling Entities as Semantic Points for Visual Information Extraction   in the Wild - [[Arxiv](https://arxiv.org/abs/2303.13095)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13095.md)]
- Orthogonal Annotation Benefits Barely-supervised Medical Image   Segmentation - [[Arxiv](https://arxiv.org/abs/2303.13090)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13090.md)]
- PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360$^{\circ}$ - [[Arxiv](https://arxiv.org/abs/2303.13071)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13071.md)]
- Human Guided Ground-truth Generation for Realistic Image   Super-resolution - [[Arxiv](https://arxiv.org/abs/2303.13069)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13069.md)]
- Top-Down Visual Attention from Analysis by Synthesis - [[Arxiv](https://arxiv.org/abs/2303.13043)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13043.md)]
- Learning a Practical SDR-to-HDRTV Up-conversion using New Dataset and   Degradation Models - [[Arxiv](https://arxiv.org/abs/2303.13031)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13031.md)]
- ENVIDR: Implicit Differentiable Renderer with Neural Environment   Lighting - [[Arxiv](https://arxiv.org/abs/2303.13022)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13022.md)]
- From Knowledge Distillation to Self-Knowledge Distillation: A Unified   Approach with Normalized Loss and Customized Soft Labels - [[Arxiv](https://arxiv.org/abs/2303.13005)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13005.md)]
- SHERF: Generalizable Human NeRF from a Single Image - [[Arxiv](https://arxiv.org/abs/2303.12791)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12791.md)]
- FeatureNeRF: Learning Generalizable NeRFs by Distilling Foundation   Models - [[Arxiv](https://arxiv.org/abs/2303.12786)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12786.md)]
- Spherical Transformer for LiDAR-based 3D Recognition - [[Arxiv](https://arxiv.org/abs/2303.12766)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12766.md)]
- Correlational Image Modeling for Self-Supervised Visual Pre-Training - [[Arxiv](https://arxiv.org/abs/2303.12670)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12670.md)]
- OcTr: Octree-based Transformer for 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2303.12621)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12621.md)]
- RaBit: Parametric Modeling of 3D Biped Cartoon Characters with a   Topological-consistent Dataset - [[Arxiv](https://arxiv.org/abs/2303.12564)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12564.md)]
- MEGA: Multilingual Evaluation of Generative AI - [[Arxiv](https://arxiv.org/abs/2303.12528)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12528.md)]
- UMC: A Unified Bandwidth-efficient and Multi-resolution based   Collaborative Perception Framework - [[Arxiv](https://arxiv.org/abs/2303.12400)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12400.md)]
- RegFormer: An Efficient Projection-Aware Transformer Network for   Large-Scale Point Cloud Registration - [[Arxiv](https://arxiv.org/abs/2303.12384)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12384.md)]
- Weakly Supervised Video Representation Learning with Unaligned Text for   Sequential Videos - [[Arxiv](https://arxiv.org/abs/2303.12370)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12370.md)]
- MAIR: Multi-view Attention Inverse Rendering with 3D Spatially-Varying   Lighting Estimation - [[Arxiv](https://arxiv.org/abs/2303.12368)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12368.md)]
- LD-ZNet: A Latent Diffusion Approach for Text-Based Image Segmentation - [[Arxiv](https://arxiv.org/abs/2303.12343)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12343.md)]
- Make Encoder Great Again in 3D GAN Inversion through Geometry and   Occlusion-Aware Encoding - [[Arxiv](https://arxiv.org/abs/2303.12326)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12326.md)]
- NLOS-NeuS: Non-line-of-sight Neural Implicit Surface - [[Arxiv](https://arxiv.org/abs/2303.12280)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12280.md)]
- Exploring the Benefits of Visual Prompting in Differential Privacy - [[Arxiv](https://arxiv.org/abs/2303.12247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12247.md)]
- Object Pose Estimation with Statistical Guarantees: Conformal Keypoint   Detection and Geometric Uncertainty Propagation - [[Arxiv](https://arxiv.org/abs/2303.12246)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12246.md)]
- Positive-Augmented Contrastive Learning for Image and Video Captioning   Evaluation - [[Arxiv](https://arxiv.org/abs/2303.12112)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12112.md)]
- Natural Language-Assisted Sign Language Recognition - [[Arxiv](https://arxiv.org/abs/2303.12080)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12080.md)]
- Two-shot Video Object Segmentation - [[Arxiv](https://arxiv.org/abs/2303.12078)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12078.md)]
- VAD: Vectorized Scene Representation for Efficient Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2303.12077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12077.md)]
- CC3D: Layout-Conditioned Generation of Compositional 3D Scenes - [[Arxiv](https://arxiv.org/abs/2303.12074)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12074.md)]
- ProphNet: Efficient Agent-Centric Motion Forecasting with   Anchor-Informed Proposals - [[Arxiv](https://arxiv.org/abs/2303.12071)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12071.md)]
- Vox-E: Text-guided Voxel Editing of 3D Objects - [[Arxiv](https://arxiv.org/abs/2303.12048)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12048.md)]
- Joint Visual Grounding and Tracking with Natural Language Specification - [[Arxiv](https://arxiv.org/abs/2303.12027)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12027.md)]
- Logical Reasoning over Natural Language as Knowledge Representation: A   Survey - [[Arxiv](https://arxiv.org/abs/2303.12023)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12023.md)]
- NeAT: Learning Neural Implicit Surfaces with Arbitrary Topologies from   Multi-view Images - [[Arxiv](https://arxiv.org/abs/2303.12012)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.12012.md)]
- Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models - [[Arxiv](https://arxiv.org/abs/2303.11989)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11989.md)]
- NEMTO: Neural Environment Matting for Novel View and Relighting   Synthesis of Transparent Objects - [[Arxiv](https://arxiv.org/abs/2303.11963)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11963.md)]
- Learning A Sparse Transformer Network for Effective Image Deraining - [[Arxiv](https://arxiv.org/abs/2303.11950)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11950.md)]
- Using Explanations to Guide Models - [[Arxiv](https://arxiv.org/abs/2303.11932)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11932.md)]
- Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D   Object Detection - [[Arxiv](https://arxiv.org/abs/2303.11926)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11926.md)]
- Context De-confounded Emotion Recognition - [[Arxiv](https://arxiv.org/abs/2303.11921)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11921.md)]
- Efficient Decision-based Black-box Patch Attacks on Video Recognition - [[Arxiv](https://arxiv.org/abs/2303.11917)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11917.md)]
- Solving Oscillation Problem in Post-Training Quantization Through a   Theoretical Perspective - [[Arxiv](https://arxiv.org/abs/2303.11906)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11906.md)]
- Focused and Collaborative Feedback Integration for Interactive Image   Segmentation - [[Arxiv](https://arxiv.org/abs/2303.11880)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11880.md)]
- The Treasure Beneath Multiple Annotations: An Uncertainty-aware Edge   Detector - [[Arxiv](https://arxiv.org/abs/2303.11828)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11828.md)]
- OTJR: Optimal Transport Meets Optimal Jacobian Regularization for   Adversarial Robustness - [[Arxiv](https://arxiv.org/abs/2303.11793)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11793.md)]
- Propagate And Calibrate: Real-time Passive Non-line-of-sight Tracking - [[Arxiv](https://arxiv.org/abs/2303.11791)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11791.md)]
- Detecting Everything in the Open World: Towards Universal Object   Detection - [[Arxiv](https://arxiv.org/abs/2303.11749)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11749.md)]
- Data-efficient Large Scale Place Recognition with Graded Similarity   Supervision - [[Arxiv](https://arxiv.org/abs/2303.11739)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11739.md)]
- Abstract Visual Reasoning: An Algebraic Approach for Solving Raven's   Progressive Matrices - [[Arxiv](https://arxiv.org/abs/2303.11730)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11730.md)]
- 3D Human Mesh Estimation from Virtual Markers - [[Arxiv](https://arxiv.org/abs/2303.11726)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11726.md)]
- Implicit Neural Representation for Cooperative Low-light Image   Enhancement - [[Arxiv](https://arxiv.org/abs/2303.11722)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11722.md)]
- A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to   GPT-5 All You Need? - [[Arxiv](https://arxiv.org/abs/2303.11717)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11717.md)]
- Learning a 3D Morphable Face Reflectance Model from Low-cost Data - [[Arxiv](https://arxiv.org/abs/2303.11686)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11686.md)]
- DiffuMask: Synthesizing Images with Pixel-level Annotations for Semantic   Segmentation Using Diffusion Models - [[Arxiv](https://arxiv.org/abs/2303.11681)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11681.md)]
- Full or Weak annotations? An adaptive strategy for budget-constrained   annotation campaigns - [[Arxiv](https://arxiv.org/abs/2303.11678)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11678.md)]
- ALOFT: A Lightweight MLP-like Architecture with Dynamic Low-frequency   Transform for Domain Generalization - [[Arxiv](https://arxiv.org/abs/2303.11674)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11674.md)]
- Manipulating Transfer Learning for Property Inference - [[Arxiv](https://arxiv.org/abs/2303.11643)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11643.md)]
- Visibility Constrained Wide-band Illumination Spectrum Design for   Seeing-in-the-Dark - [[Arxiv](https://arxiv.org/abs/2303.11642)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11642.md)]
- Human Pose as Compositional Tokens - [[Arxiv](https://arxiv.org/abs/2303.11638)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11638.md)]
- Equiangular Basis Vectors - [[Arxiv](https://arxiv.org/abs/2303.11637)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11637.md)]
- BoxSnake: Polygonal Instance Segmentation with Box Supervision - [[Arxiv](https://arxiv.org/abs/2303.11630)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11630.md)]
- TMA: Temporal Motion Aggregation for Event-based Optical Flow - [[Arxiv](https://arxiv.org/abs/2303.11629)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11629.md)]
- HRDFuse: Monocular 360Â°Depth Estimation by Collaboratively Learning   Holistic-with-Regional Depth Distributions - [[Arxiv](https://arxiv.org/abs/2303.11616)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11616.md)]
- Novel Class Discovery for 3D Point Cloud Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2303.11610)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11610.md)]
- Effective Ambiguity Attack Against Passport-based DNN Intellectual   Property Protection Schemes through Fully Connected Layer Substitution - [[Arxiv](https://arxiv.org/abs/2303.11595)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11595.md)]
- LayoutDiffusion: Improving Graphic Layout Generation by Discrete   Diffusion Probabilistic Models - [[Arxiv](https://arxiv.org/abs/2303.11589)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11589.md)]
- Boundary Unlearning - [[Arxiv](https://arxiv.org/abs/2303.11570)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11570.md)]
- One-to-Few Label Assignment for End-to-End Dense Detection - [[Arxiv](https://arxiv.org/abs/2303.11567)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11567.md)]
- Boosting Verified Training for Robust Image Classifications via   Abstraction - [[Arxiv](https://arxiv.org/abs/2303.11552)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11552.md)]
- Texture Learning Domain Randomization for Domain Generalized   Segmentation - [[Arxiv](https://arxiv.org/abs/2303.11546)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11546.md)]
- Fix the Noise: Disentangling Source Feature for Controllable Domain   Translation - [[Arxiv](https://arxiv.org/abs/2303.11545)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11545.md)]
- PRISE: Demystifying Deep Lucas-Kanade with Strongly Star-Convex   Constraints for Multimodel Image Alignment - [[Arxiv](https://arxiv.org/abs/2303.11526)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11526.md)]
- STDLens: Model Hijacking-Resilient Federated Learning for Object   Detection - [[Arxiv](https://arxiv.org/abs/2303.11511)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11511.md)]
- Sketch2Saliency: Learning to Detect Salient Objects from Human Drawings - [[Arxiv](https://arxiv.org/abs/2303.11502)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11502.md)]
- Polynomial Implicit Neural Representations For Large Diverse Datasets - [[Arxiv](https://arxiv.org/abs/2303.11424)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11424.md)]
- EPiC: Ensemble of Partial Point Clouds for Robust Classification - [[Arxiv](https://arxiv.org/abs/2303.11419)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11419.md)]
- Stable Bias: Analyzing Societal Representations in Diffusion Models - [[Arxiv](https://arxiv.org/abs/2303.11408)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11408.md)]
- eP-ALM: Efficient Perceptual Augmentation of Language Models - [[Arxiv](https://arxiv.org/abs/2303.11403)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11403.md)]
- MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action - [[Arxiv](https://arxiv.org/abs/2303.11381)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11381.md)]
- Reflexion: Language Agents with Verbal Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2303.11366)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11366.md)]
- Sound Localization from Motion: Jointly Learning Sound Direction and   Camera Rotation - [[Arxiv](https://arxiv.org/abs/2303.11329)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11329.md)]
- Zero-1-to-3: Zero-shot One Image to 3D Object - [[Arxiv](https://arxiv.org/abs/2303.11328)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11328.md)]
- 3D Concept Learning and Reasoning from Multi-View Images - [[Arxiv](https://arxiv.org/abs/2303.11327)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11327.md)]
- GeoMIM: Towards Better 3D Knowledge Transfer via Masked Image Modeling   for Multi-view 3D Understanding - [[Arxiv](https://arxiv.org/abs/2303.11325)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11325.md)]
- Open-vocabulary Panoptic Segmentation with Embedding Modulation - [[Arxiv](https://arxiv.org/abs/2303.11324)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11324.md)]
- Generative Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2303.11316)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11316.md)]
- SVDiff: Compact Parameter Space for Diffusion Fine-Tuning - [[Arxiv](https://arxiv.org/abs/2303.11305)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11305.md)]
- Learning Audio-Visual Source Localization via False Negative Aware   Contrastive Learning - [[Arxiv](https://arxiv.org/abs/2303.11302)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11302.md)]
- VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking - [[Arxiv](https://arxiv.org/abs/2303.11301)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11301.md)]
- Reliability in Semantic Segmentation: Are We on the Right Track? - [[Arxiv](https://arxiv.org/abs/2303.11298)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11298.md)]
- Attribute-preserving Face Dataset Anonymization via Latent Code   Optimization - [[Arxiv](https://arxiv.org/abs/2303.11296)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11296.md)]
- Zero-Shot Noise2Noise: Efficient Image Denoising without any Data - [[Arxiv](https://arxiv.org/abs/2303.11253)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11253.md)]
- Towards End-to-End Generative Modeling of Long Videos with   Memory-Efficient Bidirectional Transformers - [[Arxiv](https://arxiv.org/abs/2303.11251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11251.md)]
- Make Landscape Flatter in Differentially Private Federated Learning - [[Arxiv](https://arxiv.org/abs/2303.11242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11242.md)]
- HiFace: High-Fidelity 3D Face Reconstruction by Learning Static and   Dynamic Details - [[Arxiv](https://arxiv.org/abs/2303.11225)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11225.md)]
- Less is More: Reducing Task and Model Complexity for 3D Point Cloud   Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2303.11203)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11203.md)]
- Architecture, Dataset and Model-Scale Agnostic Data-free Meta-Learning - [[Arxiv](https://arxiv.org/abs/2303.11183)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11183.md)]
- Self-Correctable and Adaptable Inference for Generalizable Human Pose   Estimation - [[Arxiv](https://arxiv.org/abs/2303.11180)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11180.md)]
- Computationally Budgeted Continual Learning: What Does Matter? - [[Arxiv](https://arxiv.org/abs/2303.11165)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11165.md)]
- Picture that Sketch: Photorealistic Image Generation from Abstract   Sketches - [[Arxiv](https://arxiv.org/abs/2303.11162)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11162.md)]
- TWINS: A Fine-Tuning Framework for Improved Transferability of   Adversarial Robustness and Generalization - [[Arxiv](https://arxiv.org/abs/2303.11135)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11135.md)]
- Robustifying Token Attention for Vision Transformers - [[Arxiv](https://arxiv.org/abs/2303.11126)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11126.md)]
- SeiT: Storage-Efficient Vision Training with Tokens Using 1% of Pixel   Storage - [[Arxiv](https://arxiv.org/abs/2303.11114)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11114.md)]
- Coreset Sampling from Open-Set for Fine-Grained Self-Supervised Learning - [[Arxiv](https://arxiv.org/abs/2303.11101)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11101.md)]
- EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation - [[Arxiv](https://arxiv.org/abs/2303.11089)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11089.md)]
- Model Barrier: A Compact Un-Transferable Isolation Domain for Model   Intellectual Property Protection - [[Arxiv](https://arxiv.org/abs/2303.11078)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11078.md)]
- Boosting Semi-Supervised Learning by Exploiting All Unlabeled Data - [[Arxiv](https://arxiv.org/abs/2303.11066)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11066.md)]
- Learning Foresightful Dense Visual Affordance for Deformable Object   Manipulation - [[Arxiv](https://arxiv.org/abs/2303.11057)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11057.md)]
- ContraNeRF: Generalizable Neural Radiance Fields for Synthetic-to-real   Novel View Synthesis via Contrastive Learning - [[Arxiv](https://arxiv.org/abs/2303.11052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11052.md)]
- Benchmarking Robustness of 3D Object Detection to Common Corruptions in   Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2303.11040)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11040.md)]
- Learning Optical Flow from Event Camera with Rendered Dataset - [[Arxiv](https://arxiv.org/abs/2303.11011)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.11011.md)]
- Self-Supervised Learning for Multimodal Non-Rigid 3D Shape Matching - [[Arxiv](https://arxiv.org/abs/2303.10971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10971.md)]
- Constructing Metric-Semantic Maps using Floor Plan Priors for Long-Term   Indoor Localization - [[Arxiv](https://arxiv.org/abs/2303.10959)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10959.md)]
- Actionlet-Dependent Contrastive Learning for Unsupervised Skeleton-Based   Action Recognition - [[Arxiv](https://arxiv.org/abs/2303.10904)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10904.md)]
- Feature Alignment and Uniformity for Test Time Adaptation - [[Arxiv](https://arxiv.org/abs/2303.10902)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10902.md)]
- Graphics Capsule: Learning Hierarchical 3D Face Representations from 2D   Images - [[Arxiv](https://arxiv.org/abs/2303.10896)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10896.md)]
- Leapfrog Diffusion Model for Stochastic Trajectory Prediction - [[Arxiv](https://arxiv.org/abs/2303.10895)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10895.md)]
- Explicit Visual Prompting for Low-Level Structure Segmentations - [[Arxiv](https://arxiv.org/abs/2303.10883)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10883.md)]
- Efficient Map Sparsification Based on 2D and 3D Discretized Grids - [[Arxiv](https://arxiv.org/abs/2303.10882)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10882.md)]
- EqMotion: Equivariant Multi-agent Motion Prediction with Invariant   Interaction Reasoning - [[Arxiv](https://arxiv.org/abs/2303.10876)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10876.md)]
- Dynamic Documentation for AI Systems - [[Arxiv](https://arxiv.org/abs/2303.10854)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10854.md)]
- Ref-NeuS: Ambiguity-Reduced Neural Implicit Surface Learning for   Multi-View Reconstruction with Reflection - [[Arxiv](https://arxiv.org/abs/2303.10840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10840.md)]
- Visual Prompt Multi-Modal Tracking - [[Arxiv](https://arxiv.org/abs/2303.10826)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10826.md)]
- Cross-GAN Auditing: Unsupervised Identification of Attribute Level   Similarities and Differences between Pretrained Generative Models - [[Arxiv](https://arxiv.org/abs/2303.10774)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10774.md)]
- Fully Self-Supervised Depth Estimation from Defocus Clue - [[Arxiv](https://arxiv.org/abs/2303.10752)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10752.md)]
- Trainable Projected Gradient Method for Robust Fine-tuning - [[Arxiv](https://arxiv.org/abs/2303.10720)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10720.md)]
- NeRF-LOAM: Neural Implicit Representation for Large-Scale Incremental   LiDAR Odometry and Mapping - [[Arxiv](https://arxiv.org/abs/2303.10709)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10709.md)]
- Compatibility of Fundamental Matrices for Complete Viewing Graphs - [[Arxiv](https://arxiv.org/abs/2303.10658)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10658.md)]
- Randomized Adversarial Training via Taylor Expansion - [[Arxiv](https://arxiv.org/abs/2303.10653)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10653.md)]
- StyleRF: Zero-shot 3D Style Transfer of Neural Radiance Fields - [[Arxiv](https://arxiv.org/abs/2303.10598)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10598.md)]
- Partial Network Cloning - [[Arxiv](https://arxiv.org/abs/2303.10597)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10597.md)]
- CLIP4MC: An RL-Friendly Vision-Language Model for Minecraft - [[Arxiv](https://arxiv.org/abs/2303.10571)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10571.md)]
- Divide and Conquer: Answering Questions with Object Factorization and   Compositional Reasoning - [[Arxiv](https://arxiv.org/abs/2303.10482)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10482.md)]
- Is Prompt All You Need? No. A Comprehensive and Broader View of   Instruction Learning - [[Arxiv](https://arxiv.org/abs/2303.10475)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10475.md)]
- Uncertainty-Aware Optimal Transport for Semantically Coherent   Out-of-Distribution Detection - [[Arxiv](https://arxiv.org/abs/2303.10449)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10449.md)]
- Spatial-Aware Token for Weakly Supervised Object Localization - [[Arxiv](https://arxiv.org/abs/2303.10438)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10438.md)]
- Grounding 3D Object Affordance from 2D Interactions in Images - [[Arxiv](https://arxiv.org/abs/2303.10437)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10437.md)]
- DeAR: Debiasing Vision-Language Models with Additive Residuals - [[Arxiv](https://arxiv.org/abs/2303.10431)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10431.md)]
- 3DQD: Generalized Deep 3D Shape Prior via Part-Discretized Diffusion   Process - [[Arxiv](https://arxiv.org/abs/2303.10406)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10406.md)]
- MotionTrack: Learning Robust Short-term and Long-term Motions for   Multi-Object Tracking - [[Arxiv](https://arxiv.org/abs/2303.10404)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10404.md)]
- Sharpness-Aware Gradient Matching for Domain Generalization - [[Arxiv](https://arxiv.org/abs/2303.10353)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10353.md)]
- Extracting Class Activation Maps from Non-Discriminative Features as   well - [[Arxiv](https://arxiv.org/abs/2303.10334)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10334.md)]
- Dynamic Graph Enhanced Contrastive Learning for Chest X-ray Report   Generation - [[Arxiv](https://arxiv.org/abs/2303.10323)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10323.md)]
- CAPE: Camera View Position Embedding for Multi-View 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2303.10209)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10209.md)]
- Unified Mask Embedding and Correspondence Learning for Self-Supervised   Video Segmentation - [[Arxiv](https://arxiv.org/abs/2303.10100)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10100.md)]
- DialogPaint: A Dialog-based Image Editing Model - [[Arxiv](https://arxiv.org/abs/2303.10073)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10073.md)]
- No Fear of Classifier Biases: Neural Collapse Inspired Federated   Learning with Synthetic and Fixed Classifier - [[Arxiv](https://arxiv.org/abs/2303.10058)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.10058.md)]
- Semantic Scene Completion with Cleaner Self - [[Arxiv](https://arxiv.org/abs/2303.09977)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09977.md)]
- Adversarial Counterfactual Visual Explanations - [[Arxiv](https://arxiv.org/abs/2303.09962)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09962.md)]
- Deep Graph-based Spatial Consistency for Robust Non-rigid Point Cloud   Registration - [[Arxiv](https://arxiv.org/abs/2303.09950)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09950.md)]
- Leaping Into Memories: Space-Time Deep Feature Synthesis - [[Arxiv](https://arxiv.org/abs/2303.09941)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09941.md)]
- On the Effects of Self-supervision and Contrastive Alignment in Deep   Multi-view Clustering - [[Arxiv](https://arxiv.org/abs/2303.09877)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09877.md)]
- A Dynamic Multi-Scale Voxel Flow Network for Video Prediction - [[Arxiv](https://arxiv.org/abs/2303.09875)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09875.md)]
- TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation - [[Arxiv](https://arxiv.org/abs/2303.09870)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09870.md)]
- DiffusionRet: Generative Text-Video Retrieval with Diffusion Model - [[Arxiv](https://arxiv.org/abs/2303.09867)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09867.md)]
- Dual-path Adaptation from Image to Video Transformers - [[Arxiv](https://arxiv.org/abs/2303.09857)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09857.md)]
- FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model - [[Arxiv](https://arxiv.org/abs/2303.09833)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09833.md)]
- Hierarchical Prior Mining for Non-local Multi-View Stereo - [[Arxiv](https://arxiv.org/abs/2303.09758)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09758.md)]
- Video Dehazing via a Multi-Range Temporal Alignment Network with   Physical Prior - [[Arxiv](https://arxiv.org/abs/2303.09757)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09757.md)]
- Video Action Recognition with Attentive Semantic Units - [[Arxiv](https://arxiv.org/abs/2303.09756)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09756.md)]
- CoLT5: Faster Long-Range Transformers with Conditional Computation - [[Arxiv](https://arxiv.org/abs/2303.09752)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09752.md)]
- ElasticViT: Conflict-aware Supernet Training for Deploying Fast Vision   Transformer on Diverse Mobile Devices - [[Arxiv](https://arxiv.org/abs/2303.09730)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09730.md)]
- CHAMPAGNE: Learning Real-world Conversation from Large-Scale Web Videos - [[Arxiv](https://arxiv.org/abs/2303.09713)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09713.md)]
- Unsupervised Self-Driving Attention Prediction via Uncertainty Mining   and Knowledge Embedding - [[Arxiv](https://arxiv.org/abs/2303.09706)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09706.md)]
- DiGeo: Discriminative Geometry-Aware Learning for Generalized Few-Shot   Object Detection - [[Arxiv](https://arxiv.org/abs/2303.09674)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09674.md)]
- LOCATE: Localize and Transfer Object Parts for Weakly Supervised   Affordance Grounding - [[Arxiv](https://arxiv.org/abs/2303.09665)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09665.md)]
- Efficient Computation Sharing for Multi-Task Visual Scene Understanding - [[Arxiv](https://arxiv.org/abs/2303.09663)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09663.md)]
- Iterative Soft Shrinkage Learning for Efficient Image Super-Resolution - [[Arxiv](https://arxiv.org/abs/2303.09650)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09650.md)]
- DS-Fusion: Artistic Typography via Discriminated and Stylized Diffusion - [[Arxiv](https://arxiv.org/abs/2303.09604)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09604.md)]
- Efficient Diffusion Training via Min-SNR Weighting Strategy - [[Arxiv](https://arxiv.org/abs/2303.09556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09556.md)]
- PartNeRF: Generating Part-Aware Editable 3D Shapes without 3D   Supervision - [[Arxiv](https://arxiv.org/abs/2303.09554)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09554.md)]
- FateZero: Fusing Attentions for Zero-shot Text-based Video Editing - [[Arxiv](https://arxiv.org/abs/2303.09535)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09535.md)]
- Among Us: Adversarially Robust Collaborative Perception by Consensus - [[Arxiv](https://arxiv.org/abs/2303.09495)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09495.md)]
- Achieving a Better Stability-Plasticity Trade-off via Auxiliary Networks   in Continual Learning - [[Arxiv](https://arxiv.org/abs/2303.09483)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09483.md)]
- DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human   Avatars - [[Arxiv](https://arxiv.org/abs/2303.09375)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09375.md)]
- Hubs and Hyperspheres: Reducing Hubness and Improving Transductive   Few-shot Learning with Hyperspherical Embeddings - [[Arxiv](https://arxiv.org/abs/2303.09352)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09352.md)]
- StylerDALLE: Language-Guided Style Transfer Using a Vector-Quantized   Tokenizer of a Large-Scale Generative Model - [[Arxiv](https://arxiv.org/abs/2303.09268)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09268.md)]
- Rehearsal-Free Domain Continual Face Anti-Spoofing: Generalize More and   Forget Less - [[Arxiv](https://arxiv.org/abs/2303.09914)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09914.md)]
- Towards a Smaller Student: Capacity Dynamic Distillation for Efficient   Image Retrieval - [[Arxiv](https://arxiv.org/abs/2303.09230)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09230.md)]
- Human-AI Collaboration: The Effect of AI Delegation on Human Task   Performance and Task Satisfaction - [[Arxiv](https://arxiv.org/abs/2303.09224)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09224.md)]
- PSVT: End-to-End Multi-person 3D Pose and Shape Estimation with   Progressive Video Transformers - [[Arxiv](https://arxiv.org/abs/2303.09187)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09187.md)]
- Global Knowledge Calibration for Fast Open-Vocabulary Segmentation - [[Arxiv](https://arxiv.org/abs/2303.09181)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09181.md)]
- A New Benchmark: On the Utility of Synthetic Data with Blender for Bare   Supervised Learning and Downstream Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2303.09165)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09165.md)]
- Learning a Room with the Occ-SDF Hybrid: Signed Distance Function   Mingled with Occupancy Aids Scene Representation - [[Arxiv](https://arxiv.org/abs/2303.09152)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09152.md)]
- Taming Diffusion Models for Audio-Driven Co-Speech Gesture Generation - [[Arxiv](https://arxiv.org/abs/2303.09119)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09119.md)]
- Contrastive Semi-supervised Learning for Underwater Image Restoration   via Reliable Bank - [[Arxiv](https://arxiv.org/abs/2303.09101)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09101.md)]
- SLOPER4D: A Scene-Aware Dataset for Global 4D Human Pose Estimation in   Urban Environments - [[Arxiv](https://arxiv.org/abs/2303.09095)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09095.md)]
- MixTeacher: Mining Promising Labels with Mixed Scale Teacher for   Semi-Supervised Object Detection - [[Arxiv](https://arxiv.org/abs/2303.09061)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09061.md)]
- Robust Evaluation of Diffusion-Based Adversarial Purification - [[Arxiv](https://arxiv.org/abs/2303.09051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09051.md)]
- HE is all you need: Compressing FHE Ciphertexts using Additive HE - [[Arxiv](https://arxiv.org/abs/2303.09043)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09043.md)]
- Mimic3D: Thriving 3D-Aware GANs via 3D-to-2D Imitation - [[Arxiv](https://arxiv.org/abs/2303.09036)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09036.md)]
- ART: Automatic multi-step reasoning and tool-use for large language   models - [[Arxiv](https://arxiv.org/abs/2303.09014)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.09014.md)]
- Unified Visual Relationship Detection with Vision and Language Models - [[Arxiv](https://arxiv.org/abs/2303.08998)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08998.md)]
- Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness   with Dataset Reinforcement - [[Arxiv](https://arxiv.org/abs/2303.08983)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08983.md)]
- MAtch, eXpand and Improve: Unsupervised Finetuning for Zero-Shot Action   Recognition with Language Knowledge - [[Arxiv](https://arxiv.org/abs/2303.08914)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08914.md)]
- Stochastic Segmentation with Conditional Categorical Diffusion Models - [[Arxiv](https://arxiv.org/abs/2303.08888)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08888.md)]
- BiFormer: Vision Transformer with Bi-Level Routing Attention - [[Arxiv](https://arxiv.org/abs/2303.08810)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08810.md)]
- PLEX: Making the Most of the Available Data for Robotic Manipulation   Pretraining - [[Arxiv](https://arxiv.org/abs/2303.08789)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08789.md)]
- Re-ReND: Real-time Rendering of NeRFs across Devices - [[Arxiv](https://arxiv.org/abs/2303.08717)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08717.md)]
- Bi-directional Distribution Alignment for Transductive Zero-Shot   Learning - [[Arxiv](https://arxiv.org/abs/2303.08698)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08698.md)]
- Weakly Supervised Monocular 3D Object Detection using Multi-View   Projection and Direction Consistency - [[Arxiv](https://arxiv.org/abs/2303.08686)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08686.md)]
- Making Vision Transformers Efficient from A Token Sparsification View - [[Arxiv](https://arxiv.org/abs/2303.08685)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08685.md)]
- Skinned Motion Retargeting with Residual Perception of Motion Semantics   &amp; Geometry - [[Arxiv](https://arxiv.org/abs/2303.08658)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08658.md)]
- MSeg3D: Multi-modal 3D Semantic Segmentation for Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2303.08600)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08600.md)]
- FastInst: A Simple Query-Based Model for Real-Time Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2303.08594)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08594.md)]
- Watch or Listen: Robust Audio-Visual Speech Recognition with Visual   Corruption Modeling and Reliability Scoring - [[Arxiv](https://arxiv.org/abs/2303.08536)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08536.md)]
- Can Large Language Models design a Robot? - [[Arxiv](https://arxiv.org/abs/2303.15324)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.15324.md)]
- SeqCo-DETR: Sequence Consistency Training for Self-Supervised Object   Detection with Transformers - [[Arxiv](https://arxiv.org/abs/2303.08481)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08481.md)]
- Mutual Information-Based Temporal Difference Learning for Human Pose   Estimation in Video - [[Arxiv](https://arxiv.org/abs/2303.08475)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08475.md)]
- Task-specific Fine-tuning via Variational Information Bottleneck for   Weakly-supervised Pathology Whole Slide Image Classification - [[Arxiv](https://arxiv.org/abs/2303.08446)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08446.md)]
- Improving 3D Imaging with Pre-Trained Perpendicular 2D Diffusion Models - [[Arxiv](https://arxiv.org/abs/2303.08440)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08440.md)]
- Lana: A Language-Capable Navigator for Instruction Following and   Generation - [[Arxiv](https://arxiv.org/abs/2303.08409)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08409.md)]
- Rethinking Optical Flow from Geometric Matching Consistent Perspective - [[Arxiv](https://arxiv.org/abs/2303.08384)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08384.md)]
- Unsupervised Contour Tracking of Live Cells by Mechanical and Cycle   Consistency Losses - [[Arxiv](https://arxiv.org/abs/2303.08364)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08364.md)]
- Active Teacher for Semi-Supervised Object Detection - [[Arxiv](https://arxiv.org/abs/2303.08348)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08348.md)]
- VideoFlow: Exploiting Temporal Cues for Multi-frame Optical Flow   Estimation - [[Arxiv](https://arxiv.org/abs/2303.08340)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08340.md)]
- Towards High-Quality and Efficient Video Super-Resolution via   Spatial-Temporal Data Overfitting - [[Arxiv](https://arxiv.org/abs/2303.08331)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08331.md)]
- VideoFusion: Decomposed Diffusion Models for High-Quality Video   Generation - [[Arxiv](https://arxiv.org/abs/2303.08320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08320.md)]
- FAQ: Feature Aggregated Queries for Transformer-based Video Object   Detectors - [[Arxiv](https://arxiv.org/abs/2303.08319)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08319.md)]
- MSF: Motion-guided Sequential Fusion for Efficient 3D Object Detection   from Point Cloud Sequences - [[Arxiv](https://arxiv.org/abs/2303.08316)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08316.md)]
- SpaceEvo: Hardware-Friendly Search Space Design for Efficient INT8   Inference - [[Arxiv](https://arxiv.org/abs/2303.08308)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08308.md)]
- Chat with the Environment: Interactive Multimodal Perception Using Large   Language Models - [[Arxiv](https://arxiv.org/abs/2303.08268)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08268.md)]
- Rotation-Invariant Transformer for Point Cloud Matching - [[Arxiv](https://arxiv.org/abs/2303.08231)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08231.md)]
- Graph Transformer GANs for Graph-Constrained House Generation - [[Arxiv](https://arxiv.org/abs/2303.08225)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08225.md)]
- Diversity-Aware Meta Visual Prompting - [[Arxiv](https://arxiv.org/abs/2303.08138)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08138.md)]
- LayoutDM: Discrete Diffusion Model for Controllable Layout Generation - [[Arxiv](https://arxiv.org/abs/2303.08137)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08137.md)]
- Manipulate by Seeing: Creating Manipulation Controllers from Pre-Trained   Representations - [[Arxiv](https://arxiv.org/abs/2303.08135)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08135.md)]
- Parameter is Not All You Need: Starting from Non-Parametric Networks for   3D Point Cloud Analysis - [[Arxiv](https://arxiv.org/abs/2303.08134)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08134.md)]
- InstMove: Instance Motion for Object-centric Video Segmentation - [[Arxiv](https://arxiv.org/abs/2303.08132)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08132.md)]
- A Simple Framework for Open-Vocabulary Segmentation and Detection - [[Arxiv](https://arxiv.org/abs/2303.08131)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08131.md)]
- PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D   Object Detection - [[Arxiv](https://arxiv.org/abs/2303.08129)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08129.md)]
- ViperGPT: Visual Inference via Python Execution for Reasoning - [[Arxiv](https://arxiv.org/abs/2303.08128)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08128.md)]
- Blind Video Deflickering by Neural Filtering with a Flawed Atlas - [[Arxiv](https://arxiv.org/abs/2303.08120)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08120.md)]
- Alias-Free Convnets: Fractional Shift Invariance via Polynomial   Activations - [[Arxiv](https://arxiv.org/abs/2303.08085)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08085.md)]
- Editing Implicit Assumptions in Text-to-Image Diffusion Models - [[Arxiv](https://arxiv.org/abs/2303.08084)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08084.md)]
- Window-Based Early-Exit Cascades for Uncertainty Estimation: When Deep   Ensembles are More Efficient than Single Models - [[Arxiv](https://arxiv.org/abs/2303.08010)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08010.md)]
- Non-Contrastive Unsupervised Learning of Physiological Signals from   Video - [[Arxiv](https://arxiv.org/abs/2303.07944)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07944.md)]
- Controllable Mesh Generation Through Sparse Latent Point Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2303.07938)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07938.md)]
- DAA: A Delta Age AdaIN operation for age estimation via binary code   transformer - [[Arxiv](https://arxiv.org/abs/2303.07929)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07929.md)]
- DynaMask: Dynamic Mask Selection for Instance Segmentation - [[Arxiv](https://arxiv.org/abs/2303.07868)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07868.md)]
- You Can Ground Earlier than See: An Effective and Efficient Pipeline for   Temporal Sentence Grounding in Compressed Videos - [[Arxiv](https://arxiv.org/abs/2303.07863)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07863.md)]
- Adaptive Rotated Convolution for Rotated Object Detection - [[Arxiv](https://arxiv.org/abs/2303.07820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07820.md)]
- MobileVOS: Real-Time Video Object Segmentation Contrastive Learning   meets Knowledge Distillation - [[Arxiv](https://arxiv.org/abs/2303.07815)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07815.md)]
- ICICLE: Interpretable Class Incremental Continual Learning - [[Arxiv](https://arxiv.org/abs/2303.07811)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07811.md)]
- USAGE: A Unified Seed Area Generation Paradigm for Weakly Supervised   Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2303.07806)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07806.md)]
- Data-Free Sketch-Based Image Retrieval - [[Arxiv](https://arxiv.org/abs/2303.07775)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07775.md)]
- Good Neighbors Are All You Need for Chinese Grapheme-to-Phoneme   Conversion - [[Arxiv](https://arxiv.org/abs/2303.07726)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07726.md)]
- PATS: Patch Area Transportation with Subdivision for Local Feature   Matching - [[Arxiv](https://arxiv.org/abs/2303.07700)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07700.md)]
- Query2doc: Query Expansion with Large Language Models - [[Arxiv](https://arxiv.org/abs/2303.07678)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07678.md)]
- One scalar is all you need -- absolute depth estimation using monocular   self-supervision - [[Arxiv](https://arxiv.org/abs/2303.07662)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07662.md)]
- NEF: Neural Edge Fields for 3D Parametric Curve Reconstruction from   Multi-view Images - [[Arxiv](https://arxiv.org/abs/2303.07653)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07653.md)]
- SIM: Semantic-aware Instance Mask Generation for Box-Supervised Instance   Segmentation - [[Arxiv](https://arxiv.org/abs/2303.08578)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.08578.md)]
- I$^2$-SDF: Intrinsic Indoor Scene Reconstruction and Editing via   Raytracing in Neural SDFs - [[Arxiv](https://arxiv.org/abs/2303.07634)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07634.md)]
- RE-MOVE: An Adaptive Policy Design for Robotic Navigation Tasks in   Dynamic Environments via Language-Based Feedback - [[Arxiv](https://arxiv.org/abs/2303.07622)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07622.md)]
- The Life Cycle of Knowledge in Big Language Models: A Survey - [[Arxiv](https://arxiv.org/abs/2303.07616)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07616.md)]
- V2V4Real: A Real-world Large-scale Dataset for Vehicle-to-Vehicle   Cooperative Perception - [[Arxiv](https://arxiv.org/abs/2303.07601)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07601.md)]
- Frequency-Modulated Point Cloud Rendering with Easy Editing - [[Arxiv](https://arxiv.org/abs/2303.07596)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07596.md)]
- Unsupervised Cumulative Domain Adaptation for Foggy Scene Optical Flow - [[Arxiv](https://arxiv.org/abs/2303.07564)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07564.md)]
- WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminant   Analysis - [[Arxiv](https://arxiv.org/abs/2303.07543)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07543.md)]
- Audio Visual Language Maps for Robot Navigation - [[Arxiv](https://arxiv.org/abs/2303.07522)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07522.md)]
- FreeNeRF: Improving Few-shot Neural Rendering with Free Frequency   Regularization - [[Arxiv](https://arxiv.org/abs/2303.07418)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07418.md)]
- TriDet: Temporal Action Detection with Relative Boundary Modeling - [[Arxiv](https://arxiv.org/abs/2303.07347)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07347.md)]
- Erasing Concepts from Diffusion Models - [[Arxiv](https://arxiv.org/abs/2303.07345)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07345.md)]
- Revisiting Class-Incremental Learning with Pre-Trained Models:   Generalizability and Adaptivity are All You Need - [[Arxiv](https://arxiv.org/abs/2303.07338)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07338.md)]
- PoseExaminer: Automated Testing of Out-of-Distribution Robustness in   Human Pose and Shape Estimation - [[Arxiv](https://arxiv.org/abs/2303.07337)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07337.md)]
- MP-Former: Mask-Piloted Transformer for Image Segmentation - [[Arxiv](https://arxiv.org/abs/2303.07336)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07336.md)]
- Lite DETR : An Interleaved Multi-Scale Encoder for Efficient DETR - [[Arxiv](https://arxiv.org/abs/2303.07335)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07335.md)]
- Align and Attend: Multimodal Summarization with Dual Contrastive Losses - [[Arxiv](https://arxiv.org/abs/2303.07284)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07284.md)]
- Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of   Synthetic and Compositional Images - [[Arxiv](https://arxiv.org/abs/2303.07274)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07274.md)]
- Efficient Semantic Segmentation by Altering Resolutions for Compressed   Videos - [[Arxiv](https://arxiv.org/abs/2303.07224)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07224.md)]
- Modality-Agnostic Debiasing for Single Domain Generalization - [[Arxiv](https://arxiv.org/abs/2303.07123)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07123.md)]
- Upcycling Models under Domain and Category Shift - [[Arxiv](https://arxiv.org/abs/2303.07110)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07110.md)]
- Prototype-based Embedding Network for Scene Graph Generation - [[Arxiv](https://arxiv.org/abs/2303.07096)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07096.md)]
- MSINet: Twins Contrastive Search of Multi-Scale Interaction for Object   ReID - [[Arxiv](https://arxiv.org/abs/2303.07065)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07065.md)]
- Improving Table Structure Recognition with Visual-Alignment Sequential   Coordinate Modeling - [[Arxiv](https://arxiv.org/abs/2303.06949)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06949.md)]
- TARGET: Federated Class-Continual Learning via Exemplar-Free   Distillation - [[Arxiv](https://arxiv.org/abs/2303.06937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06937.md)]
- Twin Contrastive Learning with Noisy Labels - [[Arxiv](https://arxiv.org/abs/2303.06930)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06930.md)]
- NeRFLiX: High-Quality Neural View Synthesis by Learning a   Degradation-Driven Inter-viewpoint MiXer - [[Arxiv](https://arxiv.org/abs/2303.06919)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06919.md)]
- DR2: Diffusion-based Robust Degradation Remover for Blind Face   Restoration - [[Arxiv](https://arxiv.org/abs/2303.06885)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06885.md)]
- SCPNet: Semantic Scene Completion on Point Cloud - [[Arxiv](https://arxiv.org/abs/2303.06884)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06884.md)]
- Uni3D: A Unified Baseline for Multi-dataset 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2303.06880)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06880.md)]
- Progressive Open Space Expansion for Open-Set Model Attribution - [[Arxiv](https://arxiv.org/abs/2303.06877)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06877.md)]
- Interventional Bag Multi-Instance Learning On Whole-Slide Pathological   Images - [[Arxiv](https://arxiv.org/abs/2303.06873)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06873.md)]
- Three Guidelines You Should Know for Universally Slimmable   Self-Supervised Learning - [[Arxiv](https://arxiv.org/abs/2303.06870)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06870.md)]
- Adaptive Data-Free Quantization - [[Arxiv](https://arxiv.org/abs/2303.06869)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06869.md)]
- FlexGen: High-Throughput Generative Inference of Large Language Models   with a Single GPU - [[Arxiv](https://arxiv.org/abs/2303.06865)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06865.md)]
- Learning Distortion Invariant Representation for Image Restoration from   A Causality Perspective - [[Arxiv](https://arxiv.org/abs/2303.06859)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06859.md)]
- Dynamic Neural Network for Multi-Task Learning Searching across Diverse   Network Topologies - [[Arxiv](https://arxiv.org/abs/2303.06856)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06856.md)]
- DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion - [[Arxiv](https://arxiv.org/abs/2303.06840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06840.md)]
- Label Information Bottleneck for Label Enhancement - [[Arxiv](https://arxiv.org/abs/2303.06836)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06836.md)]
- Transformer-based Planning for Symbolic Regression - [[Arxiv](https://arxiv.org/abs/2303.06833)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06833.md)]
- TranSG: Transformer-Based Skeleton Graph Prototype Contrastive Learning   with Structure-Trajectory Prompted Reconstruction for Person   Re-Identification - [[Arxiv](https://arxiv.org/abs/2303.06819)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06819.md)]
- Backdoor Defense via Deconfounded Representation Learning - [[Arxiv](https://arxiv.org/abs/2303.06818)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06818.md)]
- Traj-MAE: Masked Autoencoders for Trajectory Prediction - [[Arxiv](https://arxiv.org/abs/2303.06697)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06697.md)]
- Self-planning Code Generation with Large Language Models - [[Arxiv](https://arxiv.org/abs/2303.06689)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06689.md)]
- Universal Instance Perception as Object Discovery and Retrieval - [[Arxiv](https://arxiv.org/abs/2303.06674)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06674.md)]
- Iterative Geometry Encoding Volume for Stereo Matching - [[Arxiv](https://arxiv.org/abs/2303.06615)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06615.md)]
- Multi-metrics adaptively identifies backdoors in Federated learning - [[Arxiv](https://arxiv.org/abs/2303.06601)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06601.md)]
- ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched   Visual Descriptions - [[Arxiv](https://arxiv.org/abs/2303.06594)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06594.md)]
- Improving Masked Autoencoders by Learning Where to Mask - [[Arxiv](https://arxiv.org/abs/2303.06583)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06583.md)]
- Large Language Models Know Your Contextual Search Intent: A Prompting   Framework for Conversational Search - [[Arxiv](https://arxiv.org/abs/2303.06573)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06573.md)]
- Gradient-Regulated Meta-Prompt Learning for Generalizable   Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2303.06571)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06571.md)]
- Normal-guided Garment UV Prediction for Human Re-texturing - [[Arxiv](https://arxiv.org/abs/2303.06504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06504.md)]
- Regularized Vector Quantization for Tokenized Image Synthesis - [[Arxiv](https://arxiv.org/abs/2303.06424)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06424.md)]
- ChatGPT Prompt Patterns for Improving Code Quality, Refactoring,   Requirements Elicitation, and Software Design - [[Arxiv](https://arxiv.org/abs/2303.07839)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.07839.md)]
- FAC: 3D Representation Learning via Foreground Aware Feature Contrast - [[Arxiv](https://arxiv.org/abs/2303.06388)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06388.md)]
- Semi-supervised Hand Appearance Recovery via Structure Disentanglement   and Dual Adversarial Discrimination - [[Arxiv](https://arxiv.org/abs/2303.06380)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06380.md)]
- Probing neural representations of scene perception in a hippocampally   dependent task using artificial neural networks - [[Arxiv](https://arxiv.org/abs/2303.06367)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06367.md)]
- MetaViewer: Towards A Unified Multi-View Representation - [[Arxiv](https://arxiv.org/abs/2303.06329)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06329.md)]
- DeltaEdit: Exploring Text-free Training for Text-Driven Image   Manipulation - [[Arxiv](https://arxiv.org/abs/2303.06285)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06285.md)]
- Task and Motion Planning with Large Language Models for Object   Rearrangement - [[Arxiv](https://arxiv.org/abs/2303.06247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06247.md)]
- Who's Thinking? A Push for Human-Centered Evaluation of LLMs using the   XAI Playbook - [[Arxiv](https://arxiv.org/abs/2303.06223)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06223.md)]
- SemARFlow: Injecting Semantics into Unsupervised Optical Flow Estimation   for Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2303.06209)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06209.md)]
- Turning Strengths into Weaknesses: A Certified Robustness Inspired   Attack Framework against Graph Neural Networks - [[Arxiv](https://arxiv.org/abs/2303.06199)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06199.md)]
- Overwriting Pretrained Bias with Finetuning Data - [[Arxiv](https://arxiv.org/abs/2303.06167)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06167.md)]
- StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces - [[Arxiv](https://arxiv.org/abs/2303.06146)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06146.md)]
- MVImgNet: A Large-scale Dataset of Multi-view Images - [[Arxiv](https://arxiv.org/abs/2303.06042)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.06042.md)]
- Accountable Textual-Visual Chat Learns to Reject Human Instructions in   Image Re-creation - [[Arxiv](https://arxiv.org/abs/2303.05983)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05983.md)]
- Neuron Structure Modeling for Generalizable Remote Physiological   Measurement - [[Arxiv](https://arxiv.org/abs/2303.05955)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05955.md)]
- Understanding and Constructing Latent Modality Structures in Multi-modal   Representation Learning - [[Arxiv](https://arxiv.org/abs/2303.05952)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05952.md)]
- ACR: Attention Collaboration-based Regressor for Arbitrary Two-Hand   Reconstruction - [[Arxiv](https://arxiv.org/abs/2303.05938)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05938.md)]
- Structural Multiplane Image: Bridging Neural View Synthesis and 3D   Reconstruction - [[Arxiv](https://arxiv.org/abs/2303.05937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05937.md)]
- GECCO: Geometrically-Conditioned Point Diffusion Models - [[Arxiv](https://arxiv.org/abs/2303.05916)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05916.md)]
- Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection - [[Arxiv](https://arxiv.org/abs/2303.05892)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05892.md)]
- Bi3D: Bi-domain Active Learning for Cross-domain 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2303.05886)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05886.md)]
- TrojDiff: Trojan Attacks on Diffusion Models with Diverse Targets - [[Arxiv](https://arxiv.org/abs/2303.05762)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05762.md)]
- GameFormer: Game-theoretic Modeling and Learning of Transformer-based   Interactive Prediction and Planning for Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2303.05760)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05760.md)]
- Hardware Acceleration of Neural Graphics - [[Arxiv](https://arxiv.org/abs/2303.05735)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05735.md)]
- 3D Cinemagraphy from a Single Image - [[Arxiv](https://arxiv.org/abs/2303.05724)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05724.md)]
- Context-Based Trit-Plane Coding for Progressive Image Compression - [[Arxiv](https://arxiv.org/abs/2303.05715)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05715.md)]
- Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing   Mistake Severity - [[Arxiv](https://arxiv.org/abs/2303.05689)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05689.md)]
- HumanBench: Towards General Human-centric Perception with Projector   Assisted Pretraining - [[Arxiv](https://arxiv.org/abs/2303.05675)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05675.md)]
- Scaling up GANs for Text-to-Image Synthesis - [[Arxiv](https://arxiv.org/abs/2303.05511)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05511.md)]
- Mimic before Reconstruct: Enhancing Masked Autoencoders with Feature   Mimicking - [[Arxiv](https://arxiv.org/abs/2303.05475)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05475.md)]
- Rethinking Range View Representation for LiDAR Segmentation - [[Arxiv](https://arxiv.org/abs/2303.05367)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05367.md)]
- Probability-based Global Cross-modal Upsampling for Pansharpening - [[Arxiv](https://arxiv.org/abs/2303.13659)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.13659.md)]
- 3D Video Loops from Asynchronous Input - [[Arxiv](https://arxiv.org/abs/2303.05312)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05312.md)]
- From Visual Prompt Learning to Zero-Shot Transfer: Mapping Is All You   Need - [[Arxiv](https://arxiv.org/abs/2303.05266)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05266.md)]
- Masked Image Modeling with Local Multi-Scale Reconstruction - [[Arxiv](https://arxiv.org/abs/2303.05251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05251.md)]
- Revisiting Rotation Averaging: Uncertainties and Robust Losses - [[Arxiv](https://arxiv.org/abs/2303.05195)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05195.md)]
- RiDDLE: Reversible and Diversified De-identification with Latent   Encryptor - [[Arxiv](https://arxiv.org/abs/2303.05171)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05171.md)]
- Local Implicit Normalizing Flow for Arbitrary-Scale Image   Super-Resolution - [[Arxiv](https://arxiv.org/abs/2303.05156)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05156.md)]
- Trajectory-Aware Body Interaction Transformer for Multi-Person Pose   Forecasting - [[Arxiv](https://arxiv.org/abs/2303.05095)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05095.md)]
- Efficient Transformer-based 3D Object Detection with Dynamic Token   Halting - [[Arxiv](https://arxiv.org/abs/2303.05078)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05078.md)]
- Identification of Systematic Errors of Image Classifiers on Rare   Subgroups - [[Arxiv](https://arxiv.org/abs/2303.05072)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05072.md)]
- MBPTrack: Improving 3D Point Cloud Tracking with Memory Networks and Box   Priors - [[Arxiv](https://arxiv.org/abs/2303.05071)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05071.md)]
- ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for   Document Information Extraction - [[Arxiv](https://arxiv.org/abs/2303.05063)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05063.md)]
- Lifelong-MonoDepth: Lifelong Learning for Multi-Domain Monocular Metric   Depth Estimation - [[Arxiv](https://arxiv.org/abs/2303.05050)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05050.md)]
- Unifying Layout Generation with a Decoupled Diffusion Model - [[Arxiv](https://arxiv.org/abs/2303.05049)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05049.md)]
- Diversity-Measurable Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2303.05047)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05047.md)]
- CoralStyleCLIP: Co-optimized Region and Layer Selection for Image   Editing - [[Arxiv](https://arxiv.org/abs/2303.05031)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05031.md)]
- Text-Visual Prompting for Efficient 2D Temporal Video Grounding - [[Arxiv](https://arxiv.org/abs/2303.04995)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04995.md)]
- NIFF: Alleviating Forgetting in Generalized Few-Shot Object Detection   via Neural Instance Feature Forging - [[Arxiv](https://arxiv.org/abs/2303.04958)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04958.md)]
- X-Pruner: eXplainable Pruning for Vision Transformers - [[Arxiv](https://arxiv.org/abs/2303.04935)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04935.md)]
- CROSSFIRE: Camera Relocalization On Self-Supervised Features from an   Implicit Representation - [[Arxiv](https://arxiv.org/abs/2303.04869)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04869.md)]
- Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion   Models - [[Arxiv](https://arxiv.org/abs/2303.04803)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04803.md)]
- Cost-Effective Hyperparameter Optimization for Large Language Model   Generation Inference - [[Arxiv](https://arxiv.org/abs/2303.04673)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04673.md)]
- Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation   Models - [[Arxiv](https://arxiv.org/abs/2303.04671)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04671.md)]
- DNBP: Differentiable Nonparametric Belief Propagation - [[Arxiv](https://arxiv.org/abs/2303.04616)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04616.md)]
- A Light Weight Model for Active Speaker Detection - [[Arxiv](https://arxiv.org/abs/2303.04439)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04439.md)]
- Semi-Supervised 2D Human Pose Estimation Driven by Position   Inconsistency Pseudo Label Correction Module - [[Arxiv](https://arxiv.org/abs/2303.04346)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04346.md)]
- Neural Vector Fields: Implicit Representation by Explicit Learning - [[Arxiv](https://arxiv.org/abs/2303.04341)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04341.md)]
- CUDA: Convolution-based Unlearnable Datasets - [[Arxiv](https://arxiv.org/abs/2303.04278)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04278.md)]
- Where We Are and What We're Looking At: Query Based Worldwide Image   Geo-localization Using Hierarchies and Scenes - [[Arxiv](https://arxiv.org/abs/2303.04249)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04249.md)]
- Foundation Models for Decision Making: Problems, Methods, and   Opportunities - [[Arxiv](https://arxiv.org/abs/2303.04129)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04129.md)]
- Meta-Explore: Exploratory Hierarchical Vision-and-Language Navigation   Using Scene Object Spectrum Grounding - [[Arxiv](https://arxiv.org/abs/2303.04077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.04077.md)]
- Multiscale Tensor Decomposition and Rendering Equation Encoding for View   Synthesis - [[Arxiv](https://arxiv.org/abs/2303.03808)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03808.md)]
- Guiding Pseudo-labels with Uncertainty Estimation for Source-free   Unsupervised Domain Adaptation - [[Arxiv](https://arxiv.org/abs/2303.03770)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03770.md)]
- DLT: Conditioned layout generation with Joint Discrete-Continuous   Diffusion Layout Transformer - [[Arxiv](https://arxiv.org/abs/2303.03755)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03755.md)]
- Learning Discriminative Representations for Skeleton Based Action   Recognition - [[Arxiv](https://arxiv.org/abs/2303.03729)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03729.md)]
- MOSO: Decomposing MOtion, Scene and Object for Video Prediction - [[Arxiv](https://arxiv.org/abs/2303.03684)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03684.md)]
- Run, Don't Walk: Chasing Higher FLOPS for Faster Neural Networks - [[Arxiv](https://arxiv.org/abs/2303.03667)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03667.md)]
- No One Left Behind: Improving the Worst Categories in Long-Tailed   Learning - [[Arxiv](https://arxiv.org/abs/2303.03630)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03630.md)]
- LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global   Cross-Modal Fusion - [[Arxiv](https://arxiv.org/abs/2303.03595)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03595.md)]
- Can an Embodied Agent Find Your "Cat-shaped Mug"? LLM-Based Zero-Shot   Object Navigation - [[Arxiv](https://arxiv.org/abs/2303.03480)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03480.md)]
- Structured Kernel Estimation for Photon-Limited Deconvolution - [[Arxiv](https://arxiv.org/abs/2303.03472)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03472.md)]
- PaLM-E: An Embodied Multimodal Language Model - [[Arxiv](https://arxiv.org/abs/2303.03378)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03378.md)]
- Detecting Human-Object Contact in Images - [[Arxiv](https://arxiv.org/abs/2303.03373)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03373.md)]
- Multimodal Prompting with Missing Modalities for Visual Recognition - [[Arxiv](https://arxiv.org/abs/2303.03369)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03369.md)]
- Referring Multi-Object Tracking - [[Arxiv](https://arxiv.org/abs/2303.03366)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03366.md)]
- Nerflets: Local Radiance Fields for Efficient Structure-Aware 3D Scene   Representation from 2D Supervision - [[Arxiv](https://arxiv.org/abs/2303.03361)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03361.md)]
- CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive   Learning - [[Arxiv](https://arxiv.org/abs/2303.03323)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03323.md)]
- MACARONS: Mapping And Coverage Anticipation with RGB Online   Self-Supervision - [[Arxiv](https://arxiv.org/abs/2303.03315)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03315.md)]
- Continuous Sign Language Recognition with Correlation Network - [[Arxiv](https://arxiv.org/abs/2303.03202)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03202.md)]
- Masked Images Are Counterfactual Samples for Robust Fine-tuning - [[Arxiv](https://arxiv.org/abs/2303.03052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03052.md)]
- UniHCP: A Unified Model for Human-Centric Perceptions - [[Arxiv](https://arxiv.org/abs/2303.02936)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02936.md)]
- LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations   and Infographics using Large Language Models - [[Arxiv](https://arxiv.org/abs/2303.02927)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02927.md)]
- DeepMAD: Mathematical Architecture Design for Deep Convolutional Neural   Network - [[Arxiv](https://arxiv.org/abs/2303.02165)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02165.md)]
- Human-Art: A Versatile Human-Centric Dataset Bridging Natural and   Artificial Scenes - [[Arxiv](https://arxiv.org/abs/2303.02760)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02760.md)]
- HairStep: Transfer Synthetic to Real Using Strand and Depth Maps for   Single-View 3D Hair Modeling - [[Arxiv](https://arxiv.org/abs/2303.02700)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02700.md)]
- PyramidFlow: High-Resolution Defect Contrastive Localization using   Pyramid Normalizing Flow - [[Arxiv](https://arxiv.org/abs/2303.02595)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02595.md)]
- Super-Resolution Neural Operator - [[Arxiv](https://arxiv.org/abs/2303.02584)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02584.md)]
- Prismer: A Vision-Language Model with An Ensemble of Experts - [[Arxiv](https://arxiv.org/abs/2303.02506)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02506.md)]
- CapDet: Unifying Dense Captioning and Open-World Detection Pretraining - [[Arxiv](https://arxiv.org/abs/2303.02489)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02489.md)]
- FAME-ViL: Multi-Tasking Vision-Language Model for Heterogeneous Fashion   Tasks - [[Arxiv](https://arxiv.org/abs/2303.02483)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02483.md)]
- DistilPose: Tokenized Pose Regression with Heatmap Distillation - [[Arxiv](https://arxiv.org/abs/2303.02455)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02455.md)]
- ConZIC: Controllable Zero-shot Image Captioning by Sampling-Based   Polishing - [[Arxiv](https://arxiv.org/abs/2303.02437)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02437.md)]
- PixMIM: Rethinking Pixel Reconstruction in Masked Image Modeling - [[Arxiv](https://arxiv.org/abs/2303.02416)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02416.md)]
- Fine-Grained Classification with Noisy Labels - [[Arxiv](https://arxiv.org/abs/2303.02404)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02404.md)]
- NeuDA: Neural Deformable Anchor for High-Fidelity Implicit Surface   Reconstruction - [[Arxiv](https://arxiv.org/abs/2303.02375)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02375.md)]
- Decompose, Adjust, Compose: Effective Normalization by Playing with   Frequency for Domain Generalization - [[Arxiv](https://arxiv.org/abs/2303.02328)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02328.md)]
- MathPrompter: Mathematical Reasoning using Large Language Models - [[Arxiv](https://arxiv.org/abs/2303.05398)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.05398.md)]
- Virtual Sparse Convolution for Multimodal 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2303.02314)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02314.md)]
- Technical Report on: Tripedal Dynamic Gaits for a Quadruped Robot - [[Arxiv](https://arxiv.org/abs/2303.02280)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02280.md)]
- X$^3$KD: Knowledge Distillation Across Modalities, Tasks and Stages for   Multi-Camera 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2303.02203)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02203.md)]
- Unleashing Text-to-Image Diffusion Models for Visual Perception - [[Arxiv](https://arxiv.org/abs/2303.02153)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02153.md)]
- Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong   Few-shot Learners - [[Arxiv](https://arxiv.org/abs/2303.02151)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02151.md)]
- Gradient Norm Aware Minimization Seeks First-Order Flatness and Improves   Generalization - [[Arxiv](https://arxiv.org/abs/2303.03108)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.03108.md)]
- Zero-shot Object Counting - [[Arxiv](https://arxiv.org/abs/2303.02001)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.02001.md)]
- Unsupervised 3D Shape Reconstruction by Part Retrieval and Assembly - [[Arxiv](https://arxiv.org/abs/2303.01999)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01999.md)]
- PointCert: Point Cloud Classification with Deterministic Certified   Robustness Guarantees - [[Arxiv](https://arxiv.org/abs/2303.01959)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01959.md)]
- Spring: A High-Resolution High-Detail Dataset and Benchmark for Scene   Flow, Optical Flow and Stereo - [[Arxiv](https://arxiv.org/abs/2303.01943)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01943.md)]
- MobileBrick: Building LEGO for 3D Reconstruction on Mobile Devices - [[Arxiv](https://arxiv.org/abs/2303.01932)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01932.md)]
- EcoTTA: Memory-Efficient Continual Test-time Adaptation via   Self-distilled Regularization - [[Arxiv](https://arxiv.org/abs/2303.01904)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01904.md)]
- Prompting Large Language Models with Answer Heuristics for   Knowledge-based Visual Question Answering - [[Arxiv](https://arxiv.org/abs/2303.01903)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01903.md)]
- Intrinsic Physical Concepts Discovery with Object-Centric Predictive   Models - [[Arxiv](https://arxiv.org/abs/2303.01869)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01869.md)]
- Visual Exemplar Driven Task-Prompting for Unified Perception in   Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2303.01788)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01788.md)]
- Diverse 3D Hand Gesture Prediction from Body Dynamics by Bilateral Hand   Disentanglement - [[Arxiv](https://arxiv.org/abs/2303.01765)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01765.md)]
- A Complete Recipe for Diffusion Generative Models - [[Arxiv](https://arxiv.org/abs/2303.01748)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01748.md)]
- Towards Domain Generalization for Multi-view 3D Object Detection in   Bird-Eye-View - [[Arxiv](https://arxiv.org/abs/2303.01686)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01686.md)]
- Near Optimal Memory-Regret Tradeoff for Online Learning - [[Arxiv](https://arxiv.org/abs/2303.1673)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.1673.md)]
- Learning Common Rationale to Improve Self-Supervised Representation for   Fine-Grained Visual Recognition Problems - [[Arxiv](https://arxiv.org/abs/2303.01669)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01669.md)]
- WESPER: Zero-shot and Realtime Whisper to Normal Voice Conversion for   Whisper-based Speech Interactions - [[Arxiv](https://arxiv.org/abs/2303.1639)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.1639.md)]
- Hierarchical discriminative learning improves visual representations of   biomedical microscopy - [[Arxiv](https://arxiv.org/abs/2303.01605)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01605.md)]
- A Meta-Learning Approach to Predicting Performance and Data Requirements - [[Arxiv](https://arxiv.org/abs/2303.01598)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01598.md)]
- DejaVu: Conditional Regenerative Learning to Enhance Dense Prediction - [[Arxiv](https://arxiv.org/abs/2303.01573)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01573.md)]
- Improving GAN Training via Feature Space Shrinkage - [[Arxiv](https://arxiv.org/abs/2303.01559)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01559.md)]
- Delivering Arbitrary-Modal Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2303.01480)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01480.md)]
- First Order Quantum Phase Transition in the Hybrid Metal-Mott Insulator   Transition Metal Dichalcogenide 4Hb-TaS2 - [[Arxiv](https://arxiv.org/abs/2303.1447)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.1447.md)]
- Isotopic effects in molecular attosecond photoelectron interferometry - [[Arxiv](https://arxiv.org/abs/2303.1329)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.1329.md)]
- Zero-Shot Text-to-Parameter Translation for Game Character Auto-Creation - [[Arxiv](https://arxiv.org/abs/2303.01311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01311.md)]
- Token Contrast for Weakly-Supervised Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2303.1267)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.1267.md)]
- MixPHM: Redundancy-Aware Parameter-Efficient Tuning for Low-Resource   Visual Question Answering - [[Arxiv](https://arxiv.org/abs/2303.01239)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01239.md)]
- Demystifying Causal Features on Adversarial Examples and Causal   Inoculation for Robust Network by Adversarial Instrumental Variable   Regression - [[Arxiv](https://arxiv.org/abs/2303.01052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01052.md)]
- ACL-SPC: Adaptive Closed-Loop system for Self-Supervised Point Cloud   Completion - [[Arxiv](https://arxiv.org/abs/2303.01979)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01979.md)]
- Neural Intrinsic Embedding for Non-rigid Point Cloud Matching - [[Arxiv](https://arxiv.org/abs/2303.01038)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01038.md)]
- Eulerian-Lagrangian particle-based model for diffusional growth for the   better parameterization of ISM clouds: A road map for improving climate model   through small-scale model using observations - [[Arxiv](https://arxiv.org/abs/2303.0987)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.0987.md)]
- Image Labels Are All You Need for Coarse Seagrass Segmentation - [[Arxiv](https://arxiv.org/abs/2303.00973)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00973.md)]
- Disentangling Orthogonal Planes for Indoor Panoramic Room Layout   Estimation with Cross-Scale Distortion Awareness - [[Arxiv](https://arxiv.org/abs/2303.00971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00971.md)]
- UniDexGrasp: Universal Robotic Dexterous Grasping via Learning Diverse   Proposal Generation and Goal-Conditioned Policy - [[Arxiv](https://arxiv.org/abs/2303.00938)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00938.md)]
- Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation - [[Arxiv](https://arxiv.org/abs/2303.00914)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00914.md)]
- Open-World Object Manipulation using Pre-trained Vision-Language Models - [[Arxiv](https://arxiv.org/abs/2303.00905)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00905.md)]
- Towards Trustable Skin Cancer Diagnosis via Rewriting Model's Decision - [[Arxiv](https://arxiv.org/abs/2303.00885)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00885.md)]
- Grounded Decoding: Guiding Text Generation with Grounded Models for   Robot Control - [[Arxiv](https://arxiv.org/abs/2303.00855)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00855.md)]
- UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and   Distillation of Rerankers - [[Arxiv](https://arxiv.org/abs/2303.00807)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00807.md)]
- WhisperX: Time-Accurate Speech Transcription of Long-Form Audio - [[Arxiv](https://arxiv.org/abs/2303.00747)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00747.md)]
- IPCC-TP: Utilizing Incremental Pearson Correlation Coefficient for Joint   Multi-Agent Trajectory Prediction - [[Arxiv](https://arxiv.org/abs/2303.00575)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00575.md)]
- Quality-aware Pre-trained Models for Blind Image Quality Assessment - [[Arxiv](https://arxiv.org/abs/2303.00521)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00521.md)]
- On the Audio-visual Synchronization for Lip-to-Speech Synthesis - [[Arxiv](https://arxiv.org/abs/2303.00502)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00502.md)]
- Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision - [[Arxiv](https://arxiv.org/abs/2303.00462)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00462.md)]
- Distilled Reverse Attention Network for Open-world Compositional   Zero-Shot Learning - [[Arxiv](https://arxiv.org/abs/2303.00404)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00404.md)]
- A Practical Upper Bound for the Worst-Case Attribution Deviations - [[Arxiv](https://arxiv.org/abs/2303.00340)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00340.md)]
- Can ChatGPT Assess Human Personalities? A General Evaluation Framework - [[Arxiv](https://arxiv.org/abs/2303.01248)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.01248.md)]
- Single Image Backdoor Inversion via Robust Smoothed Classifiers - [[Arxiv](https://arxiv.org/abs/2303.00215)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00215.md)]
- Zyxin is all you need: machine learning adherent cell mechanics - [[Arxiv](https://arxiv.org/abs/2303.00176)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00176.md)]
- Semi-supervised Parametric Real-world Image Harmonization - [[Arxiv](https://arxiv.org/abs/2303.00157)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00157.md)]

### February 2023
- Towards Generalisable Video Moment Retrieval: Visual-Dynamic Injection   to Image-Text Pre-Training - [[Arxiv](https://arxiv.org/abs/2303.00040)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.00040.md)]
- A Comprehensive Perturbative Formalism for Phase Mixing in Perturbed   Disks. II. Phase Spirals in an Inhomogeneous Disk Galaxy with a   Non-responsive Dark Matter Halo - [[Arxiv](https://arxiv.org/abs/2303.0034)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.0034.md)]
- PA&amp;DA: Jointly Sampling PAth and DAta for Consistent NAS - [[Arxiv](https://arxiv.org/abs/2302.14772)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14772.md)]
- Generic-to-Specific Distillation of Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2302.14771)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14771.md)]
- Mask3D: Pre-training 2D Vision Transformers by Learning Masked 3D Priors - [[Arxiv](https://arxiv.org/abs/2302.14746)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14746.md)]
- Which One Are You Referring To? Multimodal Object Identification in   Situated Dialogue - [[Arxiv](https://arxiv.org/abs/2302.14680)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14680.md)]
- Backdoor Attacks Against Deep Image Compression via Adaptive Frequency   Trigger - [[Arxiv](https://arxiv.org/abs/2302.14677)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14677.md)]
- Attention-based Point Cloud Edge Sampling - [[Arxiv](https://arxiv.org/abs/2302.14673)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14673.md)]
- Focus On Details: Online Multi-object Tracking with Diverse Fine-grained   Representation - [[Arxiv](https://arxiv.org/abs/2302.14589)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14589.md)]
- Interactive Segmentation as Gaussian Process Classification - [[Arxiv](https://arxiv.org/abs/2302.14578)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14578.md)]
- A Little Bit Attention Is All You Need for Person Re-Identification - [[Arxiv](https://arxiv.org/abs/2302.14574)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14574.md)]
- A Hierarchical Representation Network for Accurate and Detailed Face   Reconstruction from In-The-Wild Images - [[Arxiv](https://arxiv.org/abs/2302.14434)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14434.md)]
- DREAM: Efficient Dataset Distillation by Representative Matching - [[Arxiv](https://arxiv.org/abs/2302.14416)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14416.md)]
- Neural Video Compression with Diverse Contexts - [[Arxiv](https://arxiv.org/abs/2302.14402)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14402.md)]
- GLM-Dialog: Noise-tolerant Pre-training for Knowledge-grounded Dialogue   Generation - [[Arxiv](https://arxiv.org/abs/2302.14401)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14401.md)]
- HelixSurf: A Robust and Efficient Neural Implicit Surface Learning of   Indoor Scenes with Iterative Intertwined Regularization - [[Arxiv](https://arxiv.org/abs/2302.14340)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14340.md)]
- Markerless Camera-to-Robot Pose Estimation via Self-supervised   Sim-to-Real Transfer - [[Arxiv](https://arxiv.org/abs/2302.14332)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14332.md)]
- BEVPlace: Learning LiDAR-based Place Recognition using Bird's Eye View   Images - [[Arxiv](https://arxiv.org/abs/2302.14325)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14325.md)]
- Towards Memory- and Time-Efficient Backpropagation for Training Spiking   Neural Networks - [[Arxiv](https://arxiv.org/abs/2302.14311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14311.md)]
- GradMA: A Gradient-Memory-based Accelerated Federated Learning with   Alleviated Catastrophic Forgetting - [[Arxiv](https://arxiv.org/abs/2302.14307)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14307.md)]
- Learning to Retain while Acquiring: Combating Distribution-Shift in   Adversarial Data-Free Knowledge Distillation - [[Arxiv](https://arxiv.org/abs/2302.14290)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14290.md)]
- Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense   Video Captioning - [[Arxiv](https://arxiv.org/abs/2302.14115)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14115.md)]
- Internet Explorer: Targeted Representation Learning on the Open Web - [[Arxiv](https://arxiv.org/abs/2302.14051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14051.md)]
- Language Is Not All You Need: Aligning Perception with Language Models - [[Arxiv](https://arxiv.org/abs/2302.14045)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.14045.md)]
- Aligning Bag of Regions for Open-Vocabulary Object Detection - [[Arxiv](https://arxiv.org/abs/2302.13996)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.13996.md)]
- LLaMA: Open and Efficient Foundation Language Models - [[Arxiv](https://arxiv.org/abs/2302.13971)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.13971.md)]
- Communication-efficient Federated Learning with Single-Step Synthetic   Features Compressor for Faster Convergence - [[Arxiv](https://arxiv.org/abs/2302.13562)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.13562.md)]
- Navigating the Grey Area: Expressions of Overconfidence and Uncertainty   in Language Models - [[Arxiv](https://arxiv.org/abs/2302.13439)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.13439.md)]
- Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting - [[Arxiv](https://arxiv.org/abs/2302.13130)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.13130.md)]
- Raw Image Reconstruction with Learned Compact Metadata - [[Arxiv](https://arxiv.org/abs/2302.12995)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.12995.md)]
- Self-similarity Driven Scale-invariant Learning for Weakly Supervised   Person Search - [[Arxiv](https://arxiv.org/abs/2302.12986)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.12986.md)]
- Control flow in active inference systems - [[Arxiv](https://arxiv.org/abs/2303.1514)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2303.1514.md)]
- From Occlusion to Insight: Object Search in Semantic Shelves using Large   Language Models - [[Arxiv](https://arxiv.org/abs/2302.12915)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.12915.md)]
- SplineCam: Exact Visualization and Characterization of Deep Network   Geometry and Decision Boundaries - [[Arxiv](https://arxiv.org/abs/2302.12828)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.12828.md)]
- Decoupling Human and Camera Motion from Videos in the Wild - [[Arxiv](https://arxiv.org/abs/2302.12827)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.12827.md)]
- Automatic Prompt Augmentation and Selection with Chain-of-Thought from   Labeled Data - [[Arxiv](https://arxiv.org/abs/2302.12822)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.12822.md)]
- VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene   Completion - [[Arxiv](https://arxiv.org/abs/2302.12251)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.12251.md)]
- Active Prompting with Chain-of-Thought for Large Language Models - [[Arxiv](https://arxiv.org/abs/2302.12246)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.12246.md)]
- Side Adapter Network for Open-Vocabulary Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2302.12242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.12242.md)]
- DiffusioNeRF: Regularizing Neural Radiance Fields with Denoising   Diffusion Models - [[Arxiv](https://arxiv.org/abs/2302.12231)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.12231.md)]
- Aligning Text-to-Image Models using Human Feedback - [[Arxiv](https://arxiv.org/abs/2302.12192)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.12192.md)]
- Can Pre-trained Vision and Language Models Answer Visual   Information-Seeking Questions? - [[Arxiv](https://arxiv.org/abs/2302.11713)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.11713.md)]
- Some Might Say All You Need Is Sum - [[Arxiv](https://arxiv.org/abs/2302.11603)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.11603.md)]
- Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via   Self-supervised Scene Decomposition - [[Arxiv](https://arxiv.org/abs/2302.11566)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.11566.md)]
- Connecting Vision and Language with Video Localized Narratives - [[Arxiv](https://arxiv.org/abs/2302.11217)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.11217.md)]
- Distributionally Robust Recourse Action - [[Arxiv](https://arxiv.org/abs/2302.11211)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.11211.md)]
- Open-domain Visual Entity Recognition: Towards Recognizing Millions of   Wikipedia Entities - [[Arxiv](https://arxiv.org/abs/2302.11154)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.11154.md)]
- Hyena Hierarchy: Towards Larger Convolutional Language Models - [[Arxiv](https://arxiv.org/abs/2302.10866)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.10866.md)]
- Seasoning Model Soups for Robustness to Adversarial and Natural   Distribution Shifts - [[Arxiv](https://arxiv.org/abs/2302.10164)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.10164.md)]
- Zero-Shot Information Extraction via Chatting with ChatGPT - [[Arxiv](https://arxiv.org/abs/2302.10205)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.10205.md)]
- Prompt Stealing Attacks Against Text-to-Image Generation Models - [[Arxiv](https://arxiv.org/abs/2302.09923)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.09923.md)]
- EuroCrops: All you need to know about the Largest Harmonised Open Crop   Dataset Across the European Union - [[Arxiv](https://arxiv.org/abs/2302.10202)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.10202.md)]
- ChatGPT for Robotics: Design Principles and Model Abilities - [[Arxiv](https://arxiv.org/abs/2306.17582)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2306.17582.md)]
- Weakly Supervised Label Learning Flows - [[Arxiv](https://arxiv.org/abs/2302.09649)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.09649.md)]
- Temporal Interpolation Is All You Need for Dynamic Neural Radiance   Fields - [[Arxiv](https://arxiv.org/abs/2302.09311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.09311.md)]
- StyleAdv: Meta Style Adversarial Training for Cross-Domain Few-Shot   Learning - [[Arxiv](https://arxiv.org/abs/2302.09309)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.09309.md)]
- Recent Advances towards Safe, Responsible, and Moral Dialogue Systems: A   Survey - [[Arxiv](https://arxiv.org/abs/2302.09270)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.09270.md)]
- Invertible Neural Skinning - [[Arxiv](https://arxiv.org/abs/2302.09227)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.09227.md)]
- Complex QA and language models hybrid architectures, Survey - [[Arxiv](https://arxiv.org/abs/2302.09051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.09051.md)]
- Are Gaussian data all you need? Extents and limits of universality in   high-dimensional generalized linear estimation - [[Arxiv](https://arxiv.org/abs/2302.08923)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.08923.md)]
- A survey on online active learning - [[Arxiv](https://arxiv.org/abs/2302.08893)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.08893.md)]
- MixNeRF: Modeling a Ray with Mixture Density for Novel View Synthesis   from Sparse Inputs - [[Arxiv](https://arxiv.org/abs/2302.08788)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.08788.md)]
- Conformers are All You Need for Visual Speech Recogntion - [[Arxiv](https://arxiv.org/abs/2302.10915)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.10915.md)]
- 3D-aware Conditional Image Synthesis - [[Arxiv](https://arxiv.org/abs/2302.08509)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.08509.md)]
- PersonNeRF: Personalized Reconstruction from Photo Collections - [[Arxiv](https://arxiv.org/abs/2302.08504)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.08504.md)]
- Tuning computer vision models with task rewards - [[Arxiv](https://arxiv.org/abs/2302.08242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.08242.md)]
- Aligning Language Models with Preferences through f-divergence   Minimization - [[Arxiv](https://arxiv.org/abs/2302.08215)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.08215.md)]
- Parallax-Tolerant Unsupervised Deep Image Stitching - [[Arxiv](https://arxiv.org/abs/2302.08207)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.08207.md)]
- Ã-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable   Prompting - [[Arxiv](https://arxiv.org/abs/2302.07994)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.07994.md)]
- One-Shot Face Video Re-enactment using Hybrid Latent Spaces of StyleGAN2 - [[Arxiv](https://arxiv.org/abs/2302.07848)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.07848.md)]
- Augmented Language Models: a Survey - [[Arxiv](https://arxiv.org/abs/2302.07842)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.07842.md)]
- Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction - [[Arxiv](https://arxiv.org/abs/2302.07817)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.07817.md)]
- Video Probabilistic Diffusion Models in Projected Latent Space - [[Arxiv](https://arxiv.org/abs/2302.07685)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.07685.md)]
- LiveHand: Real-time and Photorealistic Neural Hand Rendering - [[Arxiv](https://arxiv.org/abs/2302.07672)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.07672.md)]
- The Capacity for Moral Self-Correction in Large Language Models - [[Arxiv](https://arxiv.org/abs/2302.07459)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.07459.md)]
- PolyFormer: Referring Image Segmentation as Sequential Polygon   Generation - [[Arxiv](https://arxiv.org/abs/2302.07387)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.07387.md)]
- Painting 3D Nature in 2D: View Synthesis of Natural Scenes from a Single   Semantic Mask - [[Arxiv](https://arxiv.org/abs/2302.07224)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.07224.md)]
- VQ3D: Learning a 3D-Aware Generative Model on ImageNet - [[Arxiv](https://arxiv.org/abs/2302.06833)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.06833.md)]
- Learning from Noisy Labels with Decoupled Meta Label Purifier - [[Arxiv](https://arxiv.org/abs/2302.06810)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.06810.md)]
- Learning with Noisy labels via Self-supervised Adversarial Noisy Masking - [[Arxiv](https://arxiv.org/abs/2302.06805)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.06805.md)]
- The Stable Entropy Hypothesis and Entropy-Aware Decoding: An Analysis   and Algorithm for Robust Natural Language Generation - [[Arxiv](https://arxiv.org/abs/2302.06784)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.06784.md)]
- Robust Unsupervised StyleGAN Image Restoration - [[Arxiv](https://arxiv.org/abs/2302.06733)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.06733.md)]
- Stitchable Neural Networks - [[Arxiv](https://arxiv.org/abs/2302.06586)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.06586.md)]
- A Reparameterized Discrete Diffusion Model for Text Generation - [[Arxiv](https://arxiv.org/abs/2302.05737)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.05737.md)]
- Compositional Exemplars for In-context Learning - [[Arxiv](https://arxiv.org/abs/2302.05698)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.05698.md)]
- Adding Conditional Control to Text-to-Image Diffusion Models - [[Arxiv](https://arxiv.org/abs/2302.05543)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.05543.md)]
- MaskSketch: Unpaired Structure-guided Masked Image Generation - [[Arxiv](https://arxiv.org/abs/2302.05496)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.05496.md)]
- The Wisdom of Hindsight Makes Language Models Better Instruction   Followers - [[Arxiv](https://arxiv.org/abs/2302.05206)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.05206.md)]
- MEGANE: Morphable Eyeglass and Avatar Network - [[Arxiv](https://arxiv.org/abs/2302.04868)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.04868.md)]
- RelightableHands: Efficient Neural Relighting of Articulated Hand Models - [[Arxiv](https://arxiv.org/abs/2302.04866)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.04866.md)]
- Toolformer: Language Models Can Teach Themselves to Use Tools - [[Arxiv](https://arxiv.org/abs/2302.04761)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.04761.md)]
- Q-Diffusion: Quantizing Diffusion Models - [[Arxiv](https://arxiv.org/abs/2302.04304)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.04304.md)]
- Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models - [[Arxiv](https://arxiv.org/abs/2302.04222)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.04222.md)]
- On the Computational Complexity of Ethics: Moral Tractability for Minds   and Machines - [[Arxiv](https://arxiv.org/abs/2302.04218)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.04218.md)]
- GPTScore: Evaluate as You Desire - [[Arxiv](https://arxiv.org/abs/2302.04166)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.04166.md)]
- A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on   Reasoning, Hallucination, and Interactivity - [[Arxiv](https://arxiv.org/abs/2302.04023)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.04023.md)]
- Is ChatGPT a General-Purpose Natural Language Processing Task Solver? - [[Arxiv](https://arxiv.org/abs/2302.06476)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.06476.md)]
- Neural Congealing: Aligning Images to a Joint Semantic Atlas - [[Arxiv](https://arxiv.org/abs/2302.03956)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.03956.md)]
- Zero-shot Generation of Coherent Storybook from Plain Text Story using   Diffusion Models - [[Arxiv](https://arxiv.org/abs/2302.03900)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.03900.md)]
- Controlling Personality Style in Dialogue with Zero-Shot Prompt-Based   Learning - [[Arxiv](https://arxiv.org/abs/2302.03848)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.03848.md)]
- Standing Between Past and Future: Spatio-Temporal Modeling for   Multi-Camera 3D Multi-Object Tracking - [[Arxiv](https://arxiv.org/abs/2302.03802)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.03802.md)]
- Long Horizon Temperature Scaling - [[Arxiv](https://arxiv.org/abs/2302.03686)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.03686.md)]
- HumanMAC: Masked Motion Completion for Human Motion Prediction - [[Arxiv](https://arxiv.org/abs/2302.03665)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.03665.md)]
- Fair Diffusion: Instructing Text-to-Image Generation Models on Fairness - [[Arxiv](https://arxiv.org/abs/2302.10893)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.10893.md)]
- OSRT: Omnidirectional Image Super-Resolution with Distortion-aware   Transformer - [[Arxiv](https://arxiv.org/abs/2302.03453)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.03453.md)]
- Pic2Word: Mapping Pictures to Words for Zero-shot Composed Image   Retrieval - [[Arxiv](https://arxiv.org/abs/2302.03084)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.03084.md)]
- Structure and Content-Guided Video Synthesis with Diffusion Models - [[Arxiv](https://arxiv.org/abs/2302.03011)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.03011.md)]
- LexLIP: Lexicon-Bottlenecked Language-Image Pre-Training for Large-Scale   Image-Text Retrieval - [[Arxiv](https://arxiv.org/abs/2302.02908)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.02908.md)]
- Chain of Hindsight Aligns Language Models with Feedback - [[Arxiv](https://arxiv.org/abs/2302.02676)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.02676.md)]
- Rethinking Out-of-distribution (OOD) Detection: Masked Image Modeling is   All You Need - [[Arxiv](https://arxiv.org/abs/2302.02615)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.02615.md)]
- Decoupled Iterative Refinement Framework for Interacting Hands   Reconstruction from a Single RGB Image - [[Arxiv](https://arxiv.org/abs/2302.02410)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.02410.md)]
- Contrast with Reconstruct: Contrastive 3D Representation Learning Guided   by Generative Pretraining - [[Arxiv](https://arxiv.org/abs/2302.02318)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.02318.md)]
- MOMA:Distill from Self-Supervised Teachers - [[Arxiv](https://arxiv.org/abs/2302.02089)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.02089.md)]
- Aligning Robot and Human Representations - [[Arxiv](https://arxiv.org/abs/2302.01928)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.01928.md)]
- MOSE: A New Dataset for Video Object Segmentation in Complex Scenes - [[Arxiv](https://arxiv.org/abs/2302.01872)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.01872.md)]
- vMAP: Vectorised Object Mapping for Neural Field SLAM - [[Arxiv](https://arxiv.org/abs/2302.01838)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.01838.md)]
- Robust Camera Pose Refinement for Multi-Resolution Hash Encoding - [[Arxiv](https://arxiv.org/abs/2302.01571)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.01571.md)]
- Describe, Explain, Plan and Select: Interactive Planning with Large   Language Models Enables Open-World Multi-Task Agents - [[Arxiv](https://arxiv.org/abs/2302.01560)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.01560.md)]
- Inference in Non-stationary High-Dimensional VARs - [[Arxiv](https://arxiv.org/abs/2302.1434)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.1434.md)]
- Accelerating Policy Gradient by Estimating Value Function from Prior   Computation in Deep Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2302.01399)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.01399.md)]
- Accelerating Large Language Model Decoding with Speculative Sampling - [[Arxiv](https://arxiv.org/abs/2302.01318)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.01318.md)]
- Are Diffusion Models Vulnerable to Membership Inference Attacks? - [[Arxiv](https://arxiv.org/abs/2302.01316)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.01316.md)]
- Boosting Low-Data Instance Segmentation by Unsupervised Pre-training   with Saliency Prompt - [[Arxiv](https://arxiv.org/abs/2302.01171)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.01171.md)]
- Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model using   Pixel-aligned Reconstruction Priors - [[Arxiv](https://arxiv.org/abs/2302.01162)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.01162.md)]
- Real-Time Evaluation in Online Continual Learning: A New Hope - [[Arxiv](https://arxiv.org/abs/2302.01047)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.01047.md)]
- HaMuCo: Hand Pose Estimation via Multiview Collaborative Self-Supervised   Learning - [[Arxiv](https://arxiv.org/abs/2302.00988)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.00988.md)]
- Multimodal Chain-of-Thought Reasoning in Language Models - [[Arxiv](https://arxiv.org/abs/2302.00923)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.00923.md)]
- Language Quantized AutoEncoders: Towards Unsupervised Text-Image   Alignment - [[Arxiv](https://arxiv.org/abs/2302.00902)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.00902.md)]
- Collaborating with language models for embodied reasoning - [[Arxiv](https://arxiv.org/abs/2302.00763)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.00763.md)]
- Synthetic Prompting: Generating Chain-of-Thought Demonstrations for   Large Language Models - [[Arxiv](https://arxiv.org/abs/2302.00618)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.00618.md)]
- Compositional Prompt Tuning with Motion Cues for Open-vocabulary Video   Relation Detection - [[Arxiv](https://arxiv.org/abs/2302.00268)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.00268.md)]

### January 2023
- Learning Universal Policies via Text-Guided Video Generation - [[Arxiv](https://arxiv.org/abs/2302.00111)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.00111.md)]
- Large Language Models Can Be Easily Distracted by Irrelevant Context - [[Arxiv](https://arxiv.org/abs/2302.00093)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.00093.md)]
- Debiasing Vision-Language Models via Biased Prompts - [[Arxiv](https://arxiv.org/abs/2302.00070)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.00070.md)]
- Grounding Language Models to Images for Multimodal Inputs and Outputs - [[Arxiv](https://arxiv.org/abs/2301.13823)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.13823.md)]
- Large Language Models are Versatile Decomposers: Decompose Evidence and   Questions for Table-based Reasoning - [[Arxiv](https://arxiv.org/abs/2301.13808)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.13808.md)]
- The Flan Collection: Designing Data and Methods for Effective   Instruction Tuning - [[Arxiv](https://arxiv.org/abs/2301.13688)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.13688.md)]
- Anti-Exploration by Random Network Distillation - [[Arxiv](https://arxiv.org/abs/2301.13616)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.13616.md)]
- Faithful Chain-of-Thought Reasoning - [[Arxiv](https://arxiv.org/abs/2301.13379)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.13379.md)]
- Neural Operator: Is data all you need to model the world? An insight   into the impact of Physics Informed Machine Learning - [[Arxiv](https://arxiv.org/abs/2301.13331)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.13331.md)]
- Shape-aware Text-driven Layered Video Editing - [[Arxiv](https://arxiv.org/abs/2301.13173)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.13173.md)]
- GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis - [[Arxiv](https://arxiv.org/abs/2301.12959)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.12959.md)]
- DepGraph: Towards Any Structural Pruning - [[Arxiv](https://arxiv.org/abs/2301.12900)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.12900.md)]
- Red teaming ChatGPT via Jailbreaking: Bias, Robustness, Reliability and   Toxicity - [[Arxiv](https://arxiv.org/abs/2301.12867)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.12867.md)]
- Direct Preference-based Policy Optimization without Reward Modeling - [[Arxiv](https://arxiv.org/abs/2301.12842)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.12842.md)]
- Specializing Smaller Language Models towards Multi-Step Reasoning - [[Arxiv](https://arxiv.org/abs/2301.12726)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.12726.md)]
- Adversarial Style Augmentation for Domain Generalization - [[Arxiv](https://arxiv.org/abs/2301.12643)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.12643.md)]
- BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image   Encoders and Large Language Models - [[Arxiv](https://arxiv.org/abs/2301.12597)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.12597.md)]
- Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making   using Language Guided World Modelling - [[Arxiv](https://arxiv.org/abs/2301.12050)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.12050.md)]
- Understanding the Effectiveness of Very Large Language Models on Dialog   Evaluation - [[Arxiv](https://arxiv.org/abs/2301.12004)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.12004.md)]
- Generalized Munchausen Reinforcement Learning using Tsallis KL   Divergence - [[Arxiv](https://arxiv.org/abs/2301.11476)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.11476.md)]
- Unsupervised Volumetric Animation - [[Arxiv](https://arxiv.org/abs/2301.11326)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.11326.md)]
- Cut and Learn for Unsupervised Object Detection and Instance   Segmentation - [[Arxiv](https://arxiv.org/abs/2301.11320)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.11320.md)]
- Principled Reinforcement Learning with Human Feedback from Pairwise or   $K$-wise Comparisons - [[Arxiv](https://arxiv.org/abs/2301.11270)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.11270.md)]
- On the Importance of Noise Scheduling for Diffusion Models - [[Arxiv](https://arxiv.org/abs/2301.10972)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.10972.md)]
- Causal Reasoning of Entities and Events in Procedural Texts - [[Arxiv](https://arxiv.org/abs/2301.10896)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.10896.md)]
- ExaRanker: Explanation-Augmented Neural Ranker - [[Arxiv](https://arxiv.org/abs/2301.10521)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.10521.md)]
- HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling - [[Arxiv](https://arxiv.org/abs/2301.10460)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.10460.md)]
- RangeViT: Towards Vision Transformers for 3D Semantic Segmentation in   Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2301.10222)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.10222.md)]
- Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2301.10100)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.10100.md)]
- HexPlane: A Fast Representation for Dynamic Scenes - [[Arxiv](https://arxiv.org/abs/2301.09632)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.09632.md)]
- OvarNet: Towards Open-vocabulary Object Attribute Recognition - [[Arxiv](https://arxiv.org/abs/2301.09506)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.09506.md)]
- GP-NAS-ensemble: a model for NAS Performance Prediction - [[Arxiv](https://arxiv.org/abs/2301.09231)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.09231.md)]
- Learning Open-vocabulary Semantic Segmentation Models From Natural   Language Supervision - [[Arxiv](https://arxiv.org/abs/2301.09121)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.09121.md)]
- BallGAN: 3D-aware Image Synthesis with a Spherical Background - [[Arxiv](https://arxiv.org/abs/2301.09091)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.09091.md)]
- Regeneration Learning: A Learning Paradigm for Data Generation - [[Arxiv](https://arxiv.org/abs/2301.08846)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.08846.md)]
- FlatFormer: Flattened Window Attention for Efficient Point Cloud   Transformer - [[Arxiv](https://arxiv.org/abs/2301.08739)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.08739.md)]
- Novel-View Acoustic Synthesis - [[Arxiv](https://arxiv.org/abs/2301.08730)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.08730.md)]
- Neural Architecture Search: Insights from 1000 Papers - [[Arxiv](https://arxiv.org/abs/2301.08727)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.08727.md)]
- Open-Set Likelihood Maximization for Few-Shot Learning - [[Arxiv](https://arxiv.org/abs/2301.08390)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.08390.md)]
- Multiview Compressive Coding for 3D Reconstruction - [[Arxiv](https://arxiv.org/abs/2301.08247)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.08247.md)]
- Self-Supervised Learning from Images with a Joint-Embedding Predictive   Architecture - [[Arxiv](https://arxiv.org/abs/2301.08243)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.08243.md)]
- Masked Autoencoding Does Not Help Natural Language Supervision at Scale - [[Arxiv](https://arxiv.org/abs/2301.07836)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.07836.md)]
- NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via   Novel-View Synthesis - [[Arxiv](https://arxiv.org/abs/2301.08556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.08556.md)]
- Learning 3D-aware Image Synthesis with Unknown Pose Distribution - [[Arxiv](https://arxiv.org/abs/2301.07702)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.07702.md)]
- OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic   Perception, Reconstruction and Generation - [[Arxiv](https://arxiv.org/abs/2301.07525)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.07525.md)]
- Behind the Scenes: Density Fields for Single View Reconstruction - [[Arxiv](https://arxiv.org/abs/2301.07668)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.07668.md)]
- PIRLNav: Pretraining with Imitation and RL Finetuning for ObjectNav - [[Arxiv](https://arxiv.org/abs/2301.07302)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.07302.md)]
- Understanding the Role of Human Intuition on Reliance in Human-AI   Decision-Making with Explanations - [[Arxiv](https://arxiv.org/abs/2301.07255)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.07255.md)]
- Learning Customized Visual Models with Retrieval-Augmented Knowledge - [[Arxiv](https://arxiv.org/abs/2301.07094)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.07094.md)]
- GLIGEN: Open-Set Grounded Text-to-Image Generation - [[Arxiv](https://arxiv.org/abs/2301.07093)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.07093.md)]
- Long Range Pooling for 3D Large-Scale Scene Understanding - [[Arxiv](https://arxiv.org/abs/2301.06962)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.06962.md)]
- Event-based Shape from Polarization - [[Arxiv](https://arxiv.org/abs/2301.06855)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.06855.md)]
- A Large-Scale Outdoor Multi-modal Dataset and Benchmark for Novel View   Synthesis and Implicit Scene Reconstruction - [[Arxiv](https://arxiv.org/abs/2301.06782)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.06782.md)]
- FemtoDet: An Object Detection Baseline for Energy Versus Performance   Tradeoffs - [[Arxiv](https://arxiv.org/abs/2301.06719)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.06719.md)]
- Dissociating language and thought in large language models: a cognitive   perspective - [[Arxiv](https://arxiv.org/abs/2301.06627)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.06627.md)]
- DPE: Disentanglement of Pose and Expression for General Video Portrait   Editing - [[Arxiv](https://arxiv.org/abs/2301.06281)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.06281.md)]
- Multimodality Helps Unimodality: Cross-Modal Few-Shot Learning with   Multimodal Models - [[Arxiv](https://arxiv.org/abs/2301.06267)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.06267.md)]
- T2M-GPT: Generating Human Motion from Textual Descriptions with Discrete   Representations - [[Arxiv](https://arxiv.org/abs/2301.06052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.06052.md)]
- DSVT: Dynamic Sparse Voxel Transformer with Rotated Sets - [[Arxiv](https://arxiv.org/abs/2301.06051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.06051.md)]
- CMAE-V: Contrastive Masked Autoencoders for Video Action Recognition - [[Arxiv](https://arxiv.org/abs/2301.06018)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.06018.md)]
- TikTalk: A Video-Based Dialogue Dataset for Multi-Modal Chitchat in Real   World - [[Arxiv](https://arxiv.org/abs/2301.05880)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.05880.md)]
- Leveraging Large Language Models to Power Chatbots for Collecting User   Self-Reported Data - [[Arxiv](https://arxiv.org/abs/2301.05843)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.05843.md)]
- CLIP the Gap: A Single Domain Generalization Approach for Object   Detection - [[Arxiv](https://arxiv.org/abs/2301.05499)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.05499.md)]
- Learning Transformations To Reduce the Geometric Shift in Object   Detection - [[Arxiv](https://arxiv.org/abs/2301.05496)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.05496.md)]
- Self-Supervised Image-to-Point Distillation via Semantically Tolerant   Contrastive Loss - [[Arxiv](https://arxiv.org/abs/2301.05709)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.05709.md)]
- Domain Expansion of Image Generators - [[Arxiv](https://arxiv.org/abs/2301.05225)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.05225.md)]
- Open-vocabulary Object Segmentation with Diffusion Models - [[Arxiv](https://arxiv.org/abs/2301.05221)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.05221.md)]
- Accidental Light Probes - [[Arxiv](https://arxiv.org/abs/2301.05211)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.05211.md)]
- Event-Based Frame Interpolation with Ad-hoc Deblurring - [[Arxiv](https://arxiv.org/abs/2301.05191)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.05191.md)]
- ViTs for SITS: Vision Transformers for Satellite Image Time Series - [[Arxiv](https://arxiv.org/abs/2301.04944)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.04944.md)]
- CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP - [[Arxiv](https://arxiv.org/abs/2301.04926)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.04926.md)]
- Learning to Memorize Entailment and Discourse Relations for   Persona-Consistent Dialogues - [[Arxiv](https://arxiv.org/abs/2301.04871)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.04871.md)]
- Self-supervised Learning for Segmentation and Quantification of Dopamine   Neurons in Parkinson's Disease - [[Arxiv](https://arxiv.org/abs/2301.08141)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.08141.md)]
- EXIF as Language: Learning Cross-Modal Associations Between Images and   Camera Metadata - [[Arxiv](https://arxiv.org/abs/2301.04647)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.04647.md)]
- LinkGAN: Linking GAN Latents to Pixels for Controllable Image Synthesis - [[Arxiv](https://arxiv.org/abs/2301.04604)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.04604.md)]
- ChatGPT is not all you need. A State of the Art Review of large   Generative AI models - [[Arxiv](https://arxiv.org/abs/2301.04655)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.04655.md)]
- Pruning Compact ConvNets for Efficient Inference - [[Arxiv](https://arxiv.org/abs/2301.04502)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.04502.md)]
- Vision Transformers Are Good Mask Auto-Labelers - [[Arxiv](https://arxiv.org/abs/2301.03992)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.03992.md)]
- Mastering Diverse Domains through World Models - [[Arxiv](https://arxiv.org/abs/2301.04104)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.04104.md)]
- FrustumFormer: Adaptive Instance-aware Resampling for Multi-view 3D   Detection - [[Arxiv](https://arxiv.org/abs/2301.04467)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.04467.md)]
- Designing BERT for Convolutional Networks: Sparse and Hierarchical   Masked Modeling - [[Arxiv](https://arxiv.org/abs/2301.03580)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.03580.md)]
- Locomotion-Action-Manipulation: Synthesizing Human-Scene Interactions in   Complex 3D Environments - [[Arxiv](https://arxiv.org/abs/2301.02667)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02667.md)]
- STPrivacy: Spatio-Temporal Privacy-Preserving Action Recognition - [[Arxiv](https://arxiv.org/abs/2301.03046)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.03046.md)]
- A Survey on Transformers in Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2301.03044)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.03044.md)]
- MoreauGrad: Sparse and Robust Interpretation of Neural Networks via   Moreau Envelope - [[Arxiv](https://arxiv.org/abs/2302.05294)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2302.05294.md)]
- Learning Support and Trivial Prototypes for Interpretable Image   Classification - [[Arxiv](https://arxiv.org/abs/2301.04011)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.04011.md)]
- InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers - [[Arxiv](https://arxiv.org/abs/2301.02998)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02998.md)]
- 3DAvatarGAN: Bridging Domains for Personalized Editable Avatars - [[Arxiv](https://arxiv.org/abs/2301.02700)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02700.md)]
- TarViS: A Unified Approach for Target-based Video Segmentation - [[Arxiv](https://arxiv.org/abs/2301.02657)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02657.md)]
- End-to-End 3D Dense Captioning with Vote2Cap-DETR - [[Arxiv](https://arxiv.org/abs/2301.02508)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02508.md)]
- You Truly Understand What I Need: Intellectual and Friendly Dialogue   Agents grounding Knowledge and Persona - [[Arxiv](https://arxiv.org/abs/2301.02401)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02401.md)]
- CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior - [[Arxiv](https://arxiv.org/abs/2301.02379)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02379.md)]
- Anchor3DLane: Learning to Regress 3D Anchors for Monocular 3D Lane   Detection - [[Arxiv](https://arxiv.org/abs/2301.02371)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02371.md)]
- Object as Query: Lifting any 2D Object Detector to 3D Detection - [[Arxiv](https://arxiv.org/abs/2301.02364)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02364.md)]
- HierVL: Learning Hierarchical Video-Language Embeddings - [[Arxiv](https://arxiv.org/abs/2301.02311)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02311.md)]
- WIRE: Wavelet Implicit Neural Representations - [[Arxiv](https://arxiv.org/abs/2301.05187)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.05187.md)]
- Filtering, Distillation, and Hard Negatives for Vision-Language   Pre-Training - [[Arxiv](https://arxiv.org/abs/2301.02280)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02280.md)]
- Robust Dynamic Radiance Fields - [[Arxiv](https://arxiv.org/abs/2301.02239)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02239.md)]
- Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers - [[Arxiv](https://arxiv.org/abs/2301.02111)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02111.md)]
- Test of Time: Instilling Video-Language Models with a Sense of Time - [[Arxiv](https://arxiv.org/abs/2301.02074)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02074.md)]
- CAT: LoCalization and IdentificAtion Cascade Detection Transformer for   Open-World Object Detection - [[Arxiv](https://arxiv.org/abs/2301.01970)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01970.md)]
- Learning Trajectory-Word Alignments for Video-Language Tasks - [[Arxiv](https://arxiv.org/abs/2301.01953)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01953.md)]
- SPRING: Situated Conversation Agent Pretrained with Multimodal Questions   from Incremental Layout Graph - [[Arxiv](https://arxiv.org/abs/2301.01949)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01949.md)]
- Event Camera Data Pre-training - [[Arxiv](https://arxiv.org/abs/2301.01928)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01928.md)]
- GIVL: Improving Geographical Inclusivity of Vision-Language Models with   Pre-Training Methods - [[Arxiv](https://arxiv.org/abs/2301.01893)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01893.md)]
- InPars-v2: Large Language Models as Efficient Dataset Generators for   Information Retrieval - [[Arxiv](https://arxiv.org/abs/2301.01820)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01820.md)]
- Unsupervised Manifold Linearizing and Clustering - [[Arxiv](https://arxiv.org/abs/2301.01805)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01805.md)]
- PACO: Parts and Attributes of Common Objects - [[Arxiv](https://arxiv.org/abs/2301.01795)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01795.md)]
- Self-Supervised Video Forensics by Audio-Visual Anomaly Detection - [[Arxiv](https://arxiv.org/abs/2301.01767)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01767.md)]
- Chat2Map: Efficient Scene Mapping from Multi-Ego Conversations - [[Arxiv](https://arxiv.org/abs/2301.02184)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.02184.md)]
- Iterated Decomposition: Improving Science Q&amp;A by Supervising Reasoning   Processes - [[Arxiv](https://arxiv.org/abs/2301.01751)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01751.md)]
- RecRecNet: Rectangling Rectified Wide-Angle Images by Thin-Plate Spline   Model and DoF-based Curriculum Learning - [[Arxiv](https://arxiv.org/abs/2301.01661)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01661.md)]
- Learning Decorrelated Representations Efficiently Using Fast Fourier   Transform - [[Arxiv](https://arxiv.org/abs/2301.01569)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01569.md)]
- Ego-Only: Egocentric Action Detection without Exocentric Transferring - [[Arxiv](https://arxiv.org/abs/2301.01380)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01380.md)]
- TinyMIM: An Empirical Study of Distilling MIM Pre-trained Models - [[Arxiv](https://arxiv.org/abs/2301.01296)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01296.md)]
- Cross Modal Transformer: Towards Fast and Robust 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2301.01283)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01283.md)]
- Rethinking Mobile Block for Efficient Attention-based Models - [[Arxiv](https://arxiv.org/abs/2301.01146)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01146.md)]
- One-Time Universal Hashing Quantum Digital Signatures without Perfect   Keys - [[Arxiv](https://arxiv.org/abs/2301.1132)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.1132.md)]
- Understanding Imbalanced Semantic Segmentation Through Neural Collapse - [[Arxiv](https://arxiv.org/abs/2301.01100)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.01100.md)]
- ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders - [[Arxiv](https://arxiv.org/abs/2301.00808)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00808.md)]
- STEPs: Self-Supervised Key Step Extraction and Localization from   Unlabeled Procedural Videos - [[Arxiv](https://arxiv.org/abs/2301.00794)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00794.md)]
- CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection - [[Arxiv](https://arxiv.org/abs/2301.00785)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00785.md)]
- NaQ: Leveraging Narrations as Queries to Supervise Episodic Memory - [[Arxiv](https://arxiv.org/abs/2301.00746)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00746.md)]
- Efficient On-device Training via Gradient Filtering - [[Arxiv](https://arxiv.org/abs/2301.00330)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2301.00330.md)]
