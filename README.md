# Automated Question Answering with ArXiv Papers

## Latest 25 Papers
- GPT4Motion: Scripting Physical Motions in Text-to-Video Generation via
  Blender-Oriented GPT Planning - [[Arxiv](https://arxiv.org/abs/2311.12631)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.12631.md)]
- NeuroPrompts: An Adaptive Framework to Optimize Prompts for
  Text-to-Image Generation - [[Arxiv](https://arxiv.org/abs/2311.12229)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.12229.md)]
- PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics - [[Arxiv](https://arxiv.org/abs/2311.12198)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.12198.md)]
- Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models - [[Arxiv](https://arxiv.org/abs/2311.12092)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.12092.md)]
- GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark - [[Arxiv](https://arxiv.org/abs/2311.12022)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.12022.md)]
- GPT-4V(ision) for Robotics: Multimodal Task Planning from Human
  Demonstration - [[Arxiv](https://arxiv.org/abs/2311.12015)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.12015.md)]
- System 2 Attention (is something you might need too) - [[Arxiv](https://arxiv.org/abs/2311.11829)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.11829.md)]
- Igniting Language Intelligence: The Hitchhiker's Guide From
  Chain-of-Thought Reasoning to Language Agents - [[Arxiv](https://arxiv.org/abs/2311.11797)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.11797.md)]
- MultiLoRA: Democratizing LoRA for Better Multi-Task Learning - [[Arxiv](https://arxiv.org/abs/2311.11501)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.11501.md)]
- TPTU-v2: Boosting Task Planning and Tool Usage of Large Language
  Model-based Agents in Real-world Systems - [[Arxiv](https://arxiv.org/abs/2311.11315)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.11315.md)]
- LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval
  Score Matching - [[Arxiv](https://arxiv.org/abs/2311.11284)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.11284.md)]
- M$^{2}$UGen: Multi-modal Music Understanding and Generation with the
  Power of Large Language Models - [[Arxiv](https://arxiv.org/abs/2311.11255)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.11255.md)]
- AutoStory: Generating Diverse Storytelling Images with Minimal Human
  Effort - [[Arxiv](https://arxiv.org/abs/2311.11243)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.11243.md)]
- Adapters: A Unified Library for Parameter-Efficient and Modular Transfer
  Learning - [[Arxiv](https://arxiv.org/abs/2311.11077)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.11077.md)]
- Orca 2: Teaching Small Language Models How to Reason - [[Arxiv](https://arxiv.org/abs/2311.11045)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.11045.md)]
- MagicDance: Realistic Human Dance Video Generation with Motions &amp; Facial
  Expressions Transfer - [[Arxiv](https://arxiv.org/abs/2311.12052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.12052.md)]
- Make Pixels Dance: High-Dynamic Video Generation - [[Arxiv](https://arxiv.org/abs/2311.10982)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10982.md)]
- Emu Video: Factorizing Text-to-Video Generation by Explicit Image
  Conditioning - [[Arxiv](https://arxiv.org/abs/2311.10709)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10709.md)]
- SelfEval: Leveraging the discriminative nature of generative models for
  evaluation - [[Arxiv](https://arxiv.org/abs/2311.10708)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10708.md)]
- Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2 - [[Arxiv](https://arxiv.org/abs/2311.10702)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10702.md)]
- Distilling and Retrieving Generalizable Knowledge for Robot Manipulation
  via Language Corrections - [[Arxiv](https://arxiv.org/abs/2311.10678)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10678.md)]
- Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as
  an Alternative to Attention Layers in Transformers - [[Arxiv](https://arxiv.org/abs/2311.10642)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10642.md)]
- Testing Language Model Agents Safely in the Wild - [[Arxiv](https://arxiv.org/abs/2311.10538)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10538.md)]
- Text-to-Sticker: Style Tailoring Latent Diffusion Models for Human
  Expression - [[Arxiv](https://arxiv.org/abs/2311.10794)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10794.md)]
- The Chosen One: Consistent Characters in Text-to-Image Diffusion Models - [[Arxiv](https://arxiv.org/abs/2311.10093)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10093.md)]

## List of Papers by Year
- [Papers for 2023](https://github.com/taesiri/ArXivQA/blob/main/Papers-2023.md)
- [Papers for 2022](https://github.com/taesiri/ArXivQA/blob/main/Papers-2022.md)
- [Papers for 2021](https://github.com/taesiri/ArXivQA/blob/main/Papers-2021.md)
- [Papers for 2020](https://github.com/taesiri/ArXivQA/blob/main/Papers-2020.md)
- [Papers for 2019](https://github.com/taesiri/ArXivQA/blob/main/Papers-2019.md)
- [Papers for 2018](https://github.com/taesiri/ArXivQA/blob/main/Papers-2018.md)
- [Papers for 2017](https://github.com/taesiri/ArXivQA/blob/main/Papers-2017.md)
- [Papers for 2016](https://github.com/taesiri/ArXivQA/blob/main/Papers-2016.md)
- [Papers for 2015](https://github.com/taesiri/ArXivQA/blob/main/Papers-2015.md)
- [Papers for 2014](https://github.com/taesiri/ArXivQA/blob/main/Papers-2014.md)
- [Papers for 2013](https://github.com/taesiri/ArXivQA/blob/main/Papers-2013.md)
- [Papers for 2012](https://github.com/taesiri/ArXivQA/blob/main/Papers-2012.md)
- [Papers for 2010](https://github.com/taesiri/ArXivQA/blob/main/Papers-2010.md)
- [Papers for 2009](https://github.com/taesiri/ArXivQA/blob/main/Papers-2009.md)

## Acknowledgements
This project is made possible through the generous support of [Anthropic](https://www.anthropic.com/), who provided free access to the `Claude-2.0` API.
