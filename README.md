# Automated Question Answering with ArXiv Papers

## Latest 25 Papers
- Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating
  Video-based Large Language Models - [[Arxiv](https://arxiv.org/abs/2311.16103)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16103.md)]
- Test-time Adaptation of Discriminative Models via Diffusion Generative
  Feedback - [[Arxiv](https://arxiv.org/abs/2311.16102)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16102.md)]
- How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for
  Vision LLMs - [[Arxiv](https://arxiv.org/abs/2311.16101)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16101.md)]
- GART: Gaussian Articulated Template Models - [[Arxiv](https://arxiv.org/abs/2311.16099)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16099.md)]
- On Bringing Robots Home - [[Arxiv](https://arxiv.org/abs/2311.16098)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16098.md)]
- CG-HOI: Contact-Guided 3D Human-Object Interaction Generation - [[Arxiv](https://arxiv.org/abs/2311.16097)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16097.md)]
- Animatable Gaussians: Learning Pose-dependent Gaussian Maps for
  High-fidelity Human Avatar Modeling - [[Arxiv](https://arxiv.org/abs/2311.16096)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16096.md)]
- Street TryOn: Learning In-the-Wild Virtual Try-On from Unpaired Person
  Images - [[Arxiv](https://arxiv.org/abs/2311.16094)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16094.md)]
- Have we built machines that think like people? - [[Arxiv](https://arxiv.org/abs/2311.16093)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16093.md)]
- Interactive Autonomous Navigation with Internal State Inference and
  Interactivity Estimation - [[Arxiv](https://arxiv.org/abs/2311.16091)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16091.md)]
- Self-correcting LLM-controlled Diffusion Models - [[Arxiv](https://arxiv.org/abs/2311.16090)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16090.md)]
- DUnE: Dataset for Unified Editing - [[Arxiv](https://arxiv.org/abs/2311.16087)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16087.md)]
- MAST: Model-Agnostic Sparsified Training - [[Arxiv](https://arxiv.org/abs/2311.16086)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16086.md)]
- BERT Goes Off-Topic: Investigating the Domain Transfer Challenge using
  Genre Classification - [[Arxiv](https://arxiv.org/abs/2311.16083)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16083.md)]
- Transformer-QEC: Quantum Error Correction Code Decoding with
  Transferable Transformers - [[Arxiv](https://arxiv.org/abs/2311.16082)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16082.md)]
- ViT-Lens-2: Gateway to Omni-modal Intelligence - [[Arxiv](https://arxiv.org/abs/2311.16081)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16081.md)]
- XLB: Distributed Multi-GPU Lattice Boltzmann Simulation Framework for
  Differentiable Scientific Machine Learning - [[Arxiv](https://arxiv.org/abs/2311.16080)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16080.md)]
- MEDITRON-70B: Scaling Medical Pretraining for Large Language Models - [[Arxiv](https://arxiv.org/abs/2311.16079)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16079.md)]
- A Survey on Vulnerability of Federated Learning: A Learning Algorithm
  Perspective - [[Arxiv](https://arxiv.org/abs/2311.16065)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16065.md)]
- DiffSLVA: Harnessing Diffusion Models for Sign Language Video
  Anonymization - [[Arxiv](https://arxiv.org/abs/2311.16060)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16060.md)]
- Metric Space Magnitude for Evaluating Unsupervised Representation
  Learning - [[Arxiv](https://arxiv.org/abs/2311.16054)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16054.md)]
- Evaluating the Impact of Personalized Value Alignment in Human-Robot
  Interaction: Insights into Trust and Team Performance Outcomes - [[Arxiv](https://arxiv.org/abs/2311.16051)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16051.md)]
- Exploring Attribute Variations in Style-based GANs using Diffusion
  Models - [[Arxiv](https://arxiv.org/abs/2311.16052)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16052.md)]
- Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF
  Decomposition and Ray Tracing - [[Arxiv](https://arxiv.org/abs/2311.16043)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16043.md)]
- Weakly-Supervised 3D Reconstruction of Clothed Humans via Normal Maps - [[Arxiv](https://arxiv.org/abs/2311.16042)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.16042.md)]

## List of Papers by Year
- [Papers for 2023](https://github.com/taesiri/ArXivQA/blob/main/Papers-2023.md)
- [Papers for 2022](https://github.com/taesiri/ArXivQA/blob/main/Papers-2022.md)
- [Papers for 2021](https://github.com/taesiri/ArXivQA/blob/main/Papers-2021.md)
- [Papers for 2020](https://github.com/taesiri/ArXivQA/blob/main/Papers-2020.md)
- [Papers for 2019](https://github.com/taesiri/ArXivQA/blob/main/Papers-2019.md)
- [Papers for 2018](https://github.com/taesiri/ArXivQA/blob/main/Papers-2018.md)
- [Papers for 2017](https://github.com/taesiri/ArXivQA/blob/main/Papers-2017.md)
- [Papers for 2016](https://github.com/taesiri/ArXivQA/blob/main/Papers-2016.md)
- [Papers for 2015](https://github.com/taesiri/ArXivQA/blob/main/Papers-2015.md)
- [Papers for 2014](https://github.com/taesiri/ArXivQA/blob/main/Papers-2014.md)
- [Papers for 2013](https://github.com/taesiri/ArXivQA/blob/main/Papers-2013.md)
- [Papers for 2012](https://github.com/taesiri/ArXivQA/blob/main/Papers-2012.md)
- [Papers for 2010](https://github.com/taesiri/ArXivQA/blob/main/Papers-2010.md)
- [Papers for 2009](https://github.com/taesiri/ArXivQA/blob/main/Papers-2009.md)

## Acknowledgements
This project is made possible through the generous support of [Anthropic](https://www.anthropic.com/), who provided free access to the `Claude-2.1` API.
