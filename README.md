# Automated Question Answering with ArXiv Papers

## Latest 25 Papers
- Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization - [[Arxiv](https://arxiv.org/abs/2311.06243)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.06243.md)]
- Florence-2: Advancing a Unified Representation for a Variety of Vision
  Tasks - [[Arxiv](https://arxiv.org/abs/2311.06242)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.06242.md)]
- Instant3D: Fast Text-to-3D with Sparse-View Generation and Large
  Reconstruction Model - [[Arxiv](https://arxiv.org/abs/2311.06214)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.06214.md)]
- Language Models can be Logical Solvers - [[Arxiv](https://arxiv.org/abs/2311.06158)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.06158.md)]
- JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal
  Language Models - [[Arxiv](https://arxiv.org/abs/2311.05997)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05997.md)]
- FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor
  Cores - [[Arxiv](https://arxiv.org/abs/2311.05908)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05908.md)]
- Hiformer: Heterogeneous Feature Interactions Learning with Transformers
  for Recommender Systems - [[Arxiv](https://arxiv.org/abs/2311.05884)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05884.md)]
- PolyMaX: General Dense Prediction with Mask Transformer - [[Arxiv](https://arxiv.org/abs/2311.05770)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05770.md)]
- FMViT: A multiple-frequency mixing Vision Transformer - [[Arxiv](https://arxiv.org/abs/2311.05707)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05707.md)]
- Mirasol3B: A Multimodal Autoregressive model for time-aligned and
  contextual modalities - [[Arxiv](https://arxiv.org/abs/2311.05698)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05698.md)]
- LCM-LoRA: A Universal Stable-Diffusion Acceleration Module - [[Arxiv](https://arxiv.org/abs/2311.05556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05556.md)]
- LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents - [[Arxiv](https://arxiv.org/abs/2311.05437)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05437.md)]
- u-LLaVA: Unifying Multi-Modal Tasks via Large Language Model - [[Arxiv](https://arxiv.org/abs/2311.05348)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05348.md)]
- On the Road with GPT-4V(ision): Early Explorations of Visual-Language
  Model on Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2311.05332)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05332.md)]
- Prompt Engineering a Prompt Engineer - [[Arxiv](https://arxiv.org/abs/2311.05661)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05661.md)]
- Lumos: Learning Agents with Unified Data, Modular Design, and
  Open-Source LLMs - [[Arxiv](https://arxiv.org/abs/2311.05657)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05657.md)]
- GENOME: GenerativE Neuro-symbOlic visual reasoning by growing and
  reusing ModulEs - [[Arxiv](https://arxiv.org/abs/2311.04901)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04901.md)]
- ADaPT: As-Needed Decomposition and Planning with Language Models - [[Arxiv](https://arxiv.org/abs/2311.05772)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.05772.md)]
- TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models - [[Arxiv](https://arxiv.org/abs/2311.04589)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04589.md)]
- NExT-Chat: An LMM for Chat, Detection and Segmentation - [[Arxiv](https://arxiv.org/abs/2311.04498)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04498.md)]
- LRM: Large Reconstruction Model for Single Image to 3D - [[Arxiv](https://arxiv.org/abs/2311.04400)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04400.md)]
- 3DiffTection: 3D Object Detection with Geometry-Aware Diffusion Features - [[Arxiv](https://arxiv.org/abs/2311.04391)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04391.md)]
- Holistic Evaluation of Text-To-Image Models - [[Arxiv](https://arxiv.org/abs/2311.04287)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04287.md)]
- OtterHD: A High-Resolution Multi-modality Model - [[Arxiv](https://arxiv.org/abs/2311.04219)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04219.md)]
- Video Instance Matting - [[Arxiv](https://arxiv.org/abs/2311.04212)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.04212.md)]

## List of Papers by Year
- [Papers for 2023](https://github.com/taesiri/ArXivQA/blob/main/Papers-2023.md)
- [Papers for 2022](https://github.com/taesiri/ArXivQA/blob/main/Papers-2022.md)
- [Papers for 2021](https://github.com/taesiri/ArXivQA/blob/main/Papers-2021.md)
- [Papers for 2020](https://github.com/taesiri/ArXivQA/blob/main/Papers-2020.md)
- [Papers for 2019](https://github.com/taesiri/ArXivQA/blob/main/Papers-2019.md)
- [Papers for 2018](https://github.com/taesiri/ArXivQA/blob/main/Papers-2018.md)
- [Papers for 2017](https://github.com/taesiri/ArXivQA/blob/main/Papers-2017.md)
- [Papers for 2016](https://github.com/taesiri/ArXivQA/blob/main/Papers-2016.md)
- [Papers for 2015](https://github.com/taesiri/ArXivQA/blob/main/Papers-2015.md)
- [Papers for 2014](https://github.com/taesiri/ArXivQA/blob/main/Papers-2014.md)
- [Papers for 2013](https://github.com/taesiri/ArXivQA/blob/main/Papers-2013.md)
- [Papers for 2012](https://github.com/taesiri/ArXivQA/blob/main/Papers-2012.md)
- [Papers for 2010](https://github.com/taesiri/ArXivQA/blob/main/Papers-2010.md)
- [Papers for 2009](https://github.com/taesiri/ArXivQA/blob/main/Papers-2009.md)

## Acknowledgements
This project is made possible through the generous support of [Anthropic](https://www.anthropic.com/), who provided free access to the `Claude-2.0` API.
