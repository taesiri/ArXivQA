# Automated Question Answering with ArXiv Papers

## Latest 25 Papers
- Emu Video: Factorizing Text-to-Video Generation by Explicit Image
  Conditioning - [[Arxiv](https://arxiv.org/abs/2311.10709)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10709.md)]
- SelfEval: Leveraging the discriminative nature of generative models for
  evaluation - [[Arxiv](https://arxiv.org/abs/2311.10708)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10708.md)]
- Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2 - [[Arxiv](https://arxiv.org/abs/2311.10702)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10702.md)]
- Distilling and Retrieving Generalizable Knowledge for Robot Manipulation
  via Language Corrections - [[Arxiv](https://arxiv.org/abs/2311.10678)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10678.md)]
- Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as
  an Alternative to Attention Layers in Transformers - [[Arxiv](https://arxiv.org/abs/2311.10642)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10642.md)]
- Testing Language Model Agents Safely in the Wild - [[Arxiv](https://arxiv.org/abs/2311.10538)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10538.md)]
- The Chosen One: Consistent Characters in Text-to-Image Diffusion Models - [[Arxiv](https://arxiv.org/abs/2311.10093)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10093.md)]
- Adaptive Shells for Efficient Neural Radiance Field Rendering - [[Arxiv](https://arxiv.org/abs/2311.10091)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10091.md)]
- JaxMARL: Multi-Agent RL Environments in JAX - [[Arxiv](https://arxiv.org/abs/2311.10090)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10090.md)]
- I&amp;S-ViT: An Inclusive &amp; Stable Method for Pushing the Limit of
  Post-Training ViTs Quantization - [[Arxiv](https://arxiv.org/abs/2311.10126)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10126.md)]
- UnifiedVisionGPT: Streamlining Vision-Oriented AI through Generalized
  Multimodal Framework - [[Arxiv](https://arxiv.org/abs/2311.10125)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10125.md)]
- ML-Bench: Large Language Models Leverage Open-source Libraries for
  Machine Learning Tasks - [[Arxiv](https://arxiv.org/abs/2311.09835)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.09835.md)]
- MetaDreamer: Efficient Text-to-3D Creation With Disentangling Geometry
  and Texture - [[Arxiv](https://arxiv.org/abs/2311.10123)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10123.md)]
- Video-LLaVA: Learning United Visual Representation by Alignment Before
  Projection - [[Arxiv](https://arxiv.org/abs/2311.10122)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10122.md)]
- Tied-Lora: Enhacing parameter efficiency of LoRA with weight tying - [[Arxiv](https://arxiv.org/abs/2311.09578)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.09578.md)]
- VideoCon: Robust Video-Language Alignment via Contrast Captions - [[Arxiv](https://arxiv.org/abs/2311.10111)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.10111.md)]
- Single-Image 3D Human Digitization with Shape-Guided Diffusion - [[Arxiv](https://arxiv.org/abs/2311.09221)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.09221.md)]
- DMV3D: Denoising Multi-View Diffusion using 3D Large Reconstruction
  Model - [[Arxiv](https://arxiv.org/abs/2311.09217)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.09217.md)]
- ConvNet vs Transformer, Supervised vs CLIP: Beyond ImageNet Accuracy - [[Arxiv](https://arxiv.org/abs/2311.09215)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.09215.md)]
- GRIM: GRaph-based Interactive narrative visualization for gaMes - [[Arxiv](https://arxiv.org/abs/2311.09213)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.09213.md)]
- Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language
  Models - [[Arxiv](https://arxiv.org/abs/2311.09210)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.09210.md)]
- Contrastive Chain-of-Thought Prompting - [[Arxiv](https://arxiv.org/abs/2311.09277)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.09277.md)]
- Fusion-Eval: Integrating Evaluators with LLMs - [[Arxiv](https://arxiv.org/abs/2311.09204)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.09204.md)]
- PEARL: Personalizing Large Language Model Writing Assistants with
  Generation-Calibrated Retrievers - [[Arxiv](https://arxiv.org/abs/2311.09180)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.09180.md)]
- SiRA: Sparse Mixture of Low Rank Adaptation - [[Arxiv](https://arxiv.org/abs/2311.09179)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.09179.md)]

## List of Papers by Year
- [Papers for 2023](https://github.com/taesiri/ArXivQA/blob/main/Papers-2023.md)
- [Papers for 2022](https://github.com/taesiri/ArXivQA/blob/main/Papers-2022.md)
- [Papers for 2021](https://github.com/taesiri/ArXivQA/blob/main/Papers-2021.md)
- [Papers for 2020](https://github.com/taesiri/ArXivQA/blob/main/Papers-2020.md)
- [Papers for 2019](https://github.com/taesiri/ArXivQA/blob/main/Papers-2019.md)
- [Papers for 2018](https://github.com/taesiri/ArXivQA/blob/main/Papers-2018.md)
- [Papers for 2017](https://github.com/taesiri/ArXivQA/blob/main/Papers-2017.md)
- [Papers for 2016](https://github.com/taesiri/ArXivQA/blob/main/Papers-2016.md)
- [Papers for 2015](https://github.com/taesiri/ArXivQA/blob/main/Papers-2015.md)
- [Papers for 2014](https://github.com/taesiri/ArXivQA/blob/main/Papers-2014.md)
- [Papers for 2013](https://github.com/taesiri/ArXivQA/blob/main/Papers-2013.md)
- [Papers for 2012](https://github.com/taesiri/ArXivQA/blob/main/Papers-2012.md)
- [Papers for 2010](https://github.com/taesiri/ArXivQA/blob/main/Papers-2010.md)
- [Papers for 2009](https://github.com/taesiri/ArXivQA/blob/main/Papers-2009.md)

## Acknowledgements
This project is made possible through the generous support of [Anthropic](https://www.anthropic.com/), who provided free access to the `Claude-2.0` API.
