# Automated Question Answering with ArXiv Papers

## Latest 25 Papers
- Beyond ChatBots: ExploreLLM for Structured Thoughts and Personalized
  Model Responses - [[Arxiv](https://arxiv.org/abs/2312.00763)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.00763.md)]
- SeaLLMs -- Large Language Models for Southeast Asia - [[Arxiv](https://arxiv.org/abs/2312.00738)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.00738.md)]
- Instruction-tuning Aligns LLMs to the Human Brain - [[Arxiv](https://arxiv.org/abs/2312.00575)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.00575.md)]
- Dolphins: Multimodal Language Model for Driving - [[Arxiv](https://arxiv.org/abs/2312.00438)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.00438.md)]
- StyleCrafter: Enhancing Stylized Text-to-Video Generation with Style
  Adapter - [[Arxiv](https://arxiv.org/abs/2312.00330)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.00330.md)]
- Towards Accurate Differential Diagnosis with Large Language Models - [[Arxiv](https://arxiv.org/abs/2312.00164)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.00164.md)]
- GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs - [[Arxiv](https://arxiv.org/abs/2312.00093)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.00093.md)]
- Dataset Distillation in Large Data Era - [[Arxiv](https://arxiv.org/abs/2311.18838)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18838.md)]
- TrafficMOT: A Challenging Dataset for Multi-Object Tracking in Complex
  Traffic Scenarios - [[Arxiv](https://arxiv.org/abs/2311.18839)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18839.md)]
- Just Add $Ï€$! Pose Induced Video Transformers for Understanding
  Activities of Daily Living - [[Arxiv](https://arxiv.org/abs/2311.18840)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18840.md)]
- PoseGPT: Chatting about 3D Human Pose - [[Arxiv](https://arxiv.org/abs/2311.18836)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18836.md)]
- VIDiff: Translating Videos via Multi-Modal Instructions with Diffusion
  Models - [[Arxiv](https://arxiv.org/abs/2311.18837)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18837.md)]
- InstructSeq: Unifying Vision Tasks with Instruction-conditioned
  Multi-modal Sequence Generation - [[Arxiv](https://arxiv.org/abs/2311.18835)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18835.md)]
- ART$\boldsymbol{\cdot}$V: Auto-Regressive Text-to-Video Generation with
  Diffusion Models - [[Arxiv](https://arxiv.org/abs/2311.18834)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18834.md)]
- Exploiting Diffusion Prior for Generalizable Pixel-Level Semantic
  Prediction - [[Arxiv](https://arxiv.org/abs/2311.18832)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18832.md)]
- MotionEditor: Editing Video Motion via Content-Aware Diffusion - [[Arxiv](https://arxiv.org/abs/2311.18830)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18830.md)]
- MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation - [[Arxiv](https://arxiv.org/abs/2311.18829)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18829.md)]
- One-step Diffusion with Distribution Matching Distillation - [[Arxiv](https://arxiv.org/abs/2311.18828)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18828.md)]
- Motion-Conditioned Image Animation for Video Editing - [[Arxiv](https://arxiv.org/abs/2311.18827)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18827.md)]
- Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal
  Inference - [[Arxiv](https://arxiv.org/abs/2311.18826)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18826.md)]
- CAST: Cross-Attention in Space and Time for Video Action Recognition - [[Arxiv](https://arxiv.org/abs/2311.18825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18825.md)]
- An Adaptive Framework for Generalizing Network Traffic Prediction
  towards Uncertain Environments - [[Arxiv](https://arxiv.org/abs/2311.18824)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18824.md)]
- Initializing Models with Larger Ones - [[Arxiv](https://arxiv.org/abs/2311.18823)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18823.md)]
- ElasticDiffusion: Training-free Arbitrary Size Image Generation - [[Arxiv](https://arxiv.org/abs/2311.18822)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18822.md)]
- Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce
  Grokking - [[Arxiv](https://arxiv.org/abs/2311.18817)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.18817.md)]

## List of Papers by Year
- [Papers for 2023](https://github.com/taesiri/ArXivQA/blob/main/Papers-2023.md)
- [Papers for 2022](https://github.com/taesiri/ArXivQA/blob/main/Papers-2022.md)
- [Papers for 2021](https://github.com/taesiri/ArXivQA/blob/main/Papers-2021.md)
- [Papers for 2020](https://github.com/taesiri/ArXivQA/blob/main/Papers-2020.md)
- [Papers for 2019](https://github.com/taesiri/ArXivQA/blob/main/Papers-2019.md)
- [Papers for 2018](https://github.com/taesiri/ArXivQA/blob/main/Papers-2018.md)
- [Papers for 2017](https://github.com/taesiri/ArXivQA/blob/main/Papers-2017.md)
- [Papers for 2016](https://github.com/taesiri/ArXivQA/blob/main/Papers-2016.md)
- [Papers for 2015](https://github.com/taesiri/ArXivQA/blob/main/Papers-2015.md)
- [Papers for 2014](https://github.com/taesiri/ArXivQA/blob/main/Papers-2014.md)
- [Papers for 2013](https://github.com/taesiri/ArXivQA/blob/main/Papers-2013.md)
- [Papers for 2012](https://github.com/taesiri/ArXivQA/blob/main/Papers-2012.md)
- [Papers for 2010](https://github.com/taesiri/ArXivQA/blob/main/Papers-2010.md)
- [Papers for 2009](https://github.com/taesiri/ArXivQA/blob/main/Papers-2009.md)

## Acknowledgements
This project is made possible through the generous support of [Anthropic](https://www.anthropic.com/), who provided free access to the `Claude-2.1` API.
