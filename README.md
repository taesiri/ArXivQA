# Automated Question Answering with ArXiv Papers

## Latest 25 Papers
- MM-VID: Advancing Video Understanding with GPT-4V(ision) - [[Arxiv](https://arxiv.org/abs/2310.19773)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19773.md)]
- TeacherLM: Teaching to Fish Rather Than Giving the Fish, Language
  Modeling Likewise - [[Arxiv](https://arxiv.org/abs/2310.19019)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.19019.md)]
- Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive
  Learning for Code Generation - [[Arxiv](https://arxiv.org/abs/2310.18628)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.18628.md)]
- FP8-LM: Training FP8 Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.18313)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.18313.md)]
- Personas as a Way to Model Truthfulness in Language Models - [[Arxiv](https://arxiv.org/abs/2310.18168)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.18168.md)]
- ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Real Image - [[Arxiv](https://arxiv.org/abs/2310.17994)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17994.md)]
- Reconstructive Latent-Space Neural Radiance Fields for Efficient 3D
  Scene Representations - [[Arxiv](https://arxiv.org/abs/2310.17880)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17880.md)]
- ControlLLM: Augment Language Models with Tools by Searching on Graphs - [[Arxiv](https://arxiv.org/abs/2310.17796)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17796.md)]
- PockEngine: Sparse and Efficient Fine-tuning in a Pocket - [[Arxiv](https://arxiv.org/abs/2310.17752)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17752.md)]
- A Framework for Automated Measurement of Responsible AI Harms in
  Generative AI Applications - [[Arxiv](https://arxiv.org/abs/2310.17750)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17750.md)]
- Large Language Models as Generalizable Policies for Embodied Tasks - [[Arxiv](https://arxiv.org/abs/2310.17722)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17722.md)]
- JudgeLM: Fine-tuned Large Language Models are Scalable Judges - [[Arxiv](https://arxiv.org/abs/2310.17631)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17631.md)]
- CodeFusion: A Pre-trained Diffusion Model for Code Generation - [[Arxiv](https://arxiv.org/abs/2310.17680)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17680.md)]
- Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time - [[Arxiv](https://arxiv.org/abs/2310.17157)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17157.md)]
- HyperFields: Towards Zero-Shot Generation of NeRFs from Text - [[Arxiv](https://arxiv.org/abs/2310.17075)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17075.md)]
- Controlled Decoding from Language Models - [[Arxiv](https://arxiv.org/abs/2310.17022)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.17022.md)]
- Zephyr: Direct Distillation of LM Alignment - [[Arxiv](https://arxiv.org/abs/2310.16944)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16944.md)]
- LLM-FP4: 4-Bit Floating-Point Quantized Transformers - [[Arxiv](https://arxiv.org/abs/2310.16836)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16836.md)]
- LightSpeed: Light and Fast Neural Light Fields on Mobile Devices - [[Arxiv](https://arxiv.org/abs/2310.16832)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16832.md)]
- TD-MPC2: Scalable, Robust World Models for Continuous Control - [[Arxiv](https://arxiv.org/abs/2310.16828)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16828.md)]
- CommonCanvas: An Open Diffusion Model Trained with Creative-Commons
  Images - [[Arxiv](https://arxiv.org/abs/2310.16825)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16825.md)]
- DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion
  Prior - [[Arxiv](https://arxiv.org/abs/2310.16818)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16818.md)]
- QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models - [[Arxiv](https://arxiv.org/abs/2310.16795)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16795.md)]
- Detecting Pretraining Data from Large Language Models - [[Arxiv](https://arxiv.org/abs/2310.16789)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16789.md)]
- ConvNets Match Vision Transformers at Scale - [[Arxiv](https://arxiv.org/abs/2310.16764)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2310.16764.md)]

## List of Papers by Year
- [Papers for 2023](https://github.com/taesiri/ArXivQA/blob/main/Papers-2023.md)
- [Papers for 2022](https://github.com/taesiri/ArXivQA/blob/main/Papers-2022.md)
- [Papers for 2021](https://github.com/taesiri/ArXivQA/blob/main/Papers-2021.md)
- [Papers for 2020](https://github.com/taesiri/ArXivQA/blob/main/Papers-2020.md)
- [Papers for 2019](https://github.com/taesiri/ArXivQA/blob/main/Papers-2019.md)
- [Papers for 2018](https://github.com/taesiri/ArXivQA/blob/main/Papers-2018.md)
- [Papers for 2017](https://github.com/taesiri/ArXivQA/blob/main/Papers-2017.md)
- [Papers for 2016](https://github.com/taesiri/ArXivQA/blob/main/Papers-2016.md)
- [Papers for 2015](https://github.com/taesiri/ArXivQA/blob/main/Papers-2015.md)
- [Papers for 2014](https://github.com/taesiri/ArXivQA/blob/main/Papers-2014.md)
- [Papers for 2013](https://github.com/taesiri/ArXivQA/blob/main/Papers-2013.md)
- [Papers for 2012](https://github.com/taesiri/ArXivQA/blob/main/Papers-2012.md)
- [Papers for 2010](https://github.com/taesiri/ArXivQA/blob/main/Papers-2010.md)
- [Papers for 2009](https://github.com/taesiri/ArXivQA/blob/main/Papers-2009.md)

## Acknowledgements
This project is made possible through the generous support of [Anthropic](https://www.anthropic.com/), who provided free access to the `Claude-2.0` API.
