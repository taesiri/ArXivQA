# Automated Question Answering with ArXiv Papers

## Latest 25 Papers
- ReconFusion: 3D Reconstruction with Diffusion Priors - [[Arxiv](https://arxiv.org/abs/2312.02981)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02981.md)]
- GPT4Point: A Unified Framework for Point-Language Understanding and
  Generation - [[Arxiv](https://arxiv.org/abs/2312.02980)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02980.md)]
- Imitating Shortest Paths in Simulation Enables Effective Navigation and
  Manipulation in the Real World - [[Arxiv](https://arxiv.org/abs/2312.02976)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02976.md)]
- Dexterous Functional Grasping - [[Arxiv](https://arxiv.org/abs/2312.02975)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02975.md)]
- Describing Differences in Image Sets with Natural Language - [[Arxiv](https://arxiv.org/abs/2312.02974)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02974.md)]
- GauHuman: Articulated Gaussian Splatting from Monocular Human Videos - [[Arxiv](https://arxiv.org/abs/2312.02973)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02973.md)]
- Alchemist: Parametric Control of Material Properties with Diffusion
  Models - [[Arxiv](https://arxiv.org/abs/2312.02970)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02970.md)]
- Rank-without-GPT: Building GPT-Independent Listwise Rerankers on
  Open-Source Large Language Models - [[Arxiv](https://arxiv.org/abs/2312.02969)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02969.md)]
- AmbiGen: Generating Ambigrams from Pre-trained Diffusion Model - [[Arxiv](https://arxiv.org/abs/2312.02967)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02967.md)]
- Diffusion-SS3D: Diffusion Model for Semi-supervised 3D Object Detection - [[Arxiv](https://arxiv.org/abs/2312.02966)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02966.md)]
- MVHumanNet: A Large-scale Dataset of Multi-view Daily Dressing Human
  Captures - [[Arxiv](https://arxiv.org/abs/2312.02963)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02963.md)]
- Detecting algorithmic bias in medical AI-models - [[Arxiv](https://arxiv.org/abs/2312.02959)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02959.md)]
- Classification for everyone : Building geography agnostic models for
  fairer recognition - [[Arxiv](https://arxiv.org/abs/2312.02957)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02957.md)]
- Choroidalyzer: An open-source, end-to-end pipeline for choroidal
  analysis in optical coherence tomography - [[Arxiv](https://arxiv.org/abs/2312.02956)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02956.md)]
- LLaVA-Grounding: Grounded Visual Chat with Large Multimodal Models - [[Arxiv](https://arxiv.org/abs/2312.02949)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02949.md)]
- An alternating peak-optimization method for optimal trajectory
  generation of quadrotor drones - [[Arxiv](https://arxiv.org/abs/2312.02944)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02944.md)]
- Fast CT anatomic localization algorithm - [[Arxiv](https://arxiv.org/abs/2312.02941)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02941.md)]
- Synergistic Perception and Control Simplex for Verifiable Safe Vertical
  Landing - [[Arxiv](https://arxiv.org/abs/2312.02937)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02937.md)]
- Drag-A-Video: Non-rigid Video Editing with Point-based Interaction - [[Arxiv](https://arxiv.org/abs/2312.02936)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02936.md)]
- WoVoGen: World Volume-aware Diffusion for Controllable Multi-camera
  Driving Scene Generation - [[Arxiv](https://arxiv.org/abs/2312.02934)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02934.md)]
- WhisBERT: Multimodal Text-Audio Language Modeling on 100M Words - [[Arxiv](https://arxiv.org/abs/2312.02931)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02931.md)]
- LivePhoto: Real Image Animation with Text-guided Motion Control - [[Arxiv](https://arxiv.org/abs/2312.02928)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02928.md)]
- Split &amp; Merge: Unlocking the Potential of Visual Adapters via Sparse
  Training - [[Arxiv](https://arxiv.org/abs/2312.02923)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02923.md)]
- Fine-grained Controllable Video Generation via Object Appearance and
  Context - [[Arxiv](https://arxiv.org/abs/2312.02919)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02919.md)]
- Multimodal Prompt Perceiver: Empower Adaptiveness, Generalizability and
  Fidelity for All-in-One Image Restoration - [[Arxiv](https://arxiv.org/abs/2312.02918)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.02918.md)]

## List of Papers by Year
- [Papers for 2023](https://github.com/taesiri/ArXivQA/blob/main/Papers-2023.md)
- [Papers for 2022](https://github.com/taesiri/ArXivQA/blob/main/Papers-2022.md)
- [Papers for 2021](https://github.com/taesiri/ArXivQA/blob/main/Papers-2021.md)
- [Papers for 2020](https://github.com/taesiri/ArXivQA/blob/main/Papers-2020.md)
- [Papers for 2019](https://github.com/taesiri/ArXivQA/blob/main/Papers-2019.md)
- [Papers for 2018](https://github.com/taesiri/ArXivQA/blob/main/Papers-2018.md)
- [Papers for 2017](https://github.com/taesiri/ArXivQA/blob/main/Papers-2017.md)
- [Papers for 2016](https://github.com/taesiri/ArXivQA/blob/main/Papers-2016.md)
- [Papers for 2015](https://github.com/taesiri/ArXivQA/blob/main/Papers-2015.md)
- [Papers for 2014](https://github.com/taesiri/ArXivQA/blob/main/Papers-2014.md)
- [Papers for 2013](https://github.com/taesiri/ArXivQA/blob/main/Papers-2013.md)
- [Papers for 2012](https://github.com/taesiri/ArXivQA/blob/main/Papers-2012.md)
- [Papers for 2010](https://github.com/taesiri/ArXivQA/blob/main/Papers-2010.md)
- [Papers for 2009](https://github.com/taesiri/ArXivQA/blob/main/Papers-2009.md)

## Acknowledgements
This project is made possible through the generous support of [Anthropic](https://www.anthropic.com/), who provided free access to the `Claude-2.1` API.
