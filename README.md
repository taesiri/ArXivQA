# Automated Question Answering with ArXiv Papers

## Latest 25 Papers
- Do text-free diffusion models learn discriminative visual
  representations? - [[Arxiv](https://arxiv.org/abs/2311.17921)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17921.md)]
- Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion
  Models - [[Arxiv](https://arxiv.org/abs/2311.17919)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17919.md)]
- A Simple Recipe for Language-guided Domain Generalized Segmentation - [[Arxiv](https://arxiv.org/abs/2311.17922)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17922.md)]
- Driving into the Future: Multiview Visual Forecasting and Planning with
  World Model for Autonomous Driving - [[Arxiv](https://arxiv.org/abs/2311.17918)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17918.md)]
- AvatarStudio: High-fidelity and Animatable 3D Avatar Creation from Text - [[Arxiv](https://arxiv.org/abs/2311.17917)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17917.md)]
- OPERA: Alleviating Hallucination in Multi-Modal Large Language Models
  via Over-Trust Penalty and Retrospection-Allocation - [[Arxiv](https://arxiv.org/abs/2311.17911)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17911.md)]
- HUGS: Human Gaussian Splats - [[Arxiv](https://arxiv.org/abs/2311.17910)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17910.md)]
- CG3D: Compositional Generation for Text-to-3D via Gaussian Splatting - [[Arxiv](https://arxiv.org/abs/2311.17907)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17907.md)]
- Language-conditioned Detection Transformer - [[Arxiv](https://arxiv.org/abs/2311.17902)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17902.md)]
- SODA: Bottleneck Diffusion Models for Representation Learning - [[Arxiv](https://arxiv.org/abs/2311.17901)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17901.md)]
- Knowledge Pursuit Prompting for Zero-Shot Multimodal Synthesis - [[Arxiv](https://arxiv.org/abs/2311.17898)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17898.md)]
- Betrayed by Attention: A Simple yet Effective Approach for
  Self-supervised Video Object Segmentation - [[Arxiv](https://arxiv.org/abs/2311.17893)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17893.md)]
- A Pipeline For Discourse Circuits From CCG - [[Arxiv](https://arxiv.org/abs/2311.17892)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17892.md)]
- Pose Anything: A Graph-Based Approach for Category-Agnostic Pose
  Estimation - [[Arxiv](https://arxiv.org/abs/2311.17891)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17891.md)]
- Are ensembles getting better all the time? - [[Arxiv](https://arxiv.org/abs/2311.17885)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17885.md)]
- TSDF-Sampling: Efficient Sampling for Neural Surface Field using
  Truncated Signed Distance Field - [[Arxiv](https://arxiv.org/abs/2311.17878)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17878.md)]
- Enhancing Post-Hoc Explanation Benchmark Reliability for Image
  Classification - [[Arxiv](https://arxiv.org/abs/2311.17876)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17876.md)]
- FisherRF: Active View Selection and Uncertainty Quantification for
  Radiance Fields using Fisher Information - [[Arxiv](https://arxiv.org/abs/2311.17874)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17874.md)]
- SAIBench: A Structural Interpretation of AI for Science Through
  Benchmarks - [[Arxiv](https://arxiv.org/abs/2311.17869)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17869.md)]
- Evaluation of a measurement system for PET imaging studies - [[Arxiv](https://arxiv.org/abs/2311.17863)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17863.md)]
- Method for robotic motion compensation during PET imaging of mobile
  subjects - [[Arxiv](https://arxiv.org/abs/2311.17861)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17861.md)]
- Gaussian Shell Maps for Efficient 3D Human Generation - [[Arxiv](https://arxiv.org/abs/2311.17857)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17857.md)]
- Leveraging Graph Diffusion Models for Network Refinement Tasks - [[Arxiv](https://arxiv.org/abs/2311.17856)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17856.md)]
- Maximum Entropy Model Correction in Reinforcement Learning - [[Arxiv](https://arxiv.org/abs/2311.17855)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17855.md)]
- Evaluating VLMs for Score-Based, Multi-Probe Annotation of 3D Objects - [[Arxiv](https://arxiv.org/abs/2311.17851)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2311.17851.md)]

## List of Papers by Year
- [Papers for 2023](https://github.com/taesiri/ArXivQA/blob/main/Papers-2023.md)
- [Papers for 2022](https://github.com/taesiri/ArXivQA/blob/main/Papers-2022.md)
- [Papers for 2021](https://github.com/taesiri/ArXivQA/blob/main/Papers-2021.md)
- [Papers for 2020](https://github.com/taesiri/ArXivQA/blob/main/Papers-2020.md)
- [Papers for 2019](https://github.com/taesiri/ArXivQA/blob/main/Papers-2019.md)
- [Papers for 2018](https://github.com/taesiri/ArXivQA/blob/main/Papers-2018.md)
- [Papers for 2017](https://github.com/taesiri/ArXivQA/blob/main/Papers-2017.md)
- [Papers for 2016](https://github.com/taesiri/ArXivQA/blob/main/Papers-2016.md)
- [Papers for 2015](https://github.com/taesiri/ArXivQA/blob/main/Papers-2015.md)
- [Papers for 2014](https://github.com/taesiri/ArXivQA/blob/main/Papers-2014.md)
- [Papers for 2013](https://github.com/taesiri/ArXivQA/blob/main/Papers-2013.md)
- [Papers for 2012](https://github.com/taesiri/ArXivQA/blob/main/Papers-2012.md)
- [Papers for 2010](https://github.com/taesiri/ArXivQA/blob/main/Papers-2010.md)
- [Papers for 2009](https://github.com/taesiri/ArXivQA/blob/main/Papers-2009.md)

## Acknowledgements
This project is made possible through the generous support of [Anthropic](https://www.anthropic.com/), who provided free access to the `Claude-2.1` API.
