# Automated Question Answering with ArXiv Papers

## Latest 25 Papers
- Scaling Laws of Synthetic Images for Model Training ... for Now - [[Arxiv](https://arxiv.org/abs/2312.04567)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04567.md)]
- Gen2Det: Generate to Detect - [[Arxiv](https://arxiv.org/abs/2312.04566)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04566.md)]
- MuRF: Multi-Baseline Radiance Fields - [[Arxiv](https://arxiv.org/abs/2312.04565)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04565.md)]
- EAGLES: Efficient Accelerated 3D Gaussians with Lightweight EncodingS - [[Arxiv](https://arxiv.org/abs/2312.04564)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04564.md)]
- Visual Geometry Grounded Deep Structure From Motion - [[Arxiv](https://arxiv.org/abs/2312.04563)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04563.md)]
- NeRFiller: Completing Scenes via Generative 3D Inpainting - [[Arxiv](https://arxiv.org/abs/2312.04560)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04560.md)]
- GenDeF: Learning Generative Deformation Field for Video Generation - [[Arxiv](https://arxiv.org/abs/2312.04561)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04561.md)]
- PrimDiffusion: Volumetric Primitives Diffusion for 3D Human Generation - [[Arxiv](https://arxiv.org/abs/2312.04559)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04559.md)]
- MonoGaussianAvatar: Monocular Gaussian Point-based Head Avatar - [[Arxiv](https://arxiv.org/abs/2312.04558)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04558.md)]
- GenTron: Delving Deep into Diffusion Transformers for Image and Video
  Generation - [[Arxiv](https://arxiv.org/abs/2312.04557)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04557.md)]
- Large Language Models for Mathematicians - [[Arxiv](https://arxiv.org/abs/2312.04556)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04556.md)]
- Improved Visual Grounding through Self-Consistent Explanations - [[Arxiv](https://arxiv.org/abs/2312.04554)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04554.md)]
- SPIDeRS: Structured Polarization for Invisible Depth and Reflectance
  Sensing - [[Arxiv](https://arxiv.org/abs/2312.04553)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04553.md)]
- Generating Illustrated Instructions - [[Arxiv](https://arxiv.org/abs/2312.04552)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04552.md)]
- Free3D: Consistent Novel View Synthesis without 3D Representation - [[Arxiv](https://arxiv.org/abs/2312.04551)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04551.md)]
- Multiview Aerial Visual Recognition (MAVREC): Can Multi-view Improve
  Aerial Visual Perception? - [[Arxiv](https://arxiv.org/abs/2312.04548)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04548.md)]
- PlayFusion: Skill Acquisition via Diffusion from Language-Annotated Play - [[Arxiv](https://arxiv.org/abs/2312.04549)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04549.md)]
- Digital Life Project: Autonomous 3D Characters with Social Intelligence - [[Arxiv](https://arxiv.org/abs/2312.04547)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04547.md)]
- Adversarial Learning for Feature Shift Detection and Correction - [[Arxiv](https://arxiv.org/abs/2312.04546)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04546.md)]
- HyperDreamer: Hyper-Realistic 3D Content Generation and Editing from a
  Single Image - [[Arxiv](https://arxiv.org/abs/2312.04543)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04543.md)]
- SoK: Unintended Interactions among Machine Learning Defenses and Risks - [[Arxiv](https://arxiv.org/abs/2312.04542)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04542.md)]
- Sim-to-Real Causal Transfer: A Metric Learning Approach to
  Causally-Aware Interaction Representations - [[Arxiv](https://arxiv.org/abs/2312.04540)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04540.md)]
- Self-Guided Open-Vocabulary Semantic Segmentation - [[Arxiv](https://arxiv.org/abs/2312.04539)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04539.md)]
- Trajeglish: Learning the Language of Driving Scenarios - [[Arxiv](https://arxiv.org/abs/2312.04535)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04535.md)]
- PICTURE: PhotorealistIC virtual Try-on from UnconstRained dEsigns - [[Arxiv](https://arxiv.org/abs/2312.04534)] [[QA](https://github.com/taesiri/ArXivQA/blob/main/papers/2312.04534.md)]

## List of Papers by Year
- [Papers for 2023](https://github.com/taesiri/ArXivQA/blob/main/Papers-2023.md)
- [Papers for 2022](https://github.com/taesiri/ArXivQA/blob/main/Papers-2022.md)
- [Papers for 2021](https://github.com/taesiri/ArXivQA/blob/main/Papers-2021.md)
- [Papers for 2020](https://github.com/taesiri/ArXivQA/blob/main/Papers-2020.md)
- [Papers for 2019](https://github.com/taesiri/ArXivQA/blob/main/Papers-2019.md)
- [Papers for 2018](https://github.com/taesiri/ArXivQA/blob/main/Papers-2018.md)
- [Papers for 2017](https://github.com/taesiri/ArXivQA/blob/main/Papers-2017.md)
- [Papers for 2016](https://github.com/taesiri/ArXivQA/blob/main/Papers-2016.md)
- [Papers for 2015](https://github.com/taesiri/ArXivQA/blob/main/Papers-2015.md)
- [Papers for 2014](https://github.com/taesiri/ArXivQA/blob/main/Papers-2014.md)
- [Papers for 2013](https://github.com/taesiri/ArXivQA/blob/main/Papers-2013.md)
- [Papers for 2012](https://github.com/taesiri/ArXivQA/blob/main/Papers-2012.md)
- [Papers for 2010](https://github.com/taesiri/ArXivQA/blob/main/Papers-2010.md)
- [Papers for 2009](https://github.com/taesiri/ArXivQA/blob/main/Papers-2009.md)

## Acknowledgements
This project is made possible through the generous support of [Anthropic](https://www.anthropic.com/), who provided free access to the `Claude-2.1` API.
